<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="175._10.1.1.48.3960"/>
	</teiHeader>
	<text xml:lang="en">
		<front>
<lb/>
	<docTitle>
	<titlePart>Learning stable concepts in domains with hidden changes in context<lb/></titlePart>
	</docTitle>

	<byline>
	<docAuthor>Michael Harries<lb/></docAuthor>
	</byline>

	<byline>
	<affiliation>Department of Arti cial Intelligence<lb/> School of Computer Science and Engineering<lb/> University of NSW,</affiliation>
	</byline>

	<address>Sydney 2052, Australia<lb/></address>

	<email>mbh@cse.unsw.edu.au<lb/></email>

	<byline>
	<docAuthor>Kim Horn<lb/></docAuthor>
	</byline>

	<byline>
	<affiliation>Predictive Strategies Unit<lb/> Australian Gilt Securities Limited<lb/></affiliation>
	</byline>

	<address>Sydney, Australia<lb/></address>

	<email>kim@ags.com.au</email>

	Abstract<lb/>
	<div type="abstract">This paper presents Splice, a batch meta-<lb/>learning system, designed to learn locally sta-<lb/>ble concepts in domains with hidden changes<lb/> in context. The majority of machine learning<lb/> algorithms assume that target concepts re-<lb/>main stable over time. In many domains this<lb/> assumption is invalid. For example, nan-<lb/>cial prediction, medical diagnosis, and net-<lb/>work performance are domains in which tar-<lb/>get concepts may not remain stable. Unsta-<lb/>ble target concepts are often due to changes<lb/> in a hidden context. Existing works on learn-<lb/>ing in the presence of hidden changes in con-<lb/>text use an incremental learning approach.</div>

		</front>
	</text>
</tei>
