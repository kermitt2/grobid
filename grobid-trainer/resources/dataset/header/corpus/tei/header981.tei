<tei>
	<teiHeader>
	<fileDesc xml:id="1050"/>
	</teiHeader>
<text xml:lang="en">
		<front>
		<docTitle>
			<titlePart type="main">OVERVIEW OF THE CLEF 2008 <lb/> MULTILINGUAL QUESTION ANSWERING <lb/> TRACK <lb/></titlePart>
		</docTitle>
		<byline><docAuthor>Pamela Forner 1 , Anselmo Peñas 2 , Eneko Agirre 3 , Iñaki Alegria 4 , Corina <lb/> For?scu 5 , Nicolas Moreau 6 , Petya Osenova 7 , Prokopis Prokopidis 8 , Paulo Ro- <lb/> cha 9 , Bogdan Sacaleanu 10 , Richard Sutcliffe 11 , and Erik Tjong Kim Sang 12 <lb/></docAuthor></byline>
		<byline><affiliation>1 CELCT,</affiliation></byline>
		<address>Trento, Italy</address>
		<email>(forner@celct.it) <lb/></email>
		<byline><affiliation>2 Departamento de Lenguajes y Sistemas Informíticos, UNED,</affiliation></byline>
		<address>Madrid, Spain <lb/></address>
		<email>(anselmo@lsi.uned.es) <lb/></email>
		<byline><affiliation>3 Computer Science Department, University of Basque Country,</affiliation></byline>
		<address>Spain</address>
		<email>(e.agirre@ehu.es) <lb/></email>
		<byline><affiliation>4 <lb/>  University of Basque Country,</affiliation></byline>
		<address>Spain</address>
		<email>(i.alegria@ehu.es) <lb/></email>
		<byline><affiliation>5 UAIC and RACAI,</affiliation></byline>
		<address>Romania</address>
		<email>(corinfor@info.uaic.ro) <lb/></email>
		<byline><affiliation>6 ELDA/ELRA,</affiliation></byline>
		<address>Paris, France</address>
		<email>(moreau@elda.org) <lb/></email>
		<byline><affiliation>7 BTB,</affiliation></byline>
		<address>Bulgaria,</address>
		<email>(petya@bultreebank.org) <lb/></email>
		<byline><affiliation>8 ILSP Greece, Athena Research Center</affiliation></byline>
		<email>(prokopis@ilsp.gr) <lb/></email>
		<byline><affiliation>9 Linguateca, DEI UC,</affiliation></byline>
		<address>Portugal,</address>
		<email>(Paulo.Rocha@di.uminho.pt) <lb/></email>
		<byline><affiliation>10 DFKI,</affiliation></byline>
		<address>Germany,</address>
		<email>(bogdan@dfki.de) <lb/></email>
		<byline><affiliation>11 DLTG, University of Limerick,</affiliation></byline>
		<address>Ireland</address>
		<email>(richard.sutcliffe@ul.ie) <lb/></email>
		<byline><affiliation>12 University of Groningen</affiliation></byline>
		<email>(e.f.tjong.kim.sang@rug.nl) <lb/></email>
		<div type="abstract">Abstract The QA campaign at CLEF [1], was manly the same as that proposed <lb/> last year. The results and the analyses reported by last year&apos;s participants sug- <lb/> gested that the changes introduced in the previous campaign had led to a drop in <lb/> systems&apos; performance. So for this year&apos;s competition it has been decided to practi- <lb/> cally replicate last year&apos;s exercise. <lb/> Following last year&apos;s experience some QA pairs were grouped in clusters. Every <lb/> cluster was characterized by a topic (not given to participants). The questions from <lb/> a cluster contained co-references between one of them and the others. Moreover, <lb/> as last year, the systems were given the possibility to search for answers in Wiki- <lb/> pedia 1 as document corpus beside the usual newswire collection. <lb/> In addition to the main task, three additional exercises were offered, namely the <lb/> Answer Validation Exercise (AVE), the Question Answering on Speech Tran- <lb/> scriptions (QAST), which continued last year&apos;s successful pilot, and Word Sense <lb/> Disambiguation for Question Answering (QA-WSD). <lb/> As general remark, it must be said that the task still proved to be very challenging <lb/> for participating systems. In comparison with last year&apos;s results the Best Overall <lb/> Accuracy dropped significantly from 41,75% to 19% in the multi-lingual subtasks, <lb/>  1  http://wikipedia.org <lb/>  while instead it increased a little in the monolingual sub-tasks, going from 54% to <lb/> 63,5%. <lb/></div>
		<div type="intro">1 Introduction <lb/></div>
		</front>
</text>
</tei>