<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>BRIEF COMMUNICATION <lb/>OPEN <lb/>Digital biomarkers of cognitive function <lb/>Paul Dagum 1 <lb/>To identify digital biomarkers associated with cognitive function, we analyzed human-computer interaction from 7 days of <lb/>smartphone use in 27 subjects (ages 18-34) who received a gold standard neuropsychological assessment. For several <lb/>neuropsychological constructs (working memory, memory, executive function, language, and intelligence), we found a family of <lb/>digital biomarkers that predicted test scores with high correlations (p &lt; 10 −4 ). These preliminary results suggest that passive <lb/>measures from smartphone use could be a continuous ecological surrogate for laboratory-based neuropsychological assessment. <lb/>npj Digital Medicine (2018) 1:10 ; doi:10.1038/s41746-018-0018-4 <lb/></front>

			<body>INTRODUCTION <lb/>By comparison to the functional metrics available in other <lb/>disciplines, conventional measures of neuropsychiatric disorders <lb/>have several challenges. First, they are obtrusive, requiring a <lb/>subject to break from their normal routine, dedicating time and <lb/>often travel. Second, they are not ecological and require subjects <lb/>to perform a task outside of the context of everyday behavior. <lb/>Third, they are episodic and provide sparse snapshots of a patient <lb/>only at the time of the assessment. Lastly, they are poorly scalable, <lb/>taxing limited resources including space and trained staff. <lb/>In seeking objective and ecological measures of cognition, we <lb/>attempted to develop a method to measure memory and <lb/>executive function not in the laboratory but in the moment, <lb/>day-to-day. We used human-computer interaction on smart-<lb/>phones to identify digital biomarkers that were correlated with <lb/>neuropsychological performance. <lb/>RESULTS <lb/>In 2014, 27 participants (ages 27.1 ± 4.4 years, education <lb/>14.1 ± 2.3 years, M:F 8:19) volunteered for neuropsychological <lb/>assessment and a test of the smartphone app. Smartphone <lb/>human-computer interaction data from the 7 days following <lb/>the neuropsychological assessment showed a range of correla-<lb/>tions with the cognitive scores. Table 1 shows the correlation <lb/>between each neurocognitive test and the cross-validated <lb/>predictions of the supervised kernel PCA constructed from <lb/>the biomarkers for that test. Figure 1 shows each participant <lb/>test score and the digital biomarker prediction for (a) digits <lb/>backward, (b) symbol digit modality, (c) animal fluency, <lb/>(d) Wechsler Memory Scale-3rd Edition (WMS-III) logical <lb/>memory (delayed free recall), (e) brief visuospatial memory test <lb/>(delayed free recall), and (f) Wechsler Adult Intelligence Scale-<lb/>4th Edition (WAIS-IV) block design. Construct validity of the <lb/>predictions was determined using pattern matching that <lb/>computed a correlation of 0.87 with p &lt; 10 −59 between the <lb/>covariance matrix of the predictions and the covariance matrix <lb/>of the tests. <lb/>Table 1. Fourteen neurocognitive assessments covering five cognitive <lb/>domains and dexterity were performed by a neuropsychologist. <lb/>Shown are the group mean and standard deviation, range of score, <lb/>and the correlation between each test and the cross-validated <lb/>prediction constructed from the digital biomarkers for that test <lb/>Cognitive predictions <lb/>Mean (SD) Range R (predicted), <lb/>p-value <lb/>Working memory <lb/>Digits forward <lb/>10.9 (2.7) <lb/>7-15 0.71 ± 0.10, 10 −4 <lb/>Digits backward <lb/>8.3 (2.7) <lb/>4-14 0.75 ± 0.08, 10 −5 <lb/>Executive function <lb/>Trail A <lb/>23.0 (7.6) <lb/>12-39 0.70 ± 0.10, 10 −4 <lb/>Trail B <lb/>53.3 (13.1) 37-88 0.82 ± 0.06, 10 −6 <lb/>Symbol digit modality <lb/>55.8 (7.7) <lb/>43-67 0.70 ± 0.10, 10 −4 <lb/>Language <lb/>Animal fluency <lb/>22.5 (3.8) <lb/>15-30 0.67 ± 0.11, 10 −4 <lb/>FAS phonemic fluency <lb/>42 (7.1) <lb/>27-52 0.63 ± 0.12, 10 −3 <lb/>Dexterity <lb/>Grooved pegboard test <lb/>(dominant hand) <lb/>62.7 (6.7) <lb/>51-75 0.73 ± 0.09, 10 −4 <lb/>Memory <lb/>California verbal learning test <lb/>(delayed free recall) <lb/>14.1 (1.9) <lb/>9-16 0.62 ± 0.12, 10 −3 <lb/>WMS-III logical memory <lb/>(delayed free recall) <lb/>29.4 (6.2) <lb/>18-42 0.81 ± 0.07, 10 −6 <lb/>Brief visuospatial memory test <lb/>(delayed free recall) <lb/>10.2 (1.8) <lb/>5-12 0.77 ± 0.08, 10 −5 <lb/>Intelligence scale <lb/>WAIS-IV block design <lb/>46.1(12.8) <lb/>12-61 0.83 ± 0.06, 10 −6 <lb/>WAIS-IV matrix reasoning <lb/>22.1(3.3) <lb/>12-26 0.80 ± 0.07, 10 −6 <lb/>WAIS-IV vocabulary <lb/>40.6(4.0) <lb/>31-50 0.67 ± 0.11, 10 −4 <lb/></body>

			<front>Received: 5 October 2017 Revised: 3 February 2018 Accepted: 7 February 2018 <lb/>1 <lb/>Mindstrong Health, 248 Homer Street, Palo Alto, CA 94301, USA <lb/>Correspondence: Paul Dagum (paul@mindstronghealth.com) <lb/>www.nature.com/npjdigitalmed <lb/>Published in partnership with the Scripps Translational Science Institute <lb/></front>

			<body>DISCUSSION <lb/>We have shown that we can generate digital biomarkers <lb/>correlated with gold-standard neurocognitive tests using passively <lb/>acquired data during daily use of a smartphone. Using supervised <lb/>kernel PCA we can generate cross-validated predictions of the test <lb/>scores with precision comparable to the gold-standard test-retest <lb/>reliabilities. 1,2 These digital biomarkers offer several advantages to <lb/>conventional assessments. First, they are unobtrusive, placing no <lb/>burden on the subject beyond the normal use of a smartphone. <lb/>Second, they are ecological since the smartphone data is captured <lb/>in a natural environment. Third, they provide dense daily <lb/>assessments with potential insight into hour to hour or day to <lb/>day variations in cognitive function. Lastly, they could scale <lb/>globally with three billion smartphone users today, projected to <lb/>6 billion by 2020 (https://techcrunch.com/2015/06/02/6-1b-<lb/>smartphone-users-globally-by-2020-overtaking-basic-fixed-phone-<lb/>subscriptions/). <lb/>An obvious limitation of this pilot study is the small size (n = 27) <lb/>relative to the large number of potential biomarkers (n = 1035). To <lb/>counter the risk of over-fitting these results, predictions were <lb/>made using leave-one-out cross validation (LOOCV), stringent <lb/>confidence level (p &lt; 10 −4 ) and a simple linear kernel that was <lb/>regularized. Nevertheless, these results should be considered <lb/>preliminary until replicated in an independent sample. A further <lb/>limitation is that the neuropsychological assessment occurred at <lb/>one time point and the digital features were collected ecologically <lb/>over the first 7 days following the assessment. For clinical <lb/>assessments, one might argue that the real-world, continuous <lb/>assessment would yield critical information relevant to function. <lb/>Fig. 1 A blue square represents a participant test Z-score normed to the 27 participant scores and a red circle represents the digital biomarker <lb/>prediction Z-score normed to the 27 predictions. Test scores and predictions shown are a digits backward, b symbol digit modality, c animal <lb/>fluency, d Wechsler memory Scale-3rd Edition (WMS-III) logical memory (delayed free recall), e brief visuospatial memory test (delayed free <lb/>recall), and f Wechsler adult intelligence scale-4th Edition (WAIS-IV) block design <lb/></body>

			<note place="headnote">Digital biomarkers of cognitive function <lb/>P Dagum <lb/></note>

			<page>2 <lb/></page>

			<note place="footnote">npj Digital Medicine (2018) 10 <lb/>Published in partnership with the Scripps Translational Science Institute <lb/></note>

			1234567890():,; <lb/>

			<body>Indeed, we postulate that the daily variability in the digital <lb/>biomarkers will provide rich temporal insight into state-dependent <lb/>changes in cognition and emotional health that may arise from <lb/>disease and environmental effects. The selection of 7 days <lb/>provided ecological data from which to select the peak value of <lb/>each biomarker, which consistently led to the best predictions, <lb/>suggesting that in the laboratory a participant performs at their <lb/>best while in the real-world the participant&apos;s function will deviate <lb/>from peak depending on disease and environmental effects. <lb/>Several large clinical studies will confirm our hypothesis and <lb/>further establish the clinical utility of our approach. <lb/>METHOD <lb/>All participants, recruited via social media, signed an informed consent <lb/>form. Inclusion criteria required participants to be functional English <lb/>speaking and active users of a smartphone. The protocol involved 3 h of <lb/>psychometric assessment, installation of an app on their smartphone. The <lb/>test battery is shown in the first column of Table 1. A single <lb/>psychometrician performed all testing in a standard assessment clinic. <lb/>The app on the phone ran passively in the background and captured <lb/>tactile user activity that included swipes, taps, and keystroke events, <lb/>collectively termed human-computer interactions (HCI). <lb/>From the HCI events we identified 45 event patterns. Each pattern <lb/>represents a task that is repeated up to several hundred times per day by a <lb/>user during normal use of their phone. Most patterns consisted of two <lb/>successive events, such as tapping on the space-bar followed by the first <lb/>character of a word, or tapping delete followed by another delete tap. <lb/>Some patterns were collected in a specific context of use. For example, <lb/>tapping on a character followed by another character could be collected at <lb/>the beginning of a word, middle of a word, or end of a word. Each pattern <lb/>generated a time-series composed of the time interval between patterns. <lb/>The time-series were segmented into daily time-series. To each daily time-<lb/>series we applied 23 mathematical transforms to produce 1035 distinct <lb/>daily measurements that we term digital biomarkers. <lb/>For each participant we selected the first 7 days of data following their <lb/>test date. A biomarker was considered a candidate for a neurocognitive <lb/>test if over the 7 day window the 7 correlations between sorted biomarker <lb/>values and the test scores were stable (meaning of the same sign). The <lb/>two-dimensional design matrix for the supervised kernel PCA was <lb/>constructed by selecting the peak value of each candidate biomarker <lb/>over the 7 days. For each test, we constructed a linear reproducing Hilbert <lb/>space kernel from the biomarkers and used a supervised kernel principal <lb/>component analysis 3 with LOOCV as follows. To predict the 1st participant <lb/>test result the model fitting algorithm was run on the remaining <lb/>participants without access to the 1st participant&apos;s data, and so forth <lb/>iterating 27 times to generate the 27 predictions. <lb/></body>

			<div type="availability">Code availability <lb/>The code that support the findings of this study are available on <lb/>reasonable request from the author. <lb/></div>

			<div type="availability">Data availability <lb/>The data that support the findings of this study are available on reasonable <lb/>request from the author. <lb/></div>

			<div type="acknowledgement">ACKNOWLEDGEMENTS <lb/>The author is grateful to the intellectual feedback and support of Tom Insel and Rick <lb/>Klausner. This work was self-funded. <lb/></div>

			<div type="annex">ADDITIONAL INFORMATION <lb/>Competing Interests: This paper describes results from the use of a proprietary <lb/>product for which the author holds multiple US patents. The author is a significant <lb/>share holder of Mindstrong Health that owns the intellectual property for commercial <lb/>use. <lb/>Publisher&apos;s note: Springer Nature remains neutral with regard to jurisdictional claims <lb/>in published maps and institutional affiliations. <lb/></div>

			<listBibl>REFERENCES <lb/>1. Strauss, E., Sherman, E. M. S. &amp; Spreen, O. A compendium of neuropsychological <lb/>tests. Administration, Norms, and Commentary. Third edition, (Oxford University <lb/>Press, New York, NY, 2006). <lb/>2. Heaton, R. K., Akschoomoff, N., Tulsky, D. &amp; Mungas, D. Reliability and validity of <lb/>composite scores from the NIH Toolbox Cognition Battery in adults. J. Int. Neu-<lb/>ropsychol Soc. 20, 588-598 (2014). <lb/>3. Barshan, E., Ghodsi, A., Azimifar, Z. &amp; Jahromi, M. Z. Supervised principal compo-<lb/>nent analysis: Visualization, classification and regression on subspaces and sub-<lb/>manifolds. Pattern Recognit. 44, 1357-1371 (2011). <lb/></listBibl>

			<front>Open Access This article is licensed under a Creative Commons <lb/>Attribution 4.0 International License, which permits use, sharing, <lb/>adaptation, distribution and reproduction in any medium or format, as long as you give <lb/>appropriate credit to the original author(s) and the source, provide a link to the Creative <lb/>Commons license, and indicate if changes were made. The images or other third party <lb/>material in this article are included in the article&apos;s Creative Commons license, unless <lb/>indicated otherwise in a credit line to the material. If material is not included in the <lb/>article&apos;s Creative Commons license and your intended use is not permitted by statutory <lb/>regulation or exceeds the permitted use, you will need to obtain permission directly <lb/>from the copyright holder. To view a copy of this license, visit http://creativecommons. <lb/>org/licenses/by/4.0/. <lb/>© The Author(s) 2018 <lb/></front>

			<note place="headnote">Digital biomarkers of cognitive function <lb/>P Dagum <lb/></note>

			<page>3 <lb/></page>

			<note place="footnote">Published in partnership with the Scripps Translational Science Institute <lb/>npj Digital Medicine (2018) 10 </note>


	</text>
</tei>
