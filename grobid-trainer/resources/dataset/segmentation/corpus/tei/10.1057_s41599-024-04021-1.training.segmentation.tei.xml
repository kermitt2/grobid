<TEI xmlns="http://www.tei-c.org/ns/1.0">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title level="a">Violence against women and girls in Dorset, United Kingdom: an epidemiological study of perpetrators and locations based on police records</title>
        <author>
          <persName>
            <forename>Jessica</forename>
            <surname>Pearcey</surname>
          </persName>
        </author>
        <author>
          <persName>
            <forename>Barak</forename>
            <surname>Ariel</surname>
          </persName>
        </author>
        <author>
          <persName>
            <forename>Vincent</forename>
            <surname>Harinam</surname>
          </persName>
        </author>
        <author>
          <persName>
            <forename>Noy</forename>
            <surname>Assaraf</surname>
          </persName>
        </author>
      </titleStmt>
      <editionStmt>
        <edition>
          <date when="2025-10-28T09:22:34.481169Z">28.10.2025 09:22:34</date>
          <title>grobid.training.segmentation [default]</title>
          <idno type="fileref">10.1057$1$s41599-024-04021-1</idno>
        </edition>
      </editionStmt>
      <publicationStmt>
        <publisher>Springer Science and Business Media LLC</publisher>
        <availability>
          <licence target="https://creativecommons.org/licenses/by/4.0/"/>
        </availability>
        <date type="publication">2024</date>
        <idno type="DOI">10.1057/s41599-024-04021-1</idno>
      </publicationStmt>
      <sourceDesc>
        <bibl>Jessica Pearcey, Barak Ariel, Vincent Harinam, Noy Assaraf. (2024). Violence against women and girls in Dorset, United Kingdom: an epidemiological study of perpetrators and locations based on police records. Humanities and Social Sciences Communications, 11(1), None. DOI: 10.1057/s41599-024-04021-1</bibl>
      </sourceDesc>
    </fileDesc>
    <encodingDesc>
      <appInfo>
        <application version="1.0" ident="pdf-tei-editor" type="editor">
          <ref target="https://github.com/mpilhlt/pdf-tei-editor"/>
        </application>
        <application version="0.8.3-SNAPSHOT" ident="GROBID" when="2025-10-28T09:22:34.481169Z" type="extractor">
          <desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
          <label type="revision">eb7768b</label>
          <label type="flavor">default</label>
          <label type="variant-id">grobid.training.segmentation</label>
          <ref target="https://github.com/kermitt2/grobid"/>
        </application>
      </appInfo>
    </encodingDesc>
    <revisionDesc>
      <change when="2025-10-28T09:22:34.481169Z" status="draft">
        <desc>Generated with createTraining API</desc>
      </change>
    </revisionDesc>
  </teiHeader>
  <text xmlns="http://www.tei-c.org/ns/1.0" xml:lang="en">
			<front>1 <lb/>All-optical complex field imaging using diffractive processors <lb/>Jingxi Li 1,2,3 , Yuhang Li 1,2,3 , Tianyi Gan 1,3 , Che-Yung Shen 1,2,3 , Mona Jarrahi 1,3 , and Aydogan <lb/>Ozcan 1,2,3* <lb/>1 Electrical and Computer Engineering Department, University of California, Los Angeles, CA, <lb/>90095, USA <lb/>2 Bioengineering Department, University of California, Los Angeles, CA, 90095, USA <lb/>3 California NanoSystems Institute (CNSI), University of California, Los Angeles, CA, 90095, <lb/>USA <lb/>* <lb/>Correspondence to: ozcan@ucla.edu <lb/>Abstract <lb/>Complex field imaging, which captures both the amplitude and phase information of input optical <lb/>fields or objects, can offer rich structural insights into samples, such as their absorption and <lb/>refractive index distributions. However, conventional image sensors are intensity-based and <lb/>inherently lack the capability to directly measure the phase distribution of a field. This limitation <lb/>can be overcome using interferometric or holographic methods, often supplemented by iterative <lb/>phase retrieval algorithms, leading to a considerable increase in hardware complexity and <lb/>computational demand. Here, we present a complex field imager design that enables snapshot <lb/>imaging of both the amplitude and quantitative phase information of input fields using an intensity-<lb/>based sensor array without any digital processing. Our design utilizes successive deep learning-<lb/>optimized diffractive surfaces that are structured to collectively modulate the input complex field, <lb/>forming two independent imaging channels that perform amplitude-to-amplitude and phase-to-<lb/>intensity transformations between the input and output planes within a compact optical design, <lb/>axially spanning ~100 wavelengths. The intensity distributions of the output fields at these two <lb/>channels on the sensor plane directly correspond to the amplitude and quantitative phase profiles <lb/>of the input complex field, eliminating the need for any digital image reconstruction algorithms. <lb/>We experimentally validated the efficacy of our complex field diffractive imager designs through <lb/>3D-printed prototypes operating at the terahertz spectrum, with the output amplitude and phase <lb/>channel images closely aligning with our numerical simulations. We envision that this complex <lb/>field imager will have various applications in security, biomedical imaging, sensing and material <lb/>science, among others. <lb/></front>

			<page>2 <lb/></page>

			<body>Introduction <lb/>Optical imaging can characterize diverse properties of light, including amplitude, phase, <lb/>wavelength, and polarization, which provides abundant information about samples, such as their <lb/>morphology and composition. However, conventional image sensors and focal plane arrays, based <lb/>on e.g., Complementary Metal-Oxide-Semiconductor (CMOS) or Charge-Coupled Device (CCD) <lb/>technologies, are inherently constrained to detecting only the intensity of the optical field <lb/>impinging on their active area. Measuring the phase information of a complex field presents <lb/>challenges, which require indirect encoding through interferometric or holographic detection <lb/>systems 1-3 . Some of the traditional examples of phase imaging techniques include Zernike phase <lb/>contrast microscopy and interferometric microscopy. Subsequent developments of quantitative <lb/>phase imaging (QPI) have enabled high-precision characterization of phase information; <lb/>advancements such as the Fourier phase microscopy 4 , Hilbert phase microscopy 5 and digital <lb/>holographic microscopy 6-12 have also emerged, making QPI a potent label-free optical <lb/>measurement technique. Nevertheless, these QPI methods often necessitate relatively bulky <lb/>experimental setups and rely on iterative algorithms based on multiple measurements to digitally <lb/>reconstruct the desired phase information, leading to slow imaging speeds. <lb/>Recently, fueled by the advances made in deep learning, the application of deep neural networks <lb/>has been adopted for accurate and rapid reconstruction of phase information in complex fields <lb/>through a single feed-forward operation 13-20 . While these deep learning-based approaches offer <lb/>considerable benefits, they typically demand intensive computational resources for network <lb/>inference, requiring the use of graphics processing units (GPUs). Simultaneously, the progress in <lb/>micro-and nano-fabrication technologies facilitated the development of metasurfaces 21-29 and <lb/>thin-film optical components 30,31 for QPI applications. However, the functionality of these devices <lb/>still relies on indirect encoding processes that generate intensity variations on the sensor plane, <lb/>such as diffused speckles 21 or polarized interference patterns 29 . These existing solutions, therefore, <lb/>necessitate digital computation for image reconstruction and, in certain cases, also require the <lb/>incorporation of additional hardware along the optical path, such as polarizers and polarization <lb/>cameras. <lb/>In this work, we demonstrate the design of a complex field imager that can directly capture the <lb/>amplitude and phase distributions of an incoming field using an intensity-only image sensor array. <lb/>As shown in Fig. 1a, this complex field imager is composed of a series of spatially engineered <lb/>diffractive surfaces (layers) 32-49 , optimized using supervised deep learning algorithms to <lb/>simultaneously perform two tasks: (1) an amplitude-to-amplitude (Aâ†’A) transformation and (2) <lb/>a phase-to-intensity (Pâ†’I) transformation. Here, the first task involves mapping the amplitude of <lb/>the incoming complex field to a specific output field of view (FOV) that is solely dedicated to <lb/>amplitude imaging, independent of the input wave&apos;s phase profile. The second task, on the other <lb/>hand, aims to approximate a nonlinear transformation by converting the phase of the incoming <lb/>wave into an intensity pattern at another output FOV, exclusively used for quantitative phase <lb/>imaging, QPI. Therefore, by placing complex objects or feeding complex fields into the input FOV <lb/>of the diffractive complex field imager and measuring the intensity distributions at its output FOVs, <lb/>the amplitude and phase information of the input complex objects/fields can be directly obtained <lb/>within a single intensity-only image recording step, eliminating the necessity for any form of image <lb/>reconstruction algorithms. In addition to this spatially multiplexed design of the diffractive <lb/>complex field imager, termed design I (Fig. 1a), we also explored additional complex field imager <lb/>designs by incorporating wavelength multiplexing. As illustrated in Fig. 1b and c, these <lb/></body>

			<page>3 <lb/></page>

			<body>wavelength multiplexed designs, termed designs II and III, operate by detecting the output <lb/>amplitude and phase signals at two distinct wavelengths (ğœ† 1 and ğœ† 2 , respectively). The difference <lb/>between designs II and III is that the design II utilizes a shared FOV for both the amplitude and <lb/>phase channel outputs, while the design III maintains two spatially separated FOVs, each dedicated <lb/>to either the output amplitude or phase images. <lb/>After completing the training of these different designs, we blindly tested the performance and <lb/>generalization capabilities of our trained diffractive complex field imager models. We quantified <lb/>their imaging errors using thousands of examples of input complex fields, each composed of <lb/>independent information channels encoded in the amplitude and phase of the input field. The <lb/>results demonstrated that our diffractive models could successfully generalize to new, unseen <lb/>complex test fields, including those with structural features distinctly different from the training <lb/>objects. Through numerical simulations, we further analyzed the spatial resolution and sensitivity <lb/>of both the amplitude and phase channels of our diffractive complex field imagers. These analyses <lb/>revealed that our designs could resolve amplitude features with a linewidth of â‰¥1.5ğœ† m and phase <lb/>features with a linewidth of â‰¥3ğœ† m , where ğœ† m represents the mean wavelength. Furthermore, our <lb/>studies showed that by integrating an additional diffraction efficiency-related loss term into the <lb/>training function, one could achieve diffractive imager models with enhanced output power <lb/>efficiencies with minimal compromise in imaging performance. <lb/>Apart from these numerical analyses, we also conducted an experimental proof-of-concept <lb/>demonstration of our diffractive complex field imagers using the terahertz part of the spectrum by <lb/>fabricating the resulting diffractive layers using 3D printing. For our experiments, we constructed <lb/>test objects (never seen during the training) with spatially structured amplitude or phase <lb/>distributions through 3D printing and surface coating techniques. Our experimental results <lb/>successfully reconstructed the amplitude and phase images of the test objects, closely matching <lb/>our numerical simulations and the ground truth, validating the effectiveness of our diffractive <lb/>complex field imager designs. While our experimental demonstrations were conducted in the <lb/>terahertz spectrum, our designs are scalable and can be adapted to other spectral bands by scaling <lb/>their dimensions proportional to the wavelength of operation. The compact size of our diffractive <lb/>designs, with an axial span of ~100ï‚´ğœ† m , facilitates easy integration into existing optical imaging <lb/>systems and focal plane arrays that operate at different parts of the electromagnetic spectrum. This <lb/>complex field imager design also does not include any components that are sensitive to the <lb/>polarization of light, maintaining its amplitude and phase imaging function regardless of the input <lb/>polarization distribution of the input field. Given all these advantages, including the small footprint, <lb/>speed of all-optical computation and low-power operation, we believe that this all-optical complex <lb/>field imaging approach will find broad applications in e.g., defense/security, biomedical imaging, <lb/>sensing and material science. <lb/>Results <lb/>Designs of diffractive complex field imagers <lb/>Figure 1a illustrates a spatially multiplexed design of our diffractive complex field imager, termed <lb/>the design I. This diffractive imager is composed of 5 diffractive layers (i.e., L1, L2, â€¦, L5), where <lb/>each of these layers is spatially coded with 200Ã—200 diffractive features, with a lateral dimension <lb/>of approximately half of the illumination wavelength, i.e., ~ğœ†/2. These diffractive layers are <lb/></body>

			<page>4 <lb/></page>

			<body>positioned in a cascaded manner along the optical axis, resulting in a total axial length of 150ğœ† for <lb/>the entire design. A complex input object, ğ‘–(ğ‘¥, ğ‘¦) = ğ´(ğ‘¥, ğ‘¦)ğ‘’ ğ‘—ğœ™(ğ‘¥,ğ‘¦) , illuminated at ğœ† is placed at <lb/>the input plane in front of the diffractive layers. This complex object field exhibits an amplitude <lb/>distribution ğ´(ğ‘¥, ğ‘¦) that has a value range of [ADC, 1], along with a phase distribution ğœ™(ğ‘¥, ğ‘¦) <lb/>ranging within [0, ğ›¼Ï€]. Here, ADC denotes the minimum amplitude value of the input complex <lb/>field, and ğ›¼ is the phase contrast parameter of the input complex field. Without loss of generality, <lb/>we selected default values of ADC and ğ›¼ as 0.2 and 1, respectively, for our numerical <lb/>demonstrations. Note that it&apos;s essential to work with ADC â‰  0 since otherwise the phase would <lb/>become undefined. After the input complex fields are collectively modulated by these diffractive <lb/>layers L1-L5, the resulting optical fields ğ‘œ(ğœ†) at the output plane are measured by the detectors <lb/>within two spatially separated output FOVs, i.e., FOVPhase and FOVAmp, which produce intensity <lb/>distributions |ğ‘œ Phase (ğœ†)| 2 and |ğ‘œ Amp (ğœ†)| <lb/>2 that correspond to the phase and amplitude patterns of <lb/>each input complex field, respectively. In addition, we also defined a reference signal region â„› at <lb/>the periphery of the FOVPhase, wherein the average measured intensity across â„› is used as the <lb/>reference signal ğ‘…(ğœ†) for normalizing the quantitative phase signal |ğ‘œ Phase (ğœ†)| 2 . This <lb/>normalization process is essential to ensure that the detected phase information is independent of <lb/>the input light intensity fluctuations, yielding a quantitative phase image ğ‘‚ Phase (ğœ†) = <lb/>|ğ‘œ Phase (ğœ†)| 2 <lb/>ğ‘…(ğœ†) <lb/>, <lb/>regardless of the diffracted output power. Overall, the objective of our training process is to have <lb/>the phase image channel output approximate the ground truth phase distribution of the input <lb/>complex field, i.e., ğ‘‚ Phase (ğœ†) ï‚» ğœ™(ğœ†) , demonstrating an effective phase-to-intensity (Pâ†’I) <lb/>transformation. Concurrently, the training of the diffractive layers also aims to have the diffractive <lb/>output image in the amplitude channel, i.e., |ğ‘œ Amp (ğœ†)|, proportionally match the ground truth <lb/>amplitude distribution of the input complex field after subtracting the amplitude DC component <lb/>ADC, i.e., |ğ‘œ Amp (ğœ†)| âˆ (ğ´(ğœ†) -ğ´ ğ·ğ¶ ) , thereby achieving a successful amplitude-to-amplitude <lb/>(Aâ†’A) transformation performed by the diffractive processor. <lb/>In addition to the spatially multiplexed design I described above, we also created an alternative <lb/>complex field imager design named design II by incorporating wavelength multiplexing to <lb/>construct the amplitude and phase imaging channels. As illustrated in Fig. 1b, this approach <lb/>utilizes a dual-color scheme, where the amplitude and phase of the input images are captured <lb/>separately at two distinct wavelengths, with ğœ† 1 dedicated to the phase imaging channel and ğœ† 2 <lb/>dedicated to the amplitude imaging channel. As an empirical parameter, without loss of generality, <lb/>we selected ğœ† 2 = ğœ† 1 Ã— 1.28 and ğœ† 1 + ğœ† 2 = 2ğœ† for our numerical diffractive designs. With this <lb/>wavelength multiplexing strategy in design II, the amplitude and phase imaging FOVs can be <lb/>combined into a single FOV -as opposed to 2 spatially separated FOVs as employed by design I <lb/>shown in Fig. 1a. Consequently, the output amplitude and phase images, i.e., |ğ‘œ Amp (ğœ† 2 )| and <lb/>ğ‘‚ Phase (ğœ† 1 ), can be recorded by the same group of sensor pixels. <lb/>As illustrated in Fig. 1c, we also developed an additional complex field imager design, referred to <lb/>as design III, which integrates both space and wavelength multiplexing strategies in constructing <lb/>the amplitude and phase imaging channels. Specifically, design III incorporates two FOVs that are <lb/>spatially separated at the output plane (similar to design I) for amplitude and phase imaging, also <lb/>utilizing two different wavelength channels (akin to design II) to encode the output <lb/>amplitude/phase images separately. <lb/></body>

			<page>5 <lb/></page>

			<body>Following these design configurations (I, II and III) depicted above, we performed their numerical <lb/>modeling and conducted the training of our diffractive imager models. For this training, we <lb/>constructed an image dataset comprising 55,000 images of EMNIST handwritten English capital <lb/>letters, and within each training epoch, we randomly grouped these images in pairs -one <lb/>representing the amplitude image and another representing the phase image -thereby forming <lb/>27,500 training input complex fields. The phase contrast parameter ğ›¼ tr used for constructing these <lb/>training input complex fields was set as 1. We utilized deep learning-based optimization with <lb/>stochastic gradient descent to optimize the thickness values of the diffractive features on the <lb/>diffractive layers. This training was targeted at minimizing a custom-designed loss function <lb/>defined by the mean squared error (MSE) between the diffractive imager output amplitude and <lb/>phase images with respect to their corresponding ground truth. More information about the <lb/>structural parameters of the diffractive complex field imagers, the specific loss functions employed, <lb/>and additional aspects of the training methodology can be found in the Methods section. <lb/>Numerical results and quantitative performance analysis of diffractive complex field imagers <lb/>After the training phase, the resulting diffractive layers of our complex field imager models <lb/>following designs I, II and III are visualized in Supplementary Figs. S1a, S2a and Fig. 2a, <lb/>respectively, showing their thickness value distributions. To evaluate and quantitatively compare <lb/>the complex field imaging performances of these diffractive processors, we first conducted blind <lb/>testing by selecting 10,000 test images from the EMNIST handwritten letter dataset that were never <lb/>used in the training set and randomly grouped them in pairs to synthesize 5,000 complex test <lb/>objects. To compare the structural fidelity of the resulting output amplitude and phase images (i.e., <lb/>|ğ‘œ Amp (ğœ†)| and ğ‘‚ Phase ) produced by our diffractive complex field imager models, we quantified <lb/>the peak signal-to-noise ratio (PSNR) metrics between these diffractive output images and their <lb/>corresponding ground truth (i.e., ğ´ and ğœ™). Our results revealed that, for the diffractive imager <lb/>model using design I that performs space-multiplexed complex field imaging, the amplitude and <lb/>phase imaging channels provided PSNR values of 16.47Â±0.96 and 14.90Â±1.60, respectively, <lb/>demonstrating a decent imaging performance. Additionally, for the diffractive imager models <lb/>using designs II (and III), these performance metrics became 16.46Â±1.02 and 14.98Â±1.51 <lb/>(17.04Â±1.06 and 15.06Â±1.63), respectively. Therefore, design III demonstrated a notable <lb/>performance advantage over the other two models in both phase and amplitude imaging channels <lb/>when both the space and wavelength multiplexing strategies were used. Apart from these <lb/>quantitative results, we also presented exemplary diffractive output images for the three models of <lb/>designs I, II and III in Supplementary Figs. S1b, S2b and Fig. 2b, respectively. These <lb/>visualization results clearly show that our diffractive output images in both amplitude and phase <lb/>channels present structural similarity to their input ground truth, even though these input complex <lb/>fields were never seen by our diffractive models before. These analyses demonstrate the internal <lb/>generalization of our diffractive complex field imagers, indicating their capability to process new <lb/>complex fields that have similar statistical distributions to the training dataset. <lb/>We also conducted blind testing of these diffractive complex field imager designs by synthesizing <lb/>input fields from other datasets where the complex images exhibit distinctly different <lb/>morphological features compared to the training complex field images. For this purpose, we <lb/>selected the MNIST handwritten digits 50 and the QuickDraw image 51 datasets, and for each dataset <lb/>we synthesized 5,000 input complex fields to test our diffractive models blindly. When using the <lb/>MNIST-based complex field images, the amplitude and phase PSNR values of our diffractive <lb/>complex field imager models using designs I, II and III were quantified as (16.59Â±0.71, <lb/></body>

			<page>6 <lb/></page>

			<body>15.42Â±1.28), (16.40Â±0.68, 15.53Â±1.25) and (17.05Â±0.78, 15.59Â±1.32), respectively. The <lb/>corresponding diffractive output images for these results are also exemplified in Supplementary <lb/>Figs. S1c, S2c and Fig. 2c. When testing using input complex fields synthesized from the <lb/>QuickDraw images, these PSNR values revealed (14.42Â±0.94, 13.34Â±1.10), (14.17Â±1.01, <lb/>13.54Â±1.61) and (14.72Â±0.97, 13.46Â±1.13), with exemplary diffractive output images visualized <lb/>in Supplementary Figs. S1d, S2d and Fig. 2d, respectively. Once again, these PSNR values, <lb/>along with the visualization results of the output patterns, demonstrate that all our diffractive <lb/>models (following designs I, II and III) achieved successful reconstructions of the amplitude and <lb/>phase channel information of the input complex fields, wherein the design III model presented <lb/>slightly improved performance over the other two designs. Importantly, these analyses <lb/>demonstrate the external generalization capabilities of our diffractive imagers, positioning them <lb/>as general-purpose complex field imagers that can handle input complex field distributions <lb/>markedly distinct from those encountered during their training stage. <lb/>Next, we quantified the complex field imaging performance of our diffractive models as a function <lb/>of the phase contrast and spatial resolution of the incoming complex fields. For this analysis, we <lb/>selected various grating patterns to form our test images, which have different linewidths and are <lb/>oriented in either horizontal or vertical directions. We first considered using these grating patterns <lb/>encoded within either the phase or the amplitude channels of the input complex fields, forming <lb/>phase-only or amplitude-only grating test objects. To be more specific, the phase-only input fields <lb/>were set to have a uniform distribution within their amplitude channel, while the amplitude-only <lb/>input fields were set to have their phase channel values set as zero/constant. For both kinds of <lb/>gratings, we selected their linewidths as 1.5ğœ† m or 3ğœ† m to generate the grating patterns, and tested <lb/>the spatial resolution for the amplitude and phase imaging channels using our diffractive models; <lb/>here ğœ† m = ğœ† for the design I model and ğœ† m = (ğœ† 1 + ğœ† 2 ) / 2 for the designs II and III. For phase-only <lb/>gratings with linewidths of 3ğœ† m , we also used different phase contrast parameters ğ›¼ test âˆˆ {0.25, <lb/>0.5, 1} to form grating patterns with different phase contrast so that we can evaluate the sensitivity <lb/>of phase imaging by our diffractive complex field processors. To better quantify the performance <lb/>of our diffractive complex field imagers for these test grating patterns, we used a grating image <lb/>contrast (Q) as our evaluation metric, defined as: <lb/>ğ‘„ = <lb/>ğ¼ max -ğ¼ min <lb/>ğ¼ max + ğ¼ min <lb/>(1). <lb/>The results of using these amplitude-or phase-only grating patterns as input fields to our diffractive <lb/>models using designs I, II and III are provided in Supplementary Figs. S3a-b, S4a-b and Fig. 3a-<lb/>b, respectively. Through visual inspection and quantification of grating image contrast Q values, <lb/>our diffractive imager models were found to resolve most of the amplitude-only grating objects of <lb/>different linewidths and orientations, with quantified Q values consistently above 0.17. The only <lb/>exception is that the diffractive model using design II fell short in resolving the horizontal grating <lb/>patterns with 1.5ğœ† m linewidth, achieving Q &lt; 0.1. For the phase-only grating inputs, all three <lb/>diffractive models succeeded in resolving the gratings with ğ›¼ test âˆˆ {0.5, 1} and linewidths of 3ğœ† m , <lb/>presenting Q values consistently over 0.19. However, when using the phase-only grating inputs <lb/>with ğ›¼ test = 0.25 and linewidths of 3ğœ† m or those with ğ›¼ test = 1 and linewidths of 1.5ğœ† m , all of <lb/>our diffractive models struggle to provide consistently clear grating images, exhibiting relatively <lb/>poor Q values of â‰¤ 0.1. These findings reveal that our diffractive imager models exhibit similar <lb/>performance in imaging resolution and phase sensitivity, providing an amplitude imaging <lb/>resolution of &gt;1.5ğœ† m for amplitude-only objects and a phase imaging resolution of â‰¥3ğœ† m for <lb/></body>

			<page>7 <lb/></page>

			<body>phase-only objects with ğ›¼ test â‰¥ 0.5. We also calculated the average Q values for different <lb/>diffractive models using these amplitude-or phase-only grating inputs; the design III model <lb/>emerges as the most competitive one, presenting average Q values of 0.418 and 0.181 for the <lb/>amplitude and phase channels, respectively. The suboptimal performance of the design II model, <lb/>we believe, can primarily be attributed to its utilization of the same output FOV for both the phase <lb/>and amplitude image formation. This strategy results in the overlap of the diffractive features to <lb/>serve the two imaging channels, thereby not fully utilizing the degrees of freedom provided by the <lb/>diffractive layers. This is also corroborated by the visualization of the diffractive layer designs <lb/>shown in Supplementary Fig. S2a: compared to designs I and III, the areas with significant <lb/>modulation patterns in the design II layers are significantly smaller and more concentrated in the <lb/>central region, indicating a less efficient utilization of the diffractive degrees of freedom available <lb/>for optimization, consequently limiting its imaging performance. <lb/>In addition to the analyses of spatial resolution and phase sensitivity, we also utilized amplitude-<lb/>and phase-only grating images to investigate the crosstalk between the amplitude and phase <lb/>imaging channels of our diffractive complex field imagers. Since the amplitude-only grating inputs <lb/>have constant/zero phase distributions, the ground truth of their corresponding diffractive output <lb/>images in the phase channel should have zero intensities, where the residual represents the <lb/>crosstalk coming from the amplitude channel. Similarly, for the phase-only grating inputs that have <lb/>a uniform amplitude distribution (ADC), their diffractive output images in the amplitude channel <lb/>should reveal no intensity distributions, with the residual representing the crosstalk coming from <lb/>the phase channel. As shown by the diffractive output images in Supplementary Figs. S3a-b, <lb/>S4a-b and Fig. 3a-b, we observe some crosstalk components in the amplitude and phase channel <lb/>imaging results. To provide a quantitative evaluation of this crosstalk, we used the signal-to-<lb/>crosstalk ratio (SCR) metric, defined as: <lb/>ğ‘†ğ¶ğ‘… Phase = <lb/>âˆ‘ ğ‘‚ Phaseâ†’Phase <lb/>âˆ‘ ğ‘‚ Ampâ†’Phase <lb/>(2), <lb/>ğ‘†ğ¶ğ‘… Amp = <lb/>âˆ‘|ğ‘œ Ampâ†’Amp | <lb/>2 <lb/>âˆ‘|ğ‘œ Phaseâ†’Amp | <lb/>2 <lb/>(3), <lb/>where ğ‘‚ Phaseâ†’Phase and ğ‘‚ Ampâ†’Phase denote the resulting output phase image when encoding the <lb/>same grating pattern within the phase and amplitude channels of the input complex field, <lb/>respectively; the first term represents the true signal and the latter represents the crosstalk term in <lb/>Eq. (2). Similarly, |ğ‘œ Ampâ†’Amp | and |ğ‘œ Phaseâ†’Amp | denote the resulting output amplitude image <lb/>when encoding the same grating pattern within the amplitude and phase channels of the input <lb/>complex field, respectively. Î£ denotes the intensity summation operation across all the pixels. <lb/>Following these definitions, we quantified the ğ‘†ğ¶ğ‘… Phase and ğ‘†ğ¶ğ‘… Amp values for all the grating <lb/>imaging outputs in Supplementary Figs. S3a-b, S4a-b and Fig. 3a-b. These SCR analyses reveal <lb/>that, for all the diffractive imager models, the grating inputs with 1.5ğœ† m linewidth and ğ›¼ test = 1 <lb/>present a ~30% lower ğ‘†ğ¶ğ‘… Amp and a ~53% lower ğ‘†ğ¶ğ‘… Phase when compared to their counterparts <lb/>with 3ğœ† m linewidth, revealing that imaging of finer, higher-resolution patterns is more susceptible <lb/>to crosstalk. Furthermore, we found that an increase in the input phase contrast (ğ›¼ test ) leads to <lb/>more crosstalk in the output amplitude channel, which results in a lower ğ‘†ğ¶ğ‘… Amp value; for <lb/>example, from &gt;3.5 for ğ›¼ test = 0.25 down to 2.5-3 for ğ›¼ test = 1. Additionally, we calculated the <lb/></body>

			<page>8 <lb/></page>

			<body>average ğ‘†ğ¶ğ‘… Phase and ğ‘†ğ¶ğ‘… Amp values across these grating images for different diffractive imager <lb/>models; for the diffractive models using designs I, II and III, the average ğ‘†ğ¶ğ‘… Amp values are 2.805, <lb/>3.178 and 3.155, respectively, and the average ğ‘†ğ¶ğ‘… Phase values are 2.331, 2.262 and 2.252, <lb/>respectively. <lb/>These analyses were performed based on amplitude and phase-only grating objects. Beyond that, <lb/>we also used complex-valued gratings to further inspect the imaging performance of our diffractive <lb/>models. Specifically, we created complex test fields that have the same grating patterns encoded <lb/>in both the amplitude and phase channels. The results reported in the top row of the <lb/>Supplementary Figs. S3c, S4c and Fig. 3c revealed that all our diffractive imager models are <lb/>capable of distinctly resolving complex gratings with 3ğœ† m linewidth, while being largely able to <lb/>resolve those with 1.5ğœ† m linewidth, albeit with occasional failure. We further created complex <lb/>fields by orthogonally placing horizontal and vertical gratings, with one of these gratings encoded <lb/>in the phase channel of the input field and the other encoded in the amplitude channel. As <lb/>evidenced by the bottom row of Supplementary Figs. S3c, S4c and Fig. 3c, our diffractive models <lb/>could successfully reconstruct the amplitude and phase patterns of the input complex fields with a <lb/>grating linewidth of 3ğœ† m . <lb/>Output power efficiency of diffractive complex field imagers <lb/>To quantify the output diffraction efficiencies of our complex field imagers, we utilized 5,000 test <lb/>complex fields created from the EMNIST image dataset, and calculated the average diffraction <lb/>efficiencies of our diffractive complex field imager models. By integrating an additional loss term <lb/>into our training loss function to balance the complex field imaging performance along with the <lb/>output diffraction efficiency, we demonstrated the feasibility of increased power efficiency for all <lb/>three designs (I, II and III), with minimal compromise in the output image quality. The added loss <lb/>term, denoted as â„’ Eff , is specifically designed to control and improve the output diffraction power <lb/>efficiency, with its definition given by: <lb/>â„’ Eff = â„’ Eff,Phase + â„’ Eff,Amp <lb/>(4), <lb/>â„’ Eff,Phase = { <lb/>ğœ‚ th -ğœ‚ Phase , if ğœ‚ Phase &lt; ğœ‚ th <lb/>0, <lb/>if ğœ‚ Phase â‰¥ ğœ‚ th <lb/>(5), <lb/>â„’ Eff,Amp = { <lb/>ğœ‚ th -ğœ‚ Amp , if ğœ‚ Amp &lt; ğœ‚ th <lb/>0, <lb/>if ğœ‚ Amp â‰¥ ğœ‚ th <lb/>(6), <lb/>where ğœ‚ Phase and ğœ‚ Amp denote the output diffraction power efficiency within FOVPhase and <lb/>FOVAmp, respectively, with their detailed definition provided in the Methods section. ğœ‚ th refers to <lb/>the target diffraction efficiency threshold for ğœ‚. By minimizing the loss function that incorporates <lb/>the â„’ Eff term, we trained 6 diffractive imager models for each design (I, II and III). For each of <lb/>these models, we set ğœ‚ th at distinct levels: 0.1%, 0.2%, 0.4%, 0.8%, 1.6% and 3.2%, and trained <lb/>the respective model to satisfy the specified ğœ‚ th . Note that all these new diffractive complex field <lb/>imager models maintain the same physical architecture as the designs illustrated in Fig. 1, and they <lb/>were trained using the same EMNIST-based complex image dataset. A performance comparison <lb/>for these models is provided in Fig. 4, where their amplitude and phase average PSNR values were <lb/>calculated across the test set and shown as a function of their average diffraction efficiency values. <lb/>Taking the architecture of design III as an example, one of our complex field imager designs <lb/>achieved an output power efficiency of ~0.2% in both amplitude and phase channels, resulting in <lb/></body>

			<page>9 <lb/></page>

			<body>average PSNR values of 14.72Â±1.47 and 16.64Â±1.03 for the two corresponding channels, <lb/>respectively. An additional model, optimized with a heightened emphasis on the output power <lb/>efficiency, demonstrated the capability of performing complex field imaging with &gt;0.8% <lb/>diffraction efficiency in both the phase and amplitude channels, while achieving average amplitude <lb/>and phase PSNR values of 13.51Â±1.32 and 16.74Â±1.05, respectively. A similar trend was also <lb/>observed for the other models using designs I and II, where a significant increase in the output <lb/>diffraction efficiency could be achieved with a modest trade-off in the output image quality. <lb/>Moreover, a comparative assessment of the three different designs under various output diffraction <lb/>efficiencies reaffirms the overall performance advantage of design III: it presents remarkable <lb/>advantages over design I in phase imaging while outperforming design II in amplitude imaging. <lb/>Overall, Figure 4 serves as a &quot;designer rule plot&quot;, which offers guidance in selecting suitable <lb/>diffractive complex field imager models by balancing the phase/amplitude imaging fidelity with <lb/>output power efficiency according to specific application requirements. <lb/>Experimental validation of diffractive complex field imagers <lb/>We performed experimental validation of our diffractive complex field imagers using the terahertz <lb/>part of the spectrum, specifically employing the design II configuration as illustrated in Fig. 1b; <lb/>we used ğœ† 1 = 0.75 mm and ğœ† 2 = 0.8 mm for the phase and amplitude imaging channels, <lb/>respectively. We used three diffractive layers for our experimental design, each layer containing <lb/>120Ã—120 learnable diffractive features with a lateral size of ~0.516ğœ† m (dictated by the resolution <lb/>of our 3D printer). The axial spacing between any two adjacent layers (including the diffractive <lb/>layers and the input/output planes) was chosen as ~25.8ğœ† m (20 mm), resulting in a total axial length <lb/>of ~103.2ğœ† m for the entire design. As a proof of concept, we designed two experimental models <lb/>that use different input phase contrast parameters, ğ›¼ exp = 1 and 0.5. These experimental models <lb/>were trained using a dataset composed of phase-only and amplitude-only objects, which feature <lb/>randomly generated spatial patterns with binary phase values of {0, ğ›¼ exp ğœ‹} or amplitude values <lb/>of {0, 1}. In these proof of concept experiments, we did not employ input objects with spatial <lb/>distributions in both the amplitude and phase channels due to the fabrication challenges of such <lb/>objects; however, the amplitude-only or phase-only objects used here still share a single common <lb/>input FOV and are processed by the same diffractive imager. Therefore, this experimental <lb/>demonstration serves as an effective proof of our all-optical complex field imaging framework, <lb/>which has never been demonstrated before in prior works. <lb/>After the training, the resulting layer thickness profiles of the diffractive models with ğ›¼ exp = 1 and <lb/>0.5 are visualized in Fig. 5a and d, respectively. These diffractive layers were fabricated using 3D <lb/>printing, with their corresponding photographs showcased in Fig. 5b and e. Additionally, we <lb/>constructed phase-only or amplitude-only test objects, which were never seen by the trained <lb/>diffractive models. The phase-only test objects were fabricated by 3D printing layers with spatially <lb/>varying height profiles representing the phase distributions, and the amplitude-only objects were <lb/>created by padding aluminum foils onto 3D-printed flat layers to delineate the amplitude patterns. <lb/>In our proof-of-concept experiments, these objects were designed to have 5Ã—5 pixels, each <lb/>featuring a size of 4.8 mm (~6.19ğœ† m ). As shown in Fig. 6b, the printed diffractive layers and input <lb/>complex objects were assembled using a custom 3D-printed holder to ensure that their relative <lb/>positions follow our numerical design. In our experiments, we employed a THz source operating <lb/>at ğœ† 1 = 0.75 mm and ğœ† 2 = 0.8 mm, and used a detector to measure the intensity distribution at the <lb/>output plane, yielding the output amplitude and phase images. The photograph and schematic of <lb/></body>

			<page>10 <lb/></page>

			<body>our experimental setup are provided in Fig. 6a and c, respectively. Further details related to the <lb/>experiment are provided in the Methods section. <lb/>The experimental results for these two models are shown in Fig. 5c and f, where the output <lb/>amplitude and phase images present a good agreement with their numerically simulated <lb/>counterparts, also aligning well with the input ground truth images. These experimental results <lb/>demonstrate the feasibility of our 3D fabricated diffractive complex field imager to accurately <lb/>image the amplitude and phase distributions of the input objects; these results also represent the <lb/>first demonstration of all-optical complex field imaging achieved through a single diffractive <lb/>processor. <lb/>Discussion <lb/>The numerical analyses and experimental validation presented in our work showcased a compact <lb/>complex field imager design through deep learning-based optimization of diffractive surfaces. We <lb/>explored three variants of this design strategy, with comparative analyses indicating that the design <lb/>employing spatial and wavelength multiplexing (design III) achieves the best balance between the <lb/>complex field imaging performance and diffraction efficiency, albeit with a minor increase in <lb/>hardware complexity. Leveraging the all-optical information processing capabilities of multiple <lb/>spatially engineered diffractive layers, diffractive complex field imagers reconstruct the amplitude <lb/>and phase distributions of the input complex field in a complete end-to-end manner, without any <lb/>digital image recovery algorithm, setting it apart from other designs in the existing literature for <lb/>similar applications. This capability enables direct recording of the amplitude and phase <lb/>information in a single snapshot using an intensity-only sensor array, which obviates the need for <lb/>additional computational processing in the back-end, thereby significantly enhancing the frame <lb/>rate and reducing the latency of the imaging process. <lb/>In our previous research, we developed diffractive processor designs tailored for imaging either <lb/>amplitude distributions of amplitude-only objects 38 or phase distributions of phase-only <lb/>objects 40,48,49 . However, these designs would become ineffective for imaging complex objects with <lb/>independent and non-uniform distributions in the amplitude and phase channels. In this work, we <lb/>have overcome this limitation by training our diffractive imager designs using complex objects <lb/>with random combinations of amplitude and phase patterns, thus allowing a single imager device <lb/>to effectively generalize to complex optical fields with various distributions in the amplitude and <lb/>phase channels. <lb/>The diffractive complex field imager designs that we presented also exhibit certain limitations. <lb/>Our results revealed residual errors in their targeted operations, particularly manifesting as <lb/>crosstalk coming from the amplitude channel into the phase channel. This suggests that the actual <lb/>phase-to-intensity transformation represented by our diffractive imager, while effective, is an <lb/>approximation with errors that are dependent on the object amplitude distribution. The mitigation <lb/>approach for this limitation might involve further enhancement of the information processing <lb/>capacity of our diffractive imagers, which can be achieved through employing a larger number of <lb/>diffractive layers (forming a deeper diffractive architecture), thus increasing the overall number of <lb/>diffractive features/neurons that are efficiently utilized 52 . Additionally, we believe another <lb/>performance improvement strategy could be to increase the lateral distance between the two output <lb/>FOVs dedicated to the phase and amplitude channels, thereby allowing the trainable diffractive <lb/>features to better specialize for the individual tasks of phase/amplitude imaging; this approach, <lb/></body>

			<page>11 <lb/></page>

			<body>however, would increase the size of the output FOV of the focal plane array and also demand <lb/>larger diffractive layers. <lb/>Moreover, in our experimental results, we observed the emergence of noise patterns within certain <lb/>regions, which did not exist in our numerical simulations. This discrepancy can be attributed to <lb/>potential misalignments and fabrication imperfections in the diffractive layers that are assembled. <lb/>A mitigation strategy could be to perform &quot;vaccination&quot; of these diffractive imager models, which <lb/>involves modeling these errors as random variables and incorporating them into the physical <lb/>forward model during the training process 35,37,53 . This has been proven effective in providing <lb/>substantial resilience against misalignment errors for diffractive processors, exhibiting a <lb/>noticeably better match between the numerical and experimental results 35,37,53 . <lb/>Methods <lb/>Numerical forward model of a diffractive complex field imager. In our numerical <lb/>implementation, the transmissive layers within the diffractive complex field imager were modeled <lb/>as thin dielectric optical modulation elements with spatially varying thickness profiles. For the ğ‘™ th <lb/>diffractive layer, the complex-valued transmission coefficient of its ğ‘– th feature at a spatial location <lb/>(ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ ) was defined depending on the illumination wavelength (ğœ†): <lb/>ğ‘¡ ğ‘™ (ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ , ğœ†) = ğ‘ ğ‘™ (ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ , ğœ†)exp(ğ‘—ğœ™ ğ‘™ (ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ , ğœ†)) <lb/>(7), <lb/>where ğ‘(ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ , ğœ†) and ğœ™(ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ , ğœ†) denote the amplitude and phase coefficients, respectively. <lb/>The free-space propagation of complex fields between diffractive layers was modeled through the <lb/>Rayleigh-Sommerfeld diffraction equation 32 : <lb/>ğ‘¤ ğ‘– <lb/>ğ‘™ (ğ‘¥, ğ‘¦, ğ‘§, ğœ†) = <lb/>ğ‘§ -ğ‘§ ğ‘™ <lb/>ğ‘Ÿ 2 ( <lb/>1 <lb/>2ğœ‹ğ‘Ÿ <lb/>+ <lb/>1 <lb/>ğ‘—ğœ† <lb/>) exp ( <lb/>ğ‘—2ğœ‹ğ‘Ÿ <lb/>ğœ† <lb/>) <lb/>(8), <lb/>where ğ‘¤ ğ‘– <lb/>ğ‘™ (ğ‘¥, ğ‘¦, ğ‘§, ğœ†) represents the complex field at the ğ‘– th diffractive feature of the ğ‘™ th layer at <lb/>location (ğ‘¥, ğ‘¦, ğ‘§) . ğ‘Ÿ = âˆš(ğ‘¥ -ğ‘¥ ğ‘– ) 2 + (ğ‘¦ -ğ‘¦ ğ‘– ) 2 + (ğ‘§ -ğ‘§ ğ‘™ ) 2 and ğ‘— = âˆš-1 . Based on Eq. (8), <lb/>ğ‘¤ ğ‘– <lb/>ğ‘™ (ğ‘¥, ğ‘¦, ğ‘§, ğœ†) can be viewed as a secondary wave generated from the source at (ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ ). As a <lb/>result, the optical field modulated by the ğ‘– th diffractive feature of the ğ‘™ th layer (ğ‘™ â‰¥ 1, treating the <lb/>input object plane as the 0 th layer), ğ‘¢ ğ‘™ (ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ , ğœ†), can be written as: <lb/>ğ‘¢ ğ‘™ (ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ , ğœ†) = ğ‘¡ ğ‘™ (ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ , ğœ†) â€¢ âˆ‘ ğ‘¢ ğ‘™-1 (ğ‘¥ ğ‘˜ , ğ‘¦ ğ‘˜ , ğ‘§ ğ‘™-1 , ğœ†) <lb/>ğ‘˜âˆˆğ‘ <lb/>â€¢ ğ‘¤ ğ‘– <lb/>ğ‘™-1 (ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ , ğœ†) <lb/>(9), <lb/>where ğ‘ denotes the number of diffractive features on the (ğ‘™ -1) th diffractive layer and ğ‘§ * <lb/>represents the location of the * th layer in the z direction parallel to the optical axis. The amplitude <lb/>and phase components of the complex transmittance of the ğ‘– th feature of diffractive layer ğ‘™, i.e., <lb/>ğ‘ ğ‘™ (ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ , ğœ†) and ğœ™ ğ‘™ (ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ , ğœ†) in Eq. (7), were defined as a function of the material thickness <lb/>over the region of that diffractive feature, â„ ğ‘– <lb/>ğ‘™ , as follows: <lb/>ğ‘ ğ‘™ (ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ , ğœ†) = exp (-<lb/>2ğœ‹ğœ… ğ‘‘ (ğœ†)â„ ğ‘– <lb/>ğ‘™ <lb/>ğœ† <lb/>) <lb/>(10), <lb/>ğœ™ ğ‘™ (ğ‘¥ ğ‘– , ğ‘¦ ğ‘– , ğ‘§ ğ‘™ , ğœ†) = (ğ‘› ğ‘‘ (ğœ†) -ğ‘› air ) <lb/>2ğœ‹â„ ğ‘– <lb/>ğ‘™ <lb/>ğœ† <lb/>(11) , <lb/></body>

			<page>12 <lb/></page>

			<body>Here the parameters ğ‘› ğ‘‘ (ğœ†) and ğœ… ğ‘‘ (ğœ†) represent the refractive index and the extinction coefficient <lb/>of the diffractive layer material, respectively. These parameters correspond to the real and <lb/>imaginary parts of the complex-valued refractive index, denoted as ğ‘› Ìƒğ‘‘(ğœ†), such that ğ‘› Ìƒğ‘‘(ğœ†) = <lb/>ğ‘› ğ‘‘ (ğœ†) + ğ‘—ğœ… ğ‘‘ (ğœ†) . We determined the values of ğ‘› Ìƒğ‘‘(ğœ†) and ğœ… ğ‘‘ (ğœ†) through experimental <lb/>characterization of the dispersion properties of the diffractive layer materials, and their values are <lb/>visualized in Supplementary Fig. S5. The trainable thickness values of the diffractive features â„ ğ‘– <lb/>ğ‘™ <lb/>were limited within the range of [â„ min , â„ max ], representing the learnable parameters of our <lb/>diffractive complex field imagers. For training the diffractive imager models used for numerical <lb/>analyses, the values of â„ min , â„ max were selected as 0.2 and 1.2 mm, respectively. For training the <lb/>diffractive imager models used for experimental validation, the values of â„ min , â„ max were selected <lb/>as 0.4 and 1.4 mm, respectively. <lb/>Experimental terahertz set-up. For our proof-of-concept experiments, we fabricated both the <lb/>diffractive layers and the test objects using a 3D printer (PR110, CADworks3D). The phase objects <lb/>were fabricated with spatially varying thickness profiles to define their phase distributions. The <lb/>amplitude objects were printed to have a uniform thickness and then manually coated with <lb/>aluminum foil to define the light-blocking areas, while the uncoated sections formed the <lb/>transmission areas, resulting in the creation of the desired amplitude profiles for test objects. <lb/>Additionally, we 3D-printed a holder using the same 3D printer, which facilitated the assembly of <lb/>the printed diffractive layers and input objects to align with their relative positions as specified in <lb/>our numerical design. To more precisely control the beam profile for the illumination of the <lb/>complex input objects, we 3D printed a square-shaped aperture of 5Ã—5 mm and padded the area <lb/>around it with aluminum foil. The pinhole was positioned 120 mm away from the object plane in <lb/>our experiments. This pinhole serves as an input spatial filter to clean the beam originating from <lb/>the source. <lb/>To test our fabricated diffractive complex field design, we employed a THz continuous-wave <lb/>scanning system, with its schematic presented in Fig. 6c. To generate the incident terahertz wave, <lb/>we used a WR2.2 modular amplifier/multiplier chain (AMC) followed by a compatible diagonal <lb/>horn antenna (Virginia Diode Inc.) as the source. Each time, we transmitted a 10 dBm sinusoidal <lb/>signal at frequencies of 11.111 or 10.417 GHz (fRF1) to the source, which was then multiplied 36 <lb/>times to generate output radiation at continuous-wave (CW) radiation at frequencies of 0.4 or 0.375 <lb/>THz, respectively, corresponding to the illumination wavelengths of 0.75 and 0.8 mm used for the <lb/>phase and amplitude imaging tasks, respectively. The AMC output was also modulated with a <lb/>1 kHz square wave for lock-in detection. We positioned the source antenna to be very close to the <lb/>3D-printed spatial pinhole filter, such that the illumination power input to the system could be <lb/>maximized. Next, using a single-pixel detector with an aperture size of ~0.1 mm, we scanned the <lb/>resulting diffraction patterns at the output plane of the diffractive complex field imager at a step <lb/>size of 0.8 mm. This detector was mounted on an XY positioning stage constructed from linear <lb/>motorized stages (Thorlabs NRT100) and aligned perpendicularly for precise control of the <lb/>detector&apos;s position. For illumination at ğœ† 1 = 0.75 mm or ğœ† 2 = 0.8 mm, a 10-dBm sinusoidal signal <lb/>was also generated at 11.083 or 10.389 GHz (fRF2), respectively, as a local oscillator and sent to <lb/>the detector to down-convert the output signal to 1 GHz. The resulting signal was then channeled <lb/>into a low-noise amplifier (Mini-Circuits ZRL-1150-LN+) with an 80 dBm gain, followed by a <lb/>bandpass filter at 1 GHz (Â± 10 MHz) (KL Electronics 3C40-1000/T10-O/O), effectively mitigating <lb/>noise from undesired frequency bands. Subsequently, the signal passed through a tunable <lb/>attenuator (HP 8495B) for linear calibration before being directed to a low-noise power detector <lb/></body>

			<page>13 <lb/></page>

			<body>(Mini-Circuits ZX47-60). The voltage output from the detector was measured using a lock-in <lb/>amplifier (Stanford Research SR830), which utilized a 1 kHz square wave as the reference signal. <lb/>The readings from the lock-in amplifier were then calibrated into a linear scale. In our post-<lb/>processing, we further applied linear interpolation to each intensity field measurement to align <lb/>with the pixel size of the output FOV used in the design phase. This process finally resulted in the <lb/>output measurement images presented in Fig. 5c and f. <lb/></body>

			<listBibl>References <lb/>1. Popescu, G. Quantitative Phase Imaging of Cells and Tissues. (McGraw-Hill Education, <lb/>2011). <lb/>2. Park, Y., Depeursinge, C. &amp; Popescu, G. Quantitative phase imaging in biomedicine. Nat. <lb/>Photonics 12, 578-589 (2018). <lb/>3. Mir, M., Bhaduri, B., Wang, R., Zhu, R. &amp; Popescu, G. Quantitative phase imaging. Prog. <lb/>Opt. 57, 217 (2012). <lb/>4. Popescu, G. et al. Fourier phase microscopy for investigation of biological structures and <lb/>dynamics. Opt. Lett. 29, 2503-2505 (2004). <lb/>5. Ikeda, T., Popescu, G., Dasari, R. R. &amp; Feld, M. S. Hilbert phase microscopy for <lb/>investigating fast dynamics in transparent systems. Opt. Lett. 30, 1165-1167 (2005). <lb/>6. Cuche, E., Bevilacqua, F. &amp; Depeursinge, C. Digital holography for quantitative phase-<lb/>contrast imaging. Opt. Lett. 24, 291-293 (1999). <lb/>7. Marquet, P. et al. Digital holographic microscopy: a noninvasive contrast imaging technique <lb/>allowing quantitative visualization of living cells with subwavelength axial accuracy. Opt. <lb/>Lett. 30, 468-470 (2005). <lb/>8. Mudanyali, O. et al. Compact, light-weight and cost-effective microscope based on lensless <lb/>incoherent holography for telemedicine applications. Lab. Chip 10, 1417-1428 (2010). <lb/>9. Greenbaum, A. et al. Imaging without lenses: achievements and remaining challenges of <lb/>wide-field on-chip microscopy. Nat. Methods 9, 889-895 (2012). <lb/></listBibl>

			<page>14 <lb/></page>

			<listBibl>10. Doblas, A. et al. Shift-variant digital holographic microscopy: inaccuracies in quantitative <lb/>phase imaging. Opt. Lett. 38, 1352-1354 (2013). <lb/>11. Greenbaum, A. et al. Wide-field computational imaging of pathology slides using lens-free <lb/>on-chip microscopy. Sci. Transl. Med. 6, 267ra175-267ra175 (2014). <lb/>12. Matlock, A. &amp; Tian, L. High-throughput, volumetric quantitative phase imaging with <lb/>multiplexed intensity diffraction tomography. Biomed. Opt. Express 10, 6432-6448 (2019). <lb/>13. Sinha, A., Lee, J., Li, S. &amp; Barbastathis, G. Lensless computational imaging through deep <lb/>learning. Optica 4, 1117-1125 (2017). <lb/>14. Rivenson, Y., Zhang, Y., GÃ¼naydÄ±n, H., Teng, D. &amp; Ozcan, A. Phase recovery and <lb/>holographic image reconstruction using deep learning in neural networks. Light Sci. Appl. 7, <lb/>17141-17141 (2018). <lb/>15. Nguyen, T. et al. Deep learning approach for Fourier ptychography microscopy. Opt. <lb/>Express 26, 26470-26484 (2018). <lb/>16. Rivenson, Y., Wu, Y. &amp; Ozcan, A. Deep learning in holography and coherent imaging. Light <lb/>Sci. Appl. 8, 85 (2019). <lb/>17. Chen, H., Huang, L., Liu, T. &amp; Ozcan, A. Fourier Imager Network (FIN): A deep neural <lb/>network for hologram reconstruction with superior external generalization. Light Sci. Appl. <lb/>11, 254 (2022). <lb/>18. Wang, F. et al. Phase imaging with an untrained neural network. Light Sci. Appl. 9, 77 <lb/>(2020). <lb/>19. Huang, L., Chen, H., Liu, T. &amp; Ozcan, A. Self-supervised learning of hologram <lb/>reconstruction using physics consistency. Nat. Mach. Intell. 5, 895-907 (2023). <lb/>20. Wang, K. et al. On the use of deep learning for phase recovery. Light Sci. Appl. 13, 4 (2024). <lb/></listBibl>

			<page>15 <lb/></page>

			<listBibl>21. Kwon, H., Arbabi, E., Kamali, S. M., Faraji-Dana, M. &amp; Faraon, A. Computational complex <lb/>optical field imaging using a designed metasurface diffuser. Optica 5, 924-931 (2018). <lb/>22. Kwon, H., Arbabi, E., Kamali, S. M., Faraji-Dana, M. &amp; Faraon, A. Single-shot quantitative <lb/>phase gradient microscopy using a system of multifunctional metasurfaces. Nat. Photonics <lb/>14, 109-114 (2020). <lb/>23. Engay, E., Huo, D., Malureanu, R., Bunea, A.-I. &amp; Lavrinenko, A. Polarization-Dependent <lb/>All-Dielectric Metasurface for Single-Shot Quantitative Phase Imaging. Nano Lett. 21, <lb/>3820-3826 (2021). <lb/>24. Ji, A. et al. Quantitative phase contrast imaging with a nonlocal angle-selective metasurface. <lb/>Nat. Commun. 13, 7848 (2022). <lb/>25. Zhou, J. et al. Fourier Optical Spin Splitting Microscopy. Phys. Rev. Lett. 129, 020801 <lb/>(2022). <lb/>26. Zhang, Y. et al. Dielectric Metasurface for Synchronously Spiral Phase Contrast and Bright-<lb/>Field Imaging. Nano Lett. 23, 2991-2997 (2023). <lb/>27. Liu, J., Wang, H., Li, Y., Tian, L. &amp; Paiella, R. Asymmetric metasurface photodetectors for <lb/>single-shot quantitative phase imaging. Nanophotonics 12, 3519-3528 (2023). <lb/>28. Wu, Q. et al. Single-shot quantitative amplitude and phase imaging based on a pair of all-<lb/>dielectric metasurfaces. Optica 10, 619-625 (2023). <lb/>29. Li, L. et al. Single-shot deterministic complex amplitude imaging with a single-layer <lb/>metalens. Sci. Adv. 10, eadl0501 (2024). <lb/>30. Wesemann, L. et al. Nanophotonics enhanced coverslip for phase imaging in biology. Light <lb/>Sci. Appl. 10, 98 (2021). <lb/></listBibl>

			<page>16 <lb/></page>

			<listBibl>31. Li, L. et al. Single-Shot Wavefront Sensing with Nonlocal Thin Film Optical Filters. Laser <lb/>Photonics Rev. 17, 2300426 (2023). <lb/>32. Lin, X. et al. All-optical machine learning using diffractive deep neural networks. Science <lb/>361, 1004-1008 (2018). <lb/>33. Mengu, D., Luo, Y., Rivenson, Y. &amp; Ozcan, A. Analysis of Diffractive Optical Neural <lb/>Networks and Their Integration With Electronic Neural Networks. IEEE J. Sel. Top. <lb/>Quantum Electron. 26, 1-14 (2020). <lb/>34. Veli, M. et al. Terahertz pulse shaping using diffractive surfaces. Nat. Commun. 12, 37 <lb/>(2021). <lb/>35. Li, J. et al. Spectrally encoded single-pixel machine vision using diffractive networks. Sci. <lb/>Adv. 7, eabd7690 (2021). <lb/>36. IÅŸÄ±l, Ã‡. et al. Super-resolution image display using diffractive decoders. Sci. Adv. 8, <lb/>eadd3433 (2022). <lb/>37. Bai, B. et al. To image, or not to image: class-specific diffractive cameras with all-optical <lb/>erasure of undesired objects. eLight 2, 14 (2022). <lb/>38. Li, J. et al. Unidirectional imaging using deep learning-designed materials. Sci. Adv. 9, <lb/>eadg1505 (2023). <lb/>39. Li, Y. et al. Universal Polarization Transformations: Spatial Programming of Polarization <lb/>Scattering Matrices Using a Deep Learning-Designed Diffractive Polarization Transformer. <lb/>Adv. Mater. 35, 2303395 (2023). <lb/>40. Shen, C.-Y., Li, J., Mengu, D. &amp; Ozcan, A. Multispectral Quantitative Phase Imaging Using <lb/>a Diffractive Optical Network. Adv. Intell. Syst. 2300300 (2023) <lb/>doi:10.1002/aisy.202300300. <lb/></listBibl>

			<page>17 <lb/></page>

			<listBibl>41. Rahman, M. S. S., Yang, X., Li, J., Bai, B. &amp; Ozcan, A. Universal linear intensity <lb/>transformations using spatially incoherent diffractive processors. Light Sci. Appl. 12, 195 <lb/>(2023). <lb/>42. Li, Y. et al. Optical information transfer through random unknown diffusers using electronic <lb/>encoding and diffractive decoding. Adv. Photonics 5, 046009 (2023). <lb/>43. Li, J. et al. Rapid sensing of hidden objects and defects using a single-pixel diffractive <lb/>terahertz sensor. Nat. Commun. 14, 6791 (2023). <lb/>44. Rahman, M. S. S. et al. Learning diffractive optical communication around arbitrary opaque <lb/>occlusions. Nat. Commun. 14, 6830 (2023). <lb/>45. Bai, B. et al. Pyramid diffractive optical networks for unidirectional magnification and <lb/>demagnification. Preprint at https://doi.org/10.48550/arXiv.2308.15019 (2023). <lb/>46. Shen, C.-Y., Li, J., Gan, T., Jarrahi, M. &amp; Ozcan, A. All-Optical Phase Conjugation Using <lb/>Diffractive Wavefront Processing. Preprint at https://doi.org/10.48550/arXiv.2311.04473 <lb/>(2023). <lb/>47. Bai, B. et al. Data Class-Specific All-Optical Transformations and Encryption. Adv. Mater. <lb/>e2212091 (2023) doi:10.1002/adma.202212091. <lb/>48. Mengu, D. &amp; Ozcan, A. All-Optical Phase Recovery: Diffractive Computing for Quantitative <lb/>Phase Imaging. Adv. Opt. Mater. 10, 2200281 (2022). <lb/>49. Li, Y., Luo, Y., Mengu, D., Bai, B. &amp; Ozcan, A. Quantitative phase imaging (QPI) through <lb/>random diffusers using a diffractive optical network. Light Adv. Manuf. 4, 1-16 (2023). <lb/>50. Deng, L. The MNIST Database of Handwritten Digit Images for Machine Learning Research <lb/>[Best of the Web]. IEEE Signal Process. Mag. 29, 141-142 (2012). <lb/></listBibl>

			<page>18 <lb/></page>

			<listBibl>51. Jongejan, J., Rowley, H., Kawashima, T., Kim, J. &amp; Fox-Gieg, N. The quick, draw!-ai <lb/>experiment. Mt. View CA Accessed Feb 17, 4 (2016). <lb/>52. Kulce, O., Mengu, D., Rivenson, Y. &amp; Ozcan, A. All-optical synthesis of an arbitrary linear <lb/>transformation using diffractive surfaces. Light Sci. Appl. 10, 196 (2021). <lb/>53. Mengu, D. et al. Misalignment resilient diffractive optical networks. Nanophotonics 9, <lb/>4207-4219 (2020). <lb/>54. Cohen, G., Afshar, S., Tapson, J. &amp; van Schaik, A. EMNIST: an extension of MNIST to <lb/>handwritten letters. ArXiv170205373 Cs (2017). <lb/>55. Kingma, D. P. &amp; Ba, J. Adam: A Method for Stochastic Optimization. in Proc. 3rd <lb/>International Conference on Learning Representations (ICLR, 2014) (2014). <lb/></listBibl>

			<div type="annex">Supplementary Materials: <lb/>â€¢ Supplementary Figures S1-S5 <lb/>â€¢ Training loss functions and quantification metrics <lb/>â€¢ Implementation details of diffractive complex field imagers <lb/></div>

			<page>19 <lb/></page>

			<body>Figures <lb/>Figure 1. Schematics for different designs of our diffractive complex field imager. a, <lb/>Illustration showing a spatially multiplexed design for the diffractive complex field imager (design <lb/>I), which performs imaging of the amplitude and phase distributions of the input complex object <lb/>simultaneously by channeling the output amplitude and phase images onto two spatially separate <lb/>FOVs at the output plane, i.e., the amplitude and phase FOVs (or FOVAmp and FOVPhase). b, <lb/>Illustration for an alternative design of the diffractive complex field imager using wavelength <lb/>multiplexing (design II), wherein the output amplitude and phase profiles are directly measured <lb/>using a common output FOV but at different wavelengths, i.e., ğœ† 1 and ğœ† 2 , respectively. c, <lb/>Illustration for design III of the diffractive complex field imager, wherein the output amplitude <lb/>and phase images are measured using two spatially separate FOVs (FOVAmp and FOVPhase) and <lb/>also at different wavelengths (ğœ† 1 and ğœ† 2 , respectively). <lb/></body>

			<page>20 <lb/></page>

			<body>Figure 2. Blind testing results of the diffractive complex field imager using design III. a, <lb/>Thickness profile of the trained layers of the diffractive complex field imager following the design <lb/>III in Fig. 1c. The layout of the amplitude and phase FOVs in comparison to the size of a diffractive <lb/>layer is also provided. b, Exemplary blind testing input complex objects never seen by the <lb/>diffractive imager model during its training, along with their corresponding output amplitude and <lb/>phase images. c and d, Same as (b), except that the testing images are taken from the MNIST and <lb/>QuickDraw datasets, respectively, demonstrating external generalization to image datasets with <lb/>different structural distributions. <lb/></body>

			<page>21 <lb/></page>

			<body>Figure 3. Performance analysis of the diffractive complex field imager model shown in Fig. <lb/>2. a, Imaging results using phase-only gratings as input fields. The binary phase grating patterns <lb/>encoded within the phase channel of the input objects are shown and compared with the resulting <lb/></body>

			<page>22 <lb/></page>

			<body>output amplitude and phase images produced by our diffractive imager (i.e., |ğ‘œ Amp (ğœ†)| and <lb/>ğ‘‚ Phase ). For each diffractive output image, the grating image contrast Q and SCR values were <lb/>quantified and shown in red and blue numbers, respectively. b, Same as in (a), except that the <lb/>amplitude-only gratings are used as input fields. c, Imaging results using complex grating objects <lb/>as input fields. These grating test objects include ones with the same grating patterns encoded in <lb/>both the amplitude and phase channels (top), as well as ones where horizontal and vertical gratings <lb/>are orthogonally placed, with one encoded in the phase channel of the input field and the other <lb/>encoded in the amplitude channel (bottom). <lb/></body>

			<page>23 <lb/></page>

			<body>Figure 4. The trade-off between the complex field imaging performance and the output <lb/>diffraction efficiency of diffractive complex field imagers. The PSNR on the y-axis reflects the <lb/>mean value computed over the entire 5,000 complex test objects derived from the EMNIST dataset. <lb/>The data points with black borders correspond to the diffractive imager models trained exclusively <lb/>using the structural fidelity loss function while disregarding diffraction efficiency, i.e., the ones <lb/>shown in Supplementary Figs. S1a, S2a and Fig. 2a. The other data points originate from models <lb/>trained with a diffraction efficiency-related penalty term, as defined in Eq. (12). These models <lb/>were trained using varying target diffraction efficiency thresholds (ğœ‚ th ), specifically set at 0.1%, <lb/>0.2%, 0.4%, 0.8%, 1.6% and 3.2% corresponding to the data points from left to right on the plot, <lb/>demonstrating the trade-off between the imaging performance and the output diffraction efficiency. <lb/></body>

			<page>24 <lb/></page>

			<body>Figure 5. Experimental results for 3D-printed diffractive complex field imagers. a, The <lb/>learned thickness profiles of the layers (L1, L2 and L3) of the diffractive imager model trained with <lb/>ğ›¼ exp = 1. b, Photographs of the 3D-printed diffractive layers in (a). c, Experimental results of the <lb/>diffractive imager shown in (a), compared with their corresponding numerical simulation results <lb/>and ground truth images. d, The learned thickness profiles of the layers (L1, L2 and L3) of the <lb/>diffractive imager model trained with ğ›¼ exp = 0.5. e, Photographs of the 3D-printed diffractive <lb/>layers in (d). f, Experimental results of the diffractive imager shown in (d), compared with their <lb/>corresponding numerical simulation results and ground truth images. <lb/></body>

			<page>25 <lb/></page>

			<body>Figure 6. Experimental set-up for diffractive complex field imagers. a, Photograph of the <lb/>experimental set-up, including a 3D-fabricated diffractive complex field imager. b, Photographs <lb/>of the 3D printed diffractive complex field imager. c, Schematic diagram of the continuous-wave <lb/>terahertz imaging set-up. </body>


	</text>

</TEI>