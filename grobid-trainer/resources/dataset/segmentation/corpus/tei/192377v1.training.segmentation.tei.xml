<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>(1) Overview <lb/>Title <lb/>A random dot kinematogram for online visual psychophysics <lb/>Paper Authors <lb/>1. Rajananda, Sivananda; <lb/>2. Lau, Hakwan; <lb/>3. Odegaard, Brian <lb/>Paper Author Roles and Affiliations <lb/>1. Designed software; coded software; tested software; uploaded software to <lb/>GitHub &amp; CodePen; <lb/>Affiliation: University of California--Los Angeles <lb/>2. Designed software <lb/>Affiliations: University of California--Los Angeles <lb/>Brain Research Institute (UCLA) <lb/>Hong Kong University <lb/>3. Designed software; proofread code; tested software <lb/>Affiliations: University of California--Los Angeles <lb/>Abstract <lb/>Online experiments using visual stimuli have become increasingly common in recent <lb/>years, but many frequently-used stimuli in visual psychophysical experiments have <lb/>yet to be developed for web-based platforms.  Here, we introduce the first open-<lb/>access random-dot kinematogram (RDK) for use in web browsers. This fully-<lb/>customizable RDK offers options to implement several different types of noise <lb/>(random position, random walk, random direction) and parameters to control aperture <lb/>shape, coherence level, the number of dots, and many other features.  We include <lb/>links to commented JavaScript code for easy implementation in online experiments, <lb/>as well as an example of how this stimulus can be integrated as a plugin with an <lb/>online experimental library (jsPsych). <lb/>Keywords <lb/>Random dot kinematogram, random dot motion, moving dot stimulus, online <lb/>experiments, visual psychophysics, visual stimuli, JavaScript, jsPsych <lb/></front>

			<body>Introduction <lb/>Over the last several decades, random dot kinematograms (RDKs) have <lb/>emerged as an effective psychophysical stimulus to evaluate low-level motion <lb/>processing [1-5].  While different versions of this type of stimulus have been created <lb/>across several software platforms (e.g., MATLAB and PsychoPy), currently, no <lb/>implementation of this stimulus exists for public use in online experiments.  Recently, <lb/>our research group developed an RDK in JavaScript to be used for presentation in <lb/>standard web browsers.  This RDK incorporates several distinct features that have <lb/>emerged in different versions used by researchers, and allows users to customize <lb/>noise types and other parameters for different paradigms.  In this short article, we <lb/>explain a few important elements of this new stimulus and provide links to both raw <lb/>code and online examples to guide implementation for vision scientists in future <lb/>experiments. <lb/>Implementation and architecture <lb/>In RDKs, a certain percentage of dots are designated as &quot;signal&quot; to move in <lb/>one coherent direction, and the remaining percentage of dots are designated as <lb/>&quot;noise&quot; to move in random directions.  However, as noted by [6], several options exist <lb/>regarding how signal and noise can be drawn in frame-by-frame presentations.  To <lb/>create the &quot;signal,&quot; dots can either move in the direction of coherent motion in all <lb/>frames (referred to as the &quot;same&quot; rule), or move in the direction of coherent motion in <lb/>only a specified proportion of frames (referred to as the &quot;different rule&quot;). To create the <lb/>&quot;noise,&quot; dots can either be drawn in a random position in the aperture on each frame <lb/>(&quot;random position&quot;), move to an adjacent position in a random direction in each frame <lb/>(&quot;random walk&quot;), or have a consistent direction of motion, designated randomly at the <lb/>beginning of the trial (&quot;random direction&quot;).  Modeling our stimulus after the random <lb/>dot kinematogram from the software PsychoPy [7,8], we parameterized these <lb/>different combinations of signal and noise to yield six different display options. <lb/>Additionally, dots in RDKs have a &quot;dot life&quot;, which determines the number of <lb/>frames that pass before a dot disappears and reappears somewhere else within the <lb/>aperture. However, if a dot reaches the end of the aperture and its dot life has not <lb/>ended, then a dot can either reappear randomly in the aperture, or be reinserted from <lb/>an opposite edge.  We include features to customize dot life length, the reinsertion <lb/>rule, as well as the number of dot sets to cycle through per frame, adapting <lb/>procedures from established RDK versions in MATLAB [9]. <lb/>Finally, we also include links to code that integrates this RDK as a plugin with <lb/>jsPsych, a library for creating and running experiments in web browsers [10].  We <lb/>include parameters to control motion direction, coherence level, the total number of <lb/>dots, dot color, aperture shape, aperture size, and how far dots move from one frame <lb/>to the next.   While our raw code can be implemented on any platform that uses <lb/>JavaScript, incorporating our plugin with the jsPsych library may be particularly <lb/>advantageous for researchers looking to use this RDK in experiments assessing <lb/>reaction times;; a comparison of reaction times assessed with jsPsych and a standard <lb/>software package (e.g., Psychophysics Toolbox in MATLAB), revealed that while <lb/>reaction times measured by jsPsych tended to be slightly slower than Psychophysics <lb/>Toolbox, response time variability was quite comparable between both software <lb/>packages [11].  This indicates that response time measurements in jsPsych are <lb/>sensitive enough to detect differences caused by experimental manipulations. <lb/>Quality control <lb/>One primary concern in conducting visual psychophysical experiments online <lb/>is that timing issues in the display could arise due to differences in internet <lb/>connectivity speeds, monitor types (i.e., liquid crystal displays vs. cathode ray tubes), <lb/>hardware, or web browsers used by participants.  In testing our new software, we <lb/>have found that running the exact same code for our RDK in different browsers yields <lb/>slightly different results.  For example, we have identified small differences in the <lb/>average frames per second when testing our RDK using Google Chrome, Firefox, <lb/>and Safari on the same computer (Figure 1). <lb/>Figure 1.  The average number of milliseconds per frame in a test of this stimulus on three <lb/>web browsers.  Shown here is an example of timing differences that emerge when conducting <lb/>100 stimulus presentations on the same computer in different browsers.  The dashed black <lb/>line denotes the ideal frame rate for a 60Hz monitor (16.667 milliseconds per frame).   Each <lb/>color represents results from a different run of 100 trials.  Five runs in each browser were <lb/>conducted in total, and all three browsers were run on OS X. (A) The average milliseconds <lb/>per frame for each trial when the RDK was displayed in Google Chrome.  Across five runs, <lb/>the average milliseconds per frame were consistent. (B) Results from the same test when the <lb/>RDK was displayed in Firefox.  Small deviations occurred in the average milliseconds per <lb/>frame using this browser. (C) Results from the same test when the RDK was displayed in <lb/>Safari.  This browser was the most variable of the three that were tested. <lb/>What is needed to ensure accuracy and precision when conducting online <lb/>psychophysics are real-time measures of not only the average frame rate of the <lb/>display, but also the number of frames that are actually presented.  Our RDK records <lb/>the number of frames used in each presentation, which serves as a valid index of <lb/>presentation clarity and coherence (Figure 2).  We recommend that users analyze <lb/>this data in one of two ways: offline, to exclude particular trials from relevant <lb/>analyses, or online, to re-present trials with missed frames to ensure balanced <lb/>numbers of trials across conditions.  In our tests of this stimulus, we did not notice <lb/>visible differences between trials when 11 or 12 frames were used, but a visible <lb/>stutter was apparent when the number of frames was below 10.  Quality checks on <lb/>other aspects of our stimulus (e.g., the locations where dots are re-drawn after <lb/>disappearing, the number of dots drawn in the stimulus, whether the colors are <lb/>rendered properly) demonstrated its viability, but we welcome feedback from users if <lb/>issues arise. <lb/>Figure 2.  The number of frames displayed per trial in a test of this stimulus in three web <lb/>browsers on a computer running OS X. In this test, we displayed our RDK for 200ms on each <lb/>trial for 100 consecutive trials.  Shown in each panel are results across five different runs in <lb/>each browser, with each run denoted by a different color. (A) The results of the test in Google <lb/>Chrome.  This browser showed the most consistency across the three that were tested, and <lb/>matched our targeted goal of 12 frames on the majority of trials.  A small number of trials <lb/>deviated slightly, using 11 frames to present the stimulus. (B) The results of this test in <lb/>Firefox.  This web browser was slightly more variable, containing more trials that used 11 <lb/>frames, and even a few trials that displayed 10 or fewer frames.  (C) The results of this test in <lb/>Safari.  This web browser displayed the most variability in the number of frames that were <lb/>displayed.  We note that while we did not see visual differences between trials when 11 and <lb/>12 frames were presented, trials with fewer than 10 frames appeared to &quot;stutter&quot; when <lb/>displayed in the browser window.  Thus, we recommend that users analyze this metric to <lb/>evaluate which trials should be dropped from analysis or re-presented when using this <lb/>stimulus in online experiments. <lb/>Finally, we also recommend that users build in explicit instructions to only have one <lb/>browser window open when participating in experiments with this stimulus and to <lb/>close other programs while it is being used, as we have noticed slight timing <lb/>idiosyncrasies that emerge when browser tabs and programs are running in the <lb/>background. <lb/></body>

			<div type="availability">(2) Availability <lb/>Operating system <lb/>This plugin is functional in the most recent versions of Safari, Firefox, and Chrome <lb/>(i.e., the most up-to-date versions available for use in September, 2017).  However, <lb/>based on our tests, Chrome appears to be the most reliable browser in presenting an <lb/>equal number of frames across trials for this stimulus.  We welcome feedback from <lb/>users if compatibility issues exist in older web browsers. <lb/>Programming language <lb/>JavaScript/CSS/HTML <lb/>Additional system requirements <lb/>None <lb/>Dependencies <lb/>The raw code for the RDK posted on CodePen works without any additional <lb/>frameworks or libraries. The jsPsych RDK plugin requires the jsPsych library, jQuery, <lb/>and a jsPsych CSS stylesheet to work properly. These scripts and links for the <lb/>jsPsych version are added in the header of the main experiment file (see the <lb/>identifier of (3) under &apos;Software location&apos; below). <lb/></div>

			<div type="annex">List of contributors <lb/>Sivananda Rajananda - Development &amp; Design <lb/>Hakwan Lau - Design <lb/>Brian Odegaard - Design &amp; Code Review <lb/></div>

			<div type="availability">Software location: <lb/>(1) Demonstration of the RDK stimulus with modifiable parameters <lb/>Code repository <lb/>Name: CodePen <lb/>Identifier: https://codepen.io/vrsivananda/pen/xLORQe <lb/>Licence: GNU General Public License <lb/>Date published: 14/09/17 <lb/>Description: The CodePen link shown above provides users with a <lb/>visual demonstration of different stimulus attributes;; by changing the <lb/>RDK parameters, users can see (for example) how different signal &amp; <lb/>noise rules change the appearance of the stimulus.  We recommend <lb/>that users input different values in the &quot;Set Parameters&quot; section of the <lb/>code to visualize different features of this stimulus. <lb/>(2) jsPsych plugin for use in visual experiments <lb/>Code repository <lb/>Name: GitHub <lb/>Identifier: https://github.com/vrsivananda/RDK/blob/master/jspsych-<lb/>5.0.3/plugins/jspsych-RDK.js <lb/>Licence: GNU General Public License <lb/>Date published: 14/09/17 <lb/>(3) Sample jsPsych experiment implementing this stimulus <lb/>Code repository <lb/>Name: GitHub <lb/>Identifier: https://github.com/vrsivananda/RDK.git <lb/>Licence: GNU General Public License <lb/>Date published: 14/09/17 <lb/>Language <lb/>JavaScript/CSS/HTML <lb/></div>

			<div type="annex">(3) Reuse potential <lb/>Recently, platforms have been created which make it possible to conduct <lb/>psychological and perceptual experiments online, including the new &quot;jsPsych&quot; <lb/>JavaScript library [10] and Amazon&apos;s mTurk website for subject recruitment.  RDKs <lb/>are a commonly-used stimulus to evaluate motion perception thresholds in visual <lb/>psychophysics;; our release of the first open-access RDK for online experiments will <lb/>be of use to visual scientists, psychologists, and any researcher interested in <lb/>investigating motion perception in large numbers of subjects. <lb/>We think use of this stimulus in online experiments will be of particular value <lb/>to researchers interested in studying populations that may be difficult to access (e.g., <lb/>the elderly, individuals in various worldwide locations, individuals living far from <lb/>testing sites, etc.).  This new RDK also facilitates fast and efficient data collection in <lb/>motion perception experiments. In addition, psychophysicists and researchers will be <lb/>able to develop and extend our code under the GNU license to improve or modify the <lb/>RDK to serve specific research purposes. We hope our creation here is of use to the <lb/>greater vision science community and researchers interested in studying motion <lb/>perception, and that efforts can be taken to adapt other types of visual <lb/>psychophysical stimuli (Gabor patches, etc.) for online presentation as well. <lb/></div>

			<div type="annex">Competing interests <lb/>The authors declare that they have no competing interests. <lb/></div>

			<listBibl>References <lb/>1. Williams DW, Sekuler R. Coherent global motion percepts from stochastic local <lb/>motions. Vision Res. 1984;24: 55-62. Available: <lb/>https://www.ncbi.nlm.nih.gov/pubmed/6695508 <lb/>2. Britten KH, Shadlen MN, Newsome WT, Movshon JA. The analysis of visual motion: a <lb/>comparison of neuronal and psychophysical performance. J Neurosci. 1992;12: 4745-<lb/>4765. Available: https://www.ncbi.nlm.nih.gov/pubmed/1464765 <lb/>3. Roitman JD, Shadlen MN. Response of neurons in the lateral intraparietal area during a <lb/>combined visual discrimination reaction time task. J Neurosci. 2002;22: 9475-9489. <lb/>Available: https://www.ncbi.nlm.nih.gov/pubmed/12417672 <lb/>4. Law C--T, Gold JI. Neural correlates of perceptual learning in a sensory--motor, but not a <lb/>sensory, cortical area. Nat Neurosci. 2008;11: 505-513. doi:10.1038/nn2070 <lb/>5. Watamaniuk SN, Sekuler R, Williams DW. Direction perception in complex dynamic <lb/>displays: the integration of direction information. Vision Res. 1989;29: 47-59. <lb/>doi:10.1016/0042--6989(89)90173--9 <lb/>6. Scase MO, Braddick OJ, Raymond JE. What is Noise for the Motion System? Vision Res. <lb/>1996;36: 2579-2586. doi:10.1016/0042--6989(95)00325--8 <lb/>7. Peirce JW. PsychoPy----Psychophysics software in Python. J Neurosci Methods. 2007;162: <lb/>8-13. doi:10.1016/j.jneumeth.2006.11.017 <lb/>8. Peirce JW. Generating Stimuli for Neuroscience Using PsychoPy. Front Neuroinform. <lb/>2008;2: 10. doi:10.3389/neuro.11.010.2008 <lb/>9. Kiani R, Churchland AK, Shadlen MN. Integration of direction cues is invariant to the <lb/>temporal gap between them. J Neurosci. 2013;33: 16483-16489. <lb/>doi:10.1523/JNEUROSCI.2094--13.2013 <lb/>10. de Leeuw JR. jsPsych: a JavaScript library for creating behavioral experiments in a Web <lb/>browser. Behav Res Methods. 2015;47: 1-12. doi:10.3758/s13428--014--0458--y <lb/>11. de Leeuw JR, Motz BA. Psychophysics in a Web browser? Comparing response times <lb/>collected with JavaScript and Psychophysics Toolbox in a visual search task. Behav Res <lb/>Methods. 2016;48: 1-12. doi:10.3758/s13428--015--0567--2 </listBibl>


	</text>
</tei>
