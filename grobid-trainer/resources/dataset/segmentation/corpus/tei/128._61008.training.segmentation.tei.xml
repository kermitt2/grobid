<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Real-Time Computing with Lock-Free Shared Objects <lb/>James H. Anderson Srikanth Ramamurthy Kevin Je ay <lb/>Department of Computer Science, University of North Carolina, Chapel Hill, NC 27599-3175 <lb/>Abstract <lb/>This paper considers the use of lock-free shared objects <lb/>within hard r eal-time systems. As the name suggests, <lb/>lock-free shared objects are distinguished by the fact <lb/>that they are not locked. As such, they do not give <lb/>rise to priority inversions, a key advantage over con-<lb/>ventional, lock-based object-sharing approaches. De-<lb/>spite this advantage, it is not immediately apparent <lb/>that lock-free shared objects can be employed if tasks <lb/>must adhere to strict timing constraints. In particular, <lb/>lock-free object implementations permit concurrent op-<lb/>erations to interfere with each other, and repeated in-<lb/>terferences can cause a given operation to take an ar-<lb/>bitrarily long time to complete. <lb/>The main contribution of this paper is to show that <lb/>such interferences can be b ounded by judicious schedul-<lb/>ing. This work pertains to periodic, hard r eal-time <lb/>tasks that share l o ck-free objects on a uniprocessor. In <lb/>the rst part of the paper, scheduling conditions are de-<lb/>rived for such tasks, for both static and dynamic prior-<lb/>ity schemes. Based on these conditions, it is formally <lb/>shown that lock-free object-sharing approaches can be <lb/>expected to incur much less overhead than approaches <lb/>based on wait-free objects or lock-based schemes. In <lb/>the last part of the paper, this conclusion is vali-<lb/>dated experimentally through work involving a real-<lb/>time desktop videoconferencing system. <lb/></front>

			<body>1 Introduction <lb/>Lock-based approaches to synchronization are the ac-<lb/>cepted means for interprocess communication in real-<lb/>time systems. The main problem that arises in such <lb/>approaches is that of priority i n version, i.e., the sit-<lb/>uation in which a given task waits on another task <lb/></body>

            <front>The rst two authors were supported by NSF contract CCR <lb/>9216421, and by a Y oung Investigator A w ard from the U.S. <lb/>Army Research O ce, grant n umberDAAHO4-95-1-0323. The <lb/>third author was supported by grants from Intel and IBM. <lb/>Email: fanderson, ramamurt, je ayg@cs.unc.edu. <lb/> In Proceedings of the 16 th IEEE Real-Time Systems Symposium, Pisa, Italy, 1995, pp. 28-37. <lb/></front>

            <body>of lower priority to unlock a semaphore. Mechanisms <lb/>such as the priority ceiling protocol PCP 17, 1 8 <lb/>are used to solve this problem. The PCP requires <lb/>the operating system to identify those tasks that may <lb/>lock a semaphore. This information is used to ensure <lb/>that the priority of a task holding a semaphore is at <lb/>least that of the highest-priority task that ever locks <lb/>that semaphore. Although the PCP provides a gen-<lb/>eral framework for real-time synchronization, this gen-<lb/>erality comes at a price, speci cally operating system <lb/>overhead that is sometimes excessive. <lb/>In this paper, we consider interprocess communi-<lb/>cation in object-based, hard real-time systems. Our <lb/>main contribution is to show that lock-free shared ob-<lb/>jects 3, 7, 16 | i.e., objects that are not critical-<lb/>section-based | are a viable alternative t o l o c k-based <lb/>schemes such as the PCP in such systems. We es-<lb/>tablish this through a combination of formal anal-<lb/>ysis and experimentation. We begin by establish-<lb/>ing scheduling conditions for hard real-time, peri-<lb/>odic tasks that share lock-free objects on a unipro-<lb/>cessor under either rate-monotonic RM or earliest-<lb/>deadline-rst EDF scheduling 15 . We then com-<lb/>pare lock-free and lock-based approaches, both for-<lb/>mally, based on our scheduling conditions, and exper-<lb/>imentally, based on work involving a real-time desktop <lb/>videoconferencing facility. <lb/>Our formal analysis and experimental work both <lb/>lead to the same conclusion: lock-free objects of-<lb/>ten require less overhead than conventional lock-based <lb/>object-sharing approaches. In addition, our schedul-<lb/>ing conditions show that lock-free objects can be ap-<lb/>plied without detailed knowledge of which speci c <lb/>tasks access which objects. This makes them easier <lb/>to apply than lock-based schemes. Also, with lock-<lb/>free objects, new tasks can be added dynamically to <lb/>a system with very little e ort. In contrast, adding <lb/>new tasks with lock-based schemes entails recomput-<lb/>ing certain operating system tables e.g., tables in the <lb/>PCP that record the highest-priority task that locks <lb/>each semaphore. Furthermore, with lock-based <lb/>schemes, when a high-priority task tries to access <lb/>an object that is locked by a l o w-priority task, two <lb/>additional&quot; context switches are required, one from <lb/>the high-priority task to the low-priority task, and <lb/>another from the low-priority task back to the high-<lb/>priority task. Such context switching is unnecessary <lb/>when lock-free objects are used. <lb/>Lock-free operations are usually implemented using <lb/>retry loops&quot; 3, 6 , 7 , 1 1 , 1 6 . Figure 1 depicts an ex-<lb/>ample of such an operation, an enqueue taken from <lb/>a shared queue implementation given in 16 . In this <lb/>example, an enqueue is performed by trying to thread <lb/>an item onto the tail of the queue by using a two-word <lb/>compare-and-swap CAS2 instruction. 1 This thread-<lb/>ing is attempted repeatedly until it succeeds. Note <lb/>that the queue is not actually locked&quot; by a n y task. <lb/>A related notion to that of a lock-free object, which <lb/>may be familiar to some readers, is that of a wait-<lb/>free object. Wait-free objects guarantee a strong form <lb/>of lock-freedom that precludes all waiting dependen-<lb/>cies among tasks 6, 7, 19 including potentially un-<lb/>bounded retry loops. 2 Although one motivation for <lb/>work on wait-free objects has been their potential use <lb/>in real-time systems, our results show that lock-free <lb/>objects are usually superior for real-time computing <lb/>on uniprocessors. <lb/>From a real-time perspective, lock-free objects are <lb/>of interest because they do not give rise to priority <lb/>inversions, and can be implemented with minimal op-<lb/>erating system support. Despite these advantages, it <lb/>may seem that unbounded retry loops render such ob-<lb/>jects useless in hard real-time systems. Nonetheless, <lb/>we show that if tasks on a uniprocessor are scheduled <lb/>appropriately, then such loops are indeed bounded. <lb/>We n o w explain intuitively why such bounds exist. <lb/>For the sake of explanation, let us call an iteration <lb/>of a retry loop a successful update if it successfully <lb/>completes, and a failed u p date otherwise. Thus, a sin-<lb/>gle invocation of a lock-free operation consists of any <lb/>number of failed updates followed by a successful one. <lb/>Consider two tasks T i and T j that access a common <lb/>lock-free object B. Suppose that T i causes T j to expe-<lb/>rience a failed update of B. On an uniprocessor, this <lb/>can only happen if T i preempts the access of T j and <lb/></body>

            <note place="footnote">1 The rst two parameters of CAS2 are shared variables, the <lb/>next two parameters are values to which the shared variables <lb/>are compared, and the last two parameters are new values to be <lb/>placed in the shared variables should both comparisons succeed. <lb/>Note that it is possible to simulate the CAS2 instruction in <lb/>software, as discussed in Section 7. <lb/></note>

            <note place="footnote">2 More precisely, individual wait-free operations are required <lb/>to be starvation-free. In contrast, lock-free objects guarantee <lb/>only system-wide progress: if several tasks concurrently access <lb/>such an object, then some access will eventually complete. <lb/></note>

            <body>type objtype =recorddata: valtype; next : objtype end <lb/>shared var queue tail : objtype <lb/>procedure Enqueueinput : valtype <lb/>local var old tail, new tail : objtype <lb/>begin <lb/>new tail := input, NULL; <lb/>repeat old tail := queue tail <lb/>until CAS2queue tail, queue tail , next, <lb/>old tail, NULL, <lb/>new tail, new tail <lb/>end <lb/>Figure 1: Lock-free enqueue operation. <lb/>then updates B successfully. H o wever, T i preempts T j <lb/>only if T i has higher priority than T j . T h us, at each <lb/>priority level, there is a correlation between failed up-<lb/>dates and task preemptions. The maximum number <lb/>of task preemptions within a time interval can be de-<lb/>termined from the timing requirements of the tasks. <lb/>Using this information, it is possible to determine a <lb/>bound on the number of failed updates in that in-<lb/>terval. Intuitively, a set of tasks that share lock-free <lb/>objects is schedulable if there is enough free proces-<lb/>sor time to accommodate the failed updates that can <lb/>occur over any i n terval. <lb/>The formal analysis that we present establishes a <lb/>fundamental tradeo between lock-free and lock-based <lb/>approaches. This tradeo essentially hinges on the <lb/>cost of a lock-free retry loop, and the cost of the <lb/>operating system overhead that arises in lock-based <lb/>schemes. An important question, then, is how costly <lb/>lock-free retry loops are likely to be. Although such <lb/>loops could be long in principle, as shown in 16 , many <lb/>common objects, including most that would be of use <lb/>in a real-time system, can be implemented with very <lb/>short retry loops, such as that depicted in Figure 1 <lb/>see 2 for a detailed discussion of this issue. The <lb/>overriding conclusion to be drawn from our work is <lb/>that, for all but certain pathological objects that re-<lb/>quire costly retry loops, lock-free objects are likely to <lb/>require substantially less overhead than lock-based ob-<lb/>jects implemented using the PCP or other approaches. <lb/>The lock-free approach to real-time object sharing <lb/>that we espouse is actually rooted in work done by <lb/>Sorenson and Hamacher in the real-time systems com-<lb/>munity some twenty y ears ago 20, 21 . Sorenson and <lb/>Hamacher&apos;s work involved a real-time communication <lb/>mechanism based on wait-free read write bu ers. In <lb/>their approach, bu ers are managed by the operating <lb/>system, so it su ers from many of the same shortcom-<lb/>ings as conventional lock-based approaches. <lb/>Unfortunately, the thread of research o n w ait-free <lb/>and lock-free communication begun by Sorenson and <lb/>Hamacher was lost in the real-time systems commu-<lb/>nity for many y ears. Recently, h o wever, this thread of <lb/>research resurfaced in work presented by Kopetz and <lb/>Reisinger in 12 and by Johnson and Harathi in 11 . <lb/>In the former paper, a simple lock-free, one-writer, <lb/>read write bu er is presented, and scheduling condi-<lb/>tions are given for tasks sharing the bu er. In the <lb/>latter paper, the primary focus is implementations of <lb/>lock-free algorithms rather than scheduling. Our work <lb/>deals almost exclusively with scheduling, and signi -<lb/>cantly extends the work of Kopetz and Reisinger by <lb/>focusing on arbitrary task sets and objects. <lb/>The rest of this paper is organized as follows. In <lb/>Section 2, we present de nitions, notation, and two <lb/>key lemmas. We then derive RM and EDF scheduling <lb/>conditions in Sections 3 and 4, respectively. In ad-<lb/>dition, we brie y consider Deadline-Monotonic DM <lb/>scheduling in Section 3. We then formally and exper-<lb/>imentally compare lock-free object sharing with other <lb/>approaches in Sections 5 and 6, respectively. W e con-<lb/>clude in Section 7. <lb/>2 De nitions and Notation <lb/>We use the term task to refer to a sequential program <lb/>that is invoked repeatedly. W e call a single execution <lb/>of a task a job. The time at which a job arrives for <lb/>execution is called its release time. A task is periodic <lb/>i the interval between job arrivals is constant. In our <lb/>analysis, we assume that all tasks are periodic and <lb/>share a single processor. We assume that all release <lb/>times and periods are integers. For simplicity, w e as-<lb/>sume that jobs can be preempted at arbitrary points <lb/>during their execution, and ignore system overheads <lb/>like context switch times, interrupt handler overheads, <lb/>etc. <lb/>As in the previous section, we call an iteration of <lb/>a l o c k-free loop a successful update if it results in the <lb/>successful completion of the corresponding operation, <lb/>and a failed u p date otherwise. For now, we assume <lb/>that the deadline of a job is the end of the correspond-<lb/>ing period. Later, when considering DM scheduling at <lb/>the end of Section 3, we relax this assumption. A task <lb/>set is schedulable i all tasks meet their deadlines at <lb/>all times. The following is a list of symbols used in <lb/>deriving our scheduling conditions. <lb/>N -The number of tasks in the system. We use <lb/>i and j as task indices. Unless stated otherwise, <lb/>we assume that i and j are universally quanti ed <lb/>over f1; : : : ; N g. <lb/>T i -The i th task in the system. <lb/>p i -The period of task T i . T asks are sorted in <lb/>nondecreasing order by their periods, i.e., p i <lb/>p j i j . <lb/>r i k -The release time of the k th job of T i , where <lb/>r i k = r i 0 + k p i . W e use k as a job index. <lb/>Unless stated otherwise, we assume that k is uni-<lb/>versally quanti ed with range k 0. <lb/>c i -The worst-case computational cost execution <lb/>time of task T i when it is the only task executing <lb/>on the processor, i.e., when there is no contention <lb/>for the processor or for shared objects. <lb/>S m -The m th shared object in the system. <lb/>s -The execution time required for one loop iter-<lb/>ation in the implementation of a lock-free object, <lb/>which for simplicity is assumed to be the same for <lb/>all objects. This is also the extra computation re-<lb/>quired in the event of a failed update. <lb/>We obtain conditions for schedulability b y deter-<lb/>mining the worst-case unful lled demand&quot; of each <lb/>task. Informally, the unful lled demand of task T i <lb/>at time t is the remaining computation time of T i &apos;s <lb/>current job. In the derivation of our scheduling con-<lb/>ditions, we assume that the unful lled demand of T i <lb/>increases by s | the computation time of the extra <lb/>loop iteration that will result from a failed update | <lb/>when a job of T i is preempted by a higher-priority <lb/>job that accesses a common lock-free object. This ap-<lb/>proach is pessimistic because the preempted job may <lb/>not, in fact, be accessing any shared object when pre-<lb/>empted. Before we present our scheduling conditions, <lb/>we de ne the concept of a busy point&quot; and then state <lb/>two lemmas used in the proofs of these conditions. <lb/>In 15 , it is shown that for independent tasks, the <lb/>longest response time of a task occurs at a critical <lb/>instant of time, at which jobs of that task and all <lb/>higher-priority tasks are released. However, this is not <lb/>necessarily the case if tasks synchronize using lock-free <lb/>objects see 2 for examples showing why this is not <lb/>so. Instead of de ning the critical instant or giving <lb/>the worst-case phasing of the tasks, we i n troduce the <lb/>notion of a busy point. The busy point of the k th <lb/>job of task T i is denoted by b i k, where k 0. The <lb/>busy point, b i k, is the most recent point in time at <lb/>or before r i k when T i and all higher-priority jobs <lb/>either release a job or have zero unful lled demand. <lb/>It is easy to show that b i k i s w ell-de ned for any <lb/>i and k. In particular, at time 0, each task has either <lb/>just released its rst job or has no unful lled demand. <lb/>Hence, 0 b i k r i k. For the RM scheme, it is <lb/>possible to prove a tighter bound of r i k , 1; r i k <lb/>on the range of b i k. See 2 for details. In the for-<lb/>mal proofs of our scheduling conditions, we inductively <lb/>count the number of failed updates over intervals of <lb/>time. A busy point provides a convenient instant a t <lb/>which to start such an inductive argument, because <lb/>tasks that have zero unful lled demand or that have <lb/>just released a job have no failed updates. <lb/>We n o w state two lemmas that bound the number <lb/>of failed updates in a given interval, under the RM <lb/>and EDF schemes. Full proofs of these lemmas can be <lb/>found in 2 . <lb/>Lemma 2.1: Consider the k th job of task T i and <lb/>any t 2 b i k; r i k + 1, where k 0. i Under <lb/>the RM scheme, the number of failed u p dates in T i <lb/>and higher-priority tasks in the interval b i k; t is at <lb/>most <lb/>P i,1 <lb/>j=1 <lb/>l t,bik <lb/>pj <lb/>m <lb/>. ii Under the EDF scheme, <lb/>the number of failed u p dates in jobs with a dead-<lb/>line at or before t in the interval b i k; t is at most <lb/>P N <lb/>j=1 <lb/>t,bik <lb/>pj . <lb/>2 <lb/>
            The above lemma states that the number of failed <lb/>updates in an interval b i k; t is at most the num-<lb/>ber of higher-priority jobs released in the interval <lb/>b i k + 1 ; t . <lb/>Lemma 2.2: Under the RM scheme, If the k th job <lb/>of task T i has not completed execution at some time <lb/>t 0 2 r i k; r i k + 1 , where k 0, then, for any <lb/>t in the interval b i k; t 0 , the di erence b etween the <lb/>total demand placed on the processor by T i and higher-<lb/>priority tasks in the interval b i k; t and the available <lb/>processor time in that interval is greater than one. 2 <lb/>3 RM DM Conditions <lb/>The following theorem gives a su cient s c heduling <lb/>condition for the RM scheme. The left-hand side of <lb/>the quanti ed expression given below gives the max-<lb/>imum demand placed by T i and higher-priority tasks <lb/>in the interval 0; t . The rst summation represents <lb/>the demand placed on the processor by T i and higher-<lb/>priority tasks, not including the demand due to failed <lb/>updates. The second summation represents the to-<lb/>tal additional demand placed on the processor due to <lb/>failed updates in T i and higher-priority tasks. The <lb/>right-hand side of the expression is the available pro-<lb/>cessor time in 0; t . As noted in the introduction, this <lb/>condition can be applied without knowledge of which <lb/>tasks access which objects. <lb/>Theorem 3.1: A set of tasks scheduled under the RM <lb/>scheme is schedulable if the following condition holds <lb/>for every task T i . <lb/>h9t : 0 t p i : P i <lb/>j=1 <lb/>l t <lb/>pj <lb/>m c j + P i,1 <lb/>j=1 <lb/>l t,1 <lb/>pj <lb/>m s ti <lb/>Proof: We prove that if a task set is not schedulable, <lb/>then the negation of the above expression holds. As-<lb/>sume that the given task set is not schedulable. Let <lb/>the k th job of some task T i be the rst job to miss <lb/>its deadline. This can only happen if T i has positive <lb/>unful lled demand at r i k + 1 , 1. Consider any t <lb/>in the interval b i k; r i k + 1. By Lemma 2.2, the <lb/>di erence between the total demand due to T i and <lb/>higher-priority tasks in the interval b i k; t and the <lb/>available processor time in that interval is greater than <lb/>one. <lb/>We n o w derive a bound on D i b i k; t , the total <lb/>demand placed on the processor by T i and higher-<lb/>priority tasks in the interval b i k; t . D i b i k; t i s <lb/>comprised of the demand placed by job releases and <lb/>the extra demand placed by failed updates. Recall <lb/>that at the busy point o f t h e k th job, T i and all higher-<lb/>priority task have either completed execution have n o <lb/>unful lled demand or have a job release. Each job of <lb/>some task T j can place a demand of c j , and there are at <lb/>most dt,b i k+1=p j e job releases of that task in the <lb/>interval b i k; t . Therefore, the total demand placed <lb/>on the processor due to job releases of T i and higher-<lb/>priority tasks is at most <lb/>P i <lb/>j=1 dt , b i k + 1 =p j ec j . <lb/>By Lemma 2.1, the number of failed updates <lb/>in the interval b i k; t is given by <lb/>P i,1 <lb/>j=1 dt , <lb/>b i k=p j e. Each failed update requires s units <lb/>of additional demand. Therefore, the total ad-<lb/>ditional demand due to failed updates is at <lb/>most <lb/>P i,1 <lb/>j=1 dt , b i k=p j es. Therefore, we h a ve <lb/>D i b i k; t <lb/>P i <lb/>j=1 <lb/>l t,bik+1 <lb/>pj <lb/>m <lb/>c j + <lb/>P i,1 <lb/>j=1 <lb/>l t,bik <lb/>pj <lb/>m <lb/>s. <lb/>As stated previously, the di erence between the to-<lb/>tal demand due to T i and higher-priority tasks in the <lb/>interval b i k; t and the available processor time in <lb/>that interval is greater than one. Hence, we h a ve the <lb/>following. <lb/>D i b i k; t , t , b i k 1 <lb/>Using the bound on D i b i k; t , the previous expres-<lb/>sion can be rewritten as follows. <lb/>P i <lb/>j=1 <lb/>l t,bik+1 <lb/>pj <lb/>m <lb/>c j + <lb/>P i,1 <lb/>j=1 <lb/>l t,bik <lb/>pj <lb/>m <lb/>s t , b i k + 1 <lb/>The above expression holds for all t in the interval <lb/>b i k; r i k + 1. Because the above expression is in-<lb/>dependent of the end points it is a function of the <lb/>length of the interval, we can replace t , b i k with <lb/>t 0 , where t 0 = t , b i k and t 0 2 0; r i k + 1 , b i k. <lb/>Hence, we h a ve the following. <lb/>P i <lb/>j=1 <lb/>l t 0 +1 <lb/>pj <lb/>m <lb/>c j + <lb/>P i,1 <lb/>j=1 <lb/>l t 0 <lb/>pj <lb/>m <lb/>s t 0 + 1 <lb/>Now, replace t 0 with t in the above expression, where <lb/>t = t 0 + 1 and t 2 0; r i k + 1 , b i k . Then, the <lb/>following holds for all t 2 0; r i k + 1 , b i k . <lb/>P i <lb/>j=1 <lb/>l t <lb/>pj <lb/>m <lb/>c j + <lb/>P i,1 <lb/>j=1 <lb/>l t,1 <lb/>pj <lb/>m <lb/>s t <lb/>By de nition, b i k r i k. Therefore, the interval <lb/>0; r i k+1,r i k is completely contained in 0; r i k+ <lb/>1 , b i k . Also, from the de nitions, r i k + 1 , <lb/>r i k = p i . Therefore, the previous expression holds <lb/>for all t in 0; p i . <lb/>2 <lb/>In the videoconferencing system described in Sec-<lb/>tion 6, job deadlines and release points for the given <lb/>task set do not necessarily coincide, as we h a ve as-<lb/>sumed. However, the scheduling condition of Theorem <lb/>3.1 can easily be adapted to apply to such a task set. <lb/>This requires changing our model to allow the relative <lb/>deadline l i of task T i to range over 0; p i | b y rel-<lb/>ative deadline, w e mean the elapsed time between a <lb/>job&apos;s release time and its deadline. For simplicity, w e <lb/>assume that tasks are indexed in nondecreasing order <lb/>by relative deadline. <lb/>With this change to our model, it is possible to <lb/>prove the following static scheduling condition. This <lb/>condition assumes that priority is assigned by the DM <lb/>scheme 14 , in which tasks with smaller relative dead-<lb/>lines have higher priorities. The two summation terms <lb/>in the stated expression below give the computational <lb/>demand of T i and higher-priority tasks, and the ad-<lb/>ditional computation required due to failed updates, <lb/>respectively, i n a n i n terval of length t. <lb/>Theorem 3.2: A set of tasks scheduled under the DM <lb/>scheme is schedulable if the following condition holds <lb/>for every task T i . <lb/>h9t : t 2 0; l i : P i <lb/>j=1 <lb/>l t <lb/>pj <lb/>m c j + P i,1 <lb/>j=1 <lb/>l t,1 <lb/>pj <lb/>m s ti. <lb/>2 <lb/>In comparing this condition to that given in The-<lb/>orem 3.1, we see that t now ranges up to l i , the rel-<lb/>ative deadline of T i , rather than up to p i , the period <lb/>of T i . Observe that when deadlines coincide with job <lb/>releases, this condition reduces to RM scheduling. <lb/>4 EDF Scheduling Condition <lb/>The following theorem gives a su ciency condition <lb/>for schedulability under the EDF scheme. Like the <lb/>RM su ciency condition of the previous section, this <lb/>condition can be applied without knowledge of which <lb/>tasks access which objects. <lb/>Theorem 4.1: A set of periodic tasks scheduled under <lb/>the EDF scheme is schedulable if the following condi-<lb/>tion holds. <lb/>P N <lb/>j=1 <lb/>c j +s <lb/>pj 1. <lb/>Proof: We prove that if a task set is not schedulable <lb/>then <lb/>P N <lb/>j=1 <lb/>c j +s <lb/>pj <lb/>1. Assume that the given task set <lb/>is not schedulable. Let the k th job of some task T i be <lb/>the rst job to miss its deadline. This can only happen <lb/>if the di erence between the total demand due to tasks <lb/>with a deadline at or before r i k + 1 in the interval <lb/>b i k; r i k + 1 and the available processor time in <lb/>that interval is greater than one. <lb/>We rst derive a bound on D i b i k; r i k + 1 , 1, <lb/>the total demand placed on the processor by T i and <lb/>higher-priority tasks in the interval b i k; r i k + 1. <lb/>D i b i k; r i k + 1 , 1 is comprised of the demand <lb/>placed by job releases and the extra demand placed <lb/>by failed updates. Recall that at the busy point o f <lb/>the k th job, all jobs of equal or higher priority h a ve ei-<lb/>ther completed execution have no unful lled demand <lb/>or have a job release. Each job of some task T j can <lb/>place a demand of c j , and there are at most r i k + <lb/>1 , b i k=p j job releases of that task in the interval <lb/>b i k; t that have a deadline at or before r i k + 1. <lb/>Therefore, the total demand placed on the processor <lb/>due to such jobs is at most <lb/>P N <lb/>j=1 <lb/>r i k+1,bikc j <lb/>pj <lb/>. <lb/>
            By Lemma 2.1, The total number of failed updates <lb/>in the interval b i k; r i k + 1 is bounded by the <lb/>term <lb/>P N <lb/>j=1 <lb/>r i k+1,bik,1 <lb/>pj <lb/>. Each failed update re-<lb/>quires s units of additional demand. Therefore, the <lb/>total additional demand due to failed updates is at <lb/>most <lb/>P N <lb/>j=1 <lb/>r i k+1,bik,1s <lb/>pj <lb/>. As stated previously, <lb/>the di erence between the total demand placed on the <lb/>processor by jobs with deadlines at or before r i k + 1 <lb/>in the interval b i k; r i k + 1 and the available pro-<lb/>cessor time in that interval is greater than one. There-<lb/>fore, we h a ve the following. <lb/>P N <lb/>j=1 <lb/>r i k+1,bikc j <lb/>pj <lb/>+ <lb/>P N <lb/>j=1 <lb/>r i k+1,bik,1s <lb/>pj <lb/>,r i k + 1 , b i k , 1 1 <lb/>The terms on left-hand side of the previous expres-<lb/>sion give the total demand placed by jobs with dead-<lb/>lines before r i k+1, the total additional demand due <lb/>to failed updates in those jobs, and the available pro-<lb/>cessor time, in the interval b i k; r i k + 1, respec-<lb/>tively. The above expression can be rewritten as fol-<lb/>lows. <lb/>P N <lb/>j=1 <lb/>r i k+1,bikc j <lb/>pj <lb/>+ <lb/>P N <lb/>j=1 <lb/>r i k+1,bik,1s <lb/>pj <lb/>r i k + 1 , b i k <lb/>The previous expression implies the following. <lb/>P N <lb/>j=1 <lb/>r i k+1,bikc j +s <lb/>pj <lb/>r i k + 1 , b i k <lb/>Canceling out r i k + 1 , b i k from both sides of the <lb/>equation, we h a ve the following expression, thus com-<lb/>pleting our proof. <lb/>P N <lb/>j=1 <lb/>c j +s <lb/>pj <lb/>1 <lb/>2 <lb/>5 Formal Comparison <lb/>In this section, we compare lock-free objects to lock-<lb/>based synchronization schemes and wait-free objects. <lb/>This comparison is based upon the scheduling con-<lb/>ditions presented in the previous two sections, and <lb/>scheduling conditions for lock-based schemes found in <lb/>the literature. For simplicity, w e assume that all ac-<lb/>cesses to lock-based objects require r units of time, <lb/>and that there are no nested object calls. We recon-<lb/>sider the subject of nested calls later in Section 7. <lb/>Thus, the computation time c i of a task T i can be <lb/>written as c i = u i + m i t acc , where u i is the compu-<lb/>tation time not involving accesses to shared objects, <lb/>m i is the number of shared object accesses by T i , and <lb/>t acc is the computation time per object access, i.e., <lb/>s for lock-free objects and r for lock-based objects. <lb/>As explained below, recent studies that evaluate the <lb/>performance of lock-free objects 16 and lock-based <lb/>objects 5 indicate that s is likely to be much smaller <lb/>than r. This is con rmed by the experimental results <lb/>presented in Section 6. <lb/>5.1 Static-Priority S c heduling <lb/>We begin by comparing the overhead of lock-free syn-<lb/>chronization under RM scheduling with the overhead <lb/>of the lock-based priority ceiling protocol PCP 17 . <lb/>When tasks synchronize by l o c king, a higher-priority <lb/>job can be blocked by a l o wer-priority job that ac-<lb/>cesses a common object; the maximum blocking time <lb/>is called the blocking factor. Under the PCP, the <lb/>worst-case blocking time equals the time required to <lb/>execute the longest critical section. Since we do not <lb/>consider nested critical sections, the blocking factor <lb/>equals r, the time to execute a single critical section. <lb/>We denote the schedulability condition for periodic <lb/>tasks using the PCP by the predicate sched PCP, <lb/>which on the basis of the analysis in 17 , is de ned <lb/>as follows. <lb/>h8i 9t : 0 t p i : r + P i <lb/>j=1 <lb/>l t <lb/>pj <lb/>m <lb/>u j + m j r = ti <lb/>Observe that h8j : j i : m j + 1 s m j <lb/>ri^sched PCP implies h8i 9t : 0 t p i : <lb/>P i <lb/>j=1 <lb/>l t <lb/>pj <lb/>m <lb/>u j +m j s+ P i,1 <lb/>j=1 <lb/>l t,1 <lb/>pj <lb/>m s ti. Because <lb/>c j = u j + m j s, the previous expression is equivalent <lb/>to the scheduling condition of Theorem 3.1. Note that <lb/>s r <lb/>2 implies that h8j : j i : m j + 1 s m j ri <lb/>because, for positive m j , 1 <lb/>2 m j <lb/>m j +1 1. Thus, if <lb/>the time taken to execute one iteration of a lock-free <lb/>retry loop is less than half the time it takes to access <lb/>a l o c k-based object under the PCP, then any task set <lb/>that is schedulable under the PCP is also schedulable <lb/>when using lock-free objects. This also implies that <lb/>there are certain task sets that are schedulable when <lb/>lock-free objects are used, but not under the PCP. <lb/>What are typical values of s and r? A performance <lb/>comparison of various lock-free objects is given by <lb/>Massalin in 16 . Massalin reports that, given hard-<lb/>ware support for primitives like compare-and-swap, <lb/>s varies from 1.3 microseconds for a counter to 3.3 <lb/>microseconds for a circular queue. In the absence <lb/>of hardware support, such primitives can be simu-<lb/>lated by a trap, adding an additional 4.2 microsec-<lb/>onds. Massalin&apos;s conclusions are based on experiments <lb/>run on a 25 MHz, one-wait-state memory, cold-cache <lb/>68030 CPU. In contrast, lock-based implementations <lb/>fared much w orse in a recent performance comparison <lb/>of commercial real-time operating systems run on a <lb/>25 MHz, zero-wait-state memory 80386 CPU 5 . In <lb/>this comparison, the implementation of semaphores on <lb/>LynxOS took 154.4 microseconds to lock and unlock <lb/>a semaphore in the worst case. The corresponding <lb/>gure for POSIX mutex-style semaphores was 243.6 <lb/>microseconds. Although these gures cannot be re-<lb/>garded as de nitive, they do give some indication as <lb/>to the added overhead when operating-system-based <lb/>locking mechanisms are used. For the videoconferenc-<lb/>ing system described in Section 6, the situation is very <lb/>similar. In this system, s is 31 microseconds, while r <lb/>is 126.5 microseconds. <lb/>In the above comparison, we h a ve actually ignored <lb/>the e ect of blocking under the PCP. If the blocking <lb/>times are considerable, then lock-free objects would <lb/>perform better than as indicated above. It should <lb/>also be noted that our scheduling analysis is very pes-<lb/>simistic. In reality, a preempted task need not be ac-<lb/>cessing a shared object, and hence may not necessarily <lb/>have a failed update as we h a ve assumed. <lb/>5.2 Dynamic-Priority S c heduling <lb/>We n o w compare the overhead of lock-free objects with <lb/>two dynamic-priority s c hemes that use semaphore-<lb/>based objects: the dynamic priority ceiling protocol <lb/>DPCP 4 , and the dynamic deadline modi cation <lb/>DDM scheme under EDF scheduling EDF DDM <lb/>8 . Based on the analysis in 4 , a su cient condition <lb/>for the schedulability of a set of periodic tasks under <lb/>the DPCP, sched DPCP, can be de ned as follows. <lb/>sched DPCP P N <lb/>j=1 <lb/>c j +block j <lb/>pj <lb/>1 <lb/>
            In the above condition, block j is the maximum <lb/>time for which task T j can be blocked by some lower-<lb/>priority task, and equals the time to execute the <lb/>longest critical section. Since we h a ve assumed that <lb/>semaphore-based accesses require at most r time units, <lb/>we h a ve block j = r. <lb/>Observe that the above condition resembles the one <lb/>we h a ve derived for lock-free objects. It can be easily <lb/>shown that if s r sched DPCP, then <lb/>P N <lb/>j=1 c j + <lb/>s=p j 1. Therefore, by Theorem 4.1, if s r then <lb/>any set of tasks that can be scheduled under the DPCP <lb/>can also be scheduled using lock-free objects. Because <lb/>s is likely to be smaller than r, processor utilization <lb/>is likely to be smaller when lock-free objects are used <lb/>for synchronization. Thus, there are task sets that can <lb/>be scheduled when lock-free objects are used but not <lb/>when DPCP is used. <lb/>We n o w turn our attention to the EDF DDM <lb/>scheme presented in 8 . Under this scheme, tasks are <lb/>divided into one or more phases. During each phase, <lb/>a task accesses at most one shared resource. Before <lb/>a task T i accesses a shared object S m , its deadline <lb/>is modi ed to the deadline of some task T j that ac-<lb/>cesses S m and that has the smallest deadline of all <lb/>tasks that access S m . Upon completing the shared <lb/>object access, T i &apos;s deadline is restored to its original <lb/>value. In our comparison, we assume that phases in <lb/>which some shared object is accessed are r units in <lb/>length. Based on the analysis of 8 , a su cient con-<lb/>dition for the schedulability of a set of periodic tasks <lb/>under the EDF DDM scheme, sched DDM , can be <lb/>de ned as follows. <lb/>sched DDM P N <lb/>j=1 <lb/>u j +m j r <lb/>pj <lb/>1ĥ <lb/>8i; t : P i t p i : r + P i,1 <lb/>j=1 <lb/>j t,1 <lb/>pj <lb/>k u j + m j r ti <lb/>Observe that h8j : m j + 1 s m j riŝ <lb/>ched DDM implies <lb/>P N <lb/>j=1 <lb/>u j +m j +1s <lb/>pj <lb/>1. Because <lb/>c j = u j + m j s, the pervious expression is equivalent <lb/>to the scheduling condition of Theorem 4.1. As noted <lb/>previously, s r <lb/>2 implies h8j : m j + 1 s m j ri. <lb/>Thus, as with the PCP, if the time taken to exe-<lb/>cute one iteration of a lock-free retry loop is less than <lb/>half the time it takes to access an object using the <lb/>DDM scheme, then any task that is schedulable un-<lb/>der the EDF DDM scheme is also schedulable under <lb/>EDF scheduling using lock-free objects. As mentioned <lb/>previously, s is likely to be much smaller than r. <lb/>5.3 Wait-Free Objects <lb/>Wait-free shared objects di er from lock-free objects <lb/>in that wait-free objects are required to guarantee that <lb/>individual tasks are free from starvation. Most wait-<lb/>free algorithms ensure termination by requiring each <lb/>task to help&quot; every other task to complete any pend-<lb/>ing object access 6, 7 . However, on a uniprocessor, <lb/>lower-priority tasks cannot help higher-priority tasks <lb/>because a higher-priority task does not release the <lb/>processor until its demand has been ful lled. Thus, <lb/>each task only helps lower-priority tasks. Hence, the <lb/>greater the task priority, the larger the access time. In <lb/>some sense, the problem of priority i n version still ex-<lb/>ists, because a medium-priority task will have t o w ait <lb/>while a high-priority task helps a low-priority task. <lb/>On the other hand, when lock-free objects are used, <lb/>the time to complete an object access decreases with <lb/>increasing priority. F or these reasons, some task sets <lb/>that are schedulable when using lock-free objects will <lb/>not be schedulable when using wait-free objects. This <lb/>is true of the task set evaluated in Section 6.2. <lb/>6 Experimental Comparison <lb/>In this section, we provide empirical evidence that <lb/>lock-free objects are always competitive with, and <lb/>often superior to, more traditional lock-based ap-<lb/>proaches to real-time object sharing. This evi-<lb/>dence comes from a set of experimental compar-<lb/>isons performed using a real-time desktop videocon-<lb/>ferencing system implemented at UNC 10 . We <lb/>modi ed this system to support lock-free shared ob-<lb/>jects implemented under both DM and EDF schedul-<lb/>ing, semaphores implemented using the PCP under <lb/>DM scheduling, and semaphores implemented under <lb/>EDF DDM scheduling. We also considered wait-free <lb/>shared objects implemented under both DM and EDF <lb/>scheduling. The formal analysis for each synchro-<lb/>nization scheme was applied to determine whether it <lb/>was theoretically possible to ensure that no deadlines <lb/>would be missed. We then executed the system us-<lb/>ing each synchronization scheme under a variety o f <lb/>loading conditions, and compared the actual perfor-<lb/>mance to that predicted by the formal analysis. In <lb/>virtually all cases, the formal analysis predicted the <lb/>actual behavior of the system. Moreover, our lock-<lb/>free synchronization schemes frequently led to higher <lb/>levels of sustainable system utilization than was possi-<lb/>ble with lock-based synchronization. Also, our experi-<lb/>ments con rm that lock-free shared objects are usually <lb/>superior to wait-free objects for real-time computing <lb/>on uniprocessors. The following subsection describes <lb/>the videoconferencing system in more detail. <lb/>6.1 Experimental Setup <lb/>The videoconferencing system considered in our in-<lb/>vestigations acquires analog audio and video samples <lb/>o n a w orkstation and then digitizes, compresses, and <lb/>transmits the samples over a local-area network to a <lb/>second workstation where they are decompressed and <lb/>displayed. We modi ed the portion of the system re-<lb/>sponsible for the acquisition, compression, and net-<lb/>work transmission of media samples by the sending <lb/>workstation. <lb/>Abstractly, the tasks on the sending workstation are <lb/>organized as a software pipeline. Communication be-<lb/>tween stages is realized through a queue of media sam-<lb/>ples that is shared using a simple producer consumer <lb/>protocol. Queues of shared media samples exist be-<lb/>tween the digitizing task and the compression task <lb/>and between the compression task and the network <lb/>transmission task. The real-time constraints on the <lb/>operation of the pipeline require media samples to ow <lb/>through the pipeline in a periodic manner. Each stage <lb/>of the pipeline must process a media sample every 33 <lb/>milliseconds, and no media samples may be lost due <lb/>to bu er over ows. These constraints are met by im-<lb/>plementing the pipeline as a set of periodic tasks. <lb/>A comprehensive view of the tasks and shared <lb/>queues on the sending workstation is given in Figure <lb/>1. In this gure, an arrow is directed from each task <lb/>to each of the shared objects it accesses. The implicit <lb/>resources S 1 , S 13 correspond to queues used for <lb/>inter-task communication. These queues do not con-<lb/>tain any media samples. For our purposes, it su ces <lb/>to consider the tasks in Figure 1 to be an abstract <lb/>set of tasks | details regarding the function of each <lb/>task, and how the tasks interact are not important t o <lb/>us. For a more detailed description of this system, we <lb/>refer the interested reader to 22 . <lb/>We e v aluated the performance of the system when <lb/>the shared queues were implemented using lock-free <lb/>algorithms, wait-free algorithms, and lock-based tech-<lb/>niques. We implemented lock-free queues by using <lb/>the shared queue implementation given by Massalin in <lb/>(S <lb/>) <lb/>Compress Source (S ) <lb/>Next Digitize <lb/>(S ) <lb/>Compress Free (S ) <lb/>Compress Sink (S ) <lb/>Audio Free <lb/>(S ) <lb/>Transmit Audio (S ) <lb/>Transmit Video (S ) <lb/>Transmit Queue (S ) <lb/>15 <lb/>17 <lb/>14 <lb/>Implicit Resouces <lb/>Initiate <lb/>Digitize <lb/>Initiate <lb/>Transmit 1 <lb/>Compression <lb/>Task <lb/>Initiate <lb/>Compress <lb/>Transmit 1 <lb/>Transmit 3 <lb/>Transmit 2 <lb/>Audio <lb/>Task <lb/>Initiate <lb/>Transmit 2 <lb/>Task <lb/>Shared Object <lb/>User Timer Task <lb/>Keyboard Input Task <lb/>Screen Output Task <lb/>Camera Task <lb/>Packetize 2 <lb/>Packetize 1 <lb/>1−13 <lb/>21 <lb/>20 <lb/>19 <lb/>18 <lb/>16 <lb/>Figure 1: Tasks and shared queues in the videoconferenc-<lb/>ing system. <lb/>
            16 , and wait-free queues by using the wait-free uni-<lb/>versal construction given by Herlihy in 7 . Massalin&apos;s <lb/>queue implementation requires CAS needed for the <lb/>dequeue operation and CAS2 needed for the enqueue <lb/>operation, and Herlihy&apos;s construction requires load-<lb/>linked and store-conditional. W e implemented these <lb/>primitives by short kernel calls; interrupts were dis-<lb/>abled for the duration of these calls. <lb/>We found that the videoconferencing task set was <lb/>not schedulable under the DM scheduling when the <lb/>shared queues were implemented using Herlihy&apos;s wait-<lb/>free universal construction. This is due to the over-<lb/>head of helping, as discussed in Section 5.3. In con-<lb/>trast, our lock-free implementations required very lit-<lb/>tle overhead, with failed updates occurring only rarely. <lb/>For example, in ten executions of the system, only 363 <lb/>failed updates occurred in 415,229 enqueue operations. <lb/>We also found that multiple failed updates by a single <lb/>operation never occurred. In the following two subsec-<lb/>tions, we discuss results of experiments that were con-<lb/>ducted to compare lock-free and lock-based schemes <lb/>under static-and dynamic-priority s c heduling. <lb/>6.2 Static-Priority S c heduling <lb/>In this subsection, we discuss the results of experi-<lb/>ments that compare the overhead of lock-free objects <lb/>to lock-based objects implemented using the PCP. <lb/>In both cases scheduling was performed using a DM <lb/>scheduling algorithm 14 . <lb/>Qualitatively, when queue synchronization was <lb/>achieved using semaphores, approximately seven me-<lb/>dia samples were lost in the pipeline every second due <lb/>to bu er over ow. In contrast, no media samples were <lb/>lost when lock-free objects were used. <lb/>This result is predicted by the formal analysis of <lb/>the system, the details of which can be found in <lb/>2 . The analysis shows that under the PCP the <lb/>task Packetize 2 is not schedulable. This task <lb/>copies compressed media sample bu ers to the net-<lb/>work adapter. When Packetize 2 does not meet its <lb/>deadline, the sender drops never transmits some of <lb/>the media samples. This analysis explains why some <lb/>media samples were lost when the system was run us-<lb/>ing lock-based objects and the PCP. The analysis also <lb/>predicts that all tasks are schedulable when lock-free <lb/>objects are used. This is con rmed by the fact that <lb/>no media samples are lost during the execution of the <lb/>system. In our system, s equals 31 microseconds and <lb/>r equals 126:5 microseconds. Observe that s is less <lb/>than r=2. <lb/>6.3 Dynamic-Priority S c heduling <lb/>In this subsection, we discuss the results of experi-<lb/>ments that compare the overhead of lock-free objects <lb/>under the EDF scheme to lock-based objects under the <lb/>EDF DDM scheme. Our experiments showed that the <lb/>set of tasks in the system is schedulable under both <lb/>schemes. This result is predicted by the formal anal-<lb/>ysis of the system. For brevity, the formal analysis is <lb/>not presented here refer to 2 for details. <lb/>In order to more precisely compare lock-free ob-<lb/>jects with objects implemented under the EDF DDM <lb/>scheme, we i n troduced a dummy task to increase the <lb/>processor utilization of the system. This dummy task <lb/>consists of a bounded loop. During each loop itera-<lb/>tion, the task performs some busy work and accesses <lb/>some shared objects. The demand on the processor <lb/>was varied by modifying the number of loop iterations <lb/>executed by the dummy task. <lb/>Our experiments showed that processor utilization <lb/>was higher under the EDF DDM scheme for all task <lb/>loads. Under the EDF DDM scheme, tasks started to <lb/>miss deadlines when the dummy task performed ap-<lb/>proximately 3500 loop iterations. The processor uti-<lb/>lization corresponding to this load was close to 99.4. <lb/>For the same load, the processor utilization was only <lb/>94 when lock-free objects were used. Processor uti-<lb/>lization is higher under EDF DDM for the same load <lb/>due to the overhead of modifying task deadlines for <lb/>each shared object access. This con rms the predic-<lb/>tion of Section 5.2 that lock-free objects should re-<lb/>quire less overhead than object implemented under the <lb/>EDF DDM scheme. In our experiments, when lock-<lb/>free objects were used, tasks started missing deadlines <lb/>when the processor utilization was about 99.1. <lb/>7 Concluding Remarks <lb/>Our results show that lock-free objects have a n um-<lb/>ber of advantages over lock-based schemes such as the <lb/>PCP for real-time computing on uniprocessors. First, <lb/>lock-free objects are easier to use, because their appli-<lb/>cation does not require detailed knowledge of which <lb/>tasks access which objects. Second, systems using <lb/>lock-free objects can be more easily modi ed to add <lb/>tasks dynamically, since operating system tables do <lb/>not have to be recomputed. Third, in contrast to <lb/>the PCP, l o c k-free accesses do not give rise to exces-<lb/>sive context switches. Finally, and most importantly, <lb/>lock-free objects usually entail substantially less over-<lb/>head than objects implemented using lock-based tech-<lb/>niques. This is the case for most common objects, <lb/>the exception being certain pathological objects that <lb/>require excessive copying and hence costly retry loops. <lb/>Even in the absence of hardware support for prim-<lb/>itives like CAS2 refer to Figure 1, lock-free shared <lb/>objects can be implemented with low o verhead. On a <lb/>uniprocessor, this can be achieved by a nonpreempt-<lb/>able kernel call that simulates the required primitive. <lb/>This requires the introduction of a blocking factor y in <lb/>our scheduling conditions. This nonpreemptable code <lb/>fragment is smaller than one iteration of a lock-free <lb/>retry loop, i.e., y s . Observe that the introduction <lb/>of this blocking term in our RM scheduling condition <lb/>does not a ect our comparison with the PCP because <lb/>in comparing the two s c hemes, we ignored the blocking <lb/>factor in sched PCP. This reasoning also holds for the <lb/>EDF DDM scheme, because our comparison with that <lb/>scheme ignored the second conjunct of sched DDM, <lb/>which includes the blocking factor under EDF DDM <lb/>scheduling. In the case of the DPCP, i f w e i n troduce <lb/>the blocking factor into our su cient condition, then <lb/>we require s + y to be at most r for lock-free ob-<lb/>jects to perform as well as lock-based objects under <lb/>the DPCP. Note that, since y is smaller than s, w e <lb/>have s r=2 s + y r. <lb/>One advantage of lock-based schemes is that they <lb/>allow critical sections to be arbitrarily nested. It might <lb/>be useful, for example, to nest two critical sections <lb/>to transfer the contents of one shared bu er to an-<lb/>other. Recently, Anderson and Moir presented algo-<lb/>rithms for implementing multi-object operations that <lb/>allow similar functionality i n l o c k-free and wait-free <lb/>implementations 1 . Using these algorithms, a bu er <lb/>transfer can be accomplished in a lock-free or wait-<lb/>free manner by simultaneously accessing both bu ers. <lb/>Our scheduling conditions are still applicable if multi-<lb/>object accesses are allowed, provided s is de ned to be <lb/>the time taken by the longest retry loop, presumably <lb/>a loop that accesses several objects at once. <lb/></body>

			<div type="acknowledgement">Acknowledgements: We are grateful to Rich Gerber and <lb/>Ted Johnson for their comments on this paper. We also <lb/>thank Dave Bennett, Don Stone, and Terry Talley for help-<lb/>ing with the experimental work described in Section 6. <lb/></div>

			<listBibl>References <lb/>1 J. Anderson and M. Moir, Universal Construc-<lb/>tions for Multi-Object Operations&quot;, to appear in the <lb/>Proceedings of the 14th Annual ACM Symposium on <lb/>Principles of Distributed Computing, 1995. <lb/>2 J. Anderson, S. Ramamurthy and K. Je ay, Real-<lb/>Time Computing Using Lock-free Shared Objects&quot;, <lb/>Technical Report TR95-021, Department of Com-<lb/>puter Science, University of North Carolina, June <lb/>1995 URL: http: www.cs.unc.edu ~anderson <lb/>papers rtss95.ps.Z. <lb/>3 B. Bershad, Practical Considerations for Non-<lb/>Blocking Concurrent Objects&quot;, Proceedings of the <lb/>13th international Conference on Distributed Com-<lb/>puting Systems, M a y 1993, pp. pages 264-274. <lb/>4 M. I. Chen and K. J. Lin, Dynamic Priority Ceil-<lb/>ing: A Concurrency Control Protocol for Real Time <lb/>Systems&quot;, Real-Time Systems Journal, V ol. 2, No. <lb/>1, 1990, pp. 325-346. <lb/>5 B. O. Gallmeister and C. Lanier, Early Expe-<lb/>rience With POSIX 1003.4 and POSIX 1003.4A&quot;, <lb/>Proceedings of the 12th IEEE Real-Time Systems <lb/>Symposium, 1991, pp. 190-198. <lb/>6 M. Herlihy, W ait-Free Synchronization&quot;, ACM <lb/>Transactions on Programming Languages and Sys-<lb/>tems, V ol. 13, No. 1, 1991, pp. 124-149. <lb/>7 M. Herlihy, A Methodology for Implementing <lb/>Highly Concurrent Data Objects&quot;, ACM Transac-<lb/>tions on Programming Languages and Systems, V ol. <lb/>15, No. 5, 1993, pp. 745-770. <lb/>8 K. Je ay, Scheduling Sporadic Tasks with Shared <lb/>Resources in Hard Real-Time Systems&quot;, Proceedings <lb/>of the 13 th IEEE Symposium on Real-Time Sys-<lb/>tems, Phoenix, AZ, 1992, pp. 89-99. <lb/>9 K. Je ay and D. Stone, Accounting for Interrupt <lb/>Handling Costs in Dynamic Priority T ask Systems&quot;, <lb/>Proceedings of the 14 th IEEE Symposium on Real-<lb/>Time Systems, Durham, NC, 1993, pp. 212-221. <lb/>10 K. Je ay, D.L. Stone, and F.D. Smith, Kernel <lb/>Support for Live Digital Audio and Video&quot;, Com-<lb/>puter Communications, V ol. 15, No. 6, July August <lb/>1992, pp. 388-395. <lb/>11 T. Johnson and K. Harathi, Interruptible Criti-<lb/>cal Sections&quot;, T echnical Report TR94-007, Depart-<lb/>ment of Computer Science, University of Florida, <lb/>1994. <lb/>12 H. Kopetz and J. Reisinger, The Non-Blocking <lb/>Write Protocol NBW: A Solution to a Real-Time <lb/>Synchronization Problem&quot;, Proceedings of the IEEE <lb/>Real-Time Systems Symposium, 1993, pp. 131-137. <lb/>13 J. Lehoczky, L. Sha, and Y. Ding, The Rate <lb/>Monotonic Scheduling Algorithm: Exact Charac-<lb/>terization and Average Case Behavior&quot;, Proceedings <lb/>of the Tenth IEEE Real-Time Systems Symposium, <lb/>Santa Monica, CA, 1989, pp. 166-171. <lb/>14 J.Y.T. Leung and J. Whitehead, On the Com-<lb/>plexity of Fixed-Priority S c heduling of Periodic, <lb/>Real-Time Tasks&quot;, Performance Evaluation, V ol. 2, <lb/>No. 4, 1982, pp. 237-250. <lb/>15 C. Liu and J. Layland, Scheduling Algorithms <lb/>for multiprogramming in a Hard Real Time Envi-<lb/>ronment&quot;, Journal of the ACM , V ol 30., Jan. 1973, <lb/>pp. 46-61. <lb/>16 H. Massalin, Synthesis: An E cient Implemen-<lb/>tation of Fundamental Operating System Services, <lb/>Ph.D. Dissertation, Columbia University, 1992. <lb/>17 Raghunathan Rajkumar, Synchronization In <lb/>Real-Time Systems -A Priority Inheritance Ap-<lb/>proach, Kluwer Academic Publications, 1991. <lb/>18 L. Sha, R. Rajkumar, and J. Lehoczky, Prior-<lb/>ity Inheritance Protocols: An Approach to Real-<lb/>Time System Synchronization&quot;, IEEE Transactions <lb/>on Computers, V ol. 39, No. 9, 1990, pp. 1175-1185. <lb/>19 A. Singh, J. Anderson, and M. Gouda, The Elu-<lb/>sive A tomic Register&quot;, Journal of the ACM , V ol. 41, <lb/>No. 2, March 1994, pp. 311-339. <lb/>20 P. Sorensen, A Methodology for Real-Time Sys-<lb/>tem Development, Ph.D. Thesis, University o f <lb/>Toronto, 1974. <lb/>21 P. Sorensen and V. Hemacher, A Real-Time Sys-<lb/>tem Design Methodology&quot;, INFOR, Vol. 13, No. 1, <lb/>February 1975, pp. 1-18. <lb/> 22 D. Stone, Managing the E ect of Delay Jitter <lb/>on the Display of Live Continuous Media, Doctoral <lb/>Dissertation, University of North Carolina, Chapel <lb/>Hill, 1995. </listBibl>


	</text>
</tei>
