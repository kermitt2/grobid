<TEI xmlns="http://www.tei-c.org/ns/1.0">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title level="a">Commutativity Simplifies Proofs of Parameterized Programs</title>
        <author>
          <persName>
            <forename>Azadeh</forename>
            <surname>Farzan</surname>
          </persName>
        </author>
        <author>
          <persName>
            <forename>Dominik</forename>
            <surname>Klumpp</surname>
          </persName>
        </author>
        <author>
          <persName>
            <forename>Andreas</forename>
            <surname>Podelski</surname>
          </persName>
        </author>
      </titleStmt>
      <editionStmt>
        <edition>
          <date when="2025-10-29T15:57:09.405043Z">29.10.2025 15:57:09</date>
          <title>grobid.training.segmentation [default]</title>
          <idno type="fileref">10.1145$1$3632925</idno>
        </edition>
      </editionStmt>
      <publicationStmt>
        <publisher>Association for Computing Machinery (ACM)</publisher>
        <availability>
          <licence target="https://creativecommons.org/licenses/by/4.0/"/>
        </availability>
        <date type="publication">2024</date>
        <idno type="DOI">10.1145/3632925</idno>
      </publicationStmt>
      <sourceDesc>
        <bibl>Azadeh Farzan, Dominik Klumpp, Andreas Podelski. (2024). Commutativity Simplifies Proofs of Parameterized Programs. Proceedings of the ACM on Programming Languages, 8(POPL), 2485-2513. DOI: 10.1145/3632925</bibl>
      </sourceDesc>
    </fileDesc>
    <encodingDesc>
      <appInfo>
        <application version="1.0" ident="pdf-tei-editor" type="editor">
          <ref target="https://github.com/mpilhlt/pdf-tei-editor"/>
        </application>
        <application version="0.8.3-SNAPSHOT" ident="GROBID" when="2025-10-29T15:57:09.405043Z" type="extractor">
          <desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
          <label type="revision">eb7768b</label>
          <label type="flavor">default</label>
          <label type="variant-id">grobid.training.segmentation</label>
          <ref target="https://github.com/kermitt2/grobid"/>
        </application>
      </appInfo>
    </encodingDesc>
    <revisionDesc>
      <change when="2025-10-29T15:57:09.405043Z" status="draft">
        <desc>Generated with createTraining API</desc>
      </change>
    </revisionDesc>
  </teiHeader>
  <text xmlns="http://www.tei-c.org/ns/1.0" xml:lang="en">
        <front>Spore: Combining Symmetry and Partial Order Reduction <lb/>MICHALIS KOKOLOGIANNAKIS, MPI-SWS, Germany <lb/>IASON MARMANIS, MPI-SWS, Germany <lb/>VIKTOR VAFEIADIS, MPI-SWS, Germany <lb/>Symmetry reduction (SR) and partial order reduction (POR) aim to scale up model checking by exploiting the <lb/>underlying program structure: SR avoids exploring executions equivalent up to some permutation of symmetric <lb/>threads, while POR avoids exploring executions equivalent up to reordering of independent instructions. <lb/>While both SR and POR have been well studied individually, their combination in the context of stateless <lb/>model checking has remained an open problem. <lb/>In this paper, we present Spore, the first stateless model checker that combines SR and POR in a sound, <lb/>complete and optimal manner. Spore can leverage both symmetries in the client program itself, but also <lb/>internal symmetries in the underlying implementation (i.e., idempotent operations), a novel symmetry notion <lb/>we introduce in this paper. Our experiments confirm that Spore explores drastically fewer executions than <lb/>tools that solely employ SR/POR, thereby greatly advancing the state-of-the-art. <lb/>CCS Concepts: • Theory of computation → Concurrency; Verification by model checking. <lb/>Additional Key Words and Phrases: Model Checking, Dynamic Partial Order Reduction, Symmetry Reduction <lb/>ACM Reference Format: <lb/>Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis. 2024. Spore: Combining Symmetry and <lb/>Partial Order Reduction. Proc. ACM Program. Lang. 8, PLDI, Article 219 (June 2024), 23 pages. https://doi.org/ <lb/>10.1145/3656449 <lb/></front>

        <body>1 INTRODUCTION <lb/>Stateless model checking (SMC) [Godefroid 1997] verifies a concurrent program by enumerating <lb/>all of its executions. SMC is quite popular in concurrent program verification as (a) can be used by <lb/>programmers without any expertise in formal methods, (b) it can handle programs in full-fledged <lb/>programming languages like C, C++ and Java, and (c) it can reason about the effects of the underlying <lb/>weak memory model (e.g., C/C++11 [Lahav et al. 2017]). On the downside, however, SMC only <lb/>supports verification of bounded programs, and often does not scale well enough to handle client <lb/>programs with a sufficient number of threads to provide strong confidence the correctness of a <lb/>given implementation. <lb/>There are two sound techniques that can be employed to increase the scalability of SMC. <lb/>Symmetry reduction (SR) [Clarke et al. 1996; Emerson and Wahl 2005] exploits symmetries in the <lb/>threads of the program under test (e.g., all threads running the same code) and avoids to consider <lb/>all the ways in which symmetric threads interleave, as the order in which such threads execute is <lb/></body>

        <front>Authors&apos; addresses: Michalis Kokologiannakis, MPI-SWS, Kaiserslautern, Germany, michalis@mpi-sws.org; Iason Marmanis, <lb/>MPI-SWS, Kaiserslautern, Germany, imarmanis@mpi-sws.org; Viktor Vafeiadis, MPI-SWS, Kaiserslautern, Germany, <lb/>viktor@mpi-sws.org. <lb/>© 2024 Copyright held by the owner/author(s). <lb/>ACM 2475-1421/2024/6-ART219 <lb/>https://doi.org/10.1145/3656449 <lb/>Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/>This work is licensed under a Creative Commons Attribution 4.0 International License. <lb/></front>

        <page>219:2 <lb/></page>

        <note place="headnote">Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis <lb/></note>

        <body>clearly irrelevant. As an example of SR, consider the fais program where symmetric threads <lb/>perform an atomic &quot;fetch-and-increment&quot; operation on : <lb/>fetch_add ( , 1) ... fetch_add ( , 1) <lb/>(fais) <lb/>While naive SMC explores ! executions for this program, SR only explores 1 execution. <lb/>Dynamic partial order reduction (DPOR) [Abdulla et al. 2014; Flanagan and Godefroid 2005] <lb/>reduces the program state space by not exploring executions that are equivalent up to some permu-<lb/>tation of independent instructions (e.g., instructions accessing different variables). For instance, <lb/>consider the program below where 26 (non-symmetric) threads write different parts of an array: <lb/>:= 1 <lb/>:= 2 ... <lb/>:= 26 <lb/>(array) <lb/>For array, naive SMC would again explore 26! executions while DPOR would only explore 1, as it <lb/>notices that all threads access different parts of memory, and hence their relative order is irrelevant. <lb/>A common way to view both SR and DPOR is via the equivalence partitioning they induce on the <lb/>program state space. Indeed, SR groups together executions that can be obtained from one another <lb/>by changing the ID of symmetric threads, while DPOR groups together executions that can be <lb/>obtained from one another by changing the order of non-conflicting instructions. <lb/>Observe, however, that even for symmetric programs, SR and DPOR are not equivalent, and <lb/>neither approach subsumes the other. This can be seen with the example below: <lb/>:= fetch_add ( , 1) <lb/>[ ] := <lb/>... <lb/>:= fetch_add ( , 1) <lb/>[ ] := <lb/>(fais+array) <lb/>While DPOR explores ! executions for fais+array (due to the conflicting fetch_adds), SR explores <lb/>(2 -1)!! executions (double factorial of odd numbers). This discrepancy is because in SMC, after <lb/>each thread has executed its fetch_add, symmetry &quot;breaks&quot;, as each thread reads a different value. <lb/>Even though SR and DPOR are both effective when applied, existing SR/DROR approaches have <lb/>two major limitations. First, they are incompatible: indeed, despite years of research on each of <lb/>SR/DPOR, no algorithm manages to successfully combine the two, so employing one of them <lb/>precludes the usage of the other. Second, both SR and DPOR fail to leverage internal symmetries, <lb/>i.e., idempotent operations of the underlying implementation. One case of internal symmetry is the <lb/>quintessential helping pattern, where some operation observes an ongoing operations of the same <lb/>type that is incomplete, and then tries to complete the ongoing operation before performing its own. <lb/>SR fails to exploit internal symmetries as the threads performing the operations are not sharing the <lb/>same code, while DPOR fails to do so because the two operations are considered conflicting. <lb/>In this paper, we present Spore (Symmetry and Partial Order Reduction Explorer), a novel <lb/>algorithm that combines SR and DPOR, and overcomes both limitations above. Spore resolves <lb/>thread-level symmetries by restricting the coherence order of symmetric conflicting operations to <lb/>agree with their thread order, and internal symmetries with a novel memory-model axiomatization <lb/>that equates executions differing only in the order of the locally symmetric operations. The resulting <lb/>algorithm is sound, complete and optimal under the combined equivalence partitionings, and <lb/>achieves exponential reduction in verification time over the state-of-the-art. Spore is also parametric <lb/>in the choice of the underlying (weak) memory model. <lb/>Our contributions can be summarized as follows. <lb/> §2 We (informally) describe why the combination of DPOR and SR is non-trivial, as well as how <lb/>Spore exploits thread-level and internal internal symmetries. <lb/> §3 We present Spore in detail and prove its correctness. <lb/> §4 We implement Spore in a tool for C/C++ programs, and empirically demonstrate that it is <lb/>orders of magnitude faster than the state-of-the-art. <lb/></body>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <note place="headnote">Spore: Combining Symmetry and Partial Order Reduction <lb/></note>

        <page>219:3 <lb/></page>

        <body>2 SPORE: INFORMAL DESCRIPTION <lb/>We develop Spore by adding SR on top of a DPOR algorithm (as opposed to the other way around), <lb/>since DPOR underpins most modern SMC solutions [Abdulla et al. 2018; Aronis et al. 2018; Chalupa <lb/>et al. 2017; Kokologiannakis et al. 2022, 2019b; Norris and Demsky 2013]. As such, we begin this <lb/>section by explaining the basics of DPOR ( §2.1), and then describe why the combination of DPOR <lb/>and symmetry reduction is non-trivial and how Spore achieves it ( §2.2). We end the section by <lb/>demonstrating how Spore handles internal symmetries ( §2.3). <lb/>2.1 Dynamic Partial Order Reduction <lb/>Modern DPOR algorithms, such as TruSt [Kokologiannakis et al. 2022], represent program execu-<lb/>tions up to the reordering of independent accesses in a structure called execution graph [Alglave <lb/>et al. 2014], and verify a given program by constructing its associated execution graphs in an <lb/>incremental fashion. <lb/>Each execution graph comprises: (a) a set of events E (graph nodes), modeling instructions <lb/>of the program, and (b) a few relations on events (graph edges), modeling various interactions <lb/>between the instructions. In the following, we consider three such directed edges: the program <lb/>order (po), which orders instructions of the same thread, the reads-from relation (rf), which relates <lb/>each read event in to a write event in , from which obtains its value, and the coherence <lb/>order (co), which totally orders writes at each memory location. <lb/>Example 1 Consider the w+r+r program below. <lb/>T1: := 1 T2: 2 := <lb/>T3: 3 := <lb/>(w+r+r) <lb/>Under sequential consistency (SC) [Lamport 1979], the program has four executions, 1 -4 , which <lb/>model the four equivalence classes into which the 3! = 6 thread interleavings are partitioned. These <lb/>graphs can be produced by the following DPOR exploration starting from the initial graph Init <lb/>through the intermediate graphs A , B , and C . <lb/>Init <lb/>init <lb/>A <lb/>init <lb/>W ( , 1) <lb/>B <lb/>init <lb/>W ( , 1) <lb/>R ( ) <lb/>1 <lb/>init <lb/>W ( , 1) <lb/>R ( ) <lb/>R ( ) <lb/>2 <lb/>init <lb/>W ( , 1) <lb/>R ( ) <lb/>R ( ) <lb/>C <lb/>init <lb/>W ( , 1) <lb/>R ( ) <lb/>3 <lb/>init <lb/>W ( , 1) <lb/>R ( ) <lb/>R ( ) <lb/>4 <lb/>init <lb/>W ( , 1) <lb/>R ( ) <lb/>R ( ) <lb/>The exploration proceeds in a depth-first manner: DPOR adds the events of the program from <lb/>left to right, one by one, and whenever a read has more than one place to read from, DPOR initiates <lb/>a recursive subexploration. For instance, when the read of T2 is added, it can read both 0 and 1 <lb/>(both options are consistent according to SC), and thus DPOR initiates subexplorations B and C . <lb/>DPOR proceeds in a similar manner, until all events of the program have been added to the graph. <lb/></body>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <page>219:4 <lb/></page>

        <note place="headnote">Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis <lb/></note>

        <body>Conventions <lb/>Following standard conventions in the weak memory model literature, we (1) treat rf as <lb/>a relation from the write to the read event; (2) assume a special initialization event init, <lb/>which initializes every location with 0 and is thus po-before all other events and co-before <lb/>all other write events; (3) we do not draw co edges from init to other writes (as it is <lb/>trivially co-before them). In explorations, we use le ers to refer to intermediate executions, <lb/>numbers to refer to full executions, and red to denote executions that will not be explored. <lb/>Revisits. The exploration in Example 1 was largely straightforward, but there is still one aspect <lb/>of DPOR we have not discussed: revisiting. For exposition purposes, suppose we add the events <lb/>of w+r+r from right to left. When we encounter the reads, they cannot yet read 1 because the <lb/>corresponding write does not exist in the graph. Therefore, whenever a write is added to a graph, <lb/>DPOR also revisits existing same-location reads to see if they can read from the newly added write. <lb/>Whenever DPOR revisits a read from a write , it restricts the graph to remove some of the <lb/>events added to the graph after , since they may depend on the value read by . (If not, they will <lb/>be re-added in subsequent steps of the exploration.) The most common choice for restricting the <lb/>graph is to keep only the events that were added before and those causally before (i.e., in its <lb/>porf △ <lb/>= (po ∪ rf) + prefix). For instance, in the right-to-left exploration of w+r+r, if W ( , 1) revisits <lb/>the read of T3, the resulting graph does not have the read of T2 because it was added after T3 and is <lb/>not porf-before W( , 1). <lb/>The restriction due to revisits may lead to duplicate explorations, as we demonstrate below. <lb/>Example 2 Consider the following variation of w+r+r. <lb/>T1: := 1 T2: 2 := <lb/>T3: := 2 <lb/>(w+r+w) <lb/>init <lb/>W ( , 1) <lb/>R ( ) <lb/>init <lb/>W ( , 1) <lb/>R ( ) <lb/>Fig. 1. Revisit opportunities <lb/>Adding the events from left to right, observe that there are <lb/>two subexplorations where W( , 2) has the chance to revisit <lb/>the read of T2: when the latter reads 0 and when it reads 1. <lb/>These subexplorations are shown in Fig. 1. If W( , 2) performs <lb/>the revisit in both, the exact same graph will be created. <lb/>There are two ways DPOR can avoid such duplication. Abdulla et al. [2014] and Kokologiannakis <lb/>et al. [2019b] simply save all encountered executions (more precisely: the ones created by revisits), <lb/>and drop subsequent revisits that yield an already encountered execution. Storing executions, <lb/>however, leads to exponential memory consumption in the size of the program under test. <lb/>Avoiding Duplication with Maximal Extensions. A better solution adopted by TruSt [Kokologian-<lb/>nakis et al. 2022] is to impose a revisiting condition so that a given revisit only takes place once <lb/>among all possible subexplorations. The key observation is that whenever DPOR encounters two <lb/>graphs that will yield the same graph immediately after a revisit, then in both cases the revisit <lb/>happens from the same write to the same read , and the graphs only differ in the sets of events <lb/>that were affected by the revisit (namely, itself and all the events deleted by the revisit). <lb/>TruSt therefore constrains the events affected by the revisit (i.e., the read being revisited and <lb/>the deleted events) to form a maximal extension: to be added co-maximally w.r.t. to the porf-prefix <lb/>of the revisiting write. Maximal conditions are better understood with an example. <lb/></body>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <note place="headnote">Spore: Combining Symmetry and Partial Order Reduction <lb/></note>

        <page>219:5 <lb/></page>

        <body>Example 3 Consider the rev-ex below along with its SC-consistent execution graphs. <lb/>T1: := <lb/>T2: if ( = 1) <lb/>:= 2 <lb/>:= <lb/>T3: := 1 <lb/>:= 1 <lb/>(rev-ex) <lb/>1 <lb/>init <lb/>R ( ) <lb/>R ( ) W ( , 1) <lb/>W ( , 1) <lb/>2 <lb/>init <lb/>R ( ) <lb/>R ( ) W ( , 1) <lb/>W ( , 1) <lb/>3 <lb/>init <lb/>R ( ) <lb/>R ( ) <lb/>W ( , 2) <lb/>R ( ) <lb/>W ( , 1) <lb/>W ( , 1) <lb/>4 <lb/>init <lb/>R ( ) <lb/>R ( ) <lb/>W ( , 2) <lb/>R ( ) <lb/>W ( , 1) <lb/>W ( , 1) <lb/>A DPOR run producing these execution can be seen below. <lb/>A <lb/>init <lb/>R ( ) R ( ) <lb/>B <lb/>init <lb/>R ( ) <lb/>R ( ) <lb/>W ( , 1) <lb/>1 <lb/>init <lb/>R ( ) <lb/>R ( ) <lb/>W ( , 1) <lb/>W ( , 1) <lb/>C <lb/>init <lb/>R ( ) R ( ) W ( , 1) <lb/>E <lb/>init <lb/>R ( ) <lb/>R ( ) <lb/>W ( , 2) <lb/>R ( ) <lb/>W ( , 1) <lb/>F <lb/>init <lb/>R ( ) <lb/>W ( , 1) <lb/>W ( , 1) <lb/>... <lb/>3 <lb/>init <lb/>R ( ) <lb/>R ( ) <lb/>W ( , 2) <lb/>R ( ) <lb/>W ( , 1) <lb/>W ( , 1) <lb/>Assuming that DPOR adds events in a left-to-right manner, after adding the events of the first two <lb/>threads, it then adds W ( , 1) which can either revisit R ( ) or not (graphs C and B , respectively). <lb/>Following the respective subexplorations, W ( , 1) is encountered in both cases: in exploration B <lb/>immediately, and in exploration C after adding the events under the conditional of T2 1 . Similarly <lb/>to W( , 1), in both subexplorations, W ( , 1) has the opportunity to either revisit R ( ) or not. <lb/>Revisiting R ( ) in both cases, however, leads to duplication, as the same graph (graph F ) will be <lb/>obtained twice. Maximal extensions dictate that the revisit only takes place from execution E , as all <lb/>the affected events are added maximally w.r.t. W ( , 1). To see why, it is helpful to think &quot;backwards&quot;: <lb/>starting from the graph obtained from the revisit without the write and read participating in the <lb/>revisit (W ( , 1) and R ( )), if all the affected events are added in a co-maximal manner (i.e., reads <lb/>reading the co-latest write and writes added last in co), we get graph E , which is the graph from <lb/>where the revisit takes place. <lb/>To define maximal extensions, we first introduce an auxiliary definition about execution graphs. <lb/>A write event is co-maximal in a set of events if ∈ and it does not have a co-successor in <lb/>(i.e., <lb/>′ ∈ . ⟨ , ′ ⟩ ∈ co). <lb/></body>

        <note place="footnote">1 These events have a unique co and rf option as SC enforces coherence: informally, T2 is already aware of W ( , 1) so W ( , 2) <lb/>has to be co-after it, and R ( ) has to read the latest value T2 is aware of. <lb/>Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <page>219:6 <lb/></page>

        <note place="headnote">Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis <lb/></note>

        <body>Definition 2.1. An event in a graph is added maximally w.r.t. a write event in , if the <lb/>following conditions hold, where is the set of all events ′ added before or in &apos;s porf prefix <lb/>(i.e., ⟨ ′ , ⟩ ∈ porf): <lb/>• If ∈ W, then is co-maximal in . <lb/>• If ∈ R, then .rf( ) is co-maximal in . <lb/>Observe that non-write/read events are always added maximally w.r.t. a revisiting write. <lb/>Maximal extensions also have the following useful property, which we will use in some of our <lb/>examples below. <lb/>Proposition 2.2. If a write revisits a read resulting in a graph , the porf-prefix of will not <lb/>be removed in any of the subsequent subexplorations starting from [Kokologiannakis et al. 2022]. <lb/>2.2 Spore: Thread-Level Symmetries <lb/>Consider again the w+r+r example where T2 and T3 share their code. <lb/>T1: := 1 T2: 2 := <lb/>T3: 3 := <lb/>(w+r+r) <lb/>We say that executions 2 and 3 from its consistent executions (see Example 1) are symmetric <lb/>because one can be obtained by permuting the symmetric threads of the other. <lb/>2.2.1 Distinguishing Among Symmetric Executions. To avoid exploring both graphs, we pick a <lb/>representative execution among them and instrument DPOR to drop non-representative symmetric <lb/>executions. <lb/>Spore achieves this using thread IDs: we deem as representative the graph where a symmetric <lb/>thread only reads values that are at least as &quot;recent&quot; (in terms of co) as the ones read by its symmetric <lb/>predecessor. In the w+r+r example, this means that graph 2 is the representative one, as in graph <lb/>3 the read of T2 reads a value that is co-after the one read by T3 2 . <lb/>Let us formalize this intuition. We say that two events , ′ in an execution graph are prefix-<lb/>matching (and write prefix-matching( , ′ )), if they originate from threads with the same code <lb/>and have matching po-prefixes, i.e., all events po-before them are either not memory accesses or <lb/>reads that pairwise read from the same write. Note that two writes can be prefix-matching, but any <lb/>po-later pair of events cannot be: writes break matching prefixes because they are co-ordered. <lb/>Spore picks as representative graphs the ones where the thread order of prefix-matching events <lb/>does not contradict an extension of co called extended coherence order: eco △ <lb/>= (co ∪ rf ∪ rb) + , <lb/>where rb △ <lb/>= rf -1 ; co is the reads-before order, denoting that a read reads from a write whose value <lb/>is later overwritten. Observe that, due to the definition of prefix-matching events above, any eco <lb/>path between two prefix-matching events will involve co. <lb/>Given this notion of representative graphs, in the w+r+w example above, graph 2 in Example 1 <lb/>is the representative because eco agrees with the thread order (there is an rb; rf path from T2 to <lb/>T3), but graph 3 is not as eco contradicts the thread order. <lb/>2.2.2 Problem #1: The Interaction Between Representative and Maximal Executions. This solution, <lb/>however, does not work that easily due to revisiting ( §2.1). The problem is that SR avoids exploring <lb/>certain graphs (i.e., the non-representative ones), the exploration of which DPOR might require so <lb/>that a given revisit happens. Put differently, maximal extensions can be non-representative graphs. <lb/></body>

        <note place="footnote">2 Recall that all writes are co-after the initializer event. <lb/>Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <note place="headnote">Spore: Combining Symmetry and Partial Order Reduction <lb/></note>

        <page>219:7 <lb/></page>

        <body>Example 4 To illustrate the problem, consider the following variation of w+r+r (again, T2 and T3 <lb/>share their code), and suppose we are interested in the executions where = 1. <lb/>T1: := 1 <lb/>:= <lb/>T2: 2 := <lb/>T3: 3 := <lb/>T4: := 1 <lb/>(w+r+r-rev) <lb/>Similarly to w+r+r, graphs 2 and 3 are symmetric, and graph 2 is the representative one. <lb/>1 <lb/>init <lb/>W ( ,1) <lb/>R ( ) <lb/>R ( ) R ( ) <lb/>W ( , 1) <lb/>2 <lb/>init <lb/>W ( ,1) <lb/>R ( ) <lb/>R ( ) R ( ) <lb/>W ( , 1) <lb/>3 <lb/>init <lb/>W ( ,1) <lb/>R ( ) <lb/>R ( ) R ( ) <lb/>W ( , 1) <lb/>4 <lb/>init <lb/>W ( ,1) <lb/>R ( ) <lb/>R ( ) R ( ) <lb/>W ( , 1) <lb/>We now present a (partial) DPOR exploration of this program, with the objective of showing <lb/>that the combination of DPOR and SR is not guaranteed to be correct. Concretely, we will show <lb/>that execution 1 will not be generated if DPOR explores the program threads in a peculiar order 3 . <lb/>init <lb/>R ( ) <lb/>init <lb/>W ( , 1) <lb/>R ( ) <lb/>R ( ) <lb/>✗ <lb/>init <lb/>W ( , 1) <lb/>R ( ) <lb/>R ( ) R ( ) <lb/>init <lb/>W ( , 1) <lb/>R ( ) <lb/>R ( ) R ( ) <lb/>init <lb/>W ( , 1) <lb/>R ( ) <lb/>R ( ) R ( ) W ( , 1) <lb/>init <lb/>W ( , 1) <lb/>R ( ) <lb/>R ( ) <lb/>. . . <lb/>. . . <lb/>Suppose DPOR first adds the read of T3, and then proceeds with the events of T1. When it adds <lb/>W ( , 1), it can either revisit R ( ) (top exploration tree) or not (bottom exploration tree). Since we <lb/>are interested in generating execution 1 , let us disregard the top exploration tree (where T3 reads <lb/>1) and focus on the bottom one. (The reason we discard the top one is that DPOR does not &quot;undo&quot; <lb/>revisits: since W ( , 1) revisits R ( ) of T3, in all subsequent subexplorations T3 keep reading 1; see <lb/>Prop. 2.2.) <lb/>At the next step, the algorithm will add the read of T2, which can either read 1 (from T1) or 0 <lb/>(the initial value). DPOR, however, will only consider the exploration where the read is reading 0, <lb/>and not the execution where it reads 1, as the latter is not the representative among the symmetric <lb/>ones. (The one where T2 reads 0 and T3 reads 1 is.) <lb/>At the final step, the algorithm will add the W( , 1) event of T4, and will consider to revisit the <lb/>R ( ). With the maximal extension condition of §2.1, however, this revisit is doomed to fail, since <lb/>the read of T2 is not added co-maximally w.r.t. W ( , 1). Hence DPOR will not generate execution 1 . <lb/></body>

        <note place="footnote">3 DPOR should be able to generate all executions of a program irrespective of the order in which it encounters its threads. <lb/>Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <page>219:8 <lb/></page>

        <note place="headnote">Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis <lb/></note>

        <body>As the w+r+r-rev example demonstrated, the problem when combining DPOR and SR is that <lb/>resulting algorithm might deem the graphs on which TruSt&apos;s maximal extension condition enables <lb/>a certain revisit as non-representative (and therefore drop them). <lb/>There are two potential solutions to this problem. <lb/>The first is to modify the maximal extension condition to hold only for representative graphs. <lb/>Unfortunately, this approach does not work because of the atomicity condition of read-modify-<lb/>write (RMW) operations. In our technical appendix [Kokologiannakis et al. 2024b], we show that <lb/>it is impossible to define a maximality condition purely at the level of execution graphs without <lb/>consulting the program. <lb/>The second solution is to keep the maximal extension condition intact, but restrict the exploration <lb/>order so that representative executions always form maximal extensions. To see why restricting <lb/>the exploration order is a promising solution, let us consider again Example 4. The reason why a <lb/>maximal extension was created in a non-representative execution was that T3 was added before <lb/>T2 (i.e., against thread order), and T2 had co-later options available to it (T1 was added after T3 but <lb/>before T2). By fixing the exploration order, we essentially try to &quot;force&quot; co to agree with the thread <lb/>order. <lb/>2.2.3 Problem #2: Fixing the Exploration Order is Inadequate. Given the above, a natural choice is <lb/>to maintain a left-to-right scheduling among threads that share their code. Even though this simple <lb/>modification mitigates the issue in w+r+r-rev, it does not restore correctness in general. <lb/>Example 5 To see why, consider the program below where T2 and T3 share their code, along with <lb/>one of its representative executions. <lb/>T1: := <lb/>T2: 2 := <lb/>:= 1 <lb/>:= 1 <lb/>T3: 3 := <lb/>:= 1 <lb/>:= 1 <lb/>(r+rww+rww) <lb/>42 <lb/>init <lb/>R ( ) <lb/>R ( ) <lb/>W ( , 1) <lb/>W ( , 1) <lb/>R ( ) <lb/>W ( , 1) <lb/>W ( , 1) <lb/>Assuming that we schedule all threads in a left-to-right manner, execution 42 cannot be generated <lb/>by the procedure described so far. The first point where the algorithm has more than one choice to <lb/>consider is the addition of R( ) of T3. The case where R( ) reads from W ( , 1) cannot lead to 42 <lb/>because the restriction of the graph upon the revisit of R ( ) will preserve the rf-edge of the R( ) <lb/>read. Therefore, we are left with the case where R( ) reads from init (graph K below). <lb/>K <lb/>init <lb/>R ( ) R ( ) <lb/>W ( , 1) <lb/>W ( , 1) <lb/>R ( ) <lb/>          <lb/>        <lb/> <lb/>L <lb/>init <lb/>R ( ) <lb/>R ( ) <lb/>W ( , 1) <lb/>W ( , 1) <lb/>R ( ) <lb/>W ( , 1) <lb/>M <lb/>init <lb/>R ( ) <lb/>R ( ) <lb/>W ( , 1) <lb/>W ( , 1) <lb/>R ( ) <lb/>W ( , 1) <lb/>N <lb/>init <lb/>R ( ) <lb/>R ( ) <lb/>R ( ) <lb/>W ( , 1) <lb/>         <lb/> <lb/>        <lb/> <lb/>When the W ( , 1) of T3 is added to K , there are three options: <lb/>L : W( , 1) is added co-after T2&apos;s W( , 1). This execution is explored by DPOR, but cannot lead to <lb/>the graph 42 because when W( , 1) is added in T3, it will be unable to revisit R ( ) because <lb/>the W( , 1) of T2 is not maximally added w.r.t. T3&apos;s W ( , 1): it is co-before T3&apos;s W ( , 1), which is <lb/>in T3&apos;s porf-prefix . <lb/></body>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <note place="headnote">Spore: Combining Symmetry and Partial Order Reduction <lb/></note>

        <page>219:9 <lb/></page>

        <body>M : W( , 1) is co-before T2&apos;s W ( , 1). This execution is dropped because co contradicts thread-order <lb/>of symmetric events. <lb/>N : W( , 1) revisits the R ( ) of T2. This execution is also dropped because it is not a representative <lb/>one (T2 is reading a co-earlier value than T3). <lb/>As the r+rww+rww example above clearly demonstrates, fixing the scheduling policy is insuffi-<lb/>cient to guarantee completeness. Essentially, the issue described in §2.2.2 still persists: execution <lb/>42 could not be produced because a maximal extension was dropped (graph M ) in favor of <lb/>the representative one (graph L ). In turn, in the representative execution L , a co-edge from a <lb/>symmetric thread to the porf-prefix of the revisiting write precluded the revisit. <lb/>This last observation is key in marrying DPOR and SR: since a revisit fails due to an event of a <lb/>symmetric thread being added non-maximally, Spore&apos;s solution is to consider symmetric events <lb/>part of the revisiting write&apos;s prefix. In the case of r+rww+rww, when Spore considers the revisit <lb/>between the W ( , 1) of T3 and the R( ) of T1, the prefix of W( , 1) will include not just the events <lb/>porf-before it, but also the porf-prefix of symmetric events as well (namely, event W ( , 1) of T2). <lb/>As such, graph 42 will be generated from L because all the affected events (namely, T1&apos;s R ( ) <lb/>and T2&apos;s W ( , 1)) are added maximally w.r.t. the new prefix of W ( , 1). <lb/>2.2.4 Problem #3: Handling po ∪ rf ∪ co cycles. Changing the notion of a prefix is instrumental in <lb/>restoring completeness, but comes with a caveat. In DPOR, a write can never revisit events in its <lb/>own prefix. So, by introducing a new notion of a prefix (henceforth sprefix) in Spore, do we lose <lb/>any executions? Is it possible that this novel notion of a prefix precludes some revisit that does not <lb/>create a causal cycle, thereby rendering Spore incomplete? <lb/>The answer depends on the underlying memory model. First, we can show that sprefix cycles <lb/>boil down to po ∪ rf ∪ co cycles. (Our full argument is presented in §3.) Strong models, such as SC, <lb/>TSO [SPARC International Inc. 1994], and SRA [Lahav et al. 2016], forbid (po ∪ rf ∪ co) + cycles, <lb/>and so it is never possible for a read to read from a write in its sprefix. <lb/>In weaker models, such as RC11 [Lahav et al. 2017], however, the answer is yes: it can be the case <lb/>that an event is in its own sprefix but not in its own porf-prefix. Such a scenario is shown below. <lb/>Example 6 Consider the sp-cyc program, where T2 and T3 share their code. <lb/>T1: := 2 T2: 2 := <lb/>if ( 2 = 2) <lb/>:= 1 <lb/>T3: 3 := <lb/>if ( 3 = 2) <lb/>:= 1 <lb/>T4: := <lb/>:= 1 <lb/>(sp-cyc) <lb/>init <lb/>W ( , 2) <lb/>R ( ) <lb/>R ( ) <lb/>W ( , 1) <lb/>R ( ) <lb/>W ( , 1) <lb/>In the execution of Example 6, W( , 1) is in its own sprefix (W ( , 1) is read from the R ( ) of T2, <lb/>which is symmetric to the R ( ) of T3, which is in turn in the prefix of W ( , 1)), but not in its own <lb/>porf-prefix (there is no porf cycle). <lb/>To restore completeness, Spore therefore checks that no consistent execution graph has a <lb/>po ∪ rf ∪ co cycle. This condition typically holds: a po ∪ rf ∪ co cycle implies that there exist <lb/>two writes that are not porf-ordered, and such unordered concurrent writes are rare in realistic <lb/>implementations [Abdulla et al. 2019; Kokologiannakis et al. 2019b]. As we show in §4, Spore is <lb/>directly applicable to realistic libraries of concurrent data structures. <lb/></body>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <page>219:10 <lb/></page>

        <note place="headnote">Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis <lb/></note>

        <body>enqueue( ) △ <lb/>= <lb/>node := malloc(...) <lb/>node.value := <lb/>node.next := NULL <lb/>do <lb/>:= tail <lb/>next := .next <lb/>if ( ≠ tail) continue <lb/>if (next ≠ NULL) <lb/>CAS (tail, , next) <lb/>continue <lb/>while (¬CAS ( .next, next, node)) <lb/>CAS (tail, , node) <lb/>dequeue() △ <lb/>= <lb/>do <lb/>ℎ := head <lb/>:= ℎ.next <lb/>if (ℎ ≠ head) continue <lb/>if ( = NULL) return None <lb/>while (¬CAS (head, ℎ, )) <lb/>:= tail <lb/>if (ℎ = ) <lb/>CAS (tail, , ) <lb/>:= .value <lb/>reclaim(ℎ) <lb/>return <lb/>rdcss_read( 2 ) △ <lb/>= <lb/>:= 2 <lb/>while (is_desc( )) <lb/>complete( ) <lb/>:= 2 <lb/>return <lb/>complete( ) △ <lb/>= <lb/>:= . 2 <lb/>:= ( = . 1 ) ? <lb/>. 2 : . 2 <lb/>CAS ( . 2 , , ) <lb/>rdcss( ) △ <lb/>= <lb/>:= CAS ( . 2 , . 2 , ) <lb/>while (is_desc( )) <lb/>complete( ) <lb/>:= CAS ( . 2 , . 2 , ) <lb/>if ( = . 2 ) complete( ) <lb/>return <lb/>Fig. 2. DGLM queue (le ) and RDCSS (right). Global variables are underlined; function arguments are passed <lb/>by reference; CAS returns whether it succeeded. <lb/>2.3 Spore: Internal Symmetries <lb/>We now switch gears and present how Spore exploits internal symmetries. We first present some <lb/>examples of such symmetries ( §2.3.1), and then discuss Spore&apos;s treatment ( §2.3.2). We end this <lb/>section by discussing how internal and thread-level symmetries interact ( §2.3.3). <lb/>2.3.1 Internal Symmetry Examples. Fig. 2 shows two examples of internal symmetries: the Doherty-<lb/>Groves-Luchangco-Moir (DGLM) queue [Doherty et al. 2004] and Restricted Double-Compare <lb/>Single Swap (RDCSS) [Harris et al. 2002]. <lb/>DGLM queue is a lock-free queue comprising two pointers head and tail. At the end of each <lb/>enqueue operation, each enqueuer advances the tail pointer to point to the last element of the <lb/>queue. If, however, a concurrent enqueuer or dequeuer detects that the tail pointer is lagging behind <lb/>(i.e., tail.next ≠ NULL), it tries to advance tail on behalf of an incomplete enqueue. <lb/>RDCSS is a double CAS operation that takes as an argument a descriptor containing two <lb/>addresses 1 , 2 with their expected values 1 , 2 and a new value 2 . If both addresses contain their <lb/>expected values, then the new value 2 is stored at the second address 2 . To perform the double <lb/>comparison atomically, RDCSS first tries to place its descriptor in the 2 address, and then reads <lb/>1 to determine whether to replace it with the new value 2 or restore the old value 2 . In case <lb/>another thread encounters the descriptor, it tries to complete the ongoing RDCSS call. <lb/>Both algorithms employ the textbook helping pattern [Herlihy 1991; Herlihy and Shavit 2008], <lb/>where some operation A observes an ongoing, incomplete operation B and tries to complete B <lb/>before performing its own. This helping pattern appears ins widely used concurrent libraries, <lb/>including libcds [Khizhinsky n.d.], folly [Facebook n.d.] and ckit [Bahra n.d.], as well as in <lb/>most algorithms described by Herlihy and Shavit [2008]; <lb/>Observe that in both cases, the highlighted main and helping operations are idempotent: one <lb/>of the CASes succeeds and all the others fail without changing the state. Moreover, their result <lb/>is the same irrespective of which operation succeeds, and that the program cannot distinguish <lb/>which operation succeeded. Indeed: (i) both operations execute exactly the same code, (ii) their <lb/>returned value is not checked by the program, and (iii) swapping which of the operations succeeded <lb/>preserves consistency and does not mask any error. As we will shortly see, these three conditions <lb/>enable Spore to exploit internal symmetries and drastically reduce the state space. (In contrast, <lb/></body>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <note place="headnote">Spore: Combining Symmetry and Partial Order Reduction <lb/></note>

        <page>219:11 <lb/></page>

        <body>thread-level symmetries are inapplicable because the main and the helping operations have different <lb/>execution prefixes.) <lb/>2.3.2 Exploiting Idempotent Operations. Spore exploits idempotent operations by only exploring <lb/>executions where the main operation succeeds. To this end, Spore changes the underlying <lb/>memory model and treats helping operations as no-ops, which have no incoming/outgoing rf or <lb/>co edges. To do that, Spore requires assistance from the user: the user annotates helping operations <lb/>in the program (as in Fig. 2), and then Spore automatically treats them as no-ops and reduces the <lb/>state space to be searched. <lb/>Annotations bring us to a major challenge that needs to be resolved: ensuring annotation <lb/>correctness. If users incorrectly annotate a function as helping, it might mask an existing error in <lb/>the user program. As such, Spore uses a dummy event in the place of the function to check whether <lb/>certain (sufficient) conditions hold. If they do not, Spore reports an annotation error to the user. <lb/>Some minimal preconditions that need to hold for a function ℎ to be considered as helping w.r.t. a <lb/>function have already been stated in §2.3.1: (i) ℎ and execute the same code, (ii) the returned <lb/>value of ℎ and <lb/>is not checked by the program, and (iii) replacing an execution where <lb/>fails <lb/>and ℎ succeeds with one where <lb/>succeeds and ℎ is treated as no-op preserves consistency and <lb/>the presence of an error. <lb/>Let us now go over these conditions in more detail. The first two conditions lie at the heart of <lb/>idempotency, and are what allow Spore to treat ℎ as a no-op: no code uses the result of ℎ and <lb/>is thus safe to disregard it. Had ℎ and <lb/>been different (or had their results been used), then <lb/>annotating one of them as helping would mask errors in programs, like in the example below. <lb/>Example 7 Consider the helper-cf program, along with one of its execution graphs. <lb/>T1: := CAS ( , 0, 1) <lb/>assert( = 0) <lb/>T2: CAS ( , 0, 1) <lb/>(helper-cf) <lb/>init <lb/>R ( ) <lb/>Error <lb/>R excl ( ) <lb/>W excl ( , 1) <lb/>and ℎ are functions comprising a single CAS operation, but the result of <lb/>is used (i.e., ℎ is <lb/>incorrectly annotated as helping). If we treat ℎ as a dummy event, the execution above (where the <lb/>failed CAS generates a single read event and the successful one two events annotated with an excl <lb/>flag) will not be explored and the error will be missed. <lb/>Condition (iii) is a bit more intricate. To ensure it, we need to guarantee that in any execution <lb/>where ℎ succeeds, <lb/>has already observed (in a synchronizing manner) the operations of ℎ . If <lb/>reading from writes in <lb/>can imply less synchronization with the rest of the program, then it is <lb/>possible that reading from ℎ results in an error, but reading from <lb/>does not (and thus, treating ℎ <lb/>as dummy can mask errors). We demonstrate this point with the following example. <lb/>Example 8 Consider the helper-sync program under SC. <lb/>T1: := <lb/>if ( = 1) <lb/>assert( = 1) <lb/>T2: := 1 <lb/>CAS( , 0, 1) <lb/>T3: CAS( , 0, 1) <lb/>(helper-sync) <lb/>init <lb/>R ( ) <lb/>R ( ) <lb/>Error <lb/>W ( , 1) <lb/>R ( ) <lb/>R excl ( ) <lb/>W excl ( , 1) <lb/></body>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <page>219:12 <lb/></page>

        <note place="headnote">Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis <lb/></note>

        <body>If the CAS in T2 succeeds and T1&apos;s read of reads from it, then T1 will necessarily read = 1. <lb/>If, however, the CAS in T3 succeeds and T1 reads from it (as shown in the graph above), T1 can <lb/>subsequently read = 0 and violate its assertion (as shown in the graph above). <lb/>To fix this last issue, Spore imposes four more conditions on the user annotations: <lb/>(1) <lb/>and ℎ have no other writes apart from a final CAS <lb/>(2) <lb/>has a preceding source event whose value it uses as the compare operand <lb/>(3) <lb/>is immediately preceded by a write, which is observed in a synchronizing manner before <lb/>ℎ <lb/>(4) all writes to the location of &apos;s CAS are part of read-modify-write (RMW) operations <lb/>These conditions are formalized in §3. As we prove in §3, these conditions are sufficient to detect <lb/>erroneously annotated helping patterns. <lb/>2.3.3 The Interaction Between Internal and Thread-Level Symmetries. Before moving on to our <lb/>formal discussion of Spore, it is worth noting that idempotent operations facilitate SR. Consider <lb/>an example with two symmetric threads performing a helping CAS. Assuming that the threads are <lb/>symmetric up until the CASes, treating the CASes as an RMW operations breaks the symmetry, <lb/>while treating them as dummy events preserves the symmetry. <lb/>3 SPORE: FORMAL DESCRIPTION <lb/>In this section, we describe the theoretical basis of Spore. In particular, we explain: ( § 3.1) the <lb/>representation of executions as execution graphs; ( §3.2) how Spore can be represented as a memory <lb/>model; ( §3.3) Spore&apos;s exploration algorithm; ( §3.4) why Spore is correct, i.e., why it explores exactly <lb/>one graph per the combined equivalence classes of DPOR and SR, and does not mask any errors. <lb/>3.1 Execution Graphs <lb/>An execution graph comprises a set of events (nodes), and a few relations on these events (edges). <lb/>Definition 3.1. An event, e ∈ Event, is either the initialization event init, or a thread event ⟨t, i, l⟩ <lb/>where t ∈ Tid is a thread identifier, i ∈ Idx is a serial number (denoting the index of an event within <lb/>a thread), and l ∈ Lab is a label that takes (at least) one of the following forms: <lb/>• Write label: W k (l, v) ∈ W, where k records the write attributes, l ∈ Loc the location accessed, <lb/>and v ∈ Val the value written. <lb/>• Read label: R k (l, v) ∈ R, where k records the read attributes, l ∈ Loc the location accessed, <lb/>and v ∈ Val the value read. <lb/>• Annotated function label: M m ( , a ) ∈ M, where m ∈ {main, help} is the function attribute, <lb/>∈ Fname is the name of the function been called, and a ∈ Val * is a sequence representing <lb/>the function arguments. <lb/>Read and write attributes include the exclusivity flag excl for RMWs, and the access mode for RC11-<lb/>style models. (Additional kinds of events exist for memory allocations, deallocations, assertion <lb/>violations, etc., but these do not affect the model checking algorithm in any meaningful way.) <lb/>Having defined events, we define execution graphs as follows. <lb/>Definition 3.2. An execution graph ∈ Exec comprises the following components: <lb/>(1) a set of events that includes init and does not contain multiple events with the same <lb/>thread identifier and serial number; <lb/>(2) rf : ∩R → ∩W, called the reads-from function, mapping each read event to a same-location <lb/>write from where it gets its value; <lb/></body>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <note place="headnote">Spore: Combining Symmetry and Partial Order Reduction <lb/></note>

        <page>219:13 <lb/></page>

        <body>(3) co ⊆ l ∈Loc W l × W l (where W l <lb/>△ <lb/>= {init} ∪ {⟨t, i, l⟩ ∈ | l = W _ (l, _)}) called the coherence <lb/>order, a strict partial order that is total on W l for every location l ∈ Loc; and <lb/>(4) ≤, a total order on that represents the order in which events were incrementally added to <lb/>the graph. <lb/>Conventions <lb/>We write .E, .rf, .co and ≤ to project the various components of an execution graph. <lb/>Given two events 1 , 2 ∈ .E, we write 1 &lt; 2 if 1 ≤ 2 and 1 ≠ 2 . In relational algebra <lb/>expressions, we abuse notation and write .rf for the relation {⟨ .rf( ), ⟩ | ∈ .R}. <lb/>We assume that init ∈ W, and omit the ∅ for read/write labels with no attributes. <lb/>The functions tid, idx, loc, mod and arg respectively return the thread identifier, serial <lb/>number, location, access mode and function arguments of an event, when applicable. <lb/>We write .W for .E ∩ W (and similarly for other sets), and use superscript and subscripts <lb/>to restrict label sets (e.g., W l <lb/>△ <lb/>= {init} ∪ { ∈ W | loc( ) = l}). <lb/>Observe that does not have an explicit program order (po) component. We induce po based on <lb/>our representation of events as follows: <lb/>po △ <lb/>= ⟨init, ⟩ <lb/>∈ Event \ {init} ∪ ⟨⟨t 1 , i 1 , l 1 ⟩, ⟨t 2 , i 2 , l 2 ⟩⟩ t 1 = t 2 ∧ i 1 &lt; i 2 <lb/>In our technical appendix [Kokologiannakis et al. 2024b], we define two mappings from programs <lb/>to sets of execution graphs: (1) . , which ignores function annotation labels, and simply generates <lb/>an event with a M m label before the events corresponding to the function body; and (2) . Annot , <lb/>which in the case of functions annotated with help, generates only the M help event and does not <lb/>generate any events for the body of the function call. Both mappings keep the rf and co components <lb/>of graphs completely unconstrained. These components will be constrained by the memory model. <lb/>3.2 Consistency and Error Detection <lb/>A memory model, M, comprises three components: (a) a causal prefix relation, cb M , (b) a consistency <lb/>predicate consistent M ( ) that determines whether an execution graph is consistent, and (c) an <lb/>IsErroneous M ( ) predicate, prescribing whether contains an error (e.g., an invalid memory <lb/>access) according to M. <lb/>The consistency predicate is used to constrain the semantics of a program. The annotation-<lb/>ignoring (resp. annotation-aware) semantics of a program P under a memory model M, denoted <lb/>P M (resp. P Annot <lb/>M <lb/>), is given by the set of execution graphs in P (resp. P Annot ) that are M-<lb/>consistent. <lb/>In Spore, we assume an underlying memory model M with cb M = (po ∪ rf) + , consistent M (•) <lb/>being extensible, prefix-closed, and implying RMW atomicity and cb M -acyclicity [Kokologiannakis <lb/>et al. 2022], and IsErroneous M (•) being prefix-monotone. Models satisfying these requirements <lb/>include SC [Lamport 1979], TSO [SPARC International Inc. 1994], Release-Acquire (RA) [Lahav <lb/>et al. 2016], and RC11 [Lahav et al. 2017]. We then define a new memory model, SYM, with <lb/>cb SYM <lb/>△ <lb/>= (po ∪ rf ∪ symb) + <lb/>consistent SYM ( ) △ <lb/>= consistent M ( ) ∧ irreflexive(symb; eco) <lb/>IsErroneous SYM ( ) △ <lb/>= IsErroneous M ( ) ∨ ¬irreflexive((po ∪ rf ∪ co) + ) <lb/>∨ is incorrectly annotated (see Def. 3.3 below) <lb/>where .symb is the symmetry-before order that orders prefix-matching events according to their <lb/>thread order. Concretely, ⟨ 1 , 2 ⟩ ∈ .symb if the following hold: <lb/></body>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <page>219:14 <lb/></page>

        <note place="headnote">Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis <lb/></note>

        <body>(i) idx( 1 ) = idx( 2 ) and tid( 1 ) &lt; tid( 2 ) <lb/>(ii) 1 and 2 originate from threads running the same code (and spawned consecutively), <lb/>(iii) have no preceding same-thread writes, and <lb/>(iv) for every preceding same-thread read 1 of 1 , the corresponding (i.e., having the same index) <lb/>read 2 in tid( 2 ) has the same rf (i.e., .rf( 1 ) = .rf( 2 )). <lb/>Annotation Correctness. To ensure annotation correctness, Spore first checks that for each ℎ ∈ <lb/>.M help , there exists a (unique) <lb/>∈ .M main with the same arguments, and that these functions do <lb/>not return any results (cf. conditions (i) and (ii) of §2.3.2), and are well-formed:.they comprise a <lb/>(possibly empty) sequence of reads followed by a CAS operation, with a possible data dependency <lb/>from the reads to the CAS (no other dependencies are allowed so that the locations accessed can be <lb/>deduced by the arguments of / ℎ ). <lb/>Assuming both functions has the proper form, Spore has to now ensure that (iii) holds, i.e., that <lb/>their synchronization is the same. Since the definition of synchronization differs among memory <lb/>models, for simplicity, we here provide a definition that works for SC and RA 4 . In what follows, we <lb/>lift loc/exp to return the location/expected-value of the CAS read following an <lb/>∈ .M main . <lb/>Our definition uses the notion of a source write at location loc( ), which is observed before <lb/>(i.e., either it is po-before <lb/>or it is read po-before ), and writes the value exp( ). We also <lb/>require that the immediate po-predecessor of <lb/>is observed before ℎ , which ensures that the ℎ <lb/>has synchronized with everything in &apos;s prefix, and that all writes to loc( ) after are RMWs <lb/>and do not write the same value as . The latter condition ensures that <lb/>and ℎ cannot both <lb/>succeed, and that if ℎ succeeds, then <lb/>observes its update. <lb/>Definition 3.3 (Annotation correctness). An execution is correctly annotated if for all ℎ ∈ .M help , <lb/>there exist (a) a corresponding <lb/>∈ .M main with arg( ) = arg( ℎ ) and (b) a source write ∈ .W <lb/>with loc( ) = loc( ) and val( ) = exp( ) such that: <lb/>• ⟨ , ⟩ ∈ .rf ? ; po <lb/>( is observed before ), <lb/>• ⟨ , ℎ ⟩ ∈ po -1 | imm ; .rf; po <lb/>(the immediate predecessor of <lb/>is observed before ℎ ), <lb/>• for all ∈ rng([ ]; co), ∈ W excl and val( ) ≠ val( ) (all subsequent writes to loc( ) <lb/>are RMWs and write different values). <lb/>3.3 Exploration Algorithm <lb/>Let us now proceed by showing how Spore enumerates all SYM-consistent execution graphs of <lb/>a program P. The algorithm is shown in Algorithm 1, which constructs the consistent graphs <lb/>incrementally by recording the event addition order in the graphs&apos; ≤ component. Spore is optimal <lb/>in the sense that it only explores consistent execution graphs and it never explores two execution <lb/>graphs that differ only in their ≤ components. <lb/>Spore verifies the input program P under a memory model M by calling Explore with the initial <lb/>graph ∅ containing only the initialization event init. <lb/>First, Explore( , ) checks whether the current graph contains an error (Line 2). Note that errors <lb/>are checked against Spore&apos;s memory model: they include not only errors under the underlying <lb/>memory model M, but also user annotation errors. <lb/>In addition, recall that Spore&apos;s errors include the existence of po ∪ rf ∪ co cycles. Such a check is <lb/>necessary to justify why exploring cb SYM -acyclic execution graphs suffices: any (po∪rf∪co)-acyclic <lb/>graph where the symmetry-before order does not contradict the eco order is also cb SYM -acyclic. <lb/></body>

        <note place="footnote">4 In our technical appendix [Kokologiannakis et al. 2024b], we provide the definition for the RC11 memory model. The <lb/>definition for SC/RA is a special case of the RC11 definition. <lb/></note>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <note place="headnote">Spore: Combining Symmetry and Partial Order Reduction <lb/></note>

        <page>219:15 <lb/></page>

        <body>Algorithm 1 Spore: An optimal combination of DPOR and SR <lb/>1: procedure Explore P ( ) <lb/>2: <lb/>if IsErroneous SYM ( ) then exit(&quot;Error&quot;) <lb/>3: <lb/>← AddNextEvent P ( ) <lb/>4: <lb/>if ∈ R then <lb/>5: <lb/>for ∈ .W loc( ) do ExploreIfConsistent P (SetRF( , , )) <lb/>6: <lb/>else if ∈ W then <lb/>7: <lb/>ExploreCOs P ( , ) <lb/>8: <lb/>for ∈ .R loc( ) such that ⟨ , ⟩ ∉ .cb SYM do <lb/>9: <lb/>Deleted ← { ∈ .E | &lt; <lb/>&lt; <lb/>∧ ⟨ , ⟩ ∉ .cb SYM } <lb/>10: <lb/>if ShouldRevisit( , ⟨ , , Deleted⟩) then <lb/>11: <lb/>ExploreCOs P (SetRF( \ Deleted, , ), ) <lb/>12: <lb/>else if ≠ ⊥ then <lb/>13: <lb/>Explore P ( ) <lb/>14: procedure ExploreIfConsistent P ( ) <lb/>15: <lb/>if consistent SYM ( ) then Explore P ( ) <lb/>16: procedure ExploreCOs P ( , ) <lb/>17: <lb/>for <lb/>∈ .W loc( ) do ExploreIfConsistent P (SetCO( , , )) <lb/>If the graph is error-free, Explore extends it by one event from the program by calling <lb/>AddNextEvent (Line 3). If there are no events to add, then a full execution of P has been explored, <lb/>and Explore returns. <lb/>If is a read, then Explore recursively explores all consistent rf options for that read. As <lb/>such, for each same-location write , Explore recursively calls itself (via the helper function <lb/>ExploreIfConsistent) on the graph that results if reads from (Line 5). ExploreIfConsistent <lb/>checks whether is consistent (Line 15), and if so calls Explore recursively. (Recall that consistency <lb/>also requires that the graph does not violate our SR principle.) <lb/>If is a write, Spore proceeds with the non-revisit case and the revisit case, respectively. For <lb/>the non-revisit case, Explore checks for all possible placements of the newly added write in co by <lb/>means of ExploreCOs (Line 7). <lb/>For the revisit case, Spore also checks whether any of the existing reads of can be revisited <lb/>to read from : since was not present when their possible reads-from options were examined, <lb/>Explore explores these additional rf options now. Thus, for each same-location read that does <lb/>not precede , if revisiting will not lead to a duplicate exploration (checked by ShouldRevisit 5 ), <lb/>Explore calls ExploreCOs on the graph that occurs if all the events that were added after are <lb/>deleted, excluding and its predecessors (Line 11). <lb/>Observe, however, that as we motivated earlier in § 2.2.4, Spore only explores cb SYM -acyclic <lb/>execution graphs. As such, Spore never revisits reads that are in cb SYM -before (as opposed to <lb/>cb M -before ), as revisiting such reads would create cb SYM cycles (the cb SYM -prefix of a revisiting <lb/>write is always preserved). <lb/>If has any other type (Line 13), Explore recursively calls itself. <lb/></body>

        <note place="footnote">5 As the definition of ShouldRevisit is unnecessary for this discussion, we omit it; we refer interested readers to our <lb/>technical appendix [Kokologiannakis et al. 2024b]. <lb/>Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <page>219:16 <lb/></page>

        <note place="headnote">Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis <lb/></note>

        <body>Remark 1. Observe that, with the exception of annotation errors, Spore does not take any special <lb/>care for method annotation labels M. Indeed, this is because these are handled implicitly by the <lb/>interpreter: Line 3 adds events according to our annotated semantics P Annot . When the interpreter <lb/>encounters a function annotated with main, it will yield an M main (a ) (which is not treated specially) <lb/>as well as the events of the function, while for a function annotated with help it will only yield an <lb/>M help (a ) event. <lb/>Remark 2. We assume that the AddNextEvent procedure (Line 3), always picks the leftmost thread <lb/>among the ones that are symmetric, i.e., their next events are prefix-matching. This is necessary <lb/>for the algorithm&apos;s correctness, which demands that when an event is added, its cb SYM -prefix <lb/>already be present in the graph. <lb/>3.4 Soundness, Completeness and Optimality <lb/>3.4.1 Soundness of Internal Symmetries. We show that if a program P is erroneous under its <lb/>standard interpretation P (which ignores annotations), then it is also erroneous under the an-<lb/>notated interpretation P Annot (which encodes annotated functions with dummy events). See <lb/>[Kokologiannakis et al. 2024b] for how programs are mapped to execution graph sets. <lb/>Theorem 3.4. Let P be an annotated program and ∈ P M such that IsErroneous M ( ). Then, <lb/>there exists ′ ∈ P Annot <lb/>M <lb/>such that IsErroneous SYM ( ). <lb/>Proof sketch. It suffices to show that there exists a corresponding execution ′ (where every <lb/>ℎ being treated as a (single) dummy event M help (...)) such that (1) IsErroneous M ( ′ ) holds, or <lb/>(2) ′ is incorrectly annotated (see Def. 3.3). The lack of an annotation error is essential in showing <lb/>that changing ′ so that <lb/>succeeds instead of ℎ does not affect &apos;s consistency. <lb/>The conditions of Def. 3.3 essentially enforce that in any execution where ℎ would succeed, <lb/>(a) there is an , running the same code, (b) <lb/>fails (there can only be one write that writes the <lb/>expected value), (c) <lb/>reads from the CAS of ℎ , or from a co-later (due to coherence and the <lb/>presence of the source event), and therefore there is a porf-path from the CAS of ℎ to the CAS <lb/>of <lb/>(all writes to the CAS location are part of an RMW, and thus such a co path is also a porf <lb/>path), (d) <lb/>is preceded by a write that was observed by the thread of ℎ . This guarantees that <lb/>swapping the events of <lb/>with those of ℎ , and replacing the events of ℎ with a no-op, adds no <lb/>synchronization in the execution, and therefore preserves both consistency and the presence of an <lb/>error. <lb/>If any of the previous conditions fails, we show that there exists an execution with ℎ being <lb/>treated as a no-op that is not correctly annotated. <lb/>□ <lb/>3.4.2 Correctness of Spore. To state our desired result, we first need to formally define which are <lb/>the execution graphs that are considered equivalent up to symmetry. Given a program P with <lb/>threads, a valid thread permutation is a bijection {1, ... , } ↦ → {1, ... , } such that threads ( ) <lb/>and share the same code for all 1 ≤ ≤ . We say that two executions 1 and 2 are symmetric, <lb/>denoted 1 ≈ 2 , if there exists a valid thread permutation such that ( 1 ) = 2 , where ( 1 ) <lb/>applies the permutation to all the thread IDs in the events of 1 . <lb/>The following proposition demonstrates that the class of M-consistent execution graphs up to <lb/>symmetry corresponds (one-to-one) to the class of SYM-consistent execution graphs. <lb/>Proposition 3.5. Given a program P and an execution graph ∈ P Annot <lb/>M <lb/>, there is a unique <lb/>execution graph ′ ∈ P Annot <lb/>SYM such that ≈ ′ . <lb/>Proof. To obtain ′ from , sort the threads running the same function by the eco of the <lb/>respective events (lexicographically, in po order). It is easy to see that this ordering is well-defined <lb/></body>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <note place="headnote">Spore: Combining Symmetry and Partial Order Reduction <lb/></note>

        <page>219:17 <lb/></page>

        <body>(there are no cycles), and unique: any possibly eco-unordered threads are in fact equal, and that <lb/>the constructed graph ′ satisfies irreflexive(symb; eco). <lb/>□ <lb/>Correctness of the exploration algorithm follows by adapting the proof of Awamoche [Kokolo-<lb/>giannakis et al. 2023] and is captured by the following proposition. <lb/>Proposition 3.6 (Algorithmic Correctness and Optimality). <lb/>(1) Explore P ( ∅ ) terminates. <lb/>(2) Explore P ( ∅ ) only explores cb SYM -prefixes of executions in P Annot <lb/>SYM . <lb/>(3) Explore P ( ∅ ) explores every execution ∈ P Annot <lb/>SYM such that irreflexive( .cb SYM ). <lb/>(4) Explore P ( ∅ ) never explores the same twice. <lb/>Termination holds because either a revisit step is performed and the part of the graph that cannot <lb/>be changed grows or a non-revisit step is performed and the execution graph grows. Soundness <lb/>holds by construction because consistency is checked before every recursive call. Completeness is <lb/>more elaborate: it holds because all possible rf/co options are considered for each newly added <lb/>event, and moreover previous reads can be revisited in their maximal extension (which always <lb/>exists and is consistent). Optimality holds because there cannot be two steps leading to the same <lb/>graph; in case of revisits, that is precluded by the uniqueness of maximal extensions. <lb/>We next show that if P Annot <lb/>SYM includes a cb SYM -cyclic execution, which the algorithm would <lb/>not explore, then it also includes a cb SYM -acyclic execution with a po ∪ rf ∪ co cycle, which the <lb/>algorithm would explore and report. <lb/>Proposition 3.7 (cb SYM cycle). If there is an execution ∈ P Annot <lb/>SYM with a .cb SYM cycle, then <lb/>there is an execution ′ ∈ P Annot <lb/>SYM such that irreflexive( ′ .cb SYM ) and ′ has a po ∪ rf ∪ co cycle. <lb/>Combining Prop. 3.5, Prop. 3.6(3), and Prop. 3.7, we obtain our completeness result. <lb/>Theorem 3.8 (Completeness). If there exists ∈ P Annot <lb/>SYM such that IsErroneous SYM ( ), then <lb/>Explore P ( ∅ ) will report an error. Otherwise, for each ∈ P Annot <lb/>M <lb/>, Explore P ( ∅ ) will explore an <lb/>execution ′ ∈ P Annot <lb/>SYM such that ≈ ′ . <lb/>Combining Prop. 3.5 and Prop. 3.6(4), we obtain our optimality result. <lb/>Theorem 3.9 (Optimality). For any two executions and ′ explored by Explore P ( ∅ ), <lb/>′ . <lb/>4 EVALUATION <lb/>We implemented Spore as a tool for C/C++ programs on top of the open-source GenMC stateless <lb/>model checker, which implements the TruSt algorithm for DPOR. We reused GenMC&apos;s infrastruc-<lb/>ture for interpreting programs and constructing and maintaining execution graphs, but replaced <lb/>GenMC&apos;s consistency checking and error detection mechanism with the ones described in §3.1. We <lb/>also modified the notion of a prefix used in graph construction to use cb SYM , and made GenMC&apos;s <lb/>scheduler respect cb SYM when encountering symmetric threads. <lb/>4.1 Goals <lb/>We evaluate Spore on a set of real-world implementations with two goals: (1) show that Spore scales <lb/>well enough to verify useful implementations (and determine its scalability limit), and (2) determine <lb/>to what extent its scalability should be attributed to internal vs thread-level symmetries. <lb/>To attain these goals, we run Spore on a set of representative real-world clients and benchmarks. <lb/>The clients evaluate the effectiveness of the SR algorithm, while the benchmarks evaluate the <lb/>effectiveness of Spore&apos;s modeling of internal symmetries. To further study how internal and <lb/></body>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <page>219:18 <lb/></page>

        <note place="headnote">Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis <lb/></note>

        <body>thread-level symmetries contribute to Spore&apos;s performance, we compares Spore against (a) plain <lb/>SMC enhanced with SR (SR), (b) a baseline TruSt implementation (TruSt), (c) Spore without <lb/>thread-level symmetries (DPOR+IS), and (d) Spore without internal symmetries (DPOR+SR). Our <lb/>evaluation is performed under RC11. <lb/>As we show, Spore yields a huge improvement over the state-of-the-art as it can gracefully scale <lb/>to up to 6 threads (often to many more), and both internal and thread-level symmetries are crucial <lb/>for its scalability to more threads. <lb/>Experimental Setup. We conducted all experiments on a Dell PowerEdge R6525 system running a <lb/>custom Debian-based distribution with 2 AMD EPYC 7702 CPUs (256 cores @ 2.80 GHz) and 2TB <lb/>of RAM. We set the timeout limit to 30 minutes (denoted by ). All times are in seconds. <lb/>We also ran some of our benchmarks against the DPOR implementation of Nidhugg [Abdulla <lb/>et al. 2014], which obtained similar and/or worse results than TruSt (see [Kokologiannakis et al. <lb/>2024b]). <lb/>4.2 Benchmarks <lb/>To evaluate the effectiveness of thread-level symmetries, we used three different clients: <lb/>• Multiset( ): 2 (resp. 2 ) threads insert (resp. remove) elements at a data structure; the <lb/>client checks whether each removed element was previously inserted. <lb/>• LIFO/FIFO( ): two threads check for the LIFO/FIFO property, while 2 (resp. 2 ) threads <lb/>create &quot;noise&quot; in the queue to increase traffic, by inserting (resp. removing) elements. <lb/>• Empty( ): threads insert an element and subsequently remove an element; the client <lb/>ensures each removal succeeds. <lb/>As it can be seen, the clients become progressively more challenging in the sense that the number <lb/>of multiple operations per thread increases, which hinders symmetry reduction. <lb/>To demonstrate that Spore is applicable to non-data-structure benchmarks as well, we used two <lb/>other clients (Fig. 4): <lb/>• Mutex( ): threads perform a lock followed by an unlock operation. <lb/>• RDCSS( ): threads perform an RDCSS call followed by an RDCS/read call, and 2 threads <lb/>perform a single RDCSS call. <lb/>To evaluate the effectiveness of internal symmetries, we used some representative benchmarks <lb/>both with and without idempotent operations: <lb/>• msqueue [Michael and Scott 1998], dglmqueue [Doherty et al. 2004], folqueue [Fober et al. <lb/>2001] and rdcss [Harris et al. 2002] all employ idempotent operations. <lb/>• treiber [Treiber 1986], ttaslock [Herlihy and Shavit 2008, §7.2] and twalock [Dice and <lb/>Kogan 2019] do not employ idempotent operations. <lb/>These benchmarks exercise different aspects of internal symmetries so that the individual effects of <lb/>each symmetry type are more visible. <lb/>We also note that we have identified idempotent operations in various widely used concurrency <lb/>libraries (e.g., libcds [Khizhinsky n.d.], folly [Facebook n.d.], ckit [Bahra n.d.]). Even though <lb/>Spore&apos;s support for C++ precluded us from using libcds and folly as benchmarks, we did manage <lb/>to run certain benchmarks from ckit, with similar performance gains. <lb/>4.3 Results <lb/>Our results are summarized in Fig. 3 6 . First, as explained in §1, SR alone is inadequate for scalability, <lb/>and using a combination of DPOR and SR is crucial: with the exception of a few benchmarks, SR <lb/></body>

        <note place="footnote">6 Detailed tables can be found in [Kokologiannakis et al. 2024b]. <lb/>Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <note place="headnote">Spore: Combining Symmetry and Partial Order Reduction <lb/></note>

        <page>219:19 <lb/></page>

        <body>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>SR <lb/>DPOR <lb/>DPOR+SR DPOR+IS <lb/>SPORE <lb/>msqueue -Multiset <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>DPOR <lb/>DPOR+SR <lb/>DPOR+IS <lb/>SPORE <lb/>msqueue -FIFO <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>SR <lb/>DPOR <lb/>DPOR+SR <lb/>DPOR+IS <lb/>SPORE <lb/>msqueue -Empty <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>SR <lb/>DPOR <lb/>DPOR+SR <lb/>DPOR+IS <lb/>SPORE <lb/>dglmqueue -Multiset <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>DPOR <lb/>DPOR+SR <lb/>DPOR+IS <lb/>SPORE <lb/>dglmqueue -FIFO <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>SR <lb/>DPOR <lb/>DPOR+SR <lb/>DPOR+IS <lb/>SPORE <lb/>dglmqueue -Empty <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>SR <lb/>DPOR <lb/>DPOR+SR DPOR+IS <lb/>SPORE <lb/>folqueue -Multiset <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>DPOR <lb/>DPOR+SR <lb/>DPOR+IS <lb/>SPORE <lb/>folqueue -FIFO <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>DPOR <lb/>DPOR+SR <lb/>DPOR+IS <lb/>SPORE <lb/>folqueue -Empty <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>SR <lb/>DPOR <lb/>DPOR+SR <lb/>DPOR+IS <lb/>SPORE <lb/>treiber -Multiset <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>DPOR <lb/>DPOR+SR <lb/>DPOR+IS <lb/>SPORE <lb/>treiber -LIFO <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>SR <lb/>DPOR <lb/>DPOR+SR <lb/>DPOR+IS <lb/>SPORE <lb/>treiber -Empty <lb/>Fig. 3. Data structure benchmarks: Number of executions expored (Y-axis) per input parameter (X-axis) <lb/>consistently times out (and we therefore dismiss it for the rest of this discussion). Second, both <lb/>thread-level and internal symmetries are crucial for scaling to more threads: exclusively either kind <lb/>of symmetry typically leads to timeouts for some number of threads. <lb/>Let us now examine the benchmarks in more detail, starting with the multiset client (left column). <lb/>The main takeaway from this client is immediately evident: while TruSt typically scales up to 6 <lb/>threads before timing out, Spore scales gracefully to 8 threads (and more). Looking more closely, <lb/>however, there are a few other interesting aspects as well. <lb/>Starting with msqueue and dglmqueue 7 , TruSt times out for 6 threads and above, while Spore <lb/>can scale up to many more. The reason for that is simple: the CAS instruction present in the queue&apos;s <lb/></body>

        <note place="footnote">7 These benchmarks only differ in their dequeue method, which is why the results are very similar. <lb/>Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <page>219:20 <lb/></page>

        <note place="headnote">Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis <lb/></note>

        <body>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>DPOR <lb/>DPOR+SR <lb/>DPOR+IS <lb/>SPORE <lb/>ttaslock -Mutex <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>DPOR <lb/>DPOR+SR <lb/>DPOR+IS <lb/>SPORE <lb/>twalock -Mutex <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>7 <lb/>8 <lb/>10 0 <lb/>10 1 <lb/>10 2 <lb/>10 3 <lb/>10 4 <lb/>10 5 <lb/>10 6 <lb/>10 7 <lb/>DPOR <lb/>DPOR+SR <lb/>DPOR+IS <lb/>SPORE <lb/>rdcss -RDCSS <lb/>Fig. 4. Non-data-structure benchmarks: Number of executions expored (Y-axis) per input parameter (X-axis) <lb/>idempotent operation breaks symmetry, thereby leading to state-space explosion. Spore, on the <lb/>other hand, runs lickety-split: it explores a single execution when the client is fully symmetric (up <lb/>to 4 threads), and a small number of executions otherwise (modeling the different ways insertions <lb/>interfere with deletions). As the number of dequeuers increases, Spore explores more executions,as <lb/>there are more ways for deletions to interfere with insertions. <lb/>Moving on to folqueue and treiber, we can make observations similar to the ones for the <lb/>previous benchmarks, albeit a bit toned down. In the case of folqueue, thread-level symmetries <lb/>have a limited effect, as each thread uses a distinct (global) location to dispose pointers, which breaks <lb/>symmetry among threads early: Spore performs similarly to DPOR+IS, while TruSt performs <lb/>similarly to DPOR+SR. Analogously, in treiber, internal symmetries have no effect, as the code <lb/>has no idempotent operations: Spore performs just as well as DPOR+SR, while DPOR+IS performs <lb/>just as well as TruSt. <lb/>Generally, we observe that DPOR+IS performs better than DPOR+SR in the multiset client when <lb/>both thread-level and internal symmetries are present, implying that internal symmetries carry more <lb/>weight when it comes to scaling to more threads. This should not come as a surprise. Idempotent <lb/>operations might be performed more than once per thread, while thread-level symmetry will break <lb/>after the first non-symmetric operation. As such, since the number of idempotent operations is <lb/>greater than the number of threads, internal symmetries offer a greater reduction. <lb/>Next, we move on to the other two clients. In a similar fashion, Spore scales much better than <lb/>TruSt (which only manages to terminate within the time limit for two or three configurations), <lb/>although it does not manage to finish within the time limit for all configurations, since these <lb/>clients are not completely symmetric (like the multiset one). As expected, Spore performs better in <lb/>the LIFO/FIFO (where it can better leverage the symmetry in the client), and DPOR+IS performs <lb/>better than DPOR+SR whenever there are internal symmetries, for the same reasons as in the <lb/>multiset client. (Note that Spore performs similarly to DPOR+IS for the first configuration of each <lb/>benchmark in the LIFO/FIFO client, as SR requires at least two symmetric threads to have any <lb/>effect.) <lb/>Finally, in Fig. 4 we compare all tools on some non-data-structure benchmarks. The two locking <lb/>benchmarks do not employ idempotent operations, and thus Spore coincides with DPOR+SR, which <lb/>has an exponentially smaller state-space than plain DPOR. In contrast, rdcss makes heavy use of <lb/>idempotent operations, and so Spore manages to scale way better than plain DPOR. <lb/>5 RELATED WORK <lb/>As far as symmetry reduction is concerned, it has mostly been explored in the context of stateful <lb/>model checking [Clarke et al. 1996; Emerson and Wahl 2005; Wahl and Donaldson 2010]. In that <lb/>setting, the main challenge is to identify when two threads are symmetric, that is computationally <lb/></body>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <note place="headnote">Spore: Combining Symmetry and Partial Order Reduction <lb/></note>

        <page>219:21 <lb/></page>

        <body>as hard as the graph isomorphism problem. By contrast, Spore is able to detect when two threads <lb/>are symmetric on-the-fly, though in principle the reductions it achieves are not as good as the ones <lb/>in stateful model checking. <lb/>As far as internal symmetries are concerned, even though a lot of effort has been devoted into <lb/>making DPOR algorithms more efficient and scalable during the past few years (e.g., [Abdulla et al. <lb/>2015, 2017, 2018; Aronis et al. 2018; Chalupa et al. 2017; Chatterjee et al. 2019; Kokologiannakis <lb/>et al. 2017, 2022, 2019b; Nguyen et al. 2018; Norris and Demsky 2013; Rodríguez et al. 2015]), most <lb/>works focus on improving the core of DPOR and do not take into consideration the programs under <lb/>test. SAVer [Kokologiannakis et al. 2021] and LAPOR [Kokologiannakis et al. 2019a] extend DPOR <lb/>for programs that have spinloops and locks, respectively, while constrained-DPOR [Albert et al. <lb/>2018] takes programmer annotations into account in order to consider certain atomic operations <lb/>non-conflicting. <lb/>In a different context, there has been a large body of work on static verification of concurrent <lb/>programs, with techniques such as bounded model checking (BMC) or abstraction-based techniques <lb/>(e.g., [Clarke et al. 2004; Elmas et al. 2009; Flanagan et al. 2005; Gavrilenko et al. 2019]). We expect <lb/>that-at least for SAT/SMT-based techniques-both thread-level and internal symmetries could be <lb/>exploited in a similar fashion to reduce the size of the resulting SAT formula and speed up the <lb/>verification. <lb/>6 CONCLUSION <lb/>We presented Spore, a novel model checking algorithm that combines DPOR with symmetry reduc-<lb/>tion, and also exploits internal symmetries of C/C++ concurrent data structures. Our experiments <lb/>confirm that Spore outperforms the state-of-the-art by a wide margin. <lb/>There are several ways this work could be extended. First, we would like to see whether Spore <lb/>can handle other classes of programs in related domains, namely distributed algorithms and/or <lb/>persistent programs, where similar symmetries appear. It remains to be seem whether those <lb/>patterns exhibit symmetries that can be exploited in a similar fashion to enhance the applicability <lb/>of automated verification techniques in those domains. Second, it would also be interesting whether <lb/>Spore can be applied to models like ARMv8 [Flur et al. 2016] and POWER [Alglave et al. 2014] <lb/>that do allow TruSt&apos;s po ∪ rf cycles in consistent executions (which Spore does not currently <lb/>produce). Finally, Spore could also be combined with testing techniques, so that only representative <lb/>executions are produced when obtaining traces of a concurrent program. <lb/></body>

        <div type="acknowledgement">ACKNOWLEDGMENTS <lb/>We thank the anonymous reviewers for their valuable feedback. This work was supported by a <lb/>European Research Council (ERC) Consolidator Grant for the project &quot;PERSIST&quot; under the European <lb/>Union&apos;s Horizon 2020 research and innovation programme (grant agreement No. 101003349). <lb/></div>

        <div type="availability">DATA-AVAILABILITY STATEMENT <lb/>The benchmarks and tools used to produce the results of this paper can be found at [Kokologiannakis <lb/>et al. 2024a]. Spore is available at [Kokologiannakis n.d.]. <lb/></div>

        <listBibl>REFERENCES <lb/>Parosh Aziz Abdulla, Stavros Aronis, Mohamed Faouzi Atig, Bengt Jonsson, Carl Leonardsson, and Konstantinos Sagonas. <lb/>2015. &quot;Stateless model checking for TSO and PSO.&quot; In: TACAS 2015 (LNCS). Vol. 9035. Springer, Berlin, Heidelberg, <lb/>353-367. https://doi.org/10.1007/978-3-662-46681-0_28. <lb/>Parosh Aziz Abdulla, Stavros Aronis, Bengt Jonsson, and Konstantinos Sagonas. 2014. &quot;Optimal dynamic partial order <lb/>reduction. &quot; In: POPL 2014. ACM, New York, NY, USA, 373-384. https://doi.org/10.1145/2535838.2535845. <lb/></listBibl>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <page>219:22 <lb/></page>

        <note place="headnote">Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis <lb/></note>

        <listBibl>Parosh Aziz Abdulla, Stavros Aronis, Bengt Jonsson, and Konstantinos Sagonas. Sept. 2017. &quot;Source sets: A foundation for <lb/>optimal dynamic partial order reduction. &quot; J. ACM, 64, 4, (Sept. 2017), 25:1-25:49. https://doi.org/10.1145/3073408. <lb/>Parosh Aziz Abdulla, Mohamed Faouzi Atig, Bengt Jonsson, Magnus Lång, Tuan Phong Ngo, and Konstantinos Sagonas. <lb/>Oct. 10, 2019. &quot;Optimal stateless model checking for reads-from equivalence under sequential consistency. &quot; Proc. ACM <lb/>Program. Lang., 3, (Oct. 10, 2019), 150:1-150:29, OOPSLA, (Oct. 10, 2019). https://doi.org/10.1145/3360576. <lb/>Parosh Aziz Abdulla, Mohamed Faouzi Atig, Bengt Jonsson, and Tuan Phong Ngo. Oct. 2018. &quot;Optimal stateless model <lb/>checking under the release-acquire semantics. &quot; Proc. ACM Program. Lang., 2, OOPSLA, (Oct. 2018), 135:1-135:29. https://d <lb/>oi.org/10.1145/3276505. <lb/>Elvira Albert, Miguel Gómez-Zamalloa, Miguel Isabel, and Albert Rubio. 2018. &quot;Constrained dynamic partial order reduction. &quot; <lb/>In: CAV 2018. Ed. by Hana Chockler and Georg Weissenbacher. Springer International Publishing, Cham, 392-410. isbn: <lb/>978-3-319-96142-2. https://doi.org/10.1007/978-3-319-96142-2_24. <lb/>Jade Alglave, Luc Maranget, and Michael Tautschnig. July 2014. &quot;Herding cats: Modelling, simulation, testing, and data <lb/>mining for weak memory. &quot; ACM Trans. Program. Lang. Syst., 36, 2, (July 2014), 7:1-7:74. https://doi.org/10.1145/2627752. <lb/>Stavros Aronis, Bengt Jonsson, Magnus Lång, and Konstantinos Sagonas. 2018. &quot;Optimal dynamic partial order reduction <lb/>with observers. &quot; In: TACAS 2018 (LNCS). Vol. 10806. Springer, 229-248. https://doi.org/10.1007/978-3-319-89963-3_14. <lb/>Samy Al Bahra. N.d. Concurrency Kit. (). https://github.com/concurrencykit/ck. <lb/>Marek Chalupa, Krishnendu Chatterjee, Andreas Pavlogiannis, Nishant Sinha, and Kapil Vaidya. Dec. 2017. &quot;Data-centric <lb/>dynamic partial order reduction. &quot; Proc. ACM Program. Lang., 2, POPL, (Dec. 2017), 31:1-31:30. https://doi.org/10.1145/315 <lb/>8119. <lb/>Krishnendu Chatterjee, Andreas Pavlogiannis, and Viktor Toman. Oct. 2019. &quot;Value-Centric Dynamic Partial Order Reduction. &quot; <lb/>Proc. ACM Program. Lang., 3, OOPSLA, (Oct. 2019). https://doi.org/10.1145/3360550. <lb/>Edmund M. Clarke, Somesh Jha, Reinhard Enders, and Thomas Filkorn. 1996. &quot;Exploiting symmetry in temporal logic model <lb/>checking. &quot; Form. Meth. Syst. Des., 9, 1/2, 77-104. https://doi.org/10.1007/BF00625969. <lb/>Edmund M. Clarke, Daniel Kroening, and Flavio Lerda. 2004. &quot;A tool for checking ANSI-C programs. &quot; In: TACAS 2004 (LNCS). <lb/>Vol. 2988. Springer, Berlin, Heidelberg, 168-176. https://doi.org/10.1007/978-3-540-24730-2_15. <lb/>Dave Dice and Alex Kogan. 2019. &quot;TWA -Ticket Locks Augmented with a Waiting Array. &quot; In: Euro-Par 2019. Springer-Verlag, <lb/>Berlin, Heidelberg, 334-345. isbn: 978-3-030-29399-4. https://doi.org/10.1007/978-3-030-29400-7_24. <lb/>Simon Doherty, Lindsay Groves, Victor Luchangco, and Mark Moir. 2004. &quot;Formal Verification of a Practical Lock-Free <lb/>Queue Algorithm. &quot; In: FORTE 2004 (LNCS). Ed. by David de Frutos-Escrig and Manuel Núñez. Vol. 3235. Springer, 97-114. <lb/>https://doi.org/10.1007/978-3-540-30232-2\_7. <lb/>Tayfun Elmas, Shaz Qadeer, and Serdar Tasiran. 2009. &quot;A calculus of atomic actions. &quot; In: POPL 2009. Ed. by Zhong Shao and <lb/>Benjamin C. Pierce. ACM, 2-15. https://doi.org/10.1145/1480881.1480885. <lb/>E. Allen Emerson and Thomas Wahl. 2005. &quot;Dynamic Symmetry Reduction.&quot; In: TACAS 2005 (LNCS). Ed. by Nicolas <lb/>Halbwachs and Lenore D. Zuck. Vol. 3440. Springer, 382-396. https://doi.org/10.1007/978-3-540-31980-1_25. <lb/>Facebook. N.d. Folly: Facebook Open-source Library. (). https://github.com/facebook/folly. <lb/>Cormac Flanagan, Stephen N. Freund, and Shaz Qadeer. 2005. &quot;Exploiting Purity for Atomicity. &quot; IEEE Trans. Software Eng., <lb/>31, 4, 275-291. https://doi.org/10.1109/TSE.2005.47. <lb/>Cormac Flanagan and Patrice Godefroid. 2005. &quot;Dynamic partial-order reduction for model checking software.&quot; In: POPL <lb/>2005. ACM, New York, NY, USA, 110-121. https://doi.org/10.1145/1040305.1040315. <lb/>Shaked Flur, Kathryn E. Gray, Christopher Pulte, Susmit Sarkar, Ali Sezgin, Luc Maranget, Will Deacon, and Peter Sewell. <lb/>2016. &quot;Modelling the ARMv8 architecture, operationally: Concurrency and ISA. &quot; In: POPL 2016. ACM, St. Petersburg, FL, <lb/>USA, 608-621. isbn: 978-1-4503-3549-2. https://doi.org/10.1145/2837614.2837615. <lb/>Dominique Fober, Yann Orlarey, and Stéphane Letz. 2001. Optimised Lock-Free FIFO Queue. Technical Report. GRAME. <lb/>https://hal.archives-ouvertes.fr/hal-02158792. <lb/>Natalia Gavrilenko, Hernán Ponce-de-León, Florian Furbach, Keijo Heljanko, and Roland Meyer. 2019. &quot;BMC for weak <lb/>memory models: Relation analysis for compact SMT encodings. &quot; In: CAV 2019. Ed. by Isil Dillig and Serdar Tasiran. Springer <lb/>International Publishing, Cham, 355-365. isbn: 978-3-030-25540-4. https://doi.org/10.1007/978-3-030-25540-4_19. <lb/>Michalis Kokologiannakis. N.d. GenMC: Generic model checking for C programs. (). https://github.com/MPI-SWS/genmc. <lb/>Patrice Godefroid. 1997. &quot;Model checking for programming languages using VeriSoft. &quot; In: POPL 1997. ACM, Paris, France, <lb/>174-186. https://doi.org/10.1145/263699.263717. <lb/>Timothy L. Harris, Keir Fraser, and Ian A. Pratt. 2002. &quot;A Practical Multi-word Compare-and-Swap Operation.&quot; In: DISC <lb/>2002 (LNCS). Ed. by Dahlia Malkhi. Vol. 2508. Springer, 265-279. https://doi.org/10.1007/3-540-36108-1\_18. <lb/>Maurice Herlihy. 1991. &quot;Wait-Free Synchronization. &quot; ACM Trans. Program. Lang. Syst., 13, 1, 124-149. <lb/>Maurice Herlihy and Nir Shavit. 2008. The art of multiprocessor programming. <lb/>Max Khizhinsky. N.d. CDS C++ library. (). https://github.com/khizmax/libcds. <lb/></listBibl>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. <lb/></note>

        <note place="headnote">Spore: Combining Symmetry and Partial Order Reduction <lb/></note>

        <page>219:23 <lb/></page>

        <listBibl>Michalis Kokologiannakis, Ori Lahav, Konstantinos Sagonas, and Viktor Vafeiadis. Dec. 2017. &quot;Effective stateless model <lb/>checking for C/C++ concurrency. &quot; Proc. ACM Program. Lang., 2, POPL, (Dec. 2017), 17:1-17:32. https://doi.org/10.1145/31 <lb/>58105. <lb/>Michalis Kokologiannakis, Iason Marmanis, Vladimir Gladstein, and Viktor Vafeiadis. Jan. 2022. &quot;Truly stateless, optimal <lb/>dynamic partial order reduction. &quot; Proc. ACM Program. Lang., 6, POPL, (Jan. 2022). https://doi.org/10.1145/3498711. <lb/>Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis. June 2024a. SPORE: Combining Symmetry and Partial <lb/>Order Reduction (Replication Package). (June 2024). https://doi.org/10.5281/zenodo.10798179. <lb/>Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis. June 2024b. &quot;Spore: Combining Symmetry and Partial <lb/>Order Reduction (supplementary material), &quot; (June 2024). https://plv.mpi-sws.org/genmc. <lb/>Michalis Kokologiannakis, Iason Marmanis, and Viktor Vafeiadis. 2023. &quot;Unblocking Dynamic Partial Order Reduction. &quot; In: <lb/>CAV 2023. Vol. 13964. Springer, 230-250. https://doi.org/10.1007/978-3-031-37706-8\_12. <lb/>Michalis Kokologiannakis, Azalea Raad, and Viktor Vafeiadis. Oct. 2019a. &quot;Effective lock handling in stateless model <lb/>checking. &quot; Proc. ACM Program. Lang., 3, OOPSLA, (Oct. 2019). https://doi.org/10.1145/3360599. <lb/>Michalis Kokologiannakis, Azalea Raad, and Viktor Vafeiadis. 2019b. &quot;Model checking for weakly consistent libraries. &quot; In: <lb/>PLDI 2019. ACM, New York, NY, USA. https://doi.org/10.1145/3314221.3314609. <lb/>Michalis Kokologiannakis, Xiaowei Ren, and Viktor Vafeiadis. 2021. &quot;Dynamic Partial Order Reductions for Spinloops. &quot; In: <lb/>FMCAD 2021. IEEE, 163-172. https://doi.org/10.34727/2021/isbn.978-3-85448-046-4\_25. <lb/>Ori Lahav, Nick Giannarakis, and Viktor Vafeiadis. 2016. &quot;Taming Release-acquire Consistency.&quot; In: POPL 2016. ACM, St. <lb/>Petersburg, FL, USA, 649-662. isbn: 978-1-4503-3549-2. https://doi.org/10.1145/2837614.2837643. <lb/>Ori Lahav, Viktor Vafeiadis, Jeehoon Kang, Chung-Kil Hur, and Derek Dreyer. 2017. &quot;Repairing sequential consistency in <lb/>C/C++11. &quot; In: PLDI 2017. ACM, Barcelona, Spain, 618-632. isbn: 978-1-4503-4988-8. https://doi.org/10.1145/3062341.3062 <lb/>352. <lb/>Leslie Lamport. Sept. 1979. &quot;How to Make a Multiprocessor Computer that Correctly Executes Multiprocess Programs.&quot; <lb/>IEEE Trans. Computers, 28, 9, (Sept. 1979), 690-691. https://doi.org/10.1109/TC.1979.1675439. <lb/>Maged M. Michael and Michael L. Scott. 1998. &quot;Nonblocking algorithms and preemption-safe locking on multiprogrammed <lb/>shared memory multiprocessors. &quot; J. Parallel Distrib. Comput., 51, 1, 1-26. <lb/>Huyen T. T. Nguyen, César Rodríguez, Marcelo Sousa, Camille Coti, and Laure Petrucci. 2018. &quot;Quasi-optimal partial <lb/>order reduction. &quot; In: CAV 2018 (LNCS). Ed. by Hana Chockler and Georg Weissenbacher. Vol. 10982. Springer, 354-371. <lb/>https://doi.org/10.1007/978-3-319-96142-2_22. <lb/>Brian Norris and Brian Demsky. 2013. &quot;CDSChecker: Checking concurrent data structures written with C/C++ atomics. &quot; In: <lb/>OOPSLA 2013. ACM, 131-150. https://doi.org/10.1145/2509136.2509514. <lb/>César Rodríguez, Marcelo Sousa, Subodh Sharma, and Daniel Kroening. 2015. &quot;Unfolding-based Partial Order Reduction. &quot; In: <lb/>CONCUR 2015 (LIPIcs). Vol. 42. Schloss Dagstuhl -Leibniz-Zentrum fuer Informatik, 456-469. https://doi.org/10.4230 <lb/>/LIPIcs.CONCUR.2015.456. <lb/>SPARC International Inc.. 1994. The SPARC architecture manual (version 9). Prentice-Hall. <lb/>R. Kent Treiber. 1986. Systems Programming: Coping with Parallelism. Tech. rep. Technical Report RJ5118, IBM. https://domi <lb/>noweb.draco.res.ibm.com/58319a2ed2b1078985257003004617ef.html. <lb/>Thomas Wahl and Alastair Donaldson. 2010. &quot;Replication and Abstraction: Symmetry in Automated Formal Verification. &quot; 2, <lb/>2, 799-847. https://doi.org/10.3390/sym2020799. <lb/></listBibl>

        <front>Received 2023-11-16; accepted 2024-03-31 <lb/></front>

        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 219. Publication date: June 2024. </note>


	</text>

</TEI>