<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>
			
			<front>1 <lb/>TITLE <lb/>FULL (200c max): The computation of strategic learning in repeated social competitive interactions: <lb/>Learning sophistication, reward attractor points and strategic asymmetry <lb/>SHORT (70c max): Sophisticated learning in social competitive interactions <lb/>AUTHORS <lb/>Thibaud Griessinger, Giorgio Coricelli*, Mehdi Khamassi* <lb/>(* equally contributing authors) <lb/>AUTHORS INFORMATIONS <lb/>AFFILIATIONS: <lb/>TG: Laboratoire de neurosciences cognitives, Département d&apos;études cognitives, École normale <lb/>supérieure, INSERM, PSL Research University, 75005 Paris, France <lb/>GC: Department of Economics, University of Southern California, Los Angeles, USA. <lb/>MK: Institute of Intelligent Systems and Robotics, Sorbonne Université, CNRS, Paris, France <lb/>ROLES: <lb/>TG: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Software, <lb/>Visualization, Writing -original draft <lb/>GC: Conceptualization, Methodology, Funding acquisition, Project administration, Resources, <lb/>Supervision, Validation, Writing -review &amp; editing <lb/>MK: Funding acquisition, Formal analysis, Methodology, Resources, Software, Supervision, Validation, <lb/>Writing -review &amp; editing <lb/>EMAIL ADDRESSES: <lb/>TG: thibaud.griessinger@gmail.com <lb/></front>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>2 <lb/></page>

			<front>GC: coricell@usc.edu <lb/>MK: mehdi.khamassi@upmc.fr (corresponding author) <lb/>ABSTRACT (300w max) <lb/>Social interactions rely on our ability to learn and adjust our behavior to the behavior of others. Strategic <lb/>games provide a useful framework to study the cognitive processes involved in the formation of beliefs <lb/>about the others&apos; intentions and behavior, what we may call strategic theory of mind. Through the years, <lb/>the growing field of behavioral economics provided evidence of a systematic departure of human&apos;s <lb/>behavior from the optimal game theoretical prescriptions. One hypothesis posits that human&apos;s ability to <lb/>accurately process the other&apos;s behavior is somehow bounded. The question of what constraints the <lb/>formation of sufficiently high order beliefs remained unanswered. We hypothesize that maximizing final <lb/>earnings in a competitive repeated game setting, requires moving away from reward-based learning to <lb/>engage in sophisticated belief-based learning. Overcoming the attraction of the immediate rewards by <lb/>displaying a computationally costly type of learning might not be a strategy shared among all individuals. <lb/>In this work, we manipulated the reward structure of the interaction so that the action displayed by the two <lb/>types of learning becomes (respectively not) discriminable, giving a relative strategic (resp. dis) <lb/>advantage to the participant given the role endorsed during the interaction. We employed a computational <lb/>modeling approach to characterize the individual level of belief learning sophistication in three types of <lb/>interactions (agent-agent, human-human and human-agent). The analysis of the participants&apos; choice <lb/>behavior revealed that the strategic learning level drives the formation of more accurate beliefs and <lb/>eventually leads to convergence towards game optimality (equilibrium). More specifically we show that <lb/>the game structure interacts with the level of engagement in strategically sophisticated learning to explain <lb/>the outcome of the interaction. This study provides the first evidence of a key implication of strategic <lb/>learning heterogeneity in equilibrium departure and provides insight to explain the emergence of a leader-<lb/>follower dynamics of choice. <lb/>AUTHOR SUMMARY (200w max) <lb/></front>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>3 <lb/></page>

			<front>Dynamic interaction between individuals appears to be a cornerstone for understanding how humans <lb/>grasp other minds. During a strategic interaction, in which the outcome of one&apos;s action depends directly <lb/>on what the other individual decides, it appears crucial to anticipate the other&apos;s actions in order to adjust <lb/>our own behavior. In theory, choosing optimally in a strategic setting requires that both players hold <lb/>correct beliefs over their opponent&apos;s behavior and best-respond to it. However, in practice humans <lb/>systematically deviate from the game-theoretical (equilibrium), suggesting that our ability to form accurate <lb/>beliefs is cognitively and/or contextually constrained. Previous studies using computational modelling <lb/>suggested that during a repeated game interaction humans vary in the sophistication of their learning <lb/>process leading to the formation of beliefs over their opponent&apos;s behavior of different orders of complexity <lb/>(level of recursive thinking such as &quot;I think that you think that ...&quot;). In this work we show that the individual <lb/>engagement in sophisticated (belief-based) learning drives the convergence towards equilibrium and <lb/>ultimately performance. Moreover, we show that this effect is influenced by both the game environment <lb/>and the cognitive capacity of the participants, shaping the very dynamic of the social interaction. <lb/>DATA AVAILABILITY: <lb/>The authors confirm that upon publication the raw behavioral data and Matlab code for reconstruction of <lb/>all figures, computational models and statistical analyses will be made available for download at the <lb/>following URL: https://zenodo.org/ <lb/></front>

			<body>I-INTRODUCTION <lb/>Inferring someone&apos;s intention is key to adapt to the behavior of others and maximize the outcome of <lb/>social interactions [1]. It enables to establish shared action plans and efficient coordination in cases of <lb/>cooperation [2]. It also enables anticipation of an opponent&apos;s actions in cases of competition such as in <lb/>strategic games. <lb/>Recently, an emphasis has been placed on one particular feature of this mind reading ability: using the <lb/>past experience to predict the behavior of a conspecific [3]. Strategic interactions during repeated <lb/>competitive games have been proven to be a useful experimental paradigm to capture the behavioral <lb/>dynamics revealing such theory of mind in human and non-human primates [4], as they consist in social <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>4 <lb/></page>

			<body>situations where one&apos;s choice outcome critically depends upon the action of the other. Game-theory <lb/>provides formal solutions to strategic interactions, modelled as games, through the concept of Nash <lb/>Equilibrium (NE) and its refinements [5]. The so-called Mixed Strategy Nash Equilibrium (MSNE), for <lb/>instance, prescribes a probability distribution over possible actions that ensures to each involved agent <lb/>that they would have no incentive to deviate if they all follow it. In practice, however, humans typically <lb/>deviate from equilibrium [6]. Moreover, the way human subjects progressively learn to reach MSNE is still <lb/>little understood. One hypothesis, which encounters growing support, lies on the idea that convergence <lb/>towards MSNE distribution during repeated games requires that both players, who aim to maximize their <lb/>earnings, should learn and adjust beliefs through predictions over the opponent&apos;s behavior in order to <lb/>best-respond to it [13]. Nevertheless, the important variability observed in this process [15] makes the <lb/>characterization of the underlying learning mechanism difficult. <lb/>Research in cognitive neuroscience suggests that, in probabilistic tasks, humans learn to adjust their <lb/>decisions based on expected values computed from previously experienced outcomes (model-free <lb/>reinforcement learning, RL) but also through the incorporation of (probabilistic) beliefs over the action-<lb/>outcome contingencies underlying the structure of such environment (model-based RL) [19], [20]. Indeed <lb/>in such tasks, reward convey at least two types of information, often correlated: the affective (hedonic) <lb/>value embodied in the monetary reward and the information (predictive) value about the structure of the <lb/>world [21]. The ability to use the latter to maintain and update, using prediction accuracy, a mental <lb/>representation of the choice environment has been found to encompass social interactions as well [22], <lb/>[23]. In fact, by pairing the normative framework of game theory to the computational approach in <lb/>neurosciences, recent research has shown that during repeated games, humans can engage in model-<lb/>based learning using an iterative computation of the strategic information provided by the interaction [24], <lb/>[25]. Such strategically sophisticated computations drive higher order beliefs that incorporate the level of <lb/>influence of one&apos;s past actions on her opponent&apos;s choice behavior, thus allowing for more accurate <lb/>predictions [26]. Such hierarchy of belief computation has been observed at the brain level, with common <lb/>brain structures implicated in model-based (non-social) and belief-based (social) learning computations <lb/>(medial prefrontal cortex) [27], and higher-order belief (strategic) learning incorporating signals from areas <lb/>involved in theory of mind (temporo parietal junction) [28]. <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>5 <lb/></page>

			<body>Crucially, all these studies reported important heterogeneity in the level of engagement in belief-based <lb/>learning, linked to variation in overall performance. However, none of the previous studies directly <lb/>investigated the relationship between the human&apos;s ability to engage in strategic learning and the observed <lb/>deviation from best response distribution, and ultimately MSNE. Taken together these results yet suggest <lb/>that humans&apos; propensity to follow optimality prescription from game-theory requires to disengage from <lb/>reward-oriented, model-free, learning and fully engage in belief-based learning. <lb/>We hypothesized that, depending on how the reward structure interacts with the MSNE prescription in a <lb/>repeated strategic game, human performance in the game may be differently affected so that it does not <lb/>necessarily reflect an individual&apos;s general level or ability of strategic learning. Previous studies suggest <lb/>that the amplitude of the payoffs interferes with the propensity to follow the MSNE [7], and that the <lb/>symmetric nature of a game might facilitate the belief formation over the opponent&apos;s behavior through <lb/>perspective taking [29], [30]. <lb/>We developed a novel 2x2 competitive game setting, symmetric in payoff amplitude and expected payoff, <lb/>so that the two players would earn the same if they both follow the MSNE distribution. The structure of the <lb/>payoff matrix was however designed to lead to strategic asymmetry where one player&apos;s highest rewarded <lb/>action would happen to be, at the informational level, the one the MSNE prescribes to choose the most <lb/>(advantageous role), while for the other player the attractive action (focal point) would be the one she <lb/>should choose the less (disadvantageous position). If following the optimal distribution of choice is <lb/>conditioned on the ability to consider the strategic structure beyond the payoffs value to engage in belief <lb/>learning, then our game should lead to strategic asymmetry. We made the secondary hypothesis that in <lb/>the repeated version of this game, humans with different individual strategic learning levels (SL) would <lb/>differ in their capacity to overcome this asymmetry and lead to observable differences in the final earnings <lb/>between the advantageous and disadvantageous roles in the game. <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>6 <lb/></page>

			<body>We ran 2 distinct experiments with the same game setting: In the first one human subjects play against <lb/>each other, while in the second we specifically manipulate the level of subjects&apos; computerized opponent. <lb/>Beforehand, we simulated agents interacting repeatedly through our competitive game, all modeled as <lb/>simple learning algorithms varying from reward-based to sophisticated belief-based computations [25] <lb/>and developed to capture different levels of strategic learning sophistication (SL). As anticipated we show <lb/>that, at the population level, the game payoff matrix lead to a strong strategic asymmetry, such that the <lb/>agents playing in the disadvantaged position see their loss reduced only when they engage in higher SL <lb/>level than their opponent. We moreover found that the observed deviation from game optimality (MSNE) <lb/>is mainly driven by the individual propensity to depart from reward-based learning and engage in <lb/>sophisticated belief-learning, and that individuals in the disadvantageous position were driven by loss <lb/>reduction and constrained by their own SL learning capacity, while subjects in the advantageous position <lb/>were mainly adjusting their best response to the estimated behavior of their opponent. Importantly for our <lb/>computational hypothesis, behavioral results from both experiments matched the predictions made in <lb/>simulation. Strikingly, only subjects endorsing the disadvantageous role (hence pressed towards their <lb/>own limit) showed a SL level which was stable across opponent, as if the reduction of the strategic <lb/>asymmetry was cognitively bounded [31]. These findings thus provide a possible explanation for the <lb/>discrepancy between previous studies in which no correlation between SL level in strategic games and <lb/>cognitive abilities was observed [24]. <lb/>II-MATERIALS AND METHODS <lb/>1-Experiment 1: Computer against computer <lb/>The game is a two-by-two (two players, two actions) (payoffs) asymmetric game, with a unique Mixed <lb/>strategy equilibrium (Fig. 1A). The expected payoffs at the mixed strategy Nash equilibrium are the same <lb/>for both players. <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>7 <lb/></page>

			<body>To make predictions about the effect of the strategic asymmetry of our payoff matrix on subjects&apos; behavior <lb/>we simulated different computerized agents playing a repeated version of our game in each of the 2 roles, <lb/>with different levels of strategic sophistication. Such a simulation analysis allows us to not only test the <lb/>robustness of our design but also to make precise predictions regarding the effect the individual level of <lb/>strategic learning would have on the dynamics of play of humans interacting through this experimental <lb/>setting (see Text S1 for details on the computational modelling and the simulation analysis). <lb/>To mimic inter-individual variation of strategic learning we used 3 computational models varying in their <lb/>level of strategic sophistication (SL): a simple reinforcement algorithm learning only from the outcomes <lb/>obtained through its past choices; a fictitious play best responding to the probability of each opponent&apos;s <lb/>choice computed from its history of actions; and an Influence model, i.e. a 2nd order fictitious taking into <lb/>account the influence of its own past choices in the computation of the opponent&apos;s probability of play [25]. <lb/>Each simulation consisted in 2 computerized agents, endorsing one of the 2 roles and modeled by one of <lb/>the 3 models, playing against each other during 100 repetitions of the stage game. <lb/>2-Experiment 2: Human against human <lb/>a-Population <lb/>64 participants (29 male, 35 female; ages 27.1±9.4) took part in the experiment. They were students at <lb/>the University of Lyon 1, France, who had previously joined the recruitment system on a voluntary basis. <lb/>These volunteers gave written informed consent for the project which was approved by the French <lb/>National Ethical Committee. All participants were right-handed, medication-free, with normal eyesight, no <lb/>history of neurological disorders. <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>8 <lb/></page>

			<body>Figure 1. Experimental design of experiment 1. (A) Payoff matrix of the repeated game, in points. In <lb/>light blue the action probabilities prescribed by the mixed strategy equilibrium (MSNE). (B) We <lb/>manipulated 2 variables : the role (within subject level), and the opponent (between subject level). At start <lb/>subjects were randomly assigned to one of the two roles in the game (player 1 or 2). After being <lb/>instructed, they were randomly paired to an anonymous counterpart during a block of 100 repetitions of <lb/>the game, and to a different counterpart during the second trial block. (C) Trial Structure : At each trial the <lb/>two game actions, represented by the randomly assigned colors, were presented for 3s to each player. <lb/>The choice was made by pressing the corresponding button (left or right). 4s after the trial onset, both <lb/>players were simultaneously provided with the outcome feedback of their choice for 3s (the cell matrix <lb/>matching to the 2 players choices was highlighted and the points won displayed in turquoise). <lb/>b-Experimental Design <lb/>The first experiment consisted in a repeated interaction against another anonymized participant. One of <lb/>the 2 roles was randomly attributed to each participant at the beginning of the experiment. Each subject <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>9 <lb/></page>

			<body>interacted with two different human opponents, one after the other in two trial blocks of 100 repetitions of <lb/>the stage game with complete choice feedback (Fig. 1B). These two opponents were randomly selected <lb/>among the participants assigned the opposite role to the subject. Points earned at each trial were <lb/>accumulated through each block and summed up to determine their final payoff which would ultimately be <lb/>converted to euros according to a predetermined rule. Each subject was initially instructed of the 2 stimuli <lb/>representing her two available actions in the task, the payoff structure of the game, and trained to learn <lb/>the stimulus-outcome contingencies of the payoff matrix. Each action was made of a different colored <lb/>circle randomly picked from 4 possible colors (all controlled for luminance). The 4 colors were randomly <lb/>assigned to each pair of subjects in the first block, and kept unchanged in the second interaction block <lb/>(thus constraining the re-matching random procedure in the second block). At each trial, both subjects <lb/>had 3 seconds to select one of the 2 colors displayed at the left and right of the screen (randomized order <lb/>across trials), the chosen one was highlighted for 1 second as choice feedback. 4s after the trial onset, <lb/>both players were simultaneously provided with the outcome feedback of their choice and the one of their <lb/>opponent for 3s. The outcome feedback screen consisted in the payoff matrix (note that depending of the <lb/>role endorsed in the game the matrix was flipped so that subjects were always presented as row player), <lb/>with the cell corresponding to the matching of the 2 players choices highlighted and the points won by the <lb/>subject displayed in turquoise (Fig. 1C). This display ensured minimal framing effect, while controlling for <lb/>participants&apos; awareness of the underlying payoff structure of the game. <lb/>We also provided to the subjects an additional task which consisted of a series of four different types of <lb/>2x2 static (one-shot) games [16]. The goal was to test the endogeneous hypothesis of strategic learning <lb/>sophistication developed in Griessinger &amp; Coricelli [26]. We hypothesized that participants with a SL level <lb/>in the repeated game (captured by our computational approach from the game behavior in the main task) <lb/>would also display a higher strategic reasoning (SR, expressed as their capacity to conform to equilibrium <lb/>play when a game is not repeated and no feedback is provided). All the subjects came back a second <lb/>time to the lab a week later to complete a series of cognitive tasks. Both the additional experiment and <lb/>cognitive tasks are detailed in Text S1. <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>10 <lb/></page>

			<body>c-Computational modeling <lb/>To capture the level of strategic learning of the subjects we first used the computational approach <lb/>introduced in the simulation analysis (Exp.1): 3 computational models, fcorresponding to 3 different levels <lb/>of strategic sophistication, were fitted individually to each choice series from the two trial block <lb/>independently (Q-Learning, Fictitious and Influence models). The underlying assumption is that the higher <lb/>the level of strategic complexity of the model that best fits a subject&apos;s behavior, the higher her strategic <lb/>learning engagement in the interaction. As detailed in the Text S1 we also tested additional models to <lb/>control for the reliability of our computational approach. <lb/>3-Experiment 3: Human against computerized opponents <lb/>a-Population <lb/>76 participants (36 male, 40 female; ages 18-30) took part in the experiment. They were student at the <lb/>University of Trento, Italy, who had previously joined the Cognitive and Experimental Economics <lb/>Laboratory (CEEL) recruitment system on a voluntary basis. All participants were right-handed, <lb/>medication-free, with normal eyesight, no history of neurological disorders. The Ethics Commission of the <lb/>University of Trento approved the experiment. Informed consent was obtained from each subject before <lb/>the experiment. Data collection was performed blind to the conditions of the experiment. <lb/>b-Experimental Design <lb/>The experimental design remained unchanged: participants were randomly assigned to one of the 2 roles <lb/>of the same game, with the same trial structure and timing, and also played 2 blocks of 100 trials each. <lb/>Nevertheless, this time they did not play against another randomly picked human participant, but rather <lb/>played against 2 computerized learning agents: a fictitious play (low SL) and an Influence (High SL), one <lb/>after the other in a random order. To be fully consistent with the previous experiment, we used as model <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>11 <lb/></page>

			<body>parameters of the 2 opponents the average best fitting values obtained in the first experiment (details in <lb/>Text <lb/>S1). <lb/>All statistical analyses were performed using Matlab (www.mathworks.com) with the addition of the <lb/>Statistical toolbox and other free-download functions. All stimuli and feedbacks were presented using <lb/>PsychToolBox and appeared on a uniform black background. <lb/>III -RESULTS: <lb/>Figure 2. Strategic characteristic of the game : simulation of play between 2 agents varying in <lb/>their Strategic Learning level (SL) shows strong asymmetry in total earnings between the 2 roles. <lb/>(A) Each agent modeled by either one of the 3 models of increasing strategic complexity, or SL level (i.e. <lb/>Level 0: Q-Learning, 1: Fictitious play and 2: the Influence model) played the game in one of the 2 role. <lb/>Every Player1-Player2 model combination was simulated 100 times playing against each other the 100 <lb/>repetitions of the game. Agents endorsing the role of Player 1 won more points on average than Players <lb/>2. In fact Player 2 agents won more that their opponent only in the situation where they were playing SL <lb/>Level 2 and Player 2 agent a level below or more. (B) Agents were modelled by the Influence model <lb/>varying in the values of their parameter λ from 0 (low SL level -fictitious) to 1 (high SL level -full <lb/>influence), as well as their η ([0:1]). The heatmap were obtained by averaging across the whole range of <lb/>η values, for each λ combination. <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>12 <lb/></page>

			<body>1-Experiment 1 <lb/>Our simulation results reveal an important advantage of Players 1 over Players 2 in our game. Not only <lb/>simulated agents playing as Player 1 performed better than Players 2 in the game, but Players 2 had to <lb/>be consistently higher SL level than their opponent in order to win more points (Fig. 2). To ensure that <lb/>this game propriety does not depend on the tuning of our simulations we replicated the simulation <lb/>analysis with different proxies of the SL level such as the parameter λ of the Influence model. This <lb/>parameter captures the weight of the second order fictitious update in the computation of the opponent&apos;s <lb/>action probability. Our additional simulation analyses systematically show that the only way for Players 2 <lb/>to outperform their opponent is to engage in a higher level of Strategic Learning (Fig. S1 in Text S1). <lb/>Altogether this preliminary analysis confirms the strategic asymmetry of our payoff matrix, revealing the <lb/>strong advantage of player 1 over player 2 in the sub-optimal domain. This setting allows us to clearly test <lb/>how the individual level of strategic sophistication is affected by the strategic asymmetry of the repeated <lb/>competitive interaction. <lb/>2-Experiment 2 <lb/>a-Behavioral results <lb/>We first tested our hypothesis that our game settings triggers differences in choice behavior between the <lb/>2 roles. As predicted by our simulation analysis subjects who endorsed the role of Players 1 won more <lb/>points on average than Players 2 (Block 1, B1 : F(2,31)= 3.272 p= 0.0014, t(48.3)= 4.396 p&lt;0.0001 ; B2 : <lb/>F(2,31)= 2.236 p= 0.0282, t(54.10)= 3.894 p=0.0003). In fact, across the 2 blocks, only 15% of Players 2 <lb/>won more points than their opponent. The choice behavior of the 2 groups deviated on average from the <lb/>optimal solution in both blocks (Player 1, P1 -B1: P(a) = 0.399(±0.065), B2: P(a) = 0.391(±0.070) ; P2 -<lb/>B1: P(A) = 0.482(±0.098), B2: P(A) = 0.448(±0.097) ) but Players 2 were the ones who deviated the most <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>13 <lb/></page>

			<body>from game optimality by choosing the action &quot;A&quot; much more frequently than the mixed strategy <lb/>equilibrium (MSNE) prescription in comparison to Players 1 (B1 t(54.09)= 3.935 p=0.0002 unequal <lb/>variance, B2: t(62)= 2.696 p=0.0090). We thus aimed to test if this difference could explain the difference <lb/>in performance between the 2 players. As shown on Fig. 3, Players 2&apos;s deviation from MSNE was not <lb/>correlated to their overall performance like Players 1 (Fig. 3.A), but rather to the size of their loss in the <lb/>interaction (Fig. 3.B). In fact, the disadvantage in the interaction that was experimentally induced through <lb/>the structure of the game lead Players 2 to be constrained to the loss domain, so that the closer their <lb/>choice proportion was to the MSNE, the less difference in points they had with their opponent. This <lb/>asymmetry in the interaction seems to have been fully exploited by Players 1 since deviation of Players 2 <lb/>from the MSNE lead them to perform better than their counterpart did in this situation (Fig. 3.C -Fig. <lb/>S1.C). <lb/>Before investigating how the level of strategic learning affects the choice behavior of the two roles, we <lb/>first tested that our prior assumption that subjects differ in their level of strategic learning was met. Our <lb/>computational analysis revealed that half of our subjects behavior was best captured by the Influence <lb/>model (Fig. 4.A), while near one third of our population was best fitted by models of lower level of <lb/>strategic complexity (less than 10% by the reinforcement learning model). Moreover, not only the subjects <lb/>best fitted by the Fictitious model were also better captured by the Influence model in comparison to the <lb/>reinforcement model (relative fit of the Influence) (Fig. 4.B), but the better a subject&apos;s choice behavior was <lb/>captured by the high SL model, the higher the value of her Influence best fitting parameter λ was (B1 : r = <lb/>0.7534, p=6.76e-13; B2 : r = 0.7535, p=6.73e-13). Taken together these results reveal that the majority of <lb/>subjects were engaged in some form of strategic learning throughout a gradient of strategic complexity <lb/>(SL). <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>14 <lb/></page>

			<body>Figure 3. Model free analysis -Deviation from game optimality affects differently the 2 roles in the <lb/>strategically asymmetric game, leading to a structural disadvantage of Players 2. <lb/>(A) The closer to the MSNE the choice distribution of Players 1 is the higher their absolute performance. <lb/>On the other hand Players 2 choice optimality did not lead to higher absolute performance but to a higher <lb/>relative performance (B), reducing the gap in points that separate them from their opponent. This <lb/>structural asymmetry lead Players 1 to fully exploit the disadvantage, their absolute performance <lb/>increased more with their opponent suboptimality than Players 2 confronted to a suboptimal opponent <lb/>(C). <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>15 <lb/></page>

			<body>Figure 4. Strategic learning heterogeneity <lb/>captured by our computational approach. Most <lb/>of the participants engaged in Strategic <lb/>Learning (SL&gt;0). <lb/>(A) Individual Best Model (I.B.M.) frequency plot. <lb/>While at the population level, the Influence model <lb/>fits the best the population behavior (not shown), <lb/>at the individual level about half of the subjects <lb/>were best fitted by high SL and one third by <lb/>models of lower levels of strategic learning. <lb/>To maximize the accuracy of our individual characterization and avoid the overestimation of an <lb/>individual&apos;s strategic learning level, we conducted an extended computational analysis including <lb/>additional models (see Text S1). None of the variations of the Reinforcement and Belief-Based models <lb/>tested improved significantly their fit, thus confirming that most of our subjects indeed engaged in some <lb/>form of strategic learning (Text S1). In fact our analysis suggests that the SL level might have been <lb/>under-estimated since more than one third of the subjects previously best fitted by the Influence were <lb/>better fitted by a 2nd order version of the model, which has an even higher SL level [24] (Fig. S2). This <lb/>nevertheless does not affect the superiority of their SL level compared to subjects best fitted by RL or <lb/>Fictitious models. Although it is important to note that if the relative fit between the 2-Inf models and the <lb/>simple reinforcement learning model improves the precision of the characterization of the individual SL <lb/>levels, all the results presented in the following consistently hold when using as SL measure the fit of the <lb/>Influence relative to the fictitious, or the value of the Influence best fitting parameter λ. <lb/>Our computational analysis thus suggests an overall departure from simple reinforcement in repeated <lb/>competitive interactions, with a population spread across a gradient of strategic sophistication going from <lb/>value-based (Reinforcement), to low (Belief-Based) and high level (Strategic) level of learning <lb/>engagement. <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>16 <lb/></page>

			<body>Besides, our simulation analysis suggested that the endogenous disadvantage of Players 2 in the game <lb/>can be overcome by engaging in a higher level of sophistication than the opponent. However, the <lb/>important difference in performance and game optimality observed between the two roles in our <lb/>experiment lead us to hypothesize that, on average, Players 2 did not engage in a higher level of strategic <lb/>learning than Players 1. Indeed, we could not reject the null-hypothesis that the two populations of SL <lb/>came from the same distribution, using as SL measure either their departure from reinforcement towards <lb/>models of highest strategic complexity (D(126)= 0.2031, p=0.1250; U(126)= 1682, Z = 1.7418 p= 0.0815) <lb/>or the weight attributed to 2nd order belief (λ) (D(126)= 0.1719, p=0.5809; U(126)= 2036, Z = 0.0548, p= <lb/>0.9563). Note that these results hold when the 2 blocks were analyzed separately (not shown). The 2 <lb/>roles did not differ either in how frequently they switched actions from one trial to the next (U(126)= <lb/>1986.5, Z =0.2913, p= 0.7708). Our results suggest that the observed disadvantage of players 2 was not <lb/>due to a difference on average strategic learning sophistication but could rather be caused by a different <lb/>implication of the SL level in the 2 roles. <lb/>We then investigated how the SL level of the two Players drove the dynamics of their interaction. We <lb/>focus first on Players 2 behavior. The level of strategic learning engagement of Players 2 was negatively <lb/>correlated with deviation from the mixed strategy equilibrium (r= -0.6455, p= 8.48e-09, SL as relative fit of <lb/>the 2-Inf). Therefore, as suggested by our model-free analysis (Fig. 5.A,B), their SL level was not <lb/>correlated directly to the total points won in each block but to the difference in points with their opponent, <lb/>so that the higher their SL level, the lower their average relative loss is (Fig. 5.A). Moreover, the higher <lb/>their SL level was compared to their Player 1 opponent, the closer their action distribution was to the <lb/>MSNE (Fig. 5.B). However, this was not enough to overcome the structural disadvantage and increase <lb/>their absolute performance (Fig. 5.C). If Players 2&apos;s behavior seems to be constrained by their own SL <lb/>level, Players 1&apos;s behavior presents a quite opposite pattern. Their deviation from MSNE frequency was <lb/>not directly driven by their SL level (r=-0.0396, p=0.7561) but by the one of their opponent (r=0.49403, <lb/>p=3.34e-05), so that the higher the level of Players 2, the worse their performance was (absolute: r= -<lb/>0.5826, p= 4.40e-07 and relative: r= -0.4650, p= 0.0001). Since Players 2 who engaged in a higher SL <lb/>level deviated more from the High Reward action to play closer to the MSNE, they pushed Players 1 to <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>17 <lb/></page>

			<body>adapt by engaging in a higher SL level. Indeed, given the structural advantage they had in the game, the <lb/>better they were at anticipating their opponent&apos;s behavior (higher SL level than their opponent), the higher <lb/>were their relative earnings (r= 0.4380, p= 0.0003) and their absolute performance (Fig. 5.C). These <lb/>results hold when comparing these behavioral measures between high and low SL level (median split) in <lb/>the 2 roles. <lb/>Figure 5. Model-based analysis -The Strategic Learning level (SL) of the Players 2 in the game, <lb/>conditions their capacity to overcome the structural disadvantage of their position in the game. <lb/>(A) The higher the SL level, measured here by the difference in the fit between the (second order) <lb/>Influence model compared to the fit of the RL <lb/> † , the more Players 2 reduced their disadvantage compared <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>18 <lb/></page>

			<body>to their opponent. (B) The higher their SL level compared to their opponent the closer to the MSNE they <lb/>played. In fact both role converge towards the equilibrium distribution, only Players 2 tend to deviate <lb/>much more when not engaging in strategic learning. (C) Albeit decreasing the gap in points with their <lb/>opponent Players 2 could not on average increase their overall performance, constrained by both the <lb/>structure of the interaction and their own SL level. ( <lb/> † Similar results were obtained when running the <lb/>correlation test analysis with the relative fit of the first order Influence. Using the Influence parameter λ <lb/>values as measure of the SL level or comparing Low and High SL IBM groups of subjects lead conserved <lb/>the main statistical effects.) <lb/>To capture the simultaneous effects of both the subjects&apos; and their opponent&apos;s SL level on the subject&apos;s <lb/>own choice behavior, we ran 3 GLM analyses that confirmed that Players 2&apos;s behavior was impacted <lb/>mainly by their own level of strategic learning sophistication, and Players 1&apos;s behavior mainly by the SL <lb/>level of their opponent (Fig. S3.A.B). <lb/>This dynamic can be further unfolded by looking at the choice accuracy of the subjects. Players 2 who <lb/>engaged in higher SL level managed to overrule the value-based sub-optimal bias towards the high <lb/>reward action. Instead of repeatedly selecting action A, easily predictable by their opponent in the <lb/>advantageous situation, they switched action more often from one trial to the other (r= 0.3419, p=0.0057), <lb/>so that they got more frequently the high reward when they chose action A (Fig. S4.C). Conversely this <lb/>lead Players 1 to compensate, to avoid deviating more from the optimal play, by engaging in higher <lb/>strategic learning eventually leading to also increase their accuracy (Fig. S4.C). <lb/>This overriding of the prime tendency for Players 2 to go for the high reward by engaging in higher level of <lb/>strategic learning level was also observed from one choice to another. Using a logistic regression <lb/>analysis we can take a closer look to the series of choices to investigate how the previous actions impact <lb/>the current decision (details provided in Text S1). This analysis revealed that on average subjects <lb/>consistently alternated their choices every 2 trials independently of their role (Fig. S5.A), but that only <lb/>Players 2 tended to persist in selecting the action linked to the high reward, taking less into account the <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>19 <lb/></page>

			<body>opponent&apos;s last choice (Fig. S5.A,B). And the more Players 2 engaged in strategic learning the more they <lb/>would alternate their choice (Fig. S5.C). <lb/>Altogether, our analyses suggest that among the subjects endorsing the role of Player 2 in this <lb/>experiment, only the ones who had a high level of strategic learning sophistication could detach from the <lb/>game sub-optimal focal point to overcome the structural disadvantage they had in the game interaction. <lb/>Their opponent, albeit in the easy position, was then forced to adapt and at the end to follow the Players <lb/>2&apos;s choices to avoid as much as possible to lose their advantage. The leader becomes the follower. <lb/>This hypothesis was further backed up by our initial simulation. Indeed, running the same type of analysis <lb/>on our simulation results leads to a very similar dissymmetry in the implication of the SL level between the <lb/>advantageous and the disadvantageous role (Fig. S6). <lb/>b-Correlation with additional cognitive tasks <lb/>Our main hypothesis was that Players 2&apos;s disadvantage in the game would push them to make the effort <lb/>to use their strategic thinking abilities, so that their performance in the game, as measured in terms of <lb/>heterogeneity of the SL level of the computational model that best accounted for each subject&apos;s behavior, <lb/>would be more stable across opponents and rely more on cognitive constraints than it would be the case <lb/>for Players 1. Conversely we hypothesized that Players 1&apos;s strategic learning engagement would be <lb/>influenced more by individual traits and problem-solving or planning abilities, because their advantage in <lb/>the game would leave them free to play with the SL level they are habituated to use outside the <lb/>laboratory. To test our hypothesis we first looked at the consistency of the SL level of Players 2 across <lb/>blocks compared to Players 1. We found that their SL level was significantly more consistent (89% of the <lb/>subjects were best fitted by the same class -low / high -of SL level models in Block 1 and Block 2) <lb/>compared to Players 1 (59%, Fisher exact test: N = 49, p = 0.0269). Also the correlation in SL level <lb/>across the 2 blocks was significant for Players 2 only (P1 : r = -0.0781, p= 0.6710; P2 : r = 0.7171, <lb/>p=3.88e-06). Moreover, no difference on average (or distribution of) SL nor choice behavior (deviation <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>20 <lb/></page>

			<body>from MSNE, absolute or relative performance, choice accuracy of high reward action, frequency of switch) <lb/>was found between the 2 blocks for each role. Interestingly, our analysis nevertheless revealed that <lb/>Players 1 chose faster in the second trial block (P1 : t(62)= 2.7102, p = 0.0087, P2 : t(62)= 1.9009, p = <lb/>0.0620), suggesting some adaptation of Players 1&apos;s play in the second block. <lb/>Finally, we compared the SL level of the subjects and their individual performances in the additional tasks <lb/>and questionnaires. At the population level only the CRT score (used as a proxy of reasoning ability in the <lb/>literature) was higher for high SL vs. low SL (median split: U(62)=313.5,Z= 2.7678, p=0.0056 ; r=0.2572, <lb/>p=0.0402) and in Block 1 only. When comparing the performance in the additional tasks in high vs. low <lb/>SL level (median split) subjects for each role separately, we found that high SL Players 1 in Block 1 only <lb/>had a higher CRT score (U(30)=54, Z=2.8891, p=0.0038), performed better in the Raven test (U(30)=62, <lb/>Z=2.5389, p=0.0111), and were on average more successful in the Tower of London task (ToL: <lb/>t(25)=2.0675, p=0.0491; ToL (difficult condition: high Goal Hierarchy, high Search Depth): U(25)=46, <lb/>Z=2.3271, p=0.0199). No correlation between the performance in any the additional tasks was found with <lb/>the SL level of Players 2 in any of the 2 blocks. No difference was found between subjects based on the <lb/>role they endorsed in the game in terms of demographics (Age, salary and education level) nor additional <lb/>cognitive tasks performances (Working Memory, CRT, Raven, ToL). No difference either in performance <lb/>in these additional tasks was found between subjects who were consistently fitted by the same SL model <lb/>in both blocks and the one who switched SL level between the two. <lb/>Our results suggest that regardless of the role, the subject&apos;s level of strategic sophistication does not <lb/>depend on the level of the opponent nor the role endorsed in the game but might be related more to <lb/>different individual cognitive abilities: subjects playing as Player 2 seem to be limited in their propensity to <lb/>engage in strategic learning preventing them to fully compensate their disadvantage in the game <lb/>interaction, while the heterogeneity in SL level observed in Players 1, already in a dominant position, <lb/>might be more driven initially by their executive cognitive abilities (problem-solving, planning). If this is <lb/>true then Players 2 ability to engage in strategic learning might be correlated to their ability to reason <lb/>strategically (i.e. in an iterative fashion). <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>21 <lb/></page>

			<body>During our experimental session, subjects were provided with a second task meant to test specifically the <lb/>hypothesis that the level of strategic learning engagement in the repeated game matches the ability to <lb/>play the Nash equilibrium in one-shot games [26]. This task was composed of different types of one-shot <lb/>games played 8 times each, in a random order, with no feedback. In one type of games (Dominant <lb/>Solvable Other, DSO), higher strategic sophistication was required to form correct belief over the <lb/>opponent&apos;s action and best respond to it but not in the other (Dominant Solvable Self, DSS). The analysis <lb/>detailed in the Text S1 did not allow us to reject our null-hypothesis of an absence of direct mapping <lb/>between strategic learning and strategic reasoning at the population level. This therefore suggests that <lb/>different cognitive processes are involved in the engagement in strategic sophisticated play in a repeated <lb/>game <lb/>interaction <lb/>with feedback and <lb/>in <lb/>static one-shot games without feedback. <lb/>However we found that the more Players 2 reached the N.E. in DSO (requiring higher level of strategic <lb/>sophistication) the closer to the Nash their frequency of action(a) was in the first Block in the repeated <lb/>game (all trials B1: r=-0.3822 p=0.0309; B2: r=-0.3078 p=0.0865). This correlation, specific to Players 2, <lb/>was the strongest in the first trials of the all repeated game experiment (B1 t(1:10): r=-0.5647 p=7.6e-4 -<lb/>not sig. for following bins ; B2 t(1:10): r= -0.1992 p= 0.2743 -not sig. for following bins). Using 2 other, <lb/>more precise, measures of strategic reasoning developed in SI, lead to similar results (SR: r=-0.5034, p= <lb/>0.0063 ; SR&apos;: r= -0.6853, p=0.0068), no correlation was found with the % of NE in DSS. <lb/>Taken together these results suggest a transition from static strategic reasoning to on-line computation <lb/>and update of beliefs over the opponent&apos;s behavior when sufficient choice outcomes are observed. <lb/>3-Experiment 3: <lb/>To better characterize the interplay of strategic learning sophistication with the strategic asymmetry in <lb/>game interaction, we conducted a second study with human subjects in which we controlled for the <lb/>opponent&apos;s behavior by making the subject play against a computer opponent (instructed) and specifically <lb/>manipulating the SL level of this opponent. The goal of this experiment was to replicate our initial results <lb/>and test the specific hypotheses derived from them, that subjects endorsing the disadvantageous role in <lb/>this strategically asymmetric game were constrained in their choice behavior by their own SL level, while <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>22 <lb/></page>

			<body>subjects playing in the advantageous position will indeed have the strategic space to adapt, given their SL <lb/>level, to the behavior of their opponent. <lb/>Our Human vs. Agent design allowed us to test the 2 main hypotheses from Exp. 1 and 2: 1) that the role <lb/>impacts the average performance and game optimality (Players 1 perform better than Players 2), but not <lb/>the overall SL distribution of the two groups. 2) that Players 1&apos;s choice behavior should be impacted by <lb/>the identity of the opponent, with lower performance against High SL agents (Influence) compared to Low <lb/>SL agents (fictitious). Players 2&apos;s behavior on the other hand should only be affected by their own SL <lb/>level, not the opponent. Beforehand we simulated once again the experiment by making agents with <lb/>different SL level play against the 2 algorithms. Our results show the selective effect of the opponent SL <lb/>level manipulation on the Players 1 we expect to see in the actual experiment, thus confirming the <lb/>adequacy of our design (Fig. S7). <lb/>On average, Players 1 won more points (t(142)= 8.5298 p=2.79e-14) and had a distribution of choices <lb/>closer to the Mixed Nash Equilibrium (t(142)= -4.5144 p=1.32e-05 unequal variance) than Players 2. Our <lb/>Model-based analysis replicated nicely the distribution and SL gradient across the population observed in <lb/>Exp.1 (Fig. S8). And, as in Exp.1, no difference in SL distribution was found between the 2 roles. But this <lb/>time participants were playing against an algorithm, not against another human. And since they played <lb/>the repeated game in the same experimental conditions as in Experiment 1, we tested if this difference <lb/>affected their behavior. For each of the 2 roles, no significant difference was found in performance (total <lb/>points, points difference with the opponent) between the two experiments. However, a trend towards <lb/>higher strategic learning engagement when playing against algorithms was observed. When comparing <lb/>low vs. high SL (median split), Players 1 engaged in strategic learning were found to have a higher SL <lb/>level in the second experiment (rel. fit 2-Inf: U(66)=233, Z=4.2082, p= 2.57e-05, λ parameter: U(66)=368, <lb/>Z=2.5495, p= 0.0108 -similar results were obtained when comparing the SL level between subjects best <lb/>fitted by the Influence models). <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>23 <lb/></page>

			<body>No difference in mean SL level (nor distribution) was found between the 2 roles. Running an ANOVA to <lb/>test if the SL level was modulated by the opponent encountered did not result in any significant effect <lb/>either. As in experiment 1, Players 2 were most consistently fitted by same SL level models between the <lb/>2 opponents than Players 1 (P2= 0.84 prop. same low/high SL : P2=0.84, P1 = 0.57 ; Fisher exact test: N <lb/>= 58, p = 0.0259). <lb/>We next tested our second hypothesis regarding the specific effect of the opponent on the choice <lb/>behavior of the subject given the role endorsed in the experiment. As shown in Fig.6, only Players 1 were <lb/>affected by the identity of the opponent, exactly as predicted by the simulation (Fig.5.A.B, Fig.S7.A.B). <lb/>Figure 6. As hypothesized, only the subjects endorsing the role of Player 1 (pink) in the repeated <lb/>game were affected in their choice behavior by the SL level of the (computerized) opponent <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>24 <lb/></page>

			<body>encountered. (A) Players 1 frequency of choice is closer to the MSNE distribution when playing against <lb/>the low SL opponent compared to the high level. No difference in percentage of deviation from MSNE <lb/>distribution (p(a)=1/3) was found between the 2 opponent&apos;s block for Players 2. (B) When opposed to the <lb/>low SL level opponent, Players 1 won on average more points in total than when playing against the high <lb/>SL. No difference was found for Players 2. (C) When opposed to the low SL opponent both Players, 1 <lb/>and 2, were more frequently rewarded when playing the high payoff action (b for player 1 and A for player <lb/>2), a proxy for choice accuracy, compared to the high SL level. Effect size was however higher for Player <lb/>1 (Cohen&apos;s d= 1.1909) than Player 2 (d= 0.7633). <lb/>To refine our analysis, we ran the 3 GLMs we used in Exp. 1, taking into account not only the level of the <lb/>computerized opponent (low or high) but also the SL level of the subjects. Our results replicate strongly <lb/>the asymmetry found in our first experiment and observed in the average results (Fig.6): Subjects playing <lb/>as Player 1 have their deviation from MSNE as well as their performance affected by the level of the <lb/>opponent; Conversely Players 2&apos;s choice behavior is modulated only by their own Strategic Learning level <lb/>(Fig.6). In this experiment however, Players 1&apos;s behavior seems to have been influenced not only by the <lb/>level of the opponent but also by their own strategic learning engagement (Fig.S9). This effect could be <lb/>due to the constrain our design added on their opponent&apos;s behavior. <lb/>At the end of the experiment subjects were provided with an additional task aimed at capturing more <lb/>precisely the working-memory capacity of our population (namely 2 and 3-Back tasks -see Text S1 for <lb/>details). We observed a trend towards a higher performance and RT in this task for high SL Players 2 <lb/>(median split) only when playing against the high SL opponent (% correct in 2-Back: t(33) = 2.2047 <lb/>p=0.0361, 3-Back : t(33)=1.7420 p=0.0908, albeit a higher % for High SL =75.4(±9.5) vs. low <lb/>SL=69.9(±8.9), reaction time 3-Back : t(33)=2.2999 p=0.0279). Albeit weak, this effect suggests that the <lb/>subjects playing in the disadvantageous role might be cognitively constrained in their higher engagement <lb/>in strategic learning when confronted to a highly sophisticated learner. <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>25 <lb/></page>

			<body>VI-DISCUSSION: <lb/>The present study aimed at testing the prediction that the structure of a repeated game interaction can <lb/>lead to strategic asymmetry depending on the way it facilitates the engagement in sophisticated learning. <lb/>More precisely, the hypothesis was that a dissymmetry in the overlap between reward structure and <lb/>MSNE (even when there is still symmetry in maximum possible payoffs between players) can differently <lb/>engage human subjects in using sophisticated strategic learning so that their overall performance does <lb/>not always reflect an individual&apos;s general ability of strategic learning or strategic reasoning. <lb/>This hypothesis was rooted in research in behavioral economics and cognitive sciences suggesting that <lb/>humans can use information available about their counterpart to form beliefs over their intentions [3]. <lb/>Indeed, in the case of repeated games, where social interactions are reduced to actions and rewarded <lb/>feedbacks, payoffs convey informational value about the opponent&apos;s behavior, and beliefs become <lb/>analogous to a mapping of action-outcome contingencies, as suggested by the model-based <lb/>reinforcement learning framework [20]. Recent studies suggest that similar brain computations might be <lb/>involved in the decrease of the uncertainty (increased prediction) over the opponent&apos;s next choice <lb/>allowing one to maximize her overall outcome of the interaction (best response to beliefs) [27]. Moreover, <lb/>inferential processes might be implicated in the iterative incorporation of the strategic nature of the <lb/>interaction, not only considering one&apos;s behavior but the interplay of past actions in the history of play, <lb/>ultimately increasing belief accuracy over an opponent also capable of belief-learning [26], [32]. <lb/>Nevertheless, important heterogeneity has been observed in the level of engagement in such high-order <lb/>belief (strategic) learning among individuals [24], [25]. <lb/>We thus hypothesized that the reward structure of the interaction might affect subjects differently given <lb/>their capacity to engage in strategic learning, depending on how much best-response to reward-based <lb/>and belief-based learning overlap. Based on this prediction we developed a 2x2 strategically asymmetric <lb/>game where the two roles were meant equal (same payoff distribution and expected payoff at MSNE), but <lb/>in which inequity arises among individuals with different SL levels, from the discrepancy in one role <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>26 <lb/></page>

			<body>(disadvantaged position) only between the highest reward action (focal point) and the MSNE distribution. <lb/>To test this hypothesis, we combined agent simulation and behavioral experiments, the latters being <lb/>either unconstrained (human-human interaction) or constrained (human-computer). Our two behavioral <lb/>experiments lead to the same conclusions, predicted by our simulation analysis. First, at the population <lb/>level, subjects endorsing the disadvantageous position during the repeated game interaction earn <lb/>significantly less than their opponent. Their choice distribution also deviated more from the MSNE <lb/>prescription. Second, the more the disadvantaged participants engaged in strategic learning, the more <lb/>they overcame the strategic asymmetry. This effect was even stronger when the opponent did not fully <lb/>engage in belief-learning. Forming accurate beliefs over their opponent allows these subjects to reduce <lb/>their disadvantage in total earnings and to play closer to the MSNE. Conversely, the choice optimality and <lb/>therefore the absolute performance of the participants playing in the advantaged role was modulated only <lb/>by the behavior, and ultimately the SL level, of their opponent, but not by their own capacity to engage in <lb/>strategic learning. <lb/>These results provide clear evidence for sophisticated learning in repeated interactions [4], [33] and the <lb/>central role of belief accuracy in equilibrium play [34], [15]. Moreover, our study shows how the reward <lb/>structure of the repeated game interacts with the observed heterogeneity in belief-learning at the <lb/>population level by creating a tension between rewards and beliefs. Empirically, we show that the high <lb/>reward attracts maximizing behavior and creates a focal point, which can easily be exploited by a low <lb/>strategic learning opponent [35] when not aligned with the MSNE prescription. In our stage game the two <lb/>players had identical expected payoffs. But the fact that for only one of the two roles the focal point <lb/>corresponded to the action that was theoretically the most optimal to select, creates an endogenous <lb/>asymmetry, strategic in nature, which reveals itself throughout the interaction. <lb/>While Mixed Strategy Nash Equilibrium (MSNE) theoretically prescribes a probability distribution over <lb/>possible actions that ensures to each involved agent that they would have no incentive to deviate if they <lb/>all follow it, in practice, however, humans have been found to typically deviate from this equilibrium [6]. In <lb/>repeated games, patterns of aggregated choices have been sometimes found to converge towards <lb/>MSNE [8] while other studies have found a strong departure from MSNE [7]. Importantly, following MSNE <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>27 <lb/></page>

			<body>requires for each subject to show some level of randomness in their behavior. This enables subjects in <lb/>practice to approximately stick to the action probability distribution prescribed by the MSNE without <lb/>displaying a trivial repetitive behavior which would have entailed the risk to be detected/predictable by the <lb/>opponent. This empirical finding is surprising as humans have been systematically proved to be bad <lb/>randomizers [9]. Indeed, serial dependency in between actions is usually observed [10], leading authors <lb/>to suggest that learning might lead to MSNE [11], [12]. Here the employed asymmetric structure of our <lb/>game enabled to bring further insight about some of the conditions in which humans can deviate from <lb/>MSNE. Introducing a focal point in the game payoff matrix pushed disadvantaged players to deviate from <lb/>MSNE, while forming accurate beliefs over their opponent allowed these subjects to reduce their <lb/>disadvantage in total earnings and to play closer to the MSNE. <lb/>Previous studies also used a computational approach to capture as precisely as possible the choice <lb/>behavior of humans in repeated 2x2 games [28], [36], [37]. We went a step further and manipulated the <lb/>interaction structure to show that the level of the strategic sophistication of individual&apos;s learning drives the <lb/>formation of higher order beliefs and allows them to disengage from the attractions of immediate <lb/>outcomes and move closer to optimality. <lb/>Crucially, no correlation was found in any of the 2 experiments between the SL level of the subjects, in <lb/>any of the two roles, and the one of the opponent. This result replicates the correlation in strategic <lb/>learning level found in previous studies in which humans were confronted to different opponents also <lb/>varying in their SL level [24], [38]. It is worth noting, however, that recent research suggests that <lb/>arbitration between model-free and model-based learning can be affected by the volatility of the <lb/>environment [39]. Indeed, in our two experiments most of the subjects did engage in a rudimentary form <lb/>of belief-learning which does not reject the hypothesis that parts of a subject&apos;s learning mechanisms may <lb/>be with low sophistication (model-free). Moreover, our computational approach was meant to measure <lb/>the overall level of strategic learning sophistication embedded in individual choice series, and does not <lb/>allow to track local changes in strategy. In fact, as previously observed [40], [41], [42], the SL level of the <lb/>opponent strongly impacted the behavior of the subjects interacting in the advantageous position. <lb/>However, in our study the influence of these subjects&apos; own SL level on their choice behavior was reported <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>28 <lb/></page>

			<body>as weaker than the influence of their opponent. One hypothesis for this result is that the sophistication of <lb/>their beliefs did not condition their behavior, which obviously comes in contradiction with the above-cited <lb/>literature. An alternative hypothesis is that the accuracy of their beliefs was already sufficient to maximize <lb/>(up to a certain individual threshold) their earnings, and that engaging in higher level of strategic learning <lb/>did not present a net advantage. We argue that the present study provides the first experimental evidence <lb/>in favor of the latter explanation. First subjects playing in the advantageous role won on average more <lb/>points throughout the interaction than their opponent, even when opposed to a high SL computerized <lb/>agent (t(70)=2.7833, p=0.0069, Fig.6.B). Second, albeit good performance, these subjects presented low <lb/>consistency in SL level across interactions in both experiments. Third, their behavior was correlated to <lb/>planning and problem-solving scores captured in additional tasks in the first interaction block only, while <lb/>in the second block conjunctional evidence of behavioral re-adjustment (faster choices for no change in <lb/>performance) were observed. <lb/>In contrast, disadvantaged subjects behavior were found to be solely conditioned by their own level of <lb/>strategic engagement, not the one of their opponent. They also presented much higher consistency <lb/>across interactions, and evidence of a correlation between working-memory and their SL level was found. <lb/>Crucially, the role endorsed in the repeated game did not seem to impact the SL level of the subjects in <lb/>either of our experiments. <lb/>Altogether, our results suggest a dissociation between a strategic learning engagement bounded by <lb/>individual cognition for subjects endorsing the disadvantaged position, and what has been proposed to <lb/>resemble a cost-benefit analysis process [43] for the subjects ensured to dominate the interaction at <lb/>lower SL level. This distinction between bounded cognition and bounded rationality in suboptimal play has <lb/>also been observed in static games by Friedenberg et al [31]. <lb/>In behavioral game theory the concept of bounded rationality broadly assumes that the capacity of the <lb/>agents to grasp and use all the required information leading to equilibrium are somehow constrained [44]. <lb/>In this line, a theoretical framework which has accumulated growing support in the past decade has been <lb/>proposed to explain deviations from optimal choices in static games: level-k models [15]. This class of <lb/>model relaxes the assumption of full rationality and assumes that players actually best respond to <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>29 <lb/></page>

			<body>incomplete beliefs varying among individuals in their degree of sophistication (k) over the behavior of their <lb/>opponent, themselves considered as only capable of a lower order of beliefs (k-1 or &lt;1, see [45]). This <lb/>hierarchical organization of beliefs is very close to the computational framework previously developed in <lb/>[25], and that we used in this study. In our approach, strategic learning sophistication (SL) is modeled as <lb/>a hierarchy of different levels of computations: SL0 corresponds to reinforcement learning which <lb/>computes action values based on the past reward experienced and is agnostic about the choice behavior <lb/>of the opponent; SL1 is modeled as a fictitious play which best responds to the opponent&apos;s probability <lb/>distribution computed from its past choices; SL2 is modeled as an influence learning process which <lb/>assumes that the opponent is also learning in a way analog to a fictitious play and thus that its own past <lb/>actions can have an influence over the action probability of the other (we also included a SL2+ learning <lb/>rule that considers that the opponent is also learning through influence). Based on this correspondence <lb/>between the 2 classes of models, we have hypothesized that a direct mapping might exist between the <lb/>level k in static games and the SL level in repeated interactions [26]. We tested this hypothesis but failed <lb/>to reject a direct correlation between the two measures of strategic sophistication (see Text S1). <lb/>Nevertheless, we observed that for the subjects endorsing the disadvantaged position in the repeated <lb/>game, a correlation was found between their strategic reasoning (level k) and the frequency of play close <lb/>to the MSNE in the very first trials of the first interaction. This result therefore suggests another type of <lb/>relationship between the strategic reasoning and strategic learning models of bounded rationality: at first, <lb/>when beliefs cannot be anchored in enough observations, subjects with a strong incentive to take over <lb/>the interaction are guided by their ability to reason in an iterative fashion (level k); but when enough <lb/>experience is accumulated, subjects with the capacity to engage in strategic learning form and update <lb/>beliefs as accurate as possible over their opponent&apos;s behavior. This hypothesis appears promising to us <lb/>since it echoes other research on the influence of priors in social inference [46], and therefore calls for <lb/>proper testing in laboratory. <lb/>It is worth noting that another source of sub-optimality has been suggested in the behavioral economics <lb/>literature: heterogeneity in best response. It has been proposed that social preferences for instance could <lb/>bend utility functions [47]. If our study did not allow to directly test this hypothesis, we still observed a <lb/>higher strategic engagement in advantaged subjects capable of high strategic learning when confronted <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>30 <lb/></page>

			<body>to an algorithm compared to another human (social framing effect as in [24]). This result might suggest <lb/>that social preferences such as altruism or sensitivity to inequity could be reflected in a lower exploitation <lb/>of their advantageous position when playing with a human counterpart [48]. <lb/>Altogether, our results reveal three possible sources of variability in strategic behavior during repeated <lb/>game interactions, which makes this behavior not simply constrained by the subjects&apos; cognitive capacities <lb/>only, and can thus help reconcile previous contradictory findings that subjects&apos; strategic behavioral <lb/>performance can be either predicted by their cognitive capacity [49], [50] or not [24]. The first source of <lb/>variability, that we call exogenous, is driven by external factors such as the payoff structure, the salience <lb/>of the different outcomes of the game, and also the prior knowledge over the opponent. A second source <lb/>of heterogeneity in game play is endogenous, with differences in social preferences but also motivation <lb/>[51] or sensitivity to rewards [52]. Finally, a third type of variance emerges from the two previous ones <lb/>along experience with the repeated game, leading to specific dynamics of repeated choice behavior. <lb/>Indeed, even if our experimental setting did not allow further investigation of the phenomenon, it seems <lb/>clear that the SL level of subjects in the disadvantageous position drove the interaction, while their <lb/>opponent in the dominant position would simply track and adapt to changes in behavior and ultimately <lb/>followed them. Leader-follower dynamics have been observed in repeated games [53]. However, a <lb/>precise understanding of the underlying behavioral forces remain unclear [54]. Predicting the learning <lb/>dynamics in play by tuning the structure of the interaction can help study critical behavior such as <lb/>strategic teaching [55]. <lb/>The present study brings further support to the pertinence of the cognitive neuroscience framework of <lb/>learning for the analysis of repeated non-cooperative game behavior. Moreover, we advocate in favor of <lb/>the use of model simulations in the field, that 1) allow to take the most of a normative framework to <lb/>optimize experimental design and make precise predictions regarding the expected results [56] and 2) <lb/>open the possibility to refine agent-based simulation analyses in order to better characterize the interplay <lb/>between the level of strategic learning and the structure of the game underlying the repeated interaction. <lb/></body>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>31 <lb/></page>

			<body>At a broader scope, this study points in the direction of a systematic consideration of between-subjects <lb/>differences and the interaction effect between human variance in learning and the way strategic <lb/>interactions are constrained. Taking into consideration asymmetric facilitation can help study the <lb/>emergence of social hierarchy and strategic dominance in interactions [57], but also better understand <lb/>how inequity arising from the interaction between the environment and endogenous differences could be <lb/>reduced in real-life social interactions [58]. <lb/></body>

			<div type="annex">CONFLICT OF INTEREST STATEMENT <lb/>The authors have declared that no competing interests exist. <lb/></div>

			<div type="funding">FUNDINGS <lb/>This study was supported by the European Research Council (ERC Consolidator Grant 617629), by the <lb/>French Agence Nationale de la Recherche (ANR-12-CORD-0030), by Sorbonne-Universités (SU-15-R-<lb/>PERSU-14), by the Centre National de la Recherche Scientifique (Osez l&apos;Interdisciplinarité Program, <lb/>ROBAUTISTE Project), and two department-wide grants from the French National Research Agency <lb/>(ANR-10-LABX-0087 IEC and ANR-10-IDEX-0001-02 PSL). The funders had no role in study design, <lb/>data collection and analysis, decision to publish, or preparation of the manuscript. <lb/></div>

			<div type="acknowledgement">ACKNOWLEDGMENTS <lb/>We would like to thank Jan Drugowitsch for letting us use his matlab toolbox of optimization through slice <lb/>sampling. <lb/></div>

			<div type="annex">SUPPORTING INFORMATION <lb/>Text S1 <lb/>This is a document containing supporting information regarding models, statistical methods, experimental <lb/>details, additional data analyses. <lb/></div>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>32 <lb/></page>

			<listBibl>REFERENCES <lb/>[1] Schaafsma SM, Pfaff DW, Spunt RP, Adolphs R. Deconstructing and reconstructing theory of mind. <lb/>Trends in cognitive sciences. 2015 Feb 28;19(2):65-72. <lb/>[2] Pacherie E &amp; Khamassi, M. Action. In Andler, D., Collins, T. and Tallon-Baudry, C. (Eds) La cognition. <lb/>Paris, France: Gallimard. 2017 In press. <lb/>[3] Koster-Hale J, Saxe R. Theory of mind: a neural prediction problem. Neuron. 2013 Sep 4;79(5):836-<lb/>48. <lb/>[4] Lee D. Game theory and neural basis of social decision making. Nature neuroscience. 2008 Apr <lb/>1;11(4):404-9. <lb/>[5] Nash JF. Equilibrium points in n-person games. Proceedings of the national academy of sciences. <lb/>1950 Jan 15;36(1):48-9. <lb/>[6] Camerer C. Behavioral game theory: Experiments in strategic interaction. Princeton University Press; <lb/>2003 Mar 17. <lb/>[7] Goeree JK, Holt CA. Ten little treasures of game theory and ten intuitive contradictions. American <lb/>Economic Review. 2001 Dec 1:1402-22. <lb/>[8] Fudenberg D, Levine DK. Learning and equilibrium. Annu. Rev. Econ.. 2009 Sep;1(1):385-420. <lb/>[9] Gauvrit N, Zenil H, Soler-Toscano F, Delahaye JP, Brugger P. Human behavioral complexity peaks at <lb/>age 25. PLoS computational biology. 2017 Apr 13;13(4):e1005408. <lb/>[10] Shachat JM. Mixed strategy play and the minimax hypothesis. Journal of Economic Theory. 2002 <lb/>May 1;104(1):189-226. <lb/>[11] Erev I, Roth AE. Predicting how people play games: Reinforcement learning in experimental games <lb/>with unique, mixed strategy equilibria. American economic review. 1998 Sep 1:848-81. <lb/>[12] Fudenberg D, Levine DK. The theory of learning in games. MIT press; 1998. <lb/>[13] Camerer CF, Ho TH, Chong JK. Behavioural game theory: Thinking, learning and teaching. In <lb/>Advances in Understanding Strategic Behaviour 2004 (pp. 120-180). Palgrave Macmillan UK. <lb/>[14] Barros G. Herbert A. Simon and the concept of rationality: boundaries and procedures. Revista de <lb/>economia política. 2010 Sep;30(3):455-72. <lb/></listBibl>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>33 <lb/></page>

			<listBibl>[15] Crawford VP, Costa-Gomes MA, Iriberri N. Structural models of nonequilibrium strategic thinking: <lb/>Theory, evidence, and applications. Journal of Economic Literature. 2013 Mar 1;51(1):5-62. <lb/>[16] Polonio L, Di Guida S, Coricelli G. Strategic sophistication and attention in games: an eye-tracking <lb/>study. Games and Economic Behavior. 2015 Nov 30;94:80-96. <lb/>[17] Schilbach L, Timmermans B, Reddy V, Costall A, Bente G, Schlicht T, Vogeley K. A second-person <lb/>neuroscience in interaction. Behavioral and brain sciences. 2013 Aug;36(4):441-62. <lb/>[18] Dennett DC. The intentional stance. 1987. Cambridge, MA. 1987. <lb/>[19] Doll BB, Simon DA, Daw ND. The ubiquity of model-based reinforcement learning. Current opinion in <lb/>neurobiology. 2012 Dec 31;22(6):1075-81. <lb/>[20] Doll BB, Duncan KD, Simon DA, Shohamy D, Daw ND. Model-based choices involve prospective <lb/>neural activity. Nature neuroscience. 2015 May 1;18(5):767-72. <lb/>[21] O&apos;Doherty JP. The problem with value. Neuroscience &amp; Biobehavioral Reviews. 2014 Jun 30;43:259-<lb/>68. <lb/>[22] Joiner J, Piva M, Turrin C, Chang SW. Social learning through prediction error in the brain. npj <lb/>Science of Learning. 2017 Jun 16;2(1):8. <lb/>[23] Ruff CC, Fehr E. The neurobiology of rewards and values in social decision making. Nature Reviews <lb/>Neuroscience. 2014 Aug 1;15(8):549-62. <lb/>[24] Devaine M, Hollard G, Daunizeau J. The social Bayesian brain: does mentalizing make a difference <lb/>when we learn?. PLoS computational biology. 2014 Dec 4;10(12):e1003992. <lb/>[25] Hampton AN, Bossaerts P, O&apos;Doherty JP. Neural correlates of mentalizing-related computations <lb/>during strategic interactions in humans. Proceedings of the National Academy of Sciences. 2008 May <lb/>6;105(18):6741-6. <lb/>[26] Griessinger T, Coricelli G. The neuroeconomics of strategic interaction. Current Opinion in Behavioral <lb/>Sciences. 2015 Jun 30;3:73-9. <lb/>[27] Lee D, Seo H. Neural basis of strategic decision making. Trends in neurosciences. 2016 Jan <lb/>31;39(1):40-8. <lb/>[28] Hill CA, Suzuki S, Polania R, Moisa M, O&apos;Doherty JP, Ruff CC. A causal account of the brain network <lb/>computations underlying strategic social behavior. Nature Neuroscience. 2017 Aug 1;20(8):1142-9. <lb/></listBibl>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>34 <lb/></page>

			<listBibl>[29] Beckenkamp M, Hennig-Schmidt H, Maier-Rigaud FP. Cooperation in symmetric and asymmetric <lb/>prisoner&apos;s dilemma games. <lb/>[30] Feldman M, Kalai A, Tennenholtz M. Playing Games without Observing Payoffs. InICS 2010 (pp. <lb/>106-110). <lb/>[31] Friedenberg A, Kets W, Kneeland T. Bounded Reasoning: Rationality or Cognition. 2016. <lb/>[32] Hyndman K, Terracol A, Vaksmann J. Learning and sophistication in coordination games. <lb/>Experimental Economics. 2009 Dec 1;12(4):450-72. <lb/>[33] Shteingart H, Loewenstein Y. Reinforcement learning and human behavior. Current Opinion in <lb/>Neurobiology. 2014 Apr 30;25:93-8. <lb/>[34] Bosworth SJ. The importance of higher-order beliefs to successful coordination. Experimental <lb/>Economics. 2017 Mar 1;20(1):237-58. <lb/>[35] Coricelli G. Strategic interaction in iterated zero-sum games. Homo Oeconomicus, forthcoming. 2005. <lb/>[36] Ho TH, Camerer CF, Chong JK. Self-tuning experience weighted attraction learning in games. <lb/>Journal of Economic Theory. 2007 Mar 31;133(1):177-98. <lb/>[37] Marchiori D, Warglien M. Predicting human interactive learning by regret-driven neural networks. <lb/>Science. 2008 Feb 22;319(5866):1111-3. <lb/>[38] Shachat J, Swarthout JT. Learning about learning in games through experimental control of strategic <lb/>interdependence. Journal of Economic Dynamics and Control. 2012 Mar 31;36(3):383-402. <lb/>[39] Simon DA, Daw ND. Environmental statistics and the trade-off between model-based and TD <lb/>learning in humans. InAdvances in neural information processing systems 2011 (pp. 127-135). <lb/>[40] Duersch P, Kolb A, Oechssler J, Schipper BC. Rage against the machines: how subjects play against <lb/>learning algorithms. Economic Theory. 2010 Jun 1;43(3):407-30. <lb/>[41] Seo H, Cai X, Donahue CH, Lee D. Neural correlates of strategic reasoning during competitive <lb/>games. Science. 2014 Oct 17;346(6207):340-3. <lb/>[42] Spiliopoulos L. Strategic adaptation of humans playing computer algorithms in a repeated constant-<lb/>sum game. Autonomous agents and multi-agent systems. 2013 Jul 1:1-30. <lb/>[43] Alaoui L, Penta A. Endogenous depth of reasoning. The Review of Economic Studies. 2015 Oct <lb/>29;83(4):1297-333. <lb/></listBibl>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>35 <lb/></page>

			<listBibl>[44] Simon HA. Bounded rationality and organizational learning. Organization science. 1991 <lb/>Feb;2(1):125-34. <lb/>[45] Camerer CF, Ho TH, Chong JK. A psychological approach to strategic thinking in games. Current <lb/>Opinion in Behavioral Sciences. 2015 Jun 30;3:157-62. <lb/>[46] Chambon V, Domenech P, Jacquet PO, Barbalat G, Bouton S, Pacherie E, Koechlin E, Farrer C. <lb/>Neural coding of prior expectations in hierarchical intention inference. Scientific Reports. 2017 Apr <lb/>28;7(1):1278. <lb/>[47] Fehr E, Camerer CF. Social neuroeconomics: the neural circuitry of social preferences. Trends in <lb/>cognitive sciences. 2007 Oct 31;11(10):419-27. <lb/>[48] Silk JB, House BR. The evolution of altruistic social preferences in human groups. Phil. Trans. R. <lb/>Soc. B. 2016 Feb 5;371(1687):20150097. <lb/>[49] Carpenter J, Graham M, Wolf J. Cognitive ability and strategic sophistication. Games and Economic <lb/>Behavior. 2013 Jul 31;80:115-30. <lb/>[50] Gill D, Prowse VL. Cognitive ability and learning to play equilibrium: A level-k analysis. Analysis. <lb/>2012 Apr 2. <lb/>[51] Schmidt L, Lebreton M, Cléry-Melin ML, Daunizeau J, Pessiglione M. Neural mechanisms underlying <lb/>motivation of mental versus physical effort. PLoS biology. 2012 Feb 21;10(2):e1001266. <lb/>[52] Kim SH, Yoon H, Kim H, Hamann S. Individual differences in sensitivity to reward and punishment <lb/>and neural activity during reward and avoidance learning. Social cognitive and affective neuroscience. <lb/>2015 Sep 1;10(9):1219-27. <lb/>[53] Seip KL, Grøn Ø. Leading the game, losing the competition: identifying leaders and followers in a <lb/>repeated game. PloS one. 2016 Mar 11;11(3):e0150398. <lb/>[54] Sato Y, Akiyama E, Farmer JD. Chaos in learning a simple two-person game. Proceedings of the <lb/>National Academy of Sciences. 2002 Apr 2;99(7):4748-51. <lb/>[55] Camerer CF, Ho TH, Chong JK. Sophisticated experience-weighted attraction learning and strategic <lb/>teaching in repeated games. Journal of Economic theory. 2002 May 1;104(1):137-88. <lb/>[56] Palminteri S, Wyart V, Koechlin E. The Importance of Falsification in Computational Cognitive <lb/>Modeling. Trends in Cognitive Sciences. 2017 May 2. <lb/></listBibl>

			<note place="headnote">Sophisticated learning in social competitive interactions <lb/></note>

			<page>36 <lb/></page>

			<listBibl>[57] Qu C, Ligneul R, Van der Henst JB, Dreher JC. An Integrative Interdisciplinary Perspective on Social <lb/>Dominance Hierarchies. Trends in Cognitive Sciences. 2017 Sep 12. <lb/>[58] Decety J, Yoder KJ. The emerging social neuroscience of justice motivation. Trends in cognitive <lb/>sciences. 2016 Nov 16. </listBibl>


	</text>
</tei>
