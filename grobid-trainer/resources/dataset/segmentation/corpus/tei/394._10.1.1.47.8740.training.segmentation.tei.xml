<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Bounds on the Time to Detect Failures <lb/>Using Bounded-capacity Message Links <lb/>Stephen Ponzio <lb/>MIT Laboratory for Computer Science <lb/>Abstract <lb/>We consider a system of distributed processors that <lb/>communicate by passing messages and that have in-<lb/>exact information about time. Speci cally, a proces-<lb/>sor knows that a single message is delayed by at most <lb/>time d and the time between any two of its consec-<lb/>utive steps is at least c 1 and at most c 2 ; it has no <lb/>other way of estimating elapsed time. This simple <lb/>model is very close to traditional models used in dis-<lb/>tributed computing theory, and has been studied by <lb/>Attiya and Lynch 2, 1] among others. We extend <lb/>the model by making a realistic assumption about <lb/>how the delay of messages is a ected by the rate at <lb/>which they are sent. We de ne a model of message <lb/>links with bounded capacity, which are guaranteed to <lb/>deliver messages at only a given rate. If a proces-<lb/>sor sends messages at a greater rate, they may incur <lb/>greater delay. <lb/>We quantify the e ect of this bounded capacity on <lb/>the time necessary to detect processor failures. We <lb/>consider a system of two processors connected by a <lb/>bi-directional message link of (integral) capacity . <lb/>First we give two very simple protocols that guar-<lb/>antee any stopping failure will be detected within <lb/>time 2Cd + d and C 2 d= + Cd + d respectively, <lb/>where C = c 2 =c 1 . The main result is an almost-<lb/>matching lower bound of 2Cd+d= or C 2 d= +Cd+d, <lb/>whichever is less. If the link is uni-directional, our re-<lb/>sult specializes to give a matching upper and lower <lb/>bound of C 2 d= + Cd + d. <lb/>Supported by an NSF Graduate Fellowship <lb/></front>

			<body>1 Introduction <lb/>In fault-tolerant distributed algorithms, a common <lb/>primitive for detecting failures is to \time out&quot; failed <lb/>processors. If processors fail by simply stopping, then <lb/>a failure may be detected by the absence of mes-<lb/>sages from a processor. We consider how quickly <lb/>such failures can be detected in a semi-synchronous <lb/>model where processors have inexact information <lb/>about time, subject to realistic assumptions about <lb/>message links. <lb/>We use a very high level of abstraction of message <lb/>links; for our purposes, the \message link&quot; consists <lb/>of all processing at levels lower than the process or <lb/>code that is actually implementing the timeout algo-<lb/>rithm. The delay of a message is taken to be the to-<lb/>tal amount of time that elapses between the processor <lb/>step at which the algorithm code speci es that a mes-<lb/>sage should be sent and when the recipient processor <lb/>reads in that message. At our level of abstraction, <lb/>a message link is assumed to be completely reliable, <lb/>delivering all messages in the order sent. We will as-<lb/>sume that all messages are of some xed length, and <lb/>ignore the possible a ect of a message&apos;s length on its <lb/>delay. <lb/>For simplicity, we consider a system of two <lb/>processors. 1 A processor may send messages only at <lb/>atomic steps (which take zero time). It knows that <lb/>the time between each pair of its consecutive steps is <lb/>at least c 1 and at most c 2 . These bounds hold for <lb/>each processor and are common knowledge to each. <lb/>A processor cannot tell directly how much time has <lb/>elapsed between two particular steps|only that the <lb/></body>

			<note place="footnote">1 In 1], where systems of n processors are considered, it is <lb/>assumed that each pair of processors is connected by a pri-<lb/>vate bidirectional message link. There, it is natural to assume <lb/>that a timeout protocol executes independently for each pair of <lb/>processors. If we measure \detection time&quot; to be from failure <lb/>until detection by every processor, the bounds hold without <lb/>this assumption. <lb/></note>

			<body>elapsed time is within these bounds. For each model <lb/>of message links considered, a message sent in the <lb/>absence of other messages is always delivered within <lb/>time d of when it is sent. We are interested in the <lb/>worst-case time between when a processor fails and <lb/>when the failure is detected by the other processor. <lb/>If it is assumed that every message is delivered <lb/>within time d of when it is sent (regardless of mes-<lb/>sage tra c|\unbounded capacity&quot;), then the follow-<lb/>ing simple protocol minimizes the time between any <lb/>failure and its detection. 2 Each processor sends a <lb/>message at every step that it takes. If a proces-<lb/>sor takes more than (d + c 2 )=c 1 steps without re-<lb/>ceiving a message, it declares the other processor <lb/>faulty. We see that non-failed processors are never <lb/>declared faulty: the time between delivery of any <lb/>two consecutive messages is at most c 2 + d and at <lb/>least this much time|(d + c 2 )=c 1 steps, each tak-<lb/>ing at least time c 1 |is waited by the recipient be-<lb/>fore declaring the sender faulty. The maximum time <lb/>between a failure and its detection is approximately <lb/>Cd + d, where C = c 2 =c 1 , occurring in the follow-<lb/>ing scenario: processor p broadcasts a message at <lb/>time t and then fails immediately; this message is <lb/>delivered to q at time t + d; after receiving this mes-<lb/>sage, processor q runs slowly (its steps separated by <lb/>c 2 ) and thus p&apos;s failure is not detected until time <lb/>t + d + c 2 ((d + c 2 )=c 1 ) = t + d + C(d + c 2 ). It is not <lb/>di cult to show that this detection time is optimal. <lb/>Although the above protocol guarantees minimal <lb/>delay between any failure and its detection, it requires <lb/>sending messages nearly continuously. It relies on <lb/>the strong assumption that all messages are delivered <lb/>within time d, regardless of the rate at which they are <lb/>sent. In reality, the rate at which a processor issues <lb/>messages may be much greater than the rate at which <lb/>messages may be actually sent and delivered. In such <lb/>a case, lower-level processing bu ers the messages by <lb/>holding them in a queue in memory until they can ac-<lb/>tually be sent. If messages are continually issued at a <lb/>rate greater than they can be sent, then the number <lb/>of queued messages grows without bound. Thus there <lb/>is an upper bound on the rate at which messages can <lb/>be issued before such backup occurs. It is precisely <lb/>this rate that will a ect the bound on detection time. <lb/>Our model gleans this rate by the following reasoning. <lb/>The maximum total delay d of a single message may <lb/>account for several levels of processing. It is therefore <lb/></body>

			<note place="footnote">2 This is the strategy employed in the algorithms of 1] and <lb/>6], which assume such unbounded-capacity message links. <lb/></note>

			<body>likely that although one message is sent at time t and <lb/>delivered at time t + d, another message may be sent <lb/>before time t + d without a ecting the total delay of <lb/>the second message. That is, messages sent between <lb/>the processors (algorithm code) may be pipelined to <lb/>some degree. The number of messages that can be in <lb/>transit between the processors without a ecting the <lb/>total delay of any message correponds roughly to our <lb/>notion of the \capacity&quot; of a message link. In our <lb/>model, if all messages sent are separated by at least <lb/>time d= , then each one is delivered within time d; <lb/>if two messages are sent within less than time d= of <lb/>each other, the second message may be delayed by <lb/>more than d. This is the essential property of the <lb/>message links we will consider. Our upper bounds <lb/>depend only on this property; our lower bounds de-<lb/>pend only on the property that if messages are sent <lb/>at too great a rate then they become backed up and <lb/>their delay grows. <lb/>We rst give two very simple protocols that guaran-<lb/>tee any stopping failure will be detected within time <lb/>2Cd+d and C 2 d= +Cd+d respectively. The main re-<lb/>sult is an almost-matching lower bound of 2Cd+d= <lb/>or C 2 d= + Cd + d, whichever is less. Note that the <lb/>rst expression of the lower bound is not tight with <lb/>the rst expression of the upper bound. If the link is <lb/>uni-directional, our result specializes to give a match-<lb/>ing upper and lower bound of C 2 d= + Cd + d. <lb/>2 Model and de nitions <lb/>Our underlying formal model is that proposed by <lb/>Lynch and Attiya 2, 1], following the timed automata <lb/>model of 5]. We consider a system of two processors, <lb/>p and q. Each processor is a deterministic (possi-<lb/>bly in nite) state machine. Formally, an execution <lb/>of the algorithm is a sequence of con gurations alter-<lb/>nated with events. A con guration is a vector of the <lb/>processors&apos; local states. Each event has a real time <lb/>associated with it and these times are non-decreasing <lb/>with the sequence. Events are of three types: <lb/>1. A processor computation step. In a computa-<lb/>tion step, a processor, based on its local state, <lb/>may perform local computation and send a -<lb/>nite number of messages to other processor(s). <lb/>2. A message delivery, del(m; x). A message de-<lb/>livery event may denote the delivery of a mes-<lb/>sage to a processor (del(m; p)) or to a message <lb/>link (del(m; `)). If a message delivery event de-<lb/>notes the delivery of a message m to a processor <lb/>p, p may change its local state according to m <lb/>and its current state (i.e., \remember&quot; the de-<lb/>livered message). Events corresponding to mes-<lb/>sages \delivered&quot; to links serve only to mark the <lb/>time at which a message is sent, as explained in <lb/>the next section. <lb/>3. A processor failure. During a failure step, a pro-<lb/>cessor&apos;s normal computation transition function <lb/>is applied to its local state, but only a subset <lb/>of the speci ed messages are actually sent and <lb/>the processor goes into a permanent failed state. <lb/>In all subsequent steps, it remains in the failed <lb/>state. <lb/>For further details and precise formalism, we refer the <lb/>reader to 1]. Our formalism for messages links cap-<lb/>tures their interaction with processors by considering <lb/>a message m sent by p to q at time t to be \deliv-<lb/>ered&quot; at time t to the message link connecting p and <lb/>q. That is, we consider only executions in which ev-<lb/>ery computation event at which a message m is sent is <lb/>followed by a delivery event del(m; `) with the same <lb/>real time, where `is the appropriate message link. If <lb/>the message link has unbounded capacity (like those <lb/>in 1, 6]), then valid executions must include an event <lb/>no later than time t + d corresponding to the deliv-<lb/>ery of m at q. For simplicity, we will assume that <lb/>message links deliver messages in the order sent. Our <lb/>algorithms do not make strong use of this assumption <lb/>and our lower bounds hold in spite of it. The formal-<lb/>ism for bounded links is described below. Also, we <lb/>consider only executions in which the successive steps <lb/>of all processors are separated by at least time c 1 and <lb/>at most c 2 . Note that a processor does not \know&quot; <lb/>directly the time between two particular steps|this <lb/>quantity is not an argument to the state transition <lb/>function. Although it is not necessary for the proof, <lb/>we will generally assume that c 2 d: processor step <lb/>time is very small compared to the maximummessage <lb/>delay time. In the analysis, we therefore approximate <lb/>the quantity d + c 2 by d. <lb/>2.1 Modeling bounded-capacity links <lb/>In modeling bounded-capacity message links, we <lb/>would like to capture the reality that if messages are <lb/>sent too frequently, they may take longer to be deliv-<lb/>ered. <lb/>We de ne a message link of unit capacity and delay <lb/>d from p to q as follows: if p sends a message m to <lb/>q at time t and t 0 is the time at which the previous <lb/>message from p to q is delivered to q, then m is deliv-<lb/>ered to q by time max(t; t 0 )+d. If t &lt; t 0 , then we say <lb/>that the message link \queues&quot; m while the previous <lb/>message is \in transit&quot; during the interval (t; t 0 ). For <lb/>positive integer , we de ne a message link of capacity <lb/>and delay d as the serial composition of message <lb/>links `1; : : :; ` , each of unit capacity and delay d= . <lb/>These links are connected serially so that messages <lb/>are delivered from `i to link `i+1 (1 i &lt; ) and ` <lb/>delivers messages to the recipient process. Formally, <lb/>we consider only executions in which the computa-<lb/>tion event with the sending of m is followed by a <lb/>del(m; `1) event at the same time, and every deliv-<lb/>ery event del(m; `i) is followed by a delivery event <lb/>del(m; `i+1 ) (or del(m; p) if i = ) within time d= . <lb/>We note that this model does not necessarily cor-<lb/>respond to physical reality, but is meant to capture <lb/>the degree of message pipelining available between <lb/>the highest level processors that are exchanging mes-<lb/>sages. It is this parameter, the number of messages <lb/>that may be \in transit&quot; at the same time without <lb/>an increase in their delay, which a ects the e ciency <lb/>of failure detection. <lb/>Thus, in the absence of any other message traf-<lb/>c, the delay of a single message is bounded by <lb/>d= = d. Note that if a single component link <lb/>delays all messages by its maximum amount, d= , <lb/>then messages are delivered at a maximum rate of <lb/>messages per time d. In particular, it is easy to see <lb/>that if the last component link delays each message <lb/>by d= , then for any interval of time of length l, at <lb/>most <lb/>l l <lb/>d= <lb/>m <lb/>messages are delivered. If no two mes-<lb/>sages are sent within time d= of each other, then <lb/>each message is delivered within time d of when it is <lb/>sent. This is easily seen by induction. For the lower <lb/>bound, we assume only that when a link delays each <lb/>message by the maximum possible amount, at least <lb/>time d= elapses between the delivery of messages. <lb/>For this reason, our results hold for other models of <lb/>message links with capacity and delay d, such as <lb/>d-delay links of unit capacity in parallel, each con-<lb/>nected directly with p and q. <lb/>2.2 Timing out failed processors <lb/>A processor is said to detect the failure of another <lb/>processor when it irrevocably decides that the other <lb/>has failed. A timeout protocol is correct if it satis es <lb/>two properties for all executions and all processors <lb/>p and q: (1) if p fails and q does not fail, then q <lb/>eventually detects the failure of p, and (2) if neither <lb/>p nor q fails, then neither p nor q detects the failure <lb/>of the other. <lb/>For a given execution , we say that p detects the <lb/>failure of q within time T in if q fails at time t <lb/>in and p detects the failure of q at time t 0 t + <lb/>T in ,. We say a timeout protocol guarantees a <lb/>detection time of T if for all processors p and q and <lb/>all executions in which p fails but q does not, q <lb/>detects the failure of p within time T in . <lb/>3 Simple upper bounds <lb/>An upper bound of 2Cd + d is achieved by a sim-<lb/>ple protocol that works for any link capacity. The <lb/>two processors continually exchange a single \token&quot; <lb/>message: when p receives the token message from q, <lb/>it sends the token message back to q, and q does like-<lb/>wise. If a processor takes more than 2(d + c 2 )=c 1 <lb/>steps without receiving a message, it concludes that <lb/>the other processor is faulty. Because there is at most <lb/>one message in transit at any time, it is always de-<lb/>livered within time d of when it is sent. Clearly a <lb/>nonfaulty processor is never timed out. This proto-<lb/>col guarantees that any failure is detected within time <lb/>2Cd + d (to be precise, d + 2C(d + c 2 ) + c 2 ; recall we <lb/>approximate d + c 2 d): if p fails at time t, then <lb/>by time t + d all of the messages it has sent to q are <lb/>delivered and q has sent its last message to p; within <lb/>another time c 2 (1 + 2(d + c 2 )=c 1 ) 2Cd, q has taken <lb/>enough steps to conclude that p has failed. <lb/>An upper bound of C 2 d= + Cd + d is achieved <lb/>by a one-way protocol in which each processor sends <lb/>a message every (d= )=c 1 steps. This is \one-way&quot; <lb/>in the sense that only messages from p to q are <lb/>used to detect the failure of p and these messages <lb/>are independent of messages from q to p. A pro-<lb/>cessor concludes that the other has failed if it takes <lb/>more than (Cd= + d)=c 1 steps without receiving a <lb/>message. Clearly, the sending times of every two <lb/>messages are separated by at least time d= and <lb/>therefore, as shown in Section 2.1, each message is <lb/>delivered within time d of when it is sent. The <lb/>maximum amount of time between the delivery of <lb/>two consecutive messages from a given processor is <lb/>c 2 (d= )=c 1 + d = Cd= + d (if the rst message is <lb/>delivered immediately, the sender runs slowly, and <lb/>the following message incurs the maximum possible <lb/>delay, d). This is less than the minimum amount <lb/>of time, Cd= + d + c 1 , that the other processor <lb/>waits before detecting failure. This protocol guaran-<lb/>tees a detection time of C 2 d= + Cd + d: if p fails <lb/>at time t, then by time t + d all of the messages <lb/>it has sent are delivered to q; within another time <lb/>c 2 (Cd= + d)=c 1 = C 2 d= + Cd, q has taken enough <lb/>steps to conclude that p has failed. Thus we obtain a <lb/>simple upper bound of min(2Cd+d; C 2 d= +Cd+d). <lb/>4 The lower bound <lb/>We now prove a nearly corresponding lower bound of <lb/>min(2Cd + d= ; C 2 d= + Cd + d). Note that 2Cd + <lb/>d= &lt; C 2 d= + Cd + d if and only if &lt; C + 1. <lb/>Thus, the bounds are tight except for &lt; C + 1; in <lb/>particular, when &lt; C, 2Cd + d is the best upper <lb/>bound and 2Cd + d= is the best lower bound. <lb/>We rst prove that there exists some execution in <lb/>which p runs \fast&quot; (its steps separated by time c 1 ), <lb/>q runs \slowly&quot; (its steps separated by time c 2 ), mes-<lb/>sages from q to p are delivered immediately, messages <lb/>from p to q are delayed by at least time d, and at least <lb/>time d= elapses between when p sends some pair of <lb/>messages. We prove that such an execution is pos-<lb/>sible for any protocol that is guaranteed to detect <lb/>failures within any bounded amount of time. This is <lb/>proved below using the properties of the bounded-<lb/>capacity message links. The idea is that if the last <lb/>component link from p to q delays all messages by <lb/>d= then the delivery of every pair of messages is <lb/>separated by time d= . Therefore, if each pair of <lb/>messages sent by p were separated by less than d= , <lb/>then messages would be sent faster than they were <lb/>delivered. Thus the number of messages sent but <lb/>undelivered and, consequently, the total delay of a <lb/>message, would grow in time without bound. After p <lb/>crashes, the queued messages are still delivered to q, <lb/>and q cannot tell that p has crashed until the queue <lb/>is emptied. <lb/>Lemma 4.1 For any correct timeout protocol that <lb/>guarantees a bounded detection time, there exists an <lb/>execution in which (1) all consecutive steps of p are <lb/>separated by c 1 , of q are separated by c 2 ; (2) all mes-<lb/>sages from q to p are delayed by time 0, from p to <lb/>q are delayed by at least time d; and (3) for any t 0 , <lb/>there exists a pair of messages m 1 and m 2 sent by <lb/>p at times t 1 and t 2 respectively, with no message <lb/>sent by p in between those times, such that t 1 t 0 , <lb/>t 2 ? t 1 d= . <lb/>Figure 1 depicts an example of such an execution. <lb/>q <lb/>p <lb/>(slow) <lb/>(fast) <lb/>q t0 <lb/>. . . <lb/>0 <lb/>0 <lb/>H H H H H H H H H H j <lb/>q <lb/>H H H H H H H H H H j <lb/>d <lb/>d <lb/>(m1 ) <lb/>(m2 ) <lb/>t1 <lb/>t1+d= <lb/>t2 <lb/>q t1+d= +d <lb/>Figure 1: Execution , the existence of which is proved by <lb/>Lemma 4.1, takes the above form except that messages from <lb/>p to q may be delayed more than d and messages may be <lb/>sent by q at arbitrary times. The events of p (q) are on the <lb/>left (right), with time represented by the vertical dimension. <lb/>An arrow represents a message labelled with its delay, with <lb/>its tail at the time of the send event and its tip at the time <lb/>of the receive event. <lb/>Proof: Fix any execution of the protocol in which <lb/>(i) the rst three timing constraints are satis ed, (ii) <lb/>each component link from p to q delays each message <lb/>by time d= , and (iii) no processor fails. Such an <lb/>execution exists because conditions (i), (ii) and (iii) <lb/>are independent of each other and within the bounds <lb/>of the model. Clearly, condition (ii) implies that all <lb/>messages from p to q are delayed at least time d. We <lb/>prove that third condition is also satis ed in . To <lb/>do so, assume for contradiction that it is not. <lb/>First note that because is unbounded in length, <lb/>p must send an unbounded number of messages: if <lb/>it does not, then let m `be the last message that it <lb/>sends and consider an execution in which p fails af-<lb/>ter sending m `. Because q receives the same messages <lb/>from p in each execution, it cannot distinguish be-<lb/>tween the two executions and therefore q either does <lb/>not detect p&apos;s failure in or erroneously decides that <lb/>p has failed in . <lb/>Recall that a processor can send messages only at <lb/>steps and p&apos;s steps are separated by exactly time c 1 <lb/>in . It follows that if two consecutive messages are <lb/>not separated by at least time d= , then they are <lb/>separated by at most k = <lb/>l d= <lb/>c1 <lb/>m ? 1 steps, which is <lb/>time k c 1 &lt; d= . <lb/>Consider the interval t 0 ; t 0 + x] of execution , <lb/>where x is de ned below. Because p sends an un-<lb/>bounded number of messages and, by assumption, ev-<lb/>ery two consecutive messages are separated at most <lb/>time kc 1 , processor p sends at least bx=(kc 1 )c mes-<lb/>sages in this interval. But since the last component <lb/>link delays each message by d= , at most <lb/>l x <lb/>d= <lb/>m <lb/>mes-<lb/>sages are delivered in this interval. Thus the number <lb/>of messages sent but not delivered in this interval is <lb/>at least ( x <lb/>kc1 ? 1) ? ( x <lb/>d= + 1). According to the prop-<lb/>erties of the message links, the last message sent in <lb/>this interval may not be delivered until all prior mes-<lb/>sages have been delivered. Thus the last message sent <lb/>by p in this interval may not be delivered until time <lb/>t 0 +x+ d ( x <lb/>kc1 ? x <lb/>d= ?2). If B is the bound on detec-<lb/>tion time guaranteed by the protocol, then let x be <lb/>large enough so that d ( x <lb/>kc1 ? x <lb/>d= ? 2) &gt; B (recall <lb/>that kc 1 &lt; d= ). <lb/>We conclude that the last message sent by p in the <lb/>interval t 0 ; t 0 + x] of is not delivered until after <lb/>time t 0 +x+B. Since p does not fail in , q does not <lb/>time out p; in particular, q does not time out p before <lb/>time t 0 +x+B. However, before time t 0 +x+B, this <lb/>execution is indistinguishable to q from an execution <lb/>in which p fails at time t 0 + x and which is otherwise <lb/>identical to at p and q up to times t 0 + x and t 0 + <lb/>x+B, respectively. Therefore in this execution q does <lb/>not detect the failure of p within time B. Thus the <lb/>protocol cannot be correct; this contradiction proves <lb/>the lemma. <lb/>Our lower bound proof uses the retiming tech-<lb/>niques of \shifting&quot; events in time and \shrinking&quot; <lb/>portions of executions that were used in 2] and 4]. <lb/>The basic strategy of the proof is as follows. Begin-<lb/>ning with an execution given by Lemma 4.1, we <lb/>know that if p were to fail during the step at which <lb/>it sends m 1 , then q would declare p faulty by time <lb/>t 1 + T. We would like to show that if the bound T <lb/>guaranteed by the algorithm is small, then there is an <lb/>execution in which q declares p faulty though p has <lb/>not failed. Notice that q cannot tell if p has failed <lb/>or not until message m 2 arrives or doesn&apos;t. The idea <lb/>for showing such an execution exists is to ask, what <lb/>if instead, all events at q occurred earlier by d and <lb/>messages from p to q arrived earlier by d? Because <lb/>q does not have a way of telling time absolutely, it&apos;s <lb/>cannot tell the di erence between this execution and <lb/>. (Formally, it&apos;s state transition function takes as <lb/>input only the current state and possibly a delivered <lb/>message and so its sequence of states is the same in <lb/>the two executions.) We say that the two executions <lb/>are indistinguishable to q. Using a similar reasoning, <lb/>we further ask, what if p ran slowly (its steps sepa-<lb/>rated by c 2 ) between the when it sends m 1 and when <lb/>it sends m 2 , and q runs fast (its steps separated by <lb/>c 1 ) after it receives m 1 , and m 2 is delayed by the <lb/>maximum possible amount, d? We are able to show <lb/>that in the resulting execution, q declares p faulty too <lb/>soon|that is, before m 2 arrives. <lb/>We will use the technique above several times, <lb/>where, given an interval of events in which a pro-<lb/>cessor is running slowly (time c 2 between its steps), <lb/>we create a new execution in which that processor <lb/>runs fast over that interval of events (time c 1 between <lb/>its steps). We call this construction \shrinking&quot; that <lb/>interval. Conversely, given an interval in which a pro-<lb/>cessor is running fast, we may create a new execution <lb/>in which we \stretch&quot; that interval. Of course, we <lb/>preserve the order of events at that processor by ac-<lb/>cordingly retiming message delivery events at that <lb/>processor, and we must verify that the timing con-<lb/>straints on message delivery are not violated. This <lb/>may require individually retiming the message deliv-<lb/>ery events at the component message links `2 : : :` . <lb/>This is easily done within the time bounds of each <lb/>individual delivery event, as long as the total delay <lb/>of any message is not increased to be greater than d <lb/>or made less than 0. We will suppress the detail of <lb/>retiming the delivery events at the component links <lb/>and verify only that the total delay of any message is <lb/>within the proper bounds. <lb/>Theorem 4.2 In a system with links of capacity <lb/>and delay d, no correct timeout protocol can guar-<lb/>antee failures to be detected within less than time <lb/>min(2Cd + d= ; C 2 d= + Cd + d). <lb/>Proof: Let T = min(2Cd + d= ; C 2 d= + Cd + d). <lb/>For contradiction, assume the existence of a protocol <lb/>that guarantees a detection time of T. We do not <lb/>make use of the particular value of T until the nal <lb/>step of the proof (the construction of execution 00 ). <lb/>We will reach a contradiction by showing that there <lb/>is an execution of the protocol in which p does not <lb/>fail but q decides that it has. <lb/>Let be an execution of the protocol whose exis-<lb/>tence is implied by Lemma 4.1 with t 0 = d C <lb/>C?1 . <lb/>Let m 1 and m 2 be the two messages speci ed by the <lb/>lemma, sent by p at times t 1 and t 2 respectively. Fig-<lb/>ure 1 depicts an example of an execution satisfying <lb/>Lemma 4.1; for presentation, messages from p to q <lb/>are shown taking exactly time d, and messages from <lb/>q to p are shown sent at arbitrary times. <lb/>Let be an execution in which (i) events at p are <lb/>identical to those of up to time t 1 , (ii) p fails at <lb/>time t 1 after sending m 1 , and (iii) events at q are <lb/>identical to those of up to time t 1 +d= +d. Clearly <lb/>exists, since in , message m 2 does not arrive until <lb/>t 2 +d t 1 +d= +d and thus the state transitions of <lb/>q in are identical those in until this time. Also, <lb/>the assumed protocol guarantees that in , q detects <lb/>the failure of p before time t 1 + T. <lb/>The rest of the proof proceeds as follows. By shift-<lb/>ing the events of q in and , we construct executions <lb/>0 and 0 , which are indistinguishable from and <lb/>respectively, to both p and q. By retiming the events <lb/>of 0 , we construct 00 , which to q is indistinguishable <lb/>from 0 . By retiming the events of 0 , we construct <lb/>00 , which to q is indistinguishable from 00 until the <lb/>event at which it times out p. Execution 00 is also <lb/>indistinguishable to p from 0 until after it sends m 2 . <lb/>Thus, although p does not fail in 00 , q times out p <lb/>in 00 , contradicting the correctness of the assumed <lb/>protocol. <lb/>4.1 Construction of 0 and 0 <lb/>Conceptually, we wish to construct 0 from by let-<lb/>ting each event at q occur earlier in time by d (\shift-<lb/>ing&quot; those events earlier by d). 3 Figure 2 depicts the <lb/>su x of 0 , showing the shifted events of the region <lb/>in which we shall be interested. <lb/>This execution satis es the timing constraints on <lb/>message delivery, since messages sent by p (delayed <lb/>by at least d in ) are received by q at most d earlier in <lb/>0 and hence are delayed by at least 0 in 0 ; messages <lb/>sent by q (delayed by 0 in ) are sent at most d earlier <lb/>in 0 and hence are delayed by at most d in 0 . <lb/>Execution 0 is constructed similarly, shifting ear-<lb/>lier by d the events at q in . <lb/></body>

			<note place="footnote">3 Strictly speaking, this may not be possible for all events at <lb/>q because of initial conditions. However, because we are really <lb/>only interested in shifting the events in the region around t 1 , <lb/>we may \shrink&quot; some earlier interval of the execution, so that <lb/>events subsequent to that interval occur earlier by time d, as <lb/>desired. In particular, we may shrink (by a factor c 2 =c 1 = C) <lb/>the interval 0; C <lb/>C?1 d] of , so that it correspondsto the interval <lb/>0; 1 <lb/>C?1 d] of 0 . Thus the last event of this interval is shifted <lb/>earlier by C <lb/>C?1 d? 1 <lb/>C?1 d = d. Recall that we chose t 0 = C <lb/>C?1 d <lb/>in and t 0 t 1 , so in , the last event of this interval occurs <lb/>before time t 1 , when m 1 is sent; in 0 , the last event of this <lb/>interval occurs at t 0 ? d, before time t 1 ? d . <lb/></note>

			<body>q <lb/>p <lb/>(slow) <lb/>(fast) <lb/>q t0?t0=C <lb/>-<lb/>. . . <lb/>d <lb/>d <lb/>d <lb/>d <lb/>0 <lb/>(m1) <lb/>t1 <lb/>t1+d= <lb/>t1?(d?d= ) <lb/>t1?d <lb/>t1 <lb/>s t1+T?d <lb/>Figure 2: In the region of interest, execution 0 is simply <lb/>with events of processor q occurring earlier in time by d. <lb/>Because p fails at time t1, q detects the failure of p by time <lb/>t1 + T ? d, denoted by the circle. <lb/>Because p and q do not know the time between <lb/>any particular pair of steps they take, they cannot <lb/>distinguish between either and 0 or and 0 . It <lb/>follows that 0 and 0 are not distinguishable to p up <lb/>to the point at which it fails and not distinguishable <lb/>to q up to when it receives m 2 in 0 (which is at least <lb/>time t 2 t 1 + d= ). Also, q&apos;s detection of p&apos;s failure <lb/>occurs before time t 1 + T ? d in 0 . <lb/>4.2 Construction of execution 00 <lb/>Recall that q runs slowly in and 0 |its steps are <lb/>separated by c 2 . We now construct 00 from 0 by re-<lb/>timing certain events at q. Events at p are the same <lb/>as in 0 up to time t 1 , when p fails in both execu-<lb/>tions; events at p after time t 1 are inconsequential to <lb/>the proof and may be de ned arbitrarily within the <lb/>bounds of the model. <lb/>The retiming operation at q maps the interval t 1 ? <lb/>(d?d= ); t 1 +(T ?d)] of 0 to the interval t 1 ? 1 <lb/>C (d? <lb/>d= ); t 1 + 1 <lb/>C (T ? d)] of 00 by letting q run fast over <lb/>this interval in 00 . The mapping shrinks the events <lb/>around time t 1 : events at time t 1 in 0 also occur at <lb/>q <lb/>p <lb/>(fast) <lb/>) <lb/>) <lb/>) <lb/>) <lb/>q t0?t0=C <lb/>-<lb/>. . . <lb/>d?(d?d= )+ 1 <lb/>C (d?d= ) <lb/>00 <lb/>00 <lb/>00 <lb/>0 <lb/>(m1) <lb/>9 <lb/>&gt; &gt; = <lb/>&gt; &gt; ; <lb/>(slow) <lb/>9 <lb/>&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; = <lb/>&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; ; <lb/>(fast) <lb/>t1 <lb/>t1+d= <lb/>t1? 1 <lb/>C (d?d= ) <lb/>t1 <lb/>s t1+ 1 <lb/>C (T ?d) <lb/>Figure 3: Execution 00 is constructed from 0 by mapping <lb/>the interval t1?(d?d= ); t1+(T ?d)] of 0 to the interval <lb/>t1 ? 1 <lb/>C (d ? d= ); t1 + 1 <lb/>C (T ? d)] of 00 and appropriately <lb/>shifting the rest of q&apos;s events. <lb/>t 1 in 00 ; events in the above interval of 0 are retimed <lb/>to occur closer to time t 1 by a factor of C. The rest of <lb/>execution 0 |before time t 1 ?(d?d= ) and after time <lb/>t + (T ? d)|is shifted to preserve the step times of <lb/>events on the borders of this interval. To be precise, <lb/>00 is de ned at q by retiming each event that occurs <lb/>at q at time t 0 1 <lb/>C?1 d in 0 to occur at q at time t 00 <lb/>in 00 , where t 00 is de ned as follows: <lb/>t 00 = <lb/>8 <lb/>&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; <lb/>&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : <lb/>t 0 + (d ? d= ) ? 1 <lb/>C (d ? d= ) <lb/>shift <lb/>if 1 <lb/>C?1 d t 0 t 1 ? (d ? d= ) <lb/>t 1 + 1 <lb/>C (t 0 ? t 1 ) <lb/>shrink <lb/>if t 1 ? (d ? d= ) t 0 t 1 + (T ? d) <lb/>t 0 ? (T ? d) + 1 <lb/>C (T ? d) <lb/>shift <lb/>if t 0 t 1 + (T ? d) <lb/>This execution is illustrated in Figure 3. 4 <lb/></body>

			<note place="footnote">4 Again, we need to shift the events before time t 1 ?(d?d= ) <lb/>while preservinginitial conditions. To do this we partially undo <lb/>the shrinking performed on the interval 0; C <lb/>C?1 d] of . These <lb/>events were mapped to the interval 0; 1 <lb/>C?1 d] of 0 , in which q <lb/>runs fast, with the last event of the interval occurring exactly <lb/>time d earlier in 0 than in . In 00 , we need the last event of <lb/>this interval to occur exactly time (d?d= )? 1 <lb/>C (d?d= ) later <lb/></note>

			<body>By construction, this retiming operation does not <lb/>cause violations of the bounds on processor step <lb/>times. We now verify that 00 is consistent with the <lb/>timing assumptions for message delivery. First note <lb/>that all events at p before time t 1 occur at the same <lb/>time in executions ; ; 0 and 00 . We show that <lb/>for any event at q occurring at time t 00 in 00 and at <lb/>time t in (and hence at t 0 = t ? d in 0 ) such that <lb/>t 00 t 1 and t C <lb/>C?1 d, we have t ? d t 00 &lt; t. By <lb/>the retiming mapping above, if t 0 &lt; t 1 , then <lb/>t 0 t 00 t 0 + (d ? d= ) ? 1 <lb/>C (d ? d= ); <lb/>(this is because t 0 is mapped forward in time furthest <lb/>when t 0 t 1 ? (d ? d= ); least when t 0 = t 1 ) which, <lb/>substituting t 0 = t ? d, gives <lb/>t ? d t 00 &lt; t ? d= ? 1 <lb/>C (d ? d= ) &lt; t: (1) <lb/>In , every message from p to q is delayed by at <lb/>least d. We claim that in 00 , every message from p <lb/>to q is delayed by at least time 0 and by less time <lb/>than in . If a message is delivered at q after time t 1 <lb/>in 00 , then because p sends no messages after time <lb/>t 1 , it must be sent by t 1 (no new message receipts at <lb/>q have been introduced to 00 ) and hence delayed at <lb/>least time 0; also, events at q after time t 1 in 00 occur <lb/>earlier in 00 than in , so the message is delayed by <lb/>less than it is in . If a message is delivered at q <lb/>at time t 00 t 1 in 00 then by Equation (1), it is <lb/>delivered earlier in 00 than in by not more than d; <lb/>because this message is delayed by at least d in , it <lb/>follows that it is delayed by at least time 0 in 00 . <lb/>We also claim that the delay of each message from <lb/>q to p in 00 is delayed by at least 0 and at most d. <lb/>In , all messages from q to p are delayed 0; if in 00 <lb/>they are sent before t 1 , then from Equation 1 they <lb/>are sent earlier (and delayed more) by not more than <lb/>d. The receipt of any message sent by q after t 1 is <lb/>inconsequential to the proof and is de ned arbitrarily <lb/>to be within the bounds of the model. <lb/>Finally, we note that q detects the failure of p be-<lb/>fore time t 1 + 1 <lb/>C (T ? d) in 00 . <lb/></body>

			<note place="footnote">than in 0 . Because this amount is less than d, we are able to <lb/>do this, in e ect partially undoing the original shrinking. The <lb/>timing assumptions for steps of q are clearly satis ed. Because <lb/>the net e ect from both shrinking operations is to shift any <lb/>particular event in the interval 0; C <lb/>C?1 d] of earlier by less <lb/>than d in 00 , the timing assumptions for message delivery are <lb/>also clearly satis ed, for the reasons outlined in the discussion <lb/>of 0 . <lb/></note>

			<body>4.3 Construction of execution 00 <lb/>We now construct execution 00 in which p does not <lb/>fail and which is indistinguishable to q from 00 up to <lb/>time t 1 + 1 <lb/>C (T ? d). In proving that 00 satis es the <lb/>timing assumptions on step time and message deliv-<lb/>ery, we will, for the rst and only time, make use of <lb/>the fact that T = min(2Cd + d= ; C 2 d= + Cd + d). <lb/>Because q times out p before time t 1 + 1 <lb/>C (T ? d) in <lb/>00 , we conclude that in 00 , q mistakenly times out <lb/>the nonfaulty p, contradicting the assumed correct-<lb/>ness and completing the proof. <lb/>To construct 00 at q we use exactly the same events <lb/>as in 00 , up to time t 1 + 1 <lb/>C (T ?d). We do not specify <lb/>the events occurring at q later than this except to say <lb/>that any message sent by p after time t 1 is delayed <lb/>by time d. <lb/>q <lb/>p <lb/>) <lb/>) <lb/>+ <lb/>q t0?t0=C <lb/>-<lb/>Q Q Q Q Q Q Q Q Q Q Q Q s <lb/>. . . <lb/>d?(d?d= )+ 1 <lb/>C (d?d= ) <lb/>00 <lb/>0 <lb/>(m1) <lb/>d <lb/>(m2) <lb/>9 <lb/>&gt; &gt; = <lb/>&gt; &gt; ; <lb/>(slow) <lb/>9 <lb/>&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; = <lb/>&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; ; <lb/>(fast) <lb/>t1 <lb/>t1+ 1 <lb/>C (T ?d)?d <lb/>8 <lb/>&lt; <lb/>: <lb/>(fast) <lb/>8 <lb/>&gt; &gt; &lt; <lb/>&gt; &gt; : <lb/>(not fast) <lb/>t1? 1 <lb/>C (d?d= ) <lb/>t1 <lb/>s t1+ 1 <lb/>C (T ?d) <lb/>Figure 4: Execution 00 is essentially the same as execution <lb/>00 , except that p does not fail; instead, it runs slowly after <lb/>sending message m1, and message m2 is delayed by d. Be-<lb/>cause p sends no other messages before m2, this execution <lb/>appears the same as 00 to q until it receives m2. <lb/>At p, we construct 00 from 0 by mapping the in-<lb/>terval t 1 ; t 1 + d= ] of 0 to the interval t 1 ; t 1 + <lb/>1 <lb/>C (T ? d) ? d] of 00 (p runs fast over this inteval <lb/>in 0 ; it runs more slowly over this interval in 00 ). <lb/>Events in this interval are retimed to occur further <lb/>from time t 1 by at most a factor of C (as we will <lb/>show). We do not specify events occurring at p after <lb/>time t 1 + 1 <lb/>C (T ?d)?d except to say that any message <lb/>sent by q after time t 1 ? 1 <lb/>C (d ? d= ) is delivered at p <lb/>exactly time d later. Thus, 00 is de ned at p (up to <lb/>t 1 + 1 <lb/>C (T ?d)?d) by retiming each event that occurs <lb/>at time t 0 in 0 to occur at time t 00 in 00 , where t 00 is <lb/>de ned as follows: <lb/>t 00 = <lb/>( t 0 <lb/>if t 0 t 1 <lb/>t 1 + <lb/>1 <lb/>C (T ?d)?d <lb/>d= <lb/>(t 0 ? t 1 ) if t 1 t 0 t 1 + d= <lb/>This execution is illustrated in Figure 4. <lb/>We now verify that 00 is consistent with the timing <lb/>assumptions of the model. Note that all events of 00 <lb/>at p before time t 1 are the same as in ; 0 ; ; 0 , and <lb/>00 ; events of 00 at q before time t 1 + 1 <lb/>C (T ?d) are by <lb/>de nition the same as in 00 . Having already veri ed <lb/>the timing properties for 00 , we need verify only the <lb/>timing properties involving events (processor steps, <lb/>message sends, and message receipts) occurring at p <lb/>in the interval t 1 ; t 1 + 1 <lb/>C (t?d)?d]. Events occurring <lb/>at p later than t 1 + 1 <lb/>C (T ? d) ? d and at q later than <lb/>t 1 + 1 <lb/>C (T ?d) are inconsequential to the proof and may <lb/>be scheduled in any way consistent with the bounds <lb/>of the model. Basically, we just need to ensure that <lb/>we are not causing p to run too fast over this interval <lb/>(that&apos;s why we need T C 2 d= + Cd + d) and that <lb/>messages from q to p are not delivered more than d <lb/>after they are sent (that&apos;s why we need T 2Cd+d). <lb/>First, we verify that successive steps of p after t 1 <lb/>are separated by at most c 2 . We show that for any <lb/>interval t 00 i ; t 00 j ] of 00 , mapped from the interval t 0 i ; t 0 j ] <lb/>of 0 , where t 1 t 0 i t 0 j t 1 +d= , we have t 00 j ?t 00 i <lb/>C(t 0 j ? t 0 i ): <lb/>t 00 j ? t 00 i = (t 0 j ? t 0 i ) <lb/>1 <lb/>C (T ? d) ? d <lb/>d= <lb/>(t 0 j ? t 0 i ) <lb/>1 <lb/>C (C 2 d= + Cd) ? d <lb/>d= <lb/>= (t 0 j ? t 0 i )C: <lb/>Because any two steps of p are separated by time c 1 <lb/>in 0 , they are separated by at most C c 1 = c 2 in 00 . <lb/>We now verify that the delays of messages sent by <lb/>p after t 1 are within the proper bounds. Actually, it <lb/>turns out that m 2 (the rst message sent by p after <lb/>t 1 ) is sent by p after time t 1 + 1 <lb/>C (T ? d) ? d: m 2 is <lb/>sent at t 2 t 1 + d= in 0 (and ) and thus at t 00 <lb/>2 <lb/>t 1 + 1 <lb/>C (T ?d)?d in 00 . Messages sent by p after time <lb/>t 1 are speci ed to be delayed by at least time d, so m 2 <lb/>is not delivered until at least time t 1 + 1 <lb/>C (T ?d) (after <lb/>q times out p). The delivery of m 2 and all subsequent <lb/>messages by p is consistent with our de nition of 00 <lb/>at q. <lb/>We now verify that messages from q to p are within <lb/>the proper bounds. We analyze these messages in <lb/>three cases according to when they are sent by q in <lb/>execution 0 (which is the same time as they are sent <lb/>in 0 ). <lb/>Case 1 : q sends at time t 0 t 1 ? d in 0 (and 0 ). <lb/>These messages are delivered to p by time t 1 in 0 (in <lb/>beta, they were sent at t 1 and delivered immediately). <lb/>Events at p before t 1 in 0 occur at the same time in <lb/>00 . These events occur at the same time in 0 and 00 <lb/>(events at p before t 1 were not changed in going from <lb/>0 to 00 ). Since both the send events and receive <lb/>events for these messages occur at the same times <lb/>respectively in 00 and 00 , the analysis of 00 shows <lb/>that their delays are within the proper bounds. <lb/>Case 2 : q sends at time t 0 in 0 (and 0 ), where <lb/>t 1 ? d t 0 t 1 ? (d ? d= ). <lb/>In 00 (and 00 ) the sending event at q is shifted to <lb/>time t 0 +(d?d= )? 1 <lb/>C (d?d= ), which is less than t 1 . <lb/>Such a message is delivered at time t 0 +d in 0 where <lb/>t 1 t 0 +d t 1 +d= . In 00 the delivery event at p is <lb/>mapped to t 1 + 1 <lb/>d= ( 1 <lb/>C (T ? d) ? d)(t 0 + d? t 1 ), which <lb/>is greater than t 1 . Thus, such a message is properly <lb/>delivered after it is sent (delayed by at least 0). With <lb/>some calculation, using the de nitions of T and t 0 and <lb/>noting 1 <lb/>d= ( 1 <lb/>C (T ? d) ? d) ? 1 0, it is easily veri ed <lb/>that the di erence between t 1 + 1 <lb/>d= ( 1 <lb/>C (T ?d)?d)(t 0 + <lb/>d ? t 1 ) and t 0 + (d ? d= ) ? 1 <lb/>C (d ? d= ) is at most d. <lb/>Case 3 : q sends at time t 0 t 1 ? (d ? d= ) in 0 . <lb/>These messages are sent at t 00 &gt; t 1 ? 1 <lb/>C (d ? d= ) in <lb/>00 and thus are de ned to be delivered at p exactly <lb/>time d later. Note that such messages are delivered <lb/>at p later than time <lb/>t 1 ? 1 <lb/>C d + 1 <lb/>C d= + d = t 1 + 2d + 1 <lb/>C d= ? 1 <lb/>C d ? d <lb/>= t 1 + 1 <lb/>C (2Cd + d= ? d) ? d <lb/>t 1 + 1 <lb/>C (T ? d) ? d: <lb/>This is consistent with our de nition of 00 at p. <lb/>Thus we conclude that 00 is a valid timed execution <lb/>in which p does not fail but q times out p. This <lb/>is a contradiction on the correctness of the assumed <lb/>protocol. <lb/>4.4 Bounds for a unidirectional mes-<lb/>sage link <lb/>We remark that our proof gives a tight upper and <lb/>lower bound of C 2 d= + Cd + d for a system of two <lb/>processors with a message link in only one direction. <lb/>In such a system, we have two processors, p and q, <lb/>and a single message link of capacity from p to q. <lb/>Naturally, a protocol does not need to detect failures <lb/>of q. All other previous de nitions apply. <lb/>The second simple protocol described in Section 3 <lb/>operates independently in each direction. It imme-<lb/>diately gives a protocol for the unidirectional case, <lb/>guaranteeing that in any execution, q detects the fail-<lb/>ure of p within time C 2 d= + Cd + d. <lb/>It is also not di cult to see that our lower bound <lb/>proof of Theorem 4.2 specializes to the unidirec-<lb/>tional case to give a corresponding lower bound of <lb/>C 2 d= + Cd + d. Theorem 4.2 is proved for T = <lb/>min(2Cd + d= ; C 2 d= + Cd + d). A similar theo-<lb/>rem for the unidirectional case may be proved with <lb/>T = C 2 d= + Cd + d. Recall that in that proof, <lb/>the value of the timeout detection time T guaranteed <lb/>by the protocol is not used before the claims about <lb/>execution 00 . All preceding claims except those in-<lb/>volving messages from q to p carry over a fortiori. <lb/>Lemma 4.1, for example, is true also for the unidirec-<lb/>tional case with the exception of its third condition, <lb/>which regards messages from q to p. The proof of <lb/>Theorem 4.2 uses the fact that T 2Cd + d= in <lb/>claims about 00 only to verify bounds on the delay <lb/>of messages from q to p. This analysis is not needed <lb/>for a theorem about the unidirectional case and hence <lb/>the entire proof specializes to the unidirectional case <lb/>to give a lower bound of C 2 d= + Cd + d. <lb/>5 Conclusion <lb/>We have attempted to reconcile an important as-<lb/>sumption of 2, 1, 6] with the reality that processors <lb/>can, but should not, send messages faster than they <lb/>can be delivered. Our model intended to capture the <lb/>parameters that are important to the designer of algo-<lb/>rithms for failure detection: the total message delay <lb/>time and the amount of pipelining that is available <lb/>within our entire (high-level) message link abstrac-<lb/>tion. Our formal model of bounded-capacity links <lb/>was motivated not by a desire to re ect physical re-<lb/>ality but to quantify this degree of pipelining. Using <lb/>this model, we were able to derive mathematical re-<lb/>sults that depend explicity on these parameters. <lb/></body>

			<div type="acknowledgement">Acknowledgments <lb/>Thanks to Greg Troxel and Nancy Lynch for helpful <lb/>discussions. <lb/></div>

			<listBibl>References <lb/>1] H. Attiya, C. Dwork, N. Lynch, and L. Stock-<lb/>meyer. Bounds on the time to reach agreement in <lb/>the presence of timing uncertainty. Report TM{ <lb/>435, Laboratory for Computer Science, MIT, <lb/>November 1990. Also in STOC 1991. <lb/>2] H. Attiya and N. A. Lynch. Time bounds for <lb/>real-time process control in the presence of tim-<lb/>ing uncertainty. Proc. 10th IEEE Real-Time Sys-<lb/>tems Symposium, 1989, pp. 268{284. Also: <lb/>Technical Memo MIT/LCS/TM{403, Labora-<lb/>tory for Computer Science, MIT, July 1989. <lb/>3] M. Fischer, N. Lynch and M. Paterson. Impossi-<lb/>bility of distributed consensus with one faulty <lb/>process. Journal of the ACM, Vol. 32, No. 2 <lb/>(1985), pp. 374{382. <lb/>4] J. Lundelius and N. Lynch. An upper and <lb/>lower bound for clock synchronization. Infor-<lb/>mation and Control, Vol. 62, Nos. 2/3 (Au-<lb/>gust/September 1984), pp. 190{204. <lb/>5] M. Merritt, F. Modugno and M. Tuttle. Time <lb/>constrained automata. CONCUR&apos;91 Proceed-<lb/>ings Workshop on Theories of Concurrency: Uni-<lb/>cation and Extension, 1991. <lb/>6] S. Ponzio. Consensus in the presence of timing <lb/>uncertainty: omission and Byzantine failures. <lb/>Proc. 10th ACM Symp. on Principles of Dis-<lb/>tributed Computing, 1991, pp. 125{138. Also: <lb/>The real-time cost of timing uncertainty: con-<lb/>sensus and failure detection. MIT SM Thesis, <lb/>June 1991. Available as MIT Lab. for Com-<lb/>puter Science Technical Report MIT/LCS/TR{ <lb/>518, October 1991. </listBibl>


	</text>
</tei>
