<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="-1"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Research Letter | Equity, Diversity, and Inclusion <lb/>Demographic Representation of Generative Artificial Intelligence Images <lb/>of Physicians <lb/>Sang Won Lee, MSc; Mary Morcos, BS; Dong Won Lee, BS; Jason Young, MD <lb/></front>

			<body>Introduction <lb/>Generative artificial intelligence (AI) is a powerful tool that has revolutionized economic outlooks <lb/>across multiple sectors, including health care. As text-to-image generative AI has become popular, its <lb/>applications in health care have the potential to amplify racial, ethnic, and gender biases. 1,2 This <lb/>concern is particularly alarming and may undermine ongoing diversity, equity, and inclusion (DEI) <lb/>initiatives within clinical and medical education landscapes. 3 Consequently, we performed a <lb/>demographic evaluation of AI-generated images of physicians and compared them with those of <lb/>physicians in the US. We aimed to assess the implications of text-to-image generative AI on <lb/>demographic representation for physicians as a first step toward understanding the role of <lb/>generative AI in health care. <lb/>Methods <lb/>We used the Harvard Longwood Campus Institutional Review Board Decision Tool to determine <lb/>exemption for nonhuman research. Images of physicians were generated across 5 popular AI text-to-<lb/>image platforms: DALL-E 2 (platform 1; Open AI; images created on February 1, 2024), Imagine AI Art <lb/>Generator (platform 2; Vyro AI; February 2, 2024), Jasper Art: AI Art Generator (platform 3; Jasper <lb/>AI; February 2, 2024), Midjourney Beta (platform 4; Midjourney; March 19, 2024), and Text-to-Image <lb/>(platform 5; Runway AI; February 2, 2024). For each platform, 50 images were created for each of <lb/>the following search terms: &quot;face of a doctor in the United States,&quot; &quot;face of a physician in the United <lb/>States,&quot; &quot;photo of a doctor in the United States,&quot; and &quot;photo of a physician in the United States&quot; for a <lb/>total of 1000 images across 5 platforms. Images with partial or multiple identifiable faces were <lb/>Table. Race and Ethnicity and Gender of Artificial Intelligence-Generated Images of Physicians <lb/>Physician <lb/>Artificial intelligence-generated platforms <lb/>AAMC survey, total <lb/>(n = 886 030) b <lb/>Platform 1 <lb/>(n = 200) a <lb/>Platform 2 <lb/>(n = 200) a <lb/>Platform 3 <lb/>(n = 200) a <lb/>Platform 4 <lb/>(n = 200) a <lb/>Platform 5 <lb/>(n = 200) a <lb/>Total <lb/>(n = 1000) a <lb/>Race and ethnicity, No. (%) <lb/>Asian <lb/>4 (2) <lb/>0 <lb/>29 (15) <lb/>11 (6) <lb/>0 <lb/>44 (4) <lb/>186 175 (21) <lb/>Black <lb/>9 (5) <lb/>9 (5) <lb/>57 (29) <lb/>24 (12) <lb/>16 (8) <lb/>115 (12) <lb/>50 965 (6) <lb/>Latino <lb/>4 (2) <lb/>0 <lb/>0 <lb/>7 (4) <lb/>0 <lb/>11 (1) <lb/>62 667 (7) <lb/>White <lb/>180 (90) <lb/>190 (95) <lb/>108 (54) <lb/>158 (79) <lb/>184 (92) <lb/>820 (82) <lb/>558 938 (63) <lb/>Other c <lb/>3 (2) <lb/>1 (1) <lb/>6 (3) <lb/>0 <lb/>0 <lb/>10 (1) <lb/>27 285 (3) <lb/>Gender, No. (%) d <lb/>Women <lb/>42 (21) <lb/>0 <lb/>5 (3) <lb/>16 (8) <lb/>11 (6) <lb/>74 (7) <lb/>371 851 (38) <lb/>Men <lb/>158 (79) <lb/>200 (100) <lb/>195 (98) <lb/>184 (92) <lb/>189 (95) <lb/>926 (93) <lb/>613 974 (62) <lb/>Abbreviation: AAMC, Association of American Medical Colleges. <lb/>a Adjusted P &lt; .001 following Bonferroni correction. <lb/>b The unknown racial and ethnic category was removed in the AAMC survey data for a <lb/>more accurate representation of distribution of race and ethnicity in the US physician <lb/>workforce. <lb/>c Defined as racial and ethnic categories not otherwise captured by Asian, Black, Latino, <lb/>or White categories. <lb/>d The &quot;other&quot; category was removed to fit the data categories available for physician <lb/>demographics (women, men). Note that the total number for the gender section is <lb/>985 825. <lb/>+ Invited Commentary <lb/>+ Supplemental content <lb/>Author affiliations and article information are <lb/>listed at the end of this article. <lb/>Open Access. This is an open access article distributed under the terms of the CC-BY License. <lb/>JAMA Network Open. 2024;7(8):e2425993. doi:10.1001/jamanetworkopen.2024.25993 (Reprinted) <lb/>August 6, 2024 <lb/>1/3 <lb/>Downloaded from jamanetwork.com by guest on 09/10/2025 <lb/>excluded, and new images were generated. Racial and ethnic categories (White, Black, Asian <lb/>[including East Asian and South Asian], Latino, and unable to determine or other) were developed <lb/>based on validated classification systems, including the Chicago Face Dataset, IBM Diversity in Faces, <lb/>and UTKFace. 4 Two independent raters (M.M. and D.W.L.) evaluated each image for race and <lb/>ethnicity and gender, with resolution of differential classification by group consensus. We compared <lb/>the distribution of race and ethnicity and gender within each platform and combined across all <lb/>platforms with US physician demographics based on the 2023 Association of American Medical <lb/>Colleges (AAMC) survey. 5 Comparisons across groups were conducted using χ 2 tests with a <lb/>Bonferroni correction for multiple hypothesis testing. Interrater reliability was assessed using Cohen <lb/>κ. The α level was set at .05. All statistical tests were performed in R, version 4.2.3. This cross-<lb/>sectional study followed the STROBE reporting guideline. <lb/>Results <lb/>Overall, AI-generated images of physicians were more frequently White (82% vs 63%; P &lt; .001) and <lb/>more frequently men (93% vs 62%; P &lt; .001) compared with the US physician population. All 5 <lb/>platforms individually had significant differences in the distribution of race and ethnicity and gender <lb/>compared with the AAMC census (P &lt; .001). However, there was variability in the distribution of race <lb/>and ethnicity and gender across platforms, with 3 platforms producing no images of Latino <lb/>physicians, 2 platforms producing no images of Asian physicians, and 1 platform producing no images <lb/>of female physicians (Table). Interrater reliability between the graders for race and ethnicity and <lb/>gender classifications was κ = 0.81 and κ = 0.88, respectively. <lb/>Discussion <lb/>Our study identifies demographic biases in AI-generated images of physicians with disproportionate <lb/>representation of White and male physicians and concerning underrepresentation of other races and <lb/>ethnicities (Asian and Latino) and female physicians in some platforms. This bias has the potential <lb/>to reinforce stereotypes and undermine DEI initiatives within health care. 1 <lb/>Although strides toward a more representative health care workforce are being made as <lb/>trainees from increasingly diverse backgrounds enter the workforce, this representation remains <lb/>lacking within generative AI, highlighting a critical area for improvement. 6 These biases necessitate <lb/>closer examination of the training data and algorithms used by AI platforms. Ensuring a balanced <lb/>depiction of the increasingly diverse workforce is essential to prevent AI from perpetuating existing <lb/>inequities. <lb/>Future work should focus on enhancing training dataset diversity, creating algorithms capable <lb/>of generating more representative images, while educating AI developers and users about the <lb/>importance of diversity and inclusivity in AI output. By tackling these biases, AI can become a <lb/>powerful tool for advancing DEI initiatives, rather than hindering it. This nuanced understanding of <lb/>AI&apos;s capabilities and limitations is critical because its use continues to grow in health care and beyond. <lb/>Limitations of the study include subjective assessment of race and ethnicity and gender of the <lb/>included images. Two independent raters, a validated image classification, 4 and interrater reliability <lb/>testing were used to mitigate misclassification. Additionally, confinement of search terms to <lb/>physician representation limits generalizability to other clinician classes, such as nurses and <lb/>residents. <lb/></body>

            <front>ARTICLE INFORMATION <lb/>Accepted for Publication: May 27, 2024. <lb/>Published: August 6, 2024. doi:10.1001/jamanetworkopen.2024.25993 <lb/>JAMA Network Open | Equity, Diversity, and Inclusion <lb/>Demographic Representation of Generative AI Images of Physicians <lb/></front>

            <note place="footnote">JAMA Network Open. 2024;7(8):e2425993. doi:10.1001/jamanetworkopen.2024.25993 (Reprinted) <lb/>August 6, 2024 <lb/></note>

            <page>2/3 <lb/></page>

            <note place="footnote">Downloaded from jamanetwork.com by guest on 09/10/2025 <lb/></note>

            <front>Open Access: This is an open access article distributed under the terms of the CC-BY License. © 2024 Lee SW <lb/>et al. JAMA Network Open. <lb/>Corresponding Author: Sang Won Lee, MSc, Harvard Medical School, 25 Shattuck St, Boston, MA 02115 <lb/>(sangwon_lee@hms.harvard.edu). <lb/></front>

            <div type="contribution">Author Affiliations: Harvard Medical School, Boston, Massachusetts (S. W. Lee, Morcos, Young); Nova <lb/>Southeastern University Kiran C. Patel College of Osteopathic Medicine, Davie, Florida (D. W. Lee); Harvard <lb/>Combined Orthopedic Residency Program, Boston, Massachusetts (Young). <lb/>Author Contributions: Mr S. W. Lee had full access to all of the data in the study and takes responsibility for the <lb/>integrity of the data and the accuracy of the data analysis. <lb/>Concept and design: S. W. Lee, Morcos, Young. <lb/>Acquisition, analysis, or interpretation of data: All authors. <lb/>Drafting of the manuscript: S. W. Lee, Morcos. <lb/>Critical review of the for important intellectual content: All authors. <lb/>Statistical analysis: S. W. Lee. <lb/>Administrative, technical, or material support: Morcos, D. W. Lee, Young. <lb/>Supervision: Young. <lb/></div>

            <div type="conflict">Conflict of Interest Disclosures: None reported. <lb/></div>

            <div type="annex">Data Sharing Statement: See the Supplement. <lb/></div>

            <listBibl>REFERENCES <lb/>1. Drahl C. AI was asked to create images of Black African docs treating White kids. How&apos;d it go? NPR. October 6, <lb/>2023. Accessed March 18, 2024. https://www.npr.org/sections/goatsandsoda/2023/10/06/1201840678/ai-was-<lb/>asked-to-create-images-of-black-african-docs-treating-white-kids-howd-it-<lb/>2. Parikh RB, Teeple S, Navathe AS. Addressing bias in artificial intelligence in health care. JAMA. 2019;322(24): <lb/>2377-2378. doi:10.1001/jama.2019.18058 <lb/>3. Capers Q IV. Diversifying the physician workforce-from rhetoric to positive action. N Engl J Med. 2023;388 <lb/>(10):865-867. doi:10.1056/NEJMp2211874 <lb/>4. Ma DS, Correll J, Wittenbrink B. The Chicago Face Database: a free stimulus set of faces and norming data. <lb/>Behav Res Methods. 2015;47(4):1122-1135. doi:10.3758/s13428-014-0532-5 <lb/>5. U.S. Physician Workforce Data Dashboard. Association of American Medical Colleges (AAMC). 2023. Accessed <lb/>March 11, 2024. https://www.aamc.org/data-reports/data/2023-us-physician-workforce-data-dashboard <lb/>6. Salsberg E, Richwine C, Westergaard S, et al. Estimation and comparison of current and future racial/ethnic <lb/>representation in the US health care workforce. JAMA Netw Open. 2021;4(3):e213789. doi:10.1001/ <lb/>jamanetworkopen.2021.3789 <lb/></listBibl>

            <div type="annex">SUPPLEMENT. <lb/>Data Sharing Statement <lb/></div>

            <note place="headnote">JAMA Network Open | Equity, Diversity, and Inclusion <lb/>Demographic Representation of Generative AI Images of Physicians <lb/></note>

            <note place="footnote">JAMA Network Open. 2024;7(8):e2425993. doi:10.1001/jamanetworkopen.2024.25993 (Reprinted) <lb/>August 6, 2024 <lb/></note>

            <page>3/3 <lb/></page>

            <note place="footnote">Downloaded from jamanetwork.com by guest on 09/10/2025 </note>


	</text>
</tei>
