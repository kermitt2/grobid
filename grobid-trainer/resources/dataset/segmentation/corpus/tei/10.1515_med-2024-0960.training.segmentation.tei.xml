<TEI xmlns="http://www.tei-c.org/ns/1.0">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title level="a">Elevation of D-dimer in eosinophilic gastrointestinal diseases in the absence of venous thrombosis: A case series and literature review</title>
        <author>
          <persName>
            <forename>Yang</forename>
            <surname>Song</surname>
          </persName>
        </author>
        <author>
          <persName>
            <forename>Boyu</forename>
            <surname>Yang</surname>
          </persName>
        </author>
        <author>
          <persName>
            <forename>Wanlei</forename>
            <surname>Ren</surname>
          </persName>
        </author>
        <author>
          <persName>
            <forename>Doudou</forename>
            <surname>Hu</surname>
          </persName>
        </author>
      </titleStmt>
      <editionStmt>
        <edition>
          <date when="2025-11-03T17:20:31.126340Z">03.11.2025 17:20:31</date>
          <title>grobid.training.segmentation [default]</title>
          <idno type="fileref">10.1515$1$med-2024-0960</idno>
        </edition>
      </editionStmt>
      <publicationStmt>
        <publisher>Walter de Gruyter GmbH</publisher>
        <availability>
          <licence target="https://creativecommons.org/licenses/by/4.0/"/>
        </availability>
        <date type="publication">2024</date>
        <idno type="DOI">10.1515/med-2024-0960</idno>
      </publicationStmt>
      <sourceDesc>
        <bibl>Yang Song, Boyu Yang, Wanlei Ren, Doudou Hu. (2024). Elevation of D-dimer in eosinophilic gastrointestinal diseases in the absence of venous thrombosis: A case series and literature review. Open Medicine, 19(1), None. DOI: 10.1515/med-2024-0960</bibl>
      </sourceDesc>
    </fileDesc>
    <encodingDesc>
      <appInfo>
        <application version="1.0" ident="pdf-tei-editor" type="editor">
          <ref target="https://github.com/mpilhlt/pdf-tei-editor"/>
        </application>
        <application version="0.8.3-SNAPSHOT" ident="GROBID" when="2025-11-03T17:20:31.126340Z" type="extractor">
          <desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
          <label type="revision">eb7768b</label>
          <label type="flavor">default</label>
          <label type="variant-id">grobid.training.segmentation</label>
          <ref target="https://github.com/kermitt2/grobid"/>
        </application>
      </appInfo>
    </encodingDesc>
    <revisionDesc>
      <change when="2025-11-03T17:20:31.126340Z" status="draft">
        <desc>Generated with createTraining API</desc>
      </change>
    </revisionDesc>
  </teiHeader>
  <text xmlns="http://www.tei-c.org/ns/1.0" xml:lang="en">

        <front>Annika Meyer*, Johannes Ruthard and Thomas Streichert <lb/>Dear ChatGPT -can you teach me how to program <lb/>an app for laboratory medicine? <lb/>https://doi.org/10.1515/labmed-2024-0034 <lb/>Received February 26, 2024; accepted April 18, 2024; <lb/>published online May 15, 2024 <lb/>Abstract <lb/>Objectives: The multifaceted potential of ChatGPT in the <lb/>medical domain remains underexplored, particularly <lb/>regarding its application in software development by in-<lb/>dividuals with a medical background but limited informa-<lb/>tion technology expertise. <lb/>Methods: This study investigates ChatGPT&apos;s utility in <lb/>creating a laboratory medicine application. <lb/>Results: Despite minimal programming skills, the authors <lb/>successfully developed an automated intra-assay, inter-de-<lb/>vice precision test for immunophenotyping with a shiny user <lb/>interface, facilitated by ChatGPT. While the coding process <lb/>was expedited, meticulous oversight and error correction by <lb/>the authors were imperative. <lb/>Conclusions: These findings highlight the value of large <lb/>language models such as ChatGPT in code-based application <lb/>development for automating work processes in a medical <lb/>context. Particularly noteworthy is the facilitation of these <lb/>tasks for non-technically trained medical professionals and <lb/>its potential for digital medical education. <lb/>Keywords: ChatGPT; digital skills gap; programming; <lb/>laboratory medicine <lb/></front>

        <body>Introduction <lb/>Historically, the fields of laboratory medicine and informa-<lb/>tion technology have been closely intertwined [1]. Digital <lb/>progress has been a driving force behind the digital trans-<lb/>formation towards Lab 4.0 [2]. With an increasing focus on <lb/>digital solutions, the need for expertise extending beyond <lb/>the core competencies of laboratory medicine becomes <lb/>increasingly prominent [3]. <lb/>Thus, according to the literature, future laboratory <lb/>professionals require not only a fundamental understanding <lb/>of technology and basic digital skills but also programming <lb/>abilities [4]. Correspondingly, the Association for Diagnostics <lb/>and Laboratory Medicine issued to &apos;Embrace the R Pro-<lb/>gramming Language&apos; as a &apos;Gateway to Laboratory Medi-<lb/>cine&apos;s Digital Future&apos; as early as 2020 [5]. <lb/>However, among the &apos;digital native&apos; &apos;Young Scientists&apos; in <lb/>laboratory medicine, only 23 % program daily in R and a <lb/>mere 6 % in Python. Despite 96 % of young laboratory <lb/>medicine scientists recognizing the necessity of digital edu-<lb/>cation, only 20 % receive it. This reflects a disparity between <lb/>the availability and demand for digital education in this <lb/>field, with a call for learning resources tailored to various <lb/>knowledge levels [4]. In this context, ChatGPT&apos;s capabilities <lb/>in code generation, optimization, debugging assistance, code <lb/>documentation, and review, coupled with its accessibility <lb/>and ease of use [6], present a potential opportunity for <lb/>novices to develop programming skills [7, 8]. This case study, <lb/>to the best of the authors&apos; knowledge, is the first to explore <lb/>the application of ChatGPT in programming a laboratory <lb/>medicine application by non-programming-experts, aiming <lb/>to further bridge the &apos;digital skills gap&apos; in laboratory medi-<lb/>cine [4]. <lb/>Methods <lb/>The problem <lb/>At the Institute of Clinical Chemistry at the University Hos-<lb/>pital Cologne, the reproducibility of immunophenotyping is <lb/>regularly assessed. This involves evaluating intra-assay, in-<lb/>ter-device precision tests using Pearson correlation of <lb/>multicolor flow cytometry from 10 patient samples across <lb/>two different BD FACSCanto™ II. Traditionally, this process <lb/>involved file sorting and manual data transfer from PDF to <lb/>Excel, consuming several hours of medical staff time. <lb/>In pursuit of process optimization, reducing input errors, <lb/>and more effective time utilization, the development of an <lb/>R-based alternative solution was appealing. However, imple-<lb/>menting such a solution with rudimentary knowledge of R, <lb/></body>

        <front>*Corresponding author: Annika Meyer, Institute of Clinical Chemistry, <lb/>University Hospital Cologne, Cologne, Germany, <lb/>E-mail: annika.meyer1@uk-koeln.de. https://orcid.org/0000-0002-8411-<lb/>8799 <lb/>Johannes Ruthard and Thomas Streichert, Institute of Clinical Chemistry, <lb/>University Hospital Cologne, Cologne, Germany. https://orcid.org/0000-<lb/>0002-6588-720X (T. Streichert) <lb/>J Lab Med 2024; 48(5): 197-201 <lb/>Open Access. © 2024 the author(s), published by De Gruyter. <lb/>This work is licensed under the Creative Commons Attribution 4.0 International License. <lb/></front>

        <body>focused primarily on data management and statistics, did not <lb/>seem feasible without external help. <lb/>The solution approach <lb/>Inspired by the utilization of ChatGPT by experienced pro-<lb/>grammers, we decided to employ ChatGPT (GPT-4 version) to <lb/>address this challenge and explore its potential advantages <lb/>and disadvantages. For this purpose, we initially developed <lb/>a procedural plan for our experiment. The objective was <lb/>to write an application in the R programming language, <lb/>without the involvement of external human experts, that <lb/>would automate the following steps: <lb/>-Reading all file names in a folder and including the <lb/>names in a list. <lb/>-Removal of file names with erroneous measurements <lb/>from the list. <lb/>-Grouping of file names according to the sample tested. <lb/>-Grouping of file names based on the measuring <lb/>instrument. <lb/>-Removal of file names with incomplete measurements <lb/>from the list. <lb/>-Extraction of comparative parameters (e.g., CD3+ values <lb/>measured by the different devices) from the sorted PDF <lb/>files in the list into juxtaposed tables. <lb/>-Calculation of analysis-specific Pearson correlation co-<lb/>efficients and their graphical representation. <lb/>In addition, this program was supposed to have a shiny <lb/>user interface to lower the inhibition threshold for use in <lb/>everyday laboratory work. The interface was intended to <lb/>allow the user to choose the file folder, select parameters, <lb/>and export individual graphs and tables. With this plan in <lb/>mind, we began our adventure with the relatively unspec-<lb/>tacular phrase: &apos;I have a PDF document and would like to <lb/>read it into R as text, how can I do that?&apos; (original prompt: <lb/>‚Ich hab ein PDF dokument und möchte dieses gerne als text <lb/>in R einlesen, wie kann ich das machen?&apos;). The R-Code <lb/>developed in this project is available as Supplementary <lb/>Material. <lb/>Results <lb/>Over the course of two weeks, we exchanged 135,615 words <lb/>with ChatGPT, which facilitated the development of an <lb/>application that met our intended specifications. <lb/>ChatGPT compensated for our lack of skills in areas such <lb/>as extracting data from PDF files and creating user interfaces <lb/>(Figure 1). It provided multiple solutions to open-ended <lb/>questions. Knowledge gaps were bridged by the easy-to-<lb/>understand code annotations and explanations provided by <lb/>ChatGPT, concurrently improving our programming skills. <lb/>However, implementation without basic knowledge of <lb/>programming languages and the structure of R would not <lb/>have been feasible, even with the support of ChatGPT. <lb/>ChatGPT frequently produced erroneous code in <lb/>response to vaguely formulated user input (&quot;prompts&quot;). We <lb/>often had to experiment with the wording and language, <lb/>switching from German to English, until ChatGPT correctly <lb/>interpreted our intentions and translated them into code. <lb/>Even with an adjusted input formulation, ChatGPT&apos;s execu-<lb/>tion of solution strategies was often inadequate, requiring <lb/>the development of new strategies for sub-problems within <lb/>the process. In general, the code snippets written by ChatGPT <lb/>Figure 1: User interface of the developed <lb/>application for assessing the intra-assay, <lb/>inter-device precision of immunophenotyping, <lb/>Cologne 2023. Users can select folders and <lb/>parameters for analysis through a drop-down <lb/>menu, download extracted values in CSV <lb/>format, and obtain inter-assay precision results <lb/>as a PDF containing a regression plot with a <lb/>correlation coefficient. <lb/></body>

        <page>198 <lb/></page>

        <note place="headnote">Meyer et al.: Utilizing ChatGPT for programming and developing laboratory medicine apps <lb/></note>

        <body>often generated error messages, which in most cases could <lb/>be resolved with the help of ChatGPT and further research <lb/>into the vignettes (Table 1). <lb/>The authors are currently in communication with the IT <lb/>department of the University Hospital Cologne to enable <lb/>routine use of the shiny app in the future. <lb/>Discussion <lb/>Programming expertise is becoming increasingly vital in the <lb/>daily practice of future medical laboratory professionals. <lb/>Thus, to bridge the &quot;digital skills gap&quot; in laboratory medi-<lb/>cine, the development and research of potential learning <lb/>resources for individual skill acquisition are essential [4]. <lb/>In the wider landscape of software development, social <lb/>media users are already leveraging ChatGPT&apos;s capabilities <lb/>for developing and debugging code across 10 different pro-<lb/>gramming languages [9]. This utility underscores ChatGPT&apos;s <lb/>superior problem-solving capabilities, as in Python, where it <lb/>outperforms counterparts such as Bard and Claude [10], and <lb/>demonstrates robustness in addressing tasks of varying <lb/>complexity in Java and C++ [11]. <lb/>This research further extends this narrative by <lb/>demonstrating the suitability of ChatGPT for aiding the <lb/>development of functional laboratory medicine applications <lb/>by non-programmers. This is consistent with existing liter-<lb/>ature on the utilization of ChatGPT for code generation in <lb/>pharmacometrics [7] and medical statistics [8], where it has <lb/>enabled users with minimal programming knowledge to <lb/>write code and develop operational programs [7, 8], indi-<lb/>cating its potential applicability across various disciplines. <lb/>Furthermore, this study underscores ChatGPT&apos;s cross-<lb/>linguistic ability to generate code, a capability further <lb/>emphasized by the diverse linguistic focus in prior studies [7, <lb/>8]. However, the observations indicate a preference for En-<lb/>glish inputs, a tendency probably stemming from the pre-<lb/>dominance of English in ChatGPT&apos;s training dataset [12]. This <lb/>linguistic inclination is consistent with trends noted in other <lb/>domains [13], including medical exams [14], suggesting a <lb/>broader pattern of language bias. <lb/>In harmony with findings from multiple studies [7, 8, 10, <lb/>11, 15], the necessity of repeated input refinement is critical <lb/>for deriving accurate and operational code from ChatGPT <lb/>also within the domain of laboratory medicine. Moreover, <lb/>observations regarding the inconsistency in ChatGPT&apos;s <lb/>output for identical prompts are reaffirmed, highlighting a <lb/>deficiency in reproducibility [7]. In addition to concerns <lb/>regarding reproducibility, reliability, and accuracy, <lb/>ChatGPT&apos;s code-generation capabilities are also not immune <lb/>to the more general criticisms of this type of Artificial In-<lb/>telligence, including ethical concerns, over-reliance, and <lb/>security risks [6]. For instance, over-reliance on ChatGPT&apos;s <lb/>programming capabilities might inhibit critical thinking and <lb/>hinder the development of individual programming skills [6, <lb/>16], thus leading to &quot;deskilling&quot; and &quot;automation-bias&quot; [17]. <lb/>Table : Evaluation of ChatGPT&apos;s implications on coding in laboratory medicine. <lb/>Attributes Observation <lb/>Link reference <lb/>Implication <lb/>Positive <lb/>Code generation by <lb/>ChatGPT <lb/>https://chat.openai.com/share/aaee-fa-<lb/>bc-ac-cdddae <lb/>ChatGPT demonstrates the potential to assist non-experts in <lb/>generating applications for medical laboratories, stream-<lb/>lining the coding process <lb/>Explained solutions to <lb/>error messages <lb/>https://chat.openai.com/share/cbf-e-<lb/>-bb-bfd <lb/>ChatGPT provides actionable solutions for resolving pro-<lb/>gramming errors, potentially reducing downtime in error <lb/>spotting <lb/>Simplified explanations of <lb/>code <lb/>https://chat.openai.com/share/ee--<lb/>df-f-cefdafb <lb/>ChatGPT contributes to the enhancement of medical pro-<lb/>fessionals&apos; programming capabilities through clear and <lb/>detailed explanations <lb/>Provision of code <lb/>annotations <lb/>https://chat.openai.com/share/caea--<lb/>-bf-cfe <lb/>ChatGPT&apos;s annotations for code facilitate a deeper under-<lb/>standing of programming constructs, improving code literacy <lb/>among medical researchers <lb/>Negative <lb/>Missing reproducibility of <lb/>ChatGPT output <lb/>ChatGPT&apos;s first output: https://chat.openai.com/ <lb/>share/ccdf-ff-ba-a-febed <lb/>ChatGPT&apos;s responses are missing reproducibility despite <lb/>identical user inputs, indicating the need for cautious inter-<lb/>pretation of automated code suggestions <lb/>ChatGPT&apos;s second output: https://chat.openai. <lb/>com/share/df-ec--ace-<lb/>bbbfc <lb/>Complex solutions without <lb/>further examples <lb/>https://chat.openai.com/share/dbaca-b-<lb/>e-dc-efcf <lb/>Understanding and implementing the solutions offered by <lb/>ChatGPT requires basic coding skills, highlighting the <lb/>importance of basic coding skills for healthcare professionals <lb/></body>

        <note place="headnote">Meyer et al.: Utilizing ChatGPT for programming and developing laboratory medicine apps <lb/></note>

        <page>199 <lb/></page>

        <body>In turn, inadequate proficiency in code reading and inter-<lb/>pretation present a security hazard [6], with the potential for <lb/>sensitive data leakage [18] and discriminatory algorithms [9] <lb/>to pass undetected. This concern is especially pronounced in <lb/>sensitive domains such as healthcare, where the integrity of <lb/>patient data and network security are critical [19]. Conse-<lb/>quently, instead of relying solely on automated code gener-<lb/>ation, adopting a cautious strategy alongside a basic grasp of <lb/>programming principles is essential for ensuring safe usage. <lb/>Contrary to these concerns, research by Kazemitabaar <lb/>et al. highlights that ChatGPT does not adversely affect novice <lb/>programmers&apos; ability to modify or generate code [20]. In fact, <lb/>it has been shown to improve performance, boost self-<lb/>efficacy, decrease frustration, and promote skill retention <lb/>over time [20, 21], thereby positioning ChatGPT as a potential <lb/>educational aid and companion for novice programmers [16]. <lb/>Overall, while ChatGPT holds the promise to streamline <lb/>code development and debugging, as well as enrich educa-<lb/>tional experiences for learners, its outputs must be rigorously <lb/>monitored and evaluated, especially within data-sensitive <lb/>fields like healthcare. Therefore, ChatGPT should only be used <lb/>as a complementary tool in laboratory medicine by users with <lb/>basic programming knowledge. Future studies are needed in <lb/>this context to investigate possible integration into corre-<lb/>sponding academic training programs. <lb/>Conclusions <lb/>Overall, it is evident that ChatGPT is capable of assisting <lb/>individuals with limited coding expertise in writing labo-<lb/>ratory medicine programs using R. However, in light of valid <lb/>criticisms regarding its accuracy and reliability, as well as <lb/>concerns pertaining to security, over-reliance, and ethical <lb/>implications, the outputs generated by ChatGPT should be <lb/>subjected to rigorous scrutiny. <lb/>The easily comprehensible explanations and annota-<lb/>tions provided by ChatGPT underscore its potential to sup-<lb/>port digital education in the field of laboratory medicine. <lb/>Therefore, future research focusing on the successful inte-<lb/>gration of ChatGPT into academic digital education pro-<lb/>grams appears to be a worthwhile endeavor. <lb/>Learning points <lb/>(1) ChatGPT can aid non-experts in programming medical <lb/>laboratory applications. <lb/>(2) Through clear explanations and detailed connotations, <lb/>ChatGPT can help develop the programming skills of <lb/>medical professionals. <lb/>(3) ChatGPT&apos;s code often generates error messages that can <lb/>only be partially solved by input reformulations. <lb/>(4) Due to justified criticism regarding reproducibility and <lb/>accuracy as well as ethical and safety concerns, ChatGPT <lb/>should only be used by trained personnel for program-<lb/>ming support. <lb/></body>

        <div type="acknowledgement">Acknowledgments: The authors thank Regine Meyer for <lb/>proofreading the manuscript. DeepL as well as ChatGPT <lb/>were utilized for linguistic and translation purposes. As <lb/>described in the article, ChatGPT was also used for the pro-<lb/>gramming part of the application development. All outputs <lb/>from AI have been critically reviewed by the authors. <lb/></div>

        <div type="annex">Research ethics: Not applicable. <lb/>Informed consent: Not applicable. <lb/></div>

        <div type="contribution">Author contributions: AM, JR and TS designed this experi-<lb/>ment. AM programmed the application with the assistance of <lb/>ChatGPT and JR. AM wrote the manuscript. TS and JR criti-<lb/>cally reviewed the manuscript. All authors have accepted <lb/>responsibility for the entire content of this manuscript and <lb/>approved its submission. <lb/></div>

        <div type="conflict">Competing interests: TS and AM received support by the <lb/>DFG (German Research Foundation) for article processing <lb/>charges of other publications. TS received honoraria for <lb/>lectures by Roche, Siemens and Werfen as well as travel <lb/>support by the DGKL (German Society for Laboratory Med-<lb/>icine), DGLN (German Society for CSF/Neurology), ADLM <lb/>(Association for Diagnostics and Laboratory Medicine) as <lb/>well as ICFF (International Federation of Clinical Chemistry). <lb/></div>

        <div type="funding">Research funding: The research was supported by the <lb/>Institute for Clinical Chemistry at the University Hospital of <lb/>Cologne. <lb/></div>

        <div type="availability">Data availability: The underlying code is enclosed in the <lb/>appendix. <lb/></div>

        <listBibl>References <lb/>1. Queraltó Compañó JM, Bosch Ferrer MA, Bedini Chesa JL, <lb/>Raventós Monjo J, Fuentes-Arderiu X. Computers in clinical <lb/>laboratories. Chemistry Int -Newsmagazine for IUPAC 2008;30:5-8. <lb/>2. Jovičić SŽ, Vitkus D. Digital transformation towards the clinical <lb/>laboratory of the future. Perspectives for the next decade. Clin Chem <lb/>Lab Med 2023;61:567-9. <lb/>3. Desiere F, Kowalik K, Fassbind C, Assaad RS, Füzéry AK, Gruson D, et al. <lb/>Digital diagnostics and mobile health in laboratory medicine: an <lb/>International Federation of Clinical Chemistry and Laboratory Medicine <lb/>Survey on current practice and future perspectives. J Appl Lab Med <lb/>2021;6:969-79. <lb/>4. Adler J, Lenski M, Tolios A, Taie SF, Sopic M, Rajdl D, et al. Digital <lb/>competence in laboratory medicine. J Lab Med 2023;47:143-8. <lb/></listBibl>

        <page>200 <lb/></page>

        <note place="headnote">Meyer et al.: Utilizing ChatGPT for programming and developing laboratory medicine apps <lb/></note>

        <listBibl>5. Haymond S, Master S. Why clinical laboratorians should embrace the R <lb/>Programming Language -a case for learning R as a gateway to <lb/>laboratory. Medicine&apos;s Digital Future Clinical Laboratory News: Association <lb/>for Diagnostics &amp; Laboratory Medicine; 2020. Available from: https://www. <lb/>myadlm.org/cln/articles/2020/april/why-clinical-laboratorians-should-<lb/>embrace-the-r-programming-language#. <lb/>6. Ray PP. ChatGPT: a comprehensive review on background, <lb/>applications, key challenges, bias, ethics, limitations and future scope. <lb/>Internet of Things and Cyber-Physical Systems 2023;3:121-54. <lb/>7. Cloesmeijer ME, Janssen A, Koopman SF, Cnossen MH, Mathôt RAA, <lb/>consortium ftS. ChatGPT in pharmacometrics? Potential opportunities <lb/>and limitations. Br J Clin Pharmacol 2024;90:360-5. <lb/>8. Loh BCS, Fong AYY, Ong TK, Then PHH. Deep learning in digital health <lb/>with chatgpt: a study on efficient code generation. Eur Heart J 2023;44. <lb/>https://doi.org/10.1093/eurheartj/ehad655.2937. <lb/>9. Feng Y, Vanam S, Cherukupally M, Zheng W, Qiu M, Chen H, editors. <lb/>Investigating code generation performance of ChatGPT with <lb/>crowdsourcing social data. In: 2023 IEEE 47th annual computers, <lb/>software, and applications conference (COMPSAC), Torino, Italy, June <lb/>26-30, 2023. Torino, Italy: IEEE; 2023:876-85 p. <lb/>10. Coello CEA, Alimam MN, Kouatly R. Effectiveness of ChatGPT in coding: <lb/>a comparative analysis of popular large language models. Digital 2024; <lb/>4:114-25. <lb/>11. Bucaioni A, Ekedahl H, Helander V, Nguyen PT. Programming with <lb/>ChatGPT: how far can we go? Mach Learn Appl 2024;15:100526. <lb/>12. Nicholas G, Bhatia A. Lost in translation: large language models in non-<lb/>English content analysis. Center for Democracy &amp; Technology; 2023. <lb/>Available from: https://cdt.org/insights/lost-in-translation-large-<lb/>language-models-in-non-english-content-analysis/. <lb/>13. Achiam J, Adler S, Agarwal S, Ahmad L, Akkaya I, Aleman FL, et al. Gpt-4 <lb/>technical report. arXiv preprint arXiv:230308774; 2023. <lb/>14. Meyer A, Riese J, Streichert T. Comparison of the performance of <lb/>GPT-3.5 and GPT-4 with that of medical students on the written German <lb/>medical licensing examination: observational study. JMIR Med Educ <lb/>2024;10:e50965. <lb/>15. Rodriguez DV, Lawrence K, Gonzalez J, Brandfield-Harvey B, Xu L, <lb/>Tasneem S, et al. Leveraging generative AI tools to support the <lb/>development of digital solutions in health care research: case study. <lb/>JMIR Hum Factors 2024;11:e52885. <lb/>16. Bringula R. ChatGPT in a programming course: benefits and <lb/>limitations. Front Education 2024;9. https://doi.org/10.3389/feduc. <lb/>2024.1248705. <lb/>17. Ethikrat D. Mensch und Maschine-Herausforderungen durch <lb/>Künstliche Intelligenz. Vorabfassung der Stellungnahme Berlin: <lb/>Geschäftsstelle der Deutschen Ethikrats; 2023. ethikrat org/fileadmin/ <lb/>Publikationen/Stellungnahmen/deutsch/stellungnahme-mensch-und-<lb/>maschine pdf. <lb/>18. Li J. Security implications of AI Chatbots in health care. J Med Internet <lb/>Res 2023;25:e47551. <lb/>19. Olatunji IE, Rauch J, Katzensteiner M, Khosla M. A review of <lb/>anonymization for healthcare data. Big Data 2022. https://doi.org/10. <lb/>1089/big.2021.0169. <lb/>20. Kazemitabaar M, Chow J, Ma CKT, Ericson BJ, Weintrop D, <lb/>Grossman T. Studying the effect of AI code generators on <lb/>supporting novice learners in introductory programming. In: <lb/>Proceedings of the 2023 CHI conference on human factors in <lb/>computing systems. Hamburg, Germany: Association for Computing <lb/>Machinery; 2023:Article 455 p. <lb/>21. Yilmaz R, Karaoglan Yilmaz FG. The effect of generative artificial <lb/>intelligence (AI)-based tool use on students&apos; computational thinking <lb/>skills, programming self-efficacy and motivation. Comput Educ: Artif <lb/>Intell 2023;4:100147. <lb/></listBibl>

        <div type="annex">Supplementary Material: This article contains supplementary material <lb/>(https://doi.org/10.1515/labmed-2024-0034). <lb/></div>

        <note place="headnote">Meyer et al.: Utilizing ChatGPT for programming and developing laboratory medicine apps <lb/></note>

        <page>201 </page>


	</text>

</TEI>