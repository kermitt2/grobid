<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>December 27, 2017 <lb/>High-to low-level decoding does not generally <lb/>improve perceptual performance <lb/>Long Luu*, Cheng Qiu*, and Alan A. Stocker <lb/>University of Pennsylvania <lb/>*: joint first authors <lb/>Ding et al. (1) recently proposed that the brain automatically encodes high-level, <lb/>relative stimulus information (i.e. the ordinal relation between two lines), which it then <lb/>uses to constrain the decoding of low-level, absolute stimulus features (i.e. when <lb/>recalling the actual lines orientation). This is an interesting idea that is in line with the <lb/>self-consistent Bayesian observer model (2, 3) and may have important implications for <lb/>understanding how the brain processes sensory information. However, the notion <lb/>suggested in Ding et al. (1) that the brain uses this decoding strategy because it <lb/>improves perceptual performance is misleading. Here we clarify the decoding model <lb/>and compare its perceptual performance under various noise and signal conditions. <lb/></front>

			<body>Orientations of the 2-line stimulus used in Ding et al. (1) (Fig.1a, black asterisk; 50° and <lb/>53° orientation) are encoded as two noisy, sensory measurements (Fig.1a, red) that can <lb/>be further corrupted by memory noise (Fig.1a, blue). A low-to high-level decoding <lb/>strategy predicts estimates that are identical to the memory samples (assuming a flat <lb/>prior for simplicity) and are distributed according to the combined sensory and memory <lb/>noise (Fig.1a, right column). In contrast, a high-to low-level decoder assumes that the <lb/>line estimates are conditioned on the relative order of the two lines, which predicts the <lb/>characteristic repulsive bias pattern in the estimates. Importantly, if ordinal information <lb/>is based on the memory samples, then the low-to high-level and the high-to low-level <lb/>decoder are identical with regard to the ordinal information contained in the estimates <lb/>(ordinal performance 68%); that is, a high-to low-level decoding strategy per se does <lb/>not improve ordinal discrimination because ordinal performance is strictly limited by <lb/>the available stimulus information (Signal Detection Theory). Only if the high-to low-<lb/>level decoder has access to ordinal information contained in the less corrupted <lb/>sensory measurements, ordinal performance is higher because the ordinal information <lb/>contained in the sensory signals is preserved in the estimates. <lb/>Ultimately, however, subjects in Ding et al. (1) were asked to provide accurate <lb/>orientation estimates. We computed the relative estimation accuracy between high-to <lb/>low-level and low-to high-level decoding in terms of mean squared-error for different <lb/>sensory and memory noise levels. If both decoders have the same sensory information <lb/>(no memory noise) then high-to low-level decoding only performs better in a narrow <lb/>regime of intermediate d-prime values (Fig. 1b). When adding memory noise and giving <lb/>high-to low-level decoding the advantage of having more accurate ordinal information, <lb/>it also rarely outperforms the low-to high-level decoder in particular for larger sensory <lb/>noise (Fig. 1c). Therefore, the implication by Ding et al. (1) that the high-to low-level <lb/>decoding strategy generally improves the reliability of the decoded orientations is <lb/>incorrect. <lb/>In conclusion, Ding et al. (1) provided a great example of self-consistent/high-to low-<lb/>level inference. However, the benefits of this decoding strategy have been overstated; <lb/>why and under what conditions the brain adopts such a strategy remains an open (yet <lb/>very interesting!) question. <lb/></body>

			<listBibl>(1) Ding S, et al. (2017) Visual perception as retrospective Bayesian decoding from <lb/>high-to low-level features. Proc. National Academies of Sciences U.S.A 114 (43) <lb/>E9115-E9124 <lb/>(2) Stocker AA, Simoncelli EP (2007) A Bayesian model of conditioned perception. Adv. <lb/>In Neural Information Processing Systems (NIPS) Vol.20: 1409-1416 <lb/>(3) Long L, and Stocker AA (2016) Choice-induced biases in perception. bioRxiv <lb/>043224 <lb/></listBibl>

			<body>Figure 1: Decoding performance. (a) Line orientations are encoded according to sensory and <lb/>memory noise. Low-to high-level decoding results in orientation estimates that are distributed <lb/>according to the combined noise. High-to low-level decoding results in characteristic bi-modal <lb/>distributions. If conditioning is based on memory samples (Hm-to-L) then ordinal information in <lb/>the estimates is the same as for the low-to high-level decoder. Only if conditioning is based on <lb/>the less noisy sensory samples (Hs-to-L), ordinal performance improves. (b) Estimation <lb/>accuracy (relative mean-squared-error (MSE)) as function of d-prime. (c) Relative MSE for <lb/>different noise conditions and three pairs of line orientations. <lb/>Low to High <lb/>High to Low <lb/>Encoding <lb/>Decoding <lb/>Estimate distribution <lb/>Hm-to-L <lb/>Hs-to-L <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 1 orientation (deg) <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 2 orientation (deg) <lb/>Ordinal correct: 68% <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 1 orientation (deg) <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 2 orientation (deg) <lb/>Ordinal correct: 68% <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 1 orientation (deg) <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 2 orientation (deg) <lb/>Ordinal correct: 86% <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 1 orientation (deg) <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 2 orientation (deg) <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 1 orientation (deg) <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 2 orientation (deg) <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 1 orientation (deg) <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 2 orientation (deg) <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 1 orientation (deg) <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>Line 2 orientation (deg) <lb/>a. <lb/>b. <lb/>c. <lb/>0 <lb/>2 <lb/>4 <lb/>6 <lb/>8 <lb/>d-prime <lb/>0.8 <lb/>0.9 <lb/>1 <lb/>1.1 <lb/>1.2 <lb/>1.3 <lb/>1.4 <lb/>Relative MSE: <lb/>Hs-to-L/L-to-H <lb/>Memory : 0 <lb/>0 <lb/>5 <lb/>1 0 <lb/>1 5 <lb/>2 0 <lb/>Memory <lb/>0.8 <lb/>0.9 <lb/>1 <lb/>1.1 <lb/>1.2 <lb/>1.3 <lb/>1.4 <lb/>Relative MSE: <lb/>Hs-to-L/L-to-H <lb/>Sensory : 1 <lb/>[50 53] <lb/>[50 52] <lb/>[50 51] <lb/>0 <lb/>5 <lb/>1 0 <lb/>1 5 <lb/>2 0 <lb/>Memory <lb/>0.8 <lb/>0.9 <lb/>1 <lb/>1.1 <lb/>1.2 <lb/>1.3 <lb/>1.4 <lb/>Sensory : 2 <lb/>0 <lb/>5 <lb/>1 0 <lb/>1 5 <lb/>2 0 <lb/>Memory <lb/>0.8 <lb/>0.9 <lb/>1 <lb/>1.1 <lb/>1.2 <lb/>1.3 <lb/>1.4 <lb/>Sensory : 3 <lb/>stimulus <lb/>sensory sample <lb/>memory sample <lb/>estimate <lb/>memory noise <lb/>distribution <lb/>sensory noise <lb/>distribution <lb/>combined sensory <lb/>and memory noise <lb/>90% quantile over <lb/>20 repetitions of <lb/>10,000 samples </body>


	</text>
</tei>
