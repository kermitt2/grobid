<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="-1"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Heliyon 10 (2024) e31017 <lb/>Available online 14 May 2024 <lb/>2405-8440/© 2024 The Authors. <lb/>Published by Elsevier Ltd. <lb/>This is an open access article under the CC BY license <lb/>(http://creativecommons.org/licenses/by/4.0/). <lb/>Research article <lb/>Automated system for classifying uni-bicompartmental knee <lb/>osteoarthritis by using redefined residual learning with <lb/>convolutional neural network <lb/>Soaad M. Naguib a , Mohamed A. Kassem b , Hanaa M. Hamza c , Mostafa M. Fouda d , <lb/>Mohammed K. Saleh e , Khalid M. Hosny c,* <lb/>a Department of Information Systems, Faculty of Computers and Informatics, Zagazig University, Zagazig, 44519, Egypt <lb/>b Department of Robotics and Intelligent Machines, Faculty of Artificial Intelligence, Kafrelsheikh University, Kafr el-Sheikh, Egypt <lb/>c Department of Information Technology, Faculty of Computers and Informatics, Zagazig University, Zagazig, 44519, Egypt <lb/>d Department of Electrical and Computer Engineering, Idaho State University, Pocatello, ID, 83209, USA <lb/>e Department of Orthopedic Surgery, Faculty of Medicine, Zagazig University, Zagazig, 44519, Egypt <lb/>A R T I C L E I N F O <lb/>Keywords: <lb/>Deep learning <lb/>Redefined residual learning <lb/>Knee osteoarthritis classification <lb/>Overstep connection <lb/>X-ray <lb/>A B S T R A C T <lb/>Knee Osteoarthritis (OA) is one of the most common joint diseases that may cause physical <lb/>disability associated with a significant personal and socioeconomic burden. X-ray imaging is the <lb/>cheapest and most common method to detect Knee (OA). Accurate classification of knee OA can <lb/>help physicians manage treatment efficiently and slow knee OA progression. This study aims to <lb/>classify knee OA X-ray images according to anatomical types, such as uni or bicompartmental. <lb/>The study proposes a deep learning model for classifying uni or bicompartmental knee OA based <lb/>on redefined residual learning with CNN. The proposed model was trained, validated, and tested <lb/>on a dataset containing 733 knee X-ray images (331 normal Knee images, 205 unicompartmental, <lb/>and 197 bicompartmental knee images). The results show 61.81 % and 68.33 % for accuracy and <lb/>specificity, respectively. Then, the performance of the proposed model was compared with <lb/>different pre-trained CNNs. The proposed model achieved better results than all pre-trained <lb/>CNNs. <lb/></front>

			<body>1. Introduction <lb/>Knee OA is one of the most common joint diseases in orthopedics [1]. Knee OA is a knee joint disease accompanied by chronic pain, <lb/>mobility limitations, and an increased risk of falls [2]. Knee osteoarthritis is a chronic disease with long-term symptoms and structural <lb/>changes, including articular cartilage disintegration, subchondral bone sclerosis, and structural changes in all soft tissues surrounding <lb/>the knee joint [3-5]. As a result, knee OA negatively affects the patient&apos;s quality of life due to decreased muscle strength, physical <lb/>performance, range of joint motion, and physical performance [6]. Knee OA is clinically presented with limited activity, knee pain, and <lb/>joint stiffness, which markedly affect the quality of life [1]. Although Knee OA mainly occurs in older adults, younger people are <lb/>affected by Knee OA due to obesity and knee fractures [7]. Researchers have estimated that by 2050 around 130 million people will <lb/>suffer from Knee OA [8]. The increasing need for complete knee replacements yearly reflects healthcare costs and the lack of treatment <lb/></body>

			<front>* Corresponding author. <lb/>E-mail addresses: k_hosny@yahoo.com, k_hosny@zu.edu.eg (K.M. Hosny). <lb/>Contents lists available at ScienceDirect <lb/>Heliyon <lb/>journal homepage: www.cell.com/heliyon <lb/>https://doi.org/10.1016/j.heliyon.2024.e31017 <lb/>Received 11 January 2024; Received in revised form 8 May 2024; Accepted 9 May 2024 <lb/></front>

			<note place="headnote">Heliyon 10 (2024) e31017 <lb/></note>

			<page>2 <lb/></page>

			<body>methods to prevent disease progression [9]. The Knee OA can affect two compartments of the knee, which are lateral and medial. When <lb/>the OA changes only affect the medial or lateral side of the knee, this is considered a unicompartmental type. If the structural changes <lb/>affect both medial and lateral sides, it is known as the bicompartmental type. Identifying uni-bicompartmental OA is valuable in <lb/>determining which type of knee replacement is needed [10-12]. Fig. 1 (a,b, and c) represents the knee in normal, unicompartmental <lb/>OA, and bicompartmental OA, respectively. X-ray imaging is one of the most common and cheap methods used in clinical medicine to <lb/>scan any bone in the human body [13,14] due to its cost-effectiveness, safety, speed, and accessibility. X-rays are often used to diagnose <lb/>and assess knee OA. They are the gold standard for knee OA screening [15]. <lb/>The recent advances in artificial intelligence (AI) for healthcare have led to significant improvements and discoveries in ortho-<lb/>pedics [16]. The efficiency of AI allows for quick processing of patient image data, which facilitates timely diagnosis and patient <lb/>management [17]. Therefore, many researchers use AI to build computer-aided diagnosing tools to help physicians decrease time and <lb/>effort while examining patients with knee OA symptoms, as many Radiographic and physicians suffer from the increasing workload in <lb/>radiology and orthopedic departments [18]. <lb/>[19] built a hybrid deep learning model for early diagnosing Knee OA. Three different CNN architectures were used as the base for <lb/>the hybrid model. The model was compared to eight different CNN architectures, achieving the highest accuracy performance [8]. <lb/>identified the grade of severity of Knee OA from X-ray images using deep learning (pre-trained CNN). <lb/>Furthermore, a conventional machine learning classifier was employed to take advantage of the enriched feature space and <lb/>improve the classification performance of Knee OA. The proposed models are evaluated and prove their contribution to the early <lb/>classification of the disease with a 90.8 % accuracy rate [20]. developed a deep convolutional neural network (DenseNet169) ar-<lb/>chitecture coupled with an adaptive early stopping technique that uses gradual cross-entropy loss estimation for knee OA detection <lb/>using X-ray images. Then, the authors compared the results obtained from the existing studies. The comparison shows that the pro-<lb/>posed model performed better in accuracy, precision, and recall. <lb/>However, to our best knowledge, no previous studies have been done to classify Knee OA X-ray images according to anatomical <lb/>types. The proposed research classifies knee OA as uni or bicompartmental. Total knee joint replacement is expensive for the patient <lb/>and the national economy. Therefore, detecting that knee OA is unicompartmental will help minimize the rate of bicompartmental <lb/>arthroplasty (total knee joint replacement), decreasing hospital stay and early return to daily activities. In addition, such a study can <lb/>help doctors in remote areas that lack qualified orthopedic surgeons and are only supported by family and/or general practitioners. <lb/>The main contributions of this study are: <lb/>1 Classifying knee OA based on anatomical types to uni-bicompartmental types. <lb/>2 A deep learning model using an overstepping connection is developed to classify uni-bicompartmental knee OA. <lb/>3 The proposed deep learning method is based on redefined residual learning. <lb/>The remainder of the paper is organized as follows: Section 2 introduces the method used in the study. Section 3 discusses the <lb/>proposed algorithm in detail. Then, we describe the used datasets by clarifying their references and explaining their classification in <lb/>section 4. Then, the results and discussion of the experiment are presented in section 5. The paper is concluded in Section 6. <lb/>2. Methods <lb/>In knee joints, localizing information would acquire more discriminative features. It is possible to enhance classification perfor-<lb/>mance by using discriminative features. When combined with the class activation map, CNNs have a substantial locating capability. <lb/>CNNs have a significant locating capacity when used with the class activation map [21-25]. A class activation map was used to <lb/>Fig. 1. (a) Normal knee; (b) unicompartmental OA; (c) bicompartmental OA [13]. <lb/></body>

			<note place="headnote">S.M. Naguib et al. <lb/>Heliyon 10 (2024) e31017 <lb/></note>

			<page>3 <lb/></page>

			<body>distinguish the discriminative ROI. Instead of relying on the pre-trained models to locate the knee, the proposed method can use <lb/>different filter sizes and a cross-channel correlation approach that ignores the spatial dimensions of the ROI in a 1 × 1 convolution <lb/>through the residual block to locate the ROI better. Based on the global characteristics of the same class, the proposed model annotates <lb/>Fig. 2. The proposed redefined residual learning deep learning model. <lb/></body>

			<note place="headnote">S.M. Naguib et al. <lb/>Heliyon 10 (2024) e31017 <lb/></note>

			<page>4 <lb/></page>

			<body>classification levels to focus on the explicit minimization of interclass distances. Ethical approval was waived as the data obtained was <lb/>retrospective and de-identified. <lb/>2.1. The proposed algorithms <lb/>The classification will be incorrect if there aren&apos;t enough features employed. For a successful classification process, discriminative <lb/>features are therefore crucial. A suggested deep learning approach utilizes redefined residual learning, cross-channel correlation, and <lb/>an imbalanced dataset to analyze a challenging dataset of knee osteoarthritis images with uni-bicompartmental involvement. Knee-<lb/>Net, a new DL architecture with 54 layers, is proposed. The recommended approach for redefined residual deep learning involves <lb/>using various layers such as input, convolutional, batch normalization, pooling, dropout, fully connected, SoftMax, and activation <lb/>rectified linear unit (ReLU). <lb/>The Height (H), Width (W), and Number of Channels (D) of the input image are the three dimensions that the first layer (also known <lb/>as the &quot;input layer&quot;) is responsible for defining. In contrast to cutting-edge DL models like Google-net, Alex-net, VGG, and Res-net, <lb/>limited values for W and H are employed, such as 227 × 227 or 224 × 224. All images in the W × H × D proposed model were <lb/>scaled down to 300 × 300 × 3. <lb/>From the input layer, the &quot;convolution layer&quot; receives input. Neurons in this layer connect various image areas. Convolution layers <lb/>are first learned using low-level information, after which deeper layers extract additional features, including objects, shapes, and <lb/>colors. Convolutional layers are used to localize features in a scanned image. Features must be extracted from the input image after the <lb/>convolutional layers, resulting in a reduced feature map to downscale an image. So, a down-sampling layer addressed this problem. <lb/>Consequently, we added a max-pooling layer. The pooled features map&apos;s features are duplicated in a new group of features generated <lb/>by this layer. <lb/>The input dimension of each layer is altered during the training phase by changing the layer parameters. Training the DCNN is <lb/>challenging as a result. The training process is delayed by the need for slower learning rates and precise parameter settings during each <lb/>iteration. Batch normalization layers were used to speed up training and reduce sensitivity. The mean and variance of the input <lb/>distributions are normalized using the batch normalization layer, which also removes the negative effects of the internal shift <lb/>covariance. Before the ReLU alters the DCNN, there is a normalization layer. As a result, it becomes easier to coordinate changes <lb/>between layers. <lb/>It is challenging to raise and deepen layers. Even with proper initialization, the gradient vanishing problem can still arise in deeper <lb/>networks. Research has established that accuracy is unaffected by increasing depth, and that degradation is unavoidable [26]. As a <lb/>result, efficiency does not considerably rise as network thickness increases and may be impacted by the degradation issue. More images <lb/>are needed for training deeper systems because there are numerous parameters that these networks must call to generalize. The output <lb/>from one layer of a deep neural network is fed into the next layer, which is organized progressively. Going deeper is not an option <lb/>because there aren&apos;t enough images in the datasets for medical images, particularly knee X-rays. <lb/>The proposed model employs a redefined residual learning technique to overcome image shortages and degradation. Overstepping <lb/>layer input connections is a way to address degradation through redefined residual learning by increasing information flow and <lb/>rearranging layers to address degradation. Different redefined residual blocks are combined to form the proposed deep redefined <lb/>residual network. Fig. 2 displays the suggested method&apos;s general architecture and describes all convolutional layers. <lb/>We produce two types of redefined residual blocks, as shown in Fig. 2. Like the first, second, fourth, and sixth overstepping layer <lb/>input connections in Fig. 2. , the first overstep input connections have no additional layer. The third and fifth layers of the second <lb/>overstep input connections are batch normalization and convolutional. The input vector &quot;o&quot; is used to represent each redefined residual <lb/>block, the output vector is &quot;m,&quot; and the mapping of the stacked layers is represented by &quot;S(o)&quot; for each redefined residual block. The <lb/>redefined residual function of these layers is now identified using equation (1) below [22]: <lb/>І(o) = S(o) -o <lb/>(1) <lb/>Instead of imitating the stacked layers S(o), in equation (1), the redefined residual learning is used to increase the layers&apos; learning <lb/>rate even with a small dataset. This subnetwork&apos;s output &quot;m&quot; is computed from equation (2): <lb/>S(o i ) = І(o i ) + o i <lb/>(2) <lb/>The proposed method has been modified to operate with multiclass classification after the fully connected and SoftMax layers. <lb/>Using an entropy function, the final layer, called the output layer, changes the SoftMax output into the target class name. A probability <lb/>value of 1 must be used in sigmoid. Still, a probability value 1 can be used in SoftMax if the target class has a more excellent probability <lb/>value than other SoftMax classes. One potential limitation of SoftMax is that it can become computationally expensive when the <lb/>number of &quot;knee&quot; classes increases [22]. <lb/>It is also possible for the proposed method to perform a solution to the class imbalance. We developed a bootstrap algorithm to <lb/>ensure the classes were balanced in the dataset. Regular sampling of images is carried out by replacing the samples with new ones, and <lb/>then the samples are weighted based on how many images are in each class. The dataset images are first arranged alphabetically by the <lb/>names of the classes. Now, the algorithm computes how many images are in the entire dataset and how many there are in each class. <lb/>The algorithm calculated the weight of the images by dividing the count of each class image by the overall number of images in the <lb/>dataset. <lb/>Furthermore, it is important to note that images within the same class are weighted equally. When all labels&apos; weights are added <lb/></body>

			<note place="headnote">S.M. Naguib et al. <lb/>Heliyon 10 (2024) e31017 <lb/></note>

			<page>5 <lb/></page>

			<body>together, the sum of all labels&apos; weights equals one. The dataset is transformed into a vector, and instead of utilizing images labeled <lb/>alphabetically, the labels of the images will be numerical weights. As a result, the class with the most images has the least weight, while <lb/>the class with the fewest images has the highest weight. Then, the suggested technique multiplies the weight of the classification layer <lb/>by the weight of the images in the image vector. The proposed redefined residual learning is shown in the following algorithm. <lb/>Fig. 3. a) Samples from the normal group, b) Samples from the unicompartmental group, c) Samples from the bicompartmental group. <lb/></body>

			<note place="headnote">S.M. Naguib et al. <lb/>Heliyon 10 (2024) e31017 <lb/></note>

			<page>6 <lb/></page>

			<body>3. Experiment <lb/>This section will describe the used datasets by clarifying their references and explaining their classification. Then, the results of the <lb/>experiments will be presented later in the following sections. The first dataset has been obtained from Mendeley Data [27]. The second <lb/>dataset has been obtained from Kaggle Datasets [28]. The two image datasets have been merged into one dataset and classified into <lb/>three groups. Specialized orthopedic surgeons did the classification. <lb/>The first normal group includes 331 images (Fig. 3 a). The second unicompartmental group contains 205 images (Fig. 3 b). Finally, <lb/>the third bicompartmental group comprises 197 images (Fig. 3 c). The proposed model was trained, validated, and tested on the <lb/>merged datasets. <lb/>3.1. Results <lb/>The proposed model was developed in MATLAB 2022b 64-bit and executed on an IBM PC with a Core i7 CPU, 16 GB of DDRAM, and <lb/>an NVIDIA MX150 GPU card. The SGD optimizer was used to adjust network weights throughout the training period. As the learning <lb/>process progresses, each network weight or parameter has a specific learning rate that changes. In the training phase, the network <lb/>parameters are randomly initialized and adjusted. All trials use a similar learn rate drop period, weight decay, batch size, momentum, <lb/>and maximum epochs, and these values were 4, 0.9, 0.001, 10, 0.9, and 30, respectively. <lb/>Quantitative and qualitative indicators were used to evaluate the suggested model&apos;s performance. Two quantitative metrics were <lb/>used: accuracy and specificity. If accuracy is used to assess the model&apos;s quality, a model that classifies all testing samples into the class <lb/>with the most images will have excellent accuracy. Nonetheless, this model will not give us any helpful information. As a result, we <lb/>employed other performance metrics. The confusion matrix is utilized as a qualitative metric to display and analyze the dependability <lb/>of the suggested method. These measurements are calculated using the following equation [29]: <lb/>Accuracy = <lb/>t p + t n <lb/>t p + f p + f n + t n <lb/>(3) <lb/>Specificity = <lb/>t n <lb/>f p + t n <lb/>(4) <lb/>where the terms f p &quot;false-positive&quot; and f n &quot;false-negative&quot; stands in contrast to t p &quot;true positive&quot; and t n &quot;true negative,&quot; respectively. <lb/></body>

			<note place="headnote">S.M. Naguib et al. <lb/>Heliyon 10 (2024) e31017 <lb/></note>

			<page>7 <lb/></page>

            <body>The confusion matrix of the proposed method is shown in Fig. 4, while Table 1 summarizes the obtained measures (see Fig. 5). <lb/>According to the results obtained and summarized in Table 1, The accuracy of the proposed method was 65 %, while the specificity <lb/>was 66.67 without augmentation. The proposed method constructs the deep learning model based on the dataset images. Instead of <lb/>constructing a stacked layer deep learning model, the proposed method refined the residual learning to overcome the problem of a lack <lb/>of images in the dataset. The proposed method fails to detect bicompartmental. <lb/>3.2. Discussions <lb/>The previous results show that the performance measures of the proposed method still need some enhancement. Because the <lb/>proposed method fails to detect and classify bicompartmental, we suggest augmenting the dataset images and comparing the obtained <lb/>results with others. <lb/>To our knowledge, no recently published paper on the same dataset exists. Therefore, we used a pre-trained model with transfer <lb/>learning to compare the obtained measures using the proposed deep learning model against the pre-trained model. Here, Alexnet, <lb/>shuffelnet, mobilenetv2, darknet53, and googlenet were used with transfer learning to compare the proposed method against others. <lb/>The last two layers have been replaced with new, fully connected classification layers. In addition, all the previous layers were frozen <lb/>to keep all the weights of these layers fixed without any change. Finally, the last two layers have been trained using the knee images <lb/>(see Fig. 9). <lb/>Before training the proposed model, some limitations and challenges must be added to relatively little data that can be accessed <lb/>readily. So, we use various augmentation techniques, including random vertical and horizontal flips, random vertical and horizontal <lb/>shifts, and random rotation angles between 0 and 360. There are requirements for augmentation, such as overcoming the limitation of <lb/>the dataset images and generalizing the CNNs model to overcome the issue of overfitting and underfitting. The confusion matrices for <lb/>modified pre-trained CNNs and the proposed method are shown in Figs. 5-10. Table 2 summarizes the measures obtained, while Fig. 11 <lb/>depicts the results. <lb/>The previous results show that the proposed method&apos;s performance measures are better than all pre-trained CNNs with transfer <lb/>learning in detecting the three classes, bicompartmental, normal, and unicompartmental, as shown in Fig. 4. Although the proposed <lb/>model was not pre-trained, it performed better than pre-trained CNNs. However, these measures are still unacceptable for many <lb/>reasons. Based on radiographic findings, we will require baseline diagnostic imaging and follow-up clinical evaluations to identify uni-<lb/>bicompartmental knee osteoarthritis. These assessments can be costly as well as challenging to obtain. These issues lead to limited <lb/>data. Even after augmentation, the features are still the same. Secondly, there were no precomputed features, segmentations of the X-<lb/>ray images, or processed images. <lb/>The limitation of this study is that the dataset contains a few knee images and the extraction of some redundant information, which <lb/>degrades classification accuracy and lengthens computation, are the main limitations of this study. In the future, the dataset of knee <lb/>images must increase. In addition, Bayesian optimization can be used to solve this problem. <lb/>4. Conclusions <lb/>This study proposes a deep redefined residual network architecture to classify knee OA as uni-bicompartmental. The model utilizes <lb/>convolutional, pooling, and batch normalization layers to extract features from knee X-ray images. We used a dataset containing 733 <lb/>knee X-ray images (331 normal Knee images, 205 unicompartmental, and 197 bicompartmental knee images). This study shows <lb/>satisfactory results with 61.81 % and 68.33 % for accuracy and specificity, respectively. Then, we compare the performance of the <lb/>proposed model with pre-trained CNN models (Alexnet, shufflenet, mobilenetv2, darknet53, and googlenet) using transfer learning. <lb/>Results show that the proposed model outperforms the pre-trained models regarding accuracy and specificity. The proposed study <lb/>could help orthopedic surgeons and related healthcare specialists interpret knee OA, especially in remote areas with insufficient <lb/>qualified physicians. It can also assist in classifying the pathology into uni-bicompartmental, thus facilitating its treatment with either <lb/>unicompartmental arthroplasty or bicompartmental (total) knee replacement. <lb/></body>

            <div type="availability">Data availability <lb/>Data is available on request from the authors. <lb/></div>

            <div type="annex">CRediT authorship contribution statement <lb/>Soaad M. Naguib: Writing -original draft, Validation, Formal analysis, Data curation, Conceptualization. Mohamed A. Kassem: <lb/></div>

            <body>Fig. 4. The proposed model is without data augmentation. <lb/></body>

			<note place="headnote">S.M. Naguib et al. <lb/>Heliyon 10 (2024) e31017 <lb/></note>

			<page>8 <lb/></page>

            <div type="annex">Writing -original draft, Visualization, Software, Methodology, Conceptualization. Hanaa M. Hamza: Visualization, Resources, <lb/>Project administration, Data curation. Mostafa M. Fouda: Resources, Project administration, Funding acquisition. Mohamed K. <lb/>Saleh: Visualization, Validation, Data curation, Conceptualization. Khalid M. Hosny: Writing -review &amp; editing, Supervision, <lb/>Methodology, Conceptualization. <lb/></div>

            <body>Table 1 <lb/>Performance measure without augmentation. <lb/>Accuracy <lb/>specificity <lb/>The proposed model <lb/>65 <lb/>66.67 <lb/>Fig. 5. Alexnet with data augmentation. <lb/>Fig. 6. Darknet53 with data augmentation. <lb/>Fig. 7. Mobilenetv2 with data augmentation. <lb/>Fig. 8. Shuffelnet with data augmentation. <lb/>Fig. 9. Googlenet with augmentation. <lb/>Fig. 10. The proposed model with data augmentation. <lb/></body>

			<note place="headnote">S.M. Naguib et al. <lb/>Heliyon 10 (2024) e31017 <lb/></note>

			<page>9 <lb/></page>

			<div type="annex">Declaration of competing interest <lb/>The authors declare that they have no known competing financial interests or personal relationships that could have appeared to <lb/>influence the work reported in this paper. <lb/></div>

			<listBibl>References <lb/>[1] W. Lin, L. Xie, L. Zhou, J. Zheng, W. Zhai, D. Lin, Effects of platelet-rich plasma on subchondral bone marrow edema and biomarkers in synovial fluid of knee <lb/>osteoarthritis, Knee 42 (2023) 161-169, https://doi.org/10.1016/j.knee.2023.03.002. <lb/>[2] A. Hislop, N.J. Collins, K. Tucker, A.I. Semciw, The association between hip strength, physical function, and dynamic balance in people with unilateral knee <lb/>osteoarthritis: a cross-sectional study, Musculoskelet. Sci. Pract 63 (2023, December) 102696, https://doi.org/10.1016/j.msksp.2022.102696. <lb/>[3] X. Liu, S. Virk, T. Fedorova, W.M. Oo, D.J. Hunter, The effect of pentosan polysulfate sodium for improving dyslipidemia and knee pain in people with knee <lb/>osteoarthritis: a pilot study, Osteoarthr. Cartil. Open 5 (2) (2023) 100343, https://doi.org/10.1016/j.ocarto.2023.100343. <lb/>[4] M. Burfield, M. Sayers, R. Buhmann, The association between running volume and knee osteoarthritis prevalence: a systematic review and meta-analysis, Phys. <lb/>Ther. Sport 61 (2023) 1-10, https://doi.org/10.1016/j.ptsp.2023.02.003. <lb/>[5] G. Cai, et al., Knee symptom but not radiographic knee osteoarthritis increases the risk of falls and fractures: results from the Osteoarthritis Initiative, <lb/>Osteoarthritis Cartilage 30 (3) (2022) 436-442, https://doi.org/10.1016/j.joca.2021.11.015. <lb/>[6] N. Hammami, et al., Isokinetic strengthening and neuromuscular electrical stimulation protocol impact on physical performances, functional status and quality <lb/>of life in knee osteoarthritis overweight/obese women, Knee 39 (2022) 106-115, https://doi.org/10.1016/j.knee.2022.09.004. <lb/>[7] H. Bonakdari, J.P. Pelletier, F. Abram, J. Martel-Pelletier, A machine learning model to predict knee osteoarthritis cartilage volume changes over time using <lb/>baseline bone Curvature, Biomedicines 10 (6) (2022), https://doi.org/10.3390/biomedicines10061247. <lb/>[8] S.M. Ahmed, R.J. Mstafa, Identifying severity grading of knee osteoarthritis from X-ray images using an efficient mixture of deep learning and machine learning <lb/>models, Diagnostics 12 (12) (2022), https://doi.org/10.3390/diagnostics12122939. <lb/>[9] M. Hall, et al., How does hip osteoarthritis differ from knee osteoarthritis? Osteoarthritis Cartilage 30 (1) (2022) 32-41, https://doi.org/10.1186/s13075-023-<lb/>03179-4. <lb/>[10] O. Al-Dadah, G. Hawes, P.J. Chapman-Sheath, J.W. Tice, D.S. Barrett, Unicompartmental vs. segmental bicompartmental vs. total knee replacement: comparison <lb/>of clinical outcomes, Knee Surg. Relat. Res. 32 (1) (2020), https://doi.org/10.1186/s43019-020-00065-0. <lb/>[11] J.C. Stoddart, O. Dandridge, A. Garner, J. Cobb, R.J. van Arkel, The compartmental distribution of knee osteoarthritis -a systematic review and meta-analysis, <lb/>Osteoarthritis Cartilage 29 (4) (2021) 445-455, https://doi.org/10.1016/j.joca.2020.10.011. <lb/>[12] K. Wada, A. Price, K. Gromov, S. Lustig, A. Troelsen, Clinical outcome of bi-unicompartmental knee arthroplasty for both medial and lateral femorotibial <lb/>arthritis: a systematic review-is there proof of concept? Arch. Orthop. Trauma Surg. 140 (10) (2020) 1503-1513, https://doi.org/10.1007/s00402-020-03492-<lb/>6. <lb/>[13] B. Moradi, et al., Unicompartmental and bicompartmental knee osteoarthritis show different patterns of mononuclear cell infiltration and cytokine release in the <lb/>affected joints, Clin. Exp. 180 (1) (2015) 143-154, https://doi.org/10.1111/cei.12486. <lb/>[14] S.M. Naguib, H.M. Hamza, K.M. Hosny, M.K. Saleh, M.A. Kassem, Classification of cervical spine fracture and dislocation using refined pre-trained deep model <lb/>and saliency map, Diagnostics 13 (7) (2023) 1-16, https://doi.org/10.3390/diagnostics13071273. <lb/>[15] J. Hirvasniemi, et al., The KNee OsteoArthritis Prediction (KNOAP2020) Challenge: an image analysis challenge to predict incident symptomatic radiographic <lb/>knee osteoarthritis from MRI and X-ray images, Osteoarthritis Cartilage 31 (1) (2023) 115-125, https://doi.org/10.1016/j.joca.2022.10.001. <lb/>[16] M. Binvignat, et al., Use of machine learning in osteoarthritis research: a systematic literature review, RMD Open 8 (1) (2022) 1-10, https://doi.org/10.1136/ <lb/>rmdopen-2021-001998. <lb/></listBibl>

			<body>Table 2 <lb/>Performance measure with data augmentation. <lb/>Accuracy <lb/>specificity <lb/>Alexnet <lb/>52.72 <lb/>66.33 <lb/>Darknet53 <lb/>49.7 <lb/>64 <lb/>Mobilenetv2 <lb/>60 <lb/>68 <lb/>Shuffelnet <lb/>59.94 <lb/>65.67 <lb/>Googlenet <lb/>51.52 <lb/>67 <lb/>The proposed model <lb/>61.81 <lb/>68.33 <lb/>Fig. 11. Clarification of the obtained results for the proposed method and Alexnet with transfer learning after data augmentation. <lb/></body>

			<note place="headnote">S.M. Naguib et al. <lb/>Heliyon 10 (2024) e31017 <lb/></note>

			<page>10 <lb/></page>

			<listBibl>[17] M.S. Arif, A. Mukheimer, D. Asif, Enhancing the early detection of chronic kidney disease: a robust machine learning model, Big Data Cogn. Comput. 7 (3) <lb/>(2023) 144, https://doi.org/10.3390/bdcc7030144. <lb/>[18] N. Pongsakonpruttikul, et al., Artificial intelligence assistance in radiographic detection and classification of knee osteoarthritis and its severity: a cross-sectional <lb/>diagnostic study, Eur. Rev. Med. Pharmacol. Sci. 26 (5) (2022) 1549-1558, https://doi.org/10.26355/eurrev_202203_28220. <lb/>[19] S. Aslan, Automatic detection of knee osteoarthritis disease with the developed CNN, NCA, and SVM-based hybrid model. Trait, Du Signal. 40 (1) (2023) <lb/>317-326, https://doi.org/10.18280/ts.400131. <lb/>[20] B.A.S. Al-rimy, F. Saeed, M. Al-Sarem, A.M. Albarrak, S.N. An adaptive early stopping technique for DenseNet169-based knee osteoarthritis detection <lb/>model, Diagnostics 13 (11) (2023), https://doi.org/10.3390/diagnostics13111903. <lb/>[21] M.A. Kassem, S.M. Naguib, H.M. Hamza, M.M. Fouda, M.K. Saleh, K.M. Hosny, Explainable transfer learning-based deep learning model for pelvis fracture <lb/>detection, Int. J. Intell. Syst. 2023 (2023, Jun), https://doi.org/10.1155/2023/3281998. Article ID 3281998, 10 pages. <lb/>[22] Y.S. Alsahafi, M.A. Kassem, K.M. Hosny, Skin-Net: a novel deep residual network for skin lesions classification using multilevel feature extraction and cross-<lb/>channel correlation with detection of outlier, J Big Data 10 (1) (2023, Jun) 105, https://doi.org/10.1186/s40537-023-00769-6. <lb/>[23] M.M. Eltoukhy, K.M. Hosny, M.A. Kassem, Classification of multiclass histopathological breast images using residual deep learning, Comput. Intell. Neurosci. <lb/>2022 (2022, Oct), https://doi.org/10.1155/2022/9086060. Article ID 9086060, 10 pages. <lb/>[24] K.M. Hosny, M.A. Kassem, Refined residual deep convolutional network for skin lesion classification, J. Digit. Imag. 35 (2022) 258-280, https://doi.org/ <lb/>10.1007/s10278-021-00552-0. <lb/>[25] K. Djoulde, B. Ousman, A. Hamadjam, L. Bitjoka, C. Tchiegang, Classification of pepper seeds by machine learning using color filter array images, Journal of <lb/>Imaging 10 (2) (2024), https://doi.org/10.3390/jimaging10020041. <lb/>[26] M.A. Kassem, K.M. Hosny, R. Damaševičius, M.M. Eltoukhy, Machine learning and deep learning methods for skin lesion classification and diagnosis: a <lb/>systematic review, Diagnostics 11 (8) (2021, Jul) 1390, https://doi.org/10.3390/diagnostics11081390. <lb/>[27] M.W. Insha, A. Sakshi, Knee X-Ray Osteoporosis Database, Mendeley Data, V2, 2021. <lb/>[28] https://www.kaggle.com/datasets/stevepython/osteoporosis-knee-xray-dataset?resource=download. <lb/>[29] M. Stojanovi, Understanding sensitivity specificity and predictive values, Vojnosanit. Pregl. 71 (11) (2014) 1062-1065, https://doi.org/10.2298/vsp1411062s. <lb/></listBibl>

			<note place="headnote">S.M. Naguib et al. </note>


	</text>
</tei>
