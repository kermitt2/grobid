<?xml version="1.0" ?>
<tei>
	<teiHeader>
		<fileDesc xml:id="-1"/>
	</teiHeader>
	<text xml:lang="en">
			<front> Proceedings of the Workshop on BioNLP: Shared Task, pages 115–118, <lb/>Boulder, Colorado, June 2009. c <lb/> 2009 Association for Computational Linguistics <lb/> Biomedical Event Detection using Rules, <lb/>Conditional Random Fields and Parse Tree Distances <lb/> Farzaneh Sarafraz*, James Eales*, Reza Mohammadi  ♦ <lb/> ♦ ♦ <lb/>♦  , Jonathan Dickerson  ♣ <lb/>♣ ♣ <lb/>♣  , <lb/>David Robertson  ♣ <lb/>♣ ♣ <lb/>♣  , Goran Nenadic* <lb/> *  School of Computer Science, University of Manchester <lb/> ♣  Faulty of Life Sciences, University of Manchester <lb/> ♦  Dept. of Mathematics and Computer Science, Sharif University of Technology <lb/> sarafraf@cs.man.ac.uk, g.nenadic@manchester.ac.uk <lb/> Abstract <lb/> This paper reports on a system developed for <lb/>the BioNLP&apos;09 shared task on detection and <lb/>characterisation of biomedical events. Event <lb/>triggers and types were recognised using a <lb/>conditional random field classifier and a set of <lb/>rules, while event participants were identified <lb/>using a rule-based system that relied on rela-<lb/>tive distances between candidate entities and <lb/>the trigger in the associated parse tree. The re-<lb/>sults on previously unseen test data were en-<lb/>couraging: for non-regulatory events, the F-<lb/>score was almost 50% (with precision above <lb/>60%), with the overall F-score of around 30% <lb/>(49% precision). The performance on more <lb/>complex regulatory events was poor <lb/>(F-measure of 7%). Among the 24 teams <lb/>submitting the test results, our results were <lb/>ranked 12 th for the overall F-score and 8 th for <lb/>the F-score of non-regulation events. <lb/></front>

			<body> 1 Introduction <lb/> The aim of the BioNLP&apos;09 shared task 1 was to <lb/>characterise molecular events being reported in a <lb/>Medline abstract by identifying the textual trigger, <lb/>event type and participating entities (Kim et al. <lb/>2009). Nine event types were considered: gene <lb/> expression, transcription, protein catabolism, lo-<lb/>calisation, phosporylation, binding, regulation, <lb/>positive regulation, and negative regulation. De-<lb/>pending on the event type, the task included the <lb/>identification of either one (for the first five event <lb/>types mentioned above) or more (e.g. for binding) <lb/> participating proteins. Information requested for <lb/>regulatory events was more complex: in addition to <lb/>one theme (a protein or another event), these <lb/>events could also have a cause (a protein or an-<lb/>other event) that needed to be identified. <lb/>The organisers have distributed a training <lb/>dataset of 800 abstracts, with gene and gene prod-<lb/>uct mentions pre-annotated in text. In addition, a <lb/>development set (150 abstracts) was provided to <lb/>assess the quality of the extractions during the <lb/>training and development phases. <lb/> 2 Methods <lb/> The system developed for the challenge consists of <lb/>three main modules: (1) event trigger and type de-<lb/>tection, (2) event participant detection, and <lb/>(3) post-processing of the results. <lb/> 2.1 Event Trigger and Type Detection <lb/> Our view of the event trigger and type detection <lb/>subtask was that each token in a sentence needed <lb/>to be tagged either as a trigger for one of the nine <lb/>event types, or as a non-trigger/event token. We <lb/>therefore decided to identify event types and trig-<lb/>gers in a single step by training a conditional ran-<lb/>dom field (CRF) classifier that assigned one of ten <lb/>(nine types plus non-trigger) tags to each token. <lb/>CRFs have been shown to be particularly suitable <lb/>for tagging sequential data such as natural lan-<lb/>guage text, because they take into account features <lb/>and tags of neighbouring tokens when evaluating <lb/>the probability of a tag for a given token. <lb/>Tokens and their part-of-speech (POS) tags <lb/>were recognised using the Genia Tagger (Tsuruoka <lb/>et al. 2005). Each stemmed token was represented <lb/>using a feature vector consisting of the following <lb/>features: <lb/> • A binary feature indicating whether the to-<lb/>ken is a protein; <lb/> • A binary feature indicating whether the to-<lb/>ken is a known protein-protein interaction <lb/>word (we used a pre-complied dictionary of <lb/></body>

			<page> 115 <lb/></page>

			<body> such words collected from previous studies <lb/>(Fu et al. 2008; Yang et al. 2008); <lb/> • The token&apos;s POS tag; <lb/> • The log-frequencies of the token being a <lb/>trigger for each event type in the training <lb/>data (nine features); <lb/> • The number of proteins in the given sen-<lb/>tence. <lb/>Other features (e.g. separating the known inter-<lb/>action words according to the nine event types) <lb/>were explored during the development phase, but <lb/>were not included in the final feature list since they <lb/>increased the sparseness of the data and did not <lb/>improve the overall results. The CRF parameters <lb/>were adjusted for maximum performance, includ-<lb/>ing the choice of training algorithms, the number <lb/>of training steps, the size of the window within <lb/>which the tokens can affect any certain token, and <lb/>the number of training abstracts used in each train-<lb/>ing step. It was interesting to notice that there were <lb/>no significant improvements in the performance <lb/>after training on 100, 400 or 800 abstracts from the <lb/>training set (data not shown). <lb/> 2.2 Locating Event Themes <lb/> After detecting potential triggers and associated <lb/>event types, the next task was to locate possible <lb/>participants (i.e. &apos;themes&apos; and &apos;causes&apos;) for each <lb/>event. It was obvious that participants did not have <lb/>to be the nearest to the trigger on the surface level, <lb/>so our approach was based on distances within the <lb/>parse trees associated with the sentences contain-<lb/>ing candidate events. Parse tree distances have <lb/>been studied previously in clustering and automatic <lb/>translation tasks (Emms 2008), so we hypothesised <lb/>that we could use them to identify the most likely <lb/>participants. The training data was analysed for the <lb/>proximities between the triggers and the (correct) <lb/>event participants in the parse tree of the sentence. 1 <lb/> Figure 1 gives a detailed density function of these <lb/>distances (ignoring non-protein nodes). The analy-<lb/>sis showed that a theme was usually amongst the <lb/>nearest proteins to the trigger in terms of parse tree <lb/>distances: for example, in 60% of all single theme <lb/>events (e.g. localisation, phosphorylation) the cor-<lb/>rect protein participant was the trigger&apos;s nearest or <lb/>second nearest protein in the parse tree. A further <lb/> 
			
			<note place="footnote">1 The parse trees were produced by the GDep parser (Sagae <lb/>and Tsujii, 2007) and supplied by the challenge organisers. <lb/></note>
			
			analysis demonstrated that it was more likely for a <lb/>theme to appear in the sub-tree of the correspond-<lb/>ing trigger, with 70% of all single theme events <lb/>having a theme which appeared in the sub-tree of <lb/>the trigger. Furthermore, specific analyses of the <lb/>parse trees associated to the binding events (which <lb/>can have more than one theme) suggested a linear <lb/>relationship between the parse tree distance and <lb/>binding event participant number (participant 1 is <lb/>the nearest, participant 2 is the second nearest, etc.). <lb/> Figure 1: Probability density function of the distance <lb/>between the trigger and the theme in the parse tree <lb/>(ignoring the tokens that are not proteins) <lb/> We used this distributional analysis (derived <lb/>from the training data) to design a rule-based <lb/>method for the identification of participating <lb/>themes. The rules were manually derived for each <lb/>of the nine event classes, by defining: <lb/> • a threshold for the maximum distance to the <lb/>trigger in the sub-tree for the given event <lb/>type; <lb/> • a threshold for the difference between the <lb/>maximum distance in the whole tree and the <lb/>given sub-tree for the given event type; <lb/> • the number of nearest proteins to be re-<lb/>ported for each trigger. <lb/>All entities that satisfied a distance-based rule <lb/>for a given trigger were selected as the correspond-<lb/>ing theme(s). For example, if the event type is <lb/> binding, then up to the second closest protein in the <lb/>sub-tree, and the first closest protein in the rest of <lb/>the tree are reported as themes. <lb/>
			
			<page> 116 <lb/></page>

			Figure 2 provides an example of the method ap-<lb/>plied to a sentence with multiple events. Regulates <lb/> and secretion are correctly identified as triggers for <lb/>a regulation and a localization event in the first <lb/>phase. Using the rules for localization, the themes <lb/>for two localization events are correctly recognised <lb/>as proteins T2 and T3, whereas T1 was ignored <lb/>since it did not appear in the trigger&apos;s sub-tree. <lb/>Engineering and applying rules for non-<lb/>regulatory events was relatively straightforward. <lb/>However, regulatory events can have different <lb/>kinds of participants (a protein or an event). In the <lb/>case of an event, we were trying to locate the near-<lb/>est trigger for the event (being regulated) in the <lb/>parse tree. For example, in Figure 2, the nearest <lb/>option to the regulation trigger (secretion) was the <lb/>trigger of the two localization events, and both <lb/>events should be (correctly) reported as the themes <lb/>of two regulation events. Therefore, we require a <lb/>number of recursions in the application of the rules <lb/>to represent higher-order regulatory dependences. <lb/>For the purposes of this challenge, only regulations <lb/>up to the second &quot; order &quot; were detected, allowing <lb/>other events to act as themes and causes as well as <lb/>proteins. Attempts to find more complicated regu-<lb/>latory events using this method resulted in a de-<lb/>creased precision and/or F-score. <lb/> 2.3 Post-processing Event Profiles <lb/> The performance of the first two phases was <lb/>studied on the development dataset: we noted a <lb/>number of false-positive and false-negative results <lb/>that were mostly due to a set of recurring triggers. <lb/>We therefore decided to perform a post-processing <lb/>step to improve the identification of event triggers <lb/>and associated types. In the first step (improving <lb/>the event trigger and type detection), the output of <lb/>the CRF was overridden in cases where the triggers <lb/>appeared in a list of negatively discriminated trig-<lb/>ger words which was collected after the manual <lb/>analysis of the false positive results on the training <lb/>and development data. Similarly, in cases where <lb/>the CRF missed a highly indicative trigger (from a <lb/>manually collected set) for a given event type, the <lb/>trigger was added as part of post-processing. In the <lb/>latter case, the sentence was then processed for the <lb/>event theme detection (as described in 2.2). <lb/>In the second step of the pre-processing phase, <lb/>we forced highly indicative regulation triggers (if <lb/>not previously identified) to be associated with an <lb/> Figure 2: The parse tree of sentence Monocyte tethering <lb/>by P-selectin regulates monocyte chemotactic protein-1 <lb/>and tumor necrosis factor-alpha secretion. The triggers <lb/>are shown in boxes, and the entities are numbered. <lb/> event by assigning proteins appearing in the sen-<lb/>tence to them, even when no protein in the sen-<lb/>tence satisfied the theme or cause criteria described <lb/>in Section 2.2. This was aimed at improving the <lb/>extremely low recall for regulatory events. <lb/>Finally, since triggers could consist of more than <lb/>one consecutive token, a set of simple rules were <lb/>applied to remove typical false-negative constitu-<lb/>ents identified by the CRF as part of triggers (e.g. <lb/>sometimes linking words appeared within triggers). <lb/> 3 Results and discussion <lb/> The task 1 assessment was based on the output of <lb/>the system when applied to the test dataset of 260 <lb/>previously unseen abstracts. An event was counted <lb/>as a true positive if its type, trigger and all partici-<lb/>pants had been correctly identified. The overall F-<lb/>score for our system was 30.35% with 48.61% pre-<lb/>cision (approximate span matching, see Table 1). <lb/>The best performing event types were phosphory-<lb/>lation (the best F-score and the best recall) and <lb/> gene expression (the best precision with a reasona-<lb/>bly good F-measure). While the results for non-<lb/>regulatory events were encouraging, they were low <lb/>for regulatory events. Among the 24 teams submit-<lb/>ting the test results, our results were ranked 12 th for <lb/>the overall F-score and 8 th for the F-score of non-<lb/>regulation events. <lb/>A preliminary analysis of the results was per-<lb/>formed on the development data (as the test data is <lb/>not available), which had around 5% higher overall <lb/>F-score than the test data (9% for non-regulation <lb/>events, see Table 2 for details). <lb/>

			<page> 117 <lb/></page>

			Event Class <lb/>#Gold <lb/>R <lb/>P <lb/>F-score <lb/> Localisation <lb/> 174 <lb/>44.83 53.06 <lb/>48.60 <lb/>Binding <lb/>347 <lb/>12.68 40.37 <lb/>19.30 <lb/>Gene expression <lb/>722 <lb/>52.63 69.34 <lb/> 59.84 <lb/>Transcription <lb/>137 <lb/>15.33 67.74 <lb/>25.00 <lb/>Protein catabolism <lb/>14 <lb/>42.86 50.00 <lb/>46.15 <lb/>Phosphorylation <lb/>135 <lb/> 78.52 53.81 <lb/> 63.86 <lb/> Non-reg total <lb/>1529 <lb/>41.53 60.82 <lb/>49.36 <lb/>Regulation <lb/>291 <lb/>3.09 <lb/>19.15 <lb/>5.33 <lb/>Positive regulation <lb/>983 <lb/>1.12 <lb/>8.87 <lb/>1.99 <lb/>Neg. regulation <lb/>379 <lb/>12.4 <lb/>20.52 <lb/>15.46 <lb/>Regulatory total <lb/>1653 <lb/>4.05 <lb/>16.75 <lb/>6.53 <lb/>All total <lb/>3182 <lb/>22.06 48.61 <lb/>30.35 <lb/>Table 1: Evaluation of the test data (260 abstracts), <lb/>(approximate span matching; #Gold = the number of <lb/>examples in the gold standard) <lb/> In order to assess the effects of different steps <lb/>in our approach, we evaluated the performance of <lb/>the event trigger and event participant detection <lb/>steps separately. The results presented in Table 3 <lb/>indicated that the performance of the CRF module <lb/>was not much better than the overall performance <lb/>of the system (an F-score of 43% vs. 35%), sug-<lb/>gesting that the CRF part was mostly responsible <lb/>for the errors, by both missing triggers and falsely <lb/>reporting them. This was particularly the case with <lb/>non-regulatory events (even for binding). Con-<lb/>versely, when considering only those events whose <lb/>triggers were correctly identified, their participants <lb/>were also correctly recognised in most cases. <lb/>Overall, the analysis suggested that the parse tree <lb/>distance method performed reasonable well, de-<lb/>spite a reduction in recall of approximately 12%. <lb/>There are a number of possibilities for im-<lb/>provements. We believe applying the CRF model <lb/>in two stages would be a better approach to detect <lb/> Event Class <lb/>#Gold <lb/>R <lb/>P <lb/>F-score <lb/> Localisation <lb/>40 77.50 <lb/>47.69 <lb/>59.05 <lb/>Binding <lb/>180 33.33 <lb/>54.55 <lb/>41.38 <lb/>Gene expression <lb/>282 76.60 <lb/>58.54 <lb/>66.36 <lb/>Transcription <lb/>68 58.82 <lb/>18.60 <lb/>28.27 <lb/>Protein catabolism <lb/>19 84.21 <lb/> 88.89 <lb/> 86.49 <lb/>Phosphorylation <lb/>40 97.50 <lb/> 81.25 <lb/> 88.64 <lb/> Non-reg total <lb/>629 63.91 <lb/>48.73 <lb/>55.30 <lb/>Regulation <lb/>138 13.04 <lb/>62.07 <lb/>21.56 <lb/>Positive regulation <lb/>462 13.85 <lb/>54.24 <lb/>22.07 <lb/>Neg. regulation <lb/>153 29.41 <lb/>45.92 <lb/>35.86 <lb/>All total <lb/>1382 38.28 <lb/>49.44 <lb/>43.15 <lb/>Table 3: Trigger-only evaluation of the development data <lb/> Event Class <lb/>#Gold <lb/>R <lb/>P <lb/>F-score <lb/> Localisation <lb/>53 <lb/>67.92 46.75 <lb/>55.38 <lb/>Binding <lb/>312 <lb/>21.47 63.81 <lb/>32.13 <lb/>Gene expression <lb/>356 <lb/>64.61 76.33 <lb/>69.98 <lb/>Transcription <lb/>82 <lb/>53.66 89.80 <lb/> 67.18 <lb/>Protein catabolism <lb/>21 <lb/>90.48 67.86 <lb/> 77.55 <lb/> Phosphorylation <lb/>47 <lb/> 91.49 53.09 <lb/>67.19 <lb/>Non-reg total <lb/>871 <lb/>50.4 <lb/>68.44 <lb/>58.05 <lb/>Regulation <lb/>172 <lb/>5.23 <lb/>33.33 <lb/>9.05 <lb/>Positive regulation <lb/>632 <lb/>3.48 <lb/>21.36 <lb/>5.99 <lb/>Neg. regulation <lb/>201 <lb/>9.45 <lb/>15.08 <lb/>11.62 <lb/>Regulatory total <lb/>1005 <lb/>4.98 <lb/>19.53 <lb/>7.93 <lb/>All total <lb/>1876 <lb/>26.07 54.46 <lb/>35.26 <lb/>Table 2: Evaluation of the development data (150 abstracts) <lb/>(approximate span matching; #Gold as in Table 1) <lb/> events: first identify triggers and then link them to <lb/>event classes. In addition, the rules employed for <lb/>determining themes need to be more specific to <lb/>reflect both event type and grammatical structure. <lb/>In the case of regulatory events, however, signifi-<lb/>cantly better results were noticed in the trigger de-<lb/>tection part when compared to the overall scores, <lb/>indicating that it was difficult to identify regulatory <lb/>participants, as any of those participants could be <lb/>either a protein or another event. <lb/>Overall, the results achieved by our system <lb/>suggest that combining parse tree results, rules and <lb/>CRFs is a promising approach for the identification <lb/>of non-regulatory events in the literature, while <lb/>more work would be needed for regulatory events. <lb/>
		
		</body>

		<back>

			<listBibl> References <lb/> Emms M. 2008. Tree-distance and some other Variants <lb/>of evalb. Proc. of LREC 2008, pp 1373-1379. <lb/>Fu W. et al. 2008. Human Immunodeficiency Virus type <lb/>1, Human protein interaction database at NCBI, Nu-<lb/>cleic Acid Research 2008, D417-D422 <lb/>Kim JD et al. 2009. Overview of BioNLP&apos;09 Shared <lb/>Task on Event Extraction, Proc. of BioNLP NAACL <lb/>2009 Workshop (to appear) <lb/>Sagae K, Tsujii J. 2007. Dependency Parsing and Do-<lb/>main Adaptation with LR Models and Parser Ensem-<lb/>bles. Proc. of the CoNLL 2007 Shared Task, 1044-50 <lb/>Tsuruoka Y. et al. 2005. Developing a Robust Part of-<lb/>Speech Tagger for Biomedical Text. Advances in In-<lb/>formatics, 382–392. <lb/>Yang H. et al. 2008. Identification of Transcription Fac-<lb/>tor Contexts in Literature using Machine Learning <lb/>Approaches. BMC Bioinformatics, Vol. 9(3):S11. <lb/></listBibl>

			<page> 118 </page>

		</back>
	</text>
</tei>
