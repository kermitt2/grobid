<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Noise Control In Gene Regulatory Networks <lb/>With Negative Feedback <lb/>Michael Hinczewski * , † and D. Thirumalai * , ‡ <lb/> †Department of Physics, Case Western Reserve University, OH 44106 <lb/> ‡Department of Chemistry, The University of Texas at Austin, TX 78712 <lb/>E-mail: mxh605@case.edu; dave.thirumalai@gmail.com <lb/> 1 <lb/> Abstract <lb/>Genes and proteins regulate cellular functions through complex circuits of biochem-<lb/>ical reactions. Fluctuations in the components of these regulatory networks result in <lb/>noise that invariably corrupts the signal, possibly compromising function. Here, we <lb/>create a practical formalism based on ideas introduced by Wiener and Kolmogorov <lb/>(WK) for filtering noise in engineered communications systems to quantitatively assess <lb/>the extent to which noise can be controlled in biological processes involving negative <lb/>feedback. Application of the theory, which reproduces the previously proven scaling of <lb/>the lower bound for noise suppression in terms of the number of signaling events, shows <lb/>that a tetracycline repressor-based negative-regulatory gene circuit behaves as a WK <lb/>filter. For the class of Hill-like nonlinear regulatory functions, this type of filter provides <lb/>the optimal reduction in noise. Our theoretical approach can be readily combined with <lb/>experimental measurements of response functions in a wide variety of genetic circuits, <lb/>to elucidate the general principles by which biological networks minimize noise. <lb/></front>

			<body>The genetic regulatory circuits that control all aspects of life are inherently stochas-<lb/>tic. They depend on fluctuating populations of biomolecules interacting across the crowded, <lb/>thermally agitated interior of the cell. Noise is also exacerbated by low copy numbers of <lb/>particular proteins and mRNAs, as well as variability in the local environment. 1-6 Yet the <lb/>robust and reproducible functioning of key systems requires mechanisms to filter out fluctua-<lb/>tions. For example, regulating noise is relevant in stabilizing cell-fate decisions in embryonic <lb/>development, 7 prevention of random switching to proliferating states in cancer-regulating <lb/>miRNA networks, 8 and maximization of the efficiency of bacterial chemotaxis along attrac-<lb/>tant gradients. 9 Comprehensive analysis of yeast protein expression reveals that proteins <lb/>involved in translation initiation, ribosome formation, and protein degradation, have lower <lb/>relative noise levels, 10 suggesting natural selection could favor noise reduction for certain <lb/>essential cellular components. 11,12 <lb/>A common regulatory motif capable of suppressing noise is the negative feedback loop, 1,2,13-18 <lb/>as has been explicitly demonstrated in synthetic gene circuits. 1,14,15 Feedback pathways for a <lb/></body>

			<page>2 <lb/></page>

			<body>given chemical species can be mediated by numerous signaling molecules, each with its own <lb/>web of interactions and stochastic characteristics that determine the ultimate effectiveness <lb/>of the system in damping the fluctuations of the target population and maintaining home-<lb/>ostasis. Thus, uncovering generic laws governing the behavior of such control networks is <lb/>difficult. A major advance was made by Lestas, Vinnicombe, and Paulsson (LVP), 19 who <lb/>showed that information theory can set a rigorous lower bound on the magnitude of fluc-<lb/>tuations within an arbitrarily complicated homeostatic negative feedback network. Since <lb/>the bound scales like the fourth root of the number of signaling events, noise reduction is <lb/>extremely expensive. This underscores the pervasiveness of biological noise, even in cases <lb/>where there may be evolutionary pressure to minimize it. <lb/>The existence of a rigorous bound raises a number of intriguing issues. Can a biochemical <lb/>network actually reach this lower bound, and thus optimally suppress fluctuations? What <lb/>would be the dynamic behavior of such an optimal system, and how would it depend on the <lb/>noise spectrum of the system components? Here we answer these equations using a theory re-<lb/>lated to the optimal linear noise-reduction filter, developed by Wiener 20 and Kolmogorov. 21 <lb/>Though the original context of Wiener-Kolmogorov (WK) filter theory was removing noise <lb/>from corrupted signals in engineered communications systems, it has recently become a <lb/>powerful tool for characterizing the constraints on signaling in biochemical networks. 22,23 <lb/>Recently, we showed that the action of kinase and phosphatase enzymes on their protein <lb/>substrates, the basic elements of many cellular signaling pathways, can in fact effectively <lb/>be represented as an optimal WK filter. 22 The WK theory also describes how systems like <lb/>E. coli chemotaxis can optimally anticipate future changes in concentrations of extracellular <lb/>ligands. 23 Although the classic WK theory is strictly defined for linear filtering of contin-<lb/>uous signals (a reasonable approximation for certain biochemical networks), it can also be <lb/>extended to yield constraints in the more general case of nonlinear production of molecular <lb/>species with discrete population values. 22 <lb/>Interestingly, for a broad class of systems the WK linear solution turns out to be the <lb/></body>

			<page>3 <lb/></page>

			<body>global optimum among all nonlinear or linear networks, allowing us to delineate where non-<lb/>linearity is potentially advantageous in biochemical noise control. Most importantly, since <lb/>the WK theory is formulated in terms of experimentally accessible dynamic response func-<lb/>tions, it also provides a design template for realizing optimality in synthetic circuits. As <lb/>an illustrative example, we predict that a synthetic autoregulatory TetR loop, engineered <lb/>in yeast, 24 can be fine-tuned to approximate an optimal WK filter for TetR mRNA levels. <lb/>Though a simple design, similar filters could be employed in nature to cope with Poisson <lb/>noise arising from small copy numbers of mRNAs, often on the order of 10 per cell. 25 Based <lb/>on the application of the theory to the synthetic gene network we propose that the extent of <lb/>noise reduction in biological circuits is determined by competing factors such as functional <lb/>efficiency, adaptation, and robustness. <lb/>Results <lb/>To make the paper readable and as self-contained as possible many of the details of the <lb/>calculation are relegated to four Appendices. The main text contains only the necessary <lb/>details needed to follow the results without the distraction of the mathematics. <lb/>Linear response theory for a general control network <lb/>To motivate the WK approach for a general control network, we start with the simple case <lb/>where two species within the network are explicitly singled out: 19 a target R with time-<lb/>varying population r(t) fluctuating around mean r, and one of the mediators in the feedback <lb/>signaling pathway P , with population p(t) varying around p. We assume a continuum <lb/>Langevin description of the dynamics, 13,16,26,27 where the rate <lb/>α(t) = k α (t) + n α (t) <lb/>(1) <lb/></body>

			<page>4 <lb/></page>

			<body>for α = r or p, can be broken down into deterministic (k α ) and stochastic (n α ) parts. The <lb/>function k α (t) encapsulates the entire web of biochemical reactions underlying synthesis and <lb/>degradation of species α, and can be an arbitrary functional of the past history of the system <lb/>up to time t. It is typically divided into two parts, k α (t) = k + <lb/>α (t) − k − <lb/>α (t), corresponding <lb/>to the production (+) and destruction (-) rates of the species α. The term n α (t) is the <lb/>additive noise contribution, which can also be divided into two parts, n α (t) = n int <lb/>α (t)+n ext <lb/>α (t). <lb/>The first is the &quot;intrinsic&quot; or shot noise, arising from the stochastic Poisson nature of α <lb/>generation, n int <lb/>α (t) = 2 kα η α (t), where kα is the mean production rate, or equivalently the <lb/>mean destruction rate, kα = k + <lb/>α (t) = k − <lb/>α (t), and η α (t) is a Gaussian white noise function with <lb/>correlation η α (t)η α (t ) = δ αα δ(t − t ). The second part, n ext <lb/>α (t), is &quot;extrinsic&quot; noise, which <lb/>arises due to fluctuations in cellular components affecting the dynamics of R and P that are <lb/>not explicitly taken into account in the two-species picture. These could include mediators <lb/>in the signaling pathway, or global factors like ribosome and RNA polymerase levels. For <lb/>simplicity, our main focus will be the case of no extrinsic noise. However, we will show later <lb/>how a straightforward extension of the theory reveals that the same system can behave like <lb/>an optimal WK filter under a variety of extrinsic noise conditions. <lb/>For small deviations δα(t) = α(t)− ᾱ from the mean populations ᾱ, k α (t) can be linearized <lb/>with respect to δα(t), <lb/>k α (t) = <lb/>α =r,p <lb/>t <lb/>−∞ <lb/>dt G αα (t − t )δα (t ), <lb/>(2) <lb/>where G αα (t) are linear response functions, which express the dependence of k α (t) on the <lb/>past history of δα (t). The functions G αα (t) capture the essential characteristic responses <lb/>of the control network to perturbations away from equilibrium (Fig. 1). In the static limit, <lb/>G αα (t) have appeared in various guises as gains, 6 susceptibilities, 17 or steady-state Jacobian <lb/>matrices, 27 and in the frequency-domain as loop transfer functions. 13,16 Feedback between <lb/>R and P is encoded in the cross-responses G rp (t) and G pr (t). In the simplest scenario, the <lb/></body>

			<page>5 <lb/></page>

			<body>Figure 1: Schematic of a complex signaling network with the target species R and one <lb/>mediator P singled out. In focusing on two species, the action of all the other components is <lb/>effectively encoded in four response functions-G rr (t), G pp (t), G rp (t), G pr (t)-that describe <lb/>how the entire dynamical system responds to perturbations in R and P . <lb/>only non-zero self-responses G αα (t) are decay terms, G αα (t) = −τ −1 <lb/>α δ(t), where τ α is the <lb/>decay time scale for species α. However, the theory works generally for more complicated <lb/>self-response mechanisms. <lb/>Control network as a noise filter <lb/>The connection between the linearized dynamical description and WK filter theory arises <lb/>from comparing the original system to the case where feedback is turned off (i.e. setting <lb/>G rp (ω) or G pr (ω) to zero). Let us define a few terms to make the noise filter analogy <lb/>clear. Without feedback, the target fluctuations are δr 0 (t) ≡ s(t), where we denote s(t) the <lb/>signal. This is to distinguish it from δr(t) in the original system, which is the output. The <lb/>difference between the two, which reflects the impact of the feedback network, we express <lb/>as δr(t) = s(t) − s(t), where s(t) is referred to as the estimate. In this analogy, minimizing <lb/>δr(t) requires a feedback loop where the estimate s(t) is as close as possible to the signal <lb/>s(t). The only thing left to specify is the relationship between s(t) and s(t). <lb/>The dynamical system in Eqs. (1)-(2) takes a simple form in Fourier space, where the <lb/></body>

			<page>6 <lb/></page>

			<body>fluctuations δα(ω) satisfy: <lb/>−iωδα(ω) = <lb/>α =r,p <lb/>G αα (ω)δα (ω) + n α (ω). <lb/>(3) <lb/>We solve Eq. (3) for δr(ω) and break up the R fluctuation into two contributions, δr(ω) = <lb/>s(ω) − s(ω), with the signal s(ω) and estimate s(ω) given by: <lb/>s(ω) = − <lb/>n r (ω) <lb/>G rr (ω) + iω <lb/>, s(ω) = H(ω) [s(ω) + n(ω)] . <lb/>(4) <lb/>Here we have introduced a noise function n(ω), <lb/>n(ω) = <lb/>n p (ω) <lb/>G pr (ω) <lb/>, <lb/>(5) <lb/>and a filter function H(ω): <lb/>H(ω) ≡ <lb/>G rp (ω)G pr (ω) <lb/>G rp (ω)G pr (ω) − (G rr (ω) + iω)(G pp (ω) + iω) <lb/>. <lb/>(6) <lb/>Thus in the time domain the estimate s(t) is the convolution of the filter function H(t) and <lb/>a noise-corrupted signal y(t) ≡ s(t) + n(t), <lb/>s(t) = <lb/>∞ <lb/>−∞ <lb/>dt H(t − t )y(t ). <lb/>(7) <lb/>Eqs. (4)-(6) constitute a one-to-one mapping between the linear response and noise filter <lb/>descriptions of the system in Fourier space. They relate the four filter quantities, s(ω), s(ω), <lb/>n(ω), and H(ω), to the four linear response functions G rr (ω), G rp (ω), G pr (ω), and G pp (ω). <lb/>The entire noise filter system is illustrated schematically in Fig. 2. Note that the <lb/>noise function in the filter analogy, n(t), is related to n p (t) in Fourier space as n(ω) = <lb/>n p (ω)/G pr (ω). Thus, the stochastic nature of the mediator P production makes estimation <lb/>non-trivial, since the function H(t) must try to filter out the n(t) component in y(t) in order <lb/></body>

			<page>7 <lb/></page>

			<body>+ <lb/>+ <lb/>-<lb/>Figure 2: Signal processing diagram illustrating noise suppression in a negative feedback <lb/>loop re-interpreted as a linear filter. The fluctuations in the target species δr(t) (lower left) <lb/>are expressed as δr(t) = s(t) − s(t), where the raw signal s(t) (upper left) equals δr(t) in <lb/>the absence of feedback control, and the estimate s(t) (lower right) is the contribution of the <lb/>feedback loop. This estimate is given by the convolution of a filter function H(t) (center) <lb/>and the corrupted signal s(t) + n(t), where n(t) is the noise (upper right). The goal of <lb/>Wiener-Kolmogorov theory is to find a causal H(t) such that the standard deviation of δr(t) <lb/>is minimized. All sample trajectories shown in the figure are generated from numerically <lb/>solving the linearized version of the dynamical system in Eq. (10). <lb/>to produce s(t) close to s(t). Though we confine ourselves throughout this work to the case <lb/>of a dynamical system with a single target and mediator species, one can easily generalize the <lb/>entire approach to explicitly include many mediators, which could potentially be involved <lb/>in a complex signaling pathway. The linearized dynamical system in Eqs. (1)-(2) would still <lb/>have the same form (with index α running over all the species of interest), and the mapping <lb/>onto the filter problem for the target species would be analogous. The only difference is that <lb/>n(ω) and H(ω) would be more complicated functions of the various individual noise terms <lb/>n α (ω) and the response functions G αα (ω) of the mediators. In our reduced, two species <lb/>description, the action of all the unspecified chemical components is effectively included in <lb/>the four response functions described above, with their stochastic effects contributing to the <lb/>extrinsic noise. Fig. 1 shows a schematic of such a reduction. The fine-grained details of <lb/></body>

			<page>8 <lb/></page>

			<body>the signaling pathways connecting our target R and mediator P , potentially involving many <lb/>interacting species, are encoded in G rr , G pp , G rp , and G pr . As an example of how this two-<lb/>species reduction would work in practice, in Appendix B we treat an important example of <lb/>a feedback loop involving multiple mediators, representing a signaling cascade in series. <lb/>Wiener-Kolmogorov theory yields the optimal filter <lb/>The WK optimization problem consists of minimizing σ 2 <lb/>r = (δr) 2 , the variance of target fluc-<lb/>tuations, which are related to H(t), s(t), and n(t) through the frequency-domain integral 28 <lb/>(see derivation in Appendix A): <lb/>σ 2 <lb/>r = <lb/>∞ <lb/>−∞ <lb/>dω <lb/>2π <lb/>|H(ω)| 2 P n (ω) + |H(ω) − 1| 2 P s (ω) , <lb/>(8) <lb/>where H(ω) is the Fourier transform of H(t), and P n (ω), P s (ω) are the power spectral den-<lb/>sities (PSD) of n(t) and s(t) respectively, i.e. the Fourier transforms of their autocorrelation <lb/>functions. If P n (ω) and P s (ω) are given, the task is to minimize σ 2 <lb/>r in Eq. (8) over all pos-<lb/>sible H(ω). The main constraint that makes the solution mathematically difficult is that <lb/>H(ω) must correspond to a physically realizable control network, which imposes the crucial <lb/>restriction that the time-domain convolution function H(t) must be causal, depending only <lb/>on the past history of the input, H(t) = 0 for t &lt; 0. The great achievement of Wiener and <lb/>Kolmogorov was to derive the form of the optimal causal solution H opt (ω): <lb/>H opt (ω) = <lb/>1 <lb/>P c <lb/>y (ω) <lb/>P s (ω) <lb/>P c <lb/>y (ω) * <lb/>c <lb/>. <lb/>(9) <lb/>The c super/subscripts refer to two different decompositions in the frequency domain which <lb/>enforce causality: (i) Any physical PSD, in this case P y (ω) corresponding to the corrupted <lb/>signal y(t) = s(t) + n(t), can be written as P y (ω) = |P c <lb/>y (ω)| 2 . The factor P c <lb/>y (ω), if treated <lb/>as a function over the complex ω plane, contains no zeros and poles in the upper half-<lb/>plane (Im ω &gt; 0). 29 (ii) We also define an additive decomposition denoted by {F (ω)} c <lb/></body>

			<page>9 <lb/></page>

			<body>(see Appendix A) for any function F (ω), which consists of all terms in the partial fraction <lb/>expansion of F (ω) with no poles in the upper half-plane. In Appendix A we provide in detail <lb/>a new derivation of Eq. (9), the heart of the WK theory. <lb/>Optimal noise control in a yeast gene circuit with feedback <lb/>To illustrate the nature of the optimal WK solution we choose as a case study the yeast <lb/>negative autoregulatory gene circuit designed by Nevozhay et. al., 24 drawn schematically <lb/>in Fig. 3(a). The gene encoding for the TetR protein is under the control of the P GAL1−D12 <lb/>promoter, whose activity can be repressed by binding TetR dimers. The strength of the <lb/>feedback can be modulated by changing the extracellular concentration A of the inducer <lb/>anhydrotetracycline (ATc), which enters the cell, binds to TetR and prevents its association <lb/>with the promoter, thus weakening repression. <lb/>In order to analyze the TetR negative feedback gene circuit, we start with the simple <lb/>mathematical model introduced in Ref. 24, which provided results that are consistent with <lb/>the experimental data. The simplified model, which captures the essence of the synthetic <lb/>gene network, features as the main variables the population of free intracellular TetR dimer, <lb/>p(t), and free intracellular ATc molecules, a(t). In addition to the regulatory loop, the <lb/>experimental gene circuit has a parallel yEGFP reporter portion, which acts as a monitor <lb/>of TetR protein levels. Because we focus on the system as a noise filter for the TetR mRNA <lb/>population, and the yEGFP part does not influence this analysis, 24 we ignore the reporter <lb/>circuit. <lb/>The production of the TetR dimers occurs in a single step, with the autoregulation of the <lb/>rate described by a repressory Hill function. We divide this step into two parts, introducing <lb/>as an additional variable the population of TetR mRNA r(t). The feedback loop (Fig. 3(a)) <lb/>consists of mRNA production at a rate given by the Hill function κ r (t) = κ 0 θ n /(θ n + p n (t)), <lb/>followed by TetR dimer generation at a rate given by κ p r(t). The degradation/dilution <lb/>of the mRNA and dimers is modeled through decay terms γ r r(t) and γ p p(t). We could <lb/></body>

			<page>10 <lb/></page>

			<body>Figure 3: (a) The synthetic yeast gene circuit designed by Nevozhay et. al. 24 The TetR <lb/>protein negatively regulates itself by binding to its own promoter. The inducer molecule <lb/>ATc associates with TetR, inhibiting its repressor activity. The subsequent panels show <lb/>results for this gene circuit using the linear filter theory applied to the dynamical model of <lb/>Eq. (10), with experimentally-derived parameters (Table 1). (b) Filter functions H(t) and <lb/>H opt (t), sample signal s(t) and estimate s(t) time series for burst ratio B = 10 and three <lb/>different values of extracellular ATc concentration A [ng/mL]. H(t) is from Eq. (19), while <lb/>H opt (t) is from Eq. (18). The sample time series trajectories are numerical solutions of the <lb/>linearized Eq. (10). On the right are the resulting equilibrium probability distributions P (δr), <lb/>where δr(t) = s(t) − s(t), which are Gaussians with variance σ 2 <lb/>r . For A ≈ 54 ng/mL, the <lb/>circuit approximately functions as an optimal WK filter (H(t) is close to H opt (t)), maximally <lb/>suppressing fluctuations in the population levels of TetR mRNA (minimizing σ 2 <lb/>r /r). (c) <lb/>Mean populations of free intracellular TetR mRNA, r, and TetR protein dimers, p. (d) <lb/>The decay rates of free mRNA and proteins, τ −1 <lb/>r <lb/>and τ −1 <lb/>p , which are related to the network <lb/>self-response functions G rr and G pp (both are constants in the frequency domain as shown <lb/>in Eq.11). (e) The magnitude of the network cross-response, |G rp | (solid lines), plotted <lb/>together with the optimal magnitude |G opt <lb/>rp | = τ −1 <lb/>p (1 + <lb/>√ <lb/>1 + B) −1 (dashed lines). Filled <lb/>circles mark the intersection defining A = A opt , where the system behaves approximately <lb/>like an optimal WK filter. (f) The Fano factor σ 2 <lb/>r /r (solid lines), compared to the optimal <lb/>WK value σ 2 <lb/>r,opt /r = 2/(1 + <lb/>√ <lb/>1 + B) (horizontal dashed lines). Filled circles mark the <lb/>position A = A opt . <lb/></body>

			<page>11 <lb/></page>

			<body>have modeled additional (comparatively fast) chemical substeps involved in this loop, such <lb/>as TetR dimerization, the binding of the repressor to the individual promoter sites, or the <lb/>role of RNAP and ribosomes in the transcription and translation processes. Though we limit <lb/>ourselves to the two substep description to illustrate the filter theory, the stochastic effects of <lb/>additional complexity can be approximately treated through general &quot;extrinsic&quot; noise terms <lb/>incorporated into n r (t) and n p (t). <lb/>The main experimental variable that allows tuning of the yeast gene network behavior is <lb/>the external ATc concentration A, which is assumed to be time independent. As illustrated in <lb/>Fig. 2(a), there is an influx ΦA of ATc molecules into the cell. Once inside, the ATc molecules <lb/>associate with the TetR at a rate βa(t)p(t). Additional loss of intracellular ATc through <lb/>degradation, outflux, and dilution is modeled through an effective decay rate γ a a(t). We <lb/>assume that the dissociation of ATc from TetR occurs on long enough timescales that it can be <lb/>ignored. Since the influx/association/outflux of ATc is fast compared to the transcription and <lb/>translation processes of the main feedback loop, we further assume that a(t) instantaneously <lb/>equilibriates at the current value of p(t). Thus, the dependence of a(t) on p(t) is determined <lb/>by equating the influx and total loss rate, which leads to a(p(t)) = ΦA/(γ a + βp(t)). <lb/>For the model described above, the dynamical equations for r(t) and p(t) are, <lb/>ṙ(t) = −γ r r(t) + <lb/>κ 0 θ n <lb/>θ n + p n (t) <lb/>+ n r (t), <lb/>ṗ(t) = −γ p p(t) + κ p r(t) − <lb/>βΦAp(t) <lb/>γ a + βp(t) <lb/>+ n p (t). <lb/>(10) <lb/>The parameters, with values derived from experimental fitting, 24 are listed in Table 1. The <lb/>only quantity that is not independently known from the fit is the rate κ p , which we allow <lb/>to vary in the range κ p /γ r ≡ B = 2 − 10, comparable to typical experimentally measured <lb/>protein burst sizes. 30 Setting the right sides of Eq. (10) to zero, and averaging over n r (t) <lb/>and n p (t), we numerically solve for the equilibrium values r and p as a function of external <lb/>ATc concentration A [Fig. 3(c)]. For A = 0, the promoter is nearly fully repressed, but with <lb/></body>

			<page>12 <lb/></page>

			<body>Table 1: Parameter values for the dynamical model of the yeast synthetic gene <lb/>circuit (Eq. (10)). The cell volume V is assumed fixed. Unless otherwise noted, <lb/>all values are taken from the experimental fit of Ref. 24. <lb/>Parameter <lb/>Value <lb/>n <lb/>4 <lb/>θ <lb/>0.44 nM V <lb/>γ r <lb/>3.5 h −1 a <lb/>γ p <lb/>0.12 h −1 <lb/>γ a <lb/>1.2 h −1 <lb/>β <lb/>3.6 nM −1 h −1 V −1 <lb/>Φ <lb/>0.6 h −1 V <lb/>κ 0 <lb/>50 nM h −1 V B −1 b <lb/>A <lb/>0 − 500 ng/mL c <lb/>a Ref. 31 <lb/>b The burst ratio B ≡ κ p /γ r . Though not independently determined by the experimental fit, we assume <lb/>that B is in the range B = 2 − 10. 30 <lb/>c For external ATc concentration A, 1 ng/mL corresponds to 2.25 nM. <lb/>increasing A, the mean population p of free TetR dimers is reduced, weakening the repression <lb/>and boosting the mean mRNA population r. Changing A allows us to explore a wide range <lb/>of control network behavior. Note that since p depends on B only through the the product <lb/>κ 0 B, and the value of this product is fixed at a constant value from the experimental fit <lb/>(Table 1), p is independent of B. On the other hand, r, which is proportional to κ 0 , is <lb/>inversely proportional to B. <lb/>Linearizing Eq. (10) around r and p, we extract the following frequency-domain response <lb/>functions: <lb/>G rr (ω) = −τ −1 <lb/>r <lb/>= −γ r , G rp (ω) = − <lb/>κ 0 nθ n pn−1 <lb/>(θ n + pn ) 2 , <lb/>G pp (ω) = −τ −1 <lb/>p = −γ p − <lb/>βγ a ΦA <lb/>(γ a + β p) 2 , G pr (ω) = κ p . <lb/>(11) <lb/>All the functions are constants in the frequency domain. Here τ r and τ p are effective decay <lb/>times for the mRNA and proteins, respectively. The value of τ r is fixed, and sets the intrinsic <lb/>time scale of mRNA fluctuations, but τ p and G rp depend on p, which is a function of the <lb/>external ATc concentration A. In fact, association with intracellular ATc, described by the <lb/></body>

			<page>13 <lb/></page>

			<body>second term in the G pp expression above, is the dominant form of decay for the free TetR <lb/>dimers. Fig. 3(d) plots the effective decay constants τ −1 <lb/>r <lb/>and τ −1 <lb/>p <lb/>as a function of A. Except <lb/>for A 8 ng/mL we are in the regime where τ −1 <lb/>p <lb/>τ −1 <lb/>r , which is relevant in simplifying the <lb/>optimality condition for G rp (ω) discussed below. <lb/>The optimal filter calculation for the TetR gene circuit depends on the linear response <lb/>functions of Eq. (11). We obtain the following power spectra for the signal and noise in the <lb/>absence of extrinsic noise: <lb/>P s (ω) = <lb/>2rτ r <lb/>1 + (ωτ r ) 2 , P n (ω) = <lb/>2rτ r <lb/>B <lb/>, <lb/>(12) <lb/>where the burst ratio B ≡ κ p τ r is the mean number of proteins synthesized per mRNA <lb/>during the lifetime τ r . The problem is to evaluate Eq. (9) for H opt (ω). The sum of signal <lb/>plus noise, y(ω) = s(ω) + n(ω), has a power spectrum P y (ω) = P s (ω) + P n (ω), which we can <lb/>rewrite as follows: <lb/>P y (ω) = 2rτ r <lb/>1 <lb/>1 + (ωτ r ) 2 + <lb/>1 <lb/>B <lb/>= <lb/>2rτ r <lb/>B <lb/>1/2 √ <lb/>1 + B − iωτ r <lb/>1 − iωτ r <lb/>2 <lb/>. <lb/>(13) <lb/>The expression within the absolute value brackets is zero only at ω = −iτ −1 <lb/>r <lb/>√ <lb/>1 + B, and <lb/>has a simple pole at ω = −iτ −1 <lb/>r . Since all the zeros and poles are in the lower complex ω <lb/>half-plane, it satisfies the criterion for the causal term in the factorization P y (ω) = |P c <lb/>y (ω)| 2 . <lb/>Thus: <lb/>P c <lb/>y (ω) = <lb/>2rτ r <lb/>B <lb/>1/2 √ <lb/>1 + B − iωτ r <lb/>1 − iωτ r <lb/>. <lb/>(14) <lb/>The other causal term in Eq. (9) involves the additive decomposition P s (ω)/P c <lb/>y (ω) * <lb/>c . This <lb/></body>

			<page>14 <lb/></page>

			<body>is calculated by looking at the partial fraction expansion of P s (ω)/P c <lb/>y (ω) * : <lb/>P s (ω) <lb/>P c <lb/>y (ω) * = <lb/>(2rτ r B) 1/2 <lb/>(1 − iωτ r )( <lb/>√ <lb/>1 + B + iωτ r ) <lb/>= <lb/>(2rτ r B) 1/2 <lb/>(1 − iωτ r )( <lb/>√ <lb/>1 + B + 1) <lb/>+ <lb/>(2rτ r B) 1/2 <lb/>(1 + <lb/>√ <lb/>1 + B)( <lb/>√ <lb/>1 + B + iωτ r ) <lb/>. <lb/>(15) <lb/>Of the two terms in the partial fraction expansion, only the first has poles solely in the lower <lb/>complex ω half-plane. Hence, it is the only one that contributes to P s (ω)/P c <lb/>y (ω) * <lb/>c : <lb/>P s (ω) <lb/>P c <lb/>y (ω) * <lb/>c <lb/>= <lb/>(2rτ r B) 1/2 <lb/>(1 − iωτ r )( <lb/>√ <lb/>1 + B + 1) <lb/>. <lb/>(16) <lb/>Inserting Eqs. (14) and (15) into Eq. (9), we finally find that the optimal filter is: <lb/>H opt (ω) = <lb/>√ <lb/>1 + B − 1 <lb/>√ <lb/>1 + B − iωτ r <lb/>. <lb/>(17) <lb/>Transforming H opt (ω) into the time domain, we find <lb/>H opt (t) = τ −1 <lb/>avg − τ −1 <lb/>r <lb/>e −t/τavg Θ(t), <lb/>(18) <lb/>where τ avg = τ r / <lb/>√ <lb/>1 + B, and Θ(t) is a unit step function ensuring that the filter operates <lb/>only on the past history of its input. For B <lb/>1 the prefactor in Eq. (18) is ≈ τ −1 <lb/>avg , and <lb/>H opt (t) has a straightforward interpretation: it approximately acts as a moving average of <lb/>the corrupted signal y(t) = s(t)+n(t) over a time scale τ avg . In order to get the best estimate <lb/>s(t), the averaging interval τ avg can neither be too long, since it would blur out the features <lb/>of the signal s(t) (which vary on the time scale τ r ), nor too short, since it would be ineffective <lb/>at smoothing out the noise distortion n(t). Hence, there must exist an optimum τ avg , which <lb/>is naturally proportional to τ r , the main time scale for the mRNA. <lb/>In Fig. 3(b), we show how the noise filter properties of the system vary with A for a <lb/></body>

			<page>15 <lb/></page>

			<body>burst ratio of B = 10. The filter function H(t) (solid red curve) differs substantially from <lb/>H opt (t) (dotted red curve) for large and small A, but approaches the optimal form near <lb/>A = 54 ng/mL. Consequently, at this value of A we get the closest correspondence between <lb/>the plotted sample trajectories of signal s(t) (cyan curve) and estimate s(t) (blue curve). <lb/>Similarly, the equilibrium probability distribution of the output, P (δr), shown to the right <lb/>of the trajectories, exhibits the smallest Fano factor σ 2 <lb/>r /r. The latter is a measure of noise <lb/>magnitude, and has a reference value of unity if mRNA production was a pure Poisson <lb/>process, as would be the case without feedback. Optimality is realized in the intermediate A <lb/>regime of partial repression, where the R to P responsiveness, as measured by |G rp |, is large. <lb/>Effective noise suppression requires that R be sensitive to changes in P , so that information <lb/>about R fluctuations can be transmitted through the negative feedback loop. <lb/>In order to understand the optimality condition for H(t) in more detail, let us look at <lb/>the explicit expression for H(t) in the TetR system, given by the inverse Fourier transform <lb/>of Eq. (6) with the response functions of Eq. (11): <lb/>H(t) = <lb/>G rp κ p <lb/>ω 1 − ω 2 <lb/>(e −ω 1 t − e −ω 2 t )Θ(t), <lb/>(19) <lb/>where ω 1 , ω 2 are the two ω roots of the denominator in Eq. (6). Assuming τ p <lb/>τ r (which <lb/>holds good except for small values A <lb/>8 ng/mL, as seen in Fig. 3(d)), we can directly <lb/>show the approach of H(t) to optimality at a specific intermediate value of G rp . When G rp <lb/>equals G opt <lb/>rp (B, τ p ) = −1/(τ p (1 + <lb/>√ <lb/>1 + B)), the roots ω 1 ≈ τ −1 <lb/>avg , ω 2 ≈ τ −1 <lb/>p + τ −1 <lb/>r − τ −1 <lb/>avg , up to <lb/>corrections of order τ p /τ 2 <lb/>r . In this case, Eq. (19) becomes <lb/>H(t)| Grp=G opt ≈ H opt (t) <lb/>1 − e −(τ −1 <lb/>p +τ −1 <lb/>r −2τ −1 <lb/>avg) t <lb/>1 + τ p (τ −1 <lb/>r − 2τ −1 <lb/>avg ) <lb/>, <lb/>(20) <lb/>where the factor in the brackets on the right equals 1 in the limit τ p → 0 for all t &gt; 0. Up to <lb/>this correction factor, we thus expect the system to behave optimally at A = A opt , defined by <lb/>the condition G rp = G opt <lb/>rp (B, τ p ), so long as A opt is large enough to satisfy τ p <lb/>τ r . Fig. 3(e) <lb/></body>

			<page>16 <lb/></page>

			<body>shows G rp and G opt <lb/>rp curves for B = 2, 5, 10, with dots marking the intersection points that <lb/>define A opt for each B. As explained above, |G rp | is small at small and large A, and reaches <lb/>a maximum in between. At fixed B, |G opt <lb/>rp (B, τ p )| ∝ τ −1 <lb/>p , so it increases monotonically with <lb/>A, as larger concentrations of the inducer increase the effective decay rate of free proteins. <lb/>Thus, for each B there is a single intersection point A opt at an intermediate concentration <lb/>of the inducer. <lb/>Fig. 3(f) shows the Fano factor σ 2 <lb/>r /r versus A for various B. As the control network <lb/>approximates optimality at A opt for each B, the Fano factor nears its minimum, close to the <lb/>theoretical limit marked by the horizontal dashed lines. This limit is the minimal possible <lb/>σ 2 <lb/>r /r, calculated from Eq. (8) using H opt (t) from Eq. (18): <lb/>σ 2 <lb/>r,opt <lb/>r = <lb/>2 <lb/>1 + <lb/>√ <lb/>1 + B <lb/>≥ <lb/>2 <lb/>1 + <lb/>√ <lb/>1 + 4B <lb/>(21) <lb/>A few comments concerning the above equation are in order. (1) The result on the far <lb/>right-hand side is the rigorous lower bound derived by LVP. 19 In their case, the feedback <lb/>mechanism through the rate function k r (t) could be any causal functional of p(t), linear or <lb/>nonlinear. The Fano factor of the optimal linear filter differs in form only by the coefficient of <lb/>B, and is always within a factor of 2 of the lower bound for any value of B. (2) For Gaussian-<lb/>distributed signal s(t) and noise n(t) time series, the linear filter is optimal among all possible <lb/>filters. 28 If the system fluctuates around a single stable state, and the copy numbers of <lb/>the species are large enough that their Poisson distributions converge to Gaussians (mean <lb/>populations 10), the signal and noise are usually approximately Gaussian. This is a wide <lb/>class of systems where the rigorous lower bound (the last term in Eq. 21) can never be <lb/>achieved. In other words, here the WK filter yields the most efficient feedback mechanism. <lb/>Although, as pointed out by LVP, nonlinearity could lead to additional noise reduction, <lb/>the benefits are likely to be restricted to those systems where the signal and/or noise are <lb/>substantially non-Gaussian. However, since the form of the optimal control network has not <lb/></body>

			<page>17 <lb/></page>

			<body>been found in the general nonlinear case, it remains an interesting open question whether the <lb/>LVP bound can actually be reached even within this category of systems. We will return to <lb/>this issue in the next section. (3) The parameter B is the key determinant of noise reduction. <lb/>For B <lb/>1, there are not enough signaling events to control the mRNA fluctuations, and <lb/>as B → 0 we approach σ 2 <lb/>r,opt /r → 1, the no-feedback Poisson result. In the limit B <lb/>1 <lb/>signaling is effective, and the Fano factor decreases with B as σ 2 <lb/>r,opt /r ≈ 2/ <lb/>√ <lb/>B. For large <lb/>enough B we approach perfect control, but at extreme expense: the standard deviation of <lb/>the mRNA fluctuations σ r,opt ∝ B −1/4 , the same scaling derived by LVP. <lb/>WK theory constrains the performance of a broad class of nonlinear, <lb/>discrete regulatory networks <lb/>The results in Fig. 3 rely on a linearized, continuum approach to the TetR dynamical system. <lb/>To assess if the conclusions based on the WK optimal filter hold if these approximations are <lb/>relaxed, we first performed kinetic Monte Carlo simulations of the full nonlinear system <lb/>(Eq. (10)) using the Gillespie algorithm. 32 We chose a cell volume of V = V 0 = 60 fL, <lb/>within the observed range for yeast, 33 which corresponds to the mean populations r and <lb/>p shown in Fig. 4(a) as a function of A. (For example, at A = A opt = 62.7 ng/mL when <lb/>B = 5, r ≈ 84 and p ≈ 11. In addition to the nonlinearity, the discrete nature of the <lb/>populations in the simulation might play a role at these low copy numbers.) The numerical <lb/>results for the Fano factor σ 2 <lb/>r /r are plotted in Fig. 4(b) at B = 2, 5, 10, for V = V 0 (circles) <lb/>and also for comparison at a larger volume V = 10V 0 (squares). The blue curves show <lb/>the linear theory results, and the dashed lines are the optimality predictions for σ 2 <lb/>r,opt /r. <lb/>Although nonlinearity and discreteness effects do change the results, the linear theory gives <lb/>a reasonable approximation, and the minimum is still near A opt . The feedback mechanism <lb/>is nonlinear in the simulations, but it does not do better than the linear predictions for <lb/>σ 2 <lb/>r,opt /r for the parameters used to describe the experimental results. Though the intrinsic <lb/>population noise is Poisson-distributed in the simulations, the Poisson distribution is very <lb/></body>

			<page>18 <lb/></page>

			<body>0 <lb/>20 <lb/>40 <lb/>60 <lb/>80 <lb/>100 <lb/>r, p in vol. V <lb/>0 <lb/>p <lb/>r <lb/>(a) <lb/>20 <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>80 <lb/>90 100 <lb/>External ATc [ng/mL] <lb/>0.5 <lb/>0.6 <lb/>0.7 <lb/>0.8 <lb/>0.9 <lb/>Fano factor σ 2 <lb/>r /r <lb/>B = 5 <lb/>B = 2 <lb/>B = 10 <lb/>(b) <lb/>linear theory <lb/>sim. V = V 0 <lb/>sim. V = 10V 0 <lb/>optimum <lb/>Figure 4: Results of simulation and theory for the yeast synthetic gene circuit, 24 as a function <lb/>of extracellular ATc concentration A. (a) Mean populations of free TetR mRNA r and TetR <lb/>dimer p, assuming a cell volume V 0 = 60 fL. (b) The Fano factor σ 2 <lb/>r /r for burst factor <lb/>B = 2, 5, 10, as predicted by the linear filter theory (solid lines), versus stochastic numerical <lb/>simulations at two different volumes, V = V 0 (circles) and V = 10V 0 (squares). The WK <lb/>filter theory predicts the minimal Fano factor σ 2 <lb/>opt /r given by Eq. (21) (horizontal dashed <lb/>lines). The system can be tuned to approach optimality near a particular A opt obtained by <lb/>the condition G rp = G opt <lb/>rp (filled circles). <lb/>close to Gaussian, even for copy numbers as low as ∼ O(10). Since the linear filter is the <lb/>true optimum for a Gaussian-distributed signal and noise, 28 we do not expect improvements <lb/>in noise suppression by employing a nonlinear version. In the opposite limit of large copy <lb/>numbers, V → ∞, the continuum approximation should be valid, and population fluctuations <lb/>increasingly negligible relative to the mean. Thus, the linear theory should directly apply <lb/>in this limit, and indeed we see that for V = 10V 0 the discrepancies between numerical and <lb/>theory results are substantially reduced (Fig. 4(b)). It is worth emphasizing, that even at the <lb/>realistically small cell volume V 0 , the linear theory retains much of its predictive power. More <lb/>generally, the conditions for WK optimality do not have to be perfectly satisfied in order <lb/>for the filter to perform close to maximum efficiency. There is an inherent adaptability and <lb/>robustness in near-optimal networks, as reflected in the broad minima of σ 2 <lb/>r /r as a function <lb/></body>

			<page>19 <lb/></page>

			<body>0 <lb/>2 <lb/>4 <lb/>6 <lb/>8 <lb/>10 <lb/>Burst factor B <lb/>0.2 <lb/>0.3 <lb/>0.4 <lb/>0.5 <lb/>0.6 <lb/>0.7 <lb/>0.8 <lb/>0.9 <lb/>1.0 <lb/>Fano factor σ 2 <lb/>r / r <lb/>WK linear optimum <lb/>LVP lower bound <lb/>nonlinear optimum V = V 0 <lb/>nonlinear optimum V = 0.1V 0 <lb/>Figure 5: The Fano factor σ 2 <lb/>r / r as a function of burst ratio B. The solid curve is the <lb/>optimal result predicted by the WK linear theory, and the dashed curve is the rigorous lower <lb/>bound derived by LVP. 19 Symbols show numerical optimization for the generalized nonlinear <lb/>TetR feedback system (Eq. (22)) at two volumes, V = V 0 and V = 0.1V 0 . <lb/>of A (Fig. 4(b)). <lb/>The semi-quantitative agreement between the linearized theory and the simulation results <lb/>displayed in Fig. 4 still leaves open the possibility that some type of nonlinear, discrete filter, <lb/>not described by the experimentally fitted parameters of the TetR gene network, could <lb/>perform better than the WK optimum at sufficiently small volumes. Fig. 5 plots both the <lb/>WK value for the Fano factor (solid curve) and the rigorous lower bound of LVP (dashed <lb/>curve) as a function of B (Eq. (21)). The above question can be posed as follows: is it <lb/>possible to achieve a Fano factor that falls between the two curves by taking advantage <lb/>of nonlinearity and discreteness? Ideally, one should do an optimization over all possible <lb/>nonlinear regulatory functions that could describe feedback between the TetR protein and <lb/>mRNA. In full generality, such an optimization appears intractable, but one can tackle a <lb/>limited version of the nonlinear optimization. We will confine ourselves to Hill-like regulatory <lb/>functions, which describe the experimental behavior of many cellular systems, 34 and explore <lb/>whether it is possible to find any scenario where this type of nonlinear feedback outperforms <lb/></body>

			<page>20 <lb/></page>

			<body>the linear WK optimum. We consider the following generalized TetR feedback loop: <lb/>ṙ(t) = −γ r r(t) + K r (p(t)), <lb/>ṗ(t) = −γ p p(t) − Γ p (p(t)) + κ p r(t), <lb/>(22) <lb/>with two Hill-like regulatory functions, <lb/>K r (p) = <lb/>A 1 θ n 1 <lb/>1 <lb/>θ n 1 <lb/>1 + p n 1 , <lb/>Γ p (p) = <lb/>A 2 p n 2 <lb/>θ n 2 <lb/>2 + p n 2 , <lb/>(23) <lb/>involving arbitrary non-negative parameters A i , n i , θ i , i = 1, 2. The original TetR system <lb/>(Eq. (10)) is a special case of the equations above with: <lb/>A 1 = κ 0 , n 1 = n, θ 1 = θ, A 2 = βΦA, n 2 = 1, θ 2 = γ a . <lb/>(24) <lb/>The production function K r (p) is a monotonically decreasing function of p, as is expected <lb/>for negative feedback, while Γ p (p) is monotonically increasing, a generalization of some reg-<lb/>ulatory network which effectively removes the TetR protein from the feedback loop (the role <lb/>played by ATc binding in the experimental system). With these monotonicity constraints, <lb/>there is always only one steady-state solution r and p to Eq. (22). <lb/>The optimization consists of searching for K r (p) and Γ p (p) that minimize the Fano factor <lb/>σ 2 <lb/>r / r . The following quantities are fixed during the search: the degradation rates γ r , γ p , <lb/>the P production rate κ p (or equivalently the burst ratio B = κ p /γ r ), and the steady state <lb/>values r, p. Note that in the general nonlinear case, the steady state values do not necessarily <lb/>coincide with the mean values r , p , since the equilibrium distributions are generally <lb/>asymmetric with respect to the steady state. Fixing r and p during the optimization is one <lb/>way to set an overall copy number scale, to investigate the role of discreteness. It turns out <lb/>that the optimization results described below end up being independent of r and p. In terms <lb/>of the Hill function parameters, fixing r and p means setting A 1 and A 2 to the following <lb/></body>

			<page>21 <lb/></page>

			<body>values, <lb/>A 1 = θ −n 1 <lb/>1 <lb/>γ r r(θ n 1 <lb/>1 + pn 1 ), <lb/>A 2 = p−n 2 (γ p p − κ p r)(θ n 2 <lb/>2 + pn 2 ). <lb/>(25) <lb/>Thus the goal of optimization is to minimize σ 2 <lb/>r / r over the four remaining free parameters: <lb/>n 1 , θ 1 , n 2 , θ 2 . <lb/>In order to carry out this minimization, one needs an efficient procedure to calculate <lb/>σ 2 <lb/>r / r from Eq. (22), keeping both the full nonlinearity of the dynamical system, and the <lb/>discreteness of the r(t) and p(t) populations. The system can always be simulated through <lb/>the Gillespie algorithm, 32 and accurate estimates of r and σ 2 <lb/>r determined from sufficiently <lb/>long trajectories. However this approach is too slow for searching over the four-dimensional <lb/>parameter space, since each distinct set of parameters would require a separate long simula-<lb/>tion run. An equivalent, faster alternative is to directly solve the system&apos;s master equation <lb/>for the steady state probability distribution, which then yields r and σ 2 <lb/>r . The joint prob-<lb/>ability distribution P r,p (t) of finding r mRNAs and p proteins at time t is governed by the <lb/>master equation, <lb/>∂ <lb/>∂t <lb/>P r,p =γ r [(r + 1)P r+1,p − rP r,p ] + K r (p) [P r−1,p − P r,p ] + γ p [(p + 1)P r,p+1 − pP r,p ] <lb/>+ [Γ p (p + 1)P r,p+1 − Γ p (p)P r,p ] + κ p r [P r,p−1 − P r,p ] . <lb/>(26) <lb/>The steady state distribution P s <lb/>r,p is the solution obtained by setting to zero the right-hand <lb/>side of the above equation, which we denote R r,p : <lb/>0 = R r,p ≡γ r (r + 1)P s <lb/>r+1,p − rP s <lb/>r,p + K r (p) P s <lb/>r−1,p − P s <lb/>r,p + γ p (p + 1)P s <lb/>r,p+1 − pP s <lb/>r,p <lb/>+ Γ p (p + 1)P s <lb/>r,p+1 − Γ p (p)P s <lb/>r,p + κ p r P s <lb/>r,p−1 − P s <lb/>r,p . <lb/>(27) <lb/>The result is linear in the components P s <lb/>r,p for various r and p, and thus the set {R rp = 0} <lb/>for r = 0, 1, . . . and p = 0, 1, . . ., constitutes a linear system of equations for P s <lb/>r,p . The <lb/>master equation can be solved by spectral methods, which are generally more efficient than <lb/></body>

			<page>22 <lb/></page>

			<body>brute force Gillespie simulations. 35 However we use a different approach, described below, <lb/>to solve Eq. (27), which is sufficiently fast for our numerical optimization purposes. Since <lb/>r and p can take on any integer values between 0 and ∞, we truncate the system to focus <lb/>only on the non-negligible P s <lb/>r,p , in other words (r, p) within several standard deviations <lb/>of the mean ( r , p ). Specifically, we keep only those equations R rp = 0 which involve <lb/>r min ≤ r ≤ r max and p min ≤ p ≤ p max . The largest truncation range required for accurate <lb/>results was r max − r min = 100 and p max − p min = 50. All P s <lb/>r,p outside the range which appear <lb/>in the truncated system of equations are set to a positive constant &gt; 0. (The precise value <lb/>of is unimportant since the distribution is subsequently normalized, and the truncation <lb/>range is chosen large enough so that the boundary condition does not significantly affect the <lb/>outcome.) The resulting finite linear system, which is sparse, can be efficiently solved using <lb/>an unsymmetric-pattern multifrontal algorithm. 36 Knowing P s <lb/>r,p , we then directly calculate <lb/>the moments of the distribution to find r and σ 2 <lb/>r . The numerical accuracy of the procedure <lb/>is verified by comparison to Gillespie simulation results. <lb/>In order to set a starting point for each round of nonlinear optimization, we use the <lb/>following initialization procedure: we take the original TetR system at a given volume V <lb/>and burst ratio B (fixing the Hill function parameters according to Eq. (24)) and find the ATc <lb/>concentration A min where σ 2 <lb/>r / r is smallest, evaluating the Fano factor using the linear solver <lb/>described above. The r and p at this concentration are then chosen to be fixed constants <lb/>for the nonlinear optimization, where we vary the parameters n 1 , θ 1 , n 2 , θ 2 from the initial <lb/>values given by Eq. (24) to minimize σ 2 <lb/>r / r . The minimization is carried out using Brent&apos;s <lb/>principal axis method, 37 which is feasible due to the fast evaluation of r and σ 2 <lb/>r at each <lb/>different parameter set through the linear solver. <lb/>Fig. 6 shows results of a typical minimization run, where the initial system is at volume <lb/>V = V 0 with B = 10, with a corresponding A min = 50 ng/mL. The dashed lines in Fig. 6(a) <lb/>and (b) show the Hill functions K r (p) and Γ p (p) of the original TetR system at these param-<lb/>eter values, and the heat map in Fig. 6(c) represents the associated steady-state probability <lb/></body>

			<page>23 <lb/></page>

			<body>0 <lb/>5 <lb/>10 <lb/>15 <lb/>20 <lb/>25 <lb/>30 <lb/>p <lb/>K <lb/>r (p) [h <lb/>−1 ] <lb/>(p, Kr ) <lb/>(a) <lb/>0 <lb/>5 <lb/>10 <lb/>15 <lb/>20 <lb/>25 <lb/>30 <lb/>p <lb/>0 <lb/>500 <lb/>1000 <lb/>1500 <lb/>2000 <lb/>2500 <lb/>3000 <lb/>Γ <lb/>p (p) [h <lb/>−1 ] <lb/>(p, Γp ) <lb/>(b) <lb/>0 <lb/>5 <lb/>10 <lb/>15 <lb/>20 <lb/>25 <lb/>30 <lb/>p <lb/>r <lb/>(p, r) <lb/>ṗ(t) = 0 <lb/>ṙ(t) = 0 <lb/>(c) <lb/>σ 2 <lb/>r / r = 0.525 <lb/>0 <lb/>5 <lb/>10 <lb/>15 <lb/>20 <lb/>25 <lb/>30 <lb/>p <lb/>0 <lb/>10 <lb/>20 <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>80 <lb/>r <lb/>(p, r) <lb/>ṗ(t) = 0 ṙ(t) = 0 <lb/>(d) <lb/>σ 2 <lb/>r / r = 0.472 <lb/>Figure 6: Results for numerical optimization of the generalized nonlinear TetR feedback <lb/>system of Eq. (22), with starting parameters B = 10 and V = V 0 . (a) The mRNA production <lb/>regulation function K r (p) in its initial form before optimization (dashed curve), and after <lb/>several steps of the minimization algorithm (solid curve). (b) Similar to (a), but showing the <lb/>protein degradation function Γ p (p). (c) Heat map of the steady-state probability distribution <lb/>P s <lb/>r,p before optimization, corresponding to regulation governed by the dashed curves in the <lb/>top panels. The nullclines ṙ(t) = 0 and ṗ(t) = 0 are superimposed. (d) Similar to (c), but <lb/>after several steps of the minimization algorithm, corresponding to regulation governed by <lb/>the solid curves in the top panels. <lb/></body>

			<page>24 <lb/></page>

			<body>distribution P s <lb/>r,p . The dashed lines superimposed on the heat map are the loci of solutions <lb/>to ṙ(t) = 0 and ṗ(t) = 0 (the right-hand sides of Eq. (22) set to zero), which intersect at the <lb/>steady state (r, p). The Fano factor for this distribution, which represents the best the TetR <lb/>system can perform given the experimentally fitted parameters, is σ 2 <lb/>r / r = 0.525. This is <lb/>above the linear WK optimum for B = 10, 2/(1 + <lb/>√ <lb/>1 + B) = 0.463, and significantly larger <lb/>than the rigorous LVP lower bound of 2/(1 + <lb/>√ <lb/>1 + 4B) = 0.270. Once we relax the exper-<lb/>imental constraints, and carry out the numerical minimization, the Fano factor decreases. <lb/>The solid lines in Fig. 6(a) and (b) show K r (p) and Γ p (p) after several steps of the minimiza-<lb/>tion algorithm, and Fig. 6(d) shows the corresponding P s <lb/>r,p . The Hill functions have become <lb/>very steep steps around p, while the average of the distribution r has been pushed above <lb/>r. The probabilities P s <lb/>r,p for p &lt; p 0 become negligible, where p 0 ≡ p is the largest integer <lb/>value below p. For p &gt; p 0 , P s <lb/>r,p rapidly decay to zero. The Fano factor, σ 2 <lb/>r / r = 0.472, <lb/>approaches closer to the linear WK optimum, but is still above it. If we allow the minimiza-<lb/>tion to proceed, these trends continue: at each iteration the Hill functions get steeper, r <lb/>increases, P s <lb/>r,p for p &lt; p 0 tends to zero, and σ 2 <lb/>r / r approaches arbitrarily close to the linear <lb/>WK optimum from above. <lb/>In fact, the same behavior is seen irrespective of the volume V and burst ratio B used to <lb/>define the initial point of the optimization. Fig. 5 shows the results of nonlinear optimization <lb/>for B = 2 − 10 at two volumes, V = V 0 and V = 0.1V 0 . Even for the smallest volume, the <lb/>nonlinear optimization results can get arbitrarily close to the WK optimum, but never do <lb/>better. No generalized nonlinear system based on Hill function regulation brings us close <lb/>to the theoretically possible LVP lower bound. This overall conclusion holds even when we <lb/>change the functional form for the generalized feedback. We tried two alternatives: (i) using <lb/>sigmoidal (logistic) functions instead of Hill functions; (ii) expanding K r (p) and Γ p (p) in a <lb/>Taylor series around p, truncating after the third order term, and minimizing with respect <lb/>to the Taylor coefficients. In both cases numerical minimization of the Fano factor led to <lb/>similar step-like behavior for K r (p) and Γ p (p), and the Fano factor tended to WK optimum <lb/></body>

			<page>25 <lb/></page>

			<body>from above. <lb/>From the P s <lb/>r,p distribution in Fig. 6(d) we see that the step-function limit leads to a <lb/>system which is highly nonlinear along the p axis: in fact the gene network spends most of <lb/>its time at p = p 0 , just below the sudden change in regulation due to the steep Hill functions, <lb/>and p &gt; p 0 just above the sudden regulatory change. The feedback on the TetR mRNA <lb/>population is mediated by p fluctuations between the two regimes, resulting in threshold-like <lb/>regulatory behavior. Remarkably, despite this discrete, nonlinear character, the network can <lb/>still approach the efficiency of an optimal WK linear filter. To gain a deeper understanding of <lb/>how the step-like regulation can match WK optimality, we used the numerical optimization <lb/>results described above to posit a limiting form of the nonlinear gene network that can <lb/>be solved analytically (details in Appendix C). The analytic results explicitly show that <lb/>we can asymptotically approach the WK optimum behavior from above, even in systems <lb/>where the protein copy numbers are very small. Thus at least for a two-component TetR-<lb/>like system regulated by biologically-realistic Hill functions, the constraint derived from the <lb/>WK theory has a broader validity than one would guess from the underlying continuum, <lb/>linear assumptions. It thus becomes an interesting and a non-trivial problem, left for future <lb/>studies, to find an example of a gene network where the rigorous lower bound of LVP could <lb/>be directly achieved. <lb/>Realizing optimality under the influence of extrinsic noise <lb/>Extrinsic noise is ubiquitous and hence must also be considered in any effective description <lb/>of the control network. Inevitably, certain cellular components are not explicitly included <lb/>in such a description, which in our case study could include RNA polymerase, ribosomes, <lb/>and transcription factors that bind to the same promoter. Each of these components have <lb/>their own stochastic characteristics and may contribute noise to a smaller or greater extent. <lb/>Particularly for eukaryotes like yeast, the extrinsic noise contribution may be significantly <lb/>larger than the intrinsic component. 38,39 We adopt a simple model for the extrinsic noise <lb/></body>

			<page>26 <lb/></page>

			<body>20 <lb/>30 <lb/>40 <lb/>50 <lb/>60 <lb/>70 <lb/>80 <lb/>90 100 <lb/>External ATc [ng/mL] <lb/>0.8 <lb/>1.0 <lb/>1.2 <lb/>1.4 <lb/>1.6 <lb/>1.8 <lb/>Fano factor σ 2 <lb/>r /r <lb/>c p = 80, c r = 23 <lb/>c p = 160, c r = 46 <lb/>linear theory <lb/>simul. V = V 0 <lb/>simul. V = 10V 0 <lb/>optimum <lb/>Figure 7: Comparison of simulation and theory results based on the dynamical model <lb/>(Eq. (10)) of the yeast synthetic gene circuit, 24 in the presence of extrinsic noise given <lb/>by Eq. (73). All quantities are plotted as a function of extracellular ATc concentration A <lb/>for the burst ratio B = 5. Each set of curves shows the Fano factor σ 2 <lb/>r /r, as predicted by <lb/>the linear filter theory (solid lines), versus stochastic numerical simulations at two different <lb/>volumes, V = V 0 = 60 fL (circles) and V = 10V 0 (squares). The two sets correspond to <lb/>noise magnitudes c p = 80, c r = 23 and c p = 160, c r = 46. In both cases c r and c p are <lb/>related through the condition in Eq. (83), and the minimal Fano factor predicted by WK <lb/>filter theory (horizontal dashed lines) is modified as shown in Eq. (84). The system can be <lb/>tuned to approach optimality near a particular A opt obtained by the condition G rp = G opt <lb/>rp <lb/>(filled circles). <lb/>based on earlier approaches, 14,16 which assume that it is band-limited at a low frequency <lb/>τ −1 <lb/>e , where τ e is on the order of the cell growth time scale. The justification is that higher <lb/>frequency contributions to the extrinsic noise are filtered out by the gene circuits associated <lb/>with its sources. This idea is consistent with the experimental observation of extrinsic noise <lb/>in protein production in E. coli, which found long autocorrelation times for the extrinsic <lb/>noise on the order of the cell cycle period. 40 <lb/>For the TetR system, our theory is extended to the extrinsic noise case in Appendix D, <lb/>with the results illustrated in Fig. 7. The outcome is that a given TetR gene circuit, tuned <lb/>appropriately such that A = A opt , can act as a WK filter for an entire family of extrinsic <lb/>noise scenarios. A single set of parameters can approximately represent the optimal solution <lb/>for a variety of extrinsic inputs. This makes the WK concept a versatile design tool for <lb/></body>

			<page>27 <lb/></page>

			<body>noise suppression in biological systems: the same control network can act with maximum <lb/>efficiency in a variety of different contexts. It is possible that the requirement of adaptability <lb/>to a wide range of conditions has resulted in the evolution of control networks acting as WK <lb/>filters. It remains to be seen whether nature has exploited this feature in vivo. <lb/>Conclusion <lb/>The TetR feedback loop is a concrete example of how a WK filter can be implemented <lb/>in a gene network driven by a complex set of biochemical reaction rates, but the overall <lb/>approach outlined here has far reaching implications, thus highlighting the appeal of engi-<lb/>neering paradigms in biology. 41 With the entire network complexity encoded in a handful of <lb/>response functions, we can derive fundamental limits and design principles governing biolog-<lb/>ical regulation. The key step is to map the linear response picture onto a signal estimation <lb/>problem, whose solution is given by WK theory. This idea allows us to predict the dy-<lb/>namic properties of the feedback pathway required to optimally filter noise in a broad class <lb/>of negative feedback circuits. As already demonstrated in earlier works, 22,23 the mapping, <lb/>and the potential utility of the WK approach, is not unique to the negative feedback loop. <lb/>Another important byproduct of the theory is that the behavior of gene circuits away from <lb/>optimality can also be predicted. In this sense, our practical approach goes beyond just <lb/>obtaining rigorous bounds, and allows us to characterize how close or far gene networks are <lb/>from optimality for biologically relevant parameters. <lb/>We have derived response functions by linearizing a minimal model extracted from ex-<lb/>perimental observations, but it is also possible to directly apply small perturbations to a <lb/>system, and measure the resulting time-dependent changes in populations of species. Re-<lb/>cently, the yeast hyperosmolar signaling pathway has been probed by perturbations in the <lb/>form of salt shocks. 42-44 Despite the underlying complex nonlinear network, the details of <lb/>which are not completely characterized, a linear response description quantitatively cap-<lb/></body>

			<page>28 <lb/></page>

			<body>tures the frequency-dependent behavior of the pathway over a wide range of inputs. E. <lb/>Coli chemotaxis signaling also exhibits a linear regime, 45 where the fluctuation-dissipation <lb/>relationship between the system&apos;s unperturbed behavior and its reaction to external stimuli <lb/>has been explicitly verified. <lb/>Linear response functions can thus become a fundamental tool in analyzing biochemical <lb/>circuits, analogous to their established role in control engineering and signal processing. More <lb/>extensive experimental measurements will be critical in this effort, in order to ascertain how <lb/>varied the response relationships between regulatory components are in nature. Once we <lb/>understand the essential dynamical building blocks out of which complex biological function <lb/>is realized, we can map out the hidden constraints that control the behavior of living systems. <lb/></body>

			<div type="acknowledgement">Acknowledgement <lb/>This work was done while the authors were in the Institute for Physical Sciences and Tech-<lb/>nology in the University of Maryland, College Park. We are grateful to C. Güven, G. Reddy, <lb/>Z. Zhang, and P. Zhuravlev for useful discussions. This work was supported by a grant from <lb/>the National Science Foundation (CHE 13-61946). <lb/></div>

			<listBibl>References <lb/>(1) Becskei, A.; Serrano, L. Engineering stability in gene networks by autoregulation. Na-<lb/>ture 2000, 405, 590-593. <lb/>(2) Thattai, M.; van Oudenaarden, A. Intrinsic noise in gene regulatory networks. Proc. <lb/>Natl. Acad. Sci. U. S. A. 2001, 98, 8614-8619. <lb/>(3) Swain, P. S.; Elowitz, M. B.; Siggia, E. D. Intrinsic and extrinsic contributions to <lb/>stochasticity in gene expression. Proc. Natl. Acad. Sci. U. S. A. 2002, 99, 12795-12800. <lb/></listBibl>

			<page>29 <lb/></page>

			<listBibl>(4) Ozbudak, E. M.; Thattai, M.; Kurtser, I.; Grossman, A. D.; van Oudenaarden, A. <lb/>Regulation of noise in the expression of a single gene. Nature Genet. 2002, 31, 69-73. <lb/>(5) Elowitz, M. B.; Levine, A. J.; Siggia, E. D.; Swain, P. S. Stochastic gene expression in <lb/>a single cell. Science 2002, 297, 1183-1186. <lb/>(6) Paulsson, J. Summing up the noise in gene networks. Nature 2004, 427, 415-418. <lb/>(7) Arias, A. M.; Hayward, P. Filtering transcriptional noise during development: concepts <lb/>and mechanisms. Nat. Rev. Genet. 2006, 7, 34-44. <lb/>(8) Tsang, J.; Zhu, J.; van Oudenaarden, A. MicroRNA-mediated feedback and feedforward <lb/>loops are recurrent network motifs in mammals. Mol. Cell 2007, 26, 753-767. <lb/>(9) Andrews, B. W.; Yi, T.-M.; Iglesias, P. A. Optimal noise filtering in the chemotactic <lb/>response of Escherichia coli. PLoS Comput. Biol. 2006, 2, 1407-1418. <lb/>(10) Newman, J. R. S.; Ghaemmaghami, S.; Ihmels, J.; Breslow, D. K.; Noble, M.; De-<lb/>Risi, J. L.; Weissman, J. S. Single-cell proteomic analysis of S-cerevisiae reveals the <lb/>architecture of biological noise. Nature 2006, 441, 840-846. <lb/>(11) Fraser, H. B.; Hirsh, A. E.; Giaever, G.; Kumm, J.; Eisen, M. B. Noise minimization <lb/>in eukaryotic gene expression. PLoS Biol. 2004, 2, 834-838. <lb/>(12) Lehner, B. Selection to minimise noise in living systems and its implications for the <lb/>evolution of gene expression. Mol. Syst. Biol. 2008, 4, 170. <lb/>(13) Simpson, M. L.; Cox, C. D.; Sayler, G. S. Frequency domain analysis of noise in au-<lb/>toregulated gene circuits. Proc. Natl. Acad. Sci. U. S. A. 2003, 100, 4551-4556. <lb/>(14) Austin, D. W.; Allen, M. S.; McCollum, J. M.; Dar, R. D.; Wilgus, J. R.; Sayler, G. S.; <lb/>Samatova, N. F.; Cox, C. D.; Simpson, M. L. Gene network shaping of inherent noise <lb/>spectra. Nature 2006, 439, 608-611. <lb/>30 <lb/>(15) Dublanche, Y.; Michalodimitrakis, K.; Kummerer, N.; Foglierini, M.; Serrano, L. Noise <lb/>in transcription negative feedback loops: simulation and experimental analysis. Mol. <lb/>Syst. Biol. 2006, 2, 41. <lb/>(16) Cox, C. D.; McCollum, J. M.; Austin, D. W.; Allen, M. S.; Dar, R. D.; Simpson, M. L. <lb/>Frequency domain analysis of noise in simple gene circuits. Chaos 2006, 16, 026102. <lb/>(17) Zhang, J. J.; Yuan, Z. J.; Zhou, T. S. Physical limits of feedback noise-suppression in <lb/>biological networks. Phys. Biol. 2009, 6, 046009. <lb/>(18) Singh, A.; Hespanha, J. P. Optimal Feedback Strength for Noise Suppression in Au-<lb/>toregulatory Gene Networks. Biophys. J. 2009, 96, 4013-4023. <lb/>(19) Lestas, I.; Vinnicombe, G.; Paulsson, J. Fundamental limits on the suppression of <lb/>molecular fluctuations. Nature 2010, 467, 174-178. <lb/>(20) Wiener, N. Extrapolation, Interpolation and Smoothing of Stationary Times Series; <lb/>Wiley: New York, 1949. <lb/>(21) Kolmogorov, A. N. Interpolation and extrapolation of stationary random sequences. <lb/>Izv. Akad. Nauk SSSR., Ser. Mat. 1941, 5, 3-14. <lb/>(22) Hinczewski, M.; Thirumalai, D. Cellular signaling networks function as generalized <lb/>Wiener-Kolmogorov filters to suppress noise. Phys. Rev. X 2014, 4, 041017. <lb/>(23) Becker, N. B.; Mugler, A.; ten Wolde, P. R. Optimal prediction by cellular signaling <lb/>networks. Phys. Rev. Lett. 2015, 115, 258103. <lb/>(24) Nevozhay, D.; Adams, R. M.; Murphy, K. F.; Josic, K.; Balazsi, G. Negative autoregu-<lb/>lation linearizes the dose-response and suppresses the heterogeneity of gene expression. <lb/>Proc. Natl. Acad. Sci. U. S. A. 2009, 106, 5123-5128. <lb/></listBibl>

			<page>31 <lb/></page>

			<listBibl>(25) Schwanhaeusser, B.; Busse, D.; Li, N.; Dittmar, G.; Schuchhardt, J.; Wolf, J.; Chen, W.; <lb/>Selbach, M. Global quantification of mammalian gene expression control. Nature 2011, <lb/>473, 337-342. <lb/>(26) Gillespie, D. T. The chemical Langevin equation. J. Chem. Phys. 2000, 113, 297-306. <lb/>(27) de Ronde, W. H.; Tostevin, F.; ten Wolde, P. R. Effect of feedback on the fidelity of <lb/>information transmission of time-varying signals. Phys. Rev. E 2010, 82, 031914. <lb/>(28) Bode, H. W.; Shannon, C. E. A simplified derivation of linear least square smoothing <lb/>and prediction theory. Proc. Inst. Radio. Engin. 1950, 38, 417-425. <lb/>(29) Chaikin, P. M.; Lubensky, T. C. Principles of condensed matter physics; Cambridge <lb/>University Press, 1995. <lb/>(30) Cai, L.; Friedman, N.; Xie, X. S. Stochastic protein expression in individual cells at the <lb/>single molecule level. Nature 2006, 440, 358-362. <lb/>(31) Garcia-Martinez, J.; Aranda, A.; Perez-Ortin, J. E. Genomic run-on evaluates tran-<lb/>scription rates for all yeast genes and identifies gene regulatory mechanisms. Mol. Cell <lb/>2004, 15, 303-313. <lb/>(32) Gillespie, D. T. Exact stochastic simulation of coupled chemical-reactions. J. Phys. <lb/>Chem. 1977, 81, 2340-2361. <lb/>(33) Jorgensen, P.; Nishikawa, J. L.; Breitkreutz, B. J.; Tyers, M. Systematic identification <lb/>of pathways that couple cell growth and division in yeast. Science 2002, 297, 395-400. <lb/>(34) Alon, U. An Introduction to Systems Biology: Design Principles of Biological Circuits; <lb/>Chapman and Hall/CRC, 2006. <lb/>(35) Mugler, A.; Walczak, A. M.; Wiggins, C. H. Spectral solutions to stochastic models of <lb/>gene expression with bursts and regulation. Phys. Rev. E. 2009, 80, 041921. <lb/></listBibl>

			<page>32 <lb/></page>

			<listBibl>(36) Davis, T. A. Algorithm 832: UMFPACK V4.3-an unsymmetric-pattern multifrontal <lb/>method. ACM Trans. Math. Software 2004, 30, 196-199. <lb/>(37) Brent, R. Algorithms for Minimization without Derivatives; Dover, 2002. <lb/>(38) Raser, J. M.; O&apos;Shea, E. K. Control of stochasticity in eukaryotic gene expression. <lb/>Science 2004, 304, 1811-1814. <lb/>(39) Volfson, D.; Marciniak, J.; Blake, W. J.; Ostroff, N.; Tsimring, L. S.; Hasty, J. Origins <lb/>of extrinsic variability in eukaryotic gene expression. Nature 2006, 439, 861-864. <lb/>(40) Rosenfeld, N.; Young, J. W.; Alon, U.; Swain, P. S.; Elowitz, M. B. Gene regulation at <lb/>the single-cell level. Science 2005, 307, 1962-1965. <lb/>(41) Csete, M. E.; Doyle, J. C. Reverse engineering of biological complexity. Science 2002, <lb/>295, 1664-1669. <lb/>(42) Mettetal, J. T.; Muzzey, D.; Gomez-Uribe, C.; van Oudenaarden, A. The frequency <lb/>dependence of osmo-adaptation in Saccharomyces cerevisiae. Science 2008, 319, 482-<lb/>484. <lb/>(43) Hersen, P.; McClean, M. N.; Mahadevan, L.; Ramanathan, S. Signal processing by the <lb/>HOG MAP kinase pathway. Proc. Natl. Acad. Sci. U. S. A. 2008, 105, 7165-7170. <lb/>(44) Muzzey, D.; Gomez-Uribe, C. A.; Mettetal, J. T.; van Oudenaarden, A. A Systems-Level <lb/>Analysis of Perfect Adaptation in Yeast Osmoregulation. Cell 2009, 138, 160-171. <lb/>(45) Park, H.; Pontius, W.; Guet, C. C.; Marko, J. F.; Emonet, T.; Cluzel, P. Interdepen-<lb/>dence of behavioural variability and response to small stimuli in bacteria. Nature 2010, <lb/>468, 819-U114. <lb/></listBibl>

			<page>33 <lb/></page>

			<div type="annex">Appendix A: Derivation of the optimal WK filter <lb/>In this section we derive Eqs. (8) and (9) in the main text. They describe the output variance <lb/>σ 2 <lb/>r = [(δr) 2 ] and the linear filter H opt (ω) that minimizes σ 2 <lb/>r , which are the main quantities <lb/>in the Wiener-Kolmogorov theory. <lb/> Output variance σ 2 <lb/>r in terms of signal and noise power spectra P s (ω) <lb/>and P n (ω) <lb/>From Eq. (4), which defines the signal s(ω) and estimate s(ω) in the frequency domain, the <lb/>Fourier transformed output δr(ω) for any H(ω) can be rewritten as, <lb/>δr(ω) = s(ω) − s(ω) = (1 − H(ω))s(ω) − H(ω)n(ω). <lb/>(28) <lb/>In the time domain, s(ω) = −n r (ω)/(G rr (ω)+iω), is a convolution of the noise function n r (t), <lb/>and n(ω) = n p (ω)/G pr (ω) is a convolution of n p (t). So long as the noise functions n r (t) and <lb/>n p (t) are uncorrelated, s(t) and n(t) are also uncorrelated, so the frequency domain average <lb/>s(ω)n(ω ) = 0. (The theory can also be generalized to correlated noise sources, but for <lb/>simplicity we consider only the uncorrelated case.) As a result, the correlation δr(ω)δr(ω ), <lb/>related to the output power spectrum P δr (ω), can be written in terms of P s (ω) and P n (ω), <lb/>the individual power spectra of the signal and noise: <lb/>δr(ω)δr(ω ) <lb/>= (1 − H(ω))(1 − H(ω ))s(ω)s(ω ) <lb/>+ H(ω)H(ω )n(ω)n(ω ) <lb/>= 2π |H(ω) − 1| 2 P s (ω) + |H(ω)| 2 P n (ω) δ(ω + ω ) <lb/>≡ 2πP δr (ω)δ(ω + ω ), <lb/>(29) <lb/></div>

			<page>34 <lb/></page>

			<div type="annex">In the above equation we have used the definition of the power spectrum, i.e. s(ω)s(ω ) ≡ <lb/>2πP s (ω)δ(ω + ω ), and the relation H(−ω) = H * (ω) since H(ω) is the Fourier transform <lb/>of a real function H(t). The power spectrum P δr (ω) is the Fourier transform of the time <lb/>autocorrelation function δr(t)δr(0): <lb/>δr(t)δr(0) = <lb/>∞ <lb/>−∞ <lb/>dω <lb/>2π <lb/>P δr (ω)e −iωt . <lb/>(30) <lb/>At t = 0, the autocorrelation function gives us the variance σ 2 <lb/>r : <lb/>σ 2 <lb/>r = (δr(0)) 2 <lb/>= <lb/>∞ <lb/>−∞ <lb/>dω <lb/>2π <lb/>P δr (ω) <lb/>= <lb/>∞ <lb/>−∞ <lb/>dω <lb/>2π <lb/>|H(ω)| 2 P n (ω) + |H(ω) − 1| 2 P s (ω) , <lb/>(31) <lb/>which is Eq. (8) in the main text. <lb/>Minimizing σ 2 <lb/>r over all causal H(ω) yields the optimal WK filter <lb/>H opt (ω) <lb/>The convolution of the filter function H(t) on the corrupted signal s(t) + n(t) must satisfy <lb/>causality. The filter can only operate on the past history of s(t) + n(t), so H(t) = 0 for <lb/>t &lt; 0. In the frequency domain, enforcing causality restricts H(ω) to have certain general <lb/>properties as a function of complex ω: 29 it can have no poles or zeros in the upper half-plane <lb/>Im ω &gt; 0. Equivalently, the real and imaginary parts of H(ω) evaluated at real ω must <lb/>satisfy the well-known Kramers-Kronig relation: <lb/>Re H(ω) = <lb/>1 <lb/>π <lb/>P <lb/>∞ <lb/>−∞ <lb/>dω <lb/>Im H(ω ) <lb/>ω − ω <lb/>, <lb/>(32) <lb/></div>

			<page>35 <lb/></page>

			<div type="annex">where P is the Cauchy principal value of the integral. The goal of WK optimization is to <lb/>minimize σ 2 <lb/>r in Eq. (31) over all possible causal functions H(ω), given the power spectra <lb/>P s (ω) and P n (ω). <lb/>Assume such an optimum H opt (ω) exists, with the corresponding minimal variance σ 2 <lb/>r,opt . <lb/>Let us add a small perturbation, H(ω) = H opt (ω) + δH(ω), where δH(ω) is also a causal <lb/>function of complex ω. From Eq. (31), the resulting variance change δσ 2 <lb/>r = σ 2 <lb/>r − σ 2 <lb/>r,opt , to <lb/>lowest order in δH(ω), is: <lb/>δσ 2 <lb/>r = <lb/>∞ <lb/>−∞ <lb/>dω 2 Re {(H opt (ω) − 1)P s (ω) <lb/>+ H opt (ω)P n (ω)} δH * (ω) <lb/>= <lb/>∞ <lb/>−∞ <lb/>dω 2 Re F opt (ω)δH * (ω) , <lb/>(33) <lb/>where <lb/>F opt (ω) ≡ (H opt (ω) − 1)P s (ω) + H opt (ω)P n (ω). <lb/>(34) <lb/>For H opt (ω) to be the WK optimum, δσ 2 <lb/>r in Eq. (33) must be zero for any causal perturbation <lb/>δH(ω). <lb/>Out of all possible causal perturbations, we will focus on one with the specific form: <lb/>δH(ω) = <lb/>A <lb/>− i(ω − ω 0 ) <lb/>, <lb/>(35) <lb/>where Im ω 0 = 0 and A, &gt; 0. It has no zeros, and the only pole, ω = ω 0 − i , is in the lower <lb/>half-plane, so δH(ω) is causal. We will be interested in the limit as this pole approaches the <lb/>real axis, → 0 + , where the real and imaginary parts of δH(ω) are, <lb/>Re δH(ω) = <lb/>A <lb/>2 + (ω − ω 0 ) 2 → Aπδ(ω − ω 0 ), <lb/>Im δH(ω) = <lb/>A(ω − ω 0 ) <lb/>2 + (ω − ω 0 ) 2 → <lb/>A <lb/>ω − ω 0 <lb/>. <lb/>(36) <lb/></div>

			<page>36 <lb/></page>

			<div type="annex">Substituting these into Eq. (33) for δσ 2 <lb/>r , we find that the optimality condition δσ 2 <lb/>r = 0 implies <lb/>the following relation between the real and imaginary parts of F opt (ω): <lb/>Re F opt (ω 0 ) = − <lb/>1 <lb/>π <lb/>P <lb/>∞ <lb/>−∞ <lb/>dω <lb/>Im F opt (ω) <lb/>ω − ω 0 <lb/>. <lb/>(37) <lb/>This has the same form as the Kramers-Kronig relation in Eq. (32), with the important <lb/>difference of a minus sign in front. Consequently, F opt (ω) must be anticausal, which we <lb/>define as a function with no poles or zeros in the lower complex ω half-plane. <lb/>In order to use this result to derive a solution for H opt (ω), we define two types of decom-<lb/>positions, described briefly in the main text. In practice, all the frequency domain power <lb/>spectral density and filter functions we work with in the linear response formalism are mero-<lb/>morphic functions over the complex ω plane. Any meromorphic function F (ω) can be written <lb/>as a partial fraction expansion of the form F (ω) = n,k c ik /(ω − ω n ) k , where {ω n } is the set <lb/>of poles of F (ω), and c ik are constants. Most generally, the expansion could include a polyno-<lb/>mial term, but the functions F (ω) we encounter have well-defined inverse Fourier transforms, <lb/>which require |F (ω)| → 0 as |ω| → ∞ (decay at least as fast as 1/|ω|). Thus, all the terms in <lb/>the expansion are of the form c ik /(ω − ω n ) k , and we can segregate them according to whether <lb/>the pole ω n is in the upper half plane. The causal part {F (ω)} c is defined as all those terms <lb/>where ω n is not in the upper half plane, and the anticausal part {F (ω)} ac contains the <lb/>remaining terms in the expansion. The overall function F (ω) = {F (ω)} c + {F (ω)} ac . <lb/>The second type of decomposition, an example of Wiener-Hopf factorization, 20 concerns <lb/>power spectral density functions like P y (ω), which are meromorphic and also real-valued <lb/>on the real ω axis. Let us factor P y (ω) as the product of two meromorphic functions, <lb/>P y (ω) = P c <lb/>y (ω)R ac <lb/>y (ω). The function P c <lb/>y (ω) contains all the zeros and poles in P y (ω) which <lb/>are not in the upper half plane. Such a decomposition is always possible, since a meromorphic <lb/>function can always be written as a ratio of two holomorphic functions. Hence, the numerator <lb/>and denominator of P y (ω) can be decomposed individually into a product of elementary <lb/></div>

			<page>37 <lb/></page>

			<div type="annex">factors by the Weierstrass factorization theorem, with each factor containing a single zero. <lb/>Because P y (ω) is real for real ω, so P y (ω) * = P y (ω) when Im ω = 0. Thus, P c <lb/>y (ω) * R ac <lb/>y (ω) * = <lb/>P c <lb/>y (ω)R ac <lb/>y (ω). Since P c <lb/>y (ω) * for real ω has all its zeros and poles in the upper half plane, we <lb/>must have P c <lb/>y (ω) * ∝ R ac <lb/>y (ω), and similarly R ac <lb/>y (ω) * ∝ P c <lb/>y (ω). By appropriately absorbing an <lb/>overall constant into P c <lb/>y (ω), we can factor P y (ω) as P y (ω) = P c <lb/>y (ω)P c <lb/>y (ω) * = |P c <lb/>y (ω)| 2 . <lb/>With these decompositions defined, we return now to the condition in Eq. (37), which <lb/>shows that F opt (ω) is anticausal. Thus, its causal part in the additive decomposition must <lb/>be zero, {F opt (ω)} c = 0. From the definition of F opt (ω), Eq. (34), it follows that <lb/>{H opt (ω)P y (ω)} c = {P s (ω)} c , <lb/>(38) <lb/>where P y (ω) = P s (ω) + P n (ω) is the power spectrum of the noise-corrupted signal y(t) = <lb/>s(t) + n(t). Equivalently, since we can substitute {F (ω)} c = F (ω) − {F (ω)} ac for any F (ω), <lb/>the optimality condition can be rewritten as: <lb/>H opt (ω)P y (ω) − {H opt (ω)P y (ω)} ac <lb/>= P s (ω) − {P s (ω)} ac . <lb/>(39) <lb/>Divide both sides of Eq. (39) by P c <lb/>y (ω) * , and then take the causal additive part {•} c of both <lb/>sides. The result is: <lb/>{H opt (ω)P c <lb/>y (ω)} c − <lb/>{H opt (ω)P y (ω)} ac <lb/>P c <lb/>y (ω) * <lb/>c <lb/>= <lb/>P s (ω) <lb/>P c <lb/>y (ω) * <lb/>c <lb/>− <lb/>{P s (ω)} ac <lb/>P c <lb/>y (ω) * <lb/>c <lb/>. <lb/>(40) <lb/>The second terms on both the left and right hand sides are the causal parts of a ratio between <lb/>two anticausal functions. Since a ratio of anticausal functions is also anticausal, these terms <lb/>are zero. On the left hand side the first term {H opt (ω)P c <lb/>y (ω)} c = H opt (ω)P c <lb/>y (ω), since H opt (ω) <lb/>and P c <lb/>y (ω) are causal, and hence their product is also causal. Making these simplifications, <lb/></div>

			<page>38 <lb/></page>

			<div type="annex">we can then solve for H opt (ω) as: <lb/>H opt (ω) = <lb/>1 <lb/>P c <lb/>y (ω) <lb/>P s (ω) <lb/>P c <lb/>y (ω) * <lb/>c <lb/>, <lb/>(41) <lb/>which is the optimal WK filter result shown as Eq. (9) in the main text. <lb/></div>

			<div type="annex">Appendix B: Linear response and noise filter analysis for <lb/>a regulatory cascade <lb/>As an example of how our theory generalizes to control networks with multiple mediator <lb/>species, we will consider the case where the feedback loop consists of a regulatory cascade. <lb/>We will still explicitly single out a target species R and a mediator P , but now the signaling <lb/>pathway which communicates changes from R to P will be more complicated, consisting of <lb/>a cascade of N species U j , j = 1, . . . , N , with populations u j . The production of the j th <lb/>species will depend on the population of the (j −1) th species (with j = 0 corresponding to R), <lb/>and P will depend on the last member of the cascade, U N . In terms of Fourier-transformed <lb/>fluctuations δu j , the dynamical equations for the pathway have the form: <lb/>−iωδu j (ω) = G u j u j (ω)δu j (ω) + G u j u j−1 (ω)δu j−1 (ω) <lb/>+ n u j (ω), <lb/>j = 1, . . . , N. <lb/>(42) <lb/>Thus the dynamics includes three parts: (i) the self-responses G u j u j which we can assume in <lb/>the simplest case to be given by the inverse decay lifetimes of the species, G u j u j = −τ −1 <lb/>u j ; (ii) <lb/>the cross-response terms G u j u j−1 which describe how the jth member of the cascade is related <lb/>to the (j − 1)th member; (iii) the stochastic noise terms n u j . To complete the description of <lb/></div>

			<page>39 <lb/></page>

			<div type="annex">the feedback loop, we specify the equations for R and P : <lb/>−iωδr(ω) = G rr (ω)δr(ω) + G rp (ω)δp(ω) + n r (ω), <lb/>−iωδp(ω) = G pp (ω)δp(ω) + G pu N (ω)δu N (ω) + n p (ω). <lb/>(43) <lb/>Instead of the simple cross-response G pr from R to P , P is influenced by the final species of <lb/>the U j pathway through G pu N . <lb/>The regulatory cascade system described by Eqs. (42)-(43) can in fact be simplified <lb/>extensively, by solving for the dynamics of the mediator species U j and substituting the <lb/>results into Eq. (43). This yields equations for R and P which have the same form as in the <lb/>two-species case in the main text, but with an effective cross-response function G eff <lb/>pr (ω) and <lb/>noise term n eff <lb/>p (ω), <lb/>−iωδr(ω) = G rr (ω)δr(ω) + G rp (ω)δp(ω) + n r (ω) <lb/>−iωδp(ω) = G pp (ω)δp(ω) + G eff <lb/>pr (ω)δr(ω) + n eff <lb/>p (ω), <lb/>(44) <lb/>where: <lb/>G eff <lb/>pr (ω) = G pu N (ω) <lb/>N <lb/>j=1 <lb/>G u j u j−1 (ω)τ u j <lb/>1 − iωτ u j <lb/>, <lb/>n eff <lb/>p (ω) = n p (ω) <lb/>+ G pu N (ω) <lb/>N <lb/>k=1 <lb/>n u k (ω) <lb/>G u k u k−1 (ω) <lb/>N <lb/>j=k <lb/>G u j u j−1 (ω)τ u j <lb/>1 − iωτ u j <lb/>. <lb/>(45) <lb/>In this effective two-species reduction of the full system, all the stochastic effects of the <lb/>mediators in the U i pathway enter in as &quot;extrinsic&quot; noise contributions to n eff <lb/>p (ω). This is a <lb/>particular example that shows how extrinsic noise encapsulates the stochastic influence of <lb/>all the species that are not explicitly specified in the dynamical equations. <lb/>The mapping of the two-species system onto the noise filter formalism, and the calculation <lb/>of the optimal filter, can be carried out by the methods outlined in the main text. While this <lb/></div>

			<page>40 <lb/></page>

			<div type="annex">in general results in a more complicated problem than the simple example analyzed in the <lb/>main text, in one scenario the noise filter optimization problem for the cascade is relatively <lb/>straightforward: (i) we assume linear production functions k + <lb/>u j (t) = κ u j u j−1 (t) for all U j , <lb/>so the cross-responses are constants in frequency space, G u j u j−1 (ω) ≡ κ u j . Similarly, the P <lb/>production function is κ p u N (t), so G pu N (ω) ≡ κ p . (ii) We assume the decay timescales of all <lb/>the cascade species are negligible, τ u j <lb/>τ r , so we can take the limits τ u j → 0 in Eq. (45). <lb/>However, the products κ u j τ u j remain finite for all j, since from the equilibrium conditions <lb/>of the cascade (balance of production and destruction), they are related to ratios of the <lb/>steady-state populations ūj : <lb/>κ u j τ u j = <lb/>ūj <lb/>ūj−1 <lb/>. <lb/>(46) <lb/>Hence rapid decay goes hand in hand with fast production. This is the same type of serial <lb/>cascade analyzed in Ref. 19, where it was shown to maximize information transfer along the <lb/>pathway. (iii) Finally, we assume that each species in the original, full description of the <lb/>system is subject only to intrinsic noise, so the noise functions are given by: <lb/>n r (ω) = 2 kr η r (ω), <lb/>n p (ω) = 2κ p ūN η p (ω), <lb/>n u j (ω) = 2κ u j ūj−1 η u j (ω), <lb/>(47) <lb/>where the η α (ω) for different α are independent Fourier-transformed Gaussian white noise <lb/>functions. <lb/>With these assumptions the effective cross-response and noise functions in Eq. (45) be-<lb/>come: <lb/>G eff <lb/>pr (ω) = <lb/>B <lb/>τ r <lb/>, <lb/>n eff <lb/>p (ω) = n p (ω) + B <lb/>N <lb/>k=1 <lb/>n u k (ω) <lb/>B u k <lb/>, <lb/>(48) <lb/></div>

			<page>41 <lb/></page>

			<div type="annex">where the P burst ratio B ≡ κ p ūN τ r /r is analogous to B in the main text, i.e. the average <lb/>number of P molecules produced per R during the time interval τ r . Similarly the burst ratio <lb/>B u k = κ u k ūk−1 τ r /r is the average number of U k molecules produced per R during τ r . <lb/>The resulting signal and noise power spectra within the filter formalism are: <lb/>P s (ω) = <lb/>2rτ r <lb/>1 + (ωτ r ) 2 , P n (ω) = <lb/>2rτ r <lb/>B eff <lb/>, <lb/>(49) <lb/>where: <lb/>B eff = <lb/>1 <lb/>B <lb/>+ <lb/>N <lb/>k=1 <lb/>1 <lb/>B u k <lb/>−1 <lb/>. <lb/>(50) <lb/>Since the power spectra in Eq. (49) have the same form as Eq. (12), with B replaced by B eff , <lb/>all the subsequent optimality results are identical, but expressed in terms of the effective <lb/>total burst ratio B eff of the signaling pathway. This agrees with the effective burst ratio for <lb/>the cascade derived by the information theory approach in Ref. 19, under the assumptions <lb/>of rapid production/decay outlined above. Physically, this result implies that B eff will be <lb/>dominated by the smallest values among the B and B u k . Hence, the efficiency of the noise <lb/>filtration in the cascade is limited by the weakest links. <lb/></div>

			<div type="annex">Appendix C: Analytic limiting form of the generalized nonlinear <lb/>feedback network <lb/>We will use the numerical optimization results described in the main text for the generalized <lb/>nonlinear TetR feedback network (Eq. (22)) to derive a limiting form of the system that can <lb/>be solved analytically. Since the optimization algorithm results in steep step-like functions <lb/>K r (p) and Γ p (p) with thresholds at p, let us assume that optimal limit for these Hill functions <lb/>looks like: <lb/>K r (p) = K 0 <lb/>r Θ(p − p), Γ p (p) = Γ 0 <lb/>p Θ(p − p), <lb/>(51) <lb/></div>

			<page>42 <lb/></page>

			<div type="annex">where the Heaviside step function Θ(x) = 0 for x &lt; 0 and Θ(x) = 1 for x &gt; 0. The plateau <lb/>heights K 0 <lb/>r &gt; 0 and Γ 0 <lb/>p &gt; 0 are assumed to be large, with a well defined ratio ξ ≡ K 0 <lb/>r /Γ 0 <lb/>p as <lb/>K 0 <lb/>r , Γ 0 <lb/>p → ∞. Since Γ 0 <lb/>p <lb/>γ p and thus Γ p (p) acts as the dominant protein degradation term, <lb/>we will set γ p = 0 for simplicity. (This has negligible effect on the resulting P s <lb/>r,p , particularly <lb/>since γ −1 <lb/>p = 8.3 h was already the longest time scale in the system.) <lb/>Under these assumptions, we would like to find an analytical steady-state probability <lb/>distribution P s <lb/>r,p which satisfies R rp = 0 from Eq. (27) for all r, p ≥ 0. We cannot solve <lb/>the system of equations directly, but we will introduce an ansatz for P s <lb/>r,p and verify that <lb/>it is a solution to Eq. (27). The first part of the ansatz is trivial: we assume P s <lb/>r,p = 0 for <lb/>p &lt; p 0 = p . This satisfies R rp = 0 for p &lt; p 0 exactly, regardless of the values of P s <lb/>r,p at <lb/>p ≥ p 0 . To motivate the second part of the ansatz, which covers the p ≥ p 0 region, we need <lb/>some more information about the moments of the distribution. This can be gathered by <lb/>defining the generating function, <lb/>F (z 1 , z 2 ) = <lb/>∞ <lb/>r=0 <lb/>∞ <lb/>p=p 0 <lb/>z r <lb/>1 z p−p 0 <lb/>2 <lb/>P s <lb/>r,p . <lb/>(52) <lb/>Summing the steady-state conditions R rp = 0 in Eq. (27) over all r &gt; 0, p ≥ p 0 , we obtain <lb/>an equation that can be expressed in terms of F : <lb/>γ r (1 − z 1 )F (1,0) (z 1 , z 2 ) + K 0 <lb/>r (z 1 − 1)F (z 1 , 0) + Γ 0 <lb/>p (z −1 <lb/>2 − 1) [F (z 1 , z 2 ) − F (z 1 , 0)] <lb/>+ κ p z 1 (z 2 − 1)F (1,0) (z 1 , z 2 ) = 0, <lb/>(53) <lb/>where F (i,j) (z 1 , z 2 ) ≡ ∂ i <lb/>z 1 ∂ j <lb/>z 2 F (z 1 , z 2 ). Taking the z 1 derivative of Eq. (53), and evaluating <lb/>the result at z 1 = 1, z 2 = 1, gives: <lb/>−γ r F (1,0) (1, 1) + K 0 <lb/>r F (1, 0) = 0. <lb/>(54) <lb/></div>

			<page>43 <lb/></page>

			<div type="annex">Similarly, differentiating Eq. (53) with respect to z 2 yields: <lb/>−Γ 0 <lb/>p [F (1, 1) − F (1, 0)] + κ p F (1,0) (1, 1) = 0. <lb/>(55) <lb/>Using the fact that F (1, 1) = 1 from the normalization of P s <lb/>r,p , and F (1,0) (1, 1) = r , <lb/>F (1, 0) = <lb/>∞ <lb/>r=0 P s <lb/>r,p 0 from the definition of the generating function in Eq. (52), we can <lb/>use Eqs. (54) and (55) to find: <lb/>r = <lb/>Γ 0 <lb/>p ξ <lb/>γ r + κ p ξ <lb/>, <lb/>∞ <lb/>r=0 <lb/>P s <lb/>r,p 0 = <lb/>γ r <lb/>γ r + κ p ξ <lb/>. <lb/>(56) <lb/>Thus we have an analytical expression for r , one of the moments necessary for calculating <lb/>the Fano factor. If we proceed to the next order of derivation, applying ∂ 2 <lb/>z 1 , ∂ 2 <lb/>z 2 , and ∂ z 1 ∂ z 2 <lb/>on Eq. (53) and evaluating at z 1 = 1, z 2 = 1, we can extract from these three equations the <lb/>following moment relations: <lb/>p − p 0 = <lb/>κ p ((γ r + κ p )ξ − ∆(γ r + κ p ξ)) <lb/>γ r (γ r + κ p ξ) <lb/>, σ 2 <lb/>r = (1 − ∆) r , <lb/>r(p − p 0 ) = (1 − ∆) <lb/>Γ 0 <lb/>p <lb/>γ r <lb/>− <lb/>r <lb/>ξ <lb/>, <lb/>(57) <lb/>where ∆ is defined as <lb/>∆ = r − <lb/>γ r + κ p ξ <lb/>γ r <lb/>∞ <lb/>r=0 <lb/>rP s <lb/>r,p 0 . <lb/>(58) <lb/>Thus the Fano factor σ 2 <lb/>r / r = 1 − ∆, but unfortunately we do not have an explicit solution <lb/>for ∆ from the generating function approach. (Higher order partial derivatives of Eq. (53) <lb/>do not form a closed system of equations.) However, the moment relations in Eq. (57) will <lb/>prove useful below. <lb/>From Eq. (56) we note that r → ∞ as Γ 0 <lb/>p → ∞, so the distribution is pushed toward <lb/>larger r as the step functions become steeper, just as we saw in the numerical optimization <lb/>(Fig. 6). In the large r limit, we can approximate P s <lb/>r,p as a continuous function of r (though it <lb/></div>

			<page>44 <lb/></page>

			<div type="annex">remains discrete in p). Based on the numerical optimization results, we choose the following <lb/>Gaussian ansatz for P s <lb/>r,p 0 , the first non-negligible p slice of the distribution: <lb/>P s <lb/>r,p 0 = A 0 e −(r−λ 0 ) 2 /(2s 2 <lb/>0 ) . <lb/>(59) <lb/>The parameters λ 0 and s 0 are to be determined, while A 0 must be chosen to satisfy ∞ <lb/>r=0 P s <lb/>r,p 0 <lb/>from Eq. (56). In the continuum, large r limit we can approximate the sum as ∞ <lb/>r=0 P s <lb/>r,p 0 ≈ <lb/>∞ <lb/>−∞ dr P s <lb/>r,p 0 , which implies that <lb/>A 0 = <lb/>γ r <lb/>2πs 2 <lb/>0 (γ r + κ p ξ) <lb/>. <lb/>(60) <lb/>Similarly, Eq. (58) gives <lb/>∆ = r − λ 0 , <lb/>(61) <lb/>so finding λ 0 is equivalent to finding ∆. <lb/>Let us now show that the ansatz of Eq. (59) yields a solution P s <lb/>r,p for p ≥ p 0 that satisfies <lb/>Eq. (27) in the large Γ 0 <lb/>p limit. Using Eq. (51) and the continuum approximation along the r <lb/>direction, we can rewrite Eq. (27) for p ≥ p 0 as <lb/>0 = R r,p ≈γ r ∂ r (rP s <lb/>r,p ) − K 0 <lb/>r δ p,p 0 ∂ r P s <lb/>r,p + Γ 0 <lb/>p P s <lb/>r,p+1 − (1 − δ p,p 0 )Γ 0 <lb/>p P s <lb/>r,p <lb/>+ κ p r (1 − δ p,p 0 )P s <lb/>r,p−1 − P s <lb/>r,p . <lb/>(62) <lb/>Plugging the ansatz for P s <lb/>r,p 0 from Eq. (59) into Eq. (62) for p = p 0 , we can solve for P s <lb/>r,p 0 +1 , <lb/>P s <lb/>r,p 0 +1 = A 0 e −(r−λ 0 ) 2 /(2s 2 <lb/>0 ) (γ r r − K 0 <lb/>r )(r − λ 0 ) + (κ p r − γ r )s 0 <lb/>Γ 0 <lb/>p s 0 <lb/>. <lb/>(63) <lb/></div>

			<page>45 <lb/></page>

			<div type="annex">Similarly, once P s <lb/>r,p 0 and P s <lb/>r,p 0 +1 are known, Eq. (62) for p = p 0 + 1 yields P s <lb/>r,p 0 +2 , <lb/>P s <lb/>r,p 0 +2 = <lb/>A 0 e −(r−λ 0 ) 2 /(2s 2 <lb/>0 ) <lb/>(Γ 0 <lb/>p ) 2 s 2 <lb/>0 <lb/>s 2 <lb/>0 −Γ 0 <lb/>p γ r + γ 2 <lb/>r − 3γ r κ p r + κ 2 <lb/>p r 2 <lb/>+ s 0 Γ 0 <lb/>p (λ 0 − r)(K 0 <lb/>r − γ r r) + λ 0 3γ 2 <lb/>r r − γ r 2κ p r 2 + K 0 <lb/>r + κ p K 0 <lb/>r r <lb/>+ r(2γ r − κ p r)(K 0 <lb/>r − 2γ r r) + γ r r(λ 0 − r) 2 (γ r r − K 0 <lb/>r ) . <lb/>(64) <lb/>We can iterate this procedure, using Eq. (62) to generate analytical expressions for all P s <lb/>r,p 0 +m , <lb/>m &gt; 0, which depend on the unknown parameters λ 0 and s 0 . To solve for these parameters, <lb/>let us first enforce the normalization condition, <lb/>1 = <lb/>∞ <lb/>m=0 <lb/>∞ <lb/>r=0 <lb/>P s <lb/>r,p 0 +m ≈ <lb/>∞ <lb/>m=0 <lb/>∞ <lb/>−∞ <lb/>dr P s <lb/>r,p 0 +m . <lb/>(65) <lb/>Though tedious, the integrals on the right-hand side of Eq. (65) can be explicitly carried <lb/>out for each m, since P s <lb/>r,p 0 +m has the form of a Gaussian exp(−(r − λ 0 ) 2 /(2s 2 <lb/>0 )) times a <lb/>polynomial in r. Since we are interested in the large Γ 0 <lb/>p limit, we can Taylor expand the <lb/>integrals up to first order in the small variable (Γ 0 <lb/>p ) −1 , which gives the following result: <lb/>∞ <lb/>−∞ <lb/>dr P s <lb/>r,p 0 +m ≈ <lb/>γ r <lb/>γ r + κ p ξ <lb/>κ p ξ <lb/>γ r + κ p ξ <lb/>m <lb/>+ <lb/>γ r m(κ p ξ) m (ξ(−2∆ − ξm + ξ) + (m − 1)s 0 (γ r + κ p ξ)) <lb/>2Γ 0 <lb/>p ξ 2 (γ r + κ p ξ) m <lb/>, <lb/>(66) <lb/>where s0 = s 0 /Γ 0 <lb/>p , and we have used Eq. (61) to write λ 0 = r − ∆, and Eq. (56) for <lb/>r . Plugging Eq. (66) into Eq. (65) and carrying out the sum over m, the normalization <lb/>condition becomes <lb/>1 = 1 − <lb/>κ p (γ r + κ p ξ) (∆γ r − κ p s 0 (γ r + κ p ξ) + κ p ξ 2 ) <lb/>Γ 0 <lb/>p γ 2 <lb/>r <lb/>. <lb/>(67) <lb/>Thus the term of order (Γ 0 <lb/>p ) −1 on the right must be zero, implying the following relation <lb/></div>

			<page>46 <lb/></page>

			<div type="annex">between s0 and ∆, <lb/>s0 = <lb/>∆γ r + κ p ξ 2 <lb/>κ p (γ r + κ p ξ) <lb/>. <lb/>(68) <lb/>In order to complete the derivation and solve for ∆, we need to calculate the moment p−p 0 , <lb/>p − p 0 = <lb/>∞ <lb/>m=0 <lb/>∞ <lb/>r=0 <lb/>mP s <lb/>r,p 0 +m ≈ <lb/>∞ <lb/>m=0 <lb/>m <lb/>∞ <lb/>−∞ <lb/>dr P s <lb/>r,p 0 +m . <lb/>(69) <lb/>Plugging in Eq. (66) for the integral, we carry out the sum over m and simplify using Eq. (68), <lb/>giving <lb/>p − p 0 = <lb/>κ p (Γ 0 <lb/>p γ r ξ + ∆(γ r + κ p ξ) 2 ) <lb/>Γ 0 <lb/>p γ 2 <lb/>r <lb/>. <lb/>(70) <lb/>Setting this equal to the p − p 0 result from Eq. (57), we finally can solve for ∆, or equiva-<lb/>lently the Fano factor σ 2 <lb/>r / r = 1 − ∆, <lb/>σ 2 <lb/>r <lb/>r <lb/>= 1 − <lb/>Γ 0 <lb/>p γ r κ p (1 − ξ)ξ <lb/>(γ r + κ p ξ)(Γ 0 <lb/>p γ r + (γ r + κ p ξ) 2 ) <lb/>≈ 1 − <lb/>(1 − ξ)ξκ p <lb/>γ r + κ p ξ <lb/>+ O((Γ 0 <lb/>p ) −1 ), <lb/>(71) <lb/>keeping the leading terms in the Taylor expansion for small (Γ 0 <lb/>p ) −1 . The Fano factor achieves <lb/>a minimum value equal to the WK linear optimum, <lb/>σ 2 <lb/>r,min <lb/>r <lb/>= <lb/>2 <lb/>1 + <lb/>√ <lb/>1 + B <lb/>= <lb/>σ 2 <lb/>r,WK <lb/>r <lb/>(72) <lb/>at ξ = ξ min = 1/(1 + <lb/>√ <lb/>1 + B), where B = κ p /γ r . Thus we see explicitly that nonlinear <lb/>threshold regulation with K r (p) and Γ p (p) behaving like step functions can directly match <lb/>(but not improve on) the efficiency of the optimal WK linear filter, so long as Γ 0 <lb/>p is large and <lb/>the ratio of the step function heights assumes a particular value ξ min . Counterintuitively, <lb/>this occurs despite the fact that the p copy numbers can be very small in our system, with <lb/>a narrow range of fluctuations in which discreteness plays a major role. <lb/></div>

			<page>47 <lb/></page>

			<div type="annex">Appendix D: Optimality for the TetR gene network under <lb/>extrinsic noise <lb/>In the frequency domain, we will model n ext <lb/>α (ω), the extrinsic part of the noise associated <lb/>with species α using, <lb/>n ext <lb/>α (ω) = <lb/>2c α kα <lb/>1 − iωτ e <lb/>η ext <lb/>α (ω), <lb/>(73) <lb/>where c α is a coefficient measuring the strength of the noise, and η ext (ω) is a Fourier-space <lb/>Gaussian white noise function. Comparing to the definition of the intrinsic noise, n int <lb/>α (ω) = <lb/>2 kα η α (ω), we see that c α is the ratio of the extrinsic to intrinsic noise PSD for species α <lb/>at ω = 0. The (1 − iωτ e ) −1 factor acts as a cutoff that suppresses frequencies ω <lb/>τ −1 <lb/>e . <lb/>The total noise function for species α is the sum of intrinsic and extrinsic contributions, <lb/>n α (ω) = n int <lb/>α (ω) + n ext <lb/>α (ω). We will focus on how the addition of extrinsic noise affects the <lb/>optimality conditions using the TetR yeast gene circuit example. <lb/>The calculation of H opt (ω) proceeds analogously to the no-extrinsic-noise procedure de-<lb/>scribed in the main text. The power spectra of the signal and noise are, <lb/>P s (ω) = 2rτ r <lb/>1 <lb/>1 + (ωτ r ) 2 + <lb/>c r <lb/>(1 + (ωτ r ) 2 )(1 + (ωτ e ) 2 ) <lb/>, <lb/>P n (ω) = <lb/>2rτ r <lb/>B <lb/>1 + <lb/>c p <lb/>1 + (ωτ e ) 2 . <lb/>(74) <lb/>The first and second terms in the square brackets represent the intrinsic and extrinsic con-<lb/>tributions respectively. The latter is parameterized by the coefficients c r and c p , and the <lb/>timescale τ e , which is assumed to be much larger than the dominant timescale, τ r , charac-<lb/>terizing the R fluctuations. The signal plus noise power spectrum, P y (ω) = P s (ω) + P n (ω), <lb/></div>

			<page>48 <lb/></page>

			<div type="annex">can be rewritten as a causal decomposition in the following manner: <lb/>P y (ω) = <lb/>2rτ r <lb/>B <lb/>1/2 (ρ + − iωτ r )( −1 ρ − − iωτ e ) <lb/>(1 − iωτ r )(1 − iωτ e ) <lb/>2 <lb/>≡ |P c <lb/>y (ω)| 2 , <lb/>(75) <lb/>where ≡ τ r /τ e , and <lb/>ρ ± = <lb/>µ ± µ 2 − 4 2 ν <lb/>2 <lb/>, <lb/>µ = 1 + B + 2 (1 + c p ), <lb/>ν = 1 + B(1 + c r ) + c p . <lb/>(76) <lb/>The expression P s (ω)/P c <lb/>y (ω) * and its additive causal decomposition {P s (ω)/P c <lb/>y (ω) * } c is given <lb/>by: <lb/>P s (ω) <lb/>P c <lb/>y (ω) * = <lb/>(2rτ r B) 1/2 (1 + c r + (ωτ e ) 2 ) <lb/>(1 − iωτ r )(1 − iωτ e )(ρ + + iωτ r )( −1 ρ − + iωτ e ) <lb/>, <lb/>(77) <lb/>P s (ω) <lb/>P c <lb/>y (ω) * <lb/>c <lb/>= <lb/>(2rτ r B) 1/2 (1 + c r − −2 ) <lb/>(1 − iωτ r )(1 − −1 )(ρ + + 1)( −1 ρ − + −1 ) <lb/>+ <lb/>(2rτ r B) 1/2 c r <lb/>(1 − )(1 − iωτ e )(ρ + + )( −1 ρ − + 1) <lb/>. <lb/>(78) <lb/>Using Eqs. (78) and (75) in Eq. (9), we obtain the form for the optimal filter function: <lb/>H opt (ω) = <lb/>BK(ω) <lb/>(1 − )(ρ + − iωτ r )( −1 ρ − − iωτ e ) <lb/>, <lb/>(79) <lb/></div>

			<page>49 <lb/></page>

			<div type="annex">where <lb/>K(ω) = <lb/>1 − (1 + c r ) 2 <lb/>(1 + ρ − )(1 + ρ + ) <lb/>(1 − iωτ e ) <lb/>+ <lb/>c r <lb/>( + ρ − )( + ρ + ) <lb/>(1 − iωτ r ). <lb/>(80) <lb/>Since is presumed small, we will expand H opt to lowest order in , giving the approximate <lb/>expression: <lb/>H opt (ω) ≈ <lb/>√ <lb/>1 + B − 1 <lb/>√ <lb/>1 + B − iωτ r <lb/>• <lb/>1 + c r <lb/>1+ <lb/>√ <lb/>1+B <lb/>√ ν+ <lb/>√ <lb/>1+B − iωτ e <lb/>ν <lb/>1+B − iωτ e <lb/>. <lb/>(81) <lb/>The first rational term is just the optimal filter result in the intrinsic-only case, Eq. (17), <lb/>while the second term represents the modification needed to accommodate the extrinsic <lb/>noise. As expected, the latter term approaches 1 when c r , c p → 0, since ν → 1 + B in this <lb/>limit. <lb/>There is a different non-trivial scenario where the second term is equal to 1. If the noise <lb/>magnitudes c r and c p are related such that, <lb/>1 + c r <lb/>1 + <lb/>√ <lb/>1 + B <lb/>√ <lb/>ν + <lb/>√ <lb/>1 + B <lb/>= <lb/>ν <lb/>1 + B <lb/>, <lb/>(82) <lb/>then the numerator and denominator exactly cancel each other out, removing the τ e depen-<lb/>dence from the optimal filter. Using the definition ν = 1 + B(1 + c r ) + c p , Eq. (82) can be <lb/>simplified to yield the relation: <lb/>c r = <lb/>1 <lb/>1 + <lb/>√ <lb/>1 + B <lb/>c p . <lb/>(83) <lb/>If this condition is satisfied, H opt (ω) is identical to the intrinsic-only optimal filter of Eq. (17) <lb/>(to lowest order in ), and hence the approximate optimality is also achieved at the same <lb/>feedback value, G opt <lb/>rp ≈ G opt <lb/>rp (B, τ p ). <lb/>Thus, the yeast gene circuit can still be fine-tuned to approach a WK optimal filter even <lb/>in the presence of extrinsic noise. However, this tuning requires the relative strengths c r and <lb/>c p of the R and P extrinsic noise to be related (at least approximately) by Eq. (83). The <lb/></div>

			<page>50 <lb/></page>

			<div type="annex">resulting minimal possible Fano factor σ 2 <lb/>r,opt /r is: <lb/>σ 2 <lb/>r,opt <lb/>r ≈ <lb/>2 <lb/>1 + <lb/>√ <lb/>1 + B <lb/>+ <lb/>τ r <lb/>τ e (1 + B + <lb/>√ <lb/>1 + B) <lb/>c p . <lb/>(84) <lb/>This is the intrinsic-only result of Eq. (21) in the main text plus an extrinsic noise con-<lb/>tribution in the second term. Not surprisingly, with more total noise in the system, the <lb/>standard deviation of the optimally filtered output increases. Since the second term is of <lb/>the order τ r /τ e it follows that the bigger the difference in time scales between the extrinsic <lb/>noise (τ e ) and the mRNA dynamics (τ r ), the easier it is to filter out the extrinsic influence <lb/>on the mRNA fluctuations. For B <lb/>1, the fundamental limit on the noise suppression still <lb/>arises from the intrinsic term in σ 2 <lb/>r,opt /r, which scales like ∼ B −1/2 ; the extrinsic contribution <lb/>decays more rapidly, ∼ B −1 . <lb/>The blue curves in Fig. 7 show the linear theory predictions for σ 2 <lb/>r /r as a function of A <lb/>in two cases: (i) c p = 80, c r = 23; (ii) c p = 160, c r = 46. The burst ratio B = 5, and τ e <lb/>is set equal to γ −1 <lb/>p , the longest time scale among the experimentally fitted parameters. For <lb/>both these cases the noise strengths c p and c r satisfy the relation in Eq. (83), and hence <lb/>it is possible to tune the system to approximately achieve WK optimality, just as in the <lb/>intrinsic-only scenario. The noise magnitudes were chosen so that the system is noticeably <lb/>perturbed by the extrinsic contribution. For example, if the signal s(t) is split into intrinsic <lb/>and extrinsic parts s int (t) and s ext (t), the ratios of their respective standard deviations are <lb/>σ ext <lb/>s /σ int <lb/>s = 0.8 for case (i) and 1.6 for case (ii). The value of σ 2 <lb/>r,opt /r is marked by horizontal <lb/>dashed lines, and the point A = A opt , where G opt <lb/>rp (ω) ≈ G opt <lb/>rp (B, τ p ) is satisfied, by a filled <lb/>circle. In all cases the system approaches σ 2 <lb/>r,opt /r near A = A opt , verifying the optimality <lb/>prediction. <lb/>As in the intrinsic-only scenario discussed in the main text, we can test the usefulness <lb/>of the linear theory through Gillespie simulations (results shown as open squares and circles <lb/>in Fig. 7), and reach a similar conclusion even in the presence of extrinsic noise. At large <lb/></div>

			<page>51 <lb/></page>

			<div type="annex">volumes, V = 10V 0 , the simulations converge to the linear theory, whereas for the more <lb/>realistic volume V = V 0 we see discrepancies due to nonlinearity and low copy numbers <lb/>(V 0 = 60 fL). Nevertheless, the Fano factor still reaches a minimum close to the predicted <lb/>A opt and σ 2 <lb/>r,opt /r values. <lb/></div>

			<page>52 <lb/></page>

			<div type="annex">Graphical TOC Entry <lb/>protein <lb/> + <lb/>+ <lb/>-<lb/>filter H(t) <lb/>promoter gene <lb/>mRNA <lb/>negative <lb/>feedback <lb/>} <lb/>signal s(t) <lb/>noise n(t) <lb/>output r(t) <lb/>= mRNA # <lb/></div>

			<page>53 </page>


	</text>
</tei>
