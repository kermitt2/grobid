<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Appears in Proceedings of the 4 <lb/>th International Conference on Knowledge Discovery and Data Mining, <lb/>AAAI Press, 1998, 359-363. <lb/>Learning to Predict Rare Events in Event Sequences <lb/>Gary M. Weiss <lb/>* <lb/>and Haym Hirsh <lb/>Department of Computer Science <lb/>Rutgers University <lb/>New Brunswick, NJ 08903 <lb/>gmweiss@att.com, hirsh@cs.rutgers.edu <lb/>Abstract <lb/>Learning to predict rare events from sequences of events <lb/>with categorical features is an important, real-world, <lb/>problem that existing statistical and machine learning <lb/>methods are not well suited to solve. This paper describes <lb/>timeweaver, a genetic algorithm based machine learning <lb/>system that predicts rare events by identifying predictive <lb/>temporal and sequential patterns. Timeweaver is applied to <lb/>the task of predicting telecommunication equipment failures <lb/>from 110,000 alarm messages and is shown to outperform <lb/>existing learning methods. <lb/></front>

			<body>Introduction <lb/>An event sequence is a sequence of timestamped <lb/>observations, each described by a fixed set of features. In <lb/>this paper we focus on the problem of predicting rare <lb/>events from sequences of events which contain categorical <lb/>(non-numerical) features. Predicting telecommunication <lb/>equipment failures from alarm messages is one important <lb/>problem which has these characteristics. For AT&amp;T, where <lb/>most traffic is handled by 4ESS switches, the specific task <lb/>is to predict the failure of 4ESS hardware components from <lb/>diagnostic alarm messages reported by the 4ESS itself. <lb/>Predicting fraudulent credit card transactions and the start <lb/>of transcription in DNA sequences are two additional <lb/>problems with similar characteristics. For a variety of <lb/>reasons, these problems cannot be easily solved by existing <lb/>methods. This paper describes timeweaver, a machine <lb/>learning system specifically designed to solve rare event <lb/>prediction problems with categorical features by identifying <lb/>predictive temporal and sequential patterns in the data. <lb/>Background <lb/>Event prediction problems are very similar to time-series <lb/>prediction problems. Classical time-series prediction, which <lb/>has been studied extensively within the field of statistics, <lb/>involves predicting the next n successive observations from <lb/>a history of past observations (Brockwell &amp; Davis 1996). <lb/>These statistical techniques are not applicable to the event <lb/>prediction problems we are interested in because they <lb/>require numerical features and do not support predicting a <lb/></body>

			<front>*Also AT&amp;T Labs, Middletown NJ 07748 <lb/>Copyright ©1998, American Association for Artificial Intelligence <lb/>(www.aaai.org). All rights reserved. <lb/></front>

			<body>specific &quot;event&quot; within a window of time. Relevant work in <lb/>machine learning has relied on reformulating the prediction <lb/>problem into a concept learning problem (Dietterich &amp; <lb/>Michalski 1985). The reformulation process involves <lb/>transforming the event sequence into an unordered set of <lb/>examples by encoding multiple events as individual <lb/>examples. The transformation procedure preserves only a <lb/>limited amount of sequence and temporal information, but <lb/>enables any concept learning program to be used. This <lb/>approach has been used to predict catastrophic equipment <lb/>failures (Weiss, Eddy &amp; Weiss 1998) and to identify <lb/>network faults (Sasisekharan, Seshadri &amp; Weiss 1996). <lb/>Non-reformulation based approaches have also been tried. <lb/>Computational learning theory has focused on learning <lb/>regular expressions and pattern languages from data, but <lb/>has produced few practical systems (Jiang &amp; Li 1991; <lb/>Brazma 1993). Data mining algorithms for identifying <lb/>common patterns in event sequences have been developed, <lb/>but these patterns are not necessarily useful for prediction. <lb/>Nonetheless, such algorithms have been used to predict <lb/>network faults (Manilla, Toivonen &amp; Verkamo 1995). <lb/>The Event Prediction Problem <lb/>This section defines our formulation of the event prediction <lb/>problem. <lb/>Basic Problem Formulation <lb/>An event Et is a timestamped observation which occurs at <lb/>time t and is described by a set of feature-value pairs. An <lb/>event sequence is a time-ordered sequence of events, S = <lb/>Et 1 , Et 2 , ..., Et n , which includes all n events in the time <lb/>interval t 1 ≤ t ≤ t n . Events are associated with a domain <lb/>object D which is the source, or generator, of the events. <lb/>The target event is the event to be predicted and is specified <lb/>by a set of feature-value pairs. Each target event, X t , <lb/>occurring at time t, has a prediction period associated with <lb/>it, as shown below. The warning time, W, is the &quot;lead <lb/>time&quot; necessary for a prediction to be useful and the <lb/>monitoring time, M, determines the maximum amount of <lb/>time prior to the target event for which a prediction is <lb/>considered correct. <lb/>X t <lb/>t -W <lb/>t -M <lb/>prediction period <lb/></body>

			<page>2 <lb/></page>

			<body>The warning and monitoring times should be set based on <lb/>the problem domain. In general, the problem will be easier <lb/>the smaller the value of the warning time and the larger the <lb/>value of the monitoring time; however, too large a value for <lb/>the monitoring time will result in meaningless predictions. <lb/>The problem is to learn a prediction procedure P that <lb/>correctly predicts the target events. Thus, P is a function <lb/>that maps an event sequence to a boolean prediction value. <lb/>A prediction is made upon observation of each event, so <lb/>P: Et 1 , Et 2 ,..., Et x →{+,-}, for each event Et x The semantics <lb/>of a prediction still need to be specified. A target event is <lb/>predicted if at least one prediction is made within its <lb/>prediction period, regardless of any subsequent negative <lb/>predictions. Negative predictions can therefore be ignored, <lb/>and henceforth &quot;prediction&quot; will mean &quot;positive <lb/>prediction&quot;. A prediction is correct if it falls within the <lb/>prediction period of some target event. <lb/>This formulation can be applied to the telecommunication <lb/>problem. Each 4ESS generated alarm is an event with <lb/>three features: device, which identifies the component <lb/>within the 4ESS reporting the problem, severity, which can <lb/>take on the value &quot;minor&quot; or &quot;major&quot;, and code, which <lb/>specifies the exact problem. Each 4ESS switch is a domain <lb/>object that generates an event sequence and the target event <lb/>is any event with code set to &quot;FAILURE&quot;. <lb/>Evaluation Measures <lb/>The evaluation measures are summarized in Figure 1. <lb/>Recall is the percentage of target events correctly predicted. <lb/>Simple precision is the percentage of predictions that are <lb/>correct. Simple precision is misleading since it counts <lb/>multiple predictions of the same target event multiple <lb/>times. Normalized precision eliminates this problem by <lb/>replacing the number of correct predictions with the <lb/>number of target events correctly predicted. This measure <lb/>still does not account for the fact that incorrect predictions <lb/>located closely together may not be as harmful as the same <lb/>number spread out over time. Reduced precision remedies <lb/>this. A prediction is &quot;active&quot; for a period equal to its <lb/>monitoring time, since the target event should occur <lb/>somewhere during that period. Reduced precision replaces <lb/>the number of false predictions with the number of <lb/>discounted false predictions-the number of complete, non-<lb/>overlapping, monitoring periods associated with a false <lb/>prediction. Thus, two false predictions occurring a half <lb/>monitoring period apart yields 1½ discounted false <lb/>predictions, due to a ½ monitoring period overlap in their <lb/>active periods. <lb/>Recall = <lb/># Target Events Predicted <lb/>Total Target Events <lb/>Simple Precision = <lb/>TP <lb/>TP + FP <lb/>, <lb/>Normalized Precision = <lb/>Reduced Precision = <lb/># Target Events Predicted <lb/># Target Events Predicted + FP <lb/># Target Events Predicted <lb/># Target Events Predicted + Discounted FP <lb/>TP = True Predictions <lb/>FP = False Predictions <lb/>Figure 1: Evaluation Measures for Event Prediction <lb/>The Basic Learning Method <lb/>Our learning method, which operates directly on the data <lb/>and does not require the problem to be reformulated, uses <lb/>the following two steps: <lb/>1. Identify prediction patterns. The space of prediction <lb/>patterns is searched to identify a set, C, of candidate <lb/>prediction patterns. Each pattern c∈C should do well <lb/>predicting a subset of the target events. <lb/>2. Generate prediction rules. <lb/>An ordered list of <lb/>prediction patterns is generated from C. Prediction <lb/>rules are then formed by creating a disjunction of the <lb/>top n prediction patterns, thereby creating solutions <lb/>with different precision/recall values. <lb/>This two step approach allows us to focus our effort on the <lb/>more difficult task of identifying prediction patterns. Also, <lb/>by using a general search based method in the first step, we <lb/>are able to use our own evaluation metrics-something <lb/>which cannot be done with existing learning programs, <lb/>which typically use predictive accuracy. For efficiency, <lb/>our learning method exploits the fact that target events are <lb/>expected to occur infrequently. It does this by maintaining, <lb/>for each prediction pattern, a boolean prediction vector of <lb/>length n that indicates which of the n target events in the <lb/>training set are correctly predicted. This information is <lb/>used in step 1 to ensure that a diverse set of patterns is <lb/>identified and in step 2 to intelligently construct prediction <lb/>rules from the patterns. <lb/>The learning method requires a well defined space of <lb/>prediction patterns. The language for representing this <lb/>space is similar to the language for expressing the raw data. <lb/>A prediction pattern is a sequence of events connected by <lb/>ordering primitives that define sequential or temporal <lb/>constraints between consecutive events. The ordering <lb/>primitives are defined in the list below, in which A, B, C, <lb/>and D represent individual events. <lb/>• the wildcard &quot;*&quot; primitive matches any number of <lb/>events so the prediction pattern A*D matches ABCD <lb/>• the next &quot;.&quot; primitive matches no events so the <lb/>prediction pattern A.B.C only matches ABC <lb/>• the unordered &quot;|&quot; primitive allows events to occur in <lb/>any order and is commutative so that the prediction <lb/>pattern A|B|C will match, amongst others, CBA. <lb/>The &quot;|&quot; primitive has highest precedence so the pattern <lb/>&quot;A.B*C|D|E&quot; matches an A, followed immediately by a B, <lb/>followed sometime later by a C, D and E, in any order. <lb/>Each feature in an event is permitted to take on the &quot;?&quot; <lb/>value that matches any feature value. A prediction pattern <lb/>also has an integer-valued pattern duration. A prediction <lb/>pattern matches a sequence of events within an event <lb/>sequence if 1) the events within the prediction pattern <lb/>match events within the event sequence, 2) the ordering <lb/>constraints expressed in the prediction pattern are obeyed, <lb/>and 3) the events involved in the match occur within the <lb/>pattern duration. This language enables flexible and noise-<lb/>tolerant prediction rules to be constructed, such as the rule: <lb/>if 3 (or more) A events and 4 (or more) B events occur <lb/></body>

			<page>3 <lb/></page>

			<body>within an hour, then predict the target event. This language <lb/>was designed to provide a small set of features useful for <lb/>many real-world prediction tasks. Extensions to this <lb/>language require making changes only to timeweaver&apos;s <lb/>pattern-matching routines. <lb/>A Genetic Algorithm for Identifying <lb/>Prediction Patterns <lb/>We use a genetic algorithm (GA) to identify a diverse set of <lb/>prediction patterns. Each individual in the GA&apos;s population <lb/>represents part of a complete solution and should perform <lb/>well at classifying a subset of the target events. Our <lb/>approach resembles that of classifier systems, which are <lb/>GAs that evolve a set of classification rules (Goldberg <lb/>1989). The main differences are that in our approach rules <lb/>cannot chain together and that instead of forming a ruleset <lb/>from the entire population, we use a second step to prune <lb/>&quot;bad&quot; rules. Our approach is also similar to the approach <lb/>taken by other GA&apos;s which learn disjunctive concepts from <lb/>examples (Giordana, Saita &amp; Zini 1994). <lb/>We use a steady-state GA, where only a few individuals <lb/>are modified each &quot;iteration&quot;, because such a GA is <lb/>believed to be more computationally efficient than a <lb/>generational GA when the time to evaluate an individual is <lb/>large (true in our case due to the assumption of large data <lb/>sets). The basic steps in our GA are shown below. <lb/>1. Initialize population <lb/>2. while stopping criteria not met <lb/>3. <lb/>select 2 individuals from the population <lb/>4. <lb/>apply mutation operator to both individuals with P M ; <lb/>else apply crossover operator <lb/>5. <lb/>evaluate the 2 newly formed individuals <lb/>6. <lb/>replace 2 existing individuals with the new ones <lb/>7. done <lb/>The population is initialized by creating prediction patterns <lb/>containing a single event, with the feature values set 50% <lb/>of the time to the wildcard value and the remaining time to <lb/>a randomly selected feature value. The GA continues until <lb/>either a pre-specified number of iterations are executed or <lb/>the performance of the population peaks. The mutation <lb/>operator randomly modifies a prediction pattern, changing <lb/>the feature values, ordering primitives, and/or the pattern <lb/>duration. Crossover is accomplished via a variable length <lb/>crossover operator, as shown in Figure 2. The lengths of <lb/>the offspring may differ from that of the parents and hence <lb/>over time prediction patterns of any size can be generated. <lb/>The pattern duration of each child is set by trying each <lb/>parent&apos;s pattern duration and the average of the two, and <lb/>then selecting the value which yields the best results. <lb/>A || B C D E <lb/>X Y || Z <lb/>A Z <lb/>X Y B C D E <lb/>Figure 2: Variable Length Crossover <lb/>The Selection and Replacement Strategy <lb/>The GA&apos;s selection and replacement strategies must balance <lb/>two opposing criteria: they must focus the search in the <lb/>most profitable areas of the search space but also maintain <lb/>a diverse population, to avoid premature convergence and <lb/>to ensure that the individuals in the population collectively <lb/>cover most of the target events. The challenge is to <lb/>maintain diversity using a minimal amount of global <lb/>information that can be efficiently computed. <lb/>The fitness of a prediction pattern is based on both its <lb/>precision and recall and is computed using the F-measure, <lb/>defined in equation 1, where β controls the importance of <lb/>precision relative to recall. Any fixed value of β yields a <lb/>fixed bias and, in practice, leads to poor performance of the <lb/>GA. To avoid this problem, for each iteration of the GA <lb/>the value of β is randomly selected from the range of 0 to 1, <lb/>similar to what was done by Murata &amp; Ishibuchi (1995). <lb/>fitness = <lb/>(β <lb/>β <lb/>2 <lb/>2 <lb/>+ 1) precision recall <lb/>precision + recall <lb/>⋅ <lb/>(1) <lb/>To encourage diversity, we use a niching strategy called <lb/>sharing that rewards individuals based on how different <lb/>they are from other individuals in the population (Goldberg <lb/>1989). Individuals are selected proportional to their shared <lb/>fitness, which is defined as fitness divided by niche count. <lb/>The niche count, defined in equation 2, measures the degree <lb/>of similarity of individual i to the p individuals comprising <lb/>the population. <lb/>niche count i = <lb/>j <lb/>n <lb/>= <lb/>∑ <lb/>1 <lb/>(1 -distance(i,j)) <lb/>3 <lb/>(2) <lb/>The similarity of two individuals is measured using a <lb/>phenotypic distance metric that measures the distance based <lb/>on the performance of the individuals. In our case, this <lb/>distance is simply the fraction of bit positions in the two <lb/>prediction vectors that differ (i.e., the fraction of target <lb/>events for which they have different predictions). The <lb/>more similar an individual to the rest of the individuals in <lb/>the population, the smaller the distances and the greater the <lb/>niche count value; if an individual is identical to every <lb/>other individual in the population, then the niche count will <lb/>be equal to the population size. <lb/>The replacement strategy also uses shared fitness. <lb/>Individuals are chosen for deletion inversely proportional to <lb/>their shared fitness, where the fitness component is <lb/>computed by averaging together the F-measure of equation <lb/>1 with β values of 0, ½, and 1, so the patterns that perform <lb/>poorly on precision and recall are most likely to be deleted. <lb/>Creating Prediction Rules <lb/>A greedy algorithm, shown below, is used to form a list of <lb/>prediction rules, S, from the set of candidate patterns, C, <lb/>returned by the GA. The precision, recall, and prediction <lb/>vector information computed in the first step for each <lb/>prediction pattern are used, so that only step 11 requires <lb/>access to the training set; this step is therefore the most <lb/>time-intensive step in the algorithm. <lb/></body>

			<page>4 <lb/></page>

			<body>1. C = patterns returned from the GA; S = {}; <lb/>2. while C ≠ ∅ do <lb/>3. <lb/>for c ∈C do <lb/>4. <lb/>if (increase_recall(S+c, S) ≤ THRESHOLD) <lb/>5. <lb/>then C = C -c; <lb/>6. <lb/>else c.eval = PF × (c.precision -S.precision) + <lb/>7. <lb/>increase_recall(S+c, S); <lb/>8. <lb/>done <lb/>9. <lb/>best = {c ∈C, ∀x∈C| c.eval ≥ x.eval} <lb/>10. <lb/>S = S || best; C = C -best; <lb/>11. <lb/>recompute S.precision on training set; <lb/>12. done <lb/>This algorithm builds solutions with increasing recall by <lb/>heuristically selecting the best prediction pattern remaining <lb/>in C, using the evaluation function on line 6. The evaluation <lb/>function rewards those candidate patterns that have high <lb/>precision and predict many target events not predicted by S. <lb/>The Prediction Factor (PF) controls the importance of <lb/>precision vs. recall. Prediction patterns that do not increase <lb/>the recall by at least THRESHOLD are discarded. Both <lb/>THRESHOLD and PF affect the complexity of the learned <lb/>concept and can prevent overfitting of the data. The <lb/>algorithm returns an ordered list of patterns, where the first <lb/>solution contains the first prediction pattern in the list, the <lb/>second solution the first two prediction patterns, etc. Thus, <lb/>a precision/recall curve can be constructed from S and the <lb/>user can select a solution based on the relative importance <lb/>of precision and recall for the problem at hand. <lb/>The algorithm is quite efficient: if p is the population size <lb/>of the GA (i.e., p patterns are returned), then the algorithm <lb/>requires O(p <lb/>2 ) computations of the evaluation function and <lb/>O(p) evaluations on the training data (step 11). Since the <lb/>information required to compute the evaluation function is <lb/>available, this leads to an O(ps) algorithm, given the <lb/>assumption of large data sets and a small number of target <lb/>events (where s is the training set size). In practice, fewer <lb/>than p iterations of the for loop will be necessary, since <lb/>most prediction patterns will not pass the test on line 4. <lb/>Experiments <lb/>Timeweaver was applied to the task of predicting 4ESS <lb/>equipment failures, using a training set of 110,000 alarms <lb/>reported from 55 4ESS switches. The test set contained <lb/>40,000 alarms from 20 different 4ESS switches. This data <lb/>included 1200 alarms which indicate equipment failure. <lb/>For all experiments, THRESHOLD is set to 1% and PF to <lb/>10, and, unless otherwise noted, all results are based on <lb/>2000 iterations of the GA. Precision is measured using <lb/>reduced precision, except in Figure 6 where simple <lb/>precision is used in order to permit comparison with other <lb/>approaches. Unless stated otherwise, all experiments use a <lb/>20 second warning time and an 8 hour monitoring time. <lb/>Figure 3 shows the performance of the learned prediction <lb/>rules, generated at different points during the execution of <lb/>the GA. The &quot;Best 2000&quot; curve shows the performance of <lb/>the prediction rules formed by combining the &quot;best&quot; <lb/>prediction patterns from the first 2000 iterations. <lb/>Improvements were not found after iteration 2000. <lb/>0 <lb/>1 0 <lb/>2 0 <lb/>3 0 <lb/>4 0 <lb/>5 0 <lb/>6 0 <lb/>7 0 <lb/>8 0 <lb/>9 0 <lb/>1 0 0 <lb/>0 <lb/>1 0 <lb/>2 0 <lb/>3 0 <lb/>4 0 <lb/>5 0 <lb/>6 0 <lb/>R E C A L L <lb/>PRECISION <lb/>It e ra t io n 0 <lb/>It e ra t io n 2 5 0 <lb/>It e ra t io n 5 0 0 <lb/>It e ra t io n 1 0 0 0 <lb/>B e s t 2 0 0 0 <lb/>( 4 .4 ,9 0 . 0 ) <lb/>Figure 3: The Performance of the Prediction Rules <lb/>These results are notable-a baseline strategy that predicts <lb/>a failure every warning time (20 seconds) only yields a <lb/>precision of 3% and a recall of 63%. A recall greater than <lb/>63% can never be achieved since 37% of the failures have <lb/>no events within their prediction period. The pattern <lb/>351:&lt;TMSP,?,MJ&gt;*&lt;?,?,MJ&gt;*&lt;?,?,MN&gt; corresponds to the first <lb/>data point in the &quot;Best 2000&quot; curve in Figure 3. This pattern <lb/>indicates that within a 351 second time period, a major <lb/>severity alarm on a TMSP device is followed by a major <lb/>alarm and then a minor alarm. <lb/>The results of varying the warning time, shown in Figure <lb/>4, demonstrate that for this domain it is much easier to <lb/>predict failures when only a short warning time is required. <lb/>These results make sense since we expect the alarms most <lb/>indicative of a failure to occur shortly before the failure. <lb/>0 <lb/>2 0 <lb/>4 0 <lb/>6 0 <lb/>8 0 <lb/>1 0 0 <lb/>0 <lb/>1 0 <lb/>2 0 <lb/>3 0 <lb/>4 0 <lb/>5 0 <lb/>6 0 <lb/>7 0 <lb/>8 0 <lb/>R E C A L L <lb/>PRECISION <lb/>1 s e c . <lb/>1 0 s e c . <lb/>2 0 s e c . <lb/>1 0 m i n . <lb/>3 0 m i n . <lb/>Figure 4: Effect of Warning Time on Learning <lb/>Figure 5 shows that increasing the monitoring time from 1 <lb/>to 8 hours significantly improves timeweaver&apos;s ability to <lb/>predict failures; we believe no such improvement is seen <lb/>when the monitoring time increases to 1 day because the <lb/>larger prediction period leads timeweaver to focus its <lb/>attention on &quot;spurious correlations&quot; in the data. <lb/>0 <lb/>1 0 <lb/>2 0 <lb/>3 0 <lb/>4 0 <lb/>5 0 <lb/>6 0 <lb/>7 0 <lb/>8 0 <lb/>9 0 <lb/>1 0 0 <lb/>0 <lb/>1 0 <lb/>2 0 <lb/>3 0 <lb/>4 0 <lb/>5 0 <lb/>6 0 <lb/>R E C A L L <lb/>PRECISION <lb/>1 5 m i n <lb/>1 h r <lb/>8 h r <lb/>1 d a y <lb/>Figure 5: Effect of Monitoring Time on Learning <lb/></body>

			<page>5 <lb/></page>

			<body>Comparison with Other Methods <lb/>Timeweaver&apos;s performance was compared to C4.5rules <lb/>(Quinlan 1993) and RIPPER (Cohen 1995), two rule <lb/>induction systems, and FOIL, a system that learns logical <lb/>definitions from relations (Quinlan 1990). In order to use <lb/>the &quot;example-based&quot; rule induction systems, the event <lb/>sequences were transformed into examples by using a <lb/>sliding window. With a window size of 2, examples are <lb/>generated with the features: device1, severity1, code1, <lb/>device2, severity2, and code2. Each example&apos;s classification <lb/>is based on whether the last event included in the example <lb/>falls within the prediction period of a target event. Because <lb/>equipment failures are rare, the class distribution of the <lb/>generated examples is skewed; this prevented C4.5rules and <lb/>RIPPER from predicting any failures. To compensate, <lb/>various values of misclassification cost (i.e., the relative <lb/>cost of false negatives to false positives) were tried and the <lb/>best results are shown in Figure 6. In the figure, the <lb/>number after the w indicates the window size and the <lb/>number after the m the misclassification cost. FOIL is a <lb/>more natural choice for solving event prediction problems <lb/>since the problem is easily translated into a relational <lb/>learning problem. With FOIL, the sequence information is <lb/>encoded via the extensionally defined successor relation. <lb/>0 <lb/>1 0 <lb/>2 0 <lb/>3 0 <lb/>4 0 <lb/>5 0 <lb/>6 0 <lb/>7 0 <lb/>8 0 <lb/>9 0 <lb/>10 0 <lb/>0 <lb/>2 <lb/>4 <lb/>6 <lb/>8 <lb/>R E C AL L <lb/>PRECISION <lb/>tim ew e aver <lb/>c 4.5 (w 2 m 10) <lb/>c 4.5 (w 3 m 5) <lb/>ripper (w 2 m 35) <lb/>ripper (w 3 m 20) <lb/>ripper (w 4 m 20) <lb/>F O IL <lb/>Figure 6: Comparison with Other ML Methods <lb/>Figure 6 shows that timeweaver outperforms the other <lb/>methods; it produces higher precision solutions that span a <lb/>much wider range of recall values. RIPPER&apos;s best <lb/>performance resulted from a window size of 3; due to <lb/>computational limits, a window size greater than 3 could <lb/>not be used with C4.5rules. FOIL produced results inferior <lb/>to the other methods, but its performance might improve if <lb/>relations encoding temporal information were added. <lb/>Timeweaver can also be compared against ANSWER, <lb/>the expert system which handles 4ESS alarms (Weiss, Ros <lb/>&amp; Singhal 1998). ANSWER uses a simple thresholding <lb/>strategy to generate an alert when more than a specified <lb/>number of interrupt alarms occur within a specified time <lb/>period. These alerts can be interpreted as a prediction that <lb/>the device generating the alarm is going to fail. Various <lb/>thresholding strategies were tried and those yielding the <lb/>best results are shown in Figure 7. By comparing these <lb/>results with those in Figure 3, we see that timeweaver <lb/>yields results with precision 3-5 times higher for a given <lb/>recall value. Much of this improvement is undoubtedly due <lb/>to the fact that timeweaver&apos;s concept space is much more <lb/>expressive than that of a simple thresholding strategy. <lb/>6 <lb/>7 <lb/>8 <lb/>9 <lb/>1 0 <lb/>1 1 <lb/>1 2 <lb/>1 3 <lb/>1 4 <lb/>1 5 <lb/>1 6 <lb/>1 7 <lb/>0 <lb/>1 0 <lb/>2 0 <lb/>3 0 <lb/>4 0 <lb/>5 0 <lb/>R E C A L L <lb/>PRECISION <lb/>t h r e s h o l d d u r a t i o n : 4 h r <lb/>t h r e s h o l d d u r a t i o n : 1 d a y <lb/>2 i n 1 d a y <lb/>3 i n 1 d a y <lb/>4 i n 1 d a y <lb/>1 i n t e r r u p t i n 1 d a y <lb/>1 i n t e r r u p t <lb/>i n 4 h o u r s <lb/>2 i n 4 h r s <lb/>9 i n 1 d a y <lb/>3 i n 4 h r s <lb/>6 i n 1 d a y <lb/>4 i n 4 h r s <lb/>7 i n 4 h r s <lb/>Figure 7: Using Interrupt Thresholding to Predict Failures <lb/>Conclusion <lb/>This paper investigated the problem of predicting rare <lb/>events from sequences of events with categorical features <lb/>and showed that timeweaver, a GA-based machine learning <lb/>system, is able to outperform existing methods at this <lb/>prediction task. Additional information is available from <lb/>http://paul.rutgers.edu/~gweiss/thesis/timeweaver.html. <lb/></body>

			<listBibl>References <lb/>Brazma, A. 1993. Efficient identification of regular expressions <lb/>from representative examples. In of the Sixth Annual <lb/>Workshop on Computational Learning Theory, 236-242. <lb/>Brockwell, P. J., and Davis, R. 1996. Introduction to Time-Series <lb/>and Forecasting. Springer-Verlag. <lb/>Cohen, W. 1995. Fast effective rule induction. In Proceedings of the <lb/>Twelfth International Conference on Machine Learning, 115-123. <lb/>Dietterich, T., and Michalski, R. 1985. Discovering patterns in <lb/>sequences of events, Artificial Intelligence, 25:187-232. <lb/>Giordana, A., Saitta, L., and Zini, F. 1994. Learning disjunctive <lb/>concepts means of genetic algorithms. In Proceedings of the <lb/>Eleventh International Conference on Machine Learning, 96-104. <lb/>Goldberg, D. 1989. Algorithms in Search, Optimization <lb/>and Machine Learning, Addison-Wesley. <lb/>Jiang, T., and Li, M. 1991. On the complexity of learning strings <lb/>and sequences. In Proceedings of the Fourth Annual Workshop <lb/>on Computational Learning Theory, 367-371. <lb/>Manilla, H., Toivonen, H., and Verkamo, A. 1995. Discovering <lb/>frequent episodes in sequences. In Proceedings of the First <lb/>International Conference on Knowledge Discovery and Data <lb/>Mining, 210-215, AAAI Press. <lb/>Murata, T., and Ishibuchi, H. 1995. MOGA: Multi-objective <lb/>genetic algorithms. In Proceedings of the IEEE International <lb/>Conference on Evolutionary Computation, 289-294. <lb/>Quinlan, J. R., 1990. Learning logical definitions from relations, <lb/>Machine Learning, 5: 239-266. <lb/>Quinlan, J. R. 1993. C4.5: Programs for Machine Learning. San <lb/>Mateo, CA: Morgan Kaufmann. <lb/>Sasisekharan, R., Seshadri, V., and Weiss, S. 1996. Data mining <lb/>and forecasting in large-scale telecommunication networks, IEEE <lb/>Expert, 11(1): 37-43. <lb/>Weiss, G. M., Eddy, J., and Weiss, S. 1998. Intelligent <lb/>technologies for telecommunications. In Intelligent Engineering <lb/>Applications, Chapter 8, CRC Press. <lb/>Weiss, G. M., Ros J. P., and Singhal, A. 1998. ANSWER: <lb/>network monitoring using object-oriented rules. In Proceedings <lb/>of the Tenth Conference on Innovative Applications of Artificial <lb/>Intelligence, AAAI Press. </listBibl>


	</text>
</tei>
