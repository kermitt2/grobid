<TEI xmlns="http://www.tei-c.org/ns/1.0">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title level="a">Sensitivity by Parametricity</title>
        <author>
          <persName>
            <forename>Elisabet</forename>
            <surname>Lobo-Vesga</surname>
          </persName>
        </author>
        <author>
          <persName>
            <forename>Alejandro</forename>
            <surname>Russo</surname>
          </persName>
        </author>
        <author>
          <persName>
            <forename>Marco</forename>
            <surname>Gaboardi</surname>
          </persName>
        </author>
        <author>
          <persName>
            <forename>Carlos Tomé</forename>
            <surname>Cortiñas</surname>
          </persName>
        </author>
      </titleStmt>
      <editionStmt>
        <edition>
          <date when="2025-10-30T12:09:04.734303Z">30.10.2025 12:09:04</date>
          <title>grobid.training.segmentation [default]</title>
          <idno type="fileref">10.1145$1$3689726</idno>
        </edition>
      </editionStmt>
      <publicationStmt>
        <publisher>Association for Computing Machinery (ACM)</publisher>
        <availability>
          <licence target="https://creativecommons.org/licenses/by/4.0/"/>
        </availability>
        <date type="publication">2024</date>
        <idno type="DOI">10.1145/3689726</idno>
      </publicationStmt>
      <sourceDesc>
        <bibl>Elisabet Lobo-Vesga, Alejandro Russo, Marco Gaboardi, Carlos Tomé Cortiñas. (2024). Sensitivity by Parametricity. Proceedings of the ACM on Programming Languages, 8(OOPSLA2), 415-441. DOI: 10.1145/3689726</bibl>
      </sourceDesc>
    </fileDesc>
    <encodingDesc>
      <appInfo>
        <application version="1.0" ident="pdf-tei-editor" type="editor">
          <ref target="https://github.com/mpilhlt/pdf-tei-editor"/>
        </application>
        <application version="0.8.3-SNAPSHOT" ident="GROBID" when="2025-10-30T12:09:04.734303Z" type="extractor">
          <desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
          <label type="revision">eb7768b</label>
          <label type="flavor">default</label>
          <label type="variant-id">grobid.training.segmentation</label>
          <ref target="https://github.com/kermitt2/grobid"/>
        </application>
      </appInfo>
    </encodingDesc>
    <revisionDesc>
      <change when="2025-10-30T12:09:04.734303Z" status="draft">
        <desc>Generated with createTraining API</desc>
      </change>
    </revisionDesc>
  </teiHeader>
  <text xmlns="http://www.tei-c.org/ns/1.0" xml:lang="en">
        <front>Deriving Dependently-Typed OOP from First Principles <lb/>DAVID BINDER, University of Tübingen, Germany <lb/>INGO SKUPIN, University of Tübingen, Germany <lb/>TIM SÜBERKRÜB, Aleph Alpha Research at IPAI, Germany <lb/>KLAUS OSTERMANN, University of Tübingen, Germany <lb/>The expression problem describes how most types can easily be extended with new ways to produce the type or <lb/>new ways to consume the type, but not both. When abstract syntax trees are defined as an algebraic data type, <lb/>for example, they can easily be extended with new consumers, such as print or eval, but adding a new con-<lb/>structor requires the modification of all existing pattern matches. The expression problem is one way to eluci-<lb/>date the difference between functional or data-oriented programs (easily extendable by new consumers) and <lb/>object-oriented programs (easily extendable by new producers). This difference between programs which are <lb/>extensible by new producers or new consumers also exists for dependently typed programming, but with one <lb/>core difference: Dependently-typed programming almost exclusively follows the functional programming <lb/>model and not the object-oriented model, which leaves an interesting space in the programming language <lb/>landscape unexplored. In this paper, we explore the field of dependently-typed object-oriented programming <lb/>by deriving it from first principles using the principle of duality. That is, we do not extend an existing object-<lb/>oriented formalism with dependent types in an ad-hoc fashion, but instead start from a familiar data-oriented <lb/>language and derive its dual fragment by the systematic use of defunctionalization and refunctionalization. <lb/>Our central contribution is a dependently typed calculus which contains two dual language fragments. We <lb/>provide type-and semantics-preserving transformations between these two language fragments: defunction-<lb/>alization and refunctionalization. We have implemented this language and these transformations and use this <lb/>implementation to explain the various ways in which constructions in dependently typed programming can <lb/>be explained as special instances of the general phenomenon of duality. <lb/>CCS Concepts: • Theory of computation → Type theory; • Software and its engineering → Software <lb/>verification; Data types and structures; Classes and objects. <lb/>Additional Key Words and Phrases: Dependent Types, Expression Problem, Defunctionalization, Codata Types <lb/>ACM Reference Format: <lb/>David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann. 2024. Deriving Dependently-Typed OOP <lb/>from First Principles. Proc. ACM Program. Lang. 8, OOPSLA1, Article 129 (April 2024), 27 pages. https://doi. <lb/>org/10.1145/3649846 <lb/></front>
        
        <body>1 INTRODUCTION <lb/>There are many programming paradigms, but dependently typed programming languages almost <lb/>exclusively follow the functional programming model. In this paper, we show why dependently-<lb/>typed programming languages should also include object-oriented principles, and how this can <lb/></body>
        
        <front>Authors&apos; addresses: David Binder, Department of Computer Science, University of Tübingen, Sand 14, Tübingen, 72076, <lb/>Germany, david.binder@uni-tuebingen.de; Ingo Skupin, Department of Computer Science, University of Tübingen, Sand <lb/>14, Tübingen, 72076, Germany, skupin@informatik.uni-tuebingen.de; Tim Süberkrüb, Aleph Alpha Research at IPAI, Gren-<lb/>zhöfer Weg 36, Heidelberg, 69123, Germany, tim.sueberkrueb@aleph-alpha-ip.ai; Klaus Ostermann, Department of Com-<lb/>puter Science, University of Tübingen, Sand 14, Tübingen, 72076, Germany, klaus.ostermann@uni-tuebingen.de. <lb/>© 2024 Copyright held by the owner/author(s). <lb/>ACM 2475-1421/2024/4-ART129 <lb/>https://doi.org/10.1145/3649846 <lb/>Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/>This work is licensed under a Creative Commons Attribution 4.0 International License. <lb/></front>
        
        <page>129:2 <lb/></page>
        
        <note place="headnote">David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann <lb/></note>
        
        <body>be done. One of the main reasons why object-oriented features should be included is a conse-<lb/>quence of how the complexity of the domain is modeled in the functional and object-oriented <lb/>paradigm. Functional programmers structure the domain using data types defined by their con-<lb/>structors, whereas object-oriented programmers structure the domain using classes and interfaces <lb/>defined by methods. This choice has important implications for the extensibility properties of large <lb/>programs, which are only more accentuated for dependently typed programs. <lb/>Why do most dependently typed languages follow the functional style? One of the main reasons <lb/>is that dependent type theories, on which a lot of them are based, are best studied for functional <lb/>programming languages. Our challenge, then, is to develop a dependently-typed object-oriented <lb/>calculus that can serve as the foundation for object-oriented dependently-typed programming lan-<lb/>guages. Instead of specifying this calculus in an ad-hoc fashion, we want to use de-and refunction-<lb/>alization as systematic tools to derive an object-oriented language fragment from its functional <lb/>counterpart. We want to show how object-oriented programming is dual to functional program-<lb/>ming, that this duality extends from non-dependent programming languages to dependently typed <lb/>programming languages, and that we can use this duality to derive our calculus. <lb/>1.1 Data and Codata: The Essence of Functional and Object-Oriented Programming <lb/>How can functional programming (FP) and object-oriented programming (OOP) be dual, if there is <lb/>no precise definition of these two paradigms? We have to define what we mean by functional and <lb/>object-oriented programming if we want to get a precise research question. For the purposes of this <lb/>paper, and other reasonable definitions notwithstanding, we focus on the differences in program <lb/>decomposition between the two paradigms. 1 For us, the essence of functional programming is pro-<lb/>gramming with algebraic data types and pattern matching, whereas the essence of object-oriented <lb/>programming is programming against interfaces, which correspond to the type-theoretic concept <lb/>of codata and copattern matching. This definition is not novel but follows similar observations by <lb/>Cook [1990, 2009] and Downen et al. [2019]. A potentially confusing but important aspect of this <lb/>definition is that first-class functions are in the object-oriented space, since they are a particular <lb/>form of codata (and is a particular form of copattern matching). In the rest of this subsection, we <lb/>elaborate on this definition. <lb/>Let us verify first that this definition captures the essence of FP. An essential part of the pro-<lb/>gramming experience in statically typed functional languages like OCaml, Scala, Haskell or SML, <lb/>but also proof assistants like Coq, Agda, Idris and Lean, is modeling the domain with algebraic data <lb/>types. Algebraic data types consist of product types like structs and records, sum types and enums, <lb/>and recursive types like lists, which together form the essential vocabulary with which program-<lb/>mers in those languages express themselves. The dependently typed languages in this list extend <lb/>this vocabulary by allowing data types to be indexed; the vector type, for example, is indexed over <lb/>the number of its elements. <lb/>That OOP can be identified with codata types is less obvious, so we will introduce them with a <lb/>bit more detail. Data types and codata types differ in how they are defined: Whereas a data type <lb/>is defined by its constructors, i.e. all the ways in which terms of that type can be constructed, a <lb/>codata type is defined by all the ways it can be observed. One type which is defined by its two <lb/>canonical observations is the type of infinite streams. We can either observe the head of a stream, <lb/>yielding one element, or we can observe the tail, yielding a new stream. Equivalently, we can say <lb/>that every stream has to implement the stream interface which requires a head and a tail method. <lb/></body>
        
        <note place="footnote">1 Such a definition necessarily reduces the differences between the two paradigms to only one aspect, but this reduction is <lb/>hopefully also illuminating. Focusing on another difference, and, for example, analyzing how subtyping can influence the <lb/>design of dependently typed programming language would be another interesting research question. <lb/></note>
		<note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <note place="headnote">Deriving Dependently-Typed OOP from First Principles <lb/></note>
        
        <page>129:3 <lb/></page>
        
        <body>Instead of this object-oriented terminology, we use the type-theoretic jargon and the following <lb/>syntax for defining the type of streams: <lb/>codata Stream(a: Type) { <lb/>Stream(a).head(a: Type): a, <lb/>Stream(a).tail(a: Type): Stream(a) } <lb/>codef Ones: Stream(Nat) { <lb/>head(_) =&gt; S(Z), <lb/>tail(_) =&gt; Ones } <lb/>The right-hand side shows how to construct a stream by implementing the stream interface, i.e. by <lb/>saying how it will behave on the head and the tail observation. This particular stream models an <lb/>infinite sequence of ones. The syntactic construct we use here is called copattern matching [Abel <lb/>et al. 2013] and is the precise dual of pattern matching. <lb/>We mentioned that according to our definition of FP and OOP, first-class functions counter-<lb/>intuitively belong to the object-oriented space, so let us substantiate that claim. Programmers in <lb/>functional programming languages can define many types, but they usually cannot define the func-<lb/>tion type. Functions can be defined, however, using codata types: A function is just an object which <lb/>implements an interface with one apply method. For example, functions from natural numbers to <lb/>Booleans, and the constant function which always returns true are defined in the following way: <lb/>codata Fun { ap(x: Nat): Bool } <lb/>codef ConstTrue: Fun { ap(_) =&gt; True } <lb/>The research question that motivated this paper is this: If functional programming can be and <lb/>has been extended to dependent functional programming, can object-oriented programming be <lb/>similarly extended? Codata has been introduced to many proof assistants before, but for an entirely <lb/>different purpose. The purpose was to model certain infinite structures and coinductive objects, not <lb/>to program in an object-oriented style. In this paper, we are interested in this second aspect, and <lb/>we are (to the best of our knowledge) the first ones to discuss this question in detail. To approach <lb/>this question in a principled way, we need an additional technical tool, defunctionalization and <lb/>refunctionalization, which we introduce in the next section. <lb/>1.2 De-and Refunctionalization: A Tool for Systematic Language Design <lb/>Now that we have introduced two alternative programming paradigms, let us look at how one <lb/>paradigm can express programs in the other paradigm. One way in which object-oriented pro-<lb/>grammers have often represented the functional style is with the visitor pattern [Gamma et al. <lb/>1995]. Later, Downen et al. [2019] showed how the visitor pattern can be used as a compilation <lb/>technique for data and codata types; using the visitor pattern, they can compile functional pro-<lb/>grams to object-oriented programs, and using a related tabulation technique they can compile <lb/>object-oriented programs to functional ones. In this paper, we use an alternative technique: de-<lb/>functionalization and refunctionalization. <lb/>Defunctionalization [Danvy and Nielsen 2001; Reynolds 1972] is a whole-program transforma-<lb/>tion which eliminates higher-order functions by replacing lambda abstractions by constructors <lb/>of a data type, together with a top-level apply function. Refunctionalization [Danvy and Millikin <lb/>2009] is its partial inverse, and re-introduces higher-order functions by replacing occurrences of <lb/>the constructors by lambda abstractions. We already observed in the previous section that the <lb/>function type is just one instance of a codata type. Based on this observation, Rendel et al. [2015] <lb/>showed that defunctionalization and refunctionalization can be generalized to arbitrary data and <lb/>codata types, which makes these transformations both more powerful and more symmetric since <lb/>refunctionalization is now a full inverse instead of a partial one. <lb/>Let us look at an example of how these generalized defunctionalization and refunctionalization <lb/>transformations work. In Figure 1a we have defined Booleans as a data type with two construc-<lb/>tors, and negation by pattern matching on True and False. For negation we use syntax familiar <lb/>to object-oriented programmers: negating a boolean can be written as .neg. Refunctionalizing <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <page>129:4 <lb/></page>
        
        <note place="headnote">David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann <lb/></note>
        
        <body>this program results in the program in Figure 1b. In this representation, negation is the single ob-<lb/>servation of a codata type, and True and False are defined as objects implementing this interface. <lb/>data Bool { True, False } <lb/>def Bool.neg: Bool { <lb/>True =&gt; False, <lb/>False =&gt; True } <lb/>(a) Functional programming style. <lb/>codata Bool { neg: Bool } <lb/>codef True: Bool { neg =&gt; False } <lb/>codef False: Bool { neg =&gt; True } <lb/>(b) Object-oriented style. <lb/>Fig. 1. Two representations of the same program. <lb/>One way to visualize how defunctionalization and refunctionalization work is to think of each <lb/>type as a matrix. The two programs of Figure 1, for example, can be represented by the following <lb/>matrix: <lb/>Bool <lb/>True <lb/>False <lb/>neg <lb/>False <lb/>True <lb/>The rows of the matrix enumerate all the ways elements of the type can be consumed, whereas <lb/>the columns enumerate the ways in which elements of the type can be constructed. The cells of <lb/>the matrix specify the result of an interaction between one of each. Data types and codata types <lb/>are then just two different linear presentations of this type-matrix, and defunctionalization and <lb/>refunctionalization transpose the linearization. <lb/>In this paper, we use defunctionalization and refunctionalization not as a compilation technique, <lb/>but as a tool for systematic language design. These transformations are only total in a language <lb/>where the data and codata fragments of the language are equally expressive. We can therefore <lb/>use them to systematically derive the codata fragment of an object-oriented dependently-typed <lb/>language by starting from a familiar design for dependent data types and pattern matching, and <lb/>refunctionalizing programs in that language. <lb/>1.3 A Minimal Dependently-Typed Example <lb/>Let us now extend the example from the previous section by a simple proof that negation is an <lb/>involution, i.e. that applying negation twice is the identity. We look at this example first from the <lb/>familiar point of view of functional programming, and then from the more unfamiliar point of view <lb/>of dependently-typed object-oriented programming. These two dual presentations are not artifi-<lb/>cially constructed but inter-derived using de-and refunctionalization introduced in the previous <lb/>section. In the accompanying implementation that we provide, each version can be automatically <lb/>transformed into the other presentation at the click of a button. <lb/>In the functional decomposition, shown in Figure 2a, we use the Martin-Löf equality type Eq( : <lb/>Type, <lb/>: ) to express propositional equality. The way we defined the proposition that negating <lb/>a boolean twice is the identity function is interesting. Instead of a dependent function, it is formu-<lb/>lated more directly as an elimination on a named boolean self which yields a proof that self is <lb/>equal to self twice-negated, i.e. self.neg.neg. The proof pattern matches on True and False and <lb/>returns the Refl constructor in each branch. <lb/>data Eq(a: Type, x y: a) { <lb/>Refl(a: Type, x: a): Eq(a, x, x) } <lb/>data Bool { True, False } <lb/>def Bool.neg: Bool { <lb/>True =&gt; False, <lb/>False =&gt; True } <lb/>def (self: Bool).neg_inverse <lb/>: Eq(Bool, self, self.neg.neg) { <lb/>True =&gt; Refl(Bool, True), <lb/>False =&gt; Refl(Bool, False) } <lb/>(a) Functional programming style. <lb/>data Eq(a: Type, x y: a) { <lb/>Refl(a: Type, x: a): Eq(a, x, x) } <lb/>codata Bool { <lb/>neg: Bool, <lb/>(self: Bool).neg_inverse <lb/>: Eq(Bool, self, self.neg.neg) } <lb/>codef True: Bool { <lb/>neg =&gt; False, <lb/>neg_inverse =&gt; Refl(Bool, True) } <lb/>codef False: Bool { <lb/>neg =&gt; True, <lb/>neg_inverse =&gt; Refl(Bool, False) } <lb/>(b) Object-oriented style. <lb/>Fig. 2. Extending Figure 1 with proofs. <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <note place="headnote">Deriving Dependently-Typed OOP from First Principles <lb/></note>
        
        <page>129:5 <lb/></page>
        
        <body>In the object-oriented decomposition, shown in Figure 2b, we have kept the definition of the <lb/>Martin-Löf equality type. The definition of Booleans, on the other hand, has changed dramatically. <lb/>Booleans are now defined via the two observations that we defined in the original program: nega-<lb/>tion and the proof that negating a boolean twice is the identity. Instead of two canonical construc-<lb/>tors True and False we now have two mutually recursive top-level definitions of True and False. <lb/>This means that we are now free to add new Booleans without changing the definition of the type <lb/>Bool, thus we could just add another object and implement the negation operation together with <lb/>a proof of its correctness, i.e. a proof that applying it twice yields the original element. <lb/>Defining objects by interfaces that they have to implement is of course familiar. However, also <lb/>including proofs of correctness in those interfaces, and looking at familiar types like Booleans in <lb/>this flipped representation is novel. In this article, we invite you to follow us on an exploration <lb/>of the duality of these two programming styles and to discover both the expressive power we get <lb/>and the sometimes subtle problems we encounter and the restrictions we have to impose. <lb/>Fig. 3. Screenshot of the online IDE available at polarity-lang.github.io/oopsla24. <lb/>1.4 Overview <lb/>The remainder of this article is structured as follows: <lb/>• Building on our minimal example, we present dependently typed object-oriented program-<lb/>ming in Section 2. Our language consists of two fragments, a functional/data-oriented frag-<lb/>ment and an object-oriented/codata fragment, and the specification of these two fragments <lb/>is dictated by the requirement that defunctionalization and refunctionalization are total and <lb/>semantic-preserving transformations. <lb/>• In Section 3 we evaluate the expressive power and the extensibility properties of our system <lb/>using a case study of a dependently typed web server. Furthermore, in the artifact Binder <lb/>et al. [2024a] which accompanies this article, we evaluate our design and implementation <lb/>by a formalization of type preservation for a simple expression language respectively full <lb/>type soundness of the simply typed lambda calculus. Since we have an available online im-<lb/>plementation, the reader can choose to flip any of the involved types from the data to the <lb/>codata representation, and vice-versa, and observe the resulting program. <lb/>• In Section 4 we discuss the constraints on the design of the type system that we had to <lb/>observe because we want our system to be closed under de-and refunctionalization. For <lb/>each such constraint, we discuss both the problem and the solution that we have chosen for <lb/>our formalization. <lb/>• In Sections 5 and 6 we present all the formal details. We specify a declarative formaliza-<lb/>tion in the style of Martin-Löf in Section 5 and the details of the defunctionalization and <lb/>refunctionalization algorithms in Section 6. <lb/>• We discuss future work in Section 7, related work in Section 8 and conclude in Section 9. <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <page>129:6 <lb/></page>
        
        <note place="headnote">David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann <lb/></note>
        
        <body>We have implemented the language, and the defunctionalization and refunctionalization algo-<lb/>rithms presented in this paper. We make an IDE available in the browser (cf. Figure 3) which <lb/>supports the defunctionalization and refunctionalization transformations as code actions using <lb/>the language server protocol (LSP). <lb/>2 DEPENDENTLY-TYPED OBJECT-ORIENTED PROGRAMMING <lb/>Typical programs written in object-oriented and functional languages have many differences. We <lb/>will now look at how these differences appear when we consider programs written in the object-<lb/>oriented style. <lb/>2.1 Method Call Syntax and Self Parameters <lb/>import Agda.Builtin.Equality <lb/>open Agda.Builtin.Equality <lb/>data Bool : Set where <lb/>true : Bool <lb/>false : Bool <lb/>neg : Bool -&gt; Bool <lb/>neg true = false <lb/>neg false = true <lb/>neg_inverse <lb/>: (x : Bool) -&gt; x ≡ neg (neg x) <lb/>neg_inverse true = refl <lb/>neg_inverse false = refl <lb/>Fig. 4. Proving that negation is <lb/>an involution in Agda. <lb/>Object-oriented programmers are familiar with the method call syn-<lb/>tax .f( ) to invoke a method f taking an argument on an object <lb/>. This is sometimes presented under the name &quot;uniform function <lb/>call syntax&quot; as an alternative notation for the call f( , ), where the <lb/>first argument of the method f is called the self parameter. We take <lb/>this simple syntactic observation, see how we have to modify it to <lb/>the dependently typed setting, and how this influenced our design <lb/>of codata types. <lb/>As a starting point, we take the Agda proof from Figure 4. In that <lb/>proof, the Booleans are defined as a datatype, negation is defined <lb/>as a non-dependent function from Booleans to Booleans, and neg_-<lb/>inverse is defined as a dependent function from a boolean to a <lb/>proof that is equal to neg(neg ). In our system, we want to ex-<lb/>press both neg and neg_inverse without using non-dependent or <lb/>dependent functions. For the non-dependent case, we can express negation directly as an observa-<lb/>tion on Booleans: <lb/>def Bool.neg: Bool { <lb/>True =&gt; False, <lb/>False =&gt; True } <lb/>If we want to express the dependent function neg_inverse as an observation on Booleans in a <lb/>similar way, then we have to add a feature, self parameters. We can bind the term that we observe to <lb/>a variable, which we have here called self, and use this variable in the return type of the observation: <lb/>def (self: Bool).neg_inverse: Eq(Bool, self, self.neg.neg) { <lb/>True =&gt; Refl(Bool, True), <lb/>False =&gt; Refl(Bool, False) } <lb/>The refunctionalization of these methods with self-parameters dictates the first feature of de-<lb/>pendent codata types: self-parameters in destructors. <lb/>codata Bool { neg: Bool, (self: Bool).neg_inverse: Eq(Bool, self, self.neg.neg) } <lb/>It is self-parameters in codata declarations which give us the expressive power to properly rep-<lb/>resent verified interfaces and classes in an object-oriented style. <lb/>2.2 Verified Interfaces and Classes <lb/>When verifying data structures and algorithms in dependently typed languages, we can choose <lb/>between two general approaches: intrinsic and extrinsic verification. Using intrinsic verification, <lb/>we define the data structure or algorithm together with its correctness proofs. To intrinsically <lb/>verify data structures, we commonly express properties using type indices, such as the number <lb/>of elements contained in a length-indexed list. We can employ a similar approach in an object-<lb/>oriented style using indexed codata types [Thibodeau et al. 2016]. Using type indices, we can ensure <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <note place="headnote">Deriving Dependently-Typed OOP from First Principles <lb/></note>
        
        <page>129:7 <lb/></page>
        
        <body>class spec: PR <lb/>public methods: <lb/>store: X × A → X <lb/>read: X → {error} + A <lb/>empty: X → X <lb/>assertions: <lb/>s.empty.read = error <lb/>s.read = error <lb/>⊢ s.store(a).read = a <lb/>s.read = a <lb/>⊢ s.store(b).read = a <lb/>creation: <lb/>new.read = error <lb/>end class spec <lb/>(a) Original specification <lb/>codata PR { <lb/>store(a: A): PR, <lb/>read: MaybeA, <lb/>empty: PR, <lb/>--| Reading from the empty buffer yields an error <lb/>(s: PR).assert_empty: Eq(MaybeA, s.empty.read, Error), <lb/>--| We can store an element into an empty buffer <lb/>(s: PR).assert_empty_store(a: A) <lb/>: Eq(MaybeA, s.read, Error) -&gt; Eq(MaybeA, s.store(a).read, Just(a)), <lb/>--| We cannot replace the element in the buffer without calling `empty( <lb/>s: PR).assert_persistent(a b: A) <lb/>: Eq(MaybeA, s.read, Just(a)) -&gt; Eq(MaybeA, s.store(b).read, Just(a)) } <lb/>(b) Implementation in our system. <lb/>Fig. 5. Persistent read (PR) specification for one-element buffers from Jacobs [1995]. <lb/>that observations are called only on objects which are in the right state. This can be seen in the <lb/>following example, where the observation read may be called only on non-empty buffers: 2 <lb/>codata Buffer(m: Nat) { <lb/>Buffer(S(n)).read(n: Nat): Pair(Bool, Buffer(n)) } <lb/>codef EmptyBuffer: Buffer(Z) { read(n) absurd } <lb/>codef Singleton(b: Bool): Buffer(S(Z)) { read(n) =&gt; MkPair(Bool, Buffer(Z), b, EmptyBuffer) } <lb/>We can see that, as usual for dependent (co)pattern matching, infeasible pattern matches may <lb/>arise which need to be marked as absurd. That is, when we implement the buffer interface for the <lb/>empty buffer we don&apos;t have to implement the read method since it can never be called. <lb/>However, in this work, we go beyond indexed codata types, which admit an intrinsic verification <lb/>style. We also want to support the extrinsic approach, where we want to separate our objects from <lb/>their specifications. Jacobs [1995] provides us with an initial concept of how to attain that goal. He <lb/>proposes a system of coalgebraic specifications that can be used to verify object-oriented classes. <lb/>As an example, Figure 5a shows a coalgebraic specification for a one-element buffer that exhibits <lb/>persistent read (PR) behavior: After an element has been stored, it cannot be replaced using the <lb/>store method. Instead, one needs to call the method empty to explicitly empty the buffer. Reading <lb/>from the empty buffer returns an error. This specification of the buffer is given as a set of assertions <lb/>that reference the buffer state s. <lb/>In our system, we can realize this concept using self-parameters on destructors, allowing us <lb/>to express specifications as observations on codata types. The codata type in Figure 5 defines the <lb/>verified interface for persistent read buffers in our system. Similarly, we can apply this approach <lb/>to express verified interfaces such as functors or monads. <lb/>2.3 Dependent Functions <lb/>Unlike in most other dependent type theories, the Π-type of dependent functions is not part of our <lb/>core theory, but can be defined in a library. The Π-type is defined as a codata type indexed over a <lb/>type family p, for which we use the ordinary non-dependent function type. The notation a -&gt; b <lb/>used in the definition of dependent functions is just syntactic sugar for Fun(a,b). <lb/>--| Non-dependent Functions <lb/>codata Fun(a b: Type) { <lb/>Fun(a, b).ap(a b: Type, x: a): b } <lb/>--| Dependent Functions <lb/>codata Π(a: Type, p: a -&gt; Type) { <lb/>Π(a, p).dap(a: Type, p: a -&gt; Type, x: a): p.ap(a, Type, x) } <lb/></body>
        
        <note place="footnote">2 Note that the parameter occurs bound in the type Buffer(S(n)) on which we can call the observation read, and is <lb/>bound in the argument list read(n: Nat). <lb/></note>
		<note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <page>129:8 <lb/></page>
        
        <note place="headnote">David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann <lb/></note>
        
        <body>We propose that both dependent and non-dependent functions should be user-defined instead <lb/>of built-in. The designers of Java decided to follow this approach when they introduced lambda <lb/>abstractions as instances of functional interfaces [Goetz et al. 2014; Setzer 2003] in Java 8. This <lb/>shows that our proposal is not radical, and we think it is also useful. Apart from reducing the <lb/>complexity of the core language, they simplify the situation if we have more than one function <lb/>type. This is the case in substructural systems where we have linear and non-linear functions. For <lb/>instance, in the Rust programming language, there are three different built-in function traits Fn, <lb/>FnOnce, and FnMut, which differ in the modality of the receiver 3 . <lb/>2.4 Weak and Strong Dependent Pairs <lb/>In the previous section we showed how to define the Π-type. For the Π-type we had no choice but <lb/>to define it as a codata type 4 , but for the Σ-type we can choose whether to model it as a data or <lb/>codata type. This choice distinguishes weak and strong Σ-types [Howard 1980]: Strong Σ-types are <lb/>defined as a codata type with two projections, where the second projection mentions the result of <lb/>the first projection in its return type; weak Σ-types, by contrast, are defined as a data type with <lb/>one constructor which pairs the first and second element. This difference is more obvious if we <lb/>first consider the case of non-dependent pairs, which can also be written as either a data or codata <lb/>type. <lb/>data ×₊(A B: Type) { <lb/>Pair(A B: Type, x: A, y: B): ×₊(A, B) } <lb/>def ×₊(A, B).π₁(A B: Type): A { <lb/>Pair(_, _, x, y) =&gt; x } <lb/>def ×₊(A, B).π₂(A B: Type): B { <lb/>Pair(_, _, x, y) =&gt; y } <lb/>codata ×₋(A B: Type) { <lb/>×₋(A, B).π₁(A B: Type): A, <lb/>×₋(A, B).π₂(A B: Type): B } <lb/>codef Pair(A B: Type, x: A, y: B): ×₋(A, B) { <lb/>π₁(_, _) =&gt; x, <lb/>π₂(_, _) =&gt; y } <lb/>These two representations can be obtained from each other by defunctionalization and refunction-<lb/>alization. This is still the case when we generalize non-dependent pairs to the Σ-type. Similar to <lb/>the Π-type in Section 2.3, the Σ-type is indexed by a type family . As a data type, it is defined by <lb/>one constructor Pair which takes the type family , an element of type and a witness as ar-<lb/>guments. As a codata type, we still have two projections 1 and 2 as in the case of non-dependent <lb/>pairs. But the second projection now uses the self-parameter to guarantee that an element of type <lb/>applied to self . 1 is returned. <lb/>data Σ₊(A: Type, T: A -&gt; Type) { <lb/>Pair(A: Type, <lb/>T: A -&gt; Type, <lb/>x: A, <lb/>w: T.ap(A, Type, x) ) <lb/>: Σ₊(A, T) } <lb/>def Σ₊(A, T).π₁(A: Type, T: A -&gt; Type): A { <lb/>Pair(A, T, x, w) =&gt; x } <lb/>def (self: Σ₊(A, T)).π₂(A: Type, T: A -&gt; Type) <lb/>: T.ap(A, Type, self.π₁(A, T)) { <lb/>Pair(A, T, x, w) =&gt; w } <lb/>codata Σ₋(A: Type, T: A -&gt; Type) { <lb/>Σ₋(A, T).π₁(A: Type, T: A -&gt; Type): A, <lb/>(self: Σ₋(A, T)).π₂(A: Type, T: A -&gt; Type) <lb/>: T.ap(A, Type, self.π₁(A, T)) } <lb/>codef Pair(A: Type, <lb/>T: A -&gt; Type, <lb/>x: A, <lb/>w: T.ap(A, Type, x) ) <lb/>: Σ₋(A, T) { <lb/>π₁(A, T) =&gt; x, <lb/>π₂(A, T) =&gt; w } <lb/>In fact, Agda can already represent Σ-types in both of these ways. But there is one caveat: Agda <lb/>was not originally designed with codata types in mind, and its codata types are implemented on <lb/>top of dependent records, which limits what kind of codata types are possible. For example, the <lb/>order of the destructors in a codata type matter for Agda, so we cannot reorder the first and second <lb/>projection. In our system the destructors of a codata type are not ordered and can mutually refer <lb/>to each other, which precisely mirrors how definitions are mutually recursive on the toplevel. <lb/></body>
        
        <note place="footnote">3 See the Rust standard library documentation on operators: doc.rust-lang.org/std/ops/index.html. <lb/>4 If we want to define the function type as a data type, then we have to use a system with higher-level inference rules, <lb/>cf. Garner [2009]. <lb/></note>
		<note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <note place="headnote">Deriving Dependently-Typed OOP from First Principles <lb/></note>
        
        <page>129:9 <lb/></page>
        
        <body>But why should we care about these two alternative encodings of the Σ-type? Take, for example, <lb/>Eisenberg et al. [2021] who discuss the addition of existential types to Haskell. Since Haskell both <lb/>is lazy and supports type erasure, Eisenberg et al. are driven to a design that uses strong existential <lb/>types. We think that by using the framework of data and codata types we can make these kind of <lb/>differences even clearer. <lb/>2.5 Codata Encodings of Natural Numbers <lb/>Starting with the inception of the lambda calculus, researchers have been interested in functional <lb/>encodings of data types such as booleans, natural numbers and lists. Classical examples of func-<lb/>tional encodings are the Church, Scott and Parigot encodings of data types (cf. Geuvers [2014]; <lb/>Koopman et al. [2014]). Functions are from our perspective just one particular instance of a codata <lb/>type, so we are interested in the more general problem of codata encodings instead of functional <lb/>encodings. Most codata encodings of data types can be obtained by refunctionalizing a data type <lb/>with an appropriate observation. That the Church encoding can be obtained from refunctionalizing <lb/>a program with Peano numbers and an iter function has already been observed by Ostermann <lb/>and Jabs [2018]; we restate this example in Figure 6. <lb/>data Nat { Z, S(p: Nat) } <lb/>def Nat.iter(A: Type, z: A, s: A -&gt; A): A { <lb/>Z =&gt; z, <lb/>S(p) =&gt; s.ap(A, A, p.iter(A, z, s)) } <lb/>(a) Data variant <lb/>codata Nat { iter(A: Type, z: A, s: A -&gt; A): A } <lb/>codef S(p: Nat): Nat { <lb/>iter(A, z, s) =&gt; s.ap(A, A, p.iter(A, z, s)) } <lb/>codef Z: Nat { iter(A, z, s) =&gt; z } <lb/>(b) Codata variant <lb/>Fig. 6. The Church encoding as a refunctionalized program on Peano numbers. <lb/>We can observe that the codata type in Figure 6b which represents the Church encoding of <lb/>natural numbers is not recursive. This corresponds to the well-known theorem that Church encod-<lb/>ings can be typed in pure system F. If we apply the same method to obtain the Scott or Parigot <lb/>encoding of natural numbers, then we can observe that the resulting codata type is recursive. This <lb/>corresponds to the other well-known theorem that these encodings can not be typed in pure Sys-<lb/>tem F and require recursive types. <lb/>We can even go one step further. Geuvers [2001] showed that these previous encodings cannot <lb/>express induction or dependent elimination. One way to obtain typed functional encodings which <lb/>can express induction is to add a form of self types to the system; this kind of encoding was <lb/>introduced by Fu and Stump [2014]. While it is hard to prove an exact correspondence, we think <lb/>that the essential idea of the encoding of Fu and Stump can be expressed in our system in Figure 7 <lb/>and Figure 8. <lb/>codef StepFun(P: Nat -&gt; Type): Fun(Nat, Type) { <lb/>ap(_, _, x) =&gt; P.ap(Nat, Type, x) -&gt; P.ap(Nat, Type, S(x)) } <lb/>data Nat { S(m: Nat), Z } <lb/>def (n: Nat).ind(P: Nat -&gt; Type, base: P.ap(Nat, Type, Z), step: Π(Nat, StepFun(P))) <lb/>: P.ap(Nat, Type, n) { <lb/>S(m) =&gt; <lb/>step.dap(Nat, StepFun(P), m) <lb/>.ap(P.ap(Nat, Type, m), P.ap(Nat, Type, S(m)), m.ind(P, base, step)), <lb/>Z =&gt; base } <lb/>Fig. 7. The data type of natural numbers with an induction principle. <lb/>In Figure 7 we have encoded induction using a helper codata type StepFun which encodes the <lb/>induction step for a given predicate on natural numbers. Induction is then expressed as the <lb/>observation ind on a natural number which expects the base case and the induction step of the <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <page>129:10 <lb/></page>
        
        <note place="headnote">David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann <lb/></note>
        
        <body>induction as arguments. The argument on which we define the observation occurs itself in the <lb/>return type. Refunctionalization of this program results in Figure 8. <lb/>codef StepFun(P: Nat -&gt; Type): Fun(Nat, Type) { <lb/>ap(_, _, x) =&gt; P.ap(Nat, Type, x) -&gt; P.ap(Nat, Type, S(x)) } <lb/>codata Nat { <lb/>(n: Nat).ind(P: Nat -&gt; Type, base: P.ap(Nat, Type, Z), step: Π(Nat, StepFun(P))) <lb/>: P.ap(Nat, Type, n) } <lb/>codef Z: Nat { ind(P, base, step) =&gt; base } <lb/>codef S(m: Nat): Nat { <lb/>ind(P, base, step) =&gt; <lb/>step.dap(Nat, StepFun(P), m) <lb/>.ap(P.ap(Nat, Type, m), P.ap(Nat, Type, S(m)), m.ind(P, base, step)) } <lb/>Fig. 8. The encoding of Fu and Stump can be obtained by refunctionalizing the program in Figure 7. <lb/>We think that this is further evidence that the self-parameters we introduced to the system occur <lb/>naturally when we go from the non-dependent to the dependent setting. <lb/>3 CASE STUDY <lb/>We will now further illustrate the benefits of dependently typed object-oriented programming <lb/>in a small case study. For this, we create a mockup of a dependently typed web server. We will <lb/>observe that we can conveniently extend both the supported routes of the web server and the <lb/>supported methods to access these routes. We will also see how we can conveniently state and <lb/>enforce properties in intrinsic as well as in extrinsic style. <lb/>3.1 A Functional Web Server <lb/>We start in the familiar realm of functional programming. For the purpose of this demonstration, <lb/>we will create a simple web server that allows all users to read, but only authenticated users to <lb/>increment a counter. For this, we track user sessions using the State type shown below. As an <lb/>instance of intrinsic verification, we track on the type level whether the user is authenticated. <lb/>Possible responses from the server are specified by the Response type. <lb/>codata User { hasCredentials: Bool } <lb/>codata State(loggedIn: Bool) { <lb/>State(False).login(u: User): State(u.hasCredentials), <lb/>State(True).logout: State(False), <lb/>State(True).increment: State(True), <lb/>State(True).set(n: Nat): State(True), <lb/>State(b).counter(b: Bool): Nat } <lb/>data Response { Forbidden, Return(n: Nat) } <lb/>Our web server should accept a couple of HTTP request methods (get, post, …) for a set of <lb/>routes (Index, Admin, …). <lb/>data Route { Index } <lb/>def Route.requiresLogin: Bool { Index =&gt; False } <lb/>def (self: Route).get: State(self.requiresLogin) -&gt; Response { <lb/>Index =&gt; \state. Return(state.counter(False)) } <lb/>Adding support for a new request method is as simple as adding a function. For instance, we want <lb/>to handle post requests, even though we forbid them for the Index route: <lb/>def (self: Route).post: State(self.requiresLogin) -&gt; ×₋(State(self.requiresLogin), Response) { <lb/>Index =&gt; <lb/>\state. comatch { <lb/>fst(a, b) =&gt; state, <lb/>snd(a, b) =&gt; Forbidden } } <lb/>3.2 Adding New Routes in Object-Oriented Style <lb/>While adding new methods is a local change, adding a new route in the functional representation <lb/>requires touching all pattern matches on Route in the program. Therefore, before adding a route <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <note place="headnote">Deriving Dependently-Typed OOP from First Principles <lb/></note>
        
        <page>129:11 <lb/></page>
        
        <body>to increment the counter on a POST request, let us refunctionalize Route to its object-oriented <lb/>decomposition: <lb/>codata Route { <lb/>requiresLogin: Bool, <lb/>(self: Route).get: State(self.requiresLogin) -&gt; Response, <lb/>(self: Route).post: State(self.requiresLogin) -&gt; ×₋(State(self.requiresLogin), Response) } <lb/>codef Index: Route { <lb/>requiresLogin =&gt; False, <lb/>get =&gt; \state. Return(state.counter(False)), <lb/>post =&gt; <lb/>\state. comatch { <lb/>fst(a, b) =&gt; state, <lb/>snd(a, b) =&gt; Forbidden } } <lb/>In the object-oriented decomposition, adding the following Admin route is now a local change. Note <lb/>that the rearrangement works both ways: we could transpose the program back into functional <lb/>decomposition to add another method. <lb/>codef Admin: Route { <lb/>requiresLogin =&gt; True, <lb/>post =&gt; <lb/>\state. comatch { <lb/>fst(a, b) =&gt; state.increment, <lb/>snd(a, b) =&gt; Return(state.increment.counter(True)) }, <lb/>get =&gt; \state. Return(state.counter(True)) } <lb/>Similar problems of modularity appear in many applications. Functional languages force us to <lb/>always choose the same extensibility dimension for every type: We can extend data types with new <lb/>observations, but we cannot easily extend types with new constructors. If the programming lan-<lb/>guage would support both programming paradigms equally well, this choice would not be forced <lb/>on the programmer by the language, but the programmer would have the choice for each type. <lb/>3.3 Verifying Properties on Routes <lb/>In addition to the ability to increment the counter by sending a POST request to the Admin route, we <lb/>may also want to allow explicitly setting a counter value. Updating the counter to a value should <lb/>be idempotent, i.e. calling the route more than once should have the same effect. The HTTP PUT <lb/>method is supposed to capture this behavior, but how can we enforce it in our code? This leads us <lb/>to another benefit of the object-oriented style in that we can express such properties extrinsically <lb/>but still as part of the interface (compare 2.2): <lb/>data Utils { MkUtils } <lb/>def Utils.put_twice(route: Route, request: Request, state: State): Pair(State, Response) { <lb/>MkUtils =&gt; route.put(request, route.put(request, state).fst(State, Response)) } <lb/>codata Route { <lb/>(self: Route).put(request: Request, state: State): Pair(State, Response), <lb/>(self: Route).put_idempotent(request: Request, state: State) <lb/>: Eq(Pair(State, Response), self.put(request, state), MkUtils.put_twice(self, request, state)) } <lb/>The full code of the case study with the added put method is contained in the artifact Binder et al. <lb/>[2024a]. <lb/>4 DESIGN CONSTRAINTS AND SOLUTIONS <lb/>Specifying a consistent set of typing and computation rules for data and codata types is not dif-<lb/>ficult. In this section, we show the difficulties that arise if we also want the rules to be closed <lb/>under defunctionalization and refunctionalization. That is every program that typechecks should <lb/>continue to typecheck if we defunctionalize or refunctionalize any of the types that occur in it. <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <page>129:12 <lb/></page>
        
        <note place="headnote">David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann <lb/></note>
        
        <body>4.1 Judgmental Equality of Comatches <lb/>Problem. For most dependently typed languages, the term . is judgmentally equal to the term <lb/>. , and likewise .2 + 2 and .4 are considered equal. Equating such terms becomes a prob-<lb/>lem, however, if we want to defunctionalize the programs which contain them. Different lambda <lb/>abstractions in a program are defunctionalized to different constructors, which are then no longer <lb/>judgmentally equal. Let us illustrate the problem with an example. <lb/>Consider the following proof that . is the same function from natural numbers to natural <lb/>numbers as . . We prove this fact using a third lambda abstraction . as an argument to the <lb/>reflexivity constructor. <lb/>codata Fun(a b: Type) { Fun(a, b).ap(a b: Type, x: a): b } <lb/>Refl(Fun(Nat, Nat), \x. x) : Eq(Fun(Nat, Nat), \y. y, \z. z) <lb/>If we defunctionalize this program, then each of these three lambda abstractions becomes one <lb/>constructor of the data type. However since different constructors are not judgmentally equal, the <lb/>following defunctionalized program no longer typechecks. <lb/>data Fun(a b: Type) { F1: Fun(Nat, Nat), F2: Fun(Nat, Nat), F3: Fun(Nat, Nat) } <lb/>def Fun(a, b).ap(a b: Type, x: a): b { F1 =&gt; x, F2 =&gt; x, F3 =&gt; x } <lb/>Refl(Fun(Nat, Nat), F1) : Eq(Fun(Nat, Nat), F2, F3) <lb/>Here is the gist of the problem: Judgmental equality must be preserved by defunctionalization and <lb/>refunctionalization. This means that if we don&apos;t want to treat different constructors of a data type <lb/>as judgmentally equal, then we cannot treat all --equivalent comatches as judgmentally equal <lb/>either. <lb/>It is not impossible to devise a scheme which lifts judgmentally equal comatches to the same <lb/>constructors. However, we decided against this as it leads to confusing behavior. First, de-and <lb/>refunctionalization would no longer be inverse transformations at least under syntactic equality. <lb/>Second, such an attempt would necessarily be a conservative approximation as program equiv-<lb/>alence is undecidable in general. In practice, that would mean that some comatches would be <lb/>collapsed to the same constructor during lifting, while others would not. <lb/>Solution. Note that the opposite approach-never equating any comatches-doesn&apos;t work either, <lb/>since typing would then no longer be closed under substitution. For example, if is a variable stand-<lb/>ing for a function from natural numbers to natural numbers, then the term Refl(Fun(Nat, Nat), ) <lb/>is a proof of the proposition Eq(Fun(Nat, Nat), , ). But we could not substitute a comatch . <lb/>for , since the result would no longer typecheck. We therefore have to find a solution between <lb/>these two extremes. <lb/>Our solution consists of always considering local comatches together with a name 5 . Only co-<lb/>matches which have the same name are judgmentally equal, and this equality is preserved by <lb/>reduction since the comatch is duplicated together with its name. <lb/>Where do the names for local comatches come from? We support user-annotated labels, which <lb/>allow the programmer to give meaningful names to comatches. Manually naming comatches in <lb/>this way is useful as these labels can also be used by defunctionalization to name the generated <lb/>constructors. We enforce that these user-annotated labels are globally unique. However, as we do <lb/>not want to burden the user with naming every single comatch in the program, we also allow <lb/>unannotated comatches, for which we automatically generate unique names. As a result, each <lb/>comatch occurring textually in the program has a unique name, but these names possibly become <lb/>duplicated during normalization and typechecking. <lb/></body>
        
        <note place="footnote">5 This solution is similar to Binder et al.&apos;s use of labels for local (co)pattern matches <lb/></note>
		<note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <note place="headnote">Deriving Dependently-Typed OOP from First Principles <lb/></note>
        
        <page>129:13 <lb/></page>
        
        <body>4.2 Eta Equality <lb/>Problem. For reasons very similar to the previous section, -equality is not preserved under de-<lb/>functionalization and refunctionalization. Let us again consider a simple example. In the following <lb/>proof, we show that a function is equal to its -expanded form . .ap( ). In order to typecheck, <lb/>the proof would need to use a judgmental -equality for functions. <lb/>codata Fun { ap(x: Nat): Nat } <lb/>let prop_eta(f: Fun): Eq(Fun, f, (\x. f.ap(x))) = Refl(Fun, f); <lb/>However, defunctionalization of this proof would result in the following program, where we have <lb/>used an ellipsis to mark all the constructors that were generated for the other lambda abstractions <lb/>in the program. <lb/>data Fun { Eta(f: Fun), … } <lb/>def Fun.ap(x: Nat): Nat { Eta(f) =&gt; f.ap(x),… } <lb/>let prop_eta(f: Fun): Eq(Fun, f, Eta(f)) = Refl(Fun, f); <lb/>Using prop_eta it would now be possible to show that any constructor f of Fun is equal to Eta(f). <lb/>This would contradict the provable proposition that distinct constructors are not equal. <lb/>Solution. We do not support -equality in our formalization and implementation. This means <lb/>that we only normalize -redexes but not -redexes during typechecking. However, it would be <lb/>possible to support judgmental -equality on a case-by-case basis similar to the eta-equality and <lb/>no-eta-equality keywords in Agda which enable or disable eta-equality for a specific record <lb/>type 6 . De-and refunctionalization is then only available for types without -equality. <lb/>5 FORMALIZATION <lb/>In this section, we present the syntax, typing rules and operational semantics of our system. We <lb/>divide this presentation into three subsections: In Section 5.1, we introduce the core of our system. <lb/>We extend this core calculus by data types and pattern matching definitions in Section 5.2, and by <lb/>codata types and copattern matching definitions in Section 5.3. <lb/>We do not formalize local pattern and copattern matches. Instead, local pattern and copattern <lb/>matches are lifted to the top level before applying de-or refunctionalization, similar to the ap-<lb/>proach taken by Binder et al. [2019]. Some care must be taken to ensure that we close over all <lb/>required terms, as the types of terms which are part of the closure might close over additional <lb/>terms. For example, closing over v: Vec n requires us to also close over n. The main challenge for <lb/>local pattern and copattern matches revolves around judgmental equality, which we discussed in <lb/>Section 4.1. <lb/>5.1 Core System <lb/>In Figure 9 we define the syntax of our core system together with small examples in the rightmost <lb/>column. <lb/>Following standard convention, we formalize our system up to -renaming of bound variables <lb/>x, y, z. We distinguish between contexts Γ, Δ and telescopes Ξ, Ψ. Contexts track the types of free <lb/>variables and must always be closed. Telescopes are dependent parameter lists whose types may <lb/>contain free variables bound in a context. If a telescope is closed, we may implicitly use it as a <lb/>context. A substitution , is an argument list to a telescope. A program Θ is a list of declarations <lb/>, which are empty for now. There are five different kinds of expressions , , : Variables are de-<lb/>noted as described above. We denote the type universe as Type. Type constructors T instantiate a <lb/>(co)data type with a substitution . Calling a producer C is written C ; invoking a consumer d uses <lb/>the syntax .d . The producer syntax denotes constructor calls for data types and codefinition calls <lb/></body>
        
        <note place="footnote">6 Compare the section on record types in the Agda user manual: agda.readthedocs.io/en/v2.6.3/language/record-types.html. <lb/></note>
		<note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <page>129:14 <lb/></page>
        
        <note place="headnote">David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann <lb/></note>
        
        <body>T <lb/>∈ TypeNames <lb/>Type names Bool, Vec, Stream <lb/>C <lb/>∈ PRoduceRNames <lb/>Producer names True, Cons <lb/>d <lb/>∈ ConsumeRNames <lb/>Consumer names neg, neg_inverse <lb/>x, y, z ∈ VaRiables <lb/>Variables <lb/>(empty in core system) <lb/>Declaration <lb/>Θ <lb/>∅ | , Θ <lb/>Program <lb/>Γ, Δ <lb/>∅ | Γ, x : <lb/>Context x : Nat, v : Vec(Bool, x) <lb/>Ξ, Ψ <lb/>∅ | x : , Ξ <lb/>Telescope x : Nat, v : Vec(Bool, x) <lb/>, <lb/>() | ( , ) <lb/>Substitution (Bool, S(Z)) <lb/>, , <lb/>x <lb/>Variable <lb/>| Type <lb/>Universe <lb/>| T <lb/>Type Bool, Vec(Bool, S(Z)) <lb/>| C <lb/>Producer S(Z) <lb/>| <lb/>.d <lb/>Consumer x.neg <lb/>Fig. 9. Syntax of core system without data or codata types. <lb/>for codata types. The consumer syntax denotes destructor invocations for codata and definition <lb/>calls for data types. <lb/>For formalizing the core system, we closely follow the presentation by Hofmann [1997]. The <lb/>rules for contexts, telescopes, and substitutions are standard, we omit them here for space <lb/>reasons. We will use the judgment forms ⊢ Θ Γ ctx and Γ ⊢ Θ Ξ tel to specify valid contexts and <lb/>telescopes, respectively. The judgment form Γ ⊢ Θ : Ξ states that is a valid substitution for the <lb/>telescope Ξ under context Γ. <lb/>We also assume the Type-in-Type axiom, which is well-known to be inconsistent [Girard 1972; <lb/>Hurkens 1995]. In this work, we do not enforce termination or productivity in our system. As <lb/>adding the Type-in-Type axiom merely yields another source of possible divergence [Tennant <lb/>1982], we do not gain anything from avoiding this paradox, e.g. by using a hierarchy of universes. <lb/>We therefore follow Eisenberg [2016] and opt for a simpler presentation using the Type-in-Type <lb/>axiom. <lb/>5.2 Data Types and Dependent Pattern Matching <lb/>We now extend the declarations of Figure 9 by two new constructs: data type declarations and <lb/>pattern matching definitions. Data type declarations introduce a new data type together with a list <lb/>of constructors, and pattern matching definitions introduce a top-level consumer which is defined <lb/>by a list of clauses. The corresponding new typing and well-formedness rules are contained in the <lb/>upper half of Figure 10. <lb/>. . . <lb/>Extends Figure 9 <lb/>| data TΨ { CΞ : T } <lb/>Data Type data Bool { True : Bool, . . . } <lb/>| def (z : T ).dΞ : { } <lb/>Pattern Match def (x : Bool).neg : Bool { . . . } <lb/>C Ξ ↦ → <lb/>Match case S(x : Nat) ↦ → x <lb/>| C Ξ absurd <lb/>Absurd case Nil (a : Type) absurd <lb/>A data type declaration data TΨ { CΞ : T } introduces one type constructor T and a list of term <lb/>constructors C to the rest of the program. The type constructor T is indexed by a telescope Ψ, <lb/>and if we provide a substitution for this telescope, then the formation rule F-Data allows us <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <note place="headnote">Deriving Dependently-Typed OOP from First Principles <lb/></note>
        
        <page>129:15 <lb/></page>
        
        <body>to form the type T . Each term constructor is declared with parameters Ξ and a type T which <lb/>specifies how the term constructor instantiates the indices of the type constructor. We can use a <lb/>term constructor with the introduction rule I-Data, where the resulting type depends on both the <lb/>arguments to which the term constructor is applied and the substitution from the constructor <lb/>declaration. We check that a data type declaration is well-formed with the help of the rule Data: <lb/>For the type constructor T we check that the indices Ψ form a valid telescope in the program, and <lb/>for each constructor CΞ : T we check that Ξ is a valid and that is a valid substitution <lb/>for the indices Ψ of the type constructor T under context Ξ. <lb/>The second new construct is pattern matching definitions def (z : T ).dΞ : { } which define <lb/>a new consumer d by a list of cases. The consumer d takes arguments specified by the telescope Ξ, <lb/>and can be called on any term of type T , where the substitution can depend on any arguments <lb/>bound in Ξ. The scrutinee of the consumer can be referred to by the self parameter z in the return <lb/>type of d. We introduced these self-parameters in Section 2.1. The elimination rule E-Data then <lb/>eliminates a term by invoking d with arguments . These arguments are substituted in the return <lb/>type which is defined under the context Ξ; : T . Here, the self parameter is replaced by the <lb/>scrutinee . <lb/>We check whether a pattern matching definition is well-formed with the rule Def. The return <lb/>type is typed under context Ξ; z : T . We implicitly require that there exists exactly one case <lb/>of each constructor C of T, and check that every case is well-formed. For checking the well-<lb/>formedness of cases we use an auxiliary judgment form Ξ ⊢ Θ <lb/>: ( : T ). which tracks the <lb/>self parameter z : T and the return type . There are two variants of pattern matching cases we <lb/>have to consider: possible and absurd cases. In a possible case, we restate the constructor telescope <lb/>Ξ and give an expression that gives the result if the case is matched. An absurd case is determined <lb/>to be impossible by unification and hence does not need an expression. Corresponding to the two <lb/>kinds of cases, possible and absurd, there are two typing rules, Case 1 and Case 2 . In both rules, we <lb/>unify the scrutinee type T 1 with the constructor type T 2 . If there is no such unifier, the case is <lb/>absurd. In a possible case, however, unification yields a unifier . We use this unifier to refine the <lb/>typing of the right-hand side : The unifier is substituted in the context Ξ 1 ; Ξ 2 , expression and <lb/>type . We further refine by replacing the self parameter z with the constructor Cid Ξ 2 where id Ξ 2 <lb/>is the identity context morphism for Ξ 2 . <lb/>Finally, the computation rule ≡-Data allows us to reduce an expression C 1 .d 2 if 1 and 2 are <lb/>valid arguments to the constructor respectively definition. <lb/>5.3 Codata Types and Dependent Copattern Matching <lb/>Finally, we extend programs by codata type declarations and copattern matching definitions. Co-<lb/>data type declarations introduce a new codata type together with a list of destructors, and co-<lb/>pattern matching definitions introduce a new top-level producer by a list of copattern matching <lb/>clauses. Their typing and well-formedness rules are contained in the lower half of Figure 10. <lb/>. . . <lb/>Extends Figure 9 <lb/>| codata TΨ { (z : T ).dΞ : } <lb/>Codata declaration <lb/>| codef CΞ : T { } <lb/>Producer declaration <lb/>d Ξ ↦ → <lb/>Possible cocase <lb/>| d Ξ absurd <lb/>Absurd cocase <lb/>A codata type declaration codata TΨ { (z : T ).dΞ : } introduces the type constructor T and <lb/>a list of destructors d to the program. Like data types, codata types are indexed, and the type <lb/>constructor T can be instantiated to form types with the help of the rule F-Codata. The signature <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <page>129:16 <lb/></page>
        
        <note place="headnote">David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann <lb/></note>
        
        <body>Declaration Rules <lb/>⊢ Θ Ψ tel <lb/>∀ : <lb/>[ <lb/>⊢ Θ Ξ tel and Ξ ⊢ Θ : Ψ <lb/>] <lb/>Data <lb/>⊢ Θ data TΨ { CΞ : T } OK <lb/>data TΨ {...} ∈ Θ Ξ; z : T ⊢ Θ : Type <lb/>Ξ ⊢ Θ : Ψ ∀ : Ξ ⊢ Θ : (z : T ). Def <lb/>⊢ Θ def (z : T ).dΞ : { } OK <lb/>data TΨ { CΞ 2 : T 2 ,...} ∈ Θ <lb/>Ξ 1 ; Ξ 2 ⊢ Θ mgu for 1 ≡ 2 : Ψ <lb/>(Ξ 1 ; Ξ 2 ) [ ] ⊢ Θ [ ] : id Ξ 2 /z] [ ] Case 1 <lb/>Ξ 1 ⊢ Θ C Ξ 2 ↦ → : (z : T 1 ). <lb/>data TΨ { CΞ 2 : T 2 ,...} ∈ Θ <lb/>¬∃ : Ξ 1 ; Ξ 2 ⊢ Θ mgu for 1 ≡ 2 : Ψ Case 2 <lb/>Ξ 1 ⊢ Θ C Ξ 2 absurd : (z : T 1 ). <lb/>Formation, Introduction, Elimination and Computation Rules <lb/>data TΨ {...} ∈ Θ <lb/>Γ ⊢ Θ : Ψ <lb/>F-Data <lb/>Γ ⊢ Θ T : Type <lb/>data TΨ { CΞ : T ,...} ∈ Θ <lb/>Γ ⊢ Θ : Ξ <lb/>I-Data <lb/>Γ ⊢ Θ C : T [ /Ξ] <lb/>def ( : T ).dΞ : {...} ∈ Θ <lb/>Γ ⊢ Θ : Ξ <lb/>Γ ⊢ Θ : T [ /Ξ] <lb/>E-Data <lb/>Γ ⊢ Θ .d : [ /Ξ] [ /z] <lb/>data TΨ { CΞ 1 : T 1 ,...} ∈ Θ <lb/>Γ ⊢ Θ 1 : Ξ 1 <lb/>def (z : T 2 ).d Ξ 2 : { C Ξ 1 ↦ → ,... } ∈ Θ Γ ⊢ Θ 2 : Ξ 2 <lb/>Γ ⊢ Θ 1 [ 1 /Ξ 1 ] ≡ 2 [ 2 /Ξ 2 ] : Ψ <lb/>≡-Data <lb/>Γ ⊢ Θ C 1 .d 2 ≡ [ 2 /Ξ 2 ] [ 1 /Ξ 1 ] : [ 2 /Ξ 2 ] [C 1 /z] <lb/>Declaration Rules <lb/>⊢ Θ Ψ tel <lb/>∀ : <lb/> <lb/> <lb/> <lb/> <lb/> <lb/> <lb/>⊢ Θ Ξ tel and <lb/>Ξ ⊢ Θ : Ψ and <lb/>Ξ ; z : T ⊢ Θ : Type <lb/> <lb/> <lb/> <lb/> <lb/> <lb/> Codata <lb/>⊢ Θ codata T Ψ { (z : T ). d Ξ : } OK <lb/>codata TΨ{...} ∈ Θ <lb/>Ξ ⊢ Θ : Ψ <lb/>∀ , Ξ ⊢ Θ : ( : T ) <lb/>Codef <lb/>⊢ Θ codef C Ξ : T { } OK <lb/>codata T Ψ { (z : T 2 ). d Ξ 2 : } ∈ Θ <lb/>Ξ 1 ; Ξ 2 ⊢ Θ mgu for 1 ≡ 2 : Ψ <lb/>(Ξ 1 ; Ξ 2 ) [ ] ⊢ Θ [ ] : [C id Ξ 1 /z] [ ] Cocase 1 <lb/>Ξ 1 ⊢ Θ d Ξ 2 ↦ → : ( : T 1 ) <lb/>codata T Ψ { (z : T 2 ). d Ξ 2 : } ∈ Θ <lb/>¬∃ , Ξ 1 ; Ξ 2 ⊢ Θ mgu for 1 ≡ 2 : Ψ Cocase 2 <lb/>Ξ 1 ⊢ Θ d Ξ 2 absurd : ( : T ) <lb/>Formation, Introduction, Elimination and Computation Rules <lb/>codata TΨ {...} ∈ Θ <lb/>Γ ⊢ Θ : Ψ <lb/>Γ ⊢ Θ T : Type <lb/>F-Codata <lb/>codef CΞ : T {...} ∈ Θ <lb/>Γ ⊢ Θ : Ξ <lb/>Γ ⊢ Θ C : T [ /Ξ] <lb/>I-Codata <lb/>codata TΨ {(z : T ).dΞ : ,...} ∈ Θ <lb/>Γ ⊢ Θ : Ξ <lb/>Γ ⊢ Θ : T [ /Ξ] <lb/>Γ ⊢ Θ .d : [ /Ξ] [ /z] <lb/>E-Codata <lb/>codata TΨ {( : T 2 ).dΞ 2 : ,...} ∈ Θ Γ ⊢ Θ 1 : Ξ 1 <lb/>codef CΞ 1 : T 1 {d Ξ 2 ↦ → ,...} ∈ Θ Γ ⊢ Θ 2 : Ξ 2 <lb/>Γ ⊢ Θ 1 [ 1 /Ξ 1 ] ≡ 2 [ 2 /Ξ 2 ] : Ψ <lb/>≡-Codata <lb/>Γ ⊢ Θ C 1 .d 2 ≡ [ 1 /Ξ 1 ] [ 2 /Ξ 2 ] : [ 2 /Ξ 2 ] [C 1 /z] <lb/>Fig. 10. Well-formedness and typing rules for data and codata types. <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <note place="headnote">Deriving Dependently-Typed OOP from First Principles <lb/></note>
        
        <page>129:17 <lb/></page>
        
        <body>of each destructor declaration ( : T ).dΞ : corresponds precisely to the signature of a pattern <lb/>matching definition for data types: Destructors take a parameter telescope Ξ and a self parameter <lb/>( : T ), where is a substitution for the type parameters Ψ under context Ξ. The return type <lb/>is defined under the context Ξ; : T . Using the rule E-Codata, we can eliminate a term by <lb/>calling a destructor d with arguments . In order to obtain the type of .d , we substitute for the <lb/>parameters Ξ in the return type , and for the self parameter z. We use the rule Codata to check <lb/>that a codata type declaration is well-formed. <lb/>A codefinition codef CΞ : T { } has a signature which reflects the signature of constructors <lb/>of a data type. The body of a codefinition is a list of cocases, which can be either possible or absurd. <lb/>In a possible cocase, we restate the telescope Ξ and give an expression which provides the result <lb/>if the cocase gets matched. An absurd cocase is determined to be impossible by unification and <lb/>hence does not need to provide an expression. <lb/>We check whether codefinitions are well-formed with the help of the rule Codef: We check that <lb/>the parameters Ξ are valid and that the arguments to the type constructor are well-typed under <lb/>context Ξ. Further, we ensure that all cocases are well-formed with the auxiliary judgment form <lb/>Ξ ⊢ Θ <lb/>: ( : T ), which tracks label C and type T of the codefinition. We implicitly require <lb/>that there exists one cocase for each destructor d of T. As with pattern matching cases for data <lb/>types, there are possible and absurd cocases as specified by the rules Cocase 1 and Cocase 2 . Which <lb/>rule applies is determined by unifying the codefinition type T 1 with the destructor type T 2 . If no <lb/>such unifier exists, the cocase is absurd. In a possible cocase, the unifier is substituted in context <lb/>Ξ 1 ; Ξ 2 , expression , and type . We also refine the return type by substituting C id Ξ 1 , where id Ξ 1 <lb/>is the identity context morphism for Ξ 1 . Reminiscent of constructor calls, I-Codata introduces a <lb/>term of such a type by invoking a codefinition C with arguments for the parameters Ξ. As these <lb/>parameters Ξ may occur in the constructed type T , we substitute the arguments in the type. <lb/>Lastly, the computation rule ≡-Codata reduces a redex C 1 .d 2 if 1 is a valid argument for the <lb/>codefinition C and 2 is a valid argument for the destructor d. <lb/>5.4 Call-By-Value Operational Semantics <lb/>The computation rules of Section 5.2 and Section 5.3 do not specify a deterministic evaluation <lb/>order. In this section we present the call-by-value (CBV) operational semantics of our system; the <lb/>operational semantics does not depend on typing information. We specify evaluation by means of <lb/>evaluation contexts in the style of Felleisen and Hieb [1992]. Values consist of the type universe or <lb/>of type constructors and named producers applied to other values. Named producers can either be <lb/>the constructors of a data type or the call to a toplevel codefinition. Such codefinitions generalize <lb/>lambda abstractions which are lifted to the toplevel. <lb/>Type | T | C <lb/>□ | C <lb/>| T <lb/>| .d | . <lb/>Reduction ⊲ ′ happens when introduction and elimination forms meet, i.e. when a method is <lb/>called on a constructor, or when a destructor is invoked on a codefinition: <lb/>⊲ ′ <lb/>[ ] ⊲ [ ′ ] <lb/>def ( : T ).dΞ 2 : {C Ξ 1 ↦ → } ∈ Θ <lb/>C 1 .d 2 ⊲ [ 2 /Ξ 2 ] [ 1 /Ξ 1 ] <lb/>codef CΞ 1 : T 1 {d Ξ 2 ↦ → } ∈ Θ <lb/>C 1 .d 2 ⊲ [ 1 /Ξ 1 ] [ 2 /Ξ 2 ] <lb/>Here, ⊲ denotes single step reduction of a direct redex, while ⊲ denotes evaluation within an <lb/>evaluation context. <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <page>129:18 <lb/></page>
        
        <note place="headnote">David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann <lb/></note>
        
        <body>5.5 Type Soundness <lb/>We show type soundness with respect to the call-by-value semantics of Section 5.4 by the usual <lb/>progress and preservation theorems. <lb/>TheoRem 5.1 (PRogRess). For any well-formed program Θ and expressions and , if ⊢ Θ : then <lb/>either is a value or there exists an expression ′ such that ⊲ ′ . <lb/>PRoof. Available in the online appendix and the extended version [Binder et al. 2024b]. <lb/>□ <lb/>TheoRem 5.2 (PReseRvation). For any well-formed program Θ and any expressions 1 , 2 , if <lb/>⊢ Θ 1 : and 1 ⊲ 2 , then ⊢ Θ 2 : . <lb/>PRoof. Available in the online appendix and the extended version [Binder et al. 2024b]. <lb/>□ <lb/>6 DE/REFUNCTIONALIZATION <lb/>In our system, de-and refunctionalization can transform any data type into a codata type and vice <lb/>versa. The key insight behind these transformations is that any data or codata type in the program <lb/>can be represented in matrix form as shown in Figure 11. A data type is fully determined by spec-<lb/>ifying an expression for each constructor-definition pair, while a codata type is fully determined <lb/>by giving an expression for each destructor-codefinition pair. Using these matrix representations, <lb/>the process of de-and refunctionalization simplifies to matrix transposition. With this intuition in <lb/>mind, we will now formally define de-and refunctionalization and state our main propositions. <lb/>CtoR <lb/>Def <lb/>(z 1 : T 1 ).d 1 Ξ 1 : 1 • • • (z : T ).d Ξ : <lb/>C 1 Ξ 1 : T 1 <lb/>1,1 <lb/>• • • <lb/>1, <lb/>. <lb/>. <lb/>. <lb/>. <lb/>. <lb/>. <lb/>. <lb/>. <lb/>. <lb/>C Ξ : T <lb/>,1 <lb/>• • • <lb/>, <lb/>(a) The data matrix. <lb/>DtoR <lb/>Codef <lb/>C 1 Ξ 1 : T 1 • • • C Ξ : T <lb/>(z 1 : T 1 ).d 1 Ξ 1 : 1 <lb/>1,1 <lb/>• • • <lb/>,1 <lb/>. <lb/>. <lb/>. <lb/>. <lb/>. <lb/>. <lb/>. <lb/>. <lb/>. <lb/>(z : T ).d Ξ : <lb/>1, <lb/>• • • <lb/>, <lb/>(b) The codata matrix. <lb/>Fig. 11. Data and codata matrix. <lb/>Definition 6.1 (Defunctionalization). We write D T (Θ) to denote the defunctionalization of T <lb/>in Θ. The precondition for applying D T (Θ) is that codata T Ψ { ... } ∈ Θ. Defunctionalization <lb/>transforms the codata type into a data type. For each destructor d and each codefinition C in Θ: <lb/>codata T Ψ { (z : T 2 ). d Ξ 2 : , ... }, codef C Ξ 1 : T 1 { d Ξ 2 ↦ → , ... } <lb/>the program D T (Θ) contains a corresponding constructor C and a definition d: <lb/>data T Ψ { C Ξ 1 : T 1 , ... }, def (z : T 2 ).d Ξ 2 : { C Ξ 1 ↦ → , ... } <lb/>Definition 6.2 (Refunctionalization). We write R T (Θ) to denote the refunctionalization of T in Θ. <lb/>The precondition for applying R T (Θ) is that data T Ψ { ... } ∈ Θ. Refunctionalization transforms <lb/>the data type into a codata type. For each constructor C and each definition d in Θ: <lb/>data T Ψ { C Ξ 1 : T 1 , ... }, def (z : T 2 ).d Ξ 2 : { C Ξ 1 ↦ → , ... } <lb/>the program R T (Θ) contains a corresponding codefinition C and a destructor d: <lb/>codata T Ψ { (z : T 2 ). d Ξ 2 : , ... }, codef C Ξ 1 : T 1 { d Ξ 2 ↦ → , ... } <lb/>We write X T (•) for both D T (•) and R T (•), when their difference doesn&apos;t matter. Using these <lb/>definitions, we can now state our main propositions. Notice that de-and refunctionalization do not <lb/>affect the program on the expression level. This is because we reuse the syntax for producers for <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <note place="headnote">Deriving Dependently-Typed OOP from First Principles <lb/></note>
        
        <page>129:19 <lb/></page>
        
        <body>both constructor and codefinition calls and the syntax for consumers for both destructor and defi-<lb/>nition calls (see Figure 9). Therefore, in the proposition statements below, de-/refunctionalization <lb/>is only applied to the program Θ. <lb/>TheoRem 6.3 (De/Refunctionalization pReseRves typing and judgmental eality). <lb/>The following implications hold: <lb/>• Γ ⊢ Θ : <lb/>=⇒ Γ ⊢ X T (Θ) : <lb/>• Γ ⊢ Θ 1 ≡ 2 : <lb/>=⇒ Γ ⊢ X T (Θ) 1 ≡ 2 : <lb/>• Γ ⊢ Θ : Ξ <lb/>=⇒ Γ ⊢ X T (Θ) : Ξ <lb/>• Γ ⊢ Θ 1 ≡ 2 : Ξ =⇒ Γ ⊢ X T (Θ) 1 ≡ 2 : Ξ <lb/>• ⊢ Θ Γ ctx <lb/>=⇒ ⊢ X T (Θ) Γ ctx <lb/>• Γ ⊢ Θ Ξ tel <lb/>=⇒ Γ ⊢ X T (Θ) Ξ tel <lb/>PRoof. Proof outline available in the online appendix and the extended version [Binder et al. <lb/>2024b]. <lb/>□ <lb/>TheoRem 6.4 (De/Refunctionalization pReseRves well-foRmedness of pRogRams). <lb/>If ⊢ Θ Θ OK, then ⊢ Θ X T (Θ) OK <lb/>PRoof. Proof outline available in the online appendix and the extended version [Binder et al. <lb/>2024b]. <lb/>□ <lb/>7 FUTURE WORK <lb/>In this paper, we described a dependently typed programming language based on data and codata. <lb/>How to extend this programming language to a proof assistant is one of the problems that we want <lb/>to address in the future. In the following sections, we describe the problems that have to be solved <lb/>to make our system consistent, in a way that is compatible with the transformations we described. <lb/>7.1 Specifying Termination and Productivity <lb/>The system we presented does not have any form of termination or productivity checking. We <lb/>could, of course, use any of the existing off-the-shelf solutions for checking termination and pro-<lb/>ductivity. The problem with that approach is that, in general, a program that typechecks and is ver-<lb/>ified to only have terminating recursive definitions and productive corecursive definitions might <lb/>not be verifiably total after de/-refunctionalization. We illustrate this with the following example: <lb/>data Nat { S(x: Nat), Z } <lb/>def Nat.plus(n: Nat): Nat { <lb/>Z =&gt; n, <lb/>S(x&apos;) =&gt; S(x&apos;.plus(n)) } <lb/>def Nat.mul(n: Nat): Nat { <lb/>Z =&gt; Z, <lb/>S(m) =&gt; n.plus(m.mul(n)) } <lb/>codata Nat { plus(n: Nat): Nat, mul(n: Nat): Nat } <lb/>codef S(x: Nat): Nat { <lb/>plus(n) =&gt; S(x.plus(n)), <lb/>mul(n) =&gt; n.plus(x.mul(n)) } <lb/>codef Z: Nat { <lb/>plus(n) =&gt; n, <lb/>mul(n) =&gt; Z } <lb/>We could check termination for the program on the left in the usual way. We check the definition <lb/>of plus first and verify that it is only called on the structurally smaller argument m. We then add <lb/>plus to the context of functions which are checked to be total. We then check the definition of <lb/>mul, having the function plus as a total function in the context. We see again that mul is called on <lb/>the structurally smaller argument m. <lb/>Refunctionalizing the program on the left results in the program on the right. In this program, <lb/>we have to check the productivity of the definitions of Z and S. If we want de/refunctionalization <lb/>to be a transformation that maps valid programs to valid programs, then the evidence for the <lb/>productivity of Z and S has to be composed of the evidence for the termination of plus and mul. <lb/>But it is not at all clear how this can be formally specified at the moment. <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <page>129:20 <lb/></page>
        
        <note place="headnote">David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann <lb/></note>
        
        <body>7.2 Universe Hierarchy <lb/>Another reason why our system is inconsistent is that we use one impredicative universe with <lb/>the Type-in-Type axiom. This axiom is known to make the theory inconsistent [Hurkens 1995]; <lb/>on the other hand, it vastly simplifies the presentation and implementation of the theory if we <lb/>don&apos;t have to care about universe levels. We want to investigate how de-and refunctionalization <lb/>interact with the assignment of type universes to types. This was also identified as a problem by <lb/>Huang and Yallop [2023]. <lb/>7.3 The Variance Problem <lb/>Most proof assistants enforce strict positivity in the definition of data types. The strict positivity <lb/>restriction says that recursive occurrences of the type that is defined are only allowed at strictly <lb/>positive positions, and is required to avoid Curry&apos;s paradox. <lb/>The only source of contravariance in most systems is the function type, where arguments are <lb/>contravariant. In a system with user-defined codata types many different types are the source of <lb/>contravariance, but this is quite simple to specify. The problem is that many useful types from <lb/>object-oriented programming require both positive and negative occurrences of the type being <lb/>defined. For example, consider the following type 7 : <lb/>codata NatSet { member(x: Nat): Bool, union(x: NatSet): NatSet } <lb/>In this example, the NatSet type occurs both positively and negatively in the union destructor. <lb/>But this definition is a sensible one; it is not an obscure definition at all. So if we want to enable <lb/>the user to work with such definitions we have to replace the strict positivity check by something <lb/>more refined. One avenue that we want to explore is guarded type theory (e.g. [Clouston et al. <lb/>2017]). Guarded logic was introduced by [Nakano 2000] precisely in order to fix problems with <lb/>binary methods in object-oriented programming, and was later developed by other authors into <lb/>guarded type theories. <lb/>7.4 Strong Behavioural Equality <lb/>There is no universally satisfactory definition of equality as the appropriate definition depends on <lb/>the object being modeled. For many data types, syntactic equality is sensible. For instance, two <lb/>natural numbers 0 , 1 : N are considered judgmentally equal if they are built from the same <lb/>constructors, i.e. Z ≡ Z and 0 ≡ 1 =⇒ S( 0 ) ≡ S( 1 ). However, the situation is very different as <lb/>soon as we consider functions , : N → N. Syntactic equality of the function definitions does not <lb/>seem appropriate, because multiple definitions can define the same function. A more reasonable <lb/>approach is to regard two functions as equal if they behave identically on all inputs. This principle <lb/>is known as functional extensionality: <lb/>fun_ext : ∀ , (∀ , Eq(N → N, <lb/>, )) =⇒ Eq(N → N, , ) <lb/>Functional extensionality is the prototypical example of behavioral equality. It is a special case <lb/>of bisimilarity: We consider any two objects equal if they behave identically with regard to their <lb/>observations. For codata types, we often desire behavioral equalities such as bisimilarity. <lb/>In most proof assistants, one can pose those propositional behavioral equalities as axioms. But <lb/>this approach does not work in our system. This is because the functional extensionality axiom <lb/>is inconsistent for the data representation Fun of functions N → N, which can be seen in the <lb/>following example: <lb/></body>
        
        <note place="footnote">7 This example was pointed out in the answer by Neel Krishnaswami to the following question on the proof assistants stack <lb/>exchange: https://proofassistants.stackexchange.com/questions/372/bringing-oop-features-into-proof-assistants. <lb/></note>
		<note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <note place="headnote">Deriving Dependently-Typed OOP from First Principles <lb/></note>
        
        <page>129:21 <lb/></page>
        
        <body>data Fun { Id1, Id2 } <lb/>def Fun.ap(x: Nat): Nat { Id1 =&gt; x, Id2 =&gt; x } <lb/>codef apply_id1_eq_id2: Π(Nat, \x. Eq(Fun, Id1.ap(x), Id2.ap(x))) { <lb/>pi_elim(_, _, x) =&gt; Refl(Fun, x) <lb/>} <lb/>fun_ext(Id1, Id2, apply_id1_eq_id2): Eq(Fun, Id1, Id2) <lb/>Here we can derive the propositional equality Eq(Fun, Id1, Id2), which is a contradiction to the <lb/>provable proposition that Id1 is not propositionally equal to Id2. Hence, this counterexample <lb/>shows that we cannot formulate behavioral equalities as axioms in our system. <lb/>However, stating behavioral equalities as axioms is often considered unsatisfactory. Axioms <lb/>break canonicity, i.e., the property that any closed term can be reduced to a canonical value. Further, <lb/>bisimilarity is always relative to a given set of observations. To see this, consider the functional <lb/>extensionality axiom from above. It assumes that the function type has a single elimination form, <lb/>namely function application. Identifying all types that behave identically on application is, without <lb/>further conditions, only reasonable if application is the only observation we can make. Hence, we <lb/>have the principal problem that it is unclear how to specify behavioral equalities given that we are <lb/>extensible in the observations. <lb/>Luckily, there are better approaches for working with behavioral equality that are expected to be <lb/>compatible with our system. For instance, we can resort to the typical Setoid approach of defining <lb/>a type together with an equality relation: <lb/>codata Setoid { <lb/>type: Type, <lb/>(self: Setoid).equality: Fun(self.type, Fun(self.type, Type)) } <lb/>Unfortunately, the Setoid approach is known for bad usability. To achieve a more ergonomic solu-<lb/>tion, we need a system that allows us to define a type in conjunction with its equalities. In particu-<lb/>lar, it must be possible for distinctly named constructors to be equal. Future work in this direction <lb/>could look into extending de-and refunctionalization to observational type theory [Altenkirch <lb/>and McBride 2006] or a system with higher inductive types. <lb/>8 RELATED WORK <lb/>Codata types. Codata types were first introduced by Hagino [Hagino 1987, 1989]. The original <lb/>interpretation of codata types stems from coalgebras in category theory. An overview of the history <lb/>of codata types as coalgebras is given by Setzer [Setzer 2012]. We have discussed the relation <lb/>between codata types and OOP in Section 1.1. <lb/>The expression problem. The expression problem poses the challenge for statically typed lan-<lb/>guages to create a type which can be extended by both new producers and new consumers. Based <lb/>on earlier observations, Wadler [1998] formulated the problem and gave it its current name. The <lb/>expression problem for proofs is recognized as an important challenge in the verification commu-<lb/>nity, but there are fewer proposed and implemented solutions than in the programming world. One <lb/>popular solution in the programming world is Swierstra [2008]&apos;s &quot;Data Types à la carte&quot; approach. <lb/>In that approach, a type is defined as the fixpoint of a coproduct of functors which can be ex-<lb/>tended by new functors in a modular way. Most proposed solutions for dependent types are based <lb/>on Swierstra [2008]&apos;s approach and extend them to dependent types. Delaware et al. [2013a,b]; <lb/>Delaware [2013] as well as Keuchel and Schrijvers [2013] implemented this approach for the Coq <lb/>proof assistant and Schwaab and Siek [2013] implemented it for Agda. A system for writing mod-<lb/>ular proofs in the Isabelle proof assistant has been described by Molitor [2015]. The most recent <lb/>adaptation of the idea is by Forster and Stark [2020], who give an excellent presentation of this <lb/>line of work in their related work section. <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <page>129:22 <lb/></page>
        
        <note place="headnote">David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann <lb/></note>
        
        <body>In this article, our focus was not to propose a solution to the expression problem for proofs, since <lb/>the defunctionalization and refunctionalization algorithms are whole-program transformations. <lb/>Instead, our approach distills the essence of the expression problem for dependent types: Neither <lb/>the functional nor the object-oriented decomposition solves the expression problem, since data <lb/>types cannot be easily extended by new constructors, and codata types cannot be easily extended <lb/>by new destructors. <lb/>Dependently-typed object-oriented programming. In Section 2 we presented our perspective on <lb/>dependently-typed object-oriented programming. But we are not the first to think about this de-<lb/>sign space. Jacobs [1995] proposes using coalgebras to express object-oriented classes with coal-<lb/>gebraic specifications. His concept is based on three main components: objects, class implementa-<lb/>tions, and class specifications. The latter are used to specify a set of methods on an abstract state <lb/>space as well as a set of assertions that define the behavior of these methods. Such a specification <lb/>can then be implemented by a class. A class gives a carrier set as a concrete interpretation for <lb/>the state space and a coalgebra that implements the specified methods. An object is then just an <lb/>element of the carrier set. In our system, we can express specifications similar to Jacobs&apos; proposal <lb/>using self-parameters on destructors (see Section 2.2). Rather than having separate notions of spec-<lb/>ifications, classes, and objects, our system has a singular notion of codata types. Jacobs separates <lb/>these notions to construct a model in which objects are indistinguishable if they are bisimilar ac-<lb/>cording to their specification. In contrast, in our system, we have a full syntactic duality between <lb/>data and codata types through de-and refunctionalization. Hence, we need to decouple codata <lb/>types from the semantics that are usually associated with them, including behavioral equality <lb/>such as bisimilarity. Setzer [2006] conceived of dependently-typed object-oriented programming <lb/>by specifying interfaces and having interactive programs as objects implementing these interfaces. <lb/>The interfaces contain a command type, which represents the method signatures of an interface. In-<lb/>teractive programs are programs that react to incoming method calls by producing a return value <lb/>and a new object. <lb/>Dependent type theories with definable Π-type and Σ-type. In Section 2.3 we demonstrated that <lb/>the programmer can define both the Π-type and the Σ-type in our system, whereas in most proof <lb/>assistants only the Σ-type can be defined. This is a generalization of the observation that pro-<lb/>grammers can&apos;t define the function type in most functional programming languages, but that the <lb/>function type can be defined in object-oriented languages [Setzer 2003]. Apart from this paper, the <lb/>only other dependent type theory that doesn&apos;t presuppose a built-in Π-type is by Basold [2018]; <lb/>Basold and Geuvers [2016]. Like us, they give an explicit definition of the Π-type in their system. <lb/>Their definition, however, is slightly different from ours, since they have a more expressive core <lb/>system. In their system, parameterized type constructors and type variables don&apos;t have to be fully <lb/>applied. Partially applied type constructors have a special type Γ <lb/> * , and they specify a sort of <lb/>simply-typed lambda calculus which governs the rules for abstracting over, and partially applying <lb/>type constructors to arguments. As a result, their definition of the Π and Σ-type is a bit simpler: <lb/>We have to use a previously-defined non-dependent function type → Type to represent the type <lb/>family that the Σ and Π-types are indexed over, while they use a partially applied type variable <lb/>: <lb/> * . Our system is also not consistent; theirs is, and they prove both subject reduction and <lb/>strong normalization. <lb/>Dependent pattern matching. The traditional primitive elimination forms in dependent type the-<lb/>ories are eliminators. The eliminator for natural numbers, for example, has the type ∀(P : N → <lb/>Type), P 0 → (∀n : N, P n → P (S n)) → ∀n : N, P n. They are suitable for studying the metatheory <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <note place="headnote">Deriving Dependently-Typed OOP from First Principles <lb/></note>
        
        <page>129:23 <lb/></page>
        
        <body>of dependent types, but programming with them isn&apos;t very ergonomic. A more convenient alterna-<lb/>tive to eliminators is dependent pattern matching, a generalization of ordinary pattern matching to <lb/>dependent types, which was first proposed by Coquand [1992]. While ordinary pattern matching <lb/>can be compiled to eliminators and is therefore nothing more than syntactic sugar, the compila-<lb/>tion of dependent pattern matches additionally requires Streicher [1993]&apos;s axiom K. Hofmann and <lb/>Streicher [1994] proved that this axiom does not follow from the standard elimination rules for the <lb/>identity type. Since the K axiom is sometimes undesirable-it is incompatible with other principles <lb/>such as univalence-a variant of dependent pattern matching which does not rely on axiom K was <lb/>developed by Cockx et al. [2014]. We use a variant of dependent pattern and copattern match-<lb/>ing which requires axiom K if we want to compile it to eliminators, but we could get rid of this <lb/>dependency by applying the three restrictions presented in Cockx&apos; thesis [Cockx 2017, p.55]. <lb/>Copattern matching. Copattern matching as a dual concept to pattern matching was first pro-<lb/>posed by Abel et al. [2013]. Their work was motivated by the deficiencies of previous approaches <lb/>which used constructors to represent infinite objects. For instance, the coinductive types origi-<lb/>nally introduced in Coq broke subject reduction, as noted by Giménez [1996] and Oury [2008]. <lb/>Even simple infinite objects such as streams cannot be represented using constructors and pattern <lb/>matching in a sensible way. This follows from the observation of Berger and Setzer [2018] that <lb/>there exists no decidable equality for streams which admits a one-step expansion of a stream to <lb/>a stream (cons ′ ). <lb/>Inconsistent dependent type theories. The type theory presented in this paper is inconsistent, <lb/>i.e. every type is inhabited by some term, a property it shares with most programming languages <lb/>but not with proof assistants. However, the inconsistency of the theory does not imply that the <lb/>properties expressed by the dependent types are meaningless. We can compare the situation to the <lb/>programming language Haskell, where it is already possible to write dependent programs by us-<lb/>ing several language extensions and programming tricks [Eisenberg and Weirich 2012; Lindley and <lb/>McBride 2013]. Instead of relying on these tricks, a more ergonomic and complete design of depen-<lb/>dent types in Haskell has been the subject of various articles [Weirich et al. 2019, 2017] and PhD <lb/>theses [Eisenberg 2016; Gundry 2013]. Their main insight also applies to our system: the central <lb/>property of an inconsistent dependent type theory is type soundness [Wright and Felleisen 1994]. <lb/>For example, every term of type Vec(5) can only evaluate to a vector containing five elements <lb/>or diverge; it cannot evaluate to a vector of six elements. But they also show that inconsistency <lb/>has downsides, especially for optimization: In a consistent theory every term of type Eq( , ) must <lb/>evaluate to the term refl, and can therefore be erased during compilation. In an inconsistent the-<lb/>ory, we cannot erase the equality witness, since we could otherwise write a terminating unsafe <lb/>coercion between arbitrary types, which would violate type soundness. <lb/>Defunctionalization and refunctionalization. The related work on defunctionalization and re-<lb/>functionalization can be partitioned into two groups: The first group only considers defunction-<lb/>alization and refunctionalization for the function type, while the second group generalizes them <lb/>to transformations between arbitrary data and codata types. De/Refunctionalization of the func-<lb/>tion type has a long history, which starts with the seminal paper by Reynolds [1972] and the later <lb/>work of Danvy and Millikin [2009]; Danvy and Nielsen [2001]. That the defunctionalization of <lb/>polymorphic functions requires GADTs was first observed by Pottier and Gauthier [2006]. In a re-<lb/>cent paper, Huang and Yallop [2023] describe the defunctionalization of dependent functions, and <lb/>especially how to correctly deal with type universes and positivity restrictions, but don&apos;t consider <lb/>the general case of indexed data and codata types. On the contrary, they do not use data types at all <lb/></body>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <page>129:24 <lb/></page>
        
        <note place="headnote">David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann <lb/></note>
        
        <body>and instead introduce the construct of first-class function labels which enables them to avoid prob-<lb/>lems arising from the expressivity of data type definitions like recursive types. The generalization <lb/>of defunctionalization from functions to arbitrary codata types was first described by Rendel et al. <lb/>[2015] for a simply typed system without local lambda abstractions or local pattern matches. That <lb/>the generalization to polymorphic data and codata types then also requires GAcoDTs has been <lb/>described by Ostermann and Jabs [2018]. How to treat local pattern and copattern matches in such <lb/>a way as to preserve the invertibility of defunctionalization and refunctionalization has been de-<lb/>scribed by Binder et al. [2019]. Recently, Zhang et al. [2022] implemented defunctionalization and <lb/>refunctionalization for the programming language Scala, and used these transformations for some <lb/>larger case studies. In this article, we describe the generalization to indexed data and codata types, <lb/>but in distinction to Huang and Yallop [2023] we circumvent the problems of type universes and <lb/>positivity restrictions by working in an inconsistent type theory. <lb/>9 CONCLUSION <lb/>Most dependently typed programming languages don&apos;t support programming with codata as well <lb/>as programming with data. The main reason some proof assistants support codata types at all was <lb/>that some support was necessary for the convenient formalization of theorems about infinite and <lb/>coalgebraic objects. But codata types are useful for more than just representing infinite objects <lb/>like streams; they represent an orthogonal way to structure programs and proofs, with different <lb/>extensibility properties and reasoning principles. In this paper we have presented a vision of how <lb/>programming can look in a dependently typed language in which the data and codata sides are <lb/>completely symmetric and treated with equal care. By implementing this language and testing <lb/>it on a case study we have demonstrated that this style of purely functional, dependently typed <lb/>object-oriented programming does work. We think that this way of systematic language design, <lb/>in place of ad-hoc extensions, provides a good case study on how the design of dependently typed <lb/>languages and proof assistants should be approached. <lb/></body>
        
        <div type="availability">DATA-AVAILABILITY STATEMENT <lb/>This article is accompanied by an online IDE available at polarity-lang.github.io/oopsla24 where <lb/>the examples discussed in this paper can be selected and loaded. This online IDE consists of a static <lb/>website hosted on GitHub pages, with all the code running in the browser on the client side. Should <lb/>the hosted website despite our best efforts no longer be available, then it is possible to recreate it <lb/>locally using the archived version available at Zenodo [Binder et al. 2024a]. <lb/></div>
        
        <listBibl>REFERENCES <lb/>Andreas Abel, Brigitte Pientka, David Thibodeau, and Anton Setzer. 2013. Copatterns: Programming Infinite Structures <lb/>by Observations. In Proceedings of the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming <lb/>Languages (Rome, Italy) (POPL &apos;13). Association for Computing Machinery, New York, NY, USA, 27-38. https://doi.org/ <lb/>10.1145/2480359.2429075 <lb/>Thorsten Altenkirch and Conor McBride. 2006. Towards Observational Type Theory. http://www.strictlypositive.org/ott. <lb/>pdf <lb/>Henning Basold. 2018. Mixed Inductive-Coinductive Reasoning: Types, Programs and Logic. Ph. D. Dissertation. Radboud <lb/>University. https://hdl.handle.net/2066/190323 <lb/>Henning Basold and Herman Geuvers. 2016. Type Theory Based on Dependent Inductive and Coinductive Types. In <lb/>Proceedings of the Symposium on Logic in Computer Science (New York). Association for Computing Machinery, New <lb/>York, NY, USA, 327-336. https://doi.org/10.1145/2933575.2934514 <lb/>Ulrich Berger and Anton Setzer. 2018. Undecidability of Equality for Codata Types. In Coalgebraic Methods in Computer <lb/>Science, Corina Cîrstea (Ed.). Springer, 34-55. https://doi.org/10.1007/978-3-030-00389-0_4 <lb/>Binder, Julian Jabs, Ingo Skupin, and Klaus Ostermann. 2019. Decomposition Diversity with Symmetric Data and <lb/>Codata. Proc. ACM Program. Lang. 4, POPL, Article 30 (2019), 28 pages. https://doi.org/10.1145/3371098 <lb/></listBibl>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <note place="headnote">Deriving Dependently-Typed OOP from First Principles <lb/></note>
        
        <page>129:25 <lb/></page>
        
        <listBibl>David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann. 2024a. Deriving Dependently-Typed OOP from First <lb/>Principles. https://doi.org/10.5281/zenodo.10779424 Archived version of the submitted artefact. <lb/>David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann. 2024b. Deriving Dependently-Typed OOP from First <lb/>Principles -Extended Version with Additional Appendices. (2024). https://doi.org/10.48550/arXiv.2403.06707 <lb/>Ranald Clouston, Aleš Bizjak, Hans Bugge Grathwohl, and Lars Birkedal. 2017. The Guarded Lambda-Calculus: Program-<lb/>ming and Reasoning with Guarded Recursion for Coinductive Types. Logical Methods in Computer Science 12 (April <lb/>2017). Issue 3. https://doi.org/10.2168/LMCS-12(3:7)2016 <lb/>Jesper Cockx. 2017. Dependent Pattern Matching and Proof-Relevant Unification. Ph. D. Dissertation. KU Leuven. <lb/>Jesper Cockx, Dominique Devriese, and Frank Piessens. 2014. Pattern Matching without K. In International Conference on <lb/>Functional Programming. Association for Computing Machinery, New York, NY, USA, 257-268. https://doi.org/10.1145/ <lb/>2628136.2628139 <lb/>William R. Cook. 1990. Object-Oriented Programming versus Abstract Data Types. In Proceedings of the REX Workshop / <lb/>School on the Foundations of Object-Oriented Languages. Springer, 151-178. https://doi.org/10.1007/BFb0019443 <lb/>William R. Cook. 2009. On Understanding Data Abstraction, Revisited. In Proceedings of the Conference on Object-Oriented <lb/>Programming, Systems, Languages and Applications: Onward! Essays (Orlando). Association for Computing Machinery, <lb/>New York, NY, USA, 557-572. https://doi.org/10.1145/1640089.1640133 <lb/>Thierry Coquand. 1992. Pattern Matching With Dependent Types. In Proceedings of the 1992 Workshop on Types for Proofs <lb/>and Programs (Bastad, Sweden), Bengt Nordström, Kent Pettersson, and Gordon Plotkin (Eds.). 66-79. <lb/>Olivier Danvy and Kevin Millikin. 2009. Refunctionalization at Work. Science of Computer Programming 74, 8 (2009), <lb/>534-549. https://doi.org/10.1016/j.scico.2007.10.007 <lb/>Olivier Danvy and Lasse R. Nielsen. 2001. Defunctionalization at Work. In Proceedings of the Conference on Principles and <lb/>Practice of Declarative Programming (Florence). 162-174. https://doi.org/10.1145/773184.773202 <lb/>Benjamin Delaware, Bruno C. d. S. Oliveira, and Tom Schrijvers. 2013a. Meta-Theory à La Carte. In Symposium on Principles <lb/>of Programming Languages (Rome) (POPL &apos;13). Association for Computing Machinery, New York, NY, USA, 207-218. <lb/>https://doi.org/10.1145/2429069.2429094 <lb/>Benjamin Delaware, Steven Keuchel, Tom Schrijvers, and Bruno C.d.S. Oliveira. 2013b. Modular Monadic Meta-Theory. <lb/>In Proceedings of the 18th ACM SIGPLAN International Conference on Functional Programming (Boston, Massachusetts, <lb/>USA) (ICFP &apos;13). Association for Computing Machinery, New York, NY, USA, 319-330. https://doi.org/10.1145/2500365. <lb/>2500587 <lb/>Benjamin James Delaware. 2013. Feature Modularity in Mechanized Reasoning. Ph. D. Dissertation. The University of Texas <lb/>at Austin. <lb/>Paul Downen, Zachary Sullivan, Zena M. Ariola, and Simon Peyton Jones. 2019. Codata in Action. In European Symposium <lb/>on Programming (ESOP &apos;19). Springer, 119-146. https://doi.org/10.1007/978-3-030-17184-1_5 <lb/>Richard Eisenberg. 2016. Dependent Types in Haskell: Theory and Practice. Ph. D. Dissertation. University of Pennsylvania. <lb/>Richard A. Eisenberg, Guillaume Duboc, Stephanie Weirich, and Daniel Lee. 2021. An Existential Crisis Resolved: Type <lb/>Inference for First-Class Existential Types. Proc. ACM Program. Lang. 5, ICFP, Article 64 (aug 2021), 29 pages. https: <lb/>//doi.org/10.1145/3473569 <lb/>Richard A. Eisenberg and Stephanie Weirich. 2012. Dependently Typed Programming with Singletons. In Proceedings of the <lb/>Haskell Symposium (Copenhagen, Denmark) (Haskell &apos;12). Association for Computing Machinery, New York, NY, USA, <lb/>117-130. https://doi.org/10.1145/2364506.2364522 <lb/>Matthias Felleisen and Robert Hieb. 1992. The Revised Report on the Syntactic Theories of Sequential Control and State. <lb/>Theoretical Computer Science 103, 2 (1992), 235-271. https://doi.org/10.1016/0304-3975(92)90014-7 <lb/>Yannick Forster and Kathrin Stark. 2020. Coq à La Carte: A Practical Approach to Modular Syntax with Binders. In Proceed-<lb/>ings of the Conference on Certified Programs and Proofs (New Orleans) (CPP 2020). Association for Computing Machinery, <lb/>New York, NY, USA, 186-200. https://doi.org/10.1145/3372885.3373817 <lb/>Peng Fu and Aaron Stump. 2014. Self Types for Dependently Typed Lambda Encodings. In International Conference on <lb/>Rewriting Techniques and Applications, Gilles Dowek (Ed.). Springer, 224-239. https://doi.org/10.1007/978-3-319-08918-<lb/>8_16 <lb/>Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides. 1995. Design Patterns: Elements of Reusable Object-Oriented <lb/>Software. Addison-Wesley Publishing Co., Boston. <lb/>Richard Garner. 2009. On the Strength of Dependent Products in the Type Theory of Martin-Löf. Annals of Pure and Applied <lb/>Logic 160, 1 (2009), 1-12. https://doi.org/10.1016/j.apal.2008.12.003 <lb/>Herman Geuvers. 2001. Induction Is Not Derivable in Second Order Dependent Type Theory. In Typed Lambda Calculi and <lb/>Applications, Samson Abramsky (Ed.). Springer, Berlin, Heidelberg, 166-181. https://doi.org/3-540-45413-6_16 <lb/>Herman Geuvers. 2014. The Church-Scott Representation of Inductive and Coinductive Data. https://www.cs.vu.nl/ <lb/>~femke/courses/ep/slides/herman-data-types.pdf Presented at the TYPES 2014 meeting. <lb/></listBibl>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <page>129:26 <lb/></page>
        
        <note place="headnote">David Binder, Ingo Skupin, Tim Süberkrüb, and Klaus Ostermann <lb/></note>
        
        <listBibl>Eduardo Giménez. 1996. Un Calcul de Constructions Infinies et son application a la vérification de systemes communicants. <lb/>Ph. D. Dissertation. Lyon, École normale supérieure (sciences). <lb/>Jean-Yves Girard. 1972. Interprétation fonctionelle et élimination des coupures de l&apos;arithmétique d&apos;ordre supérieur. Thése de <lb/>Doctorat d&apos;Etat. Université de Paris VII. <lb/>Brian Goetz et al. 2014. JSR 335: Lambda Expressions for the Java Programming Language. https://jcp.org/en/jsr/detail?id= <lb/>335 <lb/>Adam Gundry. 2013. Type Inference, Haskell and Dependent Types. Ph. D. Dissertation. University of Strathclyde. <lb/>Tatsuya Hagino. 1987. A Categorical Programming Language. Ph. D. Dissertation. University of Edinburgh. https://doi. <lb/>org/10.48550/arXiv.2010.05167 <lb/>Tatsuya Hagino. 1989. Codatatypes in ML. Journal of Symbolic Computation 8, 6 (1989), 629-650. https://doi.org/10.1016/ <lb/>S0747-7171(89)80065-3 <lb/>Martin Hofmann. 1997. Syntax and Semantics of Dependent Types. In Extensional Constructs in Intensional Type Theory. <lb/>Springer, London, 13-54. https://doi.org/10.1007/978-1-4471-0963-1_2 <lb/>Martin Hofmann and Thomas Streicher. 1994. The Groupoid Model Refutes Uniqueness of Identity Proofs. In Proceedings <lb/>Ninth Annual IEEE Symposium on Logic in Computer Science. IEEE, 208-212. https://doi.org/10.1109/LICS.1994.316071 <lb/>William Alvin Howard. 1980. The Formulae-as-Types Notion of Construction. In To H. B. Curry: Essays on Combinatory <lb/>Logic, Lambda Calculus, and Formalism, Haskell Curry, Hindley B., Seldin J. Roger, and P. Jonathan (Eds.). Academic <lb/>Press. <lb/>Yulong Huang and Jeremy Yallop. 2023. Defunctionalization with Dependent Types. Proc. ACM Program. Lang. 7, PLDI, <lb/>Article 127 (jun 2023), 23 pages. https://doi.org/10.1145/3591241 <lb/>Antonius J. C. Hurkens. 1995. A Simplification of Girard&apos;s Paradox. In Proceedings of the Conference on Typed Lambda <lb/>Calculi and Applications. Springer, London, 266-278. http://dx.doi.org/10.1007/BFb0014058 <lb/>Bart Jacobs. 1995. Objects and Classes, Coalgebraically. In Object Orientation with Parallelism and Persistence, Burkhard <lb/>Freitag, Cliff B. Jones, Christian Lengauer, and Hans-Jörg Schek (Eds.). Springer, 83-103. https://doi.org/10.1007/978-<lb/>1-4613-1437-0_5 <lb/>Steven Keuchel and Tom Schrijvers. 2013. Generic Datatypes à La Carte. In Workshop on Generic Programming (Boston) <lb/>(WGP &apos;13). Association for Computing Machinery, New York, NY, USA, 13-24. https://doi.org/10.1145/2502488.2502491 <lb/>Pieter Koopman, Rinus Plasmeijer, and Jan Martin Jansen. 2014. Church Encoding of Data Types Considered Harmful <lb/>for Implementations: Functional Pearl. In Proceedings of the 26nd 2014 International Symposium on Implementation and <lb/>Application of Functional Languages (IFL &apos;14). Association for Computing Machinery, New York, NY, USA, Article 4, <lb/>12 pages. https://doi.org/10.1145/2746325.2746330 <lb/>Sam Lindley and Conor McBride. 2013. Hasochism: The Pleasure and Pain of Dependently Typed Haskell Programming. <lb/>In Proceedings of the Haskell Symposium (Boston) (Haskell &apos;13). Association for Computing Machinery, New York, NY, <lb/>USA, 81-92. https://doi.org/10.1145/2503778.2503786 <lb/>Richard Molitor. 2015. Open Inductive Predicates. Master&apos;s thesis. Karlsruher Institut für Technologie (KIT). <lb/>Hiroshi Nakano. 2000. A Modality for Recursion. In Proceedings of the Symposium on Logic in Computer Science. 255-266. <lb/>https://doi.org/10.1109/LICS.2000.855774 <lb/>Klaus Ostermann and Julian Jabs. 2018. Dualizing Generalized Algebraic Data Types by Matrix Transposition. In European <lb/>Symposium on Programming. Springer, 60-85. https://doi.org/10.1007/978-3-319-89884-1_3 <lb/>Nicolas Oury. 2008. Coinductive Types and Type Preservation. Message on the coq-club mailing list (2008). https://sympa. <lb/>inria.fr/sympa/arc/coq-club/2008-06/msg00022.html <lb/>François Pottier and Nadji Gauthier. 2006. Polymorphic Typed Defunctionalization and Concretization. Higher-Order and <lb/>Symbolic Computation 19, 1 (3 2006), 125-162. https://doi.org/10.1007/s10990-006-8611-7 <lb/>Tillmann Rendel, Julia Trieflinger, and Klaus Ostermann. 2015. Automatic Refunctionalization to a Language with Copat-<lb/>tern Matching: With Applications to the Expression Problem. In Proceedings of the 20th ACM SIGPLAN International <lb/>Conference on Functional Programming (Vancouver, BC, Canada) (ICFP 2015). Association for Computing Machinery, <lb/>New York, NY, USA, 269-279. https://doi.org/10.1145/2784731.2784763 <lb/>John Charles Reynolds. 1972. Definitional Interpreters for Higher-Order Programming Languages. In ACMConf (Boston). <lb/>Association for Computing Machinery, New York, NY, USA, 717-740. https://doi.org/10.1145/800194.805852 <lb/>Christopher Schwaab and Jeremy G. Siek. 2013. Modular Type-Safety Proofs in Agda. In Proceedings of the 7th Workshop <lb/>on Programming Languages Meets Program Verification (Rome, Italy) (PLPV &apos;13). Association for Computing Machinery, <lb/>New York, NY, USA, 3-12. https://doi.org/10.1145/2428116.2428120 <lb/>Anton Setzer. 2003. Java as a Functional Programming Language. In Types for Proofs and Programs, Herman Geuvers and <lb/>Freek Wiedijk (Eds.). Springer, Berlin, Heidelberg, 279-298. https://doi.org/10.1007/3-540-39185-1_16 <lb/>Anton Setzer. 2006. Object-Oriented Programming in Dependent Type Theory. Trends in Functional Programming 7 (2006), <lb/>91-108. <lb/></listBibl>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. <lb/></note>
        
        <note place="headnote">Deriving Dependently-Typed OOP from First Principles <lb/></note>
        
        <page>129:27 <lb/></page>
        
        <listBibl>Anton Setzer. 2012. Coalgebras as Types Determined by Their Elimination Rules. In Epistemology versus Ontology. Essays on <lb/>the Philosophy and Foundations of Mathematics in Honour of Per Martin-Löf, Peter Dybjer, Sten Lindström, Erik Palmgren, <lb/>and Göran Sundholm (Eds.). Logic, Epistemology, and the Unity of Science, Vol. 27. Springer, Dordrecht, 351-369. https: <lb/>//doi.org/10.1007/978-94-007-4435-6_16 <lb/>Thomas Streicher. 1993. Investigations into Intensional Type Theory. Habilitationsschrift, Ludwig-Maximilians-Universität <lb/>München. <lb/>Wouter Swierstra. 2008. Data Types à la Carte. Journal of Functional Programming 18, 4 (2008), 423-436. https://doi.org/ <lb/>10.1017/S0956796808006758 <lb/>Neil Tennant. 1982. Proof and Paradox. Dialectica 36, 2-3 (1982), 265-296. https://doi.org/10.1111/j.1746-8361.1982.tb00820. <lb/>x <lb/>David Thibodeau, Andrew Cave, and Brigitte Pientka. 2016. Indexed Codata Types. In Proceedings of the International <lb/>Conference on Functional Programming (Nara, Japan) (ICFP 2016). Association for Computing Machinery, New York, NY, <lb/>USA, 351-363. https://doi.org/10.1145/2951913.2951929 <lb/>Philip Wadler. 1998. The Expression Problem. (11 1998). https://homepages.inf.ed.ac.uk/wadler/papers/expression/ <lb/>expression.txt Note to Java Genericity mailing list. <lb/>Stephanie Weirich, Pritam Choudhury, Antoine Voizard, and Richard A. Eisenberg. 2019. A Role for Dependent Types in <lb/>Haskell. Proc. ACM Program. Lang. 3, ICFP, Article 101 (jul 2019), 29 pages. https://doi.org/10.1145/3341705 <lb/>Stephanie Weirich, Antoine Voizard, Pedro Henrique Azevedo de Amorim, and Richard A. Eisenberg. 2017. A Specification <lb/>for Dependent Types in Haskell. Proceedings of the ACM on Programming Languages 1, ICFP (8 2017). https://doi.org/ <lb/>10.1145/3110275 <lb/>Andrew K. Wright and Matthias Felleisen. 1994. A Syntactic Approach to Type Soundness. Information and Computation <lb/>115, 1 (11 1994), 38-94. https://doi.org/10.1006/inco.1994.1093 <lb/>Weixin Zhang, Cristina David, and Meng Wang. 2022. Decomposition Without Regret. arXiv preprint arXiv:2204.10411 <lb/>(2022). https://doi.org/10.48550/ARXIV.2204.10411 <lb/></listBibl>
        
        <front>Received 21-OCT-2023; accepted 2024-02-24 <lb/></front>
        
        <note place="footnote">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA1, Article 129. Publication date: April 2024. </note>
        

	</text>

</TEI>