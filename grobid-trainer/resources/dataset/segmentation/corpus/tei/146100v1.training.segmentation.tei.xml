<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>1 <lb/>

			Evaluation <lb/>of <lb/>in silico algorithms for use with ACMG/AMP clinical variant <lb/>interpretation guidelines <lb/>Rajarshi Ghosh, Ninad Oak and Sharon E. Plon <lb/>Department of Pediatrics, Baylor College of Medicine, Houston, TX <lb/>Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, TX <lb/></front>

			<page>2 <lb/></page>

			<front>Abstract <lb/>The <lb/>ACMG/AMP <lb/>variant <lb/>classification <lb/>guidelines <lb/>for <lb/>clinical <lb/>reporting <lb/>recommend <lb/>complete concordance of predictions among all in silico algorithms used without specifying <lb/>the number or types of algorithms. The subjective nature of this recommendation <lb/>contributes to discordance of variant classification among clinical laboratories. Using <lb/>14,819 benign or pathogenic missense variants from the ClinVar database, we compared <lb/>performance of 25 algorithms across datasets differing in distinct biological and technical <lb/>variables. There was wide variability in concordance among different combinations of <lb/>algorithms with particularly low concordance for benign variants. We identified recently <lb/>developed algorithms with high predictive power and robust to variables like disease <lb/>mechanism, gene constraint and mode of inheritance, although poorer performing <lb/>algorithms are more frequently used based on review of the clinical genetics literature <lb/>(2011-2017). We describe high performing algorithm combinations with increased <lb/>concordance in variant assertion, which should lead to more informed in silico algorithm <lb/>usage by diagnostic laboratories. <lb/></front>

			<page>3 <lb/></page>

			<body>Many in silico methods have been developed to predict whether amino acid substitutions <lb/>result in disease. Use of this type of evidence has become a routine part of assessment of <lb/>novel variants identified through gene-focused projects or as a part of whole exome or <lb/>genome annotation pipelines. In a clinical setting, predictions from in silico algorithms are <lb/>included as one of the eight evidence criteria recommended for variant interpretation by <lb/>the American College of Medical Genetics and Genomics (ACMG) and Association of <lb/>Molecular Pathologists (AMP) <lb/>1 . The ACMG/AMP guideline for use of in silico algorithms <lb/>specifically states: &quot;If all of the in silico programs tested agree on the prediction, then this <lb/>evidence can be counted as supporting. If in silico predictions disagree, however, then this <lb/>evidence should not be used in classifying a variant.&quot; For a given missense variant, <lb/>predictions by numerous algorithms are publicly available e.g. via dbNSFP <lb/>1 or Variant <lb/>Effect <lb/>Predictor <lb/>2 from which a few algorithms are typically chosen for variant <lb/>interpretation <lb/>and <lb/>are <lb/>often <lb/>used <lb/>without <lb/>additional <lb/>calibration. <lb/>Different <lb/>testing <lb/>laboratories use distinct combinations of in silico algorithms for variant interpretation and <lb/>this can lead to discordant interpretations. <lb/>For example, in a recent assessment of the <lb/>ACMG/AMP guidelines by the Clinical Sequence Exploratory Research consortium (CSER), <lb/>the frequency of use of in silico algorithm evidence for pathogenic and benign variant <lb/>assertion were 39% and 18% respectively <lb/>3 . The CSER study noted that use of in silico <lb/>algorithms were one major source of discordance among different clinical laboratories and <lb/>that the ACMG/AMP guideline for in silico algorithm usage may be aided by further <lb/>recommendations <lb/>3 . <lb/>Missense variants constitute a major set of variants of uncertain significance (VUS) <lb/>in ClinVar <lb/>4 . An improved recommendation for use of in silico algorithms is important for <lb/></body>

			<page>4 <lb/></page>

			<body>reducing the VUS burden in clinical medicine and increasing concordance of variant <lb/>interpretation. <lb/>Currently, there is little consensus among clinical labs on how many and <lb/>which algorithms to use for missense variant interpretation. For example, a recent exome <lb/>sequencing study classified variants in 180 medically relevant genes for hereditary cancer <lb/>according to ACMG/AMP guidelines. The authors found that the VUS rate was higher when <lb/>requiring full concordance versus majority agreement among the 13 in silico algorithms <lb/>used <lb/>5 . Other examples from literature demonstrate requiring full concordance among <lb/>three <lb/>6 to seven 7 different algorithms for variant interpretation. However, to our knowledge, <lb/>no analysis has been conducted to assess the applicability of the current ACMG/AMP <lb/>guideline for in silico algorithm usage. Here, using predictions from 25 in silico algorithms <lb/>for 14819 clinically relevant missense variants in the ClinVar database, we highlight <lb/>several limitations of implementing the ACMG/AMP guideline for in silico algorithm usage. <lb/>We find highly variable degree of concordance among different combinations of algorithms <lb/>with particularly low concordance of the predictions of variants reported in ClinVar as <lb/>benign. Using the ClinVar dataset, we identify algorithms with higher predictive power <lb/>whose performances are robust to variables such as disease mechanism, level of constraint <lb/>and mode of inheritance. <lb/>Results: <lb/>Concordance among in silico algorithms <lb/>To identify the extent of concordance among in silico algorithms for known <lb/>pathogenic and benign variants, we obtained 14,819 missense variants from ClinVar for <lb/>which the rationale for pathogenic or benign assertion has been provided by at least one <lb/></body>

			<page>5 <lb/></page>

			<body>submitter (one star status in ClinVar), primarily clinical laboratories, and annotated these <lb/>variants with scores and predictions from 25 algorithms using dbNSFP (v3.2) <lb/>8 or the <lb/>respective authors&apos; websites. We generated a matrix of binary predictions (pathogenic or <lb/>benign) for these variants with scores from the 18 algorithms, for which thresholds of <lb/>pathogenicity were publicly available (Fig. 1A, Supplementary Table 1, see Methods). We <lb/>found that when using this large number of algorithms that only 4% of the benign and 1% <lb/>of pathogenic variants had concordant assertions across all them (Fig. 1A, Table 1). We <lb/>obtained similar results when we restricted our analysis to benign and pathogenic variants <lb/>in ClinVar that had identical assertions from at least two independent laboratories (two <lb/>stars -Fig. 1B, Table 1) suggesting that errors in ClinVar assertions by a single submitter <lb/>contributes little to the low level of concordance among algorithms. We then computed the <lb/>pairwise differences among all the algorithms separately for 7346 benign and 7473 <lb/>pathogenic variants in our dataset (see Methods). We found that on average, two <lb/>algorithms tend to differ from each other significantly more in the interpretation of benign <lb/>as opposed to pathogenic variants (p&lt;0.0001, Welch Two Sample t-test) (Fig. 2A). Our data <lb/>suggests that while interpreting large number of variants, full concordance, as suggested by <lb/>the ACMG/AMP guidelines, is less likely to be achieved even when using only two <lb/>algorithms, particularly for benign variants, consistent with earlier observation of poor <lb/>correlations among predictors by Thusberg et al 9 . <lb/>To assess the level of concordance among the most commonly used algorithms we <lb/>reviewed algorithm use in the medical genetics literature between January 2011 and <lb/>January 2017 (see Methods). We found that Polyphen <lb/>10 and SIFT 11 <lb/>are cited most <lb/>frequently followed by MutationTaster <lb/>12 , CADD 13 , PROVEAN 14 , Mutpred 15 and Condel 16 . We <lb/></body>

			<page>6 <lb/></page>

			<body>did not detect any consistent pattern of combinations among these algorithms. In general, <lb/>there seemed to be a bias in usage of some of the 25 algorithms while others, especially the <lb/>more recently developed algorithms, are used less frequently. Predictions from five <lb/>commonly used algorithms (Polyphen, SIFT, CADD, PROVEAN and MutationTaster) <lb/>resulted in higher concordance relative to all 18 algorithms, but with 79% for pathogenic <lb/>variants and only 33% for benign variants (Table 1). <lb/>In addition to lack of full concordance in prediction, we identified 815 of 7346 <lb/>(11.1%) benign variants in ClinVar for which all five commonly used algorithms predicted <lb/>the variant to be pathogenic and conversely 68 of 7473 (0.9%) pathogenic variants in <lb/>ClinVar were predicted benign by all algorithms, referred to here as false concordances <lb/>(Table 1). In fact, 18.1% (1333/7346) of benign variants were assessed as pathogenic by <lb/>the majority of the 18 algorithms including 79 variants where the benign classification of <lb/>the variant had been reviewed by a ClinVar recognized expert panel (3-star review status) <lb/>suggesting that these are benign and not misclassified variants. <lb/>In comparison, 4.9% <lb/>(373/7473) of ClinVar pathogenic variants were deemed to be benign by the majority of <lb/>algorithms (Supplementary Table 2). Evaluating only three commonly used algorithms <lb/>(Polyphen, SIFT and CADD) resulted in higher concordance for pathogenic (84%) and <lb/>benign (46%) variants, however, coupled with an increase in false concordances (Table 1). <lb/>Not surprisingly, we failed to identify any combinations of algorithms that resulted <lb/>in false concordance of zero and true concordance of 100% among the 18 algorithms <lb/>whose default predictions are publicly available. We generated all possible combinations <lb/>of three (n=816), four (n= 3060) or five (n=8568) algorithms and obtained their true and <lb/>false concordance rates across the 14,819 variants. As before, there was a lower false <lb/></body>

			<page>7 <lb/></page>

			<body>concordance rate and a higher true concordance rate for pathogenic variants relative to the <lb/>benign variants (Fig. 2B). Overall, the concordance among combinations ranged from 85% <lb/>to 67% for a pair to five algorithms, respectively (Table 2). We noted that the best <lb/>performing combinations of algorithms were different for benign and pathogenic variants <lb/>(Supplementary <lb/>Table <lb/>3). <lb/>For <lb/>example, <lb/>for <lb/>benign <lb/>variants <lb/>the <lb/>best <lb/>performing <lb/>combinations of three algorithms consisted of VEST3 <lb/>17 , REVEL 18 and MetaSVM 19 with a <lb/>true concordance rate of 81.3% and a false concordance rate of 2.8 %, whereas for <lb/>pathogenic variants the same combination resulted in a 70% true concordance and a 5.4 % <lb/>false concordance. For pathogenic variants, the best performing trio combination consisted <lb/>of MutationTaster, Mcap <lb/>20 and CADD (Supplementary Table 3). We obtained similar results <lb/>for combinations of four or five algorithms (Supplementary Table 3). In general, many <lb/>different combinations performed better for pathogenic than benign variants (Fig. 2B). <lb/>Taken together, our results suggest that a given combination of algorithms (using <lb/>the publicly available threshold scores) will perform quite differently across benign and <lb/>pathogenic variants with a significant chance of erroneous assertion due to false <lb/>concordance among algorithms. <lb/>These false concordances could potentially bias the <lb/>variant interpretation towards a VUS classification if all the other available variant data <lb/>suggests the opposite assertion. <lb/>Further analysis of algorithm prediction and concordance. <lb/>For some algorithms such as Eigen <lb/>21 , hEAt 22 , GERP 23 etc. cut-offs defining pathogenic or <lb/>benign assertion are either not recommended or inferred arbitrarily. We therefore used <lb/>the actual output scores provided by all 25 algorithms as a continuous variable to identify <lb/>algorithms whose predictions are likely to be concordant independent of the algorithms <lb/></body>

			<page>8 <lb/></page>

			<body>internal cut-offs. A hierarchical clustering of the normalized output scores of 14,819 <lb/>missense variants for each of the algorithms revealed seven clusters (Fig. 2C). All the <lb/>largely evolutionary conservation algorithms such as phyloP <lb/>24 , phastCons 25 , GERP 26 and <lb/>Siphy <lb/>27 belong to different clusters from the metapredictors REVEL, MetaSVM and MetaLR <lb/>(Fig. 2C). <lb/>Comparison of performance of in silico algorithms <lb/>To identify well-performing algorithms with prediction abilities that are robust to the <lb/>nature of a variant, gene constraint and underlying disease mechanism, we quantified <lb/>performance of the in silico algorithms on multiple test datasets by determining the area <lb/>under the receiver operator characteristic curve (AUC) (see Methods). <lb/>We analyzed two overlapping datasets differing in the confidence of variant <lb/>assertions. These were 14,819 ClinVar variants that are assigned at least one star review <lb/>status and 2966 ClinVar variants with concordant scores from at least two laboratories <lb/>(two stars -see Methods). For both datasets, we observed wide variation in performance of <lb/>the algorithms with AUCs ranging from 0.5 to 0.96 (Fig. 3A). We identified several <lb/>algorithms with AUC ≥0.9 in these datasets that did not differ significantly in their <lb/>performance between &gt;1 or &gt;2 star datasets (Fig. 3A). <lb/>We next sought to identify algorithms whose performance did not differ whether a given <lb/>variant resulted in gain-of-function (GOF) or loss of function (LOF) of a gene product by <lb/>analyzing datasets enriched in activating/GOF mutations in oncogenes and LOF mutations <lb/>in TSG which are both pathogenic in cancer development <lb/>28 (see Methods). We also <lb/>separately evaluated 1169 benign and 1427 pathogenic variants in genes linked to diseases <lb/>with primarily recessive mode of inheritance as another proxy for a dataset enriched in <lb/></body>

			<page>9 <lb/></page>

			<body>LOF variants. We did not observe significant differences in performance of algorithms in <lb/>the GOF and LOF datasets including across the high performing algorithms (Fig. 3A). <lb/>Additionally, we analyzed variants in genes that are primarily linked to diseases with <lb/>dominant mode of inheritance. The latter dataset is likely a mixture of LOF and GOF <lb/>variants. <lb/>Again, there was no major departure from the rank-order of the top five <lb/>performing algorithms that we observed in the other datasets (Fig. 3A). <lb/>Finally we explored whether the performance of algorithms were affected by the <lb/>level of constraint on a gene, as defined by the comparing the expected and observed <lb/>missense variants in ExAC <lb/>29 (missense Z scores). We obtained variants in genes with high, <lb/>intermediate or low level of constraint by a missense Z score threshold of &gt;2.5, between 0 <lb/>to 2.49 or less than zero respectively. We did not observe any major changes in the rank-<lb/>order of the algorithms (Fig. 3A). <lb/>Taken together our analyses suggests that the performance of the majority of <lb/>algorithms in current use are unlikely to be affected significantly as a function of the nature <lb/>of a variant or the level of constraint on the gene. The high-performing algorithms are <lb/>robust to these variables and are more likely to give rise to consistent interpretation across <lb/>different variant datasets. <lb/>Evaluation of potential circularity in algorithm analysis <lb/>There is significant concern that the result of analyses such as that described here <lb/>may arise from circularity in data used. For example, REVEL, a meta-predictor whose <lb/>features includes 13 out of the 25 algorithms that we analyzed <lb/>18 , performed best in all nine <lb/>datasets described above. It was possible that the variants we used to assess performance <lb/>of REVEL and other algorithms described here were also included in its training sets, which <lb/></body>

			<page>10 <lb/></page>

			<body>for REVEL included some of the ClinVar and HGMD variants available until October 2015. <lb/>This type of circularity inflates the performance measures of some algorithms and is <lb/>referred to as type I circularity <lb/>30 . To examine the possibility of type 1 circularity inflating <lb/>the performance of algorithms that were trained on HGMD and ClinVar variants, we <lb/>compared performance of all the algorithms in six additional datasets: A) ClinVar Oct2015 <lb/>to Dec2016: This dataset consists of ClinVar missense variants with ≥1-star review status <lb/>that were released between October 2015 and December 2016. B) ClinVar Sept 2016 to <lb/>March 2017: This even more recent set of missense ClinVar variants with ≥1 star is absent <lb/>in ClinVar data releases prior to September 2016. The A and B datasets consists of newer <lb/>variants that are likely to be absent in the training sets of algorithms that were developed <lb/>earlier. In addition, the newer ClinVar variants are also more likely to have been classified <lb/>using ACMG/AMP 2015 guidelines, which recommends only &quot;supporting&quot; weight for in <lb/>silico evidence towards pathogenicity classification. <lb/>Thus, it is likely that the clinical <lb/>laboratory primarily relied on independent clinical and genetic data to come to the final <lb/>variant assertion. C) predictSNPselected <lb/>30 is a benchmark dataset that does not contain the <lb/>CADD training data. D) REVEL test set exclude the variants in HGMD and ClinVar that were <lb/>used for training REVEL <lb/>18 . E) and F) Minus MetaSVM/LR trainset: We removed all the <lb/>variants that were used in training the metapredictors MetaSVM and MetaLR <lb/>19 from our <lb/>ClinVar variant set. These datasets consisted of variants designated &gt;1-star (E) or &gt;2-<lb/>star(F) review status in ClinVar. The resulting predictions of these datasets which removed <lb/>variants used in training different algorithms did not demonstrate a major change in the <lb/>rank order of the top five algorithms that exhibited an AUC&gt;0.9 with REVEL performing the <lb/>best in these datasets (Fig. 3B, Supplementary Fig. 1). <lb/></body>

			<page>11 <lb/></page>

			<body>We next tested if the top performing algorithms suffered from type 2 circularity <lb/>30 , <lb/>which has been described as a caveat introduced due to the reliance of an algorithm&apos;s <lb/>performance on the distribution of pathogenic or benign variants in a protein. Thus, in a <lb/>variant dataset where there are proteins with only pathogenic variants or only benign <lb/>variants (unbalanced dataset) some algorithms tend to perform better than in a dataset <lb/>that have equal number of pathogenic and benign variants per gene (perfectly balanced), <lb/>even if this is not what is biologically present. To this end we compared performance on an <lb/>unbalanced dataset (Varibenchselected <lb/>30 ) and a balanced dataset which includes equal <lb/>number of pathogenic and benign variants per protein in ClinVar (see Methods). Consistent <lb/>with earlier results <lb/>30 we found that FATHMM 31 is particularly sensitive to this type of <lb/>circularity. In other words, there is drop in performance of FATHMM in analysis of a <lb/>dataset that is perfectly balanced (Balanced dataset * in Supplementary Fig. 2). We also <lb/>detected evidence for potential type 2 circularity for algorithms such as MetaSVM/LR and <lb/>MCAP (Balanced vs varibench for MetaSVM, MetaLR and MCAP, bootstrap p value &lt;0.0001, <lb/>Supplementary Fig. 2). Thus, caution should be used in interpreting scores using <lb/>algorithms such as FATHMM as the prediction efficacy is partly dependent on pathogenic <lb/>and benign variant distributions in any given gene. <lb/>Discussion <lb/>The ACMG/AMP guideline for use of in silico algorithms in a clinical setting suggests <lb/>full concordance among multiple algorithms for this type of evidence to be used in <lb/>missense variant classification without further clarification of the number or choice of <lb/>algorithms. As we have shown, such usage leads to discrepancies arising mainly because of <lb/>the lack of specification. Our review of the literature reveals that the metric for <lb/></body>

			<page>12 <lb/></page>

			<body>concordance is not consistent across different laboratories. While some studies have <lb/>adhered to the ACMG/AMP guidelines for strict concordance, others have used a majority <lb/>vote rule. It has been reported that use of the strict ACMG criteria gave rise to a higher rate <lb/>of VUS <lb/>5 and increased discrepancies among laboratory classifications 3 . The lack of a <lb/>standard guidance for incorporating in silico algorithms could potentially lead to increased <lb/>VUS burden and inter-lab discrepancies. <lb/>In addition, we find that frequently used algorithms are older and vary in performance. Our <lb/>analyses identified several high performance relatively newer algorithms which are <lb/>infrequently used such as REVEL, VEST3 etc. Many of these algorithms are ensemble <lb/>predictors incorporating many older algorithms as features. The performances of these <lb/>algorithms are robust to technical artifacts, levels of constraint on genes, the underlying <lb/>nature of variants and Mendelian inheritance pattern. Thus, laboratories may benefit from <lb/>modifying pre-existing variant interpretation pipelines that currently use older algorithms. <lb/>The ACMG/AMP guideline encourages use of multiple algorithms. Conversely, we <lb/>observed an increase in the discordant calls as more algorithms are used to infer variant <lb/>pathogenicity thus hindering the use of in silico evidence. An alternative is to use <lb/>metapredictors that in effect combine multiple individual predictors to generate a score. <lb/>These metapredictors satisfy the concept underlying the multiple algorithm criteria; of <lb/>note, combining them with their constituent predictors for variant interpretation may not <lb/>be ideal. <lb/>In general, we show, using author recommended thresholds for variant assertion, a <lb/>substantial increase in likelihood of discordance, particularly for benign variants. We found <lb/>that for pathogenic variants, the concordance among algorithms were higher most likely <lb/></body>

			<page>13 <lb/></page>

			<body>due to the tendency of several algorithms to call a variant pathogenic leading to incorrect <lb/>inferences. Consistent with this, we found several variants for which multiple algorithms <lb/>made concordant assertions that were opposite to what is reported in ClinVar. Although <lb/>this could be a result of misclassification in ClinVar, we found that a ClinVar designated <lb/>expert panel has interpreted some of these variants. These false concordances are another <lb/>source of error for variant interpretation. The problem of false concordance both increases <lb/>the VUS rate and highlights why it may be inappropriate to increase the ACMG/AMP <lb/>evidence strength for computational algorithms from &quot;supporting&quot; to &quot;moderate&quot; or <lb/>&quot;strong&quot;. We independently identified combinations of algorithms that tend to be more <lb/>concordant via a hierarchical clustering of the output scores of all algorithms. The <lb/>clustering pattern suggested that it is probably best to make inferences separately for <lb/>evolutionary conservation algorithms e.g. GERP and metapredictors. Combining them is <lb/>likely to result in discordant calls. Another alternative may be to calibrate the thresholds <lb/>with known variants in genes under consideration. <lb/>Our results are not designed to identify a single algorithm for use across all genes <lb/>although data suggests that high performing algorithms perform well across many different <lb/>gene and mutation mechanism type. In addition, gene specific algorithms or gene specific <lb/>calibration of algorithms using well-characterized set of benign and pathogenic variants <lb/>may perform better than the general approach described here. We note that several <lb/>algorithms are very sensitive to the multiple sequence alignment <lb/>32 . The performance of <lb/>SIFT and other algorithms within our analyses and others such as Align-GVGD <lb/>33 could <lb/>potentially be improved if gene-specific curated alignments are provided. <lb/>The analyses and the data presented in this article highlights problems associated <lb/></body>

			<page>14 <lb/></page>

			<body>with the strict use of ACMG /AMP guidelines for in silico algorithm usage, provides the <lb/>necessary data and framework for optimization of the ACMG guidelines and offers methods <lb/>to potentially reduce the burden of variants of uncertain significance in clinical variant <lb/>interpretation. <lb/>Online Methods: <lb/></body>

			<div type="availability">Code and data availability: All the data necessary to produce the figures in the <lb/>manuscript and the associated code are included as supplemental data. <lb/></div>

			<body>Variant data and annotation: <lb/>We downloaded the variant_summary.txt files from the ClinVar ftp site for variant used in <lb/>the <lb/>analysis. <lb/>In <lb/>this <lb/>manuscript <lb/>we <lb/>used <lb/>the <lb/>files <lb/>ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar//tab_delimited/archive/variant_summary_2016-<lb/>09.txt.gz <lb/>and <lb/>ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar//tab_delimited/archive/variant_summary_2016-<lb/>12.txt.gz along with their corresponding xml files. We removed all variants whose review <lb/>status were &quot;no assertion criteria provided&quot;. We also excluded any variants of uncertain <lb/>significance from our analysis. We next considered only the missense variants and filtered <lb/>out all the other classes of variants such as frameshift, termination, silent, non-coding etc. <lb/>Finally, we collapsed the Likely pathogenic and Pathogenic variants in one group and Likely <lb/>Benign and Benign variants in another group. Thus, our final data of 14819 variants had <lb/>two levels of clinical significance: Pathogenic and Benign (Supplementary data 1). <lb/>Algorithms and scores: <lb/>We annotated these variants with 25 algorithm scores using dbNSFP and authors&apos; publicly <lb/>available websites (Supplementary table 1). To generate binary predictions, we used the <lb/></body>

			<page>15 <lb/></page>

			<body>threshold recommended by dbNSFP3.2 or by the algorithms&apos; authors. Certain algorithms <lb/>such as MutationTaster, Mutation Assessor, and Polyphen <lb/>have thresholds such that it <lb/>generates more than two classes. We collapsed the &quot;probably damaging&quot; and &quot;possibly <lb/>damaging&quot; classes variants of Polyphen into a single &quot;damaging&quot; class. For MutationTaster <lb/>we collapsed the &quot;A&quot; (disease causing automatic) and &quot;D&quot; (disease causing) classes into a <lb/>single <lb/>&quot;damaging&quot; <lb/>class, <lb/>while <lb/>the <lb/>&quot;N&quot; <lb/>(&quot;polymorphism&quot;) <lb/>or <lb/>&quot;P&quot; <lb/>(&quot;polymorphism_automatic&quot;) <lb/>were <lb/>collapsed <lb/>into <lb/>a <lb/>single <lb/>&quot;Tolerated&quot; <lb/>class. <lb/>For <lb/>MutationAssessor that generates four predictions, the high (&quot;H&quot;) or medium (&quot;M&quot;) <lb/>categories were treated as &quot;Damaging&quot; whereas the low (&quot;L&quot;) or neutral (&quot;N&quot;) categories <lb/>were treated as &quot;Tolerant&quot;. LRT predictions in dbNSFP gives three classes namely <lb/>&quot;Damaging&quot;, &quot;Neutral&quot; and &quot;Unknown&quot;. We treated the &quot;Unknown&quot; labels as no data <lb/>available or NA in our analysis. For certain algorithms such as SIFT, MutationTaster, <lb/>PROVEAN and FATHMM multiple scores for a given variant corresponding to different <lb/>transcripts are provided by dbNSFP. We used the most damaging score predicted by the <lb/>corresponding algorithm for a given variant in our analyses. <lb/>Literature search <lb/>To identify the frequency of usage of algorithm from the year 2011 to 2017 we conducted a <lb/>literature <lb/>search <lb/>in <lb/>PubMed <lb/>(search <lb/>date <lb/>Jan <lb/>19, <lb/>2017) <lb/>using <lb/>PubmedReminer <lb/>(http://hgserver2.amc.nl/cgi-bin/miner/miner2.cgi) using the following search string: <lb/>&quot;humans&quot;[MeSH Terms] AND Medical Genetics[filter] AND (&quot;SOMATIC&quot;[ALL FIELDS] OR MISSENSE[ALL FIELDS] OR GERMLINE[ALL <lb/>FIELDS] OR (&quot;mutation&quot;[MeSH Terms] OR &quot;mutation&quot;[All Fields]) OR VARIANT[All Fields] OR (&quot;polymorphism, genetic&quot;[MeSH Terms] <lb/>OR (&quot;polymorphism&quot;[All Fields] AND &quot;genetic&quot;[All Fields]) OR &quot;genetic polymorphism&quot;[All Fields] OR &quot;polymorphism&quot;[All Fields]) AND <lb/>(dbnsfp[all fields] OR POLYPHEN[ALL FIELDS] OR SIFT[ALL FIELDS] OR VEST3[All Fields] OR METASVM[ALL FIELDS] OR METALR[ALL <lb/>FIELDS] OR CONDEL[ALL FIELDS] OR CADD[ALL FIELDS] OR MUTATIONASSESSOR[ALL FIELDS] OR PROVEAN[ALL FIELDS] OR <lb/>FATHMM[ALL FIELDS] OR EIGEN[ALL FIELDS] OR MUTPRED[ALL FIELDS] OR &quot;REVEL&quot;[ALL FIELDS] OR DANN[All Fields] OR LRT[All <lb/>Fields] OR MUTATIONTASTER[All Fields] OR GERP[All Fields] OR VEST3[All Fields] OR Genocanyon[All Fields] OR fitcons[All Fields] OR <lb/>phastcons[All Fields] OR phylop[All Fields]) AND (&quot;2011/01/01&quot;[PDAT] : &quot;2017/12/31&quot;[PDAT]) NOT (18570327[UID] OR <lb/>19734154[UID] OR 20052762[UID] OR 20642364[UID] OR 23990819[UID] OR 22077404[UID] OR 21763417[UID] OR 21457909[UID] <lb/>OR 21480434[UID] OR 21412949[UID] OR 23033316[UID] OR 22949387[UID] OR 22689647[UID] OR 22539353[UID] OR <lb/>27577208[uid] OR 27468419[uid] OR 27357839[uid] OR 27224906[uid] OR 27148939[uid] OR 27147307[uid] OR 27128317[uid] OR <lb/>23620363[UID] OR 23315928[UID] OR 27841654[uid] OR 27721395[uid] OR 27760515[uid] OR 27564391[uid] OR 27995669[uid] OR <lb/></body>

			<page>16 <lb/></page>

			<body>24487276[UID] OR 24205039[UID] OR 25073475[UID] OR 25684150[UID] OR 26555599[uid] OR 27776117[UID] OR 26426897[uid] <lb/>OR 26332131[uid] OR 27666373[UID] OR 26982818[uid] OR 26892727[uid] OR 26885647[uid] OR 26866982[uid] OR 26727659[uid] <lb/>OR 26681807[uid] OR 26633127[uid] OR 26677587[uid] OR 26504140[uid] OR 26269570[uid] OR 26015273[uid] OR 24675868[uid] <lb/>OR 24648498[uid] OR 24651380[uid] OR 24453961[uid] OR 24451234[uid] OR 24338390[uid] OR 24332798[uid] OR 25979475[uid] <lb/>OR 25967940[uid] OR 25851949[uid] OR 25599402[uid] OR 25587040[uid] OR 25557438[uid] OR 25552646[uid] OR 25535243[uid] <lb/>OR 25519157[uid] OR 25393880[uid] OR 23020801[uid] OR 22937107[uid] OR 22747632[uid] OR 22322200[uid] OR 22261837[uid] <lb/>OR 22110703[uid] OR 22192860[uid] OR 21925936[uid] OR 21919745[uid] OR 21814563[uid] OR 25117149[uid] OR 24980617[uid] <lb/>OR 24718290[uid] OR 24194902[uid] OR 23954162[uid] OR 23935863[uid] OR 23819846[uid] OR 23843252[uid] OR 23836555[uid] <lb/>OR 23462317[uid] OR 23424143[uid] OR 23357174[uid] OR 21685056[uid] OR 21520341[uid] OR 20866645[uid] OR 20689580[uid] <lb/>OR 20625116[uid] OR 20084173[uid] OR 19602639[uid] OR 19105187[uid] OR 18990770[uid] OR 18654622[uid] OR 18325082[uid] <lb/>OR 18384978[uid] OR 18195713[uid] OR 18186470[uid] OR 18179889[uid] OR 18005451[uid] OR 17989069[uid] OR 17537827[uid] <lb/>OR 27058395[uid] OR 26567478[uid] OR 26095143[uid] OR 22997091[uid] OR 22038522[uid] OR 20660939[uid] OR 20224765[uid] <lb/>OR 19217021[uid] OR 18361419[uid] OR 18210157[uid] OR 17349045[uid] OR &quot;REVIEW&quot;[PUBLICATION TYPE] OR &quot;REVIEW <lb/>LITERATURE AS TOPIC&quot;[MESH TERMS] OR REVEL[AU] OR DANN[AU] OR 26566084[uid] OR 26328548[uid] OR 26054510[uid] OR <lb/>24369116[uid] OR 23824587[uid] OR 22974711[uid] OR 20717976[uid] OR 20613780[uid] OR 18797516[uid] OR 23223146[uid] OR <lb/>26025364[uid] OR 26961892[uid] OR 26098940[uid] OR 25878120[uid] OR 25340732[uid] OR 24740809[uid] OR 24442417[uid] OR <lb/>24266904[uid] OR 24065196[uid] OR 24037343[uid] OR 23571404[uid] OR 23148107[uid] OR 21827660[uid] OR 21536091[uid] OR <lb/>21107268[uid] OR 19648217[uid] OR 19116934[uid] OR 18615156[uid] OR 18463975[uid] OR 18252211[uid] OR 18161052[uid] OR <lb/>24482837[uid] OR 23274505[uid] OR 22940547[uid] OR 22912676[uid] OR 21575667[uid] OR 19786005[uid] OR 19562469[uid] OR <lb/>19444471[uid] OR 19255159[uid] OR 19142206[uid] OR 19138047[uid] OR 18991109[uid] OR 18602337[uid] OR 18552399[uid] OR <lb/>18541031[uid] OR 18357615[uid] OR 18203168[uid] OR 17722232[uid] OR 17456336[uid] OR 17431481[uid] OR 17375033[uid] OR <lb/>17375033[uid] OR 17375033[uid] OR 17375033[uid] OR 28093075[uid]) <lb/>Briefly we restricted our analysis to the medical genetics literature and excluded reviews <lb/>and technical papers reporting discovery and comparative analysis of algorithms as <lb/>defined by the above search term. We obtained 507 of articles that mentioned an algorithm <lb/>in the Title or abstract. The number of articles per algorithm term was used as a proxy for <lb/>the usage of algorithms used in our analysis. <lb/>Concordance analysis: <lb/>To determine concordance among algorithms we obtained the publicly available thresholds <lb/>(Supplementary table 1) to define a dataset of pathogenic and benign prediction for each <lb/>variant. <lb/>We <lb/>next <lb/>generated <lb/>all <lb/>possible <lb/>pairwise <lb/>combinations <lb/>of <lb/>algorithms <lb/>and <lb/>determined the proportion of variants for which they agree with each other. Next we also <lb/>generated all possible combinations of algorithms with 3, 4 or 5 members and determined <lb/>the concordance with ClinVar assertions for each of these pairs. We also determined the <lb/>fraction of variants for which algorithms in each combination was concordant but the <lb/>assertion was opposite to that designated in ClinVar. We refer to these instances as false <lb/></body>

			<page>17 <lb/></page>

			<body>concordances. A list of such combinations and their true and false concordances are <lb/>provided in the Supplemental data 2-6. <lb/>Clustering: <lb/>The scores for 25 algorithms for each of the 14,819 variants were used to cluster the <lb/>algorithms using pvclust package in the R programming environment. We identified the <lb/>most confident clusters by using 50000 bootstrap replicates of the data , Euclidean distance <lb/>as a measure of similarity and ward&apos;s D2 method of hierarchical clustering as implemented <lb/>in the pvclust function <lb/>34 . We called clusters as stable if they had a 0.99 or above probability <lb/>of having the same members in the bootstrap replications. The final rendering of the plot <lb/>was done using the dendextend <lb/>35 package in R. <lb/>Performance analysis: <lb/>We compared the performance of each of the algorithms on all datasets separately by <lb/>estimating the area under the curve (AUC) of a receiver operator characteristic (ROC) <lb/>curve and its 99% confidence interval using the OptimalCutpoints library in R. <lb/>We <lb/>estimated significant differences between any two AUCs by using 10000 stratified <lb/>bootstrap replicates of the datasets in question (where each replicate contained the same <lb/>number of benign and controls than in the original sample), calculating AUC for each <lb/>replicate for each and then testing for the statistical significance as implemented in the <lb/>library pROC in R. <lb/>Datasets: <lb/>All the data are available as supplemental data files or are available from the respective <lb/>authors. We provide brief descriptions of the datasets that we used below: <lb/></body>

			<page>18 <lb/></page>

			<body>ClinVar one star: 14,819 ClinVar variants (7346 benign and 7473 pathogenic variants) that <lb/>are assigned one star or above (meaning at least 1 laboratory (primarily clinical <lb/>laboratories) have provided their rationale for variant assertion). <lb/>ClinVar 2 star: 2966 (1914 benign and 1052 pathogenic) ClinVar variants with two star <lb/>status or above. These variants have concordant assertions from at least two independent <lb/>laboratories. <lb/>ClinVar Oct 2015 to December 2016: This dataset contains 6949 (4093 benign and 2856 <lb/>pathogenic) variants in ClinVar that were obtained from the variant_summary.txt file <lb/>released in December 2016 after removing the variants that were present in the October <lb/>2015 data release. <lb/>ClinVar Sept 2016 to March 2017: This is a set of 3792 benign and 1310 pathogenic <lb/>missense variants with one star or above ClinVar review status. These were obtained by <lb/>filtering out the variants in the variant_summary.txt file in ClinVar from September 2016 <lb/>from the variant_summary.txt files from March 2017 in ClinVar. <lb/>Oncogene variants: This dataset consists of 87 benign and 321 pathogenic variants in <lb/>oncogenes as defined by genes having a high oncogene score and a low TSG score as <lb/>described in 28 . <lb/>Tumor suppressor gene variants: This dataset consists of 502 benign and 532 pathogenic <lb/>variants in tumor suppressor genes as defined by genes having a high TSG score and a low <lb/>oncogene score as described in 28 . <lb/>Dominant: This dataset contains variants in genes that were associated with dominant <lb/>mode of inheritance as determined by both <lb/>36 and 37 . There were 480 benign and 1591 <lb/>pathogenic variants in this dataset. <lb/></body>

			<page>19 <lb/></page>

			<body>Recessive: This dataset contains variants in genes that were associated with recessive <lb/>mode of inheritance as determined by both 36 and 37 . There were 1169 benign and 1429 <lb/>pathogenic variants in this dataset. <lb/>REVEL testset: This is the test dataset that contained ClinVar variants (Test Data 2) as <lb/>described in 18 . <lb/>MetaSVM/LR testset: This dataset consisted of 12496 (6275 benign and 6221 pathogenic) <lb/>ClinVar variants (with one or more review status in ClinVar) which did not include the <lb/>variants used in the training sets of MetaSVM/LR. <lb/>predictSNPdsel: This is a benchmark dataset as described in <lb/>30 . It does not contain CADD <lb/>training data. <lb/>Varibenchselected: This is a highly unbalanced dataset as described in 30 . According to the <lb/>authors, more than 98% of all proteins in this dataset contain variants that are either <lb/>&quot;pathogenic&quot; or &quot;neutral&quot;. <lb/>Balanced dataset: This dataset contained 4192 variants in ClinVar (one star or above <lb/>status) with each gene having the same number of benign and pathogenic variants. <lb/>Figure legends <lb/>Figure 1: Concordance among predictions of 18 algorithms for variants in ClinVar. <lb/>Binary predictions made by 18 algorithms for each pathogenic or benign variants in <lb/>ClinVar are shown in upper and lower panel respectively. Each variant is along a row and <lb/>an orange and a green tile depicts a pathogenic or benign call by the corresponding <lb/>algorithm. 14819 variants with ClinVar review status one star or above (A) and 2966 <lb/>variants with ClinVar review status two star or above (B) are shown. <lb/></body>

			<page>20 <lb/></page>

			<body>Figure 2: Concordance among algorithms. <lb/>A) <lb/>Distribution of proportion of variants that had concordant calls by any given pair of <lb/>algorithms (among 18 algorithms) for benign (green) and pathogenic (orange) variants in <lb/>ClinVar. <lb/>B) Scatterplots of true concordance (variant assertion matches ClinVar assertion) vs False <lb/>Concordance (Variant assertion does not match ClinVar assertion) for combinations of 3, 4 <lb/>or 5 algorithms at a time. An orange and a green point depicts the true and false <lb/>concordance of a combination for benign and pathogenic variants, respectively, in ClinVar. <lb/>C) Hierarchical clustering of 25 algorithms with scores for 14819 variants in ClinVar. Red <lb/>rectangles indicate robust clusters with an AU p-value of &gt;0.99 (see methods). <lb/>Figure 3: Performance analysis of algorithms. The AUC of a ROC are plotted for 25 <lb/>algorithms. Vertical dotted line indicates a AUC of 0.9 and 99% confidence intervals for <lb/>each AUC are shown. Blue dots indicate AUC&gt;0.89. A) AUCs of the algorithms across five <lb/>different datasets shown in the panels and described in text. B) AUCs of the algorithms <lb/>across five different datasets (represented in panels) shown in the panels to address type I <lb/>circularity as described in text. <lb/>Table 1: Concordance estimates for benign or pathogenic variants with all 18 or a subset of <lb/>algorithms shown in the last column. <lb/>Table 2: Concordance among combinations of algorithms <lb/></body>

			<div type="annex">Supplementary material. <lb/></div>

			<page>21 <lb/></page>

			<div type="annex">Supplementary Figure 1: Variability in performance of algorithms shown in each panel <lb/>across all analyzed datasets. Performance is measured using AUC and depicted along the y <lb/>axis. The algorithms are sorted by their performance and the datasets the color coded as <lb/>outlined in the legend. The horizontal dotted red line shows an AUC of 0.8. <lb/>Supplementary Figure 2: Performance analysis of algorithms. The AUC of a ROC are <lb/>plotted for 25 algorithms. Vertical dotted line indicates a AUC of 0.9 and 99% confidence <lb/>intervals for each AUC are shown. AUCs of the algorithms across four different datasets <lb/>(represented in panels) to address type II circularity as described in text. <lb/>Supplementary Table 1: Description of algorithms used in the analyses. <lb/>Supplementary Table 2: Number of variants and their review statuses for which majority <lb/>of algorithm assertion was opposite to that in ClinVar. <lb/>Supplementary Table 3: Concordance among different combination of algorithms. <lb/>Supplementary datasets: <lb/>Supplementary data 1: ClinVar dataset of 14819 variants from September 2016 <lb/>Supplementary data 2: True and false concordances for combinations of 2 algorithms <lb/>Supplementary data 3: True and false concordances for combinations of 3 algorithms <lb/>Supplementary data 4: True and false concordances for combinations of 4 algorithms <lb/>Supplementary data 5: True and false concordances for combinations of 5 algorithms <lb/>Supplementary data 6: Dataset with variants in Oncogene and TSG <lb/>Supplementary data 7: Dataset with variants in genes associated with dominant or <lb/>recessive inheritance. <lb/>Supplementary data 8: Variants in ClinVar txt files (October 2015 to December 2016) <lb/>Supplementary data 9: Variant in ClinVar txt files (September 2016 to March 2017) <lb/></div>

			<page>22 <lb/></page>

			<div type="annex">Supplementary data 10: No training variants MetaSVM/LR <lb/>Supplementary data 11: Dataset with variants in genes with different missense Z cutoff <lb/>Supplementary data 12: Balanced dataset <lb/>Supplementary data 13: Benchmark dataset: predictSNPsel <lb/>Supplementary data 14: Benchmark dataset: varibenchsel <lb/>Supplementary data 15: Compiled AUCs of algorithms for different datasets. <lb/>Supplementary data 16: Data after hierarchical clustering using pvclust . <lb/>Supplementary data 17: Code used for generating Figures and some of the supplemental <lb/>data. <lb/></div>

			<div type="acknowledgement">Acknowledgements: <lb/>We grateful to the following people who provided us with algorithm scores for the variants <lb/>and data used in the manuscript: Vikas Pejavar and Pedrag Radiovojac for providing us <lb/>with some of the Mutpred scores, Panos Katsonis and Olivier Lichtarge for providing us <lb/>with hEAt and EA scores. Weiva Sieh and Joseph Rothstein for providing the REVEL test <lb/>data set. This work was supported by NHGRI 5 U01 HG007436-03 grant to SEP. <lb/></div>

			<page>23 <lb/></page>

			<listBibl>References <lb/>1. <lb/>Liu, X., Jian, X. &amp; Boerwinkle, E. dbNSFP: a lightweight database of human nonsynonymous <lb/>SNPs and their functional predictions. Hum Mutat 32, 894-9 (2011). <lb/>2. <lb/>McLaren, W. et al. The Ensembl Variant Effect Predictor. Genome Biol 17, 122 (2016). <lb/>3. <lb/>Amendola, L.M. et al. Performance of ACMG-AMP Variant-Interpretation Guidelines <lb/>among Nine Laboratories in the Clinical Sequencing Exploratory Research Consortium. <lb/>Am J Hum Genet 99, 247 (2016). <lb/>4. <lb/>Landrum, M.J. et al. ClinVar: public archive of interpretations of clinically relevant variants. <lb/>Nucleic Acids Res 44, D862-8 (2016). <lb/>5. <lb/>Maxwell, K.N. et al. Evaluation of ACMG-Guideline-Based Variant Classification of Cancer <lb/>Susceptibility and Non-Cancer-Associated Genes in Families Affected by Breast Cancer. <lb/>Am J Hum Genet 98, 801-17 (2016). <lb/>6. <lb/>Sawyer, S.L. et al. Utility of whole-exome sequencing for those near the end of the <lb/>diagnostic odyssey: time to address gaps in care. Clin Genet 89, 275-84 (2016). <lb/>7. <lb/>Bailey, J.N. et al. EFHC1 variants in juvenile myoclonic epilepsy: reanalysis according to <lb/>NHGRI and ACMG guidelines for assigning disease causality. Genet Med 19, 144-156 <lb/>(2017). <lb/>8. <lb/>Liu, X., Wu, C., Li, C. &amp; Boerwinkle, E. dbNSFP v3.0: A One-Stop Database of Functional <lb/>Predictions and Annotations for Human Nonsynonymous and Splice-Site SNVs. Hum <lb/>Mutat 37, 235-41 (2016). <lb/>9. <lb/>Thusberg, J., Olatubosun, A. &amp; Vihinen, M. Performance of mutation pathogenicity <lb/>prediction methods on missense variants. Hum Mutat 32, 358-68 (2011). <lb/></listBibl>

			<page>24 <lb/></page>

			<listBibl>10. <lb/>Adzhubei, I.A. et al. A method and server for predicting damaging missense mutations. Nat <lb/>Methods 7, 248-9 (2010). <lb/>11. <lb/>Ng, P.C. &amp; Henikoff, S. SIFT: Predicting amino acid changes that affect protein function. <lb/>Nucleic Acids Res 31, 3812-4 (2003). <lb/>12. <lb/>Schwarz, J.M., Rodelsperger, C., Schuelke, M. &amp; Seelow, D. MutationTaster evaluates <lb/>disease-causing potential of sequence alterations. Nat Methods 7, 575-6 (2010). <lb/>13. <lb/>Kircher, M. et al. A general framework for estimating the relative pathogenicity of human <lb/>genetic variants. Nat Genet 46, 310-5 (2014). <lb/>14. <lb/>Choi, Y., Sims, G.E., Murphy, S., Miller, J.R. &amp; Chan, A.P. Predicting the functional effect of <lb/>amino acid substitutions and indels. PLoS One 7, e46688 (2012). <lb/>15. <lb/>Li, B. et al. Automated inference of molecular mechanisms of disease from amino acid <lb/>substitutions. Bioinformatics 25, 2744-50 (2009). <lb/>16. <lb/>Gonzalez-Perez, A. &amp; Lopez-Bigas, N. Improving the assessment of the outcome of <lb/>nonsynonymous SNVs with a consensus deleteriousness score, Condel. Am J Hum Genet <lb/>88, 440-9 (2011). <lb/>17. <lb/>Carter, H., Douville, C., Stenson, P.D., Cooper, D.N. &amp; Karchin, R. Identifying Mendelian <lb/>disease genes with the variant effect scoring tool. BMC Genomics 14 Suppl 3, S3 (2013). <lb/>18. <lb/>Ioannidis, N.M. et al. REVEL: An Ensemble Method for Predicting the Pathogenicity of Rare <lb/>Missense Variants. Am J Hum Genet 99, 877-885 (2016). <lb/>19. <lb/>Dong, C. et al. Comparison and integration of deleteriousness prediction methods for <lb/>nonsynonymous SNVs in whole exome sequencing studies. Hum Mol Genet 24, 2125-37 <lb/>(2015). <lb/></listBibl>

			<page>25 <lb/></page>

			<listBibl>20. <lb/>Jagadeesh, K.A. et al. M-CAP eliminates a majority of variants of uncertain significance in <lb/>clinical exomes at high sensitivity. Nat Genet 48, 1581-1586 (2016). <lb/>21. <lb/>Ionita-Laza, I., McCallum, K., Xu, B. &amp; Buxbaum, J.D. A spectral approach integrating <lb/>functional genomic annotations for coding and noncoding variants. Nat Genet 48, 214-20 <lb/>(2016). <lb/>22. <lb/>Katsonis, P. &amp; Lichtarge, O. A formal perturbation equation between genotype and <lb/>phenotype determines the Evolutionary Action of protein-coding variations on fitness. <lb/>Genome Res 24, 2050-8 (2014). <lb/>23. <lb/>Davydov, E.V. et al. Identifying a high fraction of the human genome to be under selective <lb/>constraint using GERP++. PLoS Comput Biol 6, e1001025 (2010). <lb/>24. <lb/>Cooper, G.M. et al. Distribution and intensity of constraint in mammalian genomic <lb/>sequence. Genome Res 15, 901-13 (2005). <lb/>25. <lb/>Siepel, A. et al. Evolutionarily conserved elements in vertebrate, insect, worm, and yeast <lb/>genomes. Genome Res 15, 1034-50 (2005). <lb/>26. <lb/>Cooper, G.M. et al. Single-nucleotide evolutionary constraint scores highlight disease-<lb/>causing mutations. Nat Methods 7, 250-1 (2010). <lb/>27. <lb/>Garber, M. et al. Identifying novel constrained elements by exploiting biased substitution <lb/>patterns. Bioinformatics 25, i54-62 (2009). <lb/>28. <lb/>Vogelstein, B. et al. Cancer genome landscapes. Science 339, 1546-58 (2013). <lb/>29. <lb/>Lek, M. et al. Analysis of protein-coding genetic variation in 60,706 humans. Nature 536, <lb/>285-91 (2016). <lb/>30. <lb/>Grimm, D.G. et al. The evaluation of tools used to predict the impact of missense variants <lb/>is hindered by two types of circularity. Hum Mutat 36, 513-23 (2015). <lb/></listBibl>

			<page>26 <lb/></page>

			<listBibl>31. <lb/>Shihab, H.A. et al. Predicting the functional, molecular, and phenotypic consequences of <lb/>amino acid substitutions using hidden Markov models. Hum Mutat 34, 57-65 (2013). <lb/>32. <lb/>Hicks, S., Wheeler, D.A., Plon, S.E. &amp; Kimmel, M. Prediction of missense mutation <lb/>functionality depends on both the algorithm and sequence alignment employed. Hum <lb/>Mutat 32, 661-8 (2011). <lb/>33. <lb/>Tavtigian, S.V. et al. Comprehensive statistical study of 452 BRCA1 missense substitutions <lb/>with classification of eight recurrent substitutions as neutral. J Med Genet 43, 295-305 <lb/>(2006). <lb/>34. <lb/>Suzuki, R. &amp; Shimodaira, H. Pvclust: an R package for assessing the uncertainty in <lb/>hierarchical clustering. Bioinformatics 22, 1540-2 (2006). <lb/>35. <lb/>Galili, T. dendextend: an R package for visualizing, adjusting and comparing trees of <lb/>hierarchical clustering. Bioinformatics 31, 3718-20 (2015). <lb/>36. <lb/>Berg, J.S. et al. An informatics approach to analyzing the incidentalome. Genet Med 15, 36-<lb/>44 (2013). <lb/>37. <lb/>Blekhman, R. et al. Natural selection on genes that underlie human disease susceptibility. <lb/>Curr Biol 18, 883-9 (2008). <lb/></listBibl>

			<page>27 </page>


	</text>
</tei>
