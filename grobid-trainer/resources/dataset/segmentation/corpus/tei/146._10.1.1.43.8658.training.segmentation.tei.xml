<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Dynamic Page Mapping Policies for Cache Con ict Resolution on <lb/>Standard Hardware <lb/>Theodore H. Romer <lb/>Dennis Lee <lb/>Brian N. Bershad <lb/>Department of Computer Science <lb/>and Engineering <lb/>University of Washington <lb/>Seattle, WA 98195 <lb/>fromer,dlee,bershadg@cs.washington.edu <lb/>J. Bradley Chen <lb/>Division of Applied Sciences <lb/>29 Oxford Street <lb/>Harvard University <lb/>Cambridge MA 02138 <lb/>bchen@das.harvard.edu <lb/>Abstract <lb/>In computer systems with large, physically-indexed, <lb/>direct-mapped caches, a poor mapping from virtual to <lb/>physical pages causes excessive cache con ict misses. <lb/>In a previous paper we proposed a simple hardware de-<lb/>vice, the Cache Miss Lookaside (CML) Bu er, which <lb/>identi es pages that are su ering from con ict misses. <lb/>The operating system can use this information to im-<lb/>plement a dynamic page mapping policy that resolves <lb/>con icts by performing an in-memory copy of one of <lb/>the con icting pages, and updating the virtual to phys-<lb/>ical mappings. In this paper, we propose several dy-<lb/>namic page mapping policies that detect and resolve <lb/>cache con icts using hardware available in existing sys-<lb/>tems, such as a TLB and cache miss counter, to locate <lb/>possible cache con icts. We evaluate the simulated <lb/>performance of a variety of mapping policies, and show <lb/>that a dynamic page mapping policy using standard <lb/>hardware can improve upon the performance of a static <lb/>policy, but is not as e ective as special-purpose hard-<lb/>ware such as an associative cache or a CML bu er. <lb/>We also describe the implementation and performance <lb/>of a software-based dynamic policy on a DEC Alpha <lb/>workstation running DEC OSF/1. <lb/></front>

			<body>1 Introduction <lb/>Modern workstations typically include a large direct-<lb/>mapped second-level cache to reduce the latency of <lb/></body>

            <front>This research was sponsored by a grant from the O ce of <lb/>Naval Research, and an equipment grant from Digital Equip-<lb/>ment Corporation. Bershad was partially supported by a <lb/>National Science Foundation Presidential Young Investigator <lb/>Award. Romer was supported by a National Science Foun-<lb/>dation Graduate Student Fellowship. Lee was supported by a <lb/>gift from the Intel Corporation. Part of the research was con-<lb/>ducted by Chen, Lee, and Romer at the DEC Western Research <lb/>Laboratory. The views and conclusions contained in this doc-<lb/>ument are those of the authors and should not be interpreted <lb/>as representing the o cial policies, either expressed or implied, <lb/>of the University of Washington, Harvard University, the Digi-<lb/>tal Equipment Corporation, the Intel Corporation, or the U.S. <lb/>Government. <lb/></front>

            <body>memory accesses. A direct mapped cache may su er <lb/>from con ict misses, which occur when two memory <lb/>locations compete for the same cache line, even though <lb/>the cache is large enough to hold the current working <lb/>set Hill 87]. Con ict misses cause programs to run <lb/>slowly and with unpredictable execution time. In a <lb/>physically indexed cache the mapping from a virtual <lb/>address to a cache line is determined by the physi-<lb/>cal address to which the virtual address is mapped. <lb/>This mapping provides an opportunity for the operat-<lb/>ing system to eliminate cache con icts by dynamically <lb/>relocating pages in physical memory and updating the <lb/>virtual to physical mapping. <lb/>In order to eliminate cache con icts, a dynamic page <lb/>mapping policy must determine when and where con-<lb/>icts are occurring, and resolve them. In an earlier pa-<lb/>per Bershad et al. 94] we proposed a simple hardware <lb/>device called the Cache Miss Lookaside (CML) Bu er, <lb/>which monitors memory tra c to identify pages that <lb/>are incurring large numbers of cache misses. Pages are <lb/>likely to be con icting with each other if they exhibit <lb/>large numbers of misses in a short period of time and <lb/>they map to the same color, that is, the pages map <lb/>to the same page in the cache. The operating sys-<lb/>tem resolves con icts by copying frequently con icting <lb/>pages elsewhere in physical memory. The destination <lb/>of the copy is a physical page with a color di erent <lb/>from the source page. The application&apos;s virtual pages <lb/>are remapped so that the copy is transparent. We <lb/>use the term recolor to describe the process of copy-<lb/>ing and remapping a con icting page. Our simulations <lb/>showed that the CML bu er eliminates many con icts <lb/>in a large direct mapped cache, and compares favor-<lb/>ably to a more expensive two-way set associative cache <lb/>of equivalent size. Although the CML bu er is not a <lb/>complicated piece of hardware, it does not exist on <lb/>current workstations. <lb/>In this paper, we explore alternative techniques that <lb/>rely on software to detect and eliminate cache con-<lb/>icts. Our goal is to emulate the function of the CML <lb/>bu er using features such as a TLB and a cache miss <lb/>counter that are available on many modern machines. <lb/>With these, we can construct an approximation of the <lb/>current working set to infer the location of cache con-<lb/>icts. We rst simulate a collection of software-based <lb/>techniques using trace-based simulation. This allows <lb/>us to precisely evaluate a range of policies, to explore <lb/>the tradeo s between overhead and e ectiveness, and <lb/>to compare the performance of software-based policies <lb/>to policies that rely on hardware, including the CML <lb/>bu er and a two-way set associative cache. We then <lb/>implement and measure the most promising simulated <lb/>dynamic policy on a modern workstation. <lb/>Our simulation results lead us to conclude that dy-<lb/>namic mapping strategies based on standard hardware <lb/>can improve performance, but are not as e ective as <lb/>those based on the CML bu er hardware, which has <lb/>greater precision and lower overhead. We also show <lb/>that the dynamic policies can reduce execution time <lb/>variability by removing cache con icts that occur when <lb/>the operating system makes a poor initial mapping of <lb/>a virtual page. <lb/>The rest of this paper <lb/>In Section 2, we discuss related work. In Section 3, we <lb/>describe several dynamic page mapping policies that <lb/>can be implemented using existing hardware. In Sec-<lb/>tion 4, we evaluate their impact on performance. In <lb/>Section 5, we describe an implementation and the per-<lb/>formance of the most promising dynamic page map-<lb/>ping policy on a DEC Alpha workstation running Ver-<lb/>sion 2.0 of the DEC OSF/1 operating system. Finally, <lb/>we present our conclusions in Section 6. <lb/>
            2 Related Work <lb/>The interaction between caches and memory man-<lb/>agement has been heavily studied Chiueh &amp; Katz 92, <lb/>Kessler &amp; Hill 92, Lynch 93], mostly in the context of <lb/>static mapping policies. A static mapping policy as-<lb/>signs a page frame to a virtual page at page-in time, <lb/>but unlike the dynamic policies described in this pa-<lb/>per, does not change that mapping as a program ex-<lb/>ecutes. Static policies are simple to implement and <lb/>have low overhead. However, they cannot adapt to <lb/>changing program and system conditions, leading to <lb/>unpredictable cache performance Hosking &amp; Moss 93, <lb/>Wahbe et al. 93, Chaiken &amp; Agarwal 94]. Moreover, <lb/>static policies do not address the problem of con-<lb/>icts between a user-level task and the operating sys-<lb/>tem or between multiple user-level tasks Chen 94, <lb/>Mogul &amp; Borg 91]. <lb/>In this paper, we discuss two static policies that have <lb/>been described in the literature and are used in cur-<lb/>rent systems: Page Coloring and Bin Hopping. Page <lb/>Coloring exploits spatial locality by mapping consecu-<lb/>tive virtual pages to consecutive colors, so that pages <lb/>close together in the virtual address space do not con-<lb/>ict in the cache. Operating systems that implement <lb/>Page Coloring generally hash the virtual page number <lb/>with the process ID before choosing a color to avoid <lb/>con icts between tasks that use the virtual address <lb/>space in similar ways Chiueh &amp; Katz 92]. Bin Hop-<lb/>ping Kessler &amp; Hill 92] cycles through the available <lb/>colors sequentially as pages are faulted in so that pages <lb/>rst used close together in time will map to di erent <lb/>locations in the cache. <lb/>3 Dynamic policies <lb/>A dynamic page mapping policy updates the mappings <lb/>between virtual and physical pages in order to mini-<lb/>mize the number of cache con icts. As an example, <lb/>a simple policy might maintain the invariant that no <lb/>two physical pages of the same color be mapped by the <lb/>TLB simultaneously. If satisfying a TLB miss would <lb/>cause two pages of the same color to be in the TLB, one <lb/>of the pages is copied to a physical page of a di erent <lb/>color. This policy, though simple, can incur excessive <lb/>overhead due to a more complicated TLB miss path <lb/>and frequent recoloring. No consideration is given to <lb/>questions such as \is the potentially con icting page <lb/>actually in con ict with other pages that are in use?&quot; <lb/>or \are cache misses currently a problem?&quot; A good <lb/>policy eliminates con icts, has low overhead, and re-<lb/>colors only when necessary. A bad policy can degrade <lb/>performance because it fails to eliminate con icts, has <lb/>excessive overhead, or recolors unnecessarily. <lb/>In this section, we explore two sets of policies that <lb/>use the TLB to approximate the system&apos;s current <lb/>working set in order to detect con icts. The rst set of <lb/>policies continuously monitor TLB activity in order to <lb/>detect con icts as they occur. The second set of poli-<lb/>cies periodically inspect the TLB to detect potential <lb/>con icts. We refer to the rst set of policies as ac-<lb/>tive and the second set of policies as periodic. We rst <lb/>describe a simple active policy that is easy to under-<lb/>stand and accurately detects con ict misses, but has <lb/>high overhead. We will then progressively re ne this <lb/>policy by trading away accuracy for reduced overhead. <lb/>The policies we explore require that the op-<lb/>erating system monitor references to pages and <lb/>arrange for noti cation on references to spe-<lb/>ci c pages. Modern systems satisfy these re-<lb/>quirements. In a system with a software-lled <lb/>TLB Kane 88, Digital Equipment Corporation 92], <lb/>these mechanisms are easy to support. In other sys-<lb/>tems, virtual memory page protection can be used. <lb/>We will consider one policy that relies on a cache <lb/>miss counter to determine when the cache con ict de-<lb/>tection software should be activated. This type of <lb/>simple performance monitoring hardware is becoming <lb/>increasingly common on high-performance processors <lb/>Digital Equipment Corporation 92, <lb/>Singhal &amp; Goldberg 94, Glew &amp; Wang 94, Shippy 94]. <lb/>3.1 Active policies <lb/>An active policy attempts to prevent con icts by rear-<lb/>ranging pages in physical memory whenever a con ict <lb/>might occur. The active policies discussed in this sec-<lb/>tion do so by maintaining the invariant that all pages <lb/>appearing in the TLB be of di erent colors. The sim-<lb/>plest active policy, which we will call Active-Naive, <lb/>maintains this invariant by recoloring any page which <lb/>would violate the invariant on every TLB miss. This <lb/>policy can reduce con icts by distributing the CPU&apos;s <lb/>references over the cache, but it will recolor exces-<lb/>sively. Data on pages of the same color but not in <lb/>long-term competition for cache space may be unnec-<lb/>essarily copied. <lb/>To avoid resolving false con icts, or con icts that <lb/>are short-lived, the Active-Delay policy allows poten-<lb/>tial con icts to persist brie y. Pages of the same color <lb/>are still not allowed to appear in the TLB, but rather <lb/>than immediately recoloring, the older TLB entry is in-<lb/>validated, and a counter is incremented on each TLB <lb/>miss to one of the two competing pages. Recoloring is <lb/>delayed until the counter reaches a given threshold. In <lb/>e ect, this policy uses the TLB to monitor the memory <lb/>reference stream. Using the TLB this way can reduce <lb/>
            the frequency of recoloring, but at the cost of increased <lb/>TLB and con ict misses relative to the Active-Naive <lb/>policy. <lb/>Recolor overhead can be reduced further by increas-<lb/>ing the delay, but delaying too long eliminates useful <lb/>recolor operations as well as useless ones, and also in-<lb/>creases TLB overhead. The Active-Throttle policy in-<lb/>stead caps the number of recolors in any given time in-<lb/>terval. Since it is unnecessary to detect con icts when <lb/>the throttling mechanism prevents pages from being <lb/>recolored, Active-Throttle allows con icting pages to <lb/>appear in the TLB once the cap has been reached. Af-<lb/>ter a suitable delay, the policy is re-enabled and con-<lb/>icting pages are evicted from the TLB. The Active-<lb/>Throttle policy limits recolor and TLB overhead per <lb/>unit time, but will not resolve con icts that occur <lb/>while the recolor rate is being throttled. <lb/>3.2 Periodic policies <lb/>Periodic policies poll the TLB in search of con icts <lb/>that may already be occurring, rather than preventing <lb/>con icts that have not yet occurred. A periodic pol-<lb/>icy can have lower TLB and recolor overhead than an <lb/>active policy since its intrusiveness is limited by the <lb/>rate of polling. With frequent polling, a periodic pol-<lb/>icy approximates an active one. As polling becomes <lb/>less frequent, overhead drops, but the number of out-<lb/>standing unresolved con icts may increase. <lb/>A simple periodic policy is Periodic-Random, which <lb/>periodically recolors one randomly chosen page that <lb/>appears in the TLB. Since it may recolor pages that do <lb/>not con ict, Periodic-Random may introduce as many <lb/>con icts as it removes. The Periodic-Color policy is <lb/>more selective, scanning the TLB and recoloring one <lb/>page from a set of pages that con ict. <lb/>The Periodic-Random and Periodic-Color policies <lb/>assume that the contents of the TLB accurately re ect <lb/>the current working set. In practice, inactive pages <lb/>can appear in the TLB, causing unnecessary recolors. <lb/>The Snapshot policy is similar to Periodic-Color, but <lb/>lters out these inactive pages. A \snapshot&quot; of the <lb/>working set is periodically taken by ushing the TLB, <lb/>and observing which pages incur TLB misses over a <lb/>short interval. By de nition, the working set consists <lb/>of these pages. The Snapshot policy recolors one page <lb/>from the set of pages that appear to con ict with other <lb/>pages in the snapshot. <lb/>The Snapshot policy assumes that con icting pages <lb/>will continue to con ict long enough to justify recolor-<lb/>ing. If con icts are short-lived, the policy will recolor <lb/>excessively. To con rm that a con ict is long-lived, <lb/>the Snapshot-Delay policy takes a second \con rma-<lb/>tion&quot; snapshot after a speci ed delay time, and only <lb/>recolors a page when it is found to con ict in both the <lb/>original and con rmation snapshots. In Section 4.2, <lb/>we will show that no one setting of the period and <lb/>delay parameters satis es all applications. <lb/>The periodic policies invoke the cache con ict de-<lb/>tection mechanisms at a xed rate, whether or not <lb/>cache misses are occurring. This may lead to exces-<lb/>sive recoloring when the cache miss rate is naturally <lb/>low, or delayed con ict resolution when the cache miss <lb/>rate is high. The Snapshot-Miss policy addresses these <lb/>problems and can be used on systems that provide a <lb/>register containing a count of cache misses. Snapshot-<lb/>Miss is a variant of Snapshot-Delay in which the policy <lb/>parameters are measured in cache misses rather than <lb/>machine cycles. An interrupt is generated when the <lb/>cache miss counter reaches a given threshold, at which <lb/>point the policy takes a snapshot of the working set as <lb/>described above. In e ect, this policy uses the cache <lb/>miss counter to determine when excessive cache misses <lb/>are occurring, and only then monitors the TLB to de-<lb/>termine if those misses are due to con icts, and if so, <lb/>where they are occurring. <lb/>Policy <lb/>Summary <lb/>Advantages <lb/>Disadvantages <lb/>Active-Naive <lb/>Recolor on every TLB miss <lb/>to con icting pages. <lb/>Detects all cache <lb/>con icts in mapped <lb/>memory. <lb/>Excessive <lb/>recoloring. <lb/>Active-Delay <lb/>Recolor after several TLB <lb/>misses to con icting pages. <lb/>Detects most per-<lb/>sistent <lb/>cache <lb/>con icts. <lb/>Excessive <lb/>TLB <lb/>overhead. <lb/>Active-Throttle <lb/>Recolor after several TLB <lb/>misses to con icting pages, <lb/>but with a cap on the re-<lb/>coloring rate. <lb/>Bounded <lb/>copy <lb/>overhead. <lb/>Many con icts may <lb/>not be detected. <lb/>Periodic-Random Periodically recolor a ran-<lb/>domly selected page that <lb/>appears in the TLB. <lb/>Repairs poor initial <lb/>mappings. <lb/>Destroys good ini-<lb/>tial mappings. <lb/>Periodic-Color <lb/>Periodically recolor one of <lb/>a set of pages that con ict <lb/>and appear in the TLB. <lb/>Repairs poor initial <lb/>mappings. <lb/>May recolor inac-<lb/>tive pages. <lb/>Snapshot <lb/>Periodically ush the TLB. <lb/>Recolor when two con ict-<lb/>ing pages reappear in the <lb/>TLB. <lb/>Recolors only active <lb/>pages. <lb/>Recolors <lb/>in <lb/>response to short-<lb/>lived con icts. <lb/>Snapshot-Delay <lb/>Recolor when two pages <lb/>con ict in two consecutive <lb/>snapshots. <lb/>Recolors <lb/>in response to per-<lb/>sistent con icts. <lb/>
            Di cult to deter-<lb/>mine good period <lb/>and delay values. <lb/>Snapshot-Miss <lb/>Measure snapshot interval <lb/>and length in cache misses <lb/>rather than cycles. <lb/>Adapts to cache <lb/>miss rate. <lb/>Requires cache miss <lb/>counter. <lb/>Table 1: Some dynamic page mapping policies. A poor mapping is one which results in excessive cache con icts. <lb/>3.3 Summary <lb/>Table 1 reviews the policies presented in this section, <lb/>and summarizes some of their advantages and disad-<lb/>vantages. Although not shown in the table, all of the <lb/>policies share two disadvantages. First, they may in-<lb/>terpret pages on which there are no actual cache con-<lb/>icts as con icting. For example, suppose that phys-<lb/>ical pages P1 and P2 have the same color, and that <lb/>both are being referenced by the CPU. Even if no ref-<lb/>erence to P1 actually con icts with those to P2 (sup-<lb/>pose that only the top half of P1 and only the bottom <lb/>half of P2 are active), the policies may conclude that <lb/>P1 and P2 con ict. Snapshot-Miss is the least likely to <lb/>exhibit this behavior, because it only activates during <lb/>periods of high cache miss activity. Nevertheless, all <lb/>the software policies are subject to \spoo ng&quot; because <lb/>they do not use information about actual cache misses, <lb/>only apparent ones. A policy that relies on informa-<lb/>tion about true memory tra c, that is, one that uses <lb/>hardware to collect reference information, is unlikely <lb/>to be similarly misled. <lb/>The second disadvantage of the software policies <lb/>is that they are unable to resolve con icts between <lb/>mapped and unmapped pages. A system with a CML <lb/>bu er can detect these con icts because the CML <lb/>bu er snoops on the memory bus, seeing misses to <lb/>both mapped and unmapped pages. The operating <lb/>system can then resolve these con icts by recoloring <lb/>the mapped page. Since unmapped pages do not ap-<lb/>pear in the TLB, the software approach cannot even <lb/>detect that con icts are occuring on these pages. <lb/>4 Simulation methodology and results <lb/>We use trace-driven simulation of ten benchmark pro-<lb/>grams described in Table 4 to evaluate the e ectiveness <lb/>of di erent dynamic policies. We will rst describe <lb/>our methodology and then will describe two groups of <lb/>measurements. The rst group compares all of the dy-<lb/>namic policies from Section 3. The second group com-<lb/>pares the best of these policies to static and hardware-<lb/>based policies. <lb/>4.1 Methodology <lb/>We collected our traces, which include user and <lb/>system references, using epoxie Wall 92] on a <lb/>DECstation 5000/200 running Ultrix 4.2A. The <lb/>simulated memory system, described in Table 2, <lb/>is based on the DEC 3000/500 Alpha worksta-<lb/>tion Dutton et al. 92], which contains an Alpha 21064 <lb/>processor Digital Equipment Corporation 92]. Mem-<lb/>ory references due to TLB misses are not traced di-<lb/>rectly, but are injected into the reference stream dur-<lb/>ing the simulation. The simulated TLB miss han-<lb/>dler includes any overhead incurred by the dynamic <lb/>policies. The simulations assume in nite memory, <lb/>and do not include paging e ects. Additional infor-<lb/>mation about our trace methodology can be found <lb/>in Bershad et al. 94]. <lb/>Page size <lb/>8KB <lb/>Line size <lb/>32 bytes <lb/>First level <lb/>8KB Instruction, 8KB Data <lb/>cache (L1) <lb/>physically indexed <lb/>direct-mapped <lb/>Policy <lb/>write-through, read-allocate <lb/>Write bu er 4 entries <lb/>Miss penalty 5 cycles <lb/>TLB <lb/>16-line ITLB, 32-line DTLB <lb/>no \large&quot; entries <lb/>fully associative <lb/>Second level 512 KB, uni ed, physically <lb/>cache (L2) <lb/>indexed, direct-mapped <lb/>Policy <lb/>write-back, read/write-allocate <lb/>Miss penalty 25 cycles <lb/>Table 2: The simulated memory system. <lb/>Our primary evaluation metric is Memory Cycles <lb/>Per Instruction (MCPI), which is the total number of <lb/>cycles spent servicing cache misses, write bu er stalls, <lb/>and memory management (including TLB misses and <lb/>page mapping policy), divided by the number of user <lb/>and system instructions (excluding memory manage-<lb/>ment). References due to the operating system&apos;s idle <lb/>loop are excluded, since the idle loop has good local-<lb/>ity and arti cially lowers MCPI. Since the rst-level <lb/>caches on the Alpha 21064 are each the same size as a <lb/>page of physical memory, rst-level cache performance <lb/>is largely independent of the mapping policy. Hence we <lb/>focus on memory cycles per instruction due to second <lb/>level cache misses and memory management overhead <lb/>(L2 plus Policy MCPI). <lb/>4.2 Evaluation of dynamic policies <lb/>We simulated static Page Coloring (the default Ultrix <lb/>policy) alone, and combined with each of the dynamic <lb/>policies described in Section 3. We used the parame-<lb/>ters shown in Table 3 to drive the simulator for each <lb/>policy. We selected parameter values that balanced <lb/>con ict elimination with policy overhead. This re-<lb/>sulted in values that were neither extremely large (too <lb/>conservative) or extremely small (too aggressive). <lb/>Policy <lb/>Max recoloring rate Delay <lb/>Active-Naive <lb/>Unbounded <lb/>None <lb/>Active-Delay <lb/>Unbounded <lb/>100 TLB misses <lb/>Active-Throttle 1/(1 10 6 ) cycles <lb/>100 TLB misses <lb/>Periodic-Random 1/(2 10 6 ) cycles <lb/>None <lb/>Periodic-Color 1/(2 10 6 ) cycles <lb/>None <lb/>Snapshot <lb/>1/(2 10 6 ) cycles <lb/>None <lb/>Snapshot-Delay 1/(2 10 6 ) cycles <lb/>200 10 3 cycles <lb/>Snapshot-Miss 1/(10 10 3 ) L2 misses 1 10 3 L2 misses <lb/>Table 3: Parameters of simulated dynamic page map-<lb/>ping policies. <lb/>Figure 1 shows the results of these measurements. <lb/>The gure decomposes MCPI into L2, Recolor, and <lb/>TLB MCPI. L2 MCPI is the actual memory penalty <lb/>due to misses in the second level cache. If a policy has <lb/>lower L2 MCPI than Page Coloring for a particular <lb/>application, then the policy eliminates cache con icts. <lb/>Recolor MCPI is due to the actual copying of pages <lb/>from one portion of physical memory to another. For <lb/>example, Active-Naive, as expected, has a high recolor <lb/>overhead. TLB MCPI re ects the TLB management <lb/>penalty for the given policy. The dynamic policies have <lb/>increased TLB MCPI compared to Page Coloring be-<lb/>cause they use the TLB to collect information about <lb/>the current working set. <lb/>The three active policies perform worse than static <lb/>Page Coloring for the workloads except for straw-<lb/>man, doduc, and tomcatv. Active-Delay and Active-<lb/>Throttle eliminate some of the recolor overhead of <lb/>Active-Naive, and reduce L2 MCPI for most of the <lb/>benchmarks. However, they incur many additional <lb/>TLB misses because the TLB is used to monitor the <lb/>memory reference stream. The additional TLB over-<lb/>head overwhelms the improvement in L2 MCPI. For <lb/>example, both Active-Delay and Active-Throttle re-<lb/>duce the L2 MCPI of gcc-a, but degrade overall per-<lb/>formance. <lb/>Periodic policies address the high overhead of the ac-<lb/>tive policies by monitoring the TLB periodically rather <lb/>than continuously. However, con icts may persist for <lb/>a longer time before resolution. This delay results in a <lb/>larger L2 MCPI component than the active policies in <lb/>some cases, most notably strawman and tomcatv. The <lb/>gure shows that for most of the programs and with <lb/>most of the periodic policies, the reduction in overhead <lb/>compensates for the small increase in con ict misses. <lb/>Despite the reduced overhead, Periodic-Random <lb/>and Periodic-Color still perform worse than Page Col-<lb/>oring in several cases, including gcc-b, splot, and gs. <lb/>The problem with these policies is that some of the <lb/>pages recolored are not currently active. Snapshot <lb/>attempts to address this problem, and slightly out-<lb/>performs both policies for six of the ten benchmarks. <lb/>Snapshot-Delay further improves performance by re-<lb/> L2 plus Policy MCPI <lb/>
            0 <lb/>0.1 <lb/>0.2 <lb/>0.3 <lb/>0.4 <lb/>0.5 <lb/>0.6 <lb/>0.7 <lb/>0.8 <lb/>0.9 <lb/>1 <lb/>Page Coloring <lb/>Active-Naive <lb/>Active-Delay <lb/>Active-Throttle <lb/>Periodic-Random <lb/>Periodic-Color <lb/>Snapshot <lb/>Snapshot-Delay <lb/>Snapshot-Miss <lb/>Page Coloring <lb/>Active-Naive <lb/>Active-Delay <lb/>Active-Throttle <lb/>Periodic-Random <lb/>Periodic-Color <lb/>Snapshot <lb/>Snapshot-Delay <lb/>Snapshot-Miss <lb/>Page Coloring <lb/>Active-Naive <lb/>Active-Delay <lb/>Active-Throttle <lb/>Periodic-Random <lb/>Periodic-Color <lb/>Snapshot <lb/>Snapshot-Delay <lb/>Snapshot-Miss <lb/>Page Coloring <lb/>Active-Naive <lb/>Active-Delay <lb/>Active-Throttle <lb/>Periodic-Random <lb/>Periodic-Color <lb/>Snapshot <lb/>Snapshot-Delay <lb/>Snapshot-Miss <lb/>Page Coloring <lb/>Active-Naive <lb/>Active-Delay <lb/>Active-Throttle <lb/>Periodic-Random <lb/>Periodic-Color <lb/>Snapshot <lb/>Snapshot-Delay <lb/>Snapshot-Miss <lb/>TLB MCPI <lb/>Recolor MCPI <lb/>L2 MCPI <lb/>strawman <lb/>gcc-a <lb/>gcc-b <lb/>cecil <lb/>doduc <lb/>4.81 <lb/>3.02 <lb/>2.76 <lb/>L2 plus Policy MCPI <lb/>0 <lb/>0.1 <lb/>0.2 <lb/>0.3 <lb/>0.4 <lb/>0.5 <lb/>0.6 <lb/>0.7 <lb/>0.8 <lb/>0.9 <lb/>1 <lb/>Page Coloring <lb/>Active-Naive <lb/>Active-Delay <lb/>Active-Throttle <lb/>Periodic-Random <lb/>Periodic-Color <lb/>Snapshot <lb/>Snapshot-Delay <lb/>Snapshot-Miss <lb/>Page Coloring <lb/>Active-Naive <lb/>Active-Delay <lb/>Active-Throttle <lb/>Periodic-Random <lb/>Periodic-Color <lb/>Snapshot <lb/>Snapshot-Delay <lb/>Snapshot-Miss <lb/>Page Coloring <lb/>Active-Naive <lb/>Active-Delay <lb/>Active-Throttle <lb/>Periodic-Random <lb/>Periodic-Color <lb/>Snapshot <lb/>Snapshot-Delay <lb/>Snapshot-Miss <lb/>Page Coloring <lb/>Active-Naive <lb/>Active-Delay <lb/>Active-Throttle <lb/>Periodic-Random <lb/>Periodic-Color <lb/>Snapshot <lb/>Snapshot-Delay <lb/>Snapshot-Miss <lb/>Page Coloring <lb/>Active-Naive <lb/>Active-Delay <lb/>Active-Throttle <lb/>Periodic-Random <lb/>Periodic-Color <lb/>Snapshot <lb/>Snapshot-Delay <lb/>Snapshot-Miss <lb/>tomcatv <lb/>nasa7.2 <lb/>nasa7.3 <lb/>splot <lb/>gs <lb/>2.08 <lb/>1.89 <lb/>2.18 <lb/>Figure 1: Software-Based Dynamic Policies. This gure shows the impact that software-based dynamic page <lb/>mapping policies have on second level cache performance. L2 MCPI is the cost of second level cache misses <lb/>incurred by the application under the given policy. Recolor MCPI includes all cycles spent in dynamic page <lb/>mapping policy code, including the instructions executed and cache misses incurred when recoloring pages. TLB <lb/>MCPI includes all overhead due to TLB misses. Changes in TLB MCPI relative to Page Coloring re ect the <lb/>overhead of software-based con ict detection. <lb/>Benchmark Description <lb/>Memory <lb/>References <lb/>(millions) <lb/>MCPI L2 <lb/>MCPI <lb/>strawman <lb/>a program that repeatedly alternates references to two con icting cache-<lb/>pages. <lb/>16 <lb/>5.79 <lb/>4.81 <lb/>gcc-a <lb/>gcc compiling a 17 KB pre-processed program into Sun-3 assembly code. <lb/>41 <lb/>0.81 <lb/>0.17 <lb/>gcc-b <lb/>gcc compiling a 149 KB program into Sun-3 assembly code. <lb/>279 <lb/>0.50 <lb/>0.13 <lb/>cecil <lb/>a 6000-line unoptimized Cecil program, including the 20-queens problem, <lb/>Towers of Hanoi, the game of Life, and compiler test code. (Cecil is <lb/>a pure object oriented language being developed at the University of <lb/>Washington Chambers 93].) <lb/>248 <lb/>0.56 <lb/>0.16 <lb/>doduc <lb/>Monte-Carlo simulation of the time evolution of a nuclear reactor com-<lb/>ponent described by an 8K input le. (Fortran.) <lb/>368 <lb/>0.38 <lb/>0.12 <lb/>tomcatv <lb/>a program that generates a vectorized mesh. (Fortran.) <lb/>278 <lb/>1.09 <lb/>0.77 <lb/>nasa7.2 <lb/>Fast fourier transform component of the SPEC Nasa7 oating point <lb/>benchmark. (Fortran) <lb/>255 <lb/>0.46 <lb/>0.06 <lb/>nasa7.3 <lb/>Cholesky factorization. (Fortran) <lb/>128 <lb/>0.79 <lb/>0.31 <lb/>splot <lb/>the X11 program splot run four times on four di erent input les. Total <lb/>input le size is 94 KB. <lb/>259 <lb/>0.99 <lb/>0.15 <lb/>gs <lb/>an X11 Postscript previewer on a 251 KB input le. <lb/>667 <lb/>1.09 <lb/>0.22 <lb/>Table 4: Experimental workloads. Memory references, MCPI, and L2 MCPI (MCPI due to second level cache <lb/>misses) were measured on our simulated memory system when using static page coloring as the mapping policy. <lb/>Most programs are written in C. Traces of gs and splot include client, X11 server, and operating system references. <lb/>coloring only when a con ict persists. We were able <lb/>to tune Snapshot-Delay to perform well for di erent <lb/>applications, but there was no single set of parame-<lb/>ter values that worked well for all of the benchmarks. <lb/>The problem is best illustrated by considering doduc <lb/>and tomcatv. Both applications incur con ict misses, <lb/>but at very di erent rates. Using a short period will <lb/>allow the policy to identify closely spaced con icts in <lb/>tomcatv but not to identify the relatively infrequent <lb/>con icts in doduc; using a long period in order to <lb/>identify the widely spaced con icts in doduc will cause <lb/>many of the con icts in tomcatv to remain unresolved. <lb/>This leads us to conclude that elapsed time is not a <lb/>good metric for determining when the dynamic policy <lb/>should be activated. <lb/>The Snapshot-Miss policy uses the count of cache <lb/>misses instead of elapsed time to determine when to <lb/>take action. The policy is invoked quickly during pe-<lb/>riods of high cache miss activity, which is when it is <lb/>needed. Moreover, the frequency with which it is in-<lb/>voked re ects the number cache misses and hence it <lb/>can capture con icts whether they show up frequently <lb/>or infrequently. With a single setting of the parame-<lb/>ters, the policy detects and resolves con icts for both <lb/>doduc and tomcatv. The gure shows that for all <lb/>the benchmarks, Snapshot-Miss either outperforms or <lb/>does as well as all the other software-based policies. <lb/>4.3 Software-based <lb/>and <lb/>hardware-based policies <lb/>We now compare the performance of a good <lb/>software-based dynamic policy to alternative strategies <lb/>for reducing con icts. We measured the performance <lb/>of the two static policies described in Section 2, Page <lb/>Coloring and Bin Hopping, alone, combined with the <lb/>Snapshot-Miss policy, combined with a policy based on <lb/>a CML bu er (CML), and combined with a 2-way asso-<lb/>ciative cache (A2). Figure 2 shows the results of these <lb/>simulations. Comparing just the unaugmented static <lb/>policies, we see that neither Bin Hopping nor Page <lb/>Coloring performs best across all applications. For ex-<lb/>ample, Page Coloring performs better for nasa7.2 and <lb/>splot, while Bin Hopping performs better for doduc and <lb/>tomcatv. The di culty in choosing the correct static <lb/>policy is a key motivation for using a dynamic policy. <lb/>The dynamic policies and the associative cache out-<lb/>perform the static policies for the majority of programs <lb/>because they can adjust to con icts in the memory ref-<lb/>erence stream. While the three techniques di er in the <lb/>cost of con ict resolution, the most important di er-<lb/>ence is the speed with which they identify and resolve <lb/>con icts. The associative cache resolves con icts im-<lb/>mediately with no direct cost 1 and has the best per-<lb/>formance. The CML bu er incurs a small delay be-<lb/></body>

			<note place="footnote">1 However, an associative cache may require an increased <lb/>cache access time. For this discussion, we assume that the access <lb/>time is una ected by the increased associativity. <lb/></note>

			<body>L2 plus Policy MCPI <lb/> 0 <lb/>0.1 <lb/>0.2 <lb/>0.3 <lb/>0.4 <lb/>0.5 <lb/>0.6 <lb/>Page Coloring <lb/>PC + S-Miss <lb/>PC + CML <lb/>PC + A2 <lb/>Bin Hopping <lb/>BH + S-Miss <lb/>BH + CML <lb/>BH + A2 <lb/>Page Coloring <lb/>PC + S-Miss <lb/>PC + CML <lb/>PC + A2 <lb/>Bin Hopping <lb/>BH + S-Miss <lb/>BH + CML <lb/>BH + A2 <lb/>Page Coloring <lb/>PC + S-Miss <lb/>PC + CML <lb/>PC + A2 <lb/>Bin Hopping <lb/>BH + S-Miss <lb/>BH + CML <lb/>BH + A2 <lb/>Page Coloring <lb/>PC + S-Miss <lb/>PC + CML <lb/>PC + A2 <lb/>Bin Hopping <lb/>BH + S-Miss <lb/>BH + CML <lb/>BH + A2 <lb/>Page Coloring <lb/>PC + S-Miss <lb/>PC + CML <lb/>PC + A2 <lb/>Bin Hopping <lb/>BH + S-Miss <lb/>BH + CML <lb/>BH + A2 <lb/>TLB MCPI <lb/>Recolor MCPI <lb/>L2 MCPI <lb/>strawman <lb/>gcc-a <lb/>gcc-b <lb/>cecil <lb/>doduc <lb/>PC -page coloring <lb/>BH -bin hopping <lb/>S-Miss -snapshot -miss <lb/>4.81 <lb/>L2 plus Policy MCPI <lb/>0 <lb/>0.1 <lb/>0.2 <lb/>0.3 <lb/>0.4 <lb/>0.5 <lb/>0.6 <lb/>Page Coloring <lb/>PC + S-Miss <lb/>PC + CML <lb/>PC + A2 <lb/>Bin Hopping <lb/>BH + S-Miss <lb/>BH + CML <lb/>BH + A2 <lb/>Page Coloring <lb/>PC + S-Miss <lb/>PC + CML <lb/>PC + A2 <lb/>Bin Hopping <lb/>BH + S-Miss <lb/>BH + CML <lb/>BH + A2 <lb/>Page Coloring <lb/>PC + S-Miss <lb/>PC + CML <lb/>PC + A2 <lb/>Bin Hopping <lb/>BH + S-Miss <lb/>BH + CML <lb/>BH + A2 <lb/>Page Coloring <lb/>PC + S-Miss <lb/>PC + CML <lb/>PC + A2 <lb/>Bin Hopping <lb/>BH + S-Miss <lb/>BH + CML <lb/>BH + A2 <lb/>Page Coloring <lb/>PC + S-Miss <lb/>PC + CML <lb/>PC + A2 <lb/>Bin Hopping <lb/>BH + S-Miss <lb/>BH + CML <lb/>BH + A2 <lb/>tomcatv <lb/>nasa7.2 <lb/>nasa7.3 <lb/>splot <lb/>gs <lb/>0.77 <lb/>Figure 2: Comparing Software-Based and Hardware-Based Policies. This gure compares the performance of <lb/>software-based and hardware-based mapping policies. For each benchmark two sets of four policies are shown, <lb/>one set based on Page Coloring and one based on Bin Hopping. CML is a policy based on a CML bu er. A2 is <lb/>a two-way associative cache. The categories are as shown in Figure 1. <lb/>fore recoloring a page and su ers from some con ict <lb/>misses that would be resolved by the associative cache. <lb/>Finally, the Snapshot-Miss policy may be delayed by <lb/>as much as the snapshot interval (1,000 cache misses <lb/>for the policy we simulated) and hence incurs con ict <lb/>misses that would have been resolved by a CML bu er. <lb/>As a result, for each static policy, performance is gen-<lb/>erally good for Snapshot-Miss, better for CML, and <lb/>best for A2. <lb/>While most of the programs bene t from added as-<lb/>sociativity, nasa7.2 and nasa7.3 do not. For these pro-<lb/>grams, L2 MCPI is dominated by capacity and com-<lb/>pulsory misses rather than con ict misses. As a re-<lb/>sult, they can perform worse with dynamic policies <lb/>because capacity misses are misidenti ed as con ict <lb/>misses, resulting in analysis and recoloring that pol-<lb/>lute the cache and increase overhead. <lb/>4.4 Summary <lb/>The simulations showed that no one static policy works <lb/>best, and that a dynamic policy based on software or <lb/>a CML bu er can improve the performance of a static <lb/>policy. The Snapshot-Miss policy approaches the per-<lb/>formance of the CML bu er, and has the advantage <lb/>that it can be implemented in existing systems that <lb/>provide the appropriate mechanisms. <lb/>Although the dynamic policies can improve second <lb/>level cache performance, this is only one component of <lb/>overall execution time. Comparing the MCPI numbers <lb/>in Table 4 to the L2 numbers in Figure 2, we see that <lb/>the magnitude of the di erences among di erent poli-<lb/>cies may not be very pronounced, and so end-to-end <lb/>execution time may not be signi cantly a ected except <lb/>in cases of pathological mappings. As the penalty for <lb/>accessing memory increases, the value of eliminating <lb/>con icts will also increase. <lb/>5 Implementation and performance <lb/>In this section, we describe the implementation and <lb/>performance of the Snapshot-Miss policy on a DEC <lb/>Alpha workstation running Version 2.0 of the DEC <lb/>OSF/1 operating system. The Alpha provides su -<lb/>cient support for a software-based dynamic mapping <lb/>policy in the form of cache miss counters and software-<lb/>lled TLBs. The cache miss counters can be con g-<lb/>ured to deliver an interrupt to the processor after every <lb/>4,096 misses to the second level cache 2 . Our imple-<lb/>mentation of Snapshot-Miss operates as follows: every <lb/>32,768 misses, two snapshots are collected, separated <lb/>in time by 4,096 misses. A snapshot is collected by <lb/></body>

            <note place="footnote">2 The Alpha cache miss register operates at a granularity of <lb/>4,096 misses, which is the same order of magnitude as the delay <lb/>setting of 1,000 misses from our simulations of Snapshot-Miss. <lb/></note>

            <body>ushing the TLB and recording the rst 16 pages to <lb/>incur TLB misses. If two or more pages con ict in <lb/>both the rst and second snapshots, one of the pages <lb/>is recolored. <lb/>The implementation required minimal changes to <lb/>the vendor&apos;s operating system. The policy code is con-<lb/>tained in a module devoted to analyzing the snapshots <lb/>and deciding which page, if any, to recolor. Con ict <lb/>detection is triggered by a cache miss counter inter-<lb/>rupt, which required that we de ne a simple interrupt <lb/>handler to initiate a snapshot. A modi ed TLB miss <lb/>handler collects the snapshots during periods of high <lb/>cache miss rates. The implementation complexity and <lb/>overhead of the dynamic policy is summarized in Ta-<lb/>ble 5. <lb/>Operation <lb/>Avg. Cost <lb/>Code Size <lb/>Deliver cache miss <lb/>counter interrupt <lb/>70 cycles <lb/>20 lines of C <lb/>Determine whether <lb/>to record TLB miss <lb/>6.5 cycles <lb/>4 <lb/>PAL <lb/>instructions <lb/>Record TLB miss <lb/>10 cycles <lb/>10 <lb/>PAL <lb/>instructions <lb/>Analyze TLB miss <lb/>info <lb/>11,000 cycles 200 lines of C <lb/>Recolor page and up-<lb/>date page tables <lb/>29,000 cycles 30 lines of C <lb/>Table 5: Dynamic Policy Operations. The cost of de-<lb/>livering cache miss counter interrupts was estimated by <lb/>comparing the execution time of programs with cache <lb/>miss counter interrupts enabled and then disabled. <lb/>The other overheads were measured with the Alpha <lb/>cycle counter. On the Alpha, TLB misses are han-<lb/>dled in PAL code, which is essentially programmable <lb/>microcode. <lb/>5.1 Performance <lb/>We measured the performance of the two static <lb/>mapping policies described earlier: Page Coloring <lb/>and Bin Hopping (the policy that ships with DEC <lb/>OSF/1 Woodman 94]). We then augmented those ba-<lb/>sic policies with the Snapshot-Miss policy. We rst <lb/>describe the e ect on a synthetic benchmark that is <lb/>poorly served by static mapping policies. We then <lb/>describe the end-to-end performance of several appli-<lb/>cations. The trends re ected by our measured end-to-<lb/>end times are not always consistent with our simula-<lb/>tions, which focus only on second level cache behav-<lb/>ior. Moreover, our simulations rely on traces from the <lb/>MIPS architecture, which can introduce di erences in <lb/>the trends. <lb/>A synthetic workload <lb/>The program stab is a symbol table library that uses <lb/>a standard shared library routine to compute a hash <lb/>function. This code is drawn from the Cecil com-<lb/>piler Chambers 93]. If the shared library code and <lb/>the calling routine are mapped to the same cache page <lb/>and are linked at overlapping page o sets within the <lb/>page, performance will su er. In this case, with a <lb/>static policy, the program executes in 18.3 seconds, <lb/>whereas with Snapshot-Miss, execution time drops to <lb/>9.0 seconds. With a non-con icting initial mapping, <lb/>execution time is 8.6 seconds. This synthetic bench-<lb/>mark represents a worst-case scenario, with con icts <lb/>that static policies cannot avoid. For this benchmark, <lb/>the relative location in the virtual address space of <lb/>the pages in con ict is arbitrary, and the time sepa-<lb/>rating page frame allocations for the con icting pages <lb/>is large. As such, the assumptions about relative spa-<lb/>tial and temporal distance between pages in the same <lb/>working set do not hold, and the mappings created by <lb/>Bin Hopping and Page Coloring are essentially ran-<lb/>dom. The dynamic policy serves to correct those poor <lb/>mapping choices which are impossible for the static <lb/>policy to avoid. <lb/>Application workloads <lb/>We measured a subset of the applications presented in <lb/>the Section 4 to evaluate end-to-end performance. The <lb/>workloads, together with elapsed execution times, are <lb/>described in Table 6 along with relative improvements <lb/>and overheads. The di erences between the policies <lb/>are due to the di erence in page mapping and, in the <lb/>case of the dynamic policies, the overhead due to mon-<lb/>itoring the TLB and recoloring pages. The rst only <lb/>a ects the performance of the L2 cache, while the sec-<lb/>ond only increases execution time. Thus any improve-<lb/>ment in execution time with the dynamic policies can <lb/>be attributed to fewer con ict misses in the L2 cache. <lb/>The table shows that no one static policy performs <lb/>best for all the benchmarks. Bin Hopping does bet-<lb/>ter than Page Coloring for four of the eight bench-<lb/>marks (gcc1, tomcatv, gs, and mpeg), but Page Color-<lb/>ing outperforms Bin Hopping for doduc, nasa7.3, and <lb/>nasa7.6. Both policies do about the same for nasa7.2. <lb/>The dynamic policy had only a small e ect on over-<lb/>all performance for mpeg, gs, and gcc1. In three cases <lb/>(doduc with Bin Hopping, tomcatv with Page Coloring <lb/>and nasa7.6 with Bin Hopping) the dynamic policy im-<lb/>proves execution time by removing con icts. However, <lb/>nasa7.2 and nasa7.3 are slowed down by the dynamic <lb/>policy. These programs have a working set much larger <lb/>than the second level cache. The result is that the <lb/>dynamic policy is invoked frequently in response to <lb/>capacity misses, and the interrupt handler and policy <lb/>software pollute the cache, degrading performance. <lb/>5.2 Summary <lb/>Our implementation of Snapshot-Miss for the DEC Al-<lb/>pha workstation shows that it is possible to implement <lb/>a dynamic page mapping policy that has low over-<lb/>head for most applications. The policy has measurable <lb/>and sometimes signi cant performance bene ts when <lb/>a mismatch occurs between the static policy used for <lb/>the initial page mapping and the reference patterns of <lb/>the application. In essence, the dynamic policy helps <lb/>to recover from \mistakes&quot; made by the initial (static) <lb/>policy. Snapshot-Miss is useful for reducing variabil-<lb/>ity between program executions, making it a viable <lb/>alternative for system designers who wish to avoid the <lb/>pathological behavior that can occur with static poli-<lb/>cies but do not want the variations in execution time <lb/>that a random policy tends to cause. <lb/>6 Conclusion <lb/>Dynamic page mapping policies attempt to improve <lb/>application performance by detecting and removing <lb/>con icts in a large physically indexed cache. We com-<lb/>pared static mapping policies to dynamic policies that <lb/>used hardware available on existing systems. We found <lb/>that a policy that uses a cache miss counter to de-<lb/>tect when con icts are a problem and the TLB to de-<lb/>termine the location of these con icts improves per-<lb/>formance in several cases. Performance is most im-<lb/>proved when this accounting function is performed by <lb/>specialized hardware such as a CML bu er. As the <lb/>performance disparity between the CPU and mem-<lb/>ory increases, resulting in larger on-chip caches and <lb/>greater o -chip miss penalties, we expect that mecha-<lb/>nisms that can dynamically adapt to a program&apos;s cache <lb/>access patterns will become increasingly important. <lb/></body>

			<div type="acknowledgement">Acknowledgments <lb/>We could not have completed this project without the <lb/>support of the people at DEC WRL. Alan Eustace <lb/>of DEC WRL provided invaluable assistance through-<lb/>out the course of implementing the dynamic software <lb/>policy on the DEC Alpha workstations. Marc Fi-<lb/>uczynski helped us understand the networking code in <lb/>DEC OSF/1. Je rey Dean, Anthony LaMarca, David <lb/>Grove, Larry Peterson, and Wayne Wong o ered sug-<lb/>gestions on an early draft of this paper. <lb/></div>

			<listBibl>References <lb/>Bershad et al. 94] Bershad, B. N., Chen, J. B., Lee, D., and <lb/>Romer, T. H. Avoiding Cache Misses Dynamically <lb/>in Large Direct-Mapped Caches. In Proc. 6th Inter-<lb/>national Conference on Architectural Support for <lb/></listBibl>

			<body>Bench-<lb/>mark <lb/>Description <lb/>Page Coloring <lb/>Bin Hopping <lb/>Static <lb/>Dynamic <lb/>Static <lb/>Dynamic <lb/>time <lb/>time <lb/>improve-over-recolors time <lb/>time <lb/>improve-over-recolors <lb/>ment head <lb/>ment head <lb/>gcc1 <lb/>The <lb/>full gcc1 SPEC <lb/>benchmark. <lb/>112,079 128 112,388 319 -0.3% 135 <lb/>143 111,548 75 111,335 158 <lb/>0.2% 103 <lb/>60 <lb/>doduc Nuclear reactor <lb/>simulation. <lb/>23,160 210 23,077 119 <lb/>0.4% 8 <lb/>9 23,986 1 23,093 157 <lb/>3.7% <lb/>8 <lb/>7 <lb/>tomcatv The <lb/>full <lb/>tomcatv SPEC <lb/>benchmark. <lb/>33,339 6 26,380 53 20.9% 220 <lb/>345 25,071 24 25,368 32 -1.2% 185 <lb/>111 <lb/>nasa7.2 Fast fourier <lb/>transform. <lb/>26,913 3 27,457 344 -2.0% 33 <lb/>15 26,912 5 28,296 853 -5.1% 63 <lb/>35 <lb/>nasa7.3 Cholesky <lb/>factorization. <lb/>31,571 49 32,540 125 -3.1% 142 <lb/>55 31,651 3 32,748 162 -3.5% 139 <lb/>34 <lb/>nasa7.6 Matrix <lb/>manipulation. <lb/>6,900 11 6,906 21 -0.1% 4 <lb/>2 7,301 4 6,954 36 <lb/>4.7% <lb/>5 <lb/>6 <lb/>gs <lb/>ghostscript <lb/>with a 363 KB <lb/>input le. <lb/>23,236 173 23,109 60 <lb/>0.5% 20 <lb/>11 23,188 139 23,017 127 <lb/>0.7% 19 <lb/>10 <lb/>mpeg <lb/>mpeg play with <lb/>a 217 KB input <lb/>le. <lb/>18,958 591 18,698 409 <lb/>1.4% 27 <lb/>19 17,990 117 17,929 114 <lb/>0.3% 18 <lb/>5 <lb/>Table 6: Static vs. Dynamic Policies. This table shows performance for Page Coloring and for the native OSF/1 <lb/>mapping policy (Bin Hopping), each with and without a dynamic mapping policy. The programs mpeg and gs <lb/>displays images through the X11 server. The columns labeled time and show the mean and standard deviation <lb/>of the execution time for ve runs in milliseconds. The improvement column shows the percentage improvement <lb/>of the dynamic policy over the static policy. The overhead column shows the time attributed to dynamic policy <lb/>overhead in milliseconds. The recolors column shows the total number of pages recolored. <lb/></body>

			<listBibl>Programming Languages and Operating Systems, <lb/>pages 158{170. ACM, 1994. <lb/>Chaiken &amp; Agarwal 94] Chaiken, <lb/>D. <lb/>and <lb/>Agarwal, A. Software-Extended Coherent Shared <lb/>Memory: Performance and Cost. In Proc. 21st In-<lb/>ternational Symposium on Computer Architecture, <lb/>pages 314{324. IEEE, 1994. <lb/>Chambers 93] Chambers, C. The Cecil Language: Speci ca-<lb/>tion and Rationale. Technical Report 93-03-05, Uni-<lb/>versity of Washington, March 1993. <lb/>Chen 94] Chen, J. B. Memory Behavior For An X11 Window <lb/>System. In Proc. Winter 1994 USENIX Confer-<lb/>ence, pages 189{200, January 1994. <lb/>Chiueh &amp; Katz 92] Chiueh, T. and Katz, R. H. Eliminat-<lb/>ing the Address Translation Bottleneck for Physical <lb/>Address Cache. In Proc. 5th International Con-<lb/>ference on Architectural Support for Programming <lb/>Languages and Operating Systems, pages 137{148. <lb/>ACM, 1992. <lb/>Digital Equipment Corporation 92] Digital Equipment Corpo-<lb/>ration. DECchip 21064-AA Microprocessor, Hard-<lb/>ware Reference Manual, 1992. Order Number: EC-<lb/>N0079-72. <lb/>Dutton et al. 92] Dutton, T., Eiref, D., Kurth, H., Reisert, J., <lb/>and Stewart, R. The Design Of The DEC 3000 <lb/>AXP Systems, Two High-Performance Worksta-<lb/>tions. Digital Technical Journal, 4(4):66{81, 1992. <lb/>Special Issue. <lb/>Glew &amp; Wang 94] Glew, A. and Wang, W. Personal commu-<lb/>nication, 1994. <lb/>Hill 87] Hill, M. D. Aspects of Cache Memory and In-<lb/>struction Bu er Performance. PhD dissertation, <lb/>University of California at Berkeley, Computer Sci-<lb/>ences Division, November 1987. Number UCB/CSD <lb/>87/381. <lb/>Hosking &amp; Moss 93] Hosking, A. L. and Moss, J. E. B. Pro-<lb/>tection Traps and Alternatives for Memory Man-<lb/>agement of an Object Oriented Language. In Proc. <lb/>14th ACM Symposium on Operating System Prin-<lb/>ciples, pages 106{119. ACM, December 1993. <lb/>Kane 88] Kane, G. MIPS RISC Architecture. Prentice-Hall, <lb/>Englewood Cli s, NJ, 1988. <lb/>Kessler &amp; Hill 92] Kessler, R. and Hill, M. D. Page Placement <lb/>Algorithms for Large Real-Indexed Caches. ACM <lb/>Transactions on Computer Systems, 10(4), Novem-<lb/>ber 1992. <lb/>Lynch 93] Lynch, W. L. The Interaction of Virtual Memory <lb/>and Cache Memory. PhD dissertation, Computer <lb/>Systems Laboratory, Stanford University, Novem-<lb/>ber 1993. Technical Report CSL-TR-93-587. <lb/>Mogul &amp; Borg 91] Mogul, J. C. and Borg, A. The E ect <lb/>Of Context Switches On Cache Performance. In <lb/>Proc. 4th International Conference On Architec-<lb/>tural Support For Programming Languages And <lb/>Operating Systems, pages 75{84, April 1991. <lb/>Shippy 94] Shippy, D. The Power2+ Processor. In Symposium <lb/>Record, Hot Chips VI, pages 9{18. IBM, August <lb/>1994. Slides. <lb/>Singhal &amp; Goldberg 94] Singhal, A. and Goldberg, A. J. <lb/>Archictectural Support for Performance Tuning: A <lb/>Case Study on the SPARCcenter 2000. In Proc. <lb/>21st International Symposium on Computer Archi-<lb/>tecture, pages 48{59. IEEE, 1994. <lb/>Wahbe et al. 93] Wahbe, R., Lucco, S., Anderson, T. E., and <lb/>Graham, S. L. E cient Software-Based Fault Isola-<lb/>tion. In Proc. 14th ACM Symposium on Operating <lb/>Systems Principles, pages 203{216. ACM, 1993. <lb/>Wall 92] Wall, D. W. Systems for Late Code Modi cation, <lb/>pages 275{293. Springer-Verlag, 1992. <lb/>Woodman 94] Woodman, L. Personal communication, 1994. </listBibl>


	</text>
</tei>
