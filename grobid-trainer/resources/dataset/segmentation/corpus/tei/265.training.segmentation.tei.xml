<?xml version="1.0" ?>
<tei>
	<teiHeader>
		<fileDesc xml:id="_265"/>
	</teiHeader>
	<text xml:lang="en">
			<front>A Taxonomy of Dynamic ATC Visualizations <lb/> Christophe HURTER, Stéphane CONVERSY <lb/> 񮽙 <lb/> Abstract— Air traffic control systems display information <lb/>using multiple visual variables. The research described in this <lb/>paper is an initial effort to develop a theory-driven approach to <lb/>the characterization of user interfaces. We will focus on the <lb/>displayed visual object and deliberately leave aside the <lb/>interaction. In this article, we depict the state of the art in data <lb/>visualization, and we characterize these systems using the Card, <lb/>Mackinlay and Bertin model. This work helps characterize <lb/>images more precisely, refines our understanding of the <lb/>transformations of the raw data that generates them, as well as <lb/>the role of perception in the interpretation of visualization. <lb/> Index Terms— Information Visualization, taxonomy, graphical <lb/>coding. <lb/> </front>
			
			<body> I. INTRODUCTION <lb/>ir traffic control aims to maintain the safety for <lb/>passengers and goods. This task puts them in a complex <lb/>decision making system. They communicate with pilots using <lb/>clearances to keep minimal separation of aircraft. The context <lb/>is highly dynamic; data presented to the air traffic controller <lb/>come from manifold sources: flight plan, radar data, data link, <lb/>metrological data, and supervision systems. The decision must <lb/>be planned in real time and frequently updated. This is the <lb/>reason why the air traffic controllers&apos; display must be sharp, <lb/>and must reduce their cognitive workload. <lb/>The displays used by the air traffic controllers involve <lb/>many animated visual entities. They are constrained by precise <lb/>rules of representation. The richness of these re-presentations <lb/>highlights the paucity of tools currently available to <lb/>differentiate them. The increments of such instruments are <lb/>numerous, in terms of validation, design and safety. The <lb/>objective of this article is to establish the basis to study <lb/>representations, to find out methods of characterization that <lb/>would allow comparisons between representations, and <lb/>eventually to assess them. <lb/>II. INFORMATION VISUALIZATION <lb/>Information visualization (IV) is an expanding field of <lb/>research, but rare are those who have formalized its non-<lb/>artistic approach. In the wide range of existing visualization <lb/>methods, very few of them are actually supported by scientific <lb/>considerations, and even fewer have been formally evaluated <lb/>in a rigorous context. Some are starting to address this issue <lb/>[[25], [28]] and some have summarized it in a framework <lb/>[[ <lb/>ysemic (the perceiver can <lb/>ha <lb/>semiotic to correspond to the meaning of a <lb/>gr <lb/>are perceivable, but they are <lb/>no <lb/>in particular a graphical language <lb/>to <lb/>of IV in <lb/>ge <lb/>, zoom, filter, details on demand, relate, history, <lb/>ex <lb/>[[2 <lb/>18]]. <lb/>The Works of Bertin [[1]], act as a reference: &quot; the graphic &quot; <lb/>is the mono-semantic visual representation of data. We can <lb/>contrast his formalism with music or modern abstract art, in <lb/>which the represented data is pol <lb/>ve different interpretations). <lb/>The aims of visualization techniques have been fairly well <lb/>established [[26]]. According to Bertin, the visual data <lb/>representation has three issues; store data, spread information <lb/>(the communication is carried out with known data in <lb/>advance), process information (the handling and the <lb/>perception of the data allow the analysis and the resolution of <lb/>the problem). Bertin made simple observations of visual <lb/>displays. He introduced seven visual variables: position, size, <lb/>shape, orientation, brightness, color, and granularity. <lb/>Granularity is often translated as texture, but it really means <lb/>granularity (as in the granularity of a photograph). Granularity <lb/>in this sense is also related to the spatial frequency of a <lb/>texture. Thus, he formulated issues of visual decoding and <lb/>proposed techniques for enhancing it. But he eschewed <lb/>principles of vision theory. For psychological theories on <lb/>Bertin&apos;s work, we can consult Kosslyn&apos;s books [[13]]. <lb/>Kosslyn, for instance, introduced the compatibility rules, <lb/>which leads the <lb/>aphical representation. <lb/>Wilkinson [[28]], among other things, has extended the <lb/>classification system of Bertin. He prefers the word aesthetics <lb/>to describe an object in a graphical system, because the word <lb/>perception is subjective rather than objective, and perception <lb/>refers to the perceiver rather than the object. Aesthetics turns <lb/>graphs into graphics so that they <lb/>t the perceptions themselves. <lb/>Mackinlay continued Bertin&apos;s work by presenting tools <lb/>allowing the generation and the validation of graphic <lb/>interfaces [[15]]. It develops <lb/>codify a representation. <lb/>Tufte illustrated the possible application fields <lb/>ographical, historical, economic situations [[26]]. <lb/>Shneiderman classified visualizations according to the <lb/>number of dimensions of the displayed data, to the data <lb/>representation structure (temporal, multi-dimensional, tree, <lb/>networks). He continued his work by identifying seven <lb/>minimal tasks to ensure the visualization of the data [[24]] <lb/>(overview <lb/>tract). <lb/>Card and Mackinlay (C&amp;M) carried out a taxonomy of <lb/>various charts of information in the form of a table [[5]]. This <lb/>taxonomy is partially based on the theory of Bertin. C&amp;M <lb/>applied it to twelve well-known visualizations, such as the <lb/>ordered matrices [[1],[19]], TreeMap [[11]] or ConeTree <lb/>1]]. This article will detail their work in the following <lb/>sections. <lb/> A <lb/></body> 
			
			<front>EUROCONTROL Innovative Research Workshop 2007 <lb/></front>
			
			<page>-253 -<lb/></page>
			
			<body>Tweedy [[25]] doesn&apos;t use the noun visualization, she <lb/>prefers &apos;externalizations&apos; because it indicates the cognitive <lb/>role of interactive visual representation. This article introduces <lb/>one kind of visualization characterization, without the <lb/>interactions available in visualization. This work focuses on <lb/>vi <lb/>ust be <lb/>precisely depicted using taxonomy or a generative procedure. <lb/>The next section will describe the dataflow formalism. <lb/>whic <lb/>easy to handle by the user. Chi detailed the various stages <lb/>this model [[7]]. This data flow model is widely used. <lb/>lor to code the AFL (actual flight level) then the <lb/>A <lb/>e), <lb/>speed). <lb/>between 7.00am and 8.00am is the <lb/>sa <lb/>The ratio type is the full <lb/>ve power of real numbers. <lb/>The t <lb/>rizes th <lb/>s used <lb/>ure. <lb/> B <lb/> ] <lb/> Stevens <lb/> ]] <lb/> Ware <lb/> ]] <lb/>sual representation, therefore interaction will be dealt with <lb/>in another article. <lb/>One of the most important tasks in Data Visualization is to <lb/>understand the cognitive process involved in the perception of <lb/>a representation. To reach this goal, the design space m <lb/>III. DATA FLOW MODEL <lb/> Card, Mackinlay and Shneiderman contribute greatly to our <lb/>knowledge in the field of visualizations [[6]]. They created a <lb/>model (Fig. 1) which describes visualizations as a data <lb/>processing sequence from the raw data to the display. The <lb/>processing is based on structures of intermediate data <lb/>h is <lb/>of <lb/> Fig. 1 : Schematic Dataflow of Information Visualization [[5]] <lb/> This model is based on the management of a data flow. It is <lb/>used in many toolkits (InfoViz [[10]], prefuse, VTK, Tul <lb/>Pajek…) and visualization software (SpotFire [[1]], ILOG <lb/>nVizN [[28]]…). <lb/> ip, <lb/>Discovery [[2]], <lb/> A. Data type <lb/> We define the attributes as the typed date from the dataset, <lb/>and the properties, the visual representation of a data e.g. if we <lb/>use the co <lb/>FL data are the attribute and the color is the (visual) <lb/>property. <lb/>The major distinction we can make for attributes is whether <lb/>their values are: <lb/> 񮽙 Nominal: are only equal or different to other values (e.g. <lb/>aircraft call sign), <lb/> 񮽙 Ordered: obey a &lt; rule (e.g. an aircraft&apos;s number in the <lb/>landing sequenc <lb/> 񮽙 Quantitative: can be manipulated by arithmetic (e.g. the <lb/>aircraft <lb/>The quantitative type can be split into two parts: Interval <lb/>and Ration. <lb/>The Interval can derive the gap between values but cannot <lb/>be null, e.g. the time lapse <lb/>me than 14.00am to 15.00am but we cannot say that <lb/>15.00am is twice 7.00am. <lb/>expressi <lb/>able summa <lb/>e different term <lb/> TABLE 1 <lb/> in the literat <lb/> DATA TYPES <lb/> ertin [[1] <lb/>[[23 <lb/>[[27 <lb/>Nominal <lb/>Nominal <lb/>Category <lb/>Ordinal <lb/>O rdinal <lb/>Integer <lb/>Interval <lb/>Quantitative <lb/>Ratio <lb/>Real number <lb/> B. Data structure <lb/> Bertin has suggested that there are two fundamental forms <lb/>of data: data values and data structures. A similar idea is to <lb/>divide data into entities and relationships. Entities are the <lb/>ob <lb/>rld, the call sign links the <lb/>radar data. If we display over time the position of an aircraft, <lb/>n IV, Metadata mean data derived from other <lb/>d <lb/>e <lb/>): <lb/>e (e.g. sorting variables) <lb/>h between value and structure <lb/>ar <lb/>trinsically different but their <lb/>presentation problems are the same, thus we won&apos;t make <lb/>any special survey for metadata. <lb/>jects we wish to visualize, and relations define the <lb/>structures and patterns that relate entities to each other. <lb/>He defines five data structures: linear, circular, ordered tree, <lb/>un-ordered tree, and volume. The data structure is the link that <lb/>clusters the data. In the ATC wo <lb/>we display a linear data structure. <lb/> C. Data transformation: the metadata <lb/> There is a common misconception about metadata. In a <lb/>database, metadata are the explanation of a database field <lb/>(e.g. AFL is the actual Flight level of the aircraft in a <lb/>dataset). But i <lb/>ata, this is a transformation that creates new data out of th <lb/>existing data. <lb/>Tweedy found four types of data transformations (Fig. 2 <lb/> 񮽙 Values to Derived Values (e.g. mean processing) <lb/> 񮽙 Structures to Derived Structur <lb/> 񮽙 Values to Derived Structures <lb/> 񮽙 Structure to Derived Values <lb/>Transformations that switc <lb/>e more complex. Schneiderman, Card and Mackinlay have <lb/>explained them [[6] p 21-22]. <lb/>Metadata and raw data are in <lb/>re <lb/> Fig. 2 : Types of Informat ion Represented [[25]] <lb/> D. Data sources <lb/> The data source is the same for manifold ATC visualizations. <lb/>We are not exhaustive, but mainly, the radar (aircraft position <lb/> 
			
			<page>- 254 -<lb/></page>
			
			<note place="headnote">EUROCONTROL Innovative Research Workshop 2007 <lb/></note> 
			
			received by the ground radar station), and flight plan (the <lb/>aircraft path from its take-off to its landing) are the principal <lb/>data sources. ODS is the main French radar view displayed for <lb/>the air traffic controllers; Aster is a vertical view of the <lb/>current flying aircraft, Maestro is an Arrival manager, and <lb/>ERATO displays future aircraft conflicts. <lb/> Fi <lb/> ATC visualizations display the same information, thus to <lb/>compare them we need very precise tools. <lb/> g. 3 : ATC Data source <lb/>Fi <lb/> e terms used to depict the radar track. <lb/>different levels of <lb/>cr <lb/>minimum aircraft separation). <lb/>he ATC data structure is linked to the attribute named <lb/>t possible to describe <lb/>th radar image using a dataflow and connections with the <lb/>visual variables of Bertin (Figure 3). <lb/>ation can lead to efficient, accurate visual decoding <lb/>of <lb/>a visualization <lb/>an <lb/>d named them the gulf of Execution (how to <lb/>sol <lb/>s the interface goal. This <lb/>chapter will focus on the gulf of evaluations especially on the <lb/>metrics to compare visual entities. <lb/> g. 4 : the radar track <lb/> The Fig. 4 displays th <lb/> E. Supervision <lb/> Graphics, according to Bertin, have at least three distinct <lb/>uses (c.f. introduction): store, communicate, discover. <lb/>The images of the ATC world are not visualizations <lb/>dedicated to exploration. They are described as supervision, <lb/>because the input data change independently of the user. But <lb/>the user can perform actions on the system; in principle, he <lb/>tries to improve it. Such action has <lb/>iticism: just convenient (giving a direct routing) to critic <lb/>(avoiding <lb/>T <lb/>callsign. <lb/> F. Implementation <lb/> The validation of this transformation model was carried out <lb/>using software. This software respects the data processing <lb/>sequences of the data of Fig. 1. It makes i <lb/>e <lb/>IV. METRICS AND PERCEPTUAL TASK <lb/> Visualiz <lb/>encoded information, but may lead to inefficient, inaccurate <lb/>decoding. <lb/>Bertin identified three distinct levels for <lb/>alysis: elementary (for a single item), intermediate (for a <lb/>group of items), and overall (for all the data). <lb/>One of the most basic problems humans encounter when <lb/>using computers is to know what to do to get the computer to <lb/>solve a particular problem. The second problem is to <lb/>understand the computered results, what is the graphical <lb/>meaning of the displayed data. Norman [[16]] identified these <lb/>two problems an <lb/>ve a problem with a computer) and the gulf of Evaluation <lb/>(what do I see). <lb/>The air traffic controller uses supervision interfaces, thus <lb/>the gulf of execution is reduced. The field of action is limited, <lb/>and the displayed information fit <lb/> . 5 : dataflow implementation <lb/> Cleveland, McGill and then Mackinlay [ <lb/> Fig <lb/> [15]] built scales of <lb/>expressivity (monosemic, but dependant on a precise <lb/>graphical language) and effectiveness (depend on the human <lb/>perceptual capabilities) to assess alternative designs (Fig. 6). <lb/> This scale depends on the data type. The visual property <lb/>higher in the chart is perceived more accurately than those <lb/>lower in the chart. The grey items are not relevant to that type <lb/>of information. The quantitative data type ranking as been <lb/>experimentally verified by Cleveland [[9]]. Independently of <lb/>the data type, the best way to represent the data is to code it <lb/>with a position on a scale. If we want to represent the speed of <lb/>an aircraft (quantitative data), we can use the length of a line <lb/>(speed vector). The aircraft position number in the landing <lb/>sequence (Ordinal) is better coded using the color saturation <lb/>than length. <lb/> Fig. 6 : Mackinlay ranking of perceptual task [[15]] <lb/> Speed vector <lb/>Label <lb/>Leader <lb/>t <lb/>Current aircraft <lb/>osition <lb/>Come <lb/>p <lb/> 
			
			<note place="headnote">EUROCONTROL Innovative Research Workshop 2007 <lb/></note>
			
			<page>-255 -<lb/> </page>
			
			This ranking was built for statistical graphs. Air traffic <lb/>control displays, and other iconic representations of data <lb/>addressed quite different tasks. But this is a starting point of <lb/>better for representing procedural information, <lb/>lo <lb/>representation is accurate but is limited in <lb/>ca <lb/>aivio used the dual coding theory to explain the difference <lb/>ion [[17] ]. <lb/>the Weber–Fechner law. Stevens&apos; power law is <lb/>ge <lb/>ic functions, the results apply <lb/>on <lb/>appear only <lb/>during the users test, but also, provide the metric to adjust the <lb/>ings of the visual objects. <lb/>ent with the least bias and error. But it depends on how <lb/>or other graphic is from a reference axis <lb/>be created with interpolation. If the animation is <lb/>ba <lb/>r of modern personal <lb/>computers, the opportunity exists to make far greater use of <lb/>animation in visualizing information. <lb/>icture in the communication process is well <lb/>re <lb/>imize the choices of design, and <lb/>consolidate current knowledge on the relations between <lb/>representations. <lb/>comparison criteria of the images with their work. They <lb/>propose a table for each function of transformation (Table 2). <lb/> &amp; <lb/> EP <lb/>E <lb/>T <lb/>M E <lb/> m <lb/>erception <lb/>t <lb/> Name D F D&apos; X <lb/>Z T R -[] CP <lb/>research. <lb/> A. Is Text the most powerful representation? <lb/> Despite the fact that the text involves perceptual and <lb/>cognitive processing that helps one to decode a graphic in the <lb/>same way that perceiving color or pattern does, the text entity <lb/>isn&apos;t listed in Mackinlay&apos;s perception ranking. &quot; Images are <lb/>better for spatial structures, location, and detail, whereas <lb/>words are <lb/>gical conditions, and abstract verbal concepts. &quot; Ware [[27] <lb/>p301-307]. <lb/>Graphical perception is highly parallel which works on <lb/>visual properties such as position and color, but has limited <lb/>accuracy. Text <lb/>pacity. The cognitive workload is very high when we are <lb/>reading a text. <lb/>P <lb/>between text and graphical percept <lb/> B. Stimulus vs. sensory <lb/> The Difference Threshold (or &quot;Just Noticeable Difference&quot;) <lb/>is the minimum amount by which stimulus intensity must be <lb/>changed in order to produce a noticeable variation in sensory <lb/>experience. Weber, a medical professor, discovered that the <lb/>intensity of stimuli may not be linearly related to sensation. <lb/>The relation between the stimuli and the sensation is <lb/>formalized in <lb/>nerally considered to provide a more accurate and general <lb/>correlation. <lb/>Cognitive psychologists have recently turned away from <lb/>psychophysics toward a more integrated, ecological approach. <lb/>Because all psychophysical approaches isolate stimuli in order <lb/>to examine their psychometr <lb/>ly to certain restricted, indeed artificial, situations. The <lb/>context is entirely applicable. <lb/>Hence, the Kabuki [[2]] project (DTI R&amp;D) aims to <lb/>propose methods and tools to assess ATC interfaces. The <lb/>design and the checking of the interfaces allow anticipating <lb/>the problems of perception and coherence which <lb/>relative values of parameter sett <lb/> C. Distance and evaluation <lb/> Cleveland and Mackinlay rate the position on the scale as <lb/>the best way to represent a quantitative dimension visually <lb/>(Fig. 6). This reflects the research finding that points or line <lb/>lengths placed adjacent to a common axis that enables <lb/>judgm <lb/>far a point, line, <lb/>[[14], [22]]. <lb/> D. Animation <lb/> Animation can be done on two levels: with the raw data, <lb/>and with the visual representation. With the raw data, new <lb/>data must <lb/>sed on the visual structures, each entity must have a sole <lb/>identifier. <lb/>Animation helps perception with little cognitive workload. <lb/>Patterns in moving data points can be perceived easily and <lb/>rapidly. Given the computing powe <lb/>V. TAXONOMY <lb/>The value of a p <lb/>cognized and one hears the old adage &quot; a picture is worth a <lb/>thousand words &quot; . <lb/>Visualization techniques attempt to provoke intuitive <lb/>appreciation of the salient characteristics of a data set. <lb/>It is necessary to use models of characterization which <lb/>allow the creation of taxonomy and the comparison between <lb/>the images with a metric. The design space thus described will <lb/>make it possible to find the non-explored areas and thus of <lb/>new visualizations. Moreover, this taxonomy will confront the <lb/>choices of representations, highlight the relevance of the <lb/>displayed data, opt <lb/>VI. THE CARD AND MACKINLAY MODEL <lb/> Card and Mackinlay have attempted to establish <lb/> TABLE 2 <lb/> C M R RES <lb/> auto <lb/> NTA <lb/> atic <lb/> ION OD L <lb/> p <lb/>Con roles <lb/>perception <lb/> Y <lb/>The lines correspond to the input data. The column D and <lb/>D&apos; indicate the type of data (Nominal, Ordered, and <lb/>Quantitative). F is a function or a filter which transforms or <lb/>creates a subset of D. Columns X, Y, Z, T, R, -, [] are derived <lb/>from the visual variables of Bertin [[1]]. The image has three <lb/>and a half dimensions: X, Y, Z plus time T. R corresponds to <lb/>the retinal perception which clarifies the method employed to <lb/>represent information visually (color, form, size…). The <lb/>bonds between the graphic entities are noted with &apos;-&apos;, and the <lb/>concept of encapsulation is symbolized by &apos;[]&apos;. Finally a <lb/>di inction is made if the representation of the data is treated <lb/>by ur perceptive system in an automatic or controlled way. <lb/>st <lb/>o <lb/> 
			
			<page>- 256 -<lb/></page>
			
			<note place="headnote">EUROCONTROL Innovative Research Workshop 2007 <lb/></note> 
			
			TABLE 3 <lb/>C&amp;M CHARACTERIZATION LEGEND <lb/> L <lb/>Line <lb/>S <lb/>Size <lb/>f <lb/>Function <lb/>N, O, Q <lb/>Nominal, Ordered, Quantitative <lb/>Lon, Lat <lb/>Longitude, Latitude <lb/>P <lb/>Point <lb/>O <lb/>Orientation <lb/>Fig. 7 : ASTER comet <lb/>Fig. 8 : Radar comet <lb/> A. ASTER Comet <lb/> The ASTER comet (Fig. 7) is coded by a form positioned in <lb/>(X, Y) on the screen. X screen is the distance between an <lb/>aircraft and its delivery point at the end of the sector, and Y <lb/>screen codes the flight level. The size of comet is a function of <lb/>the ground speed. The vertical speed is coded by the <lb/>ori ntation of the comet. Table 4 describes, with the model of <lb/>C&amp;M, the main graphical t <lb/>ation of the data set to the <lb/>ASTER comet. <lb/> LE <lb/> COMET CHARACTERIZATION <lb/> e <lb/>ransform <lb/> TAB 4 <lb/>ASTER <lb/>Name <lb/>D <lb/>F D&apos; X Y Z T R -[] <lb/>C P <lb/>Plot <lb/>Lat Lon <lb/>(Q ) <lb/>Shape <lb/> xQ <lb/>f <lb/>Q <lb/>P <lb/>Afl <lb/>Q <lb/>f <lb/>Q <lb/>P <lb/>Vert. speed <lb/>Q <lb/>f <lb/>Q <lb/>O <lb/>speed <lb/>Q <lb/>f <lb/>Q <lb/>S <lb/> B. ODS Comet <lb/> The last positions of the aircraft merge by effect of Gestalt <lb/>continuity [[12]], which makes a line emerge with its <lb/>particular characteristics (curve, regularity of the texture <lb/>formed by the points, etc). It is not possible to characterize it <lb/>directly using the C&amp;M transformation model. But we can <lb/>characterize individually the shapes which build the comet <lb/>(T <lb/>indicates <lb/>the opposite. The wealth of information transmitted by each <lb/>representation is thus n <lb/>tly interpretable in the <lb/>char <lb/>zat ns: th <lb/>o adapted. <lb/> L <lb/> C&amp;M <lb/>C <lb/> able 5). With this intention, we introduce the concept of <lb/>current time (Tcur: the time when the image is displayed). The <lb/>size of the square is linearly proportional to its age. <lb/>The characterization cannot integrate the result of the <lb/>analysis by the controllers of the evolution of the last positions <lb/>of the aircraft (speed, evolution of speed and direction). Thus, <lb/>in Fig. 8, the shape of the comet indicates that the plane <lb/>turned 90° to the right and accelerated. These data are <lb/>emergent in the comet. In other words, they were not directly <lb/>used to generate the image. The characterization of C&amp;M does <lb/>not make it possible to characterize this essential information <lb/>for the users, and thus does not allow the comparison of <lb/>different visualizations objectively. The radar comet is richer <lb/>than the Aster comet; the characterization of C&amp;M <lb/>ot direc <lb/>acteri io <lb/>e model of C&amp;M is n t <lb/> TAB E 5 <lb/>RADAR OMET <lb/> N ame <lb/>D <lb/>F <lb/>D&apos; <lb/>X Y Z T R -[] <lb/>CP <lb/>X <lb/>Q <lb/>on <lb/>L <lb/>L <lb/>f <lb/>Q <lb/>on <lb/>P <lb/>Q <lb/>Lat <lb/>P <lb/>Shape <lb/> Y <lb/>Q <lb/>Lat <lb/>f <lb/>T <lb/>Q <lb/>f(Tcur) <lb/>Q <lb/>S <lb/>emerge <lb/> C. Comet comparison <lb/> The characterization of the radar speed vector (Table 6) <lb/> shows that its size (Bertin&apos;s <lb/>, but as it is a line, we can <lb/>use the length), changes with the aircraft&apos;s speed. <lb/> TABLE 6 <lb/>M PEED VECTOR CHARACTERISATION <lb/> notation <lb/> C&amp; S <lb/>Name <lb/>D <lb/>F <lb/>D&apos; <lb/>X <lb/>Y <lb/>Z T R -[] CP <lb/>speed <lb/>Q <lb/>f <lb/>Q <lb/>S <lb/>direction <lb/>f <lb/>O <lb/> In addition, the same information is coded by the length of <lb/>ASTER comet and by the speed vector of the radar&apos;s comet. <lb/>The ASTER comet is thus equivalent to the radar&apos;s speed <lb/>vector, modulo a translation. It is the characterization and its <lb/>co parison which allows it to link two visualizations, and <lb/>ements of analysis. This result <lb/>e with its <lb/>pa <lb/>teria. <lb/>Th interpretation of the complete characterization of an <lb/>image is very complex (too many tables). It is thus advisable <lb/>to extend th <lb/>a new model. <lb/>acterization of <lb/>vi <lb/>m <lb/>thus to give to the designer el <lb/>shows the importance of the work carried out. <lb/> D. C&amp;M Model conclusion <lb/> The results showed that it is possible to apply such a <lb/>characterization but it is not sufficiently precise. The radar <lb/>comet (Fig. 4) displays the last positions of the plane <lb/>(increasingly small squares according to their age) clustered <lb/>by the Gestalt continuity, which makes a line emerg <lb/>rticular characteristics (curve, regularity of the texture <lb/>formed by the points, etc). It is not possible to characterize it <lb/>directly using the model of transformation of C&amp;M. <lb/>Moreover, it misses the metric for the comparison cri <lb/>e <lb/>e C&amp;M model again, or to use <lb/>VII. PROSPECTS <lb/>The realization of this taxonomy makes it possible to <lb/>consolidate current knowledge on the char <lb/>sualization as our knowledge on the design, perception and <lb/>the relations between them. The C&amp;M model gives some <lb/>comparison items but is not accurate enough. <lb/>This article captures a state of the art in Information <lb/> 
			
			<note place="headnote">EUROCONTROL Innovative Research Workshop 2007 <lb/></note>
			
			<page>-257 -<lb/></page> 
			
			ov <lb/>a common framework applicable to every display. A good <lb/>trial is to find the <lb/>tween views. It <lb/>ea <lb/>the contributi <lb/>St <lb/>nts and suggestions. <lb/>This work is supported by a PhD scholarship from the DTI <lb/>R&amp;D and ENAC LI <lb/>nership of the IRIT <lb/> phic Information Processing &quot; deGruyter <lb/>In Proc. Information Visualization <lb/>98 Information Visualization <lb/>, A Taxonomy of Visualization Techniques using the Data State <lb/>stics, <lb/>R., Graphical Perception: Theory, <lb/>InfoVis Toolkit InfoVis&apos;04, Austin, TX, Oct <lb/>h to the visualization of hier-archical information structures. <lb/>y Routledge 1935. <lb/>88. Applying a theory of graphical presentation to the <lb/>k: Holt, Rinehart, and <lb/>c Symposium on information Visualization. <lb/>.K. &quot; A Methodology for choosing Data Representations &quot; <lb/>hierarchical information, 1991 in Proceedings of the <lb/>54-465. <lb/>erman, B. 1996. The Eyes Have It: A Task by Data Type <lb/>ors in computing systems, CHI 97.pp.375-382.ACM-PRESS <lb/>E.R. The Visual Display of Quantitative Information, Graphics <lb/>an <lb/>Kaufmann. <lb/>[28] Wilkinson, L. The grammar of Graphics. New York: Springer Verlag, <lb/>1999. <lb/>[29] Zhang J. &quot; A representational analysis of relational information displays &quot; <lb/>International Journal of Human Computer Studies, 1996,45, pp59-74 <lb/> Visualization. The next part of our job will be to use all those <lb/>techniques to characterize ATC visualization, and to disc er <lb/> [2 <lb/> minimum differences be <lb/>is <lb/> [ <lb/> sier to describe small modifications than huge changes. <lb/>
			
		</body>

		<back>
			
			<div type="acknowledgement">ACKNOWLEDGEMENTS <lb/>The author gratefully acknowledges <lb/>ons of <lb/> 1997. <lb/>[26] Tufte, <lb/> ephane CONVERSY (thesis co-director), Jean-Luc VINOT. <lb/>A special thanks to all the members of the DTI for their <lb/>discussions, comme <lb/>I, with the part <lb/>Toulouse, France. <lb/></div>
		
			<listBibl>REFERENCES <lb/> [1] Ahlberg, C. 1996. Spotfire: an information explora-tion environment. <lb/>SIGMOD Rec. 25, 4 (Dec. 1996), 25-29. <lb/>[2] Athènes, S., Conversy, S., Vinot, JL., projet Kabuki, NT05-886, DTI <lb/>R&amp;D 2005 <lb/>[3] Baudel, T. 2004. Browsing through an information visualization design <lb/>space. CHI &apos;04. ACM Press, New York, 765-766. <lb/>[4] Bertin J. &quot; Graphics and Gra <lb/>Press, Berlin, 1977. <lb/>[5] Card, S.K., Mackinlay, J.D. 1997 The Structure of the Information <lb/>Visualization Design Space. <lb/>Symposium &apos;97, pages 92-99. <lb/>[6] Card, S., Mackinlay, J, Shneiderman, B. 19 <lb/>Readings in Information Visualization:Using Vision to Think. Morgan <lb/>Kaufman, introduction p 1-34. <lb/>[7] Chi, Ed. <lb/>Reference Model. InfoVis &apos;00. IEEE Press. <lb/>[8] Cleveland, William S., A Model for Studying Display Methods of <lb/>Statistical Graphics, Journal of Computational and Graphical Stati <lb/>Vol. 2. <lb/>[9] Cleveland, W.S., McGill, <lb/>Experimentation, and Application to the Development of Graphical <lb/>Methods. Journal of the American Statistical Association 79 1984. <lb/>[10] Fekete, J.D. 2004. The <lb/>2004. IEEE Press. pp. 167-174 <lb/>[11] Johnson B. and Shneiderman B. 1991, Tree-maps: A Space-filling <lb/>approac <lb/>IEEE Visualization &apos;91. <lb/>[12] Koffka, K., Principles of Gestalt psycholog <lb/>[13] Kosslyn, S.M., Image and mind Cambridge, MA: Harvard University <lb/>press. <lb/>[14] Lohse, J. 1991. A cognitive model for the perception and understanding <lb/>of graphs. In Proceedings of the SIGCHI. <lb/>[15] Mackinlay, J. 19 <lb/>graphic design of user interfaces. UIST &apos;88. <lb/>[16] Norman, D., &quot; The psychology of everyday things &quot; , 1998, Basic Books. <lb/>[17] Paivio, A. Imagery and verbal processes. New Yor <lb/>Winston. 1971. <lb/>[18] Pfitzner, D., Hobbs, V., and Powers, D. 2003. A unified taxonomic <lb/>framework for information visualization. In Proceedings of the Asia-<lb/>Pacifi <lb/>[19] Rao R., Card S. K. 1994, The Table Lens: Merging graphical and <lb/>symbolic representations in an interactive focus plus context <lb/>visualization for tabular information, in Proc. CCHI &apos;94 ACM, pp. 318– <lb/>322. <lb/>[20] Robertson, P <lb/>IEEE Computer Graphics and Applications May 1991 pp. 56-67. <lb/>[21] Robertson G. G, Mackinlay J. D. and Card S. K., Cone trees: Animated <lb/>3D visualizations of <lb/>ACM Press. <lb/>2] Simkin, D. and Hastie, R. An Information-Processing Analysis of Graph <lb/>Perception. Journal of the American Statistical Association 82, 398, <lb/>1987, pp. 4 <lb/>23] Stevens, S.S., On the theory of scales of measurement. Science, 103. <lb/>1946. <lb/>[24] Shneid <lb/>Taxonomy for Information Visualizations. In Proceedings of the 1996 <lb/>IEEE VL. <lb/>[25] Tweedie, L., Characterizing externalizations. Conference proceedings on <lb/>Human Fact <lb/>Press, Chesire, Connecticut(1983) <lb/>[27] Ware, C., Information Visualization, perception for design, Morg <lb/> </listBibl>
		</back>		

			<page>- 258 -<lb/></page>
			
			<note place="headnote">EUROCONTROL Innovative Research Workshop 2007</note> 

	</text>
</tei>
