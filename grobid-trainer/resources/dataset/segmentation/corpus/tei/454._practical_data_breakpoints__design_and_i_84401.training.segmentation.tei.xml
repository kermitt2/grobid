<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Practical Data Breakpoints: Design and Implementation <lb/>Robert Wahbe y <lb/>Steven Lucco y <lb/>Susan L. Graham y <lb/>Computer Science Division, 571 Evans Hall <lb/>UC Berkeley, Berkeley CA, 94720 <lb/>Abstract <lb/>A data breakpoint associates debugging actions with <lb/>programmer-speci ed conditions on the memory state <lb/>of an executing program. Data breakpoints provide <lb/>a means for discovering program bugs that are te-<lb/>dious or impossible to isolate using control breakpoints <lb/>alone. In practice, programmers rarely use data break-<lb/>points, because they are either unimplemented or pro-<lb/>hibitively slow in available debugging software. In this <lb/>paper, we present the design and implementation of a <lb/>practical data breakpoint facility. <lb/>A data breakpoint facility must monitor all memory <lb/>updates performed by the program being debugged. <lb/>We implemented and evaluated two complementary <lb/>techniques for reducing the overhead of monitoring <lb/>memory updates. First, we checked write instructions <lb/>by inserting checking code directly into the program <lb/>being debugged. The checks use a segmented bitmap <lb/>data structure that minimizes address lookup com-<lb/>plexity. Second, we developed data ow algorithms <lb/>that eliminate checks on some classes of write instruc-<lb/>tions but may increase the complexity of the remaining <lb/>checks. <lb/>We evaluated these techniques on the Sparc using <lb/>the spec benchmarks. Checking each write instruc-<lb/>This research was sponsored in part by the Defense Ad-<lb/>vanced Research Projects Agency under grant MDA972-92-J-<lb/>1028 and contract DABT63-92-C-0026. The content of the pa-<lb/>per does not necessarily re ect the position or the policy of the <lb/>Government and no o cial endorsement should be inferred. <lb/>y Email: frwahbe, lucco, grahamg@cs.berkeley.edu <lb/>To appear in Proceedings of the ACM SIGPLAN&apos;93 Sym-<lb/>posium on Programming Language Design and Imple-<lb/>mentation, Albuquerque, NM, June 23{25 1993. <lb/>tion using a segmented bitmap achieved an average <lb/>overhead of 42%. This overhead is independent of the <lb/>number of breakpoints in use. Data ow analysis elim-<lb/>inated an average of 79% of the dynamic write checks. <lb/>For scienti c programs such the nas kernels, analysis <lb/>reduced write checks by a factor of ten or more. On the <lb/>Sparc these optimizations reduced the average over-<lb/>head to 25%. <lb/></front>

			<body>1 Introduction <lb/>Breakpoints are user-speci ed rules that associate de-<lb/>bugging actions with break conditions that arise dur-<lb/>ing program execution. Control breakpoints specify <lb/>the break condition in terms of the program&apos;s control <lb/>ow, for example stop on call to function main. <lb/>Data breakpoints specify the break condition in terms <lb/>of the program&apos;s memorystate, for example stop when <lb/>field f of structure s is modified. <lb/>Data breakpoints support debugging tasks such as <lb/>print the value of field f of structure s every <lb/>time it is updated. To perform this task using only <lb/>control breakpoints, the programmer must nd all <lb/>statements in the program that might update f. In <lb/>the presence of pointers or reference parameters, this <lb/>search is both tedious and error-prone. <lb/>At present, e cient data breakpoint facilities are <lb/>not available to programmers. Using e cient runtime <lb/>data structures and ideas from compiler optimization, <lb/>we have developed and evaluated several methods for <lb/>providing practical data breakpoints. <lb/>The key di erence between control break conditions <lb/>and data break conditions is in the complexity of the <lb/>mapping from the break condition to the set of pro-<lb/>gram instructions that can trigger the condition. We <lb/>call an instruction that may trigger a break condi-<lb/>tion an unsafe instruction. For control break condi-<lb/>tions, the mapping to unsafe instructions is one-to-<lb/>one, or one-to-few in the presence of function inlining. <lb/>Hence, debuggers can guarantee detection of each con-<lb/>trol break condition by monitoring a handful of unsafe <lb/>instructions. <lb/>In contrast, the mapping from data break condi-<lb/>tions to unsafe instructions is one-to-many, because <lb/>the same memory location can be updated by write <lb/>instructions scattered throughout a program. A de-<lb/>bugger must either watch a memory location corre-<lb/>sponding to a data breakpoint, or it must check each <lb/>write instruction in the program that might update <lb/>that memory location. <lb/>We say a write instruction is known if static analysis <lb/>can resolve its target address. A debugger can deter-<lb/>mine the set of known instructions by inspecting target <lb/>addresses prior to execution. Programs written in lan-<lb/>guages that include pointers or permit runtime type <lb/>violations (e.g. out-of-bounds array indices) generally <lb/>contain a large number of unknown write instructions. <lb/>If any data breakpoint is active, all unknown write <lb/>instructions must be considered unsafe, and must be <lb/>checked at runtime. <lb/>Implementation Strategies Some commercially <lb/>available processors provide direct support for data <lb/>breakpoints. Examples include the Intel i386 10], the <lb/>MIPS R4000 12], and the Sparc 16]. Special-purpose <lb/>hardware can monitor memory e ciently. Unfortu-<lb/>nately, the hardware approach inherently limits the <lb/>number of data words simultaneously monitored. The <lb/>Intel i386 can monitor four words; the MIPS R4000 <lb/>and the Sparc can only monitor a single word. <lb/>The UNIX debuggers gdb 17] and dbx 14, 18] pro-<lb/>vide data breakpoints. Both systems conservatively <lb/>assume all instructions are unsafe. The possible side-<lb/>e ects of each instruction are checked through dynami-<lb/>cally inserted trap instructions. Due to context switch <lb/>and trap costs, this approach incurs very high over-<lb/>head. We measured the overhead of dbx to be a factor <lb/>of 85,000, independent of the program being debugged. <lb/>VAX DEBUG provides data breakpoints using vir-<lb/>tual memory page protection 3]. Like gdb and dbx, <lb/>VAX DEBUG assumes that all instructions are unsafe. <lb/>However, rather than check each instruction, VAX DE-<lb/>BUG protects each virtual memory page containing <lb/>data that is part of a data break condition. <lb/>Magpie is a programming environment for Pascal <lb/>that allows debugging actions to be associated with <lb/>variable updates 6]. This functionality is implemented <lb/>by inserting checks during compilation. Magpie does <lb/>not support monitoring of heap objects. <lb/>To this date, no performance information has been <lb/>reported for Magpie or for VAX DEBUG. Several au-<lb/>thors have speculated that e cient data breakpoints <lb/>require special-purpose hardware 4, 11, 15]. <lb/>To quantify the di erences among data breakpoint <lb/>implementation strategies, Wahbe 19] compared fa-<lb/>cilities based on specialized processor support, virtual <lb/>memory page protection, checking the destination ad-<lb/>dress of machine instructions via an operating system <lb/>trap, and checking the destination address of machine <lb/>instructions via a procedure call. Virtual memory and <lb/>the use of traps were shown to be too slow for practical <lb/>use. Special-purpose hardware, while e cient, could <lb/>not support all test cases due to limits on the number <lb/>of memory words simultaneously monitored. Checking <lb/>each write instruction via a procedure call emerged as <lb/>the most promising method for realizing e cient data <lb/>breakpoints. Its most signi cant disadvantage was the <lb/>expected overhead of between 209% and 642%. <lb/>In this paper, we adopt a code patching approach <lb/>to checking write instructions and signi cantly reduce <lb/>its overhead. We investigate two complementary ap-<lb/>proaches to reducing the overhead of write checks. <lb/>First, we develop an e cient data structure, the seg-<lb/>mented bitmap, for checking whether an individual <lb/>target address is part of a data breakpoint condition. <lb/>We compare several techniques for optimizing these <lb/>checks. <lb/>Second, we investigate the additional performance <lb/>bene t of eliminating write checks through compile-<lb/>time analysis. Our strategy for eliminating write <lb/>checks has three components. First, we use a sym-<lb/>bol table matching algorithm to nd as many known <lb/>write instructions as possible. We check those instruc-<lb/>tions only when the variables to which they write occur <lb/>in break conditions. Second, we use data ow analy-<lb/>sis techniques to remove checks on write instructions <lb/>within loops. We replace such checks by checks that <lb/>execute only once, on entry to the loop. Third, we <lb/>support these loop optimizations by using data struc-<lb/>tures that provide e cient checks on contiguous ranges <lb/>of memory locations. We demonstrate that, at the <lb/>cost of considerable implementation complexity, these <lb/>techniques dramatically diminish the dynamic count <lb/>of checked write instructions. <lb/>The remainder of this paper has the following struc-<lb/>ture. Section 2 describes a monitored region service <lb/>abstraction that de nes the speci c functionality pro-<lb/>vided by our system and outlines its implementation. <lb/>Section 3 describes the segmented bitmap data struc-<lb/>ture, its optimization through caching and inlining, <lb/>and its overhead for the spec benchmarks. Section <lb/>4 provides the details of our write-check elimination <lb/>algorithms, and evaluates their e ectiveness. Finally, <lb/>Section 5 draws some conclusions. <lb/>st %o0, %fp-20] <lb/>! Write instruction <lb/>sub %fp,20,%g5 <lb/>! Address passed via %g5 <lb/>call check 1 word,0 ! Write check procedure <lb/>nop <lb/>! Delay slot <lb/>Figure 1: Simpli ed example of a write check. <lb/>2 Monitored Region Service <lb/>We encapsulate the core functionality needed to im-<lb/>plement data breakpoints within an abstraction called <lb/>a monitored region service (MRS). A monitored region <lb/>service detects writes to contiguous regions of memory <lb/>called monitored regions. To simplify the implementa-<lb/>tion, monitored regions are assumed to be word aligned <lb/>and non-overlapping. The interface to the monitored <lb/>region service consists of the following three functions: <lb/>CreateMonitoredRegion (MonitoredRegion) <lb/>DeleteMonitoredRegion (MonitoredRegion) <lb/>NotificationCallBack (TargetAddress, Size) <lb/>It is the responsibility of the debugger to map source <lb/>language names used in the break conditions to mon-<lb/>itored regions, and to create and delete monitored re-<lb/>gions as necessary. <lb/>If the target of a write instruction intersects a mon-<lb/>itored region, there is a monitor hit, otherwise there is <lb/>a monitor miss. The function NotificationCallBack <lb/>is used to notify MRS clients, such as the debugger, of <lb/>monitor hits. <lb/>The monitored region service does not monitor <lb/>writes to registers or memory updates due to system <lb/>calls. Because registers cannot be aliased, detecting <lb/>writes to registers is straightforward and incurs negligi-<lb/>ble runtime overhead. A debugging system can detect <lb/>memory updates due to system calls by replacing the <lb/>library portion of each system call with an equivalent <lb/>call that reports memory updates to the debugger. <lb/>2.1 Implementation <lb/>We now outline our basic approach to implementing <lb/>a monitored region service. In the next two sections <lb/>we will show how this straightforward implementation <lb/>can be optimized. <lb/>Our system consists of a program analysis tool and <lb/>a runtime library. The analysis tool acts as an extra <lb/>processing stage between the compiler and the assem-<lb/>bler, patching each write instruction with a function <lb/>call that checks the target address to detect monitor <lb/>hits. An example Sparc assembly code fragment, gen-<lb/>erated by our MRS implementation, is shown in Fig-<lb/>ure 1. In this example, the write instruction is a one <lb/>word store to memory (st), and the target address is <lb/>%fp-20. The runtime monitor library contains the data <lb/>structures necessary to check whether a target address <lb/>represents a monitor hit. <lb/>Since our simple MRS implementation does not <lb/>monitor indirect jump instructions during program <lb/>execution, it must be prepared for arbitrary control <lb/>transfers. Indirect control transfers pose two potential <lb/>problems for the MRS. First, as a result of data corrup-<lb/>tion, control might be transferred directly to a write in-<lb/>struction. To insure that all monitor hits are detected, <lb/>checks are placed after, rather than before, the write <lb/>instruction. Second, the program might jump into the <lb/>middle of a monitor library routine. This situation <lb/>is detected by maintaining a check-in-progress ag <lb/>which is set on entry to a monitor routine and cleared <lb/>on exit. The above scheme does not prevent the rou-<lb/>tine from referencing an invalid address before check-<lb/>ing the ag. However, the MRS may use an operating <lb/>system signal to detect this situation gracefully. <lb/>The write check implementations described in Sec-<lb/>tion 3 and Section 4 reserve a minimum of three reg-<lb/>isters for the monitored region service. One register <lb/>holds the check-in-progress ag described above. <lb/>The MRS uses a second register to hold a global <lb/>disabled ag. The MRS sets this ag whenever no <lb/>data breakpoints are active. The code for each write <lb/>check branches around the body of the check when the <lb/>disabled ag is set, reducing runtime overhead. Fi-<lb/>nally, a third register is used by write checks to hold <lb/>the target address of the write instruction. <lb/>For e ciency, the monitor library data structures <lb/>are maintained in the address space of the program <lb/>being debugged. The MRS creates monitored regions <lb/>as necessary to insure the integrity of these data struc-<lb/>tures. <lb/>3 Write Check Implementa-<lb/>tions <lb/>In this section, we describe our basic Sparc imple-<lb/>mentation of a monitored region service, and present <lb/>several possible optimizations for reducing the over-<lb/>head of checking write instructions. On the Sparc, all <lb/>write instructions update either one or two memory <lb/>words. Because the two word write instructions are <lb/>suitably aligned, one-word and two-word checks incur <lb/>identical overhead for the implementation techniques <lb/>that we tested. We will discuss only single-word write <lb/>checks. <lb/>The basic operation that a write check performs is <lb/>to determine whether a write instruction&apos;s target ad-<lb/>dress references a monitored region. We call this oper-<lb/>ation address lookup. We found that the best strategy <lb/>for implementing e cient address lookup is to mini-<lb/>mize the average number of memory accesses required. <lb/>The write checks tested in Wahbe&apos;s pilot study of data <lb/>breakpoint implementations used a hash table for ad-<lb/>dress lookup 19]. This data structure uses memory <lb/>e ciently, consuming space proportional to the num-<lb/>ber of monitored regions. However, it requires sev-<lb/>eral memory accesses for each address lookup. We <lb/>tested this data structure using the spec benchmarks <lb/>and veri ed that the write check overhead generally <lb/>matched the 209% to 642% reported in the previous <lb/>study for a di erent set of benchmarks. <lb/>The overhead of hash table address lookups is due <lb/>mostly to the memory accesses performed in matching <lb/>a target address against a list of hash table entries. <lb/>The write checks described in this section use a seg-<lb/>mented bitmap data structure to implement address <lb/>lookup. This data structure uses one bit to represent <lb/>each word allocated by the program being debugged. <lb/>Each bit indicates whether or not the corresponding <lb/>word is monitored. Hence a segmented bitmap con-<lb/>sumes more space than a hash table -roughly 3% of <lb/>the total memory used by the program. However, it in-<lb/>curs at most two memory accesses per address lookup. <lb/>Further, these memory accesses are more likely to <lb/>be cached than the hash table memory accesses. Since <lb/>one bitmap word represents 32 words of memory allo-<lb/>cated by the program being debugged, and since cache <lb/>lines on the Sparc contain 32 bytes, any lookup of an <lb/>address within 512 bytes of a recently checked address <lb/>is very likely to require only cached memory accesses. <lb/>Conceptually, the bitmap contains one bit for ev-<lb/>ery word of addressable memory. To reduce its space <lb/>overhead, we organize the bitmap into segments of size <lb/>segment-size. Segments are allocated lazily in re-<lb/>sponse to monitored region installations. Right shift-<lb/>ing the target address by log 2 (segment-size) bits <lb/>yields its segment number. Segments are accessed via <lb/>a segment table, which is an array of segment pointers, <lb/>indexed by segment number. All segment pointers are <lb/>initialized to a single zeroed bitmap segment. Figure <lb/>2 depicts a segmented bitmap. <lb/>Breaking the bitmap into segments requires an extra <lb/>load instruction to index into the segment table. How-<lb/>ever, the target of this load instruction is very likely <lb/>to be cached, again assuming spatial locality among <lb/>checked addresses. <lb/>3.1 Reserving Registers for the Moni-<lb/>tored Region Service <lb/>On modern RISC architectures the naive compilation <lb/>typically used during debugging requires only a sub-<lb/>set of the available registers. We can take advantage <lb/>of this situation by reserving registers for use by the <lb/>MRS. Optimizations based on reserved registers are <lb/>Address <lb/>Segment Number <lb/>Segment Table <lb/>Segment <lb/>Single Word in Segment <lb/>Segment Pointer <lb/>&gt;&gt; <lb/>10110100111000111000101011001001 <lb/>Figure 2: A Segmented Bitmap <lb/>less applicable to architectures, such as the i386, which <lb/>have small register sets 10]. Also, as compilation for <lb/>debugging incorporates more sophisticated register al-<lb/>location, there will be a tradeo between freeing an <lb/>additional register for the compiler, and reserving that <lb/>register for the MRS. On the Sparc we found two <lb/>techniques that can bene t from reserved registers. <lb/>The segmented bitmap code requires three regis-<lb/>ters to hold intermediate values during address lookup. <lb/>The MRS can use reserved registers to avoid pushing a <lb/>register window. The MRS can use a fourth register to <lb/>hold the base address of the segmented bitmap table. <lb/>Although this value is constant, it is too large to be an <lb/>immediate assembly operand and therefore placing it <lb/>in a register requires extra register instructions during <lb/>address lookup. <lb/>A more sophisticated technique, called segment <lb/>caching, uses registers to cache the results of previous <lb/>write checks on the same bitmap segment. To sup-<lb/>port caching, each write instruction is assigned a write <lb/>type. The goal of the write type is to identify groups <lb/>of write instructions which are likely to exhibit spa-<lb/>tial locality. For C programs, we used the write types <lb/>bss, stack, and heap. All target addresses computed <lb/>using the frame or stack pointer were assigned type <lb/>stack. Writes with constant target addresses were as-<lb/>signed type bss; the remaining writes were assigned <lb/>type heap. For Fortran, in addition to the above <lb/>types, we also used the type bss-var. The Sun For-<lb/>tran compiler used a simple idiom to calculate related <lb/>bss accesses. By recognizing this idiom we were able <lb/>to increase the e ective cache hit rate. <lb/>For each write type we maintain a segment cache. <lb/>The segment cache holds the segment number of the <lb/>last checked segment to have no monitored regions. <lb/>By keeping the segment cache in a reserved register, <lb/>we can check the cache in four register instructions. <lb/>To support segment caching we must be able to de-<lb/>termine e ciently whether a bitmap segment contains <lb/>any monitored regions. We do this by maintaining, <lb/>for each bitmap segment, a boolean ag unmonitored, <lb/>indicating whether the segment has any monitored re-<lb/>gions. By suitably aligning the bitmap segments, we <lb/>can store the unmonitored ag in the unused low order <lb/>bit of the corresponding segment pointer. <lb/>In addition to supporting segment caching, the un-<lb/>monitored ag saves the address calculation and load <lb/>of the correct bitmap segment when the segment con-<lb/>tains no monitored regions. To support e cient cre-<lb/>ation and deletion of monitored regions in the pres-<lb/>ence of the unmonitored ag, an auxiliary data struc-<lb/>ture maintains a count of monitored regions for each <lb/>bitmap segment. <lb/>The algorithm for maintaining the segment caches <lb/>is as follows: <lb/>if SegmentNum(TargetAddress) = SegmentCache <lb/>Done <lb/>elsif SegmentNotMonitored(TargetAddress)) then <lb/>SegmentCache SegmentNum(TargetAddress) <lb/>elsif MonitorHit(TargetAddress) <lb/>Noti cationCallBack(TargetAddress, Size) <lb/>endif <lb/>Note that the segment cache is only updated if there <lb/>is a cache miss and the new segment contains no mon-<lb/>itored regions. <lb/>While larger segments improve segment cache local-<lb/>ity, smaller segments reduce the number of full lookups. <lb/>Full lookups are monitor misses that require checking <lb/>the cache, the unmonitored ag, and nally the appro-<lb/>priate bitmap segment word. A full lookup occurs for <lb/>target addresses whose bitmap segment contains moni-<lb/>tored regions; the impact of full lookups is discussed in <lb/>Section 3.3. Segment size also determines the number <lb/>of segments in the segment table. For a 2 32 byte ad-<lb/>dress space, a 128 word segment size requires 1 million <lb/>segments. While the segments themselves are allocated <lb/>lazily, the segment table is not. Thus, to decide seg-<lb/>ment size, one must consider tradeo s among segment <lb/>cache locality, the expected number of full lookups, <lb/>and the size of the segment table. <lb/>To limit table size, we restricted our choice of seg-<lb/>ment sizes to 128 words or greater. Figure 3 graphs <lb/>segment cache locality as a function of segment size. <lb/>Segment sizes greater than 128 words did not o er <lb/>enough gain in cache locality to justify the possible <lb/>increase in full lookups. Hence, all experiments re-<lb/>ported in Section 3.3 were performed with a 128 word <lb/>segment size. <lb/>Segment Size (Bytes) <lb/>Cache Hit Rate <lb/>20.00% <lb/>30.00% <lb/>40.00% <lb/>50.00% <lb/>60.00% <lb/>70.00% <lb/>80.00% <lb/>90.00% <lb/>100.00% <lb/>32 <lb/>64 <lb/>128 <lb/>256 <lb/>512 <lb/>1024 <lb/>2048 <lb/>4096 <lb/>8192 <lb/>16384 <lb/>C Average <lb/>F Average <lb/>Average <lb/>Figure 3: Segment Cache Locality <lb/>3.2 Inlining <lb/>In addition to reserving registers, we evaluated the im-<lb/>pact of inlining write checks. On the Sparc, inlining <lb/>eliminates as many as six instructions. Section 3.3 <lb/>demonstrates, however, that inlining can increase over-<lb/>head due to instruction cache misses. To evaluate the <lb/>e ectiveness of inlining, we compared inlined and non-<lb/>inlined versions for both simple bitmap lookup and seg-<lb/>ment cached implementations. For segment caching, <lb/>the four instructions necessary to check the cache are <lb/>always inlined. The non-inlined version makes a pro-<lb/>cedure call when there is a segment cache miss. <lb/>3.3 Evaluation <lb/>Table 1 presents monitored region service overhead <lb/>for the following write check implementations: <lb/>Bitmap. Address lookup executed via procedure call. <lb/>BitmapInline. An inlined version of Bitmap. <lb/>BitmapInlineRegisters. An inlined version of Bitmap <lb/>that makes use of reserved registers to avoid <lb/>spilling and the recalculation of address constants. <lb/>Cache. Segment caching implementation using four <lb/>segment caches. On a cache miss, lookup is ex-<lb/>ecuted via a procedure call. <lb/>CacheInline. An inlined version of Cache. <lb/>In addition to the above implementations, we mea-<lb/>sured the overhead of branching around checks when <lb/>Programs <lb/>Disabled Bitmap Bitmap Bitmap Cache Cache <lb/>Inline <lb/>Inline <lb/>Inline <lb/>Registers <lb/>(C) 023.eqntott <lb/>-3.2% <lb/>0.2% -0.5% <lb/>-1.7% -3.7% -4.4% 2.3% <lb/>(C) 008.espresso <lb/>22.2% 70.4% 66.2% 40.4% 29.6% 22.2% 4.9% <lb/>(C) 001.gcc1.35 <lb/>28.1% 75.4% 83.6% 63.1% 49.7% 53.3% 6.1% <lb/>(C) 022.li <lb/>60.2% 128.5% 124.2% 94.8% 77.2% 62.3% 19.4% <lb/>(F) 015.doduc <lb/>19.3% 58.6% 73.3% 45.2% 21.1% 37.8% 5.6% <lb/>(F) 042.fpppp <lb/>33.8% 55.4% 68.7% 56.1% 41.2% 53.8% 3.3% <lb/>(F) 030.matrix300 <lb/>7.5% <lb/>39.1% 31.8% 25.3% 15.4% 13.8% 1.1% <lb/>(F) 020.nasker <lb/>9.2% <lb/>44.5% 40.0% 37.2% 17.2% 19.6% 1.6% <lb/>(F) 013.spice2g6 <lb/>7.1% <lb/>30.9% 29.1% 25.1% 15.9% 15.7% 4.1% <lb/>(F) 047.tomcatv <lb/>13.6% 44.7% 36.6% 32.5% 19.2% 27.8% 1.3% <lb/>C Average <lb/>26.8% 68.6% 68.4% 49.2% 38.2% 33.3% 8.2% <lb/>Fortran Average <lb/>15.1% 45.5% 46.6% 36.9% 21.7% 28.1% 2.8% <lb/>Overall Average <lb/>19.8% 54.8% 55.3% 41.8% 28.3% 30.2% 5.0% <lb/>Table 1: Monitored region service overhead for di erent write check implementations. <lb/>the disabled ag is set. The column labeled is ex-<lb/>plained below. All routines were carefully hand coded <lb/>in Sparc assembly code. The standard libraries were <lb/>not patched for these experiments; using gprof 8], we <lb/>measured the percentage of time spent in library rou-<lb/>tines to be an average of 2.6% for C programs and 1.6% <lb/>for Fortran programs, excluding the Sparc library <lb/>routines for integer multiplication and division which <lb/>do not update memory. <lb/>3.3.1 Cache E ects <lb/>Our measurements show a number of interesting <lb/>anomalies. The most obvious are the negative over-<lb/>heads for 023.eqntott. For a number of programs, <lb/>the savings due to reserving registers is somewhat <lb/>higher than we had estimated. Finally, while inlin-<lb/>ing the segment caching routine slightly improved the <lb/>average overhead on C programs, inlining the simple <lb/>bitmap lookup routine had essentially no e ect. <lb/>We conjecture that these anomalies are due to cache <lb/>e ects. The Sparc used in our experiments has a <lb/>direct-mapped combined instruction and data cache <lb/>with 32 byte cache lines. Inserting write checks a ects <lb/>cache performance in two ways. First, because write <lb/>checks increase the size of the code, the cache size is <lb/>e ectively reduced. Second, adding or moving instruc-<lb/>tions changes the alignment of code and data relative <lb/>to cache line boundaries. <lb/>To evaluate the impact of caching we performed <lb/>an experiment in which we inserted 2, 4, 8, 16, or <lb/>32 nop instructions before each write instruction. In <lb/>the absence of cache e ects, the overhead should be <lb/>linearly dependent on the number of instructions in-<lb/>serted. We make the simplifying assumption that the <lb/>e ective cache size is also linearly reduced. For each <lb/>program we performed a simple linear regression on <lb/>the measured overhead for the di erent number of in-<lb/>serted nop instructions. Under the above assumptions, <lb/>any deviation from the expected linear behavior must <lb/>be caused by cache alignment e ects. The last col-<lb/>umn of Table 1 shows the standard deviation of the <lb/>di erences between expected and observed overhead. <lb/>In two ways, these cache e ects alter the conclu-<lb/>sions we can draw from comparing di erent write check <lb/>implementations. First, the ranking of a given ap-<lb/>proach could change given a di erent cache organiza-<lb/>tion. Second, we must rely more heavily on average <lb/>measurements over all spec benchmarks, as individual <lb/>measurements may include anomalous overhead due to <lb/>cache performance variation. <lb/>3.3.2 Inlining <lb/>Inlining had little e ect on the measured overheads for <lb/>our benchmark programs; overall, it slightly increased <lb/>overhead. Because inlining dramatically changes the <lb/>alignment characteristics of the program, the small dif-<lb/>ferences observed for individual programs are not sig-<lb/>ni cant. We conclude that inlining write checks on the <lb/>Sparc is not necessary. <lb/>3.3.3 Segment Caching <lb/>In contrast, segment caching did reduce the e ec-<lb/>tive overhead of write checks. However, because <lb/>full lookups may occur when monitored regions are <lb/>present, the savings from segment caching is depen-<lb/>dent on the debugging situation. If there are too <lb/>many full lookups, the additional overhead incurred <lb/>for checking the cache and unmonitored ag cancels <lb/>the bene t of caching. To address this issue, we com-<lb/>pared the cycle counts for BitmapInlineRegisters and <lb/>Cache. BitmapInlineRegisters executes 12 register in-<lb/>structions and 2 loads. Cache executes 6 register in-<lb/>structions if there is a cache hit, 18 register instruc-<lb/>tions and 1 load if there is a cache miss, and 26 reg-<lb/>ister instructions and 2 loads if there is a full lookup. <lb/>Assuming that loads take between 2 -8 cycles, the <lb/>break-even point for C programs occurs when the per-<lb/>centage of write instructions requiring a full lookup is <lb/>24.3 -44.0%. For Fortran programs, the break-even <lb/>point is 16.4 -36.7%. <lb/>Segment caching reduced overhead by an average of <lb/>13.5%. For short lived programs, we do not think the <lb/>savings justify the scheme&apos;s variability. Consider that <lb/>14% overhead represents only about 50 seconds for a <lb/>program that normally runs for 6 minutes. <lb/>For compute intensive applications, improving the <lb/>naive compilation typically used during debugging <lb/>would have more performance impact than reserving <lb/>registers for segment caching 1, 2, 9]. In particu-<lb/>lar, register allocation would speed program execution, <lb/>while reducing the number of write checks. Because <lb/>register allocation targets scalar variables found on the <lb/>stack and stack writes exhibited excellent locality in <lb/>our tests, we conjecture that register allocation would <lb/>reduce the e ective hit rate of segment caching, nar-<lb/>rowing the performance gap between simple bitmap <lb/>lookup and segment caching. <lb/>4 Eliminating Write Checks <lb/>The implementation described in the previous section <lb/>is simple but may incur signi cant overhead when the <lb/>dynamic count of write instructions is large relative <lb/>to the total instruction count. The optimizations de-<lb/>scribed in this section concentrate on reducing this <lb/>overhead by eliminating unnecessary write checks. <lb/>Write check elimination is based on dynamic inser-<lb/>tion and deletion of write checks. For certain classes <lb/>of write instructions, data ow analysis can determine <lb/>runtime conditions under which a given write instruc-<lb/>tion is safe. For example, if a particular write instruc-<lb/>tion w can only write to a speci c program variable <lb/>x, then the MRS need only check w while x is being <lb/>monitored. Hence, the analysis tool can eliminate the <lb/>check on w, and arrange for the MRS to re-insert the <lb/>check at runtime upon creation of a monitored region <lb/>that includes x. <lb/>Similarly, the analysis tool can often determine that <lb/>a particular write instruction w l within a loop will up-<lb/>date a contiguous range of memory locations. Given <lb/>this information, it can arrange for the MRS to check, <lb/>on loop entry, whether the range of memory locations <lb/>to be updated intersects any monitored regions. If this <lb/>range check succeeds, the MRS can dynamically re-<lb/>insert the eliminated write check on w l . <lb/>Kessler 13] describes a method for dynamically <lb/>patching a running program. To insert a check be-<lb/>fore an instruction, the instruction is replaced with a <lb/>branch to a write check patch. The write check patch, <lb/>in addition to checking for a monitor hit, is responsible <lb/>for executing the displaced instruction. At compile-<lb/>time, for each write instruction, a write check patch <lb/>is constructed. By having dedicated patches we in-<lb/>sure that inserting checks is extremely e cient. On <lb/>most architectures only a handful of instructions are <lb/>required. <lb/>Unfortunately, the MRS must incur additional run-<lb/>time overhead to support write check elimination. <lb/>For example, both write check optimizations outlined <lb/>above require that the MRS check all indirect jump <lb/>instructions, to verify that the control ow graph used <lb/>in data ow analysis matches the actual control ow <lb/>of the program being debugged. Whether these addi-<lb/>tional sources of overhead cancel the bene t of elim-<lb/>inating write checks depends on both the target pro-<lb/>cessor architecture and the type of program being de-<lb/>bugged. <lb/>4.1 Analysis <lb/>To support write check elimination, we augmented our <lb/>code patching and analysis tool to include a machine <lb/>independent optimizer. As before, the analysis tool <lb/>takes as input a sequence of Sparc assembly instruc-<lb/>tions. It then converts this sequence into an interme-<lb/>diate representation (IR) which is de ned as a set of <lb/>3-address codes. In addition, the analysis tool con-<lb/>verts symbol table entries (e.g. STAB) into IR form. <lb/>The optimizer takes as input the IR, and converts it to <lb/>static single assignment (SSA) form 5]. It then per-<lb/>forms several IR transformations that eliminate checks <lb/>on the target addresses of individual write instructions. <lb/>4.2 Symbol Table Pattern Matching <lb/>The rst pass of the optimizer identi es known write <lb/>instructions through symbol table pattern matching. <lb/>The optimizer creates an expression DAG for each <lb/>target address, matching the DAG against debugging <lb/>symbol table entries. When the expression for a target <lb/>address matches a symbol table expression, the opti-<lb/>mizer eliminates the expression from the IR instruction <lb/>sequence and replaces it with a pseudo-operand. For <lb/>example, if the expression %fp-20 matches a symbol <lb/>table entry, the optimizer will replace all instances of <lb/>%fp-20 with a unique variable name v. Instructions <lb/>that read from %fp-20 are converted to IR move in-<lb/>structions with v as the source. Instructions that write <lb/>into %fp-20 are converted into IR move instructions <lb/>with v as the target. <lb/>This transformation has two bene ts. First, it en-<lb/>ables a substantial portion of the write checks to be <lb/>eliminated, since there is no uncertainty about which <lb/>variable is being written. Second, substituting pseudo-<lb/>operands for target address expressions such as %fp-20 <lb/>simpli es the recognition of induction variables, a nec-<lb/>essary step in the loop optimizations described below. <lb/>During this rst pass, the optimizer generates a table <lb/>which is used at runtime to translate a symbol name <lb/>x into a list of associated write instructions. When <lb/>the monitored region containing x is created, each in-<lb/>struction w in this list must be patched to detect a <lb/>monitor hit when w is executed. To support this pro-<lb/>cedure, the monitored region service interface exports <lb/>two additional operations: <lb/>PreMonitor(symbol) <lb/>PostMonitor(symbol) <lb/>The PreMonitor operation performs this code patch-<lb/>ing procedure; the PostMonitor operation reverses it. <lb/>When a break condition involving x is set, the debug-<lb/>ger calls PreMonitor to patch the write instructions <lb/>for x and then calls CreateMonitoredRegion on the <lb/>memory region associated with x. The debugger must <lb/>create a monitored region for x because x could be <lb/>written through aliases as well as through instructions <lb/>patched to detect a monitor hit directly. <lb/>To support this symbol table optimization we must <lb/>check all de nitions of registers that appear in symbol <lb/>table expression DAGs. For example, whenever %fp is <lb/>modi ed, we must ensure that it points to the correct <lb/>stack frame. Hence, eliminating the uses of %fp will <lb/>be pro table only if the number of uses of %fp in write <lb/>instructions is greater than the dynamic count of its <lb/>de nitions. Further, to check whether %fp is reset to <lb/>its correct value following a function return requires a <lb/>pair of memory accesses to save and retrieve the cor-<lb/>rect %fp value. A dedicated register will not su ce, <lb/>except for leaf procedures. Hence, checking a de ni-<lb/>tion of %fp will be as expensive as checking two or three <lb/>write instructions that use %fp. Further, to avoid still <lb/>greater overhead (an extra load instruction for each <lb/>%fp check), the MRS must reserve a register for this <lb/>check. Because the %fp check reserves a register, the <lb/>remaining write checks in the optimized implementa-<lb/>tion must push a register window. As a whole, the <lb/>optimized implementation requires four dedicated reg-<lb/>isters. <lb/>Elimination of known write instructions also de-<lb/>pends on the control ow of the program. For example, <lb/>if the program erroneously jumps into the middle of a <lb/>procedure, the %fp can contain an incorrect value. To <lb/>prevent such an occurrence, we must also check all in-<lb/>direct jumps in the program being debugged, to ensure <lb/>that they transfer control to legitimate targets. <lb/>Finally, this optimization requires compiler support <lb/>for the correct treatment of exceptions. If an exception <lb/>causes stack unwinding, the MRS must be noti ed so <lb/>that it can unwind its stack of correct %fp values. <lb/>4.3 Loop Optimization <lb/>For many programs, writes performed in loops can <lb/>dominate the dynamic write-count, even if loop writes <lb/>make up only a small minority of the static write-<lb/>count. Because of the importance of loop writes, the <lb/>optimizer uses additional data ow analysis to elimi-<lb/>nate checks for some of the writes found in loops. <lb/>The optimizer performs two loop-based optimiza-<lb/>tions: loop invariant check motion and monotonic <lb/>write check elimination. First, the optimizer detects <lb/>all loop invariant target addresses. It eliminates the <lb/>checks for these loop invariant addresses and replaces <lb/>them with write checks in a pre-header block that dom-<lb/>inates all entrances to the loop. If one of these checks <lb/>succeeds at runtime, the MRS will insert the elimi-<lb/>nated write check within the loop. <lb/>Second, the optimizer detects write instructions that <lb/>will generate a monotonic sequence of target addresses <lb/>during the execution of a loop. We call such instruc-<lb/>tions monotonic writes. The optimizer replaces checks <lb/>on monotonic writes with range checks in the loop pre-<lb/>header. We use an e cient data structure to imple-<lb/>ment range checks. For ranges of 2 25 bytes or less, the <lb/>lookup requires at most three memory accesses. As <lb/>with loop invariant checks, if a range check succeeds <lb/>at runtime, the MRS will dynamically restore the elim-<lb/>inated write check. <lb/>To detect monotonic writes, the optimizer deter-<lb/>mines the monotonic variables for each loop. The value <lb/>of each monotonic variable must increase or decrease <lb/>monotonically during the execution of the loop. <lb/>4.3.1 Assert De nitions <lb/>To support loop optimization, the post-processor con-<lb/>verts the Sparc condition code and conditional branch <lb/>instructions into IR assert statements. An assert state-<lb/>ment has the form <lb/>DEST1,DEST2 := ASSERT_OP SRC1,SRC2 <lb/>where ASSERT OP is one of the relational operators. In <lb/>an assert statement, DEST1 is the same operand as <lb/>SRC1, and DEST2 is the same as SRC2. The role of the <lb/>assert statement is to update the data ow information <lb/>about DEST1 and DEST2 to re ect the condition code <lb/>setting. The purpose of this re-de nition is to deter-<lb/>mine precisely, for each use of a variable, the symbolic <lb/>lower and upper bounds of the value of the variable. <lb/>4.3.2 Bound Propagation <lb/>The optimizer uses a single bound propagation algo-<lb/>rithm to detect both loop invariant and monotonic <lb/>writes. Bound propagation is performed once per loop. <lb/>Loop nests are processed from inner to outer loops, <lb/>so that checks moved out of inner loops can become <lb/>candidates for further optimization. The loop being <lb/>processed is called the current loop. Following bound <lb/>propagation, the optimizer processes each write in-<lb/>struction in the current loop, replacing the checks on <lb/>all bounded writes with checks in the current loop&apos;s <lb/>pre-header. A bounded write is a write instruction <lb/>whose target address has both an upper bound and a <lb/>lower bound. <lb/>To detect bounded writes, the optimizer tags each <lb/>SSA variable with bounds (L,U), where L represents <lb/>the lower bound on the variable, and U the upper <lb/>bound. L can have one of ve values: L C , L LI , L M , <lb/>L A , or ?. L C represents a lower bound derived from <lb/>constants. A variable tagged with L C is either a con-<lb/>stant or derived from an expression DAG containing <lb/>only constants. L LI designates a lower bound derived <lb/>from loop invariants or constants. L M designates a <lb/>lower bound derived from monotonic variables, loop <lb/>invariants or constants. L A designates a lower bound <lb/>derived from assert statements, monotonic variables, <lb/>loop invariants or constants. Finally, ? designates that <lb/>the variable has no known lower bound. Similarly, U <lb/>can have the values U C , U LI , U M , U A , or ?. <lb/>The possible values for L are totally ordered accord-<lb/>ing to the usefulness of the bounds these values rep-<lb/>resent: L C &gt; L LI &gt; L M &gt; L A &gt; ?. For example, a <lb/>bound derived only from constants or loop invariants <lb/>(L LI ) is more useful than a bound derived from mono-<lb/>tonic variables, constants, and loop invariants (L M ). <lb/>The latter type of bound requires a range check in the <lb/>pre-header of the current loop, while the former re-<lb/>quires only a standard write check. The values for U <lb/>are ordered analogously. <lb/>Before bound propagation begins, the bounds of all <lb/>SSA variables are initialized. Constants and variables <lb/>with constant values have bounds (L C ; U C ). Loop in-<lb/>variant variables have bounds (L LI ; U LI ). Members of <lb/>monotonic groups have bounds (L M ; ?) or (?; U M ) de-<lb/>pending on whether their direction is increasing (L M ) <lb/>or decreasing (U M ). <lb/>After this initialization step, bound propagation <lb/>Def = statements that de ne variables <lb/>while (Def 6 = ;) <lb/>changed = false <lb/>remove S from Def <lb/>new lower bound = <lb/>max(LowerBound(Dest(S)), <lb/>ComputeLowerBound(Operands(S))) <lb/>new upper bound = <lb/>max(UpperBound(Dest(S)), <lb/>ComputeUpperBound(Operands(S))) <lb/>if (LowerBound(Dest(S)) 6 = new lower bound) <lb/>changed = true <lb/>LowerBound(Dest(S)) = new lower bound <lb/>if (UpperBound(Dest(S)) 6 = new upper bound) <lb/>changed = true <lb/>UpperBound(Dest(S)) = new upper bound <lb/>if (changed) <lb/>add all statements using Dest(S) to Def <lb/>Figure 4: Bounds propagation algorithm. <lb/>proceeds using the algorithm shown in Figure 4. Here <lb/>Dest(S) denotes the destination operand for statement <lb/>S. LowerBound and U pperBound select the appro-<lb/>priate component of the bounds associated with the <lb/>variables. <lb/>This algorithm iterates to a xed-point. It places <lb/>all statements de ning SSA variables into a set Def. <lb/>It then processes every statement S in Def, comput-<lb/>ing bounds for Dest(S). If the bounds for Dest(S) <lb/>change, then all statements using Dest(S) are added <lb/>to Def. By using the max operator to combine the <lb/>bounds on Dest(S) with the bounds computed from <lb/>the source operands of S, the algorithm propagates <lb/>the computed bounds only when they are more useful <lb/>than the current bounds for Dest(S). <lb/>The ComputeLowerBound and ComputeUpper-<lb/>Bound functions depend on the type of S. For ex-<lb/>ample, the ADD and SHIFT statements require only <lb/>the simple conjunction rule l = min(l src1; l src2) to <lb/>compute the a new lower bound l from the two source <lb/>operand lower bounds l src1 and l src2. <lb/>4.4 Generation of Checks <lb/>Once bound propagation has completed, the optimizer <lb/>visits each write instruction in the current loop. If the <lb/>target address a of a write instruction w is a bounded <lb/>value, then the optimizer can replace the check on a <lb/>with a check in the loop pre-header. The particular op-<lb/>timization performed depends on the symbolic bounds <lb/>for a. Let a have bounds (l; u). Then if l L LI and <lb/>u U LI , a is loop invariant and the optimizer can re-<lb/>Checks <lb/>Checks <lb/>Runtime <lb/>Program <lb/>Eliminated <lb/>Generated <lb/>Overhead <lb/>Symbol LI Range Total LI Range Full Sym <lb/>(C) 023.eqntott <lb/>71.9% 0.0% 0.6% 72.5% 0.0% 0.0% 0.5% 4.0% <lb/>(C) 008.espresso <lb/>23.1% 19.5% 15.4% 58.0% 0.9% 7.4% 27.8% 39.9% <lb/>(C) 001.gcc1.35 <lb/>49.0% 1.3% 1.8% 52.1% 0.0% 0.8% 80.4% 109.2% <lb/>(C) 022.li <lb/>75.9% 0.0% 0.0% 75.9% 0.0% 0.0% 89.2% 156.4% <lb/>(F) 015.doduc <lb/>84.7% 0.1% 10.6% 95.4% 0.1% 4.6% 3.1% 80.8% <lb/>(F) 042.fpppp <lb/>70.4% 0.0% 10.8% 81.2% 0.0% 0.0% 11.9% 39.5% <lb/>(F) 030.matrix300 <lb/>51.7% 0.0% 48.3% 100.0% 0.2% 0.2% 0.4% 18.8% <lb/>(F) 020.nasker <lb/>42.6% 17.3% 34.5% 94.4% 0.1% 0.2% 13.9% 26.9% <lb/>(F) 013.spice2g6 <lb/>77.7% 0.2% 1.0% 78.9% 0.0% 0.4% 11.4% 34.4% <lb/>(F) 047.tomcatv <lb/>70.4% 0.0% 10.8% 81.2% 0.0% 0.0% 8.2% 40.6% <lb/>C Average <lb/>55.0% 5.2% 4.5% 64.6% 0.2% 2.1% 49.5% 77.4% <lb/>Fortran Average <lb/>66.3% 2.9% 19.3% 88.5% 0.1% 0.9% 8.1% 40.2% <lb/>Overall Average <lb/>61.7% 3.8% 13.4% 79.0% 0.1% 1.4% 24.7% 55.1% <lb/>Table 2: Results of write check elimination. <lb/>place the check on a with a standard write check in the <lb/>pre-header of the current loop. If l = L M and u U A <lb/>or u = U M and l L A , then a is derived from a mono-<lb/>tonic variable and the optimizer can replace the check <lb/>on a with a range check in the loop pre-header. <lb/>To generate code for the moved checks, the optimizer <lb/>walks the expression DAG for a, generating statements <lb/>until it reaches loop invariant or constant operands. <lb/>For monotonic write check elimination, the optimizer <lb/>walks the DAG twice, generating code for the lower <lb/>bound and then the upper bound. If the write check <lb/>for a ever succeeds during program execution, the mon-<lb/>itored region service dynamically restores the elimi-<lb/>nated write check inside the loop. <lb/>4.5 Implementation Complexities <lb/>In performing these transformations, the optimizer <lb/>must take into account possible aliases that might af-<lb/>fect the value of a. As the optimizer generates code, <lb/>it maintains an alias list of all memory operands en-<lb/>countered while walking the expression DAG for a. <lb/>The optimizer precedes the range check generated for <lb/>a with a sequence of statements that create monitored <lb/>regions for each address on the alias list. At all exits to <lb/>the current loop, the optimizer inserts a code sequence <lb/>that deletes these monitored regions. Thus, alias de-<lb/>tection, like symbol table optimization, requires veri-<lb/>cation of program control ow. Further, it requires <lb/>compiler support for noti cation of exceptions, as the <lb/>MRS may need to delete monitored regions when an <lb/>exception transfers control outside of a loop. <lb/>4.5.1 Over ow <lb/>For range checks, the optimizer must also guard <lb/>against over ow. Over ow occurs when the monotonic <lb/>variable is incremented or decremented to a value that <lb/>is not in the domain of the variable&apos;s type. For ex-<lb/>ample, a 16-byte signed integer might be incremented <lb/>past 2 15 ?1, yielding a non-monotonic sequence of val-<lb/>ues. Detecting over ow requires the compiler to pro-<lb/>vide type information. The optimized code would use <lb/>this type information to verify the type consistency <lb/>of each sub-expression leading to a loop-optimized ad-<lb/>dress. <lb/>4.5.2 Reserved Registers <lb/>The MRS implementation that uses both symbol table <lb/>and loop optimization reserves ve registers. The extra <lb/>register beyond what is needed to support symbol table <lb/>optimization is used to hold one of the two bounds <lb/>computed by the range check code. <lb/>4.6 Evaluation <lb/>We evaluated the symbol table and loop optimizations <lb/>in two ways. First, we provide detailed dynamic count <lb/>data for write checks eliminated as a result of opti-<lb/>mizations. Second, we measured the runtime overhead <lb/>of the monitored region service for symbol table opti-<lb/>mization and for symbol table optimization combined <lb/>with loop optimizations. <lb/>4.6.1 Dynamic Write Check Counts <lb/>To compare the counts of write checks executed with <lb/>and without optimization, we measured the number of <lb/>checks that optimization was able to eliminate while <lb/>still insuring that all monitor hits are detected. We <lb/>also measured the number of dynamic write checks <lb/>executed in loop pre-headers generated as a result of <lb/>monotonic variable and loop invariant optimizations. <lb/>Under the headings \Checks Eliminated&quot; and \Checks <lb/>Generated,&quot; Table 2 reports these results as percent-<lb/>ages of total write instructions executed. <lb/>For seven of ten programs our optimizations were <lb/>able to eliminate more than 75% of the checks. <lb/>001.gcc1.35 and 008.espresso have the lowest per-<lb/>centage of checks eliminated. Both programs make <lb/>extensive use of C&apos;s register declaration. During de-<lb/>bugging, the C compiler keeps register declared vari-<lb/>ables in registers. Because registers are not aliased, <lb/>these declarations reduce both the need and the op-<lb/>portunity for optimization. <lb/>4.6.2 Expected Performance <lb/>We now turn to the expected overhead of the moni-<lb/>tored region service. This overhead includes all une-<lb/>liminated write checks and loop pre-header checks gen-<lb/>erated as a result of loop optimization. In addition, as <lb/>stated earlier, the MRS must check all indirect jumps <lb/>and de nitions of the %fp. <lb/>The column \Sym&quot; in Table 2 shows the e ect of us-<lb/>ing symbol table optimization on the spec benchmark. <lb/>Comparing the overheads from Section 3 reported in <lb/>Table 1, we observe that for some programs, checking <lb/>every write instruction incurs less overhead than the <lb/>analysis based implementations. This is due to the <lb/>added overhead of checking %fp de nitions and con-<lb/>trol ow. <lb/>The column \Full&quot; in Table 2 reports the overhead <lb/>of monitoring the spec benchmarks with checks elim-<lb/>inated through both symbol table and loop optimiza-<lb/>tion. These measurements are optimistic in that our <lb/>implementation does not check for either over ow or <lb/>aliases. Since all work performed for these checks is <lb/>done only on loop entry or exit, overhead for this check <lb/>will be insigni cant for loops that have large iteration <lb/>spaces. <lb/>The scienti c programs in the benchmark suite gain <lb/>the most from loop optimization. For these programs, <lb/>the costs of checking control ow and symbol table reg-<lb/>ister de nitions are subsumed by the bene t of elim-<lb/>inating most of the write checks. However, for some <lb/>system codes such as 001.gcc1.35, these costs domi-<lb/>nate, and checking every write instruction emerges as <lb/>the better choice. <lb/>5 Conclusion <lb/>Among the data breakpoint implementation methods <lb/>we studied on the Sparc architecture, we believe that <lb/>the best method is to check all write instructions using <lb/>a segmented bitmap, reserving registers to hold inter-<lb/>mediate values during address lookup. This implemen-<lb/>tation choice has several advantages. First, its over-<lb/>head is independent of the number and distribution <lb/>of monitored regions. Second, its average overhead on <lb/>the spec benchmarks is 42%, which is small when com-<lb/>pared to the cost of using unoptimized code for debug-<lb/>ging. Finally, this choice simpli es both the monitor <lb/>library and the assembly language analysis tool. The <lb/>monitor library need not initialize and maintain data <lb/>structures that support fast lookup on address ranges. <lb/>The analysis tool can simply insert checks after every <lb/>write instruction; it does not need to perform data ow <lb/>analysis on the assembly language code. <lb/>As debugging systems evolve to support more so-<lb/>phisticated register allocation, the dynamic count <lb/>of write instructions executed by a typical program <lb/>should diminish relative to the total instruction count. <lb/>This development will reduce the overhead of check-<lb/>ing every write instruction. It may also dictate that <lb/>freeing more registers for the compiler, rather than re-<lb/>serving them for write checks, will minimize the over-<lb/>head of providing a monitored region service. This <lb/>development will also decrease the importance of some <lb/>write check elimination techniques. For example, an <lb/>optimizing compiler will eliminate many of the same <lb/>write instructions whose write checks can by elimi-<lb/>nated through symbol table pattern matching. The <lb/>majority of these instructions access local variables <lb/>that, in optimized code, will reside in registers. <lb/>On processor architectures such as the i386, the dy-<lb/>namic count of write instructions will be far greater <lb/>relative to the total instruction count than on RISC <lb/>architectures such as the Sparc. Further, some appli-<lb/>cations of data breakpoints, such as detecting access <lb/>anomalies 7] in parallel programs, require the moni-<lb/>toring of read instructions as well as write instructions. <lb/>Since the dynamic count of read instructions is typi-<lb/>cally two to three times that of write instructions, the <lb/>overhead of monitoring every read and write can be <lb/>signi cant. The data ow analysis techniques outlined <lb/>in Section 4 successfully address this problem by pro-<lb/>viding a means for eliminating checks on the majority <lb/>of write instructions dynamically executed by the pro-<lb/>gram. Straightforward extensions of these techniques <lb/>will handle read instructions as well. <lb/>On the Sparc both implementation approaches <lb/>yielded data breakpoint services whose overhead is <lb/>low enough for practical use. In addition to support-<lb/>ing important debugging queries such as stop when <lb/>field f of structure s is modified, a practical <lb/>data breakpoint service opens the door for higher level <lb/>applications of data breakpoints. Data breakpoints <lb/>can be combined with control breakpoints to support <lb/>fault isolation. Using this technique, programmers can <lb/>prevent a subset of their program&apos;s code from access-<lb/>ing a given data structure. For example, a programmer <lb/>could detect corruption of library data structures such <lb/>as those used by a memory allocator. Other applica-<lb/>tions of data breakpoints include access anomaly de-<lb/>tection, data structure animation, checkpointing data <lb/>for replayed execution, and support for runtime type <lb/>checking. We are currently investigating several of <lb/>these applications. <lb/></body>

			<div type="acknowledgement">Acknowledgements <lb/>We wish to thank Oliver Sharp for his valuable com-<lb/>ments on earlier drafts of this paper. <lb/></div>

			<listBibl>References <lb/>1] A. Adl-Tabatabai and T. Gross. \Detection and Re-<lb/>covery of Endangered Variables Caused by Instruction <lb/>Scheduling,&quot;. In Programming Language Design and <lb/>Implementation, 1993. <lb/>2] A. Adl-Tabatabai and T. Gross. \Evicted Variables <lb/>and the Interaction of Global Register and Symbolic <lb/>Debugging,&quot;. In Principles of Programming Lan-<lb/>guages, pages 371{383, 1993. <lb/>3] B. Beander. \Vax DEBUG: an Interactive, Symbolic, <lb/>Multilingual Debugger,&quot;. In Proceedings of the ACM <lb/>SIGSOFT/SIGPLAN Software Engineering Sympo-<lb/>sium on High-Level Debugging, pages 173{179, August <lb/>1983. Appeared as SIGPLAN Notices 18(8). <lb/>4] T. Cargill and B. Locanthi. \Cheap Hardware Support <lb/>for Software Debugging and Pro ling,&quot;. In Proceedings <lb/>of the Second International Conference on Architec-<lb/>tural Support for Programming Languages and Oper-<lb/>ating Systems, pages 82{83, October 1987. Appeared <lb/>as SIGPLAN Notices 22(10). <lb/>5] R. Cytron, J. Ferrante, B. K. Rosen, M. N. Weg-<lb/>man, and F. K. Zadeck. \E ciently Computing Static <lb/>Single Assignment Form and the Control Dependence <lb/>Graph,&quot;. ACM Transactions on Programming Lan-<lb/>guages and Systems, 13(4):451{490, October 1991. <lb/>6] N. M. Delisle, D. E. Menicosy, and M. D. Schwartz. <lb/>\Viewing a Programming Environment As a Sin-<lb/>gle Tool,&quot;. In Proceedings of the ACM SIG-<lb/>SOFT/SIGPLAN Software Engineering Symposium <lb/>on Practical Software Development Environments, <lb/>pages 49{56, May 1984. Appeared as SIGPLAN No-<lb/>tices 19(5). <lb/>7] A. Dinning and E. Schonberg. \An Empirical Com-<lb/>parison of Monitoring Algorithms for Access Anomaly <lb/>Detection,&quot;. In ACM Symposium on Principles and <lb/>Practice of Parallel Programming, pages 1{10, 1990. <lb/>8] S. L. Graham, P. B. Kessler, and M. K. McKu-<lb/>sick. \An Execution Pro ler for Modular Programs,&quot;. <lb/>Software{Practice &amp; Experience, 13:671{685, August <lb/>1983. <lb/>9] J. L. Hennessy. \Symbolic Debugging of Optimized <lb/>Code,&quot;. ACM Transactions on Programming Lan-<lb/>guages and Systems, 4(3):323{344, July 1982. <lb/>10] Intel Corporation, Santa Clara, California. Intel 80386 <lb/>Programmer&apos;s Reference Manual, 1986. <lb/>11] M. S. Johnson. \Some Requirements for Architectural <lb/>Support of Software Debugging,&quot;. In Symposium on <lb/>Architectural Support for Programming Languages and <lb/>Operating Systems, pages 140{148, April 1982. Ap-<lb/>peared as SIGPLAN Notices 17(4). <lb/>12] G. Kane and J. Heinrich. MIPS RISC ARCHITEC-<lb/>TURE. Prentice Hall, New Jersey, 1992. <lb/>13] P. B. Kessler. \Fast Breakpoints: Design and Im-<lb/>plementation,&quot;. In Proceedings of the ACM SIG-<lb/>PLAN&apos;90 Conference on Programming Language De-<lb/>sign and Implementation, pages 78{84, White Plains, <lb/>New York, June 1990. Appeared as SIGPLAN Notices <lb/>25(6). <lb/>14] M. A. Linton. \The Evolution of Dbx,&quot;. In Proceedings <lb/>of the 1990 Usenix Summer Conference, pages 211{ <lb/>220, Anaheim, CA, June 1990. <lb/>15] J. M. Mellor-Crummey and T. J. LeBlanc. \A Soft-<lb/>ware Instruction Counter,&quot;. In Proceedings of the <lb/>Third International Conference on Architectural Sup-<lb/>port for Programming Languages and Operating Sys-<lb/>tems, pages 78{86, April 1989. Appeared as SIGPLAN <lb/>Notices 24(Special Issue). <lb/>16] Sparc International. The Sparc Architecture Manual. <lb/>Prentice-Hall, Inc., Menlo Park, CA, version 8 edition, <lb/>1992. <lb/>17] R. M. Stallman and R. H. Pesch. A Guide to the <lb/>GNU Source-Level Debugger. Free Software Founda-<lb/>tion, 4.01 revision 2.77 edition, January 1992. <lb/>18] Sun Microsystems, Inc. Programmer&apos;s Language <lb/>Guide, revision a edition, March 1990. Part Number: <lb/>800-3844-10. <lb/>19] R. Wahbe. \E cient Data Breakpoints,&quot;. In Fifth <lb/>International Conference on Architectural Support <lb/>for Programming Languages and Operating Systems, <lb/>pages 200{212, October 1992. Appeared as SIGPLAN <lb/>Notices 27(9). </listBibl>


	</text>
</tei>
