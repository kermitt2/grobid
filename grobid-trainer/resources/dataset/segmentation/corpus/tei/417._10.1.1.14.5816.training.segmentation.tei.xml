<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Use of Architecture-Altering Operations to Dynamically <lb/>Adapt a Three-Way Analog Source Identification Circuit to <lb/>Accommodate a New Source <lb/>John R. Koza <lb/>Computer Science Dept. <lb/>Stanford University <lb/>Stanford, California 94305-9020 <lb/>koza@cs.stanford.edu <lb/>http://www-cs-<lb/>faculty.stanford.edu/~koza/ <lb/>Forrest H Bennett III <lb/>Visiting Scholar <lb/>Computer Science Dept. <lb/>Stanford University <lb/>Stanford, California 94305 <lb/>forrest@evolute.com <lb/>Jason Lohn <lb/>Visiting Scholar <lb/>Computer Science Dept. <lb/>Stanford University <lb/>Stanford, California 94305 <lb/>jlohn7@leland.stanford.edu <lb/>Frank Dunlap <lb/>Dunlap Consulting <lb/>Palo Alto, California <lb/>Martin A. Keane <lb/>Martin Keane Inc. <lb/>5733 West Grover <lb/>Chicago, Illinois 60630 <lb/>makeane@ix.netcom.com <lb/>David Andre <lb/>Computer Science Division <lb/>University of California <lb/>Berkeley, California <lb/>dandre@cs.berkeley.edu <lb/>ABSTRACT <lb/>The <lb/>problem <lb/>of <lb/>source <lb/>identification involves correctly <lb/>classifying an incoming signal into <lb/>a category that identifies the <lb/>signal&apos;s source. <lb/>The problem is difficult because <lb/>information is not provided <lb/>concerning <lb/>each <lb/>source&apos;s <lb/>distinguishing characteristics and <lb/>because successive signals from the <lb/>same source differ. The source <lb/>identification problem can be made <lb/>more difficult by dynamically <lb/>changing the repertoire of sources <lb/>while the problem is being solved. <lb/>We used genetic programming to <lb/>evolve both the topology and the <lb/>sizing (numerical values) for each <lb/>component of an analog electrical <lb/>circuit that can correctly classify an <lb/>incoming analog electrical signal <lb/>into three categories. <lb/>Then, the <lb/>repertoire <lb/>of <lb/>sources <lb/>was <lb/>dynamically changed by adding a <lb/>new source during the run. The <lb/>paper <lb/>describes <lb/>how <lb/>the <lb/>architecture-altering operations <lb/>enabled genetic programming to <lb/>adapt, during the run, to the <lb/>changed environment. Specifically, <lb/>a three-way source identification <lb/>circuit was evolved and then <lb/>adapted into a four-way classifier, <lb/>during the run, thereby successfully <lb/>handling the additional new source. <lb/></front>

			<body>1. Introduction <lb/>In nature, living things exhibit considerable ability to adapt <lb/>to a change in their environment by acquiring new <lb/>capabilities. One mechanism that enables living things to <lb/>adapt involves changes in the architecture of their genome. <lb/>When we refer to architectural changes in the genome, we do <lb/>not mean mere changes in the value of an allele at a <lb/>particular preexisting location on the chromosome. Instead, <lb/>we mean a structural change that permits the manufacture of <lb/>an entirely new protein that, in turn, supports a new <lb/>structure, new behavior, or new functionality. <lb/>There is an analog in the world of computer <lb/>programming to a change in the architecture of the genome <lb/>of a living organism. That analog consists of a change in <lb/>the architecture of a computer program. When we refer to a <lb/>change in architecture of a computer program, we mean a <lb/>structural change in the program (i.e., a change in the <lb/>number of subprograms, the number of arguments possessed <lb/>by each subprogram, or the nature of the hierarchical <lb/>references among the subprograms) as opposed to a mere <lb/>change in the sequence of work-performing primitive <lb/>operations or the number of such operations in a particular <lb/>preexisting branch of the program. <lb/>The problem of source identification involves correctly <lb/>classifying an incoming signal into a category that identifies <lb/>the signal&apos;s source. The problem is difficult because <lb/>information is not provided concerning each source&apos;s <lb/>distinguishing characteristics and because successive signals <lb/>from the same source differ. <lb/>The source identification problem can be made more <lb/>difficult by dynamically changing the repertoire of sources <lb/>while the problem is being solved. This kind of change <lb/>occurs, for example, when a living organism encounters <lb/>something fundamentally new and different in its <lb/>environment (and must adapt to it). <lb/>This paper first considers the problem of evolving the <lb/>design for an analog electrical circuit that can solve the <lb/>problem of source identification for signals coming from <lb/>two different sources, each emitting various signals from a <lb/>certain range of frequencies. Each incoming signal is <lb/>identified as coming from the first source, the second source, <lb/>or neither source in this three-way version of the problem. <lb/>The paper then considers a second version of the problem <lb/>in which an additional source is dynamically introduced, <lb/>during the run, as soon as genetic programming successfully <lb/>evolves a solution to the original three-way source <lb/>identification problem. The addition of the source during the <lb/>run (thereby creating a four-way source identification <lb/>problem) can be viewed as a change in the environment. <lb/>One way to solve a source identification problem <lb/>involves evolving the design of an analog electrical circuit <lb/>that satisfies the specified goal of correctly classifying the <lb/>incoming signals as to their source. Automated design <lb/>(synthesis) of analog electronic circuits (involving both the <lb/>circuit topology and component sizing) is recognized as a <lb/>difficult problem. As Aaserud and Nielsen (1995) observe, <lb/>&quot;Analog designers are few and far between. In <lb/>contrast to digital design, most of the analog circuits <lb/>are still handcrafted by the experts or so-called &apos;zahs&apos; of <lb/>analog design. The design process is characterized by a <lb/>combination of experience and intuition and requires a <lb/>thorough knowledge of the process characteristics and <lb/>the detailed specifications of the actual product. <lb/>&quot;Analog circuit design is known to be a knowledge-<lb/>intensive, multiphase, iterative task, which usually <lb/>stretches over a significant period of time and is <lb/>performed by designers with a large portfolio of skills. <lb/>It is therefore considered by many to be a form of art <lb/>rather than a science.&quot; <lb/>When genetic programming was used to adapt to a <lb/>changing environment during the run and solve the four-way <lb/>source identification problem, we included automatically <lb/>defined functions (Koza 1992, 1994). Of course, when <lb/>automatically defined functions are used, we must address the <lb/>question of how to determine the architecture of the to-be-<lb/>evolved computer program (i.e., number of automatically <lb/>defined functions, the number of arguments that they each <lb/>possess, and the nature of the hierarchical references, if any, <lb/>among them). Architecture-altering operations (Koza 1994c) <lb/>enable genetic programming to determine the architecture of <lb/>a multi-part computer program dynamically during a run. A <lb/>change in the architecture of a multi-part computer program <lb/>during a run of genetic programming corresponds to a <lb/>change in genome structure in the natural world. Thus, we <lb/>used both automatically defined functions and architecture-<lb/>altering operation for the version of the problem in which <lb/>the number of sources changes during the run. <lb/>The architecture-altering operations for genetic <lb/>programming are motivated by the naturally occurring <lb/>mechanisms of gene duplication and gene deletion in <lb/>chromosome strings as described in Susumu Ohno&apos;s seminal <lb/>book Evolution by Gene Duplication (1970). In nature, <lb/>sexual recombination ordinarily recombines a part of the <lb/>chromosome of one parent with a homologous part of the <lb/>second parent&apos;s chromosome. However, in certain rare and <lb/>unpredictable occasions, recombination does not occur in <lb/>this normal way. A gene duplication is an aberrant <lb/>recombination event that results in the duplication of a <lb/>lengthy subsequence of nucleiotide bases of the DNA. <lb/>Ohno advanced the thesis that the creation of new <lb/>proteins (and hence new structures and new behaviors in <lb/>living things) begins with a gene duplication. <lb/>After a subsequence of nucleiotide bases that code for a <lb/>particular protein becomes duplicated in the DNA, there are <lb/>two identical ways of manufacturing the same protein (but <lb/>no immediate change in the set of proteins that are <lb/>manufactured). However, over time, some other genetic <lb/>operation, such as mutation or crossover, may change one or <lb/>the other of the two initially identical genes. Over short <lb/>periods of time, the changes accumulating in a gene may be <lb/>of no practical effect or value. As long as one of the two <lb/>genes remains unchanged, the original protein manufactured <lb/>from the unchanged gene continues to be manufactured and <lb/>the structure and behavior of the organism involved may <lb/>continue as before. The changed gene is simply carried <lb/>along in the DNA from generation to generation. <lb/>Natural selection exerts a powerful force in favor of <lb/>maintaining a gene that encodes for the manufacture of a <lb/>protein that is important for the survival and successful <lb/>performance of the organism. However, after a gene <lb/>duplication has occurred, there is usually no disadvantage <lb/>associated with the loss of a second way of manufacturing <lb/>the original protein. Consequently, natural selection usually <lb/>exerts little or no pressure to maintain a second way of <lb/>manufacturing a particular protein. Over time, the second <lb/>gene may accumulate additional changes and diverge more <lb/>and more from the original gene. Eventually the changed <lb/>gene may lead to the manufacture of a distinctly new and <lb/>different protein that actually does affect (advantageously or <lb/>disadvantageously) the structure and behavior of the living <lb/>thing. When a changed gene leads to the manufacture of a <lb/>viable and advantageous new protein, natural selection again <lb/>works to preserve that new gene. <lb/>Ohno also points out that ordinary point mutation and <lb/>crossover are insufficient to explain major changes. <lb/>&quot;...while allelic changes at already existing gene loci <lb/>suffice for racial differentiation within species as well <lb/>as for adaptive radiation from an immediate ancestor, <lb/>they cannot account for large changes in evolution, <lb/>because large changes are made possible by the <lb/>acquisition of new gene loci with previously non-<lb/>existent functions.&quot; <lb/>Ohno continues, <lb/>&quot;Only by the accumulation of forbidden mutations at <lb/>the active sites can the gene locus change its basic <lb/>character and become a new gene locus. An escape <lb/>from the ruthless pressure of natural selection is <lb/>provided by the mechanism of gene duplication. By <lb/>duplication, a redundant copy of a locus is created. <lb/>Natural selection often ignores such a redundant copy, <lb/>and, while being ignored, it accumulates formerly <lb/>forbidden mutations and is reborn as a new gene locus <lb/>with a hitherto non-existent function.&quot; (Emphasis in <lb/>original). <lb/>Ohno concludes, <lb/>&quot;Thus, gene duplication emerges as the major force <lb/>of evolution.&quot; <lb/>In other words, it is gene duplication that enables living <lb/>things to adapt to changing environments by acquiring new <lb/>structure, new behavior, and new functionality. The <lb/>analogy, in the realm of computer programming, of nature&apos;s <lb/>ability to adapt to changing environments is the set of <lb/>architecture-altering operations that enable an evolving <lb/>program to acquire new structure, new behavior, and new <lb/>functionality. <lb/>Section 2 of this paper provides background on the <lb/>process of evolving analog electrical circuits using genetic <lb/>programming. Section 3 presents the preparatory steps for <lb/>the three-way source identification problem and section 4 <lb/>presents the results. In section 5, adaptation to a changing <lb/>environment is required. In section 6, the three-way source <lb/>identification problem is first solved and, then, the four-way <lb/>version of the problem is solved during the same run. <lb/>2. Evolution of Circuits <lb/>Genetic programming is an extension of John Holland&apos;s <lb/>genetic algorithm (1975) in which the population consists <lb/>of computer programs of varying sizes and shapes (Koza <lb/>1992, 1994a, 1994b; Koza and Rice 1992). Recent work is <lb/>described in Kinnear (1994), Angeline and Kinnear (1996), <lb/>and Koza, Goldberg, Fogel, and Riolo (1996). <lb/>Genetic algorithms have been applied to the problem of <lb/>circuit synthesis in the past. For example, a CMOS <lb/>operational amplifier (op amp) circuit was designed using <lb/>the genetic algorithm with a problem-specific crossover <lb/>operation (Kruiskamp and Leenaerts 1995); however, the <lb/>topology of each op amp was one of 24 pre-selected <lb/>topologies based on the conventional human-designed stages <lb/>of an op amp. In his paper &quot;Silicon Evolution,&quot; Thompson <lb/>(1996) used a genetic algorithm to evolve a frequency <lb/>discriminator on a Xilinx 6216 reconfigurable digital gate <lb/>array operating in analog mode. <lb/>Genetic programming evolves computer programs that <lb/>are represented as rooted, point-labeled trees with ordered <lb/>branches. Genetic programming can be applied to circuits if <lb/>a mapping is established between the rooted, point-labeled <lb/>trees with ordered branches found in genetic programming <lb/>and the line-labeled cyclic graphs germane to circuits. <lb/>Gruau&apos;s innovative work on cellular encoding (1996) enables <lb/>genetic programming to evolve neural networks. <lb/>The principles of developmental biology suggest a way <lb/>to map program trees into circuits. The starting point of the <lb/>growth process can be a very simple embryonic electrical <lb/>circuit. This embryo contains certain fixed and invariant <lb/>elements for the circuit that is to be designed (e.g., the <lb/>number of inputs and outputs) as well as certain wires that <lb/>are capable of subsequent modification. An electrical circuit <lb/>is progressively developed by applying the functions in a <lb/>circuit-constructing program tree to the modifiable wires of <lb/>the embryonic circuit (and to the modifiable wires and <lb/>components of successor circuits). <lb/>The functions in the circuit-constructing program trees <lb/>include (1) connection-modifying functions that modify the <lb/>topology of the circuit, (2) component-creating functions <lb/>that insert components into the circuit, (3) arithmetic-<lb/>performing functions that appear in arithmetic-performing <lb/>subtrees as argument(s) to the component-creating functions <lb/>and that fix the component&apos;s numerical value, and possibly <lb/>(4) calls to automatically defined functions (if used). <lb/>The developmental process for converting a program tree <lb/>into a circuit begins with an embryonic circuit. Figure 1 <lb/>shows a one-input, one-output embryonic circuit. This <lb/>embryo contains a voltage source VSOURCE connected to <lb/>nodes 0 (ground) and 1, a fixed source resistor RSOURCE <lb/>between nodes 1 and 2, a modifiable wire Z0 between nodes <lb/>2 and 3, a fixed isolating wire ZOUT between nodes 3 and <lb/>5, a fixed output point (voltage probe) VOUT at node 5, and <lb/>a fixed load resistor RLOAD between nodes 5 and ground. <lb/>Only the modifiable wire Z0 is subject to modification <lb/>during the developmental process. <lb/>Figure 1 Embryonic circuit. <lb/>Each circuit-constructing program tree in the population <lb/>contains component-creating functions and connection-<lb/>modifying functions. Each connection-modifying function <lb/>in a program tree points to an associated highlighted <lb/>component and modifies the topology of the developing <lb/>circuit. Each branch of the program tree is created in <lb/>accordance with a constrained syntactic structure. Branches <lb/>are composed from construction-continuing subtrees that <lb/>continue the developmental process and arithmetic-<lb/>performing subtrees that set the value of components. <lb/>Connection-modifying functions have one or more <lb/>construction-continuing subtrees, but no arithmetic-<lb/>performing subtrees. Component-creating functions have <lb/>one construction-continuing subtree (and often an arithmetic-<lb/>performing subtree). Structure-preserving crossover with <lb/>point typing preserves the constrained syntactic structure. <lb/>The component-creating functions insert a component <lb/>into the developing circuit and assign component value(s) to <lb/>the component. Each component-creating function has a <lb/>writing head that points to an associated highlighted <lb/>component in the developing circuit and modifies the <lb/>highlighted component in a specified way. The construction-<lb/>continuing subtree of each component-creating function <lb/>points to a successor function or terminal in the circuit-<lb/>constructing program tree. The arithmetic-performing <lb/>subtree of a component-creating function consists of a <lb/>composition of arithmetic functions and random constants <lb/>that specify, after interpretation, the value of a component. <lb/>Space does not permit giving details for each component-<lb/>creating and connection-modifying function. For details, see <lb/>Koza, Andre, Bennett, and Keane (1996), and Koza, Bennett, <lb/>Andre, and Keane (1996a, 1996b, 1996c, 1996d, 1997). <lb/>3. Preparatory Steps for the <lb/>Three-Way Problem <lb/>The goal is to evolve the design for an analog electrical <lb/>circuit that classifies the incoming signal into three <lb/>categories. Successive incoming signals from the same <lb/>source are different; however, their differences are small in <lb/>comparison to signals coming from another source. <lb/>Specifically, the desired circuit is to produce an output of <lb/>1/2 volt (plus or minus 240 millivolts) if the frequency of <lb/>the incoming signal is within 10% of 256 Hz, produce an <lb/>output of 1 volt (plus or minus 240 millivolts) if the <lb/>frequency of the incoming signal is within 10% of 2,560 <lb/>Hz, and otherwise produce an output of 0 volts (plus or <lb/>minus 240 millivolts). The tolerance of 240 (rather than <lb/>250) millivolts was chosen to avoid the possibility of a tie <lb/>and to clearly separate the classifications. <lb/>Before applying genetic programming to a problem of <lb/>circuit synthesis, the user must perform seven major <lb/>preparatory steps, namely (1) identifying the embryonic <lb/>circuit that is suitable for the problem, (2) determining the <lb/>architecture of the circuit-constructing program trees, (3) <lb/>identifying the terminals, (4) identifying the primitive <lb/>functions contained in the programs, (5) creating the fitness <lb/>measure, (6) choosing control parameters, and (7) setting the <lb/>termination criterion and method of result designation. <lb/>A one-input, one-output embryo (figure 1) was used. <lb/>We did not use automatically defined functions for the <lb/>three-way source identification problem. Since the <lb/>embryonic circuit has one modifiable wire (and hence one <lb/>writing head), there is one result-producing branch in each <lb/>circuit-constructing program tree. <lb/>For this problem, the function set, F ccs , for each <lb/>construction-continuing subtree is <lb/>F ccs = {R, L, C, SERIES, PSS, PSL, FLIP, NOP, <lb/>T_PAIR_CONNECT_0, T_PAIR_CONNECT_1}. <lb/>The terminal set, T ccs , for each construction-continuing <lb/>subtree is <lb/>T ccs = {END, SAFE_CUT}. <lb/>The function set, F aps, for each arithmetic-performing <lb/>subtree is <lb/>Faps = {+, -}. <lb/>The terminal set for an arithmetic-performing subtree is <lb/>Taps = {ℜ}, <lb/>where ℜ represents random constants from -1.0 to +1.0. <lb/>The evaluation of fitness for each individual circuit-<lb/>constructing program tree in the population begins with its <lb/>execution. This execution applies the functions in the <lb/>program tree to the embryonic circuit, thereby developing <lb/>the embryonic circuit into a fully developed circuit. A <lb/>netlist describing the fully developed circuit is then created. <lb/>The netlist identifies each component of the circuit, the <lb/>nodes to which that component is connected, and the value <lb/>of that component. Each circuit is then simulated to <lb/>determine its behavior. <lb/>The 217,000-line SPICE <lb/>(Simulation Program with Integrated Circuit Emphasis) <lb/>simulation program (Quarles et al. 1994) was modified to <lb/>run as a submodule within the genetic programming system. <lb/>For this problem, the voltage VOUT is probed at node 5 <lb/>and the circuit is simulated in the frequency domain. <lb/>SPICE is requested to perform an AC small signal analysis <lb/>and to report the circuit&apos;s behavior for each of 101 frequency <lb/>values chosen over four decades of frequency (between 1 and <lb/>10,000 Hz). Each decade is divided into 25 parts (using a <lb/>logarithmic scale). <lb/>Fitness is measured in terms of the sum, over these 101 <lb/>fitness cases, of the absolute weighted deviation between the <lb/>actual value of the output voltage at the probe point VOUT <lb/>and the target value for voltage. <lb/>The three points that are closest to the band located <lb/>within 10% of 256 Hz are 229.1 Hz, 251.2 Hz, and 275.4 <lb/>Hz. The procedure for each of these three points is as <lb/>follows: If the voltage equals the ideal value of 1/2 volts in <lb/>this interval, the deviation is 0.0. If the voltage is within <lb/>240 millivolts of 1/2 volts, the absolute value of the <lb/>deviation from 1/2 volts is weighted by a factor of 20. If <lb/>the voltage is more than 240 millivolts from 1/2 volts, the <lb/>absolute value of the deviation from 1/2 volts is weighted <lb/>by a factor of 200. This arrangement reflects the fact that <lb/>the ideal output voltage for this range of frequencies is 1/2 <lb/>volt, that a 240 millivolts discrepancy is acceptable, and that <lb/>a larger discrepancy is not acceptable. <lb/>The three points that are closest to the band located <lb/>within 10% of 2,560 Hz are 2,291 Hz, 2,512 Hz, and 2,754 <lb/>Hz. The procedure for each of these three points is as <lb/>follows: If the voltage equals the ideal value of 1 volt in this <lb/>interval, the deviation is 0.0. If the voltage is within 240 <lb/>millivolts of 1 volt, the absolute value of the deviation from <lb/>1 volt is weighted by a factor of 20. If the voltage is more <lb/>than 240 millivolts from 1 volt, the absolute value of the <lb/>deviation from 1 volt is weighted by a factor of 200. <lb/>The procedure for each of the remaining 95 points is as <lb/>follows: If the voltage equals the ideal value of 0 volts, the <lb/>deviation is 0.0. If the voltage is within 240 millivolts of 0 <lb/>volts, the absolute value of the deviation from 0 volts is <lb/>weighted by a factor of 1.0. If the voltage is more than 240 <lb/>millivolts from 0 volts, the absolute value of the deviation <lb/>from 0 volt is weighted by a factor of 10. <lb/>Greater weights (20 and 200) were used in the two <lb/>passbands because they contain only 6 of the 101 points. <lb/>Many of the circuits that are created in the initial random <lb/>population and many that are created by the crossover and <lb/>mutation operations cannot be simulated by SPICE. Such <lb/>circuits are assigned a high penalty value of fitness (10 8 ). <lb/>The number of hits was defined as the number of fitness <lb/>cases (0 to 101) for which the voltage is acceptable or ideal. <lb/>The population size, M, was 640,000. The percentage <lb/>of genetic operations on each generation was 89% one-<lb/>offspring crossovers, 10% reproductions, and 1% mutations. <lb/>The architecture-altering operations were not used on this <lb/>problem. Since only one result-producing branch was used <lb/>in the embryo for this problem, the maximum size, H rpb , <lb/>for the result-producing branch was 600 points. The other <lb/>parameters for controlling the runs of genetic programming <lb/>were the default values specified in Koza 1994 (appendix D). <lb/>This problem was run on a medium-grained parallel <lb/>Parsytec computer system consisting of 64 80-MHz Power <lb/>PC 601 processors arranged in a toroidal mesh with a host <lb/>PC Pentium type computer. The distributed genetic <lb/>algorithm was used with a population size of Q = 10,000 at <lb/>each of the D = 64 demes. On each generation, four <lb/>boatloads of emigrants, each consisting of B = 2% (the <lb/>migration rate) of the node&apos;s subpopulation (selected on the <lb/>basis of fitness) were dispatched to each of the four <lb/>toroidally adjacent processing nodes (Andre and Koza 1996). <lb/>4. Results for the Three-Way <lb/>Source Identification Problem <lb/>A satisfactory solution to the problem was found on our <lb/>first run of this problem. <lb/>The best circuit from generation 0 (figure 2) has a fitness <lb/>of 286.2 and scores 64 hits. It has no inductors, two <lb/>capacitors, and two resistors (in addition to the source and <lb/>load resistors in the embryo). <lb/>Figure 5 shows the behavior of the best circuit of <lb/>generation 0 in the frequency domain. The horizontal axis is <lb/>logarithmic and ranges between 1 and 10,000 Hz. Notice <lb/>that this inadequate circuit pays no special attention to the <lb/>frequencies around 256 Hz and 2,560 Hz. <lb/>The best circuit from generation 20 (figure 3) has a <lb/>fitness of 129.1 and 76 hits. Figure 6 shows its behavior. <lb/>Notice the distinct areas around 256 and 2,560 Hz. <lb/>The best circuit from generation 106 (figure 4) achieves a <lb/>fitness of 21.4 and scores 101 hits. It has seven inductors, <lb/>15 capacitors, and four resistors. Figure 7 shows its <lb/>behavior in the frequency domain. This circuit produces an <lb/>output voltage in the correct band for incoming signals from <lb/>the first source, the second source, and neither source. <lb/>Figure 2 Best circuit of generation 0. <lb/>Figure 3 Best circuit of generation 20. <lb/>Figure 4 Best circuit of generation 106. <lb/>Figure 5 Frequency domain behavior of the best <lb/>circuit of generation 0. <lb/>Figure 6 Frequency domain behavior of the best <lb/>circuit of generation 20. <lb/>Figure 7 Frequency domain behavior of the best <lb/>circuit of generation 106. <lb/>5. Preparatory Steps for the <lb/>Changing Environment Problem <lb/>The goal is to evolve the design for a circuit that changes its <lb/>structure as the number of different sources increases. <lb/>Initially the circuit classifies incoming signals into three <lb/>categories. Later the circuit undergoes modification so that <lb/>it can successfully classify signals into four categories. <lb/>During the first phase, the requirements for the desired <lb/>circuit are similar to those for the tri-state frequency <lb/>discriminator except that one of the desired outputs is 1/3 <lb/>volt (instead of 1/2 volt). Specifically, the desired circuit is <lb/>to produce an output of 1/3 volts (plus or minus 166 <lb/>millivolts) if the frequency of the incoming signal is within <lb/>10% of 256 Hz, produce an output of 1 volt (plus or minus <lb/>166 millivolts) if the frequency of the incoming signal is <lb/>within 10% of 2,560 Hz, and otherwise produce an output of <lb/>0 volts (plus or minus 166 millivolts). <lb/>After a circuit is evolved that performs the tri-state task, <lb/>the requirements are changed to include an additional <lb/>frequency band. The run is continued with the existing <lb/>population until a new circuit is evolved that performs the <lb/>new task. Specifically, during the second phase, the circuit <lb/>is to produce an output of 2/3 volts (plus or minus 166 <lb/>millivolts) if the frequency of a signal is within 10% of 750 <lb/>Hz while still producing an output of 1/3, 1, and 0 volts <lb/>(plus or minus 166 millivolts) for the original three signals. <lb/>When genetic programming was called upon to adapt to a <lb/>changing environment during the run and solve the four-way <lb/>source identification problem, we included automatically <lb/>defined functions. Since the embryonic circuit has one <lb/>modifiable wire (and hence one writing head), there is one <lb/>result-producing branch in each circuit-constructing program <lb/>tree. Each program in the initial population of programs <lb/>has a uniform architecture with no automatically defined <lb/>functions. The number of automatically defined functions, if <lb/>any, will emerge as a consequence of the evolutionary <lb/>process using the architecture-altering operations. <lb/>The set of potential new functions, F potential , is <lb/>F potential = {ADF0, ADF1}. <lb/>The set of potential new terminals, T potential , is <lb/>T potential = {ARG0}. <lb/>The architecture-altering operations change the function <lb/>set, F ccs , for each construction-continuing subtree of the <lb/>result-producing and function-defining branches, so <lb/>F ccs = F ccs-initial ∪ F potential . <lb/>The architecture-altering operations change the terminal <lb/>set, T aps-adf , for each arithmetic-performing subtree, so <lb/>T aps-adf = T aps-initial ∪ T potential . <lb/>During the first phase, there are only two frequencies of <lb/>interest (256 Hz and 2,560 Hz); however, in the second <lb/>phase, there are three frequencies of interest (750 Hz in <lb/>addition to the two just mentioned). <lb/>In the first phase, fitness is computed as follows. <lb/>The procedure for each of the three points that are closest <lb/>to the band located within 10% of 256 Hz is as follows: If <lb/>the voltage equals the ideal value of 1/3 volts in this <lb/>interval, the deviation is 0.0. If the voltage is more than <lb/>166 millivolts from 1/3 volts, the absolute value of the <lb/>deviation from 1/3 volts is weighted by a factor of 20. If <lb/>the voltage is more than 166 millivolts from 1/3 volts, the <lb/>absolute value of the deviation from 1/3 volts is weighted <lb/>by a factor of 200. <lb/>The procedure for each of the three points that are closest <lb/>to the band located within 10% of 2,560 is as follows: If the <lb/>voltage equals the ideal value of 1 volt in this interval, the <lb/>deviation is 0.0. If the voltage is within 166 millivolts of 1 <lb/>volt, the absolute value of the deviation from 1 volt is <lb/>weighted by a factor of 20. If the voltage is more than 166 <lb/>millivolts from 1 volt, the absolute value of the deviation <lb/>from 1 volt is weighted by a factor of 200. <lb/>The procedure for each of the remaining 95 points is as <lb/>follows: If the voltage equals the ideal value of 0 volts, the <lb/>deviation is 0.0. If the voltage is within 166 millivolts of 0 <lb/>volts, the absolute value of the deviation from 0 volts is <lb/>weighted by a factor of 1.0. If the voltage is more than 166 <lb/>millivolts from 0 volts, the absolute value of the deviation <lb/>from 0 volt is weighted by a factor of 10. <lb/>Greater weights (20 and 200) were used in the two <lb/>passbands because they contain only 6 of the 101 points. <lb/>In the second phase, there is a source with a frequency of <lb/>around 750 Hz. <lb/>The procedure for each of the three points that are closest <lb/>to the band located within 10% of 750 Hz is as follows: If <lb/>the voltage equals the ideal value of 2/3 volts in this <lb/>interval, the deviation is 0.0. If the voltage is more than <lb/>166 millivolts from 2/3 volts, the absolute value of the <lb/>deviation from 2/3 volts is weighted by a factor of 15. If <lb/>the voltage is more than 166 mV of 2/3 volts, the absolute <lb/>value of the deviation from 2/3 volts is weighted by 150. <lb/>In the second phase, the procedure for the six points <lb/>nearest 256 Hz and 2,560 Hz are the same as above, except <lb/>that the weight is 15 and 150 (instead of 20 and 200), <lb/>respectively for the complaint and non-complaint points. <lb/>Lesser weights (15 and 150) were used in the three passbands <lb/>because 9 of the 101 points lie in the passbands. <lb/>In the second phase, the procedure for each of the <lb/>remaining 92 points is as follows: If the voltage equals the <lb/>ideal value of 0 volts, the deviation is 0.0. If the voltage is <lb/>within 166 millivolts of 0 volts, the absolute value of the <lb/>deviation from 0 volts is weighted by a factor of 1.0. If the <lb/>voltage is more than 166 mV from 0 volts, the absolute <lb/>value of the deviation from 0 is weighted by a factor of 10. <lb/>The control parameters were the same as above, except <lb/>for the following: The architecture-altering operations were <lb/>used sparingly on each generation. The percentage of <lb/>operations on each generation after generation 5 were 86.5% <lb/>one-offspring crossovers; 10% reproductions; 1% mutations; <lb/>1% branch duplications; 0.5% branch deletions; and 1% <lb/>branch creations. Since we did not want to waste large <lb/>amounts of computer time in early generations where only a <lb/>few programs have any automatically functions at all, the <lb/>percentage of operations on each generation before <lb/>generation 6 was 78.0% one-offspring crossovers; 10% <lb/>reproductions; 1% mutations; 5.0% branch duplications; 1% <lb/>branch deletions; and 5.0% branch creations. The maximum <lb/>size, H rpb , for the result-producing branch was 600 points. <lb/>The maximum number of automatically defined functions <lb/>was 2. The number of arguments for each automatically <lb/>defined function is 1. The maximum size, H adf , for each of <lb/>the automatically defined functions, if any, is 300 points. <lb/>6. Results with the Changing <lb/>Environment <lb/>The best circuit from generation 0 (figure 11) has a fitness <lb/>of 200246.8 and 68 hits. Figure 14 shows its behavior. <lb/>The best circuit from generation 41 achieves a fitness of <lb/>200015.5 and 100 hits. It has 12 inductors, 13 capacitors, <lb/>and two resistors (in addition to the source and load resistors <lb/>in the embryo). Because of the action of the architecture-<lb/>altering operations, there is one automatically defined <lb/>function in the program tree for this circuit. ADF0 is <lb/>invoked three times by the result-producing branch. Figure <lb/>8 shows the best circuit from generation 41 before the three <lb/>occurrences of ADF0 are expanded. <lb/>Figure 8 Best circuit from generation 41 before <lb/>expanding the three occurrences of ADF0. <lb/>ADF0 develops differently in different contexts. In figure <lb/>9, ADF0 develops into one 326 nF capacitor in two <lb/>instances (labeled ADF0-1 and ADF0-2 in figure 8). <lb/>Figure 9 <lb/>Result of developing ADF0-1 and <lb/>ADF0-2 for the best circuit from generation 41. <lb/>As shown in figure 10, ADF0 develops into two <lb/>inductors and three capacitors in the third instance (labeled <lb/>ADF0-3 in figure 8). <lb/>Figure 10 Result of developing ADF0 for the <lb/>best circuit from generation 41. <lb/>Figure 12 shows the best circuit from generation 41 after <lb/>expanding the three occurrences of ADF0. Figure 15 shows <lb/>the behavior of the best circuit of generation 41 in the <lb/>frequency domain. Notice the emergence of two distinct <lb/>peaks around 256 Hz and 2,560 Hz. <lb/>The best circuit (figure 13) from generation 85 achieves a <lb/>fitness of 404.3. It scores a total of 199 hits, including all <lb/>101 hits possible from the first phase. It has 23 inductors, <lb/>20 capacitors, and five resistors (in addition to the source and <lb/>load resistors in the embryo). ADF0 is invoked twice. <lb/>Figure 13 shows the best circuit from generation 85 after <lb/>expanding its two automatically defined functions, ADF0 <lb/>and ADF1. Figure 16 shows the behavior of the best circuit <lb/>of generation 85 in the frequency domain. <lb/>7. Computer Time <lb/>The run for the three-way frequency discriminator described <lb/>above took 43 hours and processed about 67,840,000 <lb/>individuals through the SPICE simulation and the other <lb/>steps. The 64 80 MHertz processors operate together at a <lb/>combined rate of 5.12 giga Hertz, so that there were about 8 <lb/>× 10 14 clock cycles in the run. The run for the changing <lb/>environment described above took about 48 hours (about 9 × <lb/>10 14 clock cycles). We make the rough approximation of <lb/>one clock cycle to one computer operation and round off <lb/>both of the above numbers to 10 15 operations. <lb/>Noting that the human brain has about 10 12 neurons <lb/>operating at an approximately millisecond rate, we designate <lb/>the gross quantity of 10 15 operations as a brain second (1 <lb/>bs) of computer operations. Thus, both versions of the <lb/>source identification problem used about one brain second <lb/>(i.e., a petaflop of operations spread over two days, instead <lb/>of one second) to produce a satisfactory circuit. However, as <lb/>described in Enabling Technologies for Petaflops <lb/>Computing (Sterling, Messina, and Smith 1995), the era of <lb/>petaflops computing (in which 10 15 operations are <lb/>performed in one second) is imminent. <lb/>Interestingly, six other problems solved with genetic <lb/>programming and one other solved with another <lb/>evolutionary algorithm have required approximately one <lb/>brain second to produce a result that is arguably competitive <lb/>with the result produced by humans on the same problem. <lb/>Approximately 1 brain second was required to evolve a <lb/>one-dimensional cellular automata rule for the majority <lb/>classification task whose accuracy (82.326%) exceeds that of <lb/>the original 1978 human-written Gacs-Kurdyumov-Levin <lb/>(GKL) rule, all other known subsequent human-written <lb/>rules, and all other known rules produced by automated <lb/>approaches for this problem (Andre, Bennett, and Koza <lb/>1996). <lb/>Also, the performance of four different versions of <lb/>genetic programming (Koza 1994a, Koza and Andre 1996a, <lb/>1996b) on the transmembrane segment identification <lb/>problem is slightly superior to that of algorithms written by <lb/>knowledgeable human investigators. Approximately 1 brain <lb/>second was required to produce each of these four results. <lb/>Figure 11 Best circuit from generation 0. <lb/>Figure 12 Best circuit from generation 41 after <lb/>expanding the three occurrences of ADF0. <lb/>Figure 13 Best circuit from generation 85 after <lb/>expanding its automatically defined functions. <lb/>In addition, approximately 1 brain second of <lb/>computational effort was required for the runs of genetic <lb/>programming that successfully evolved protein motifs for <lb/>detecting the D-E-A-D box family of proteins and for <lb/>detecting the manganese superoxide dismutase family as well <lb/>or better than the comparable human-written motifs found in <lb/>the PROSITE database (Koza and Andre 1996c). <lb/>Juille&apos;s discovery (1995), using evolutionary <lb/>computation, of a sorting network for 13 items that was <lb/>smaller than the best network in Knuth (1973) consumed <lb/>approximately 0.8 brain seconds (Juillie 1997). <lb/>Figure 14 <lb/>Frequency domain behavior of the <lb/>best circuit of generation 0. <lb/>Figure 15 Frequency domain behavior of the best <lb/>circuit of generation 41. <lb/>Figure 16 Frequency domain behavior of the best <lb/>circuit of generation 85. <lb/>8. Conclusion <lb/>Genetic programming successfully evolved both the <lb/>topology and the sizing for an analog electrical circuit that <lb/>can perform source identification by correctly classifying an <lb/>incoming analog electrical signal into three categories. <lb/>Then, as the repertoire of sources was dynamically changed <lb/>during the run, architecture-altering operations enabled <lb/>genetic programming to adapt to a changed environment <lb/>dynamically during a run. Specifically, a three-way source <lb/>identification circuit was evolved and then adapted, during <lb/>the run, to successfully handle the additional source. <lb/></body>

			<listBibl>References <lb/>Aaserud, O. and Nielsen, I. Ring. 1995. Trends in current <lb/>analog design: A panel debate. Analog Integrated Circuits <lb/>and Signal Processing. 7(1) 5-9. <lb/>Andre, David, Bennett III, Forrest H, and Koza, John R. <lb/>1996. Discovery by genetic programming of a cellular <lb/>automata rule that is better than any known rule for the <lb/>majority classification problem. In Koza, John R., <lb/>Goldberg, D. E., Fogel, D. B., and Riolo, R. L. (editors). <lb/>Genetic Programming 1996: Proceedings of the First <lb/>Annual Conference. Cambridge, MA: MIT Press. <lb/>Andre, David and Koza, John R. 1996. Parallel genetic <lb/>programming: A scalable implementation using the <lb/>transputer architecture. In Angeline, P. J. and Kinnear, <lb/>K. E. Jr. (editors). 1996. Advances in Genetic <lb/>Programming 2. Cambridge: MIT Press. <lb/>Angeline, P. J. and Kinnear, K. E. Jr. (editors). 1996. <lb/>Advances in Genetic Programming 2. Cambridge, MA: <lb/>MIT Press. <lb/>Gruau, Frederic. 1996. Artificial cellular development in <lb/>optimization and compilation. In Sanchez, Eduardo and <lb/>Tomassini, Marco (editors). 1996. Towards Evolvable <lb/>Hardware. Lecture Notes in Computer Science, Volume <lb/>1062. Berlin: Springer-Verlag. Pages 48 -75. <lb/>Holland, John H. 1975. Adaptation in Natural and <lb/>Artificial Systems. Ann Arbor, MI: University of <lb/>Michigan Press. <lb/>Juille, Hugues. 1995. Evolution of non-deterministic <lb/>incremental algorithms as a new approach for search in <lb/>state spaces. In Eshelman, L. J. (editor). Proceedings of <lb/>the Sixth International Conference on Genetic <lb/>Algorithms. San Francisco: Morgan Kaufmann. 351-358. <lb/>Juille, Hugues. 1997. Personal communication. <lb/>Kinnear, Kenneth E. Jr. (editor). 1994. Advances in <lb/>Genetic Programming. Cambridge, MA: MIT Press. <lb/>Knuth, Donald E. <lb/>1973. The Art of Computer <lb/>Programming. Vol. 3. Reading, MA: Addison-Wesley. <lb/>Koza, John R. 1992. Genetic Programming: On the <lb/>Programming of Computers by Means of Natural <lb/>Selection. Cambridge, MA: MIT Press. <lb/>Koza, John R. 1994a. Genetic Programming II: Automatic <lb/>Discovery of Reusable Programs. Cambridge: MIT Press. <lb/>Koza, John R. 1994b. Genetic Programming II Videotape: <lb/>The Next Generation. Cambridge, MA: MIT Press. <lb/>Koza, John R. 1994c. Architecture-altering operations for <lb/>evolving the architecture of a multi-part program in <lb/>genetic programming. Stanford University Computer <lb/>Science Dept. technical report STAN-CS-TR-94-1528. <lb/>Koza, John R. and Andre, David. 1996a. Classifying <lb/>protein segments as transmembrane domains using <lb/>architecture-altering operations in genetic programming. <lb/>In Angeline, Peter J. and Kinnear, Kenneth E. Jr. <lb/>(editors). 1996. Advances in Genetic Programming II. <lb/>Cambridge, MA: MIT Press. <lb/>Koza, John R. and Andre, David. 1996b. Evolution of <lb/>iteration in genetic programming. In Evolutionary <lb/>Programming V: Proceedings of the Fifth Annual <lb/>Conference Cambridge, MA: MIT Press. <lb/>Koza, John R. and Andre, David. 1996c. Automatic <lb/>discovery of protein motifs using genetic programming. <lb/>In Yao, Xin (editor). 1996. Evolutionary Computation: <lb/>Theory and Applications. Singapore: World Scientific. <lb/>Koza, John R., Andre, David, Bennett III, Forrest H, and <lb/>Keane, Martin A. 1996. Use of automatically defined <lb/>functions and architecture-altering operations in automated <lb/>circuit synthesis using genetic programming. In Koza, <lb/>John R., Goldberg, D. E., Fogel, D. B., and Riolo, R. L. <lb/>(editors). 1996. Genetic Programming 1996: <lb/>Proceedings of the First Annual Conference. Cambridge, <lb/>MA: MIT Press. <lb/>Koza, John R., Bennett III, Forrest H, Andre, David, and <lb/>Keane, Martin A. 1996a. Toward evolution of electronic <lb/>animals using genetic programming. Artificial Life V: <lb/>Proceedings of the Fifth International Workshop on the <lb/>Synthesis and Simulation of Living Systems. <lb/>Cambridge, MA: The MIT Press. <lb/>Koza, John R., Bennett III, Forrest H, Andre, David, and <lb/>Keane, Martin A. 1996b. Four problems for which a <lb/>computer program evolved by genetic programming is <lb/>competitive with human performance. Proceedings of the <lb/>1996 IEEE International Conference on Evolutionary <lb/>Computation. IEEE Press. Pages 1-10. <lb/>Koza, John R., Bennett III, Forrest H, Andre, David, and <lb/>Keane, Martin A. 1996c. Automated design of both the <lb/>topology and sizing of analog electrical circuits using <lb/>genetic programming. In Gero, John S. and Sudweeks, <lb/>Fay (editors). Artificial Intelligence in Design &apos;96. <lb/>Dordrecht: Kluwer. Pages 151-170. <lb/>Koza, John R., Bennett III, Forrest H, Andre, David, and <lb/>Keane, Martin A. 1996d. Automated WYWIWYG design <lb/>of both the topology and component values of analog <lb/>electrical circuits using genetic programming. In Koza, <lb/>John R., Goldberg, D. E., Fogel, D. B., and Riolo, R. L. <lb/>(editors). 1996. Genetic Programming 1996: <lb/>Proceedings of the First Annual Conference. Cambridge, <lb/>MA: MIT Press. <lb/>Koza, John R., Bennett III, Forrest H, Andre, David, and <lb/>Keane, Martin A. 1997. Evolution using genetic <lb/>programming of a low-distortion 96 Decibel operational <lb/>amplifier. Proceedings of the 1997 ACM Symposium on <lb/>Applied Computing, San Jose, California, February 28 -<lb/>March 2, 1997. New York: Association for Computing <lb/>Machinery. Pages 207 -216. <lb/>Koza, John R., Goldberg, D. E., Fogel, D. B., and Riolo, <lb/>R. L. (editors). 1996. Genetic Programming 1996: <lb/>Proceedings of the First Annual Conference. Cambridge, <lb/>MA: The MIT Press. <lb/>Koza, John R., and Rice, James P. 1992. Genetic <lb/>Programming: The Movie. Cambridge, MA: MIT Press. <lb/>Kruiskamp, Marinum Wilhelmus and Leenaerts, Domine. <lb/>1995. DARWIN: CMOS opamp synthesis by means of a <lb/>genetic algorithm. Proceedings of the 32nd Design <lb/>Automation Conference. New York, NY: Association for <lb/>Computing Machinery. 433-438. <lb/>Ohno, Susumu. 1970. Evolution by Gene Duplication. <lb/>New York: Springer-Verlag. <lb/>Quarles, Thomas, Newton, A. R., Pederson, D. O., and <lb/>Sangiovanni-Vincentelli, A. 1994. SPICE 3 Version <lb/>3F5 User&apos;s Manual. Dept. of Electrical Engineering and <lb/>Computer Science, Univ. of California, Berkeley, CA. <lb/>Sterling, Thomas, Messina, Paul, and Smith, Paul H. <lb/>1995. Enabling Technologies for Petaflops Computing. <lb/>Cambridge, MA: The MIT Press. <lb/>Thompson, Adrian. 1996. Silicon evolution. In Koza, <lb/>John R., Goldberg, D. E., Fogel, D. B., and Riolo, R. L. <lb/>(editors). 1996. Genetic Programming 1996: <lb/>Proceedings of the First Annual Conference. Cambridge, <lb/>MA: MIT Press. <lb/></listBibl>

			<front>Version 2 -G-084 -Camera-Ready -Submitted <lb/>March 25, 1997 to GP-97 Conference </front>


	</text>
</tei>
