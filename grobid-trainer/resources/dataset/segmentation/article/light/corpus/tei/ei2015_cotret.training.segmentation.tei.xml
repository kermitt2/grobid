<?xml version="1.0" ?>
<tei>
	<teiHeader>
		<fileDesc xml:id="__ei2015_cotret"/>
	</teiHeader>
	<text xml:lang="en">
			<titlePage>Embedded wavelet-based face recognition under variable <lb/> position <lb/> Pascal Cotret, Stéphane Chevobbe, Mehdi Darouich <lb/> To cite this version: <lb/> Pascal Cotret, Stéphane Chevobbe, Mehdi Darouich. Embedded wavelet-based face recogni-<lb/>tion under variable position. IS&amp;T/SPIE Electronic Imaging, Real-Time Image and Video <lb/>Processing 2015, Feb 2015, San Francisco, United States. &lt;hal-01109340&gt; <lb/> HAL Id: hal-01109340 <lb/>https://hal.archives-ouvertes.fr/hal-01109340 <lb/> Submitted on 26 Jan 2015 <lb/> HAL is a multi-disciplinary open access <lb/>archive for the deposit and dissemination of sci-<lb/>entific research documents, whether they are pub-<lb/>lished or not. The documents may come from <lb/>teaching and research institutions in France or <lb/>abroad, or from public or private research centers. <lb/>L&apos;archive ouverte pluridisciplinaire HAL, est <lb/>destinée au dépôt et a la diffusion de documents <lb/>scientifiques de niveau recherche, publiés ou non, <lb/>´ emanant des etablissements d&apos;enseignement et de <lb/>recherche français oú etrangers, des laboratoires <lb/>publics ou privés. <lb/></titlePage>

			<front> Embedded wavelet-based face recognition under variable <lb/>position <lb/> Pascal Cotret  a  , Stéphane Chevobbe  a  and Mehdi Darouich  a <lb/>a  CEA, LIST, Laboratoire Adéquation Algorithme Architecture, Gif-sur-Yvette, F-91191 France <lb/> ABSTRACT <lb/> For several years, face recognition has been a hot topic in the image processing field: this technique is applied <lb/>in several domains such as CCTV, electronic devices delocking and so on. In this context, this work studies the <lb/>efficiency of a wavelet-based face recognition method in terms of subject position robustness and performance <lb/>on various systems. The use of wavelet transform has a limited impact on the position robustness of PCA-based <lb/>face recognition. This work shows, for a well-known database (Yale face database B  *  ), that subject position in <lb/>a 3D space can vary up to 10% of the original ROI size without decreasing recognition rates. Face recognition <lb/>is performed on approximation coefficients of the image wavelet transform: results are still satisfying after 3 <lb/>levels of decomposition. Furthermore, face database size can be divided by a factor 64 (2  2K  with K = 3). In <lb/>the context of ultra-embedded vision systems, memory footprint is one of the key points to be addressed; that <lb/>is the reason why compression techniques such as wavelet transform are interesting. Furthermore, it leads to <lb/>a low-complexity face detection stage compliant with limited computation resources available on such systems. <lb/>The approach described in this work is tested on three platforms from a standard x86-based computer towards <lb/>nanocomputers such as RaspberryPi and SECO boards. For K = 3 and a database with 40 faces, the execution <lb/>mean time for one frame is 0.64 ms on a x86-based computer, 9 ms on a SECO board and 26 ms on a RaspberryPi <lb/>(B model). <lb/> Keywords: wavelet, face recognition, eigenfaces, embedded systems, high-constrained systems <lb/></front>

			<body> 1. INTRODUCTION <lb/> One of the key challenges in embedded systems design is to maintain a compromise between application efficiency <lb/>(i.e. computing power) and systems resources consumption (in terms of power, area and memory footprint, etc.). <lb/>In the image processing context, and especially in face recognition using subspace learning method such as <lb/>eigenfaces,  1  the computing power is directly proportional to input images resolution. Thus, by limiting memory <lb/>size and memory accesses, processing time must decrease in a significant manner. A previous work by Courroux <lb/>et al.  2  revealed an efficient method to decrease the input image resolution based on the computation of a wavelet-<lb/>based transform, such as the LeGall 5/3 wavelet, on the input image. By using only approximation coefficients as <lb/>input, the amount of data to be processed is divided by a factor 2  2K  (K being the wavelet decomposition level). <lb/>This method can be hardened against illumination variation by the preprocessing of the ROI with a region-based <lb/>equalization.  2 <lb/> Using this approach, the computing power required for a correct face recognition as well as the amount <lb/>of memory required for database storage are strongly decreased. It allows us to consider the use of low-cost <lb/>embedded systems, including low-performance embedded processors and small amounts of embedded memory. <lb/>This work studies the robustness of a wavelet-based eigenfaces approach under several level of decomposition <lb/>against 3D face position shifting. This work analyzes the impact of face position in relation to the snapshot used <lb/>for learning purposes; face databases (Yale and a custom video) are also used to measure the robustness against <lb/>light variation as well. <lb/>The paper is organized as follows. Section 2 presents related works. Section 3 describes the wavelet-based <lb/>based recognition method used in this work. Section 4 studies the approach robustness (i.e. its tolerance in terms <lb/>of face position). Section 5 summarizes several performance results. Finally, Section 6 gives some conclusions <lb/>and persectives. <lb/> </body>
			
			<front>Pascal Cotret. E-mail: pascal.cotret@gmail.com, Telephone: +33 (0)2 99 84 45 77 <lb/>  *  http://vision.ucsd.edu/~leekc/ExtYaleDatabase/ExtYaleB.html <lb/></front> 
			
			<body>2. RELATED WORKS <lb/> Face recognition methods are sensible to image variations such as illumination variation, subject misalignment or <lb/>facial corruptions/occlusions. In the literature, many methods have been studied to overcome the misalignment <lb/>issue by reconstructing an aligned Region Of Interest (ROI)  3  or using correlation filters to propose robust face <lb/>recognition method.  4  However, in a real-time embedded context, the limited processing power prevent us to <lb/>consider such complex methods. <lb/>In Shan et al.  5  work, a PCA-based face recognition method insensitive to illumination and expression <lb/>variations is proposed and embedded implementations on a DSP and a NIOS II processor are performed. Due to <lb/>the advanced methods used to enhance the recognition rate under variations, and despite several optimizations, <lb/>the recognition of a face out of 16 learned subjects is done in 1 second, which is not acceptable real-time context. <lb/>Endluri et al.  6  propose a PCA implementation on a TSK3000a (32-bit RISC embedded processor) that allows <lb/>the recognition in real-time for a 2 users database, on 320x240 images. These studies show that the eigenface <lb/>classification needs too many computing power to run on embedded system in real-time context. <lb/>However, no study is performed on the robustness of this system to image variations, and no data is given <lb/>concerning the real performance and the ROI size. Pavan et al.  7  uses a weighted modular PCA-based method <lb/>enhance the robustness of the recognition to facial variations. The proposed system, based on a NIOS processor <lb/>coupled to a PCA hardware co-processor, runs at 26 fps on a Altera Stratix II and is able to learn up to 5 <lb/>subjects (due to memory limitation). <lb/> 3. WAVELET-BASED FACE RECOGNITION ALGORITHM DESCRIPTION <lb/>3.1 Face recognition based on eigenfaces <lb/> Method used in this work for face recognition is based on eigenfaces.  1  The work of Turk et al. describes a complete <lb/>process for face recognition based on 2D calculations rather than complex 3D methods where a face should be <lb/>entirely reconstructed. Using eigenfaces, recognition can be divided in two steps: learning and recognition (also <lb/>known as testing). <lb/>Figure 1 shows a block diagram view of these two steps. <lb/>Learning is simply based on eigenfaces as it was described in the work of Turk et al.  1  First of all, faces must <lb/>be acquired from snapshots with non-uniform background. In this first approach, it is considered that faces are <lb/>clearly located in snapshots. It is considered a set of faces to be included in the learning database: these faces <lb/>are ROIs centered on each subject to be learnt. Assuming that N ROIs of size M  *  M have to be put in the <lb/>database, the learning stage is performed in five steps: <lb/> • Step 1: An inline transformation is performed on the whole dataset. For a single ROI, it consists in <lb/>a concatenation of its lines. Therefore, the size of the inline dataset (called D  inline  ) is a matrix of size <lb/> M  2  *  N . <lb/> • Step 2: The next step is to enhance image quality for recognition. A normalization is done on the line <lb/>dataset using the global mean and standard deviation. Dimension of the result matrix D  inline,norm  is not <lb/>affected. <lb/> • Step 3: Firstly, a multiplication between the transpose of D  inline,norm  and D  inline,norm  itself is done. The <lb/>result is a covariance matrix C  mat  of size N  *  N . Secondly, the algorithm computes eigenvalues (e  val  ) and <lb/>eigenvectors (e  vec  ) of C  mat  . e  val  is a vector of size N while e  vec  is a matrix of size N  *  N . <lb/> • Step 4: Then, a phase of sorting is done on eigenvalues and eigenvectors. Eigenvectors with null eigenvalues <lb/>are erased and eigenvectors are sorted according to the ascending order of their corresponding eigenvalues. <lb/>This operation does not change matrix orders as erased values are zero-padded (size(e  val,sort  ) = size(e  val  ) <lb/> and size(e  vec,sort  ) = size(e  vec  )). <lb/> • Step 5: The final step of the learning stage is the computation of weights of each face in the dataset. This <lb/>is done by a multiplication between the eigenvectors matrix and the inline database. The result, W  mat  , is <lb/>a matrix of size N  *  N . <lb/> N images <lb/>Image to test <lb/>ROI <lb/> N ROIs <lb/> N images to learn <lb/> S1 <lb/> S1 <lb/> Sn <lb/> Sn <lb/> S1 <lb/>Sn <lb/>S1 <lb/>S1 <lb/>S1 <lb/>Sn <lb/>Sn <lb/>Sn <lb/> Reshape database: <lb/>Inline transformation <lb/>Image normalization w/ <lb/>fixed mean and std <lb/> Eigenvalues/vectors of Cmat <lb/> S1 <lb/>S1 <lb/>S1 <lb/>Sn <lb/>Sn <lb/>Sn <lb/>S1 <lb/>S1 <lb/>Sn <lb/>S1 <lb/>Sn <lb/>Sn <lb/> x <lb/> Ascending sequences + <lb/> normalization <lb/> eval <lb/>evec <lb/> Computing weights <lb/> Eigenvectors matrix <lb/>S1 <lb/>S1 <lb/>S1 <lb/> Sn <lb/>Sn <lb/>Sn <lb/>W1 <lb/>Wn <lb/> x <lb/>= <lb/> Learning stage <lb/> Histogram equalization <lb/> 1. <lb/> Reshape database: <lb/> Inline transformation <lb/>2. <lb/>Image normalization w/ fixed <lb/> mean and std <lb/> Product w/ eigenvectors <lb/>matrix <lb/> Eigenvectors matrix <lb/> x <lb/> Euclidian distances (Ed) <lb/> Finding minimum of Ed <lb/> = <lb/> Testing stage <lb/> evec <lb/>evec <lb/> eval <lb/> evec <lb/>evec <lb/>evec <lb/>eval <lb/>evec <lb/>evec <lb/>evec <lb/> Covariance matrix Cmat <lb/> eval <lb/> evec <lb/>evec <lb/>evec <lb/>eval <lb/>evec <lb/>evec <lb/>evec <lb/> eval <lb/> evec <lb/>evec <lb/>evec <lb/> eval <lb/> evec <lb/>evec <lb/>evec <lb/>eval <lb/>evec <lb/>evec <lb/>evec <lb/> eval <lb/> evec <lb/>evec <lb/>evec <lb/> Figure 1: Basic face recognition flow based on eigenfaces <lb/>As outputs of the eigenfaces task, the algorithm produces three results: <lb/> • The overall eigenfaces mean. <lb/> • Weights of each face in the learning dataset (W  mat  ). <lb/> • A database including eigenfaces. <lb/>These data are processed in the testing stage of the algorithm. It also takes as inputs faces to be tested (a single <lb/>face in case of a real-time implementation). This stage is done in three major steps: <lb/> • Step 1: The first operation is to compute a Regional Histogram Equalization (RHE) aiming to highlight <lb/>face details and especially enhance borders (nose, eyes and so on). <lb/> • Step 2: Then, as it was done in the learning stage, the inline transformation and normalization is performed <lb/>on the image currently tested. <lb/> • Step 3: Finally, a product is performed between this image and the eigenfaces matrix. Compared with <lb/>the weight matrix W  mat  , it give N Euclidian distances E  d,n  (also known as &quot; scores &quot; ): the index of the <lb/>minimum value in E  d,n  will identify the most similar face in the learning database. <lb/>In the context of embedded systems, two-dimensional wavelet transform is used to preprocess images before the <lb/>eigenfaces task in order to decrease computation times and memory consumption. <lb/> S1 <lb/> N images <lb/> S1 <lb/> Sn <lb/> Sn <lb/> S1 <lb/>Sn <lb/>S1 <lb/>S1 <lb/>S1 <lb/>Sn <lb/>Sn <lb/>Sn <lb/> Reshape database: <lb/>Inline transformation <lb/>Image normalization w/ <lb/>fixed mean and std <lb/> Eigenvalues/vectors of Cmat <lb/> S1 <lb/>S1 <lb/>S1 <lb/>Sn <lb/>Sn <lb/>Sn <lb/>S1 <lb/>S1 <lb/>Sn <lb/>S1 <lb/>Sn <lb/>Sn <lb/> x <lb/> Ascending sequences + <lb/> normalization <lb/> eval <lb/>evec <lb/> Computing weights <lb/> Eigenvectors matrix <lb/>S1 <lb/>S1 <lb/>S1 <lb/> Sn <lb/>Sn <lb/>Sn <lb/>W1 <lb/>Wn <lb/> x <lb/> Image to test <lb/>ROI <lb/> = <lb/> Learning stage <lb/> Histogram equalization <lb/> 1. <lb/> Reshape database: <lb/> Inline transformation <lb/>2. <lb/>Image normalization w/ fixed <lb/> mean and std <lb/> Product w/ eigenvectors <lb/>matrix <lb/> Eigenvectors matrix <lb/> x <lb/> Euclidian distances (Ed) <lb/> Finding minimum of Ed <lb/> = <lb/> Testing stage <lb/> DWT + approximation <lb/>coefficients <lb/> N ROIs <lb/> N images to learn <lb/> DWT + approximation <lb/>coefficients <lb/> evec <lb/>evec <lb/> eval <lb/> evec <lb/>evec <lb/>evec <lb/>eval <lb/>evec <lb/>evec <lb/>evec <lb/> Covariance matrix Cmat <lb/> eval <lb/> evec <lb/>evec <lb/>evec <lb/>eval <lb/>evec <lb/>evec <lb/>evec <lb/> eval <lb/> evec <lb/>evec <lb/>evec <lb/> eval <lb/> evec <lb/>evec <lb/>evec <lb/>eval <lb/>evec <lb/>evec <lb/>evec <lb/> eval <lb/> evec <lb/>evec <lb/>evec <lb/> Figure 2: ROI-then-DWT recognition flow <lb/> 3.2 ROI-then-DWT recognition flow <lb/> Based on the the flow described in Section 3.1, a 2D-discrete wavelet transform is implemented right after <lb/>the ROI task. Figure 2 shows the so-called ROI-then-DWT recognition flow. In this approach, the wavelet <lb/>transform is done after the ROI cropping. In our context, face recognition only takes care of approximation <lb/>coefficients. Therefore, the ROI size is divided by a factor 2  2K  (2  K  ratio on each dimension, where K is the <lb/>wavelet decomposition level). The wavelet transform used in this work is based on the work of Courroux et al.  2 <lb/> The data amount processed in the algorithm is, de facto, decreased: <lb/> 
			
			• In the learning stage, the DWT-processed ROIs imply some time decrease for the first three steps (eigenfaces <lb/>computation). <lb/> • In the testing stage, DWT transformation has an impact on computation time for the first two steps (until <lb/>the product with the eigenfaces matrix). <lb/>In the context of embedded systems, the integration of wavelet transform is a key point: as data amount <lb/>is lowered, both computation time and memory consumption should be decreased. Section 5 presents some <lb/>performance results. Section 4 also studies the impact of wavelet transform on face recognition rates. <lb/> 4. ROBUSTNESS OF WAVELET-BASED FACE RECOGNITION <lb/>4.1 Experiments description <lb/> Using the wavelet-based method previously defined, several experiments are performed to measure the robustness <lb/>of our approach regarding several parameters. Position of the subject regarding the image sensor (in three <lb/>dimensions) is the main study. <lb/> 4.1.1 Faces database <lb/> Efficiency of a given face recognition method partially depends on the images quality used for both learning and <lb/>testing. As this work focuses on subject position and lightning conditions, the &quot; Extended Yale Face Database B &quot; <lb/>  †8  is used. This database provides a large set of images with fixed position of the subject regarding the image <lb/>sensor with several lightning conditions. <lb/>For the learning database construction, 35 snapshots are acquired: one for each subject, with centered light <lb/>source. For testing purposes, 210 snapshots can be processed. Each user is represented by 6 snapshots with <lb/>slightly deviated light source, close to the centered position. Testing images stricly differ from learning ones. <lb/>Following studies take into account ROIs of 200x200 pixels wide while the resolution of full-scale images is <lb/>640x480 pixels. ROIs built for face position shifting and distance from the sensor ([x,y] and [z] studies) take <lb/>into account non-uniform background: even if snapshots are generally close to the user face, a few background <lb/>elements may appear. <lb/> 4.1.2 [x,y] shifting <lb/> (a) Face position shifting ROIs. <lb/>a: centered. b: upper-left bound. <lb/>c: lower-right bound. <lb/>(b) Scale variation ROIs. <lb/>a: 80%. b: 100% (i.e. equal to the learning <lb/>database position). c: 120%. <lb/> Figure 3: ROIs for both face position shifting and scale variation studies. <lb/>For each subject from the learning database, a ROI frame is swept along all positions between b and c <lb/> positions (see Figure 3a) in both horizontal (x) and vertical (y) directions: it defines a subspace where b is the <lb/>upper-left bound and c the lower-right bound. Figure 3a shows a full-scale image taken from the database used <lb/>in this work with three ROIs: b, c and a, centered on the user (equivalent to the learning position). This test <lb/>database contains a large set of ROIs where the subject face may be partially out of the frame. <lb/>Robustness analysis against face position shifting is done in several steps : <lb/> • Firstly, a projection of each shifted ROI on learned eigenfaces is performed (testing stage of the ROI-then-<lb/>DWT algorithm described in Figure 2). <lb/> • Then, projection values (also known as scores) are collected and displayed in a color map diagram giving <lb/>35 color maps for each subject to be tested (one color map for each image in the learning database). <lb/> • Finally, for each subject, a new color map containing the minimum scores of all projections except one of <lb/>the current subject is created. A difference between the color map related to the current subject and color <lb/>maps of the minimum score is computed. When this value is positive, the subject is correctly recognized. <lb/>The thresholded map shows the area of shift variation tolerance. As each subject has its own tolerance in <lb/>terms of shifting, an accumulation of all the tolerance areas is finally computed. These colormaps display <lb/>the recogniton rate according to shift variation. <lb/>
			 
			 <note place="footnote">†  http://vision.ucsd.edu/~leekc/ExtYaleDatabase/ExtYaleB.html <lb/></note> 
			 
			 4.1.3 [z] scaling <lb/> Another study of this work demonstrates robustness against scale variation. It shows how the recognition <lb/>algorithm reacts when a subject move away or close to the image sensor compared to the learning database <lb/>position. Figure 3b shows a full-scale image with 3 ROIs. As snapshots are acquired at a fixed position, this <lb/>work proposes to take ROIs with different sizes in order to feign scale variation. Then, a test database is built <lb/>by interopolating all ROIs to the learned database size. Finally, we gather each ROI minimum score to compute <lb/>a plot of recognition probability against scale variation. <lb/> 4.2 Experiments results <lb/> 4.2.1 [x,y] shifting <lb/> By applying the previous methodology on all learned subjects, minimal score is obtained when the ROI is centered <lb/>on the subject face. Even on other projections, minimum score is obtained around the subject face center. <lb/> (a) Face #1 (currently tested). <lb/>(b) Face #2. <lb/> Figure 4: Score colormaps of 2 faces. <lb/>As an example, Figure 4 shows score colormaps of subject #1 on two learned faces. Their coordinates <lb/>represent the ROI center location ([0, 0] when centered on the subject face). Then, minima difference colormaps <lb/>for all the subjects are computed. <lb/> (a) Colored <lb/>(b) Binary/thresholded view <lb/> Figure 5: Minima difference colormaps for subject #1. <lb/>On both colormaps, shifting step is set to 5 pixels.In figure 5b, a tolerance of +/-10% of the ROI size in each <lb/>direction is obtained for a recognition rate over 75%. <lb/> 4.2.2 [z] scaling <lb/> Figure 6: Probability of correct recognition (face identification) against scale variation of a centered face. <lb/>Figure 6 shows probability results for both spatial-based and wavelet-based methods at several decomposition <lb/>levels. Wavelet decomposition does not alter the scale variation robustness: for both cases, the face recognition <lb/>algorithm support a variation of +/-10% in terms of scale with a correctness probability over 75% while a +/-<lb/>5% tolerance is admitted for a 100% rate. <lb/> 4.2.3 Wavelet decomposition impact <lb/> From an implemention of the ROI-then-DWT flow described in Section 3.2, the work of Courroux et al.  2  studied <lb/>the impact of the DWT levelon recognition rates of the Eigenfaces classifier. Even with partially obfuscated <lb/>faces (first two sets of Yale database), rates of the wavelet-based approach were correct (over 80 %, with a <lb/>decomposition level K = 3). The Regional Histogram Equalization implemented in the face recognition process <lb/>gives more tolerance about faces illumination. It is one key point of the use of wavelet transform in the face <lb/>recognition context: even if data amount is compressed by a factor 16 (between K = 1 and K = 3), recognition <lb/>rates are still correct <lb/> 5. PERFORMANCE RESULTS <lb/> The main advantage of using DWT at the input of the recognition pipeline is to drastically decrease the amount <lb/>of processed pixels. As only the approximation coefficients are kept for regonition, the size of the input image <lb/>is divided by a factor of 2  (K+1)  . We show in this section the impact on the processing time of the recognition <lb/>pipeline of the wavelet decomposition level against number of faces in the database. <lb/> 5.1 Measurement set up <lb/> The measures are conducted on three different hardware platforms: <lb/> • x86-based computer : an Intel Core i7 running at 3.4Ghz and cache size 8 MB. <lb/> • ARM-based computer : an iMX6 system from SECO  ‡  with a quadcore Cortex-A9 running at 1GHz and <lb/>cache size 32 KB. <lb/>

			<note place="footnote">  ‡  http://www.seco.com/prods/eu/boards/qseven-boards/quadmo747-x-i-mx6.html <lb/></note>

			• ARM-based computer : a RaspberryPi model B with a single core processor from Broadcom running at <lb/>700MHz and cache size 32 KB. <lb/>The x86-based computer gives a reference for the output of the recognition pipeline and for its execution time. <lb/>The two nano computers ARM-based give results on more embedded platforms. The core of the recognition <lb/>pipeline is in C code with double precision for the computation of the eigenvalues. The main function is in <lb/>C++ code. It manages the accesses to the images and outputs results of execution such as the two best scores <lb/>of eigenface recognition procedure and the identified face for each frame. The image accesses are done with <lb/>OpenCV functions. Source codes were compiled with standard options (mainly, -O3), to be executed on one core <lb/>in each case. <lb/>All the executions to profile the code on the three platforms are done on the same video sequence and the <lb/>same set of faces. The video sequence is composed of 1000 frames at resolution 640x480 with two faces changing <lb/>in x, y and z positions. The video sequence was acquired with an IDS UI-3240CP  §  . The ROI size of the faces in <lb/>the database is 200x200 pixels. <lb/>The tests are conducted on 4, 6, 8 ,10 20, 30 and 40 faces and with wavelet decomposition level (K) varying <lb/>from 0 to 5. Each execution is done in two steps. First, the learning phase is executed to generate the eigenface <lb/>basis at a given K. This step is not profiled. Second, the face classification using eigenfaces is executed and <lb/>profiled. The execution time is a mean of 5 exections measured with time command. The profiling is obtained <lb/>with the gprof tool. <lb/>x86 Core i7 K=0 K=1 K=2 K=3 K=4 K=5 <lb/>4 faces <lb/>1,16 0.74 0.64 0.61 0.60 0.60 <lb/>6 faces <lb/>1,41 0.78 0.64 0.61 0.60 0.60 <lb/>8 faces <lb/>1,71 0.82 0.65 0.61 0.60 0.60 <lb/>10 faces <lb/>2,02 0,84 0.66 0.62 0.61 0.60 <lb/>20 faces <lb/>3,86 1.04 0.69 0.62 0.61 0.60 <lb/>30 faces <lb/>4,35 1.23 0.74 0.64 0.61 N/A <lb/>40 faces <lb/>5,09 1.42 0.78 0.64 0.61 N/A <lb/>Table 1: Execution time per frame (in ms) on x86 Core i7 for K varying from 0 to 5 and number of faces in <lb/>database varying from 4 to 40 <lb/> 5.2 Profiling analysis <lb/> The table 1, 2, 3 put together the execution mean times of the face classification, respectively, on x86 Core i7, <lb/>on SECO board and on Raspberry Pi B for K varying from 0 to 5 and number of faces in database varying from <lb/>4 to 40. The mean execution times are normalized for one frame. Because the recognition rate for K = 5 and <lb/>database with 30 and 40 faces are not relevant, the mean times are not given. <lb/>SECO board K=0 K=1 K=2 K=3 K=4 K=5 <lb/>4 faces <lb/>26 <lb/>12 <lb/>9 <lb/>8 <lb/>8 <lb/>8 <lb/>6 faces <lb/>33 <lb/>13 <lb/>9 <lb/>9 <lb/>8 <lb/>8 <lb/>8 faces <lb/>41 <lb/>15 <lb/>10 <lb/>9 <lb/>8 <lb/>8 <lb/>10 faces <lb/>48 <lb/>16 <lb/>10 <lb/>9 <lb/>9 <lb/>8 <lb/>20 faces <lb/>85 <lb/>21 <lb/>11 <lb/>9 <lb/>9 <lb/>8 <lb/>30 faces <lb/>121 <lb/>26 <lb/>12 <lb/>9 <lb/>9 <lb/>N/A <lb/>40 faces <lb/>157 <lb/>31 <lb/>13 <lb/>9 <lb/>9 <lb/>N/A <lb/>Table 2: Execution time per frame (in ms) on SECO board for K varying from 0 to 5 and number of faces in <lb/>database varying from 4 to 40 <lb/>

			<note place="footnote">  §  https://en.ids-imaging.com/store/ui-3240cp.html <lb/></note>

			As expected the execution time on the intel core i7 varying from 0.6 ms to 5.09 ms is much more faster than <lb/>on the two ARM based nano computers for SECO, varying from 8 ms to 157 ms and for RPI-B from 26 ms <lb/>to 380 ms. Lots of hardware aspects such as, pipeline organization, floating point unit, vectorisation, etc. can <lb/>explain this acceleration. But memory management and accesses are key factors, as the variations of the ratio <lb/>between the execution times of the ARM based architectures and the intel core i7 follow closely the variations <lb/>of the size of the database. This is even more true between the RPI-B and the SECO board. The difference <lb/>between the execution times are mainly due to the memory accesses. <lb/>RPI <lb/>K=0 K=1 K=2 K=3 K=4 K=5 <lb/>4 faces <lb/>78 <lb/>38 <lb/>29 <lb/>27 <lb/>26 <lb/>26 <lb/>6 faces <lb/>89 <lb/>43 <lb/>30 <lb/>27 <lb/>28 <lb/>28 <lb/>8 faces <lb/>116 <lb/>51 <lb/>33 <lb/>29 <lb/>28 <lb/>28 <lb/>10 faces 135 <lb/>52 <lb/>31 <lb/>27 <lb/>26 <lb/>26 <lb/>20 faces 218 <lb/>75 <lb/>38 <lb/>28 <lb/>26 <lb/>26 <lb/>30 faces 293 <lb/>98 <lb/>41 <lb/>29 <lb/>27 <lb/>N/A <lb/>40 faces 380 <lb/>121 <lb/>46 <lb/>30 <lb/>27 <lb/>N/A <lb/>Table 3: Execution time per frame (in ms) on RaspberryPi for K varying from 0 to 5 and number of faces in <lb/>database varying from 4 to 40 <lb/>The figure 7 shows the evolutions of the execution times on the three targets in function of K and the number <lb/>of faces in the database. Even if, because the intel core i7 is very performant the impact of K and the number of <lb/>faces is less significant than on the execution times of the ARM based nano computers, all the three architectures <lb/>have the same behavior. The execution times drastically decrease when the decomposition level increases and, <lb/>to a lesser extent increase with the number of faces in the database. Over than K equal to 3, the execution times <lb/>stop to decrease and are even mostly independent of the number of faces in the database. We show, previously <lb/>in,  2  the recognition rate is not significatively modified until K equal to 3. At this level, the execution on the intel <lb/>core i7 is accelerated by a factor from 2 to 8 according to the number of faces in the database ; on the SECO <lb/>board by a factor from 3 to 17 ; and on the RPI-B by a factor from 3 to 12. <lb/> (a) on x86 Core i7 <lb/>(b) on SECO board <lb/>(c) on RPI <lb/> Figure 7: Execution time in ms of the recognition pipeline per frame function of wavelet decomposition level (K) <lb/>for database containing 4 to 40 faces. <lb/>The figures 8 show the evolution of the three main functions (histogramm equalization, wavelet decomposition, <lb/>eigenface classification) of the recognition pipeline and the total execution time on the SECO board and RPI-B <lb/>for 4 and 40 faces in database. While the eigenface classification execution time drastically decreases with K; the <lb/>wavelet decomposition execution time increases in a more limited manner. The execution time of the histogramm <lb/>equalization is more or less stable. So the total execution time decreases with K in the manner described above. <lb/>The behaviors of the execution on the SECO board and on the RPI-B are very close. <lb/> As the eigenface classification execution time is dependant of the number of faces in the database, it decreases <lb/>in a faster way for a database with 40 faces than a database for 4 users. So bigger the face database is, stronger <lb/>the acceleration of the execution is with K increasing. <lb/> (a) SECO board, 4 faces in database <lb/>(b) SECO board, 40 faces in database <lb/>(c) RPI, 4 faces in database <lb/>(d) RPI, 40 faces in database <lb/> Figure 8: Execution time per frame for the main functions of the recognition pipeline (DWT, eigenface recog-<lb/>nition, histogramm equalization) on SECO board, 4 faces in datatbase (a) and 40 faces in database (b) and on <lb/>RPI 4 faces in database (c) and 40 faces in database(d) in function of K. <lb/>The figures 9 show the percentage of the total execution time on the RPI of the three main functions for K = 1 <lb/>and K = 3 when the number of face in the database varies. In both case, K = 1 and K = 3, the contribution <lb/>of the eigenface classification increases with the number of faces in the database while the contribution of the <lb/>two other functions decreases. For K = 1, eigenface classification takes over than 50 % for 4 users to around <lb/>90 % for 40 users, as for K = 3 its contribution is between 5 % and 25 % for 4 to 40 users making the wavelet <lb/>decomposition function becoming the main function in term of execution time. <lb/> 6. CONCLUSION AND PERSPECTIVES <lb/> In our previous work, we studied the opportunity to use wavelet-based eigenface recognition in a low cost <lb/>embedded context, i.e with low computing power and memory capacity. Applying wavelet to input images before <lb/>performing the face recognition allows a high decrease of the computing time without lowering the recognition <lb/>rate. In this work, we pushed forward the study of the method robustness and characterize its performances on <lb/>existing embedded plateforms. <lb/>The first main results is the study of the wavelet-based eigenfaces robustness against face position shifting <lb/>in both horizontal and vertical directions; and in scale, under several level of decomposition. For face position, <lb/> (a) wavelet decomposition level (K = 1) <lb/>(b) wavelet decomposition level (K = 3) <lb/> 
			
			Figure 9: Execution time per frame for the main functions of the recognition pipeline (DWT, eigenface recogni-<lb/>tion, histogramm equalization) on the RPI B. <lb/>a tolerance of +/-10% of the ROI size is obtained with satisfying recognition rates (over 75%) and with a high <lb/>level of wavelet decomposition. This level of robustness allows us to consider the use of a low complexity face <lb/>detection stage compliant with the limited processing power available on embedded systems, as the location of <lb/>the face can shift of less than 10% of the ROI size. It even enables the possibility of performing no detection if <lb/>the user places his face in the indicated space, and the decision is made by accumulating the recognition results. <lb/>The performance analyzis extracted from the application execution on three systems (on Intel PC, and two <lb/>ARM-based nano-computers) has shown that applying DWT transformation to the input image before performing <lb/>the face recognition allows a speed gain of almost 3 for a 4 faces database, and more than 12 for a 40 faces database <lb/>(from no DWT to a three level DWT), enabling realtime performances on considered nanocomputers, for instance <lb/>30 fps to recognize a face in a 40 faces database on Raspberry Pi. The application of a DWT of at least 3 levels <lb/>highly decreases the computing power needed by the recognition phase which is no longer the major function <lb/>(from 91% to 25%)for a 40 faces database. Further optimizations will target the DWT function which is now at <lb/>43% of needed computing power. <lb/>These results allow us to consider a face recognition application with smooth video feedback on an embedded <lb/>low cost processing system. These results also confirms the interest of wavelet transform for face recognition with <lb/>a high number of learned subjects, as the quantity of data to store is decrease by 64 for 3 wavelet decomposition <lb/>levels. For instance, the size of the database for 10 faces is lowered form 1.5 MB to 24 KB. <lb/>In futur studies, we will consider the two major functions in term of complexity, which are DWT and histogram <lb/>equalization. <lb/></body> 
			
			<listBibl>REFERENCES <lb/> [1] Turk, M. and Pentland, A., &quot; Eigenfaces for recognition, &quot;  J. Cognitive Neuroscience 3, 71–86 (Jan. 1991). <lb/>[2] Courroux, S., Chevobbe, S., Darouich, M., and Paindavoine, M., &quot; Use of wavelet for image processing in smart <lb/>cameras with low hardware resources, &quot;  Journal of Systems Architecture -Embedded Systems Design 59(10-A), <lb/> 826–832 (2013). <lb/>[3] Yan, S., Wang, H., Liu, J., Tang, X., and Huang, T., &quot; Misalignment-robust face recognition, &quot;  Image Process-<lb/>ing, IEEE Transactions on 19, 1087–1096 (April 2010). <lb/>[4] Sawides, M., Kumar, B., and Khosla, P., &quot; &quot;corefaces&quot; -robust shift invariant pca based correlation filter for <lb/>illumination tolerant face recognition, &quot; in [Computer Vision and Pattern Recognition, 2004. CVPR 2004. <lb/>Proceedings of the 2004 IEEE Computer Society Conference on ], 2, II–834–II–841 Vol.2 (June 2004). <lb/> [5] Shan, T., Bigdeli, A., Lovell, B. C., and Chen, S., &quot; Robust face recognition technique for a real-time embedded <lb/>face recognition system, &quot; in [Pattern Recognition Technologies and Applications: Recent Advances], Verma, <lb/>B. and Blumenstein, M., eds., 188–211, IGI Global, Hershey, PA, USA (2008). <lb/> [6] Endluri, R., Kathait, M., and Ray, K., &quot; Face recognition using pca on fpga based embedded platform, &quot; in <lb/>[Control, Automation, Robotics and Embedded Systems (CARE), 2013 International Conference on], 1–4 <lb/>(Dec 2013). <lb/>[7] Kumar, A. P., Kamakoti, V., and Das, S., &quot; System-on-programmable-chip implementation for on-line face <lb/>recognition, &quot;  Pattern Recognition Letters 28(3), 342 – 349 (2007). Advances in Visual information Processing <lb/>Special Issue of Pattern Recognition Letters on Advances in Visual Information Processing. (ICVGIP 2004). <lb/>[8] Lee, K.-C., Ho, J., and Kriegman, D., &quot; Acquiring linear subspaces for face recognition under variable lighting, &quot; <lb/> Pattern Analysis and Machine Intelligence, IEEE Transactions on 27, 684–698 (May 2005). </listBibl>


	</text>
</tei>
