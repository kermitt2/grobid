<?xml version="1.0" ?>
<tei>
	<teiHeader>
		<fileDesc xml:id="__E14-1007"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 58–67, <lb/>Gothenburg, Sweden, April 26-30 2014. c <lb/> 2014 Association for Computational Linguistics <lb/></front> 
			
			<front>Inducing Example-based Semantic Frames <lb/>from a Massive Amount of Verb Uses <lb/> Daisuke Kawahara  †  Daniel W. Peterson  ‡  Octavian Popescu  §  Martha Palmer  ‡ <lb/> † <lb/> Kyoto University, Kyoto, Japan <lb/>  ‡ <lb/> University of Colorado at Boulder, Boulder, CO, USA <lb/>  § <lb/> Fondazione Bruno Kessler, Trento, Italy <lb/> dk@i.kyoto-u.ac.jp, {Daniel.W.Peterson, Martha.Palmer}@colorado.edu, popescu@fbk.eu <lb/> Abstract <lb/> We present an unsupervised method for in-<lb/> ducing semantic frames from verb uses in <lb/>giga-word corpora. Our semantic frames <lb/>are verb-specific example-based frames <lb/>that are distinguished according to their <lb/>senses. We use the Chinese Restau-<lb/>rant Process to automatically induce these <lb/>frames from a massive amount of verb in-<lb/>stances. In our experiments, we acquire <lb/>broad-coverage semantic frames from two <lb/>giga-word corpora, the larger comprising <lb/>20 billion words. Our experimental results <lb/>indicate the effectiveness of our approach. <lb/></front>

			<body> 1 Introduction <lb/> Semantic frames are indispensable knowledge for <lb/>semantic analysis or text understanding. In the <lb/>last decade, semantic frames, such as FrameNet <lb/>(Baker et al., 1998) and PropBank (Palmer et al., <lb/>2005), have been manually elaborated. These <lb/>resources are effectively exploited in many nat-<lb/>ural language processing (NLP) tasks, includ-<lb/>ing not only semantic parsing but also ma-<lb/>chine translation (Boas, 2002), information ex-<lb/>traction (Surdeanu et al., 2003), question answer-<lb/>ing (Narayanan and Harabagiu, 2004), paraphrase <lb/>acquisition (Ellsworth and Janin, 2007) and recog-<lb/>nition of textual entailment (Burchardt and Frank, <lb/>2006). <lb/>There have been many attempts to automati-<lb/>cally acquire frame knowledge from raw corpora <lb/>with the goal of either adding frequency informa-<lb/>tion to an existing resource or of inducing simi-<lb/>lar frames for other languages. Most of these ap-<lb/>proaches, however, focus on syntactic frames, i.e., <lb/>subcategorization frames (e.g., (Manning, 1993; <lb/>Briscoe and Carroll, 1997; Korhonen et al., 2006; <lb/>Lippincott et al., 2012; Reichart and Korhonen, <lb/>2013)). Since subcategorization frames represent <lb/>argument patterns of verbs and are purely syn-<lb/>tactic, expressions that have the same subcatego-<lb/>rization frame can have different meanings (e.g., <lb/>metaphors). Semantics-oriented NLP applications <lb/>based on frames, such as paraphrase acquisition <lb/>and machine translation, require consistency in the <lb/>meaning of each frame, and thus these subcatego-<lb/>rization frames are not suitable for these semantic <lb/>tasks. <lb/>Recently, there have been a few studies on au-<lb/>tomatically acquiring semantic frames (Materna, <lb/>2012; Materna, 2013). Materna induced seman-<lb/>tic frames (called LDA-Frames) from triples of <lb/>(subject, verb, object) in the British National <lb/>Corpus (BNC) based on Latent Dirichlet Allo-<lb/>cation (LDA) and the Dirichlet Process. LDA-<lb/>Frames capture limited linguistic phenomena of <lb/>these triples, and are defined across verbs based <lb/>on probabilistic topic distributions. <lb/>This paper presents a method for automati-<lb/>cally building verb-specific semantic frames from <lb/>a large raw corpus. Our semantic frames are verb-<lb/>specific like PropBank and semantically distin-<lb/>guished. A frame has several syntactic case slots, <lb/>each of which consists of words that are eligible to <lb/>fill the slot. For example, let us show three seman-<lb/>tic frames of the verb &quot; observe &quot; :  1 <lb/> observe:1 <lb/> nsubj:{we, author, ...} dobj:{effect, result, ...} <lb/>prep in:{study, case, ...} ... <lb/> observe:2 <lb/> nsubj:{teacher, we, ...} dobj:{child, student, ...} <lb/>prep in:{classroom, school, ...} ... <lb/> observe:3 <lb/> nsubj:{child, people, ...} dobj:{bird, animal, ...} <lb/>prep at:{range, time, ...} ... <lb/> 
			
			<note place="footnote">1 In this paper, we use the dependency relation names <lb/>of the Stanford collapsed dependencies (de Marneffe et al., <lb/>2006) as the notations of case slots. For instance, &quot; nsubj &quot; <lb/>means a nominal subject, &quot; dobj &quot; means a direct object, &quot; iboj &quot; <lb/>means an indirect object, &quot; ccomp &quot; means a clausal comple-<lb/>ment and &quot; prep * &quot; means a preposition. <lb/></note>

			<page> 58 <lb/></page>

			Frequencies, which are not shown in the above ex-<lb/>amples, are attached to each semantic frame, case <lb/>slot and word, and can be effectively exploited for <lb/>the applications of these semantic frames. The fre-<lb/>quencies of words in each case slot become good <lb/>sources of selectional preferences. <lb/>Our novel contributions are summarized as fol-<lb/>lows: <lb/> • induction of semantic frames based on the <lb/>Chinese Restaurant Process (Aldous, 1985) <lb/>from only automatic parses of a web-scale <lb/>corpus, <lb/> • exploitation of the assumption of one sense <lb/>per collocation (Yarowsky, 1993) to make the <lb/>computation feasible, <lb/> • providing broad-coverage knowledge for se-<lb/>lectional preferences, and <lb/> • evaluating induced semantic frames by us-<lb/>ing an existing annotated corpus with verb <lb/>classes. <lb/> 2 Related Work <lb/> The most closely related work to our semantic <lb/>frames are LDA-Frames, which are probabilistic <lb/>semantic frames automatically induced from a raw <lb/>corpus (Materna, 2012; Materna, 2013). He used a <lb/>model based on LDA and the Dirichlet Process to <lb/>cluster verb instances of a triple (subject, verb, ob-<lb/>ject) to produce semantic frames and slots. Both <lb/>of these are represented as a probabilistic distri-<lb/>bution of words across verbs. He applied this <lb/>method to the BNC and acquired 427 frames and <lb/>144 slots (Materna, 2013). These frames are over-<lb/>generalized across verbs and might be difficult <lb/>to provide with fine-grained selectional prefer-<lb/>ences. In addition, Grenager and Manning (2006) <lb/>proposed a method for inducing PropBank-style <lb/>frames from Stanford typed dependencies ex-<lb/>tracted from raw corpora. Although these frames <lb/>are based on typed dependencies and more seman-<lb/>tic than subcategorization frames, they are not dis-<lb/>tinguished in terms of the senses of words filling a <lb/>case slot. <lb/>There are hand-crafted semantic frames in the <lb/>lexicons of FrameNet (Baker et al., 1998) and <lb/>PropBank (Palmer et al., 2005). Corpus Pattern <lb/>Analysis (CPA) frames (Hanks, 2012) are another <lb/>manually created repository of patterns for verbs. <lb/>Each pattern represents a prototypical word usage <lb/>as extracted by lexicographers from the BNC. Cre-<lb/>ating CPA is time consuming, but our proposed <lb/>method may be employed to assist in the creation <lb/>of this type of resource, as shown in Section 4.4. <lb/>Our task can be regarded as clustering of verb <lb/>instances. In this respect, the models of Parisien <lb/>and Stevenson are related to our method (Parisien <lb/>and Stevenson, 2009; Parisien and Stevenson, <lb/>2010). Parisien and Stevenson (2009) proposed <lb/>a Dirichlet Process model for clustering usages <lb/>of the verb &quot; get. &quot; Later, Parisien and Stevenson <lb/>(2010) proposed a Hierarchical Dirichlet Process <lb/>model for jointly clustering argument structures <lb/>
			
			(i.e., subcategorization frames) and verb classes. <lb/>However, their argument structures are not seman-<lb/>tic but syntactic, and also they did not evaluate the <lb/>resulting frames. There have also been related ap-<lb/>proaches to clustering verb types (Vlachos et al., <lb/> 2009; Sun and Korhonen, 2009; Falk et al., 2012; <lb/>Reichart and Korhonen, 2013). These methods in-<lb/>duce verb clusters in which multiple verbs partic-<lb/>ipate, and do not consider the polysemy of verbs. <lb/>Our objective is different from theirs. <lb/>Another line of related work is unsupervised <lb/>semantic parsing or semantic role labeling (Poon <lb/>and Domingos, 2009; Lang and Lapata, 2010; <lb/>Lang and Lapata, 2011a; Lang and Lapata, 2011b; <lb/>Titov and Klementiev, 2011; Titov and Klemen-<lb/>tiev, 2012). These approaches basically clus-<lb/>ter predicates and their arguments to distinguish <lb/>predicate senses and semantic roles of arguments. <lb/>Modi et al. (2012) extended the model of Titov and <lb/>Klementiev (2012) to jointly induce semantic roles <lb/>and frames using the Chinese Restaurant Process, <lb/>which is also used in our approach. However, <lb/>they did not aim at building a lexicon of semantic <lb/>frames, but at distinguishing verbs that have dif-<lb/>ferent senses in a relatively small annotated cor-<lb/>pus. Applying this method to a large corpus could <lb/>produce a frame lexicon, but its scalability would <lb/>be a big problem. <lb/>For other languages than English, Kawahara <lb/>and Kurohashi (2006a) proposed a method for au-<lb/>tomatically compiling Japanese semantic frames <lb/>from a large web corpus. They applied con-<lb/>ventional agglomerative clustering to predicate-<lb/>argument structures using word/frame similarity <lb/>based on a manually-crafted thesaurus. Since <lb/>Japanese is head-final and has case-marking post-<lb/>positions, it seems easier to build semantic frames <lb/>with it than with other languages such as English. <lb/>They also achieved an improvement in depen-<lb/>dency parsing and predicate-argument structure <lb/> 
			
			<page>59 <lb/> </page>
			
			analysis by using their resulting frames (Kawahara <lb/>and Kurohashi, 2006b). <lb/> 3 Method for Inducing Semantic Frames <lb/> Our objective is to automatically induce verb-<lb/>specific example-based semantic frames. Each se-<lb/>mantic frame consists of a partial set of syntactic <lb/>slots: nsubj, dobj, iobj, ccomp and prep *. Each <lb/>slot consists of words with frequencies, which <lb/>could provide broad-coverage selectional prefer-<lb/>ences. <lb/>Frames for a verb should be semantically distin-<lb/>guished. That is to say, each frame should consist <lb/>of predicate-argument structures that have consis-<lb/>tent usages or meanings. <lb/>Our procedure to automatically generate seman-<lb/>tic frames from verb usages is as follows: <lb/>
			
			1. apply dependency parsing to a raw corpus <lb/>and extract predicate-argument structures for <lb/>each verb from the automatic parses, <lb/>2. merge the predicate-argument structures that <lb/>have presumably the same meaning based on <lb/>the assumption of one sense per collocation <lb/>to get a set of initial frames, and <lb/>3. apply clustering to the initial frames based <lb/>on the Chinese Restaurant Process to produce <lb/>the final semantic frames. <lb/>
			
			Each of these steps is described in the following <lb/>sections in detail. <lb/> 3.1 Extracting Predicate-argument <lb/>Structures from a Raw Corpus <lb/> We first apply dependency parsing to a large raw <lb/>corpus. We use the Stanford parser with Stanford <lb/>dependencies (de Marneffe et al., 2006).  2  Col-<lb/>lapsed dependencies are adopted to directly extract <lb/>prepositional phrases. <lb/>Then, we extract predicate-argument structures <lb/>from the dependency parses. Dependents that have <lb/>the following dependency relations to a verb are <lb/>extracted as arguments: <lb/>nsubj, xsubj, dobj, iobj, ccomp, xcomp, <lb/>prep  * <lb/> Here, we do not distinguish adjuncts from argu-<lb/>ments. All extracted dependents of a verb are han-<lb/>dled as arguments. This distinction is left for fu-<lb/>ture work, but this will be performed using slot <lb/> 
			
			<note place="footnote">2 http://nlp.stanford.edu/software/lex-parser.shtml <lb/></note> 
			
			Sentences: <lb/> They observed the effects of ... <lb/>This statistical ability to observe an effect ... <lb/>We did not observe a residual effect of ... <lb/>He could observe the results at the same time ... <lb/>My first opportunity to observe the results of ... <lb/>You can observe beautiful birds ... <lb/>Children may then observe birds ... <lb/>. . . <lb/> Predicate-argument structures: <lb/> nsubj:they observe dobj:effect <lb/>observe dobj:effect <lb/>nsubj:we observe dobj:effect <lb/>nsubj:he observe dobj:result prep at:time <lb/>observe dobj:result <lb/>nsubj:you observe dobj:bird <lb/>nsubj:child observe dobj:bird <lb/>. . . <lb/> Initial frames: <lb/> nsubj:{they, we, ...} observe dobj:{effect} <lb/>nsubj:{he, ...} observe dobj:{result} prep at:{time} <lb/>nsubj:{you, child, ...} observe dobj:{bird} <lb/>. . . <lb/>Figure 1: Examples of predicate-argument struc-<lb/>tures and initial frames for the verb &quot; observe. &quot; <lb/>frequencies in the applications of semantic frames <lb/>or the method proposed by Abend and Rappoport <lb/>(2010). <lb/>We apply the following processes to extracted <lb/>predicate-argument structures: <lb/> • A verb and an argument are lemmatized, and <lb/>only the head of an argument is preserved for <lb/>compound nouns. <lb/> • Phrasal verbs are also distinguished from <lb/>non-phrasal verbs. For example, &quot; look up &quot; <lb/>has independent frames from &quot; look. &quot; <lb/> • The passive voice of a verb is distinguished <lb/>from the active voice, and thus these have in-<lb/>dependent frames. Passive voice is detected <lb/>using the part-of-speech tag &quot; VBN &quot; (past <lb/>participle). The alignment between frames of <lb/>active and passive voices will be done after <lb/>the induction of frames using the model of <lb/>Sasano et al. (2013) in the future. <lb/> •  &quot; xcomp &quot; (open clausal complement) is re-<lb/>named to &quot; ccomp &quot; (clausal complement) and <lb/> &quot; xsubj &quot; (controlling subject) is renamed to <lb/> &quot; nsubj &quot; (nominal subject). This is because <lb/> 
			
			<page>60 <lb/></page> 
			
			these usages as predicate-argument structures <lb/>are not different. <lb/> • A capitalized argument with the part-of <lb/>speech &quot; NNP &quot; (singular proper noun) or <lb/> &quot; NNPS &quot; (plural proper noun) is general-<lb/>ized to ⟨name⟩. Similarly, an argument of <lb/> &quot; ccomp &quot; is generalized to ⟨comp⟩ since the <lb/>content of a clausal complement is not impor-<lb/>tant. <lb/>Extracted predicate-argument structures are <lb/>collected for each verb and the subsequent pro-<lb/>cesses are applied to the predicate-argument struc-<lb/>tures of each verb. Figure 1 shows examples of <lb/>predicate-argument structures for &quot; observe. &quot; <lb/> 3.2 Constructing Initial Frames from <lb/>Predicate-argument Structures <lb/> A straightforward way to produce semantic frames <lb/>is to cluster the extracted predicate-argument <lb/>structures directly. Since our objective is to com-<lb/>pile broad-coverage semantic frames, a massive <lb/>amount of predicate-argument structures should <lb/>be fed into the clustering. It would take prohibitive <lb/>computational costs to conduct the sampling pro-<lb/>cedure, which is described in the next section. <lb/>To make the computation feasible, we merge the <lb/>predicate-argument structures that have the same <lb/>or similar meaning to get initial frames. These ini-<lb/>tial frames are the input of the subsequent cluster-<lb/>ing process. For this merge, we assume one sense <lb/>per collocation (Yarowsky, 1993) for predicate-<lb/>argument structures. <lb/>For each predicate-argument structure of a verb, <lb/>we couple the verb and an argument to make a unit <lb/>for sense disambiguation. We select an argument <lb/>in the following order by considering the degree of <lb/>effect on the verb sense:  3 <lb/> dobj, ccomp, nsubj, prep  * , iobj. <lb/>This selection of a predominant argument order <lb/>above is justified by relative comparisons of the <lb/>discriminative power of the different slots for CPA <lb/>frames (Popescu, 2013). If a predicate-argument <lb/>structure does not have any of the above slots, it is <lb/>discarded. <lb/>Then, the predicate-argument structures that <lb/>have the same verb and argument pair (slot and <lb/> 
			
			<note place="footnote">3 If a predicate-argument structure has multiple preposi-<lb/>tional phrases, one of them is randomly selected. <lb/></note> 
			
			word, e.g., &quot; dobj:effect &quot; ) are merged into an ini-<lb/>tial frame (Figure 1). After this process, we dis-<lb/>card minor initial frames that occur fewer than 10 <lb/>times. <lb/>For example, we have 732,292 instances <lb/>(predicate-argument structures) for the verb &quot; ob-<lb/>serve &quot; in the web corpus that is used in our exper-<lb/>iment (its details are described in Section 4.1). As <lb/>the result of this merging process, we obtain 6,530 <lb/>initial frames, which become an input for the clus-<lb/>tering. This means that this process accelerates the <lb/>speed of clustering more than 100 times. <lb/>The precision of this process will be evaluated <lb/>in Section 4.3. <lb/> 3.3 Clustering using Chinese Restaurant <lb/>Process <lb/> We cluster initial frames for each verb to produce <lb/>final semantic frames using the Chinese Restau-<lb/>rant Process (Aldous, 1985). We regard each ini-<lb/>tial frame as an instance in the usual clustering of <lb/>the Chinese Restaurant Process. <lb/>We calculate the posterior probability of a se-<lb/>mantic frame f  j  given an initial frame v  i  as fol-<lb/>lows: <lb/> P (f  j  |v  i  ) ∝ <lb/> {  n(f  j  ) <lb/> N +α  · P (v  i  |f  j  ) f  j  ̸ = new <lb/> α <lb/>N +α  · P (v  i  |f  j  ) f  j  = new, <lb/> (1) <lb/>where N is the number of initial frames for the <lb/>target verb and n(f  j  ) is the current number of ini-<lb/>tial frames assigned to the semantic frame f  j  . α <lb/> is a hyper-parameter that determines how likely <lb/>it is for a new semantic frame to be created. In <lb/>this equation, the first term is the Dirichlet process <lb/>prior and the second term is the likelihood of v  i  . <lb/> P (v  i  |f  j  ) is defined based on the Dirichlet-<lb/>Multinomial distribution as follows: <lb/> P (v  i  |f  j  ) = <lb/> ∏ <lb/> w∈V <lb/> P (w|f  j  )  count(v  i  ,w)  , <lb/> (2) <lb/>where V is the vocabulary in all case slots cooc-<lb/>curring with the verb. It is distinguished by <lb/>the case slot, and thus consists of pairs of slots <lb/>and words, e.g., &quot; nsubj:child &quot; and &quot; dobj:bird. &quot; <lb/> count(v  i  , w) is the number of w in the initial <lb/>frame v  i  . <lb/> P (w|f  j  ) is defined as follows: <lb/> P (w|f  j  ) = <lb/> count(f  j  , w) + β <lb/> ∑ <lb/> t∈V  count(f  j  , t) + |V | · β <lb/>, (3) <lb/> 
			
			<page>61 <lb/></page> 
			
			where count(f  j  , w) is the current number of w in <lb/>the frame f  j  , and β is a hyper-parameter of Dirich-<lb/>let distribution. For a new semantic frame, this <lb/>probability is uniform (1/|V |). <lb/> We use Gibbs sampling to realize this cluster-<lb/>ing. <lb/> 4 Experiments and Evaluations <lb/> 4.1 Experimental Settings <lb/> We use two kinds of large-scale corpora: a web <lb/>corpus and the English Gigaword corpus. <lb/>To prepare a web corpus, we first crawled the <lb/>web. We extracted sentences from each web <lb/>page that seems to be written in English based <lb/>on the encoding information. Then, we selected <lb/>sentences that consist of at most 40 words, and <lb/>removed duplicated sentences. From this pro-<lb/>cess, we obtained a corpus of one billion sen-<lb/>tences, totaling approximately 20 billion words. <lb/>We focused on verbs whose frequency was more <lb/>than 1,000. There were 19,649 verbs, includ-<lb/>ing phrasal verbs, and separating passive and ac-<lb/>tive constructions. We extracted 2,032,774,982 <lb/>predicate-argument structures. <lb/>We also used the English Gigaword corpus <lb/>(LDC2011T07; English Gigaword Fifth Edition) <lb/>to induce semantic frames. This corpus consists <lb/>of approximately 180 million sentences, which to-<lb/>taling four billion words. There were 7,356 verbs <lb/>after applying the same frequency threshold as the <lb/>web corpus. We extracted 423,778,278 predicate-<lb/>argument structures from this corpus. <lb/>We set the hyper-parameters α in (1) and β in <lb/>(3) to 1.0. The frame assignments for all the com-<lb/>ponents were initialized randomly. We took 100 <lb/>samples for each initial frame and selected the <lb/>frame assignment that has the highest probability. <lb/>These parameters were determined according to a <lb/>preliminary experiment to manually examine the <lb/>quality of resulting frames. <lb/> 4.2 Experimental Results <lb/> We executed the per-verb clustering tasks on a PC <lb/>cluster. It finished within a few hours for most <lb/>verbs, but it took a couple of days for very frequent <lb/>verbs, such as &quot; get &quot; and &quot; say. &quot; The clustering pro-<lb/>duced an average number of semantic frames per <lb/>verb of 15.2 for the web corpus and 18.5 for the <lb/>Gigaword corpus. Examples of induced semantic <lb/>frames from the web corpus are shown in Table 1. <lb/> slot <lb/>
			
			instances <lb/>nsubj <lb/>i:5850, we:5201, he:3796, you:3669, ... <lb/>dobj <lb/>what:7091, people:2272, this:2262, ... <lb/>observe:1 prep in way:254, world:204, life:194, ... <lb/>. . . <lb/>nsubj <lb/>we:11135, you:1321, i:1317, ... <lb/>dobj <lb/>change:5091, difference:2719, ... <lb/>observe:2 prep in study:622, case:382, cell:362, ... <lb/>. . . <lb/>nsubj <lb/>student:3921, i:2240, we:2174, ... <lb/>dobj <lb/>child:2323, class:2184, student:2025, ... <lb/>observe:3 prep in classroom:555, action:509, ... <lb/>. . . <lb/>nsubj <lb/>we:44833, i:6873, order:4051, ... <lb/>dobj <lb/>card:28835, payment:22569, ... <lb/>accept:1 prep for payment:1166, convenience:1147, ... <lb/>. . . <lb/>nsubj <lb/>i:10568, we:9300, you:5106, ... <lb/>dobj <lb/>that:14180, this:12061, it:7756, ... <lb/>accept:2 prep as part:1879, fact:1085, truth:926, ... <lb/>. . . <lb/>nsubj <lb/>people:7459, he:6696, we:5515, ... <lb/>dobj <lb/>christ:13766, jesus:6528, it:5612, ... <lb/>accept:3 prep as savior:5591, lord:597, one:469, ... <lb/>. . . <lb/> Table 1: Examples of resulting frames for the verb <lb/> &quot; observe &quot; and &quot; accept &quot; induced from the web cor-<lb/>pus. The number following an instance word rep-<lb/>
			
			resents its frequency. <lb/> 4.3 Evaluation of Induced Semantic Frames <lb/> We evaluate precision and coverage of induced se-<lb/>mantic frames. To measure the precision of in-<lb/>duced semantic frames, we adopt the purity met-<lb/>ric, which is usually used to evaluate clustering re-<lb/>sults. However, the problem is that it is impossible <lb/>to assign gold-standard classes to the huge num-<lb/>ber of instances. To automatically measure the <lb/>purity of the induced semantic frames, we make <lb/>use of the SemLink corpus (Loper et al., 2007), in <lb/>which VerbNet classes (Kipper-Schuler, 2005) and <lb/>PropBank/FrameNet frames are assigned to each <lb/>instance. We make a test set that contains 157 pol-<lb/>ysemous verbs that occur 10 or more times in the <lb/>SemLink corpus (sections 02-21 of the Wall Street <lb/>Journal). We first add these instances to the in-<lb/>stances from a raw corpus and apply clustering to <lb/>these merged instances. Then, we compare the in-<lb/>duced semantic frames of the SemLink instances <lb/>with their gold-standard classes. We adopt Verb-<lb/>Net classes and PropBank frames as gold-standard <lb/>classes. <lb/>For each group of verb-specific semantic <lb/>frames, we measure the purity of the frames as the <lb/>percentage of SemLink instances belonging to the <lb/>majority gold class in their respective cluster. Let <lb/>

			<page> 62 <lb/></page>

			PU <lb/> CO <lb/>F  1 <lb/> Mac <lb/>Mic <lb/>Mac <lb/>Mic <lb/>Mac <lb/>Mic <lb/>against <lb/>One frame <lb/>0.799 0.802 0.917 0.952 0.854 0.870 <lb/>VerbNet <lb/>Initial frames <lb/> 0.985 0.982 0.755 0.812 0.855 0.889 <lb/>Induced sem frames 0.900 0.901 0.886 0.928 0.893 0.914 <lb/> against <lb/>One frame <lb/>0.901 0.872 <lb/> ↑ <lb/> ↑ <lb/> 0.909 0.910 <lb/>PropBank Initial frames <lb/> 0.994 0.993 <lb/> ↑ <lb/>↑ <lb/> 0.858 0.893 <lb/>Induced sem frames 0.965 0.949 <lb/> ↑ <lb/>↑ <lb/> 0.924 0.939 <lb/> Table 2: Evaluation results of semantic frames from the web corpus against VerbNet classes and Prop-<lb/>Bank frames. &quot; Mac &quot; means a macro average and &quot; Mic &quot; means a micro average. <lb/>PU <lb/>CO <lb/>F  1 <lb/> Mac <lb/>Mic <lb/>Mac <lb/>Mic <lb/>Mac <lb/>Mic <lb/>against <lb/>One frame <lb/>0.799 0.804 0.855 0.920 0.826 0.858 <lb/>VerbNet <lb/>Initial frames <lb/> 0.985 0.981 0.666 0.758 0.795 0.855 <lb/>Induced sem frames 0.916 0.909 0.796 0.880 0.852 0.894 <lb/> against <lb/>One frame <lb/>0.901 0.874 <lb/> ↑ <lb/>↑ <lb/> 0.877 0.896 <lb/>PropBank Initial frames <lb/> 0.994 0.993 <lb/> ↑ <lb/>↑ <lb/> 0.798 0.859 <lb/>Induced sem frames 0.968 0.953 <lb/> ↑ <lb/>↑ <lb/> 0.874 0.915 <lb/> Table 3: Evaluation results of semantic frames from the Gigaword corpus against VerbNet classes and <lb/>PropBank frames. &quot; Mac &quot; means a macro average and &quot; Mic &quot; means a micro average. <lb/> N denote the total number of SemLink instances <lb/>of the target verb, G  j  the set of instances belong-<lb/>ing to the j-th gold class and F  i  the set of instances <lb/>belonging to the i-th frame. The purity (PU) can <lb/>then be written as follows: <lb/>PU = <lb/> 1 <lb/> N <lb/> ∑ <lb/> i <lb/> max <lb/> j <lb/>

			|G  j  ∩ F  i  |. <lb/> (4) <lb/>For example, a frame of the verb &quot; observe &quot; con-<lb/>tains 11 SemLink instances, and eight out of them <lb/>belong to the class SAY-37.7, which is the ma-<lb/>jority class among these 11 instances. PU is cal-<lb/>culated by summing up such counts over all the <lb/>frames of this verb. <lb/>Usually, inverse purity or collocation is used <lb/>to measure the recall of normal clustering tasks. <lb/>However, these recall measures do not fit our task. <lb/>This is because it is not a real error to have similar <lb/>separate frames. Instead, we want to avoid hav-<lb/>ing so many frames that we cannot provide broad-<lb/>coverage selectional preferences due to sparsity. <lb/>To judge this aspect, we measure coverage. <lb/>The coverage (CO) measures to what extent <lb/>predicate-argument structures of the target verb in <lb/>a test set are included in one of frames of the verb. <lb/>We use the predicate-argument structures of the <lb/>above 157 verbs from the SemLink corpus, which <lb/>are the same ones used in the evaluation of PU. <lb/>We judge a predicate-argument structure as cor-<lb/>rect if all of its argument words (of the target slot <lb/>described in Section 3.1) are included in the corre-<lb/>sponding slot of a frame. If the clustering gets bet-<lb/>ter, the value of CO will get higher, because merg-<lb/>ing instances by clustering alleviates data sparsity. <lb/>These per-verb scores are aggregated into an <lb/>overall score by averaging over all verbs. We use <lb/>two ways of averaging: a macro average and a mi-<lb/>cro average. The macro average is a simple av-<lb/>erage of scores for individual verbs. The micro <lb/>average is obtained by weighting the scores for in-<lb/>dividual verbs proportional to the number of in-<lb/>stances for that verb. Finally, we use the harmonic <lb/>mean (F  1  ) of purity and coverage as a single mea-<lb/>sure of clustering quality. <lb/>For comparison, we adopt the following two <lb/>baseline methods: <lb/> One frame a frame into which all the instances <lb/>for a verb are merged <lb/> Initial frames the initial frames without cluster-<lb/>ing (described in Section 3.2) <lb/>Table 2 and Table 3 list evaluation results for <lb/>semantic frames induced from the web corpus and <lb/>the Gigaword corpus, respectively.  4  Note that CO <lb/>does not consider gold-standard classes, and thus <lb/>the values of CO are the same for the VerbNet <lb/>

			<note place="footnote"> 4 We did not adopt inverse purity, but its values for the <lb/>induced semantic frames range from 0.42 to 0.49. <lb/></note>

			<page> 63 <lb/></page>

			 and PropBank evaluations. The induced frames <lb/>outperformed the two baseline methods in terms <lb/>of F  1  in most cases. While the coverage of the <lb/>web frames was higher than that of the Giga-<lb/>word frames, as expected, the purity of the web <lb/>frames was slightly lower than that of the Giga-<lb/>word frames. This degradation might be caused <lb/>by the noise in the web corpus. <lb/>The purity of the initial frames was around <lb/>98%-99%, which means that there were few cases <lb/>that the one-sense-per-collocation assumption was <lb/>violated. <lb/>Modi et al. (2012) reported a purity of 77.9% <lb/>for the assignment of FrameNet frames to the <lb/>FrameNet corpus. We also conducted the above <lb/>purity evaluation against FrameNet frames for 140 <lb/>verbs.  
			 
			 5  We obtained a macro average of 92.9% <lb/>and a micro average of 89.2% for the web frames, <lb/>and a macro average of 93.2% and a micro average <lb/>of 89.8% for the Gigaword frames. It is difficult <lb/>to directly compare these results with Modi et al. <lb/>(2012), but our frame assignments seem to have <lb/>higher accuracy. <lb/> 4.4 Evaluation against CPA Frames <lb/> Corpus Pattern Analysis (CPA) is a technique for <lb/>linking word usage to prototypical syntagmatic <lb/>patterns. 6 The resource was built manually by in-<lb/>vestigating examples in the BNC, and the set of <lb/>corpus examples used to induce each pattern is <lb/>given. For example, the following three patterns <lb/>describe the usage of the verb &quot; accommodate. &quot; <lb/>[Human 1] accommodate [Human 2] <lb/>[Building] accommodate [Eventuality] <lb/>[Human] accommodate [Self] to [Eventuality] <lb/>In this paper, we use CPA to evaluate the quality <lb/>of the automatically induced frames. By compar-<lb/>ing the induced frames to CPA patterns, we can <lb/>evaluate the correctness and relevance of this ap-<lb/>proach from a human point of view. To do that, <lb/>we associate semantic features to the set of words <lb/>in each slot in the frames, using SUMO (Niles <lb/>and Pease, 2001). For example, take the follow-<lb/>ing frame for the verb &quot; accomplish &quot; : <lb/> accomplish:1 <lb/> nsubj:{you, leader, employee, ...} <lb/>dobj:{developing, progress, objective, ...}. <lb/> 
			 
			 <note place="footnote">5 Since FrameNet frames are not assigned to all the verbs <lb/>of SemLink, the number of verbs is different from the evalu-<lb/>ations against VerbNet and PropBank. <lb/></note> 
			 
			 <note place="footnote">6 http://deb.fi.muni.cz/pdev/ <lb/></note>
			 
			 all <lb/>K-means <lb/>Entropy (E) <lb/>0.790 <lb/>0.516 <lb/>Recovery Rate (RC) 0.347 <lb/>0.630 <lb/>Purity (P ) <lb/>0.462 <lb/>0.696 <lb/>Table 4: CPA Evaluation. <lb/>Using SUMO, we map this frame to the following: <lb/>nsubj: [Human] <lb/>dobj: [SubjectiveAssessmentAttribute], <lb/>which corresponds to pattern 3 for &quot; accomplish &quot; <lb/>in CPA. <lb/>We also associate SUMO attributes to the CPA <lb/>patterns with more than 10 examples (716 verbs). <lb/>There are many patterns of SUMO attributes for <lb/>any CPA frame or induced frame, since each <lb/>filler word in a particular slot can have more <lb/>than one SUMO attribute. We filter out the <lb/>non-discriminative SUMO attributes following the <lb/>technique described in Popescu (2013). Using <lb/>this, we obtain SUMO attributes for both CPA <lb/>clusters and induced frames, and we can use the <lb/>standard entropy-based measures to evaluate the <lb/>match between the two types of patterns: E — en-<lb/>tropy, RC — recovery rate, and P — purity (Li et <lb/>al., 2004): <lb/> E = <lb/> K <lb/> ∑ <lb/> j=1 <lb/> m  j <lb/> m <lb/> · e  j  , RC = 1 − <lb/> K,L <lb/> ∑ <lb/> j,i=1 <lb/> p  ij <lb/> m  i <lb/> , <lb/> (5) <lb/> P = <lb/> K <lb/> ∑ <lb/> j=1 <lb/> m  j <lb/> m <lb/> · p  j  , p  j  = max <lb/> i <lb/> p  ij  , <lb/> (6) <lb/> e  j  = <lb/> L <lb/> ∑ <lb/> i=1 <lb/> p  ij  log  2  p  ij  , p  ij  = <lb/> m  ij <lb/> m  i <lb/> , <lb/> (7) <lb/>where m  j  is the number of induced frames corre-<lb/>sponding to topic j, m  ij  is the number of induced <lb/>frames in cluster j and annotated with the CPA <lb/>pattern i, m is the total number of induced frames, <lb/> L is the number of CPA patterns, and K is the <lb/>number of induced frames. <lb/>We also consider a K-means clustering process, <lb/>with K set as 2 or 3 depending on the number of <lb/>SUMO-attributed patterns. The K-means evalu-<lb/>ation is carried out considering only the centroid <lb/>of the cluster, which corresponds to the prototypi-<lb/>cal induced semantic frame with SUMO attributes. <lb/>We compute E, RC and P using formulae (5) -<lb/>(7) for each verb and then compute the macro av-<lb/>erage, considering all the frames and only the K-<lb/>means centroids, respectively. The results for the <lb/>induced web frames are displayed in Table 4. <lb/>

			<page> 64 <lb/></page>

			The evaluation method presented here over-<lb/>comes some of the drawbacks of the previous ap-<lb/>proaches (Materna, 2012; Materna, 2013). First, <lb/>we did not limit the evaluation to the most frequent <lb/>patterns. Second, the mapping was carried out au-<lb/>tomatically and not by hand. The results above <lb/>compare favorably with the previous approaches, <lb/>especially considering that no filtering procedures <lb/>were applied to the induced frames. We anticipate <lb/>that the results based on the prototypical induced <lb/>frames with SUMO attributes would be competi-<lb/>tive. Our post-analysis revealed that the entropy <lb/>can be lowered further if an automatic filtering <lb/>based on frequencies is applied. <lb/> 4.5 Evaluation of the Quality of Selectional <lb/>Preferences <lb/> We also investigated the quality of selectional <lb/>preferences within the induced semantic frames. <lb/>The only publicly available test data for selectional <lb/>preferences, to our knowledge, is from Chambers <lb/>and Jurafsky (2010). This data consists of quadru-<lb/>ples (verb, relation, word, confounder) and does <lb/>not contain their context.  
			
			7 <lb/> A typical way for using our semantic frames is <lb/>to select an appropriate frame for an input sen-<lb/>tence and judge the eligibility of the word uses <lb/>against the selected frame. However, due to the <lb/>lack of context for the above data, it is difficult to <lb/>select a corresponding semantic frame for a test <lb/>quadruple and thus the induced semantic frames <lb/>cannot be naturally applied to this data. To in-<lb/>vestigate the potential for selectional preferences <lb/>of the semantic frames, we approximately match <lb/>a quadruple with each of the semantic frames of <lb/>the verb and select the frame that has the highest <lb/>probability as follows: <lb/> P (w) = max <lb/> i <lb/> P (w|v, rel, f  i  ), <lb/> (8) <lb/>where w is the word or confounder, v is the verb, <lb/> rel is the relation and f  i  is a semantic frame. By <lb/>comparing the probabilities of the word and the <lb/>confounder, we select either of them according to <lb/>the higher probability. For tie breaking in the case <lb/>that no frames are found for the verb or both the <lb/>word and confounder are not found in the case slot, <lb/>we randomly select either of them in the same way <lb/>as Chambers and Jurafsky (2010). <lb/>We use the &quot; neighbor frequency &quot; set, which is <lb/>the most difficult among the three sets included <lb/>

			<note place="footnote"> 7 A document ID of the English Gigaword corpus is avail-<lb/>able, but it is difficult to recover the context of each instance <lb/>from this information. <lb/></note>

			in the data. It contains 6,767 quadruples and the <lb/>relations consist of three classes: subject, object <lb/>and preposition, which has no distinction of ac-<lb/>tual prepositions. To link these relations with our <lb/>case slots, we manually aligned the subject with <lb/>the nsubj (nominal subject) slot, the object with <lb/>the dobj (direct object) slot and the preposition <lb/>with prep * (all the prepositions) slots. For the <lb/>preposition relation, we choose the highest prob-<lb/>ability among all the preposition slots in a frame. <lb/>To match the generalized ⟨name⟩ with the word in <lb/>a quadruple, we change the word to ⟨name⟩ if it is <lb/>capitalized and not a capitalized personal pronoun. <lb/>Our semantic frames from the Gigaword corpus <lb/>achieved an accuracy of 81.7% 8 and those from <lb/>the web corpus achieved an accuracy of 80.2%. <lb/>This slight deterioration seems to come from the <lb/>noise in the web corpus. The best performance <lb/>in Chambers and Jurafsky (2010) is 81.7% on <lb/>this &quot; neighbor frequency &quot; set, which was achieved <lb/>by conditional probabilities with the Erk (2007)&apos;s <lb/>smoothing method calculated from the English Gi-<lb/>gaword corpus. Our approach for selectional pref-<lb/>erences does not use smoothing like Erk (2007), <lb/>but it achieved equivalent performance to the pre-<lb/>vious work. If we applied our semantic frames to a <lb/>verb instance with its context, a more precise judg-<lb/>ment of selectional preferences would be possible <lb/>with appropriate frame selection. <lb/> 5 Conclusion <lb/> This paper has described an unsupervised method <lb/>for inducing semantic frames from instances of <lb/>each verb in giga-word corpora. This method is <lb/>clustering based on the Chinese Restaurant Pro-<lb/>cess. The resulting frame data are open to the pub-<lb/>lic and also can be searched by inputting a verb via <lb/>our web interface. 9 <lb/> As applications of the resulting frames, we plan <lb/>to integrate them into syntactic parsing, semantic <lb/>role labeling and verb sense disambiguation. For <lb/>instance, Kawahara and Kurohashi (2006b) im-<lb/>proved accuracy of dependency parsing based on <lb/>Japanese semantic frames automatically induced <lb/>from a large raw corpus. It is valuable and promis-<lb/>ing to apply our semantic frames to these NLP <lb/>tasks. <lb/> 
			
			<note place="footnote">8 Since the dataset was created from the NYT 2001 portion <lb/>of the English Gigaword Corpus, we built semantic frames <lb/>again from the Gigaword corpus except this part. <lb/></note> 
			
			<note place="footnote">9 http://nlp.ist.i.kyoto-u.ac.jp/member/kawahara/cf/crp.en/ <lb/></note> 
			
			<page>65 <lb/></page> 
			
		</body>
			
		<back>
			
			<div type="acknowledgement">Acknowledgments <lb/> This work was supported by Kyoto University <lb/>John Mung Program and JST CREST. We grate-<lb/>fully acknowledge the support of the National Sci-<lb/>ence Foundation Grant NSF 1116782 -RI: Small: <lb/>A Bayesian Approach to Dynamic Lexical Re-<lb/>sources for Flexible Language Processing. Any <lb/>opinions, findings, and conclusions or recommen-<lb/>dations expressed in this material are those of the <lb/>authors and do not necessarily reflect the views of <lb/>the National Science Foundation. <lb/></div> 
				
			<listBibl>References <lb/> 
			
			Omri Abend and Ari Rappoport. 2010. Fully unsuper-<lb/>vised core-adjunct argument classification. In Pro-<lb/> ceedings of the 48th Annual Meeting of the Associa-<lb/>tion for Computational Linguistics, pages 226–236. <lb/>David Aldous. 1985. Exchangeability and related top-<lb/>ics. ´ <lb/>Ecole d&apos; ´ <lb/>Eté de Probabilités de Saint-Flour XIII <lb/> 1983,  pages 1–198. <lb/>Collin Baker, Charles J. Fillmore, and John Lowe. <lb/>1998. The Berkeley FrameNet Project. In Pro-<lb/>ceedings of the 36th Annual Meeting of the Associ-<lb/>ation for Computational Linguistics and 17th Inter-<lb/>national Conference on Computational Linguistics, <lb/> pages 86–90. <lb/>Hans C. Boas. 2002. Bilingual framenet dictionaries <lb/>for machine translation. In Proceedings of the 3rd <lb/>International Conference on Language Resources <lb/>and Evaluation, pages 1364–1371. <lb/>Ted Briscoe and John Carroll. 1997. Automatic ex-<lb/>traction of subcategorization from corpora. In Pro-<lb/>ceedings of the 5th Conference on Applied Natural <lb/>Language Processing, pages 356–363. <lb/>Aljoscha Burchardt and Anette Frank. 2006. Approx-<lb/>imating textual entailment with LFG and FrameNet <lb/>frames. In Proceedings of the 2nd PASCAL Recog-<lb/>nizing Textual Entailment Workshop, pages 92–97. <lb/>Nathanael Chambers and Daniel Jurafsky. 2010. Im-<lb/>proving the use of pseudo-words for evaluating se-<lb/>lectional preferences. In Proceedings of the 48th <lb/>Annual Meeting of the Association for Computa-<lb/>tional Linguistics, pages 445–453. <lb/>Marie-Catherine de Marneffe, Bill MacCartney, and <lb/>Christopher D. Manning. 2006. Generating typed <lb/>dependency parses from phrase structure parses. In <lb/> Proceedings of the 5th International Conference on <lb/>Language Resources and Evaluation, pages 449– <lb/>454. <lb/>Michael Ellsworth and Adam Janin. 2007. Mu-<lb/>taphrase: Paraphrasing with framenet. In Proceed-<lb/>ings of the ACL-PASCAL Workshop on Textual En-<lb/>tailment and Paraphrasing, pages 143–150. <lb/>Katrin Erk. 2007. A simple, similarity-based model <lb/>for selectional preferences. In Proceedings of the <lb/>45th Annual Meeting of the Association of Compu-<lb/>tational Linguistics, pages 216–223. <lb/>Ingrid Falk, Claire Gardent, and Jean-Charles Lamirel. <lb/>2012. Classifying french verbs using french and en-<lb/>glish lexical resources. In Proceedings of the 50th <lb/>Annual Meeting of the Association for Computa-<lb/>tional Linguistics, pages 854–863. <lb/>Trond Grenager and Christopher D. Manning. 2006. <lb/>Unsupervised discovery of a statistical verb lexicon. <lb/>In Proceedings of the 2006 Conference on Empirical <lb/>Methods in Natural Language Processing, pages 1– <lb/>8. <lb/>Patrick Hanks. 2012. How people use words to make <lb/>meanings: Semantic types meet valencies. Input, <lb/>Process and Product: Developments in Teaching <lb/>and Language Corpora, pages 54–69. <lb/>Daisuke Kawahara and Sadao Kurohashi. 2006a. <lb/>Case frame compilation from the web using high-<lb/>performance computing. In Proceedings of the 5th <lb/>International Conference on Language Resources <lb/>and Evaluation, pages 1344–1347. <lb/>Daisuke Kawahara and Sadao Kurohashi. 2006b. A <lb/>fully-lexicalized probabilistic model for Japanese <lb/>syntactic and case structure analysis. In Proceedings <lb/>of the Human Language Technology Conference of <lb/>the NAACL, pages 176–183. <lb/>Karin Kipper-Schuler. 2005. VerbNet: A Broad-<lb/>Coverage, Comprehensive Verb Lexicon. Ph.D. the-<lb/>sis, University of Pennsylvania. <lb/>Anna Korhonen, Yuval Krymolowski, and Ted Briscoe. <lb/>2006. A large subcategorization lexicon for natural <lb/>language processing applications. In Proceedings of <lb/>the 5th International Conference on Language Re-<lb/>sources and Evaluation, pages 345–352. <lb/>Joel Lang and Mirella Lapata. 2010. Unsuper-<lb/>vised induction of semantic roles. In Human Lan-<lb/>guage Technologies: The 2010 Annual Conference <lb/>of the North American Chapter of the Association <lb/>for Computational Linguistics, pages 939–947. <lb/>Joel Lang and Mirella Lapata. 2011a. Unsupervised <lb/>semantic role induction via split-merge clustering. <lb/>In Proceedings of the 49th Annual Meeting of the <lb/>Association for Computational Linguistics: Human <lb/>Language Technologies, pages 1117–1126. <lb/>Joel Lang and Mirella Lapata. 2011b. Unsupervised <lb/>semantic role induction with graph partitioning. In <lb/> Proceedings of the 2011 Conference on Empirical <lb/>Methods in Natural Language Processing, pages <lb/>1320–1331. <lb/>Tao Li, Sheng Ma, and Mitsunori Ogihara. 2004. <lb/>Entropy-based criterion in categorical clustering. In <lb/> Proceedings of the 21st International Conference on <lb/>Machine Learning, volume 4, pages 536–543. <lb/> 
			
			66 <lb/> 
			
			Thomas Lippincott, Anna Korhonen, and Diarmuid <lb/>O Séaghdha. 2012. Learning syntactic verb frames <lb/>using graphical models. In Proceedings of the 50th <lb/>Annual Meeting of the Association for Computa-<lb/>tional Linguistics, pages 420–429. <lb/>Edward Loper, Szu-Ting Yi, and Martha Palmer. 2007. <lb/>Combining lexical resources: mapping between <lb/>PropBank and VerbNet. In Proceedings of the 7th <lb/>International Workshop on Computational Linguis-<lb/>tics. <lb/> Christopher Manning. 1993. Automatic acquisition <lb/>of a large subcategorization dictionary from corpora. <lb/>In Proceedings of the 31st Annual Meeting of the As-<lb/>sociation for Computational Linguistics, pages 235– <lb/>242. <lb/>Jiří Materna. 2012. LDA-Frames: An unsupervised <lb/>approach to generating semantic frames. In Alexan-<lb/>der Gelbukh, editor, Proceedings of the 13th Inter-<lb/>national Conference CICLing 2012, Part I, volume <lb/>7181 of Lecture Notes in Computer Science, pages <lb/>376–387. Springer Berlin / Heidelberg. <lb/>Jiří Materna. 2013. Parameter estimation for LDA-<lb/>Frames. In Proceedings of the 2013 Conference of <lb/>the North American Chapter of the Association for <lb/>Computational Linguistics: Human Language Tech-<lb/>nologies, pages 482–486. <lb/>Ashutosh Modi, Ivan Titov, and Alexandre Klementiev. <lb/>2012. Unsupervised induction of frame-semantic <lb/>representations. In Proceedings of the NAACL-HLT <lb/>Workshop on the Induction of Linguistic Structure, <lb/> pages 1–7. <lb/>Srini Narayanan and Sanda Harabagiu. 2004. Ques-<lb/>tion answering based on semantic structures. In <lb/> Proceedings of the 20th International Conference on <lb/>Computational Linguistics, pages 693–701. <lb/>Ian Niles and Adam Pease. 2001. Towards a standard <lb/>upper ontology. In Proceedings of the International <lb/>Conference on Formal Ontology in Information Sys-<lb/>tems, pages 2–9. <lb/>Martha Palmer, Daniel Gildea, and Paul Kingsbury. <lb/>2005. The proposition bank: An annotated cor-<lb/>pus of semantic roles. Computational Linguistics, <lb/> 31(1):71–106. <lb/>Christopher Parisien and Suzanne Stevenson. 2009. <lb/>Modelling the acquisition of verb polysemy in chil-<lb/>dren. In Proceedings of the CogSci2009 Workshop <lb/>on Distributional Semantics beyond Concrete Con-<lb/>cepts, pages 17–22. <lb/>Christopher Parisien and Suzanne Stevenson. 2010. <lb/>Learning verb alternations in a usage-based <lb/>Bayesian model. In Proceedings of the 32nd annual <lb/>meeting of the Cognitive Science Society. <lb/> Hoifung Poon and Pedro Domingos. 2009. Unsuper-<lb/>vised semantic parsing. In Proceedings of the 2009 <lb/>Conference on Empirical Methods in Natural Lan-<lb/>guage Processing, pages 1–10. <lb/>Octavian Popescu. 2013. Learning corpus patterns us-<lb/>ing finite state automata. In Proceedings of the 10th <lb/>International Conference on Computational Seman-<lb/>tics, pages 191–203. <lb/>Roi Reichart and Anna Korhonen. 2013. Improved <lb/>lexical acquisition through DPP-based verb cluster-<lb/>ing. In Proceedings of the 51st Annual Meeting <lb/>of the Association for Computational Linguistics, <lb/> pages 862–872. <lb/>Ryohei Sasano, Daisuke Kawahara, Sadao Kurohashi, <lb/>and Manabu Okumura. 2013. Automatic knowl-<lb/>edge acquisition for case alternation between the <lb/>passive and active voices in Japanese. In Proceed-<lb/>ings of the 2013 Conference on Empirical Methods <lb/>in Natural Language Processing, pages 1213–1223. <lb/>Lin Sun and Anna Korhonen. 2009. Improving verb <lb/>clustering with automatically acquired selectional <lb/>preferences. In Proceedings of the 2009 Confer-<lb/>ence on Empirical Methods in Natural Language <lb/>Processing, pages 638–647. <lb/>Mihai Surdeanu, Sanda Harabagiu, John Williams, and <lb/>Paul Aarseth. 2003. Using predicate-argument <lb/>structures for information extraction. In Proceed-<lb/>ings of the 41st Annual Meeting of the Association <lb/>for Computational Linguistics, pages 8–15. <lb/>Ivan Titov and Alexandre Klementiev. 2011. A <lb/>Bayesian model for unsupervised semantic parsing. <lb/>In Proceedings of the 49th Annual Meeting of the <lb/>Association for Computational Linguistics: Human <lb/>Language Technologies, pages 1445–1455. <lb/>Ivan Titov and Alexandre Klementiev. 2012. A <lb/>Bayesian approach to unsupervised semantic role in-<lb/>duction. In Proceedings of the 13th Conference of <lb/>the European Chapter of the Association for Com-<lb/>putational Linguistics, pages 12–22. <lb/>Andreas Vlachos, Anna Korhonen, and Zoubin <lb/>Ghahramani. 2009. Unsupervised and constrained <lb/>dirichlet process mixture models for verb cluster-<lb/>ing. In Proceedings of the Workshop on Geomet-<lb/>rical Models of Natural Language Semantics, pages <lb/>74–82. <lb/>David Yarowsky. 1993. One sense per collocation. In <lb/> Proceedings of the Workshop on Human Language <lb/>Technology, pages 266–271. <lb/></listBibl>

			<page> 67 </page>

		</back>
	</text>
</tei>
