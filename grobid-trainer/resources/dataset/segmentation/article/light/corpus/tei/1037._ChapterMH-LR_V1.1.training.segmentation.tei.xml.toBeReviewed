<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="_0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Encoding models for scholarly <lb/>literature <lb/>Does the TEI have a word to say? <lb/>Martin Holmes, Humanities Computing and Media Centre, University of Victoria <lb/>Laurent Romary, INRIA-Gemo &amp; Humboldt Universität Berlin <lb/>Abstract: In this chapter, we examine the issue of digital formats for document encoding, <lb/>archiving and publishing, through the specific example of &quot;born-digital&quot; scholarly journal <lb/>articles. This small area of electronic publishing represents a microcosm of the state of <lb/>the art, and provides a good basis for this discussion. We will begin by looking at the <lb/>traditional workflow of journal editing and publication, and how these practices have <lb/>made the transition into the online domain. We will examine the range of different file <lb/>formats in which electronic articles are currently stored and published. We will argue <lb/>strongly that, despite the prevalence of binary and proprietary formats such as PDF and <lb/>MS Word, XML is a far superior encoding choice for journal articles. Next, we look at <lb/>the range of XML document structures (DTDs, Schemas) which are in common use for <lb/>encoding journal articles, and consider some of their strengths and weaknesses. We will <lb/>suggest that, despite the existence of specialized schemas intended specifically for journal <lb/>articles (such as NLM), and more broadly-used publication-oriented schemas such as <lb/>DocBook, there are strong arguments in favour of developing a subset or customization <lb/>of the Text Encoding Initiative (TEI) schema for the purpose of journal-article encoding; <lb/>TEI is already in use in a number of journal publication projects, and the scale and <lb/>precision of the TEI tagset makes it particularly appropriate for encoding scholarly <lb/>articles. We will outline the document structure of a TEI-encoded journal article, and look <lb/>in detail at suggested markup patterns for specific features of journal articles. Next, we <lb/>will look briefly at how XML-based publication systems work, and what advantages they <lb/>bring over electronic publication methods based on other digital formats. <lb/></front>

			<body>Introduction <lb/>This book chapter provides an overview on issues related to the definition of a standard <lb/>framework for the editing of scientific content. It mainly takes its examples from the <lb/>specific case of journal papers, while attempting to cover the core features of similar <lb/>documents (conference papers, scientific books, ISO standards, etc.). The focus on <lb/>scholarly papers results from a series of converging factors indicating that the provision <lb/>of a reference model for the representation of such textual objects has become a central <lb/>aspect of the capacity of scholarly publishing to go digital. <lb/>These various factors may be summarised as follows: <lb/>hal-00390966, version 1 -3 Jun 2009 <lb/> Most of the digital edition workflow is now carried out almost entirely in <lb/>electronic form. Authors and reviewers are only exchanging digital texts with <lb/>publishers; <lb/> In the scientific world itself, the increasing role of publication repositories, in <lb/>conjunction with the open access movement, has raised questions, as well as <lb/>expectations, with regards long-term accessibility of the corresponding data; <lb/> Specific repositories such as Pubmed Central 1 have even taken strong positions <lb/>with regard to the kind of formats they will offer for long-term accessibility; <lb/> XML technology has gained enough maturity to be now considered as the natural <lb/>syntactic framework for the representation of semi-structured data in general, and <lb/>particularly text based documents; <lb/> Even when taking the XML technology for granted, one can observe that so far no <lb/>specific XML application has emerged as a de facto nor de jure standard, and <lb/>even worse, no coordinated vision seems to guide the development of ongoing <lb/>initiatives. <lb/>This chapter will approach the issue from the point of view of the actual use cases and <lb/>needs of an editing workflow, identifying how the various types of workflows (author -<lb/>publisher (reviewer) -reader), the issues and constraints related to scholarly publishing <lb/>(what is specific to journal papers as opposed to any kind of semi-structured document), <lb/>and style guides for scientific publications may impact on the definition of a reference <lb/>model and/or format. In this context, we will try to demonstrate how much one has to <lb/>consider the representation of scholarly papers in the wider context of text representation, <lb/>in order to provide both a wide and sound basis for standardization but also to ensure a <lb/>long-term convergence between specific and generic document types, through the reuse <lb/>of shared components. This will lead us to suggest that the Text Encoding Initiative can <lb/>be a good candidate to depart from proprietary endeavours and we will try to characterize <lb/>a TEI subset for journal editing that covers most of the features identified in our paper. <lb/>Scholarly publishing and open-access <lb/>It would be quite difficult to address the domain of scholarly publishing from the <lb/>academic viewpoint without tackling, at least partially, the open access debate. To make a <lb/>long story short, the open access debate is rooted in the serial crisis that took place in the <lb/>90s and led libraries as well as scholars to consider that it would be highly difficult to <lb/>absorb the ever increasing costs of scientific journals. <lb/>The principles of open access have been stated in a wide variety of contexts. The most <lb/>prominent we can quote is excerpted from the Berlin declaration 2 issued in October 2003 <lb/></body>

			<note place="footnote">1 http://www.pubmedcentral.nih.gov/ <lb/></note>

			<note place="footnote">2 http://oa.mpg.de/openaccess-berlin/berlindeclaration.html <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>and undersigned by a large number of academic institutions. Open access is presented <lb/>along two main principles: <lb/> The &quot;free, irrevocable, worldwide, right of access to, and a license to copy, use, <lb/>distribute, transmit and display open access contributions&quot; <lb/> The fact that &quot;the complete work and all supplemental materials is deposited in at <lb/>least one online repository using suitable technical standards&quot; <lb/>The first reason why this debate has bearing on our paper here is that the notion of widely <lb/>accessible information is quite systematically related to that of using open standards and <lb/>open technologies to represent and disseminate this information. <lb/>Secondly, one of the ways people have contemplated the implementation of open access <lb/>principles has always been to explore and design new publishing models that could <lb/>somehow be viable alternatives to more traditional commercial publishing. Among such <lb/>initiatives, pure online journals have been seen as a potentially cheap solution for <lb/>disseminating scientific information, ranging from pure open access journals like the <lb/>Living Review series 3 , or academic based initiatives (e.g. Revues.org 4 ) offering a <lb/>transitional model for printed journals wanting to move to a digital format. <lb/>Finally, one of the main endeavours of the open access supporters, in particular those in <lb/>favour of the so-called &quot;green&quot; way to open access, is to encourage scientists to deposit <lb/>their works in publication repositories that freely offer their content (with a possible time <lb/>embargo) online. Beyond the actual political background, the spread of publication <lb/>repositories, and most specifically institutional ones, has brought to the fore two <lb/>important questions that are directly related to the issues addressed in this paper, namely: <lb/> How can the information available in a publication archive, in particular the <lb/>metadata, may be reused as a reliable source of information for further scientific <lb/>work? <lb/> How can the model of publication archives be seen as a sustainable one from the <lb/>point of view of their content, i.e. the capacity to represent full text information in <lb/>such way that it will still be accessible and legible over a long (digital) period. <lb/>As a whole, we claim that some of the technologies and techniques we are reviewing and <lb/>would like to see take hold will make some types of open-access publishing easier and <lb/>more effective; but other than that, we will not address the broader debate around open-<lb/>access any further and in particular aspects related to commercial revenue. <lb/></body>

			<note place="footnote">3 http://www.livingreviews.org/ <lb/></note>

			<note place="footnote">4 http://www.revues.org/ <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>Editing workflows in journal publication <lb/>Over the past fifteen years, many thousands of journals have made the transition from <lb/>print publication to online or hybrid (print and online) publication, without, in most cases, <lb/>radically changing their authoring and editorial practices. The traditional workflow in the <lb/>journal publication process involves these stages: <lb/> Submission by author <lb/> Initial decision by editor <lb/> Circulation to peer-reviewers <lb/> Re-editing/rewriting/negotiation between editor and author <lb/> Final editing <lb/> Pre-print / proofing by editor(s) <lb/> Publication <lb/>As journal publishing has migrated from print to the Internet, these stages have remained <lb/>largely intact, and online journal publishing systems have evolved to support them. For <lb/>instance, the Open Journal Systems documentation 5 describes the OJS editorial process in <lb/>these five steps: <lb/>1. Submissions Queue: Items begin here and are assigned to an editor. <lb/>2. Submission Review: Items undergo peer review and editorial decision. <lb/>3. Submission Editing: Items undergo copyediting, layout, and proofreading. <lb/>4. Scheduling Queue: Items assigned to an issue and/or volume. <lb/>5. Table of Contents: Items ordered for publication and issue published. <lb/>Very little has changed here. However, all communications are now mediated through <lb/>the online journal system rather than through the mail or by telephone; submission is by <lb/>upload, reviewers access articles through the website, and galleys are proofed through the <lb/>website. In the OJS system, copyediting and layout are still very traditional; the layout <lb/>editor creates article files in HTML, PDF or other formats using desktop tools that are not <lb/>integrated into the online system. <lb/>The Public Knowledge Project, parent of OJS, claims that there are &quot;over 2000 titles <lb/>using OJS (as of January 2009)&quot; 6 . This is a remarkable achievement, and there is no <lb/>doubt that it has contributed significantly to the large-scale migration of academic <lb/>journals from print to the Internet. At the same time, many other initiatives have emerged <lb/>

			<note place="footnote">5 &quot;OJS in an Hour, 2008, p.10, http://pkp.sfu.ca/files/OJSinanHour.pdf <lb/></note>

			<note place="footnote">6 Public Knowledge Project, 2009 http://pkp.sfu.ca/ojs-journals <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			which attempt to take advantage of this transition to re-examine the editorial process. For <lb/>instance, Blesius et al 7 describe how they created a new electronic publication system for <lb/>the Dermatology Online Journal 8 with a view to allowing users/readers to create and <lb/>participate in &quot;communities around the content&quot;, through online forums, weblogs and <lb/>other content-sharing tools. Similarly, Copernicus 9 , in collaboration with the European <lb/>Geosciences Union has explored the possibility of introducing community review by <lb/>means of an open review process, which has proven very efficient in improving the <lb/>quality of initial drafts and thus augmenting the acceptance rate, with a corresponding <lb/>reduction in management costs. <lb/>Unlike OJS (at the time of writing), the DOJ publishing system is based on XML, <lb/>enabling it to &quot;export and share data with external archives using the National Library of <lb/>Medicine&apos;s Journal Archiving and Interchange Document Type Definition.&quot; Another <lb/>journal using an XML-based publication system is the Scandinavian Canadian Studies <lb/>journal (http://scancan.net/). In this case, the system uses the Text Encoding Intiative <lb/>(TEI P4 edition). Documents are encoded in XML, and a variety of publication formats <lb/>are then generated from the base XML automatically, using XSLT transformation; articles <lb/>are available in XHTML, PDF and plain text format. (They are also available in TEI P5, <lb/>the successor TEI format, through another XSLT transformation.) The journal still <lb/>produces a traditional print version, and the PDF document for each full print issue is also <lb/>automatically generated from the same XML source. One advantage of this is that each <lb/>article can be proofed and corrected by the editor, the author, and anyone else given <lb/>access, in the exact form in which it will appear in the final print volume, as soon as it is <lb/>marked up and injected into the system. In addition, the use of rich markup such as TEI <lb/>enables automated indexing of any feature that might be included in the markup. For <lb/>instance, in the case of the IALLT Journal (http://ialltjournal.org/), a system deriving <lb/>from that used for ScanCan but based on TEI P5 instead of P4, automated indexes are <lb/>created for all mentions of abbreviations, authors, organizations, people, places, software, <lb/>and topic keywords. In fact, after several years of publication, the indexes of such a <lb/>journal will amount to a rich overview of the journal&apos;s field, showing who its major and <lb/>minor figures of significance are, what topics preoccupy it, and what jargon is coming in <lb/>and out of fashion over time. Another feature of such systems is their elegant handling of <lb/>corrigenda. An error in an article can be emended as soon as it is discovered, and the <lb/>change, along with the reasons for it, can be explained in the &lt;revisionDesc&gt; element in <lb/>the &lt;teiHeader&gt;. The complete set of such errors can be automatically extracted from the <lb/>database and displayed as a single Corrigenda page. 10 Such features demonstrate clear <lb/>advantages for a system based on structured markup over one based on print-oriented <lb/>formats such as PDF or MSWord. <lb/></body>

			<listBibl>7 Blesius et al. &quot;An Open Source Model for Open Access Journal Publication.&quot; AMIA Annual Symposium <lb/>Proceedings (2005). <lb/></listBibl>

			<note place="footnote">8 http://dermatology.cdlib.org/ <lb/></note>

			<note place="footnote">9 http://publications.copernicus.org/ <lb/></note>

			<note place="footnote">10 http://scancan.net/corrigenda.htm <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>The National Library of Medicine (NLM) XML standards used by DOJ actually <lb/>constitute a family of standards, with four distinct tagsets, for &quot;Archiving and <lb/>Interchange&quot;, &quot;Journal Publishing&quot;, &quot;Article Authoring&quot; and &quot;NCBI Book&quot;. In other <lb/>words, journal articles are intended to be marked-up according to four different DTDs, <lb/>depending on what is to be done with them. In an extreme case, this might mean: <lb/> The author writes/marks up an article using the Article Authoring DTD. <lb/> Once the article is accepted for publication, the editor or publisher converts it to <lb/>the Journal Publishing DTD. <lb/> The editor or publisher also creates a version in the Archiving and Interchange <lb/>format, in order to &quot;supply the content to archives or to interchange it with other <lb/>organizations&quot;. 11 <lb/> The article might also be converted into the NCBI Book format if it is to form part <lb/>of a textbook. <lb/>In reality, the last case -use of a regular journal article directly in a textbook -is <lb/>unlikely; and the Archiving and Interchange format is intended more for marking up <lb/>existing print journal content than for use with born-digital articles. All four tag sets are <lb/>built on the same family of modules, so they do not differ a great deal. Nonetheless, one <lb/>has to wonder whether the NCBI/NLM goal of &quot;providing a common format in which <lb/>publishers and archives can exchange journal content&quot; 12 is helped or hindered by the <lb/>proliferation of variant DTDs. <lb/>The online journal Digital Humanities Quarterly 13 also uses a publication system based <lb/>on its own XML format, &quot;DHQ Markup Language&quot;. DHQML also breaks down into <lb/>DHQauthor (for authoring) and DHQpublish (for publishing). There is a third variant <lb/>called DHQcrayonbox, which is intended for articles &quot;too &apos;experimental&apos; for <lb/>DHQauthor&quot;. 14 The authoring variant has the documented goal of being &quot;consonant with <lb/>tagging constructs familiar from TEI (to the extent possible; processing semantics can <lb/>take priority but TEI should be used when its semantics fit),&quot; and the DHQpublish <lb/>schema is intended for &quot;Maximum compatibility with DHQauthor (an easy transform at <lb/>most)&quot;; 15 in other words, these are in some sense variants of TEI. <lb/>We can see from this very brief survey that in the field of academic journals, there are <lb/>now dozens of different formats for online publication; and even in the case of individual <lb/></body>

			<note place="footnote">11 http://dtd.nlm.nih.gov/faq.html <lb/></note>

			<note place="footnote">12 http://dtd.nlm.nih.gov/ <lb/></note>

			<note place="footnote">13 http://www.digitalhumanities.org/dhq/ <lb/></note>

			<note place="footnote">14 http://digitalhumanities.org/view/DHquarterly/SchemaRequirements <lb/></note>

			<note place="footnote">15 Op. cit. <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>journals which might be committed to the use of XML, multiple standards-based or <lb/>idiosyncratic schemas may be in use. <lb/>Constituents of journal papers <lb/>Before attempting to make any concrete proposal as to the ideal electronic representation <lb/>of a scientific paper, it is important to have a precise idea about its general organisation, <lb/>as well as the low-level components such papers may contain. Our aim in this section is <lb/>thus to identify how much a scientific or scholarly publication departs from any other <lb/>type of text and, from this, to identify where there is a need for more precise modelling <lb/>activity for such documents, or at least specific guidelines for applying existing text <lb/>encoding schemes. <lb/>To start with, let us consider the macro-structure of a scholarly article in the generic form <lb/>it has so far occurred on paper. Independently of any domain-specific restriction or <lb/>practices, a scholarly paper quite systematically comprises: <lb/> Title of the paper: this comes as the main reference to the scholarly work and <lb/>usually provides insights on some of the main results, especially in hard sciences: <lb/> Authors, affiliations and addresses: we will come back specifically to this issue <lb/>later in this section, but here we can point out that author identification <lb/>information is essential for scholarly work since it provides the basis for the <lb/>actual attribution of the work to the corresponding researchers. Such factors as <lb/>ordering or institutional description are here essential in this respect; <lb/> Abstract and keywords: these are intended to provide a means for a quick search <lb/>in scientific content, in order to select, for instance, those papers which are worth <lb/>consulting, in the course of a given research project; <lb/> Article body: usually organised in short sections and sub-sections, it typically <lb/>provides a strong structure that matches closely the main argument of the paper, <lb/>and may in some scientific domains (e.g. clinical studies) be very standardised in <lb/>the way certain aspects of the research (methodology, corpus, data gathering, <lb/>conclusions) are articulated; <lb/> Bibliographical references: another core part of scholarly work since it contains <lb/>all descriptions of previous scholarly material that were deemed relevant <lb/>background material for the research presented in the paper; <lb/> Back matter: this comprises a wide variety of small sections such as <lb/>acknowledgements (to colleagues or research funders), glossaries, appendices <lb/>(e.g. for data tables, additional graphics, larger quotations) or notes. <lb/>At the micro-structure level -that is basically the low-level component of the full-text <lb/>content -journal papers can be characterized by making systematic use of a few core <lb/>components that are used in complement to the prose to illustrate, support or formalize <lb/></body>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>the scientific content. Among these, we should pay specific attention to the following <lb/>ones, which deserve appropriate treatment when represented in a digitized format: <lb/> Bibliographical references: these should be formalized so that, independently of <lb/>the actual formatting (numbering, author name abbreviation, etc.) we can <lb/>unequivocally link each citation or reference to an entry in the bibliographical list <lb/>of the paper; <lb/> Citations: these are structured objects comprising a quotation from a previous <lb/>work, some possible qualifiers attached to the quotation by the author of the paper <lb/>(e.g. translation, comment, etc.), and a bibliographical reference to the work. A <lb/>highly standardized representation of citations would allow many potential <lb/>overlay applications of bibliographical items across corpora of articles; <lb/> Tables: such components may either be highly structured objects (e.g. numerical <lb/>data) or purely presentational ones, with possible embeddings. It is necessary to <lb/>adopt a clear representation policy for tables and assess whether existing schemes <lb/>(e.g. CALS 16 or XHTML 17 ) already match our needs; <lb/> Graphics and images: although they may be considered simple objects, graphics <lb/>should be treated in a way which is similar to citations, since they may also be <lb/>associated with comments and bibliographical references about the source. As is <lb/>the case with tables, existing standards such as SVG 18 provide good options here; <lb/> Mathematical equations, chemical formulae or similar formulaic content: such <lb/>information may occur either in the course of the plain text or interleaved with <lb/>paragraphs as block-level items. When not represented as a graphical object, a <lb/>formula is a highly structured object that requires specific (XML) vocabularies, <lb/>which should in no case be reinvented by text encoding schemas. For instance, <lb/>initiatives such as MathML 19 and CML 20 should be used as the basis for the <lb/>representation of mathematical or chemical content. <lb/>At this stage we need to look more deeply at two issues which, from the surface analysis <lb/>we have just conducted, clearly appear as central in the informational content of a <lb/>scholarly paper, namely bibliographical references and affiliation information. <lb/>First, we would like to make a point of the necessity of having a convergence scenario in <lb/>mind regarding the representation of bibliographic data, with the objective of ensuring <lb/></body>

			<note place="footnote">16 http://www.oasis-open.org/specs/tr9503.html <lb/></note>

			<note place="footnote">17 http://www.w3.org/TR/xhtml2/mod-tables.html <lb/></note>

			<note place="footnote">18 http://www.w3.org/TR/SVG/ <lb/></note>

			<note place="footnote">19 http://www.w3.org/Math/ <lb/></note>

			<note place="footnote">20 http://cml.sourceforge.net/ <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>maximal interoperability, but also to anticipate future workflows that will link scientific <lb/>information across publishers, publication repositories and researchers themselves. <lb/>As a matter of fact, we should see a continuum in the various bibliographical <lb/>representations that may occur within or in relation to the paper. The first source of <lb/>bibliographical data is the paper itself. The digital management of scientific articles <lb/>indeed requires that precise information related to authors, to the paper itself and to the <lb/>encompassing journal be recorded in conjunction with the management of the full text. <lb/>Such information covers aspects, which already existed in the printed world but also <lb/>information such as author ISSN, DOI or author identification numbers. Secondly, such a <lb/>metadata description can potentially be seen as the source of future bibliographic <lb/>information as present in the list of references quoted in the paper. Actually, one or the <lb/>other level of information should be linked with that available either from publishers <lb/>themselves (for instance via Crossref 21 ) or from publication archives. Finally, such <lb/>references should not be dissociated from the actual metadata associated with either <lb/>research data or, in the humanities, with the identification of primary research sources <lb/>(e.g. corpora), so that, for instance, linking from publications to data and vice versa <lb/>occurs in a homogeneous technical environment. <lb/>As a whole, even if some variation may occur from one use case to another (e.g. we may <lb/>not want systematic affiliation information within a bibliography at the end of a paper), <lb/>there is a need to design a coherent framework through which all loci of bibliographical <lb/>data are potentially expressed according to the same principles. <lb/>A second important issue, which can be seen as a side aspect of bibliographical <lb/>representation, has to do with the proper treatment of affiliations. Actually, since the early <lb/>times of scientific publishing, scholarly papers have always contained information about <lb/>the authors&apos; organisations and addresses. Initially, such information was intended to <lb/>provide means for a reader to content an author directly, but this evolved to allow for the <lb/>precise referencing of the research attribution, when for instance international rankings 22 <lb/>used this information to assess the research level of academic institutions. Such an <lb/>evolution created a tension between the necessary conciseness that is required for paper-<lb/>based affiliation schemes and the precision that is expected to provide a sound basis for <lb/>research attribution activities. <lb/>The transition to digital publishing somehow resolves the dilemma by offering a different <lb/>perspective on both the management and representation of such author-related <lb/>information. As a matter of fact, one of the underlying difficulties is that, so far, most <lb/>bibliographic or bibliometric databases have used the printed version of a paper to extract <lb/>affiliation information. Providing a born digital version of a paper with precise author-<lb/>related information permits publishers to provide a reliable source, which can then be <lb/>further consumed by information integrators. It should be noted here that publication <lb/></body>

			<note place="footnote">21 http://www.crossref.org/ <lb/></note>

			<note place="footnote">22 e.g. Shanghai ranking of Universities, see http://www.arwu.org/ <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>archives can also, when managed by academic institutions, be a reliable source for such <lb/>affiliation data. <lb/>A direct consequence of this is that digital formats for journal article archiving, as well as <lb/>for all steps in the editorial workflow, should be designed in such a way that they can <lb/>express a fine-grained representation of authors&apos; affiliations and addresses. In this respect, <lb/>it is probably a mistake to design such a format by mimicking the paper representation of <lb/>authors&apos; addresses 23 as coindexed with author reference rather than providing an <lb/>integrated representation. This is again an opportunity for convergence, where a <lb/>systematic approach to the digital representation of affiliation is aimed at in the context of <lb/>a digital journal scenario. <lb/>XML formats: what are the options? <lb/>Now that we have identified the main components of a journal paper, we can have a <lb/>closer look at the options opened to us concerning their actual digital representation. Still, <lb/>it is hardly possible to make an actual choice or even to have a global vision unless we <lb/>situate the perspective of the representation of journal content within some basic use <lb/>cases pertaining to the journal workflow, namely editing, publishing and archiving. <lb/>At the editing stage, the emphasis is basically to offer the best compromise between the <lb/>flexibility required by author in providing their manuscripts and the editorial coherence <lb/>that the journal may want to impose across all its published content. Since the <lb/>corresponding draft may not necessarily have a long lifetime, standardisation constraints <lb/>are rather low, even if great attention should be paid to processes allowing content <lb/>validation and checking (affiliation, bibliography, coherence of internal references to <lb/>figures, tables and graphics). The actual format to be used internally for this editorial <lb/>stage may also depend on the capacity to be interoperable with the various platforms and <lb/>software potentially used by authors and journal editors. <lb/>The publishing stage introduces a set of somehow reverse constraints from the editing <lb/>stage. The emphasis is indeed here to move from one reference version of the journal <lb/>paper to a multiplicity of potential presentational formats, such as the creation of a <lb/>printed version (if applicable), the production of an online distribution version (e.g. in <lb/>pdf), the setting of a (possibly reduced) consultation format in html, as well as the <lb/>generation of various output versions to feed the journal&apos;s webpages (title, author and <lb/>summary for instance), or various databases such as Crossref. This requires that the <lb/>underlying format be structured in such a way that filtering out and reorganising its <lb/>content can be fully automated and combined with a variety of layout structures. <lb/>Finally the archival stage is intended to ensure long-term reusability of the journal <lb/>content both by humans (legibility) and/or machines (processability). We should also <lb/>distinguish here between the aspects of preservation, and availability for re-use. For <lb/>instance, a PDF document is well suited to preservation, since it is likely that PDF <lb/>display and printing software will be widely available for a long time in the future, and <lb/></body>

			<note place="footnote">23 See the NLM proposal as a good example of this strategy. <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>the original print form of the document will be accurately represented through such <lb/>means. However, it is not easy to take a PDF document and re-purpose it. Text, when <lb/>extracted from a PDF, is in block-fragments (usually lines), and is organized by physical <lb/>position on the &quot;page&quot;; it has no conceptual or hierarchical structure, and cannot easily be <lb/>transformed into another kind of document. When considering what might constitute an <lb/>appropriate format for archiving, it is well to consider whether we are attempting to <lb/>archive its physical representation (in which case a series of TIFF images of the printed <lb/>pages, or a standard PDF document would presumably suffice), or its conceptual <lb/>structure and content (in which case we should be looking for a format which encodes the <lb/>hierarchical/structural organization of the document, and identifies its constituents <lb/>according to what they are rather than what they look like (e.g. a book title, rather than a <lb/>span of italicized text). <lb/>At this stage, we want to support and explore further the hypothesis that it is necessary to <lb/>work towards a back-office representation of journal papers that can seamlessly take into <lb/>consideration the constraints of the editing, publishing and archival stages. In addition, <lb/>we do think that such a format, or family of formats, should also be integrated within a <lb/>wider perspective of interoperability (whether partial or total) with, on the one hand, <lb/>other textual documents (reports, research notes, primary sources, glossaries) and, on the <lb/>other hand, with other forms of scientific outputs. The perspective adopted here is indeed <lb/>not far from the notion of datument advocated by P. Murray-Rust and H. S. Rzepa 24 . <lb/>The next stage for us is to look at the various existing formats and see how they match <lb/>the constraints identified so far. As to the current practices, textual documents are mostly <lb/>deposited in the formats that have been used for their editing or human oriented <lb/>dissemination. These fall into three main categories: <lb/> Tex/Latex-based source documents, which are used in specific scientific <lb/>communities (e.g. Mathematics, physics, computer science) and are compiled to <lb/>produce a legible Postscript or PDF output. The possibility to define specific <lb/>mechanisms through macros results in a high variation in the actual expression of <lb/>document structure and content; <lb/> Word processing proprietary files, which are dependant on the actual piece of <lb/>software and version thereof. This dependency creates an important problem as to <lb/>the long-term sustainability of the corresponding documents; <lb/> Presentational formats such as Postscript and (now mainly) PDF, which have been <lb/>designed by private companies. A specific version of PDF (PDF/A) has been <lb/>stabilized as an ISO standard 25 dedicated to the provision of a long-term archiving <lb/>format for electronic document at large. As we mentioned above, while it is likely <lb/>that software for reading, displaying and printing PDF documents will be <lb/></body>

			<listBibl>24 Peter Murray-Rust, Henry S. Rzepa, 2003, XML for scientific publishing, in OCLC Systems &amp; <lb/>Services, 19 (4), pp. 162 -169, MCB UP Ltd. <lb/></listBibl>

			<listBibl>25 ISO 19005-1:2005 Document management --Electronic document file format for long-term <lb/>preservation --Part 1: Use of PDF 1.4 (PDF/A-1) <lb/></listBibl>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>available for the foreseeable future, it is quite difficult to edit PDF documents, and <lb/>even more difficult to transform them into more conceptually-structured formats. <lb/>This situation has developed in parallel to the wide spread of the XML recommendation, <lb/>which provides a generic framework for the representation of digital objects, and which <lb/>has soon been considered (or even strongly advocated, see Murray-Rust and Rzepa, <lb/>2003) as the unavoidable basis for a long-term archival strategy of publication <lb/>documents. Arguments in favour of adopting XML can be easily summarised as follows: <lb/>it is based on a simple formalism yet offering a good expressive power (tree structures), <lb/>is straightforwardly legible, which is essential in a long term archiving perspective, and <lb/>its wide dissemination has not only yielded a wide range of generic tools, but also <lb/>specific reusable components (XLink, CALS, MathML and the like) that provide local <lb/>interoperability across applications. <lb/>As a matter of fact, once the reference to XML is made, we should immediately point out <lb/>that the stable syntactic framework it provides is not enough to guarantee full <lb/>interoperability. Beyond the syntax, it is essential to consider that one also has to share <lb/>dedicated vocabularies and the corresponding semantics. In the perspective of journal <lb/>papers, this relates to the issue of identifying how much coverage we have of the various <lb/>components that we identified earlier in this paper. <lb/>Indeed, the situation in this respect is still rather fragmented and has not led to a clear <lb/>strategy to crystallize an XML-based format for scientific publications which would be <lb/>minimally suited for long-term archival. In fact, there are currently several potential <lb/>candidate endeavours: <lb/> XML formats related to word processing platforms, mainly the OpenDocument <lb/>format (ODF; developed in the context of Open Office) and Office Open XML <lb/>(OOXML; by Microsoft), both of which have gone through an ISO <lb/>standardisation process. Their relation to editing processes and thus to the <lb/>presentation of content prevents them from being used as archival formats. In <lb/>particular they both bear a high complexity specifically linked to the nature of <lb/>word processing. <lb/> Highly specialised XML formats dedicated to scientific publishing activities, <lb/>either within specific publishing or archival initiatives (Erudit 26 ) or created in <lb/>relation to archival initiatives (DiVA). The NLM family of formats, which we <lb/>addressed previously, also falls into this category; <lb/> Generic XML formats targeted at the representation of the logical content of <lb/>textual documents. The two main relevant initiatives in this respect are DocBook <lb/>and the TEI, which both provide a rather large spectrum of encoding possibilities <lb/>while preserving a generic document structure applicable beyond the sole case of <lb/>scientific publications. <lb/></body>

			<note place="footnote">26 http://www.erudit.org/ <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>Furthermore, the TEI is organized as an international consortium, which provides a wide <lb/>base of expertise for the maintenance and improvement of the guidelines. From a <lb/>technical point of view, and beyond the more than 500 elements it already contains, the <lb/>TEI offers a framework where it is possible to design specific customisations while <lb/>remaining compliant with the guidelines as a whole. This is particular important in a <lb/>context where specific editorial projects related to certain scientific fields may need to <lb/>express their own constraints. This is also a way to avoid the necessity to design, right <lb/>from the outset, a specific format for authoring, archiving or publishing purposes. In this <lb/>context, whereas DocBook or NLM could be seen as good candidates for representing <lb/>journal content, we think the TEI offers potentially a larger, more broad-based and <lb/>generic standard than any of them. Beyond the possibility to actually share more tools <lb/>and technical settings, the TEI brings in a conceptual framework, which can be shared <lb/>with a wider community than those strictly interested in the representation of scholarly <lb/>papers. <lb/>Creating a new standard <lb/>In our discussion above, we have argued for the desirability of a single unifying journal <lb/>mark-up schema, which could be used by a majority of electronic journals, at least within <lb/>the Humanities; and we have suggested the TEI as a good candidate to form the basis of <lb/>such a schema. <lb/>The Text-Encoding Initiative 27 has been developing and documenting schemas for the <lb/>digital humanities community for more than 15 years. The current version of the TEI <lb/>schema, P5, is a complex and very sophisticated set of modules comprising many <lb/>hundreds of elements and attributes. Historically, TEI has been used primarily to create <lb/>digital encodings of existing historical texts. In recent years, however, it has increasingly <lb/>been used to create born-digital content. 28 For instance, the DHQ schemas discussed <lb/>above are actually based on TEI. As an encoding format for scholarly publications, TEI <lb/>has many advantages: <lb/> As mentioned above, it is already well-tuned for the markup of existing physical <lb/>documents, so older print articles can easily be migrated into TEI. <lb/> It has a range of modules specifically designed for addressing the needs of <lb/>humanist scholars (specialized tags for use with manuscripts, for handling obscure <lb/>languages and linguistic features, etc.). <lb/> It already integrates well with many existing standards and schemas such as SVG <lb/>(for vector graphics), MathML (for formulae etc.), W3C and ISO date formats, <lb/>XHTML (for tables), and so on. <lb/></body>

			<note place="footnote">27 http://www.tei-c.org/ <lb/></note>

			<note place="footnote">28 See, for instance, the yearly Digital Humanities conferences, organized by ADHO; conference abstracts <lb/>have been published through a TEI-based markup system since 2005. <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body> It is designed from the ground up to be customized for specific purposes, and <lb/>comes with tools for creating, documenting, publishing and using customizations. <lb/> There is a large community of existing TEI users, as well as a large base of <lb/>existing texts and projects. <lb/>We believe that creating a journal article schema framed as a TEI customization would <lb/>enable us to strike a balance between these three components: <lb/> Prescription: encouraging encoders to adopt specific practices which the <lb/>community feels are effective and appropriate. <lb/> Arbitration: selecting and endorsing one approach (or a small number of <lb/>approaches) to a specific encoding requirement, in the interests of formal <lb/>simplicity, interoperability and uniformity. <lb/> Codification: formal schematization of what encoders already actually do. <lb/>Outline of a TEI-based schema for representing journal papers <lb/>It would obviously be beyond the scope of this paper to provide a fully-fledged <lb/>description of what a TEI customization for scholarly papers could be. Still, we would <lb/>like to point to a few aspects where clear recommendations could be made, and, doing so, <lb/>demonstrate the capacity of the TEI guidelines to cover some of the core features that we <lb/>deemed essential for this textual genre. Starting with an overview of an article macro-<lb/>structure we will point out specific mechanisms, in particular in the domain of <lb/>bibliographical representation that are particularly relevant for journal paper encoding. <lb/>General structure of a TEI document <lb/>The TEI information model is intended to represent both the textual content of a <lb/>document and the metadata attached to it. This is reflected in the two main parts of a <lb/>&lt;TEI&gt; root element, namely &lt;teiHeader&gt; and &lt;text&gt;. <lb/>The TEI header is in turn organised in a series of sub-components: <lb/>-&lt;fileDesc&gt; gathering the main characteristics of the document (title, author, <lb/>bibliographic description of the source). This is the main place where metadata <lb/>information will be expressed (see below); <lb/>-&lt;profileDesc&gt; providing some information about the content. This is the place <lb/>where such information as the languages used in the text or the provision of <lb/>keywords (see example) should be situated; <lb/>-&lt;revisionDesc&gt; providing the history of the document. In the context of an <lb/>editorial workflow, this should be used to trace the history of the paper <lb/>(submission, review, revision, publication). <lb/></body>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>The &lt;text&gt; element is further decomposed into &lt;front&gt;, &lt;body&gt; and &lt;back&gt;. When <lb/>available, abstracts are represented in &lt;front&gt; and full-text content in subsequent <lb/>elements. <lb/>Skeleton of a full TEI document <lb/>We present below a model structure of a TEI document as we would see it relevant for <lb/>the representation of a journal paper. Such a skeleton already reflects a few issues where <lb/>specific implementation choices have been made, namely: <lb/> The use of &lt;biblStruct&gt; in &lt;sourceDesc&gt; as the sole structure to represent <lb/>bibliographic data attached to the paper; <lb/> The duplication of the article title in &lt;titleStmt&gt; to facilitate interoperability with <lb/>other types of TEI documents when put together, for instance, within a digital <lb/>object management system; <lb/> The insertion of copyright information in &lt;publicationStmt&gt;; <lb/> The representation formats for keywords attached to the paper; <lb/> The use of &lt;revisionDesc&gt; for tracing the editorial stages of the paper. <lb/>&lt;TEI xmlns=&quot;http://www.tei-c.org/ns/1.0&quot;&gt; <lb/>&lt;teiHeader&gt; <lb/>&lt;fileDesc&gt; <lb/>&lt;titleStmt&gt; <lb/>&lt;title level=&quot;a&quot; type=&quot;main&quot;&gt;...&lt;/title&gt; <lb/>&lt;/titleStmt&gt; <lb/>&lt;publicationStmt&gt; <lb/>&lt;availability&gt; <lb/>&lt;p&gt;Copyright © The Animal Consortium 2009&lt;/p&gt; <lb/>&lt;/availability&gt; <lb/>&lt;date&gt;2009&lt;/date&gt; <lb/>&lt;authority&gt;The Animal Consortium&lt;/authority&gt; <lb/>&lt;/publicationStmt&gt; <lb/>&lt;sourceDesc&gt; <lb/>&lt;biblStruct&gt;...&lt;/biblStruct&gt; <lb/>&lt;/sourceDesc&gt; <lb/>&lt;/fileDesc&gt; <lb/>&lt;profileDesc&gt; <lb/>&lt;textClass&gt; <lb/>&lt;keywords&gt; <lb/>&lt;list&gt; <lb/>&lt;head&gt;Keywords&lt;/head&gt; <lb/>&lt;item&gt; <lb/>&lt;term&gt;foetal development&lt;/term&gt; <lb/>&lt;/item&gt; <lb/>&lt;item&gt; <lb/>... <lb/>&lt;/item&gt; <lb/>&lt;/list&gt; <lb/>&lt;/keywords&gt; <lb/>&lt;/textClass&gt; <lb/>&lt;/profileDesc&gt; <lb/>&lt;revisionDesc&gt; <lb/>&lt;change when=&quot;2008-08-27&quot;&gt;Received&lt;/change&gt; <lb/>&lt;change when=&quot;2008-12-01&quot;&gt;Accepted&lt;/change&gt; <lb/>&lt;/revisionDesc&gt; <lb/></body>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>&lt;/teiHeader&gt; <lb/>&lt;text&gt; <lb/>&lt;front&gt; <lb/>&lt;div type=&quot;abstract&quot;&gt; <lb/>&lt;head&gt;Abstract&lt;/head&gt; <lb/>&lt;p&gt;...&lt;/p&gt; <lb/>&lt;/div&gt; <lb/>&lt;/front&gt; <lb/>&lt;body/&gt; <lb/>&lt;back/&gt; <lb/>&lt;/text&gt; <lb/>&lt;/TEI&gt; <lb/>Representation of bibliographical information <lb/>As stated earlier, the representation is based on the TEI &lt;biblStruct&gt; element, which is <lb/>organised as follows: <lb/>&lt;biblStruct type=&quot;article&quot;&gt; <lb/>&lt;analytic&gt; <lb/>… <lb/>&lt;/analytic&gt; <lb/>&lt;monogr&gt; <lb/>… <lb/>&lt;imprint&gt; <lb/>… <lb/>&lt;/imprint&gt; <lb/>&lt;/monogr&gt; <lb/>… <lb/>&lt;/biblStruct&gt; <lb/>A &lt;biblStruct&gt; is mainly divided into two sub-structures: <lb/> &lt;analytic&gt; indicates the bibliographical characteristics of an article (title and <lb/>authors); <lb/> &lt;monogr&gt; accounts for the publication details of the journal (journal name, <lb/>publisher information, issn, etc.), and contains in turn a &lt;imprint&gt; element <lb/>which gathers publication and/or distribution aspects of the article in the <lb/>corresponding journal (pagination, volume, issue, etc.); <lb/> When applicable, additional notes or identifiers can follow, for instance, the DOI, <lb/>PubMed Central id or repository-specific id will appear here: <lb/>&lt;biblStruct type=&quot;article&quot;&gt; <lb/>&lt;analytic&gt;…&lt;/analytic&gt; <lb/>&lt;monogr&gt;…&lt;/monogr&gt; <lb/>&lt;idno type=&quot;pmid&quot;&gt;12345678&lt;/idno&gt; <lb/>&lt;/biblStruct&gt; <lb/>The &lt;analytic&gt; element <lb/>The title of a journal article is represented by means of the &lt;title&gt; element (with <lb/>appropriate @level attribute) as follows: <lb/>&lt;title level=&quot;a&quot;&gt;Multilocus Analysis of Age Related Macular <lb/>Degeneration&lt;/title&gt; <lb/>hal-00390966, version 1 -3 Jun 2009 <lb/>When necessary a further @type attribute may be used to differentiate between main and <lb/>subtitles (@type=&quot;main&quot; vs. @type=&quot;subordinate&quot;), as well as specific titles such as <lb/>recto and verso running titles (at publication stage). <lb/>Each author in the &lt;analytic&gt; element is independently described by means of an <lb/>&lt;author&gt; element. This element contains the author&apos;s name, affiliation and addresses − <lb/>when available − together with some possible generic author identifiers 29 as presented in <lb/>the outline below: <lb/>&lt;author&gt; <lb/>&lt;idno type=&quot;...&quot;&gt;...&lt;/idno&gt; <lb/>&lt;persName&gt; <lb/>&lt;forename&gt;Michael&lt;/forename&gt; <lb/>&lt;surname&gt;Dean&lt;/surname&gt; <lb/>&lt;/persName&gt; <lb/>&lt;affiliation&gt;…&lt;/affiliation&gt; <lb/>&lt;email&gt;dean@ncifcrf.gov&lt;/email&gt; <lb/>&lt;/author&gt; <lb/>The &lt;affiliation&gt; component of &lt;author&gt; is intended to contain any potentially relevant <lb/>information with regard to the author&apos;s academic situation: research group, laboratory, <lb/>institution. <lb/>&lt;affiliation&gt; <lb/>&lt;orgName type=&quot;laboratory&quot;&gt;CSA Department&lt;/orgName&gt; <lb/>&lt;orgName type=&quot;institution&quot;&gt;Indian Institute of Science&lt;/orgName&gt; <lb/>&lt;address&gt; <lb/>&lt;settlement&gt;Bangalore&lt;/settlement&gt; <lb/>&lt;postCode&gt;560012&lt;/postCode&gt; <lb/>&lt;country&gt;India&lt;/country&gt; <lb/>&lt;addrLine type=&quot;phone&quot;&gt;+91-80-22932386&lt;/addrLine&gt; <lb/>&lt;addrLine type=&quot;fax&quot;&gt;+91-80-23602911&lt;/addrLine&gt; <lb/>&lt;/address&gt; <lb/>&lt;/affiliation&gt; <lb/>Such a representation provides a clear way of identifying, in a standardized manner the <lb/>various organisational levels to which a research may be affiliated. Further <lb/>standardisation would typically include defining precisely the permitted values of the <lb/>@type attribute on &lt;orgName&gt;, at least in the context of contextual (regional) research <lb/>organistion schemes, or in relation to classification scheme adopted by major vendors <lb/>such as Thomson scientific with the Web of Science. <lb/>The &lt;monogr&gt; element <lb/>The &lt;monogr&gt; element gathers journal identification information (journal title and ISSN <lb/>together with the publishing information contained in its &lt;imprint&gt; sub-element). For <lb/>instance: <lb/>&lt;monogr&gt; <lb/>&lt;title level=&quot;j&quot; type=&quot;main&quot;&gt;European Journal of Human <lb/>Genetics&lt;/title&gt; <lb/>&lt;title level=&quot;j&quot; type=&quot;nlm-ta&quot;&gt;Eur J Hum Genet&lt;/title&gt; <lb/>&lt;idno type=&quot;ISSN&quot;&gt;1018-4813&lt;/idno&gt; <lb/>&lt;imprint&gt;…&lt;/imprint&gt; <lb/></body>

			<listBibl>29 Cals, J. W. L. and Kotz, D. (2008), &apos;Researcher identification: the right needle in the haystack&apos;, The <lb/>Lancet, 371 (9631), 2152-53. <lb/></listBibl>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>&lt;/monogr&gt; <lb/>The &lt;imprint&gt; element <lb/>&quot;By imprint is meant all the information relating to the publication of a work: the person <lb/>or organization by whose authority and in whose name a bibliographic entity such as a <lb/>book is made public or distributed (whether a commercial publisher or some other <lb/>organization), the place of publication, and a date. It may also include a full address for <lb/>the publisher or organization. Full bibliographic references usually specify either the <lb/>number of pages in a print publication (or equivalent information for non-print materials), <lb/>or the specific location of the material being cited within its containing publication.&quot; 30 <lb/>The &lt;imprint&gt; element is organised as follows: <lb/>&lt;imprint&gt; <lb/>&lt;pubPlace&gt;Oxford&lt;/pubPlace&gt; <lb/>&lt;publisher&gt;Clarendon Press&lt;/publisher&gt; <lb/>&lt;date typ=&quot;published&quot; when=&quot;1969-02-07&quot;/&gt; <lb/>&lt;biblScope type=&quot;vol&quot;&gt;3&lt;/biblScope&gt; <lb/>&lt;biblScope type=&quot;issue&quot;&gt;2&lt;/biblScope&gt; <lb/>&lt;/imprint&gt; <lb/>The possible values for the attribute @type on &lt;biblScope&gt; are the following: <lb/> vol: volume <lb/> issue: issue <lb/> fpage: first page <lb/> lpage: last page <lb/> pp: number of pages when the information about full pagination is not available 31 <lb/>&lt;biblStruct&gt; skeleton <lb/>The following example provides an overview of the full internal structure of the <lb/>&lt;biblStruct&gt; element as suggested for the standard representation of bibliographical <lb/>information attached to a journal paper: <lb/>&lt;biblStruct type=&quot;article&quot;&gt; <lb/>&lt;analytic&gt; <lb/>&lt;title level=&quot;a&quot; type=&quot;main&quot;&gt;…&lt;/title&gt; <lb/>&lt;author type=&quot;corresp&quot;&gt; <lb/>&lt;persName&gt; <lb/>&lt;forename&gt;…&lt;/forename&gt; <lb/>&lt;surname&gt;…&lt;/surname&gt; <lb/>&lt;/persName&gt; <lb/>&lt;affiliation&gt; <lb/>&lt;orgName type=&quot;&quot;&gt;…&lt;/orgName&gt; <lb/>&lt;address&gt;…&lt;country&gt;FR&lt;/country&gt;&lt;/address&gt; <lb/>&lt;/affiliation&gt; <lb/></body>

			<note place="footnote">30 http://www.tei-c.org/release/doc/tei-p5-doc/en/html/CO.html#COBICOI <lb/></note>

			<note place="footnote">31 We restrict here the semantics of the recommended value (cf. http://www.tei-c.org/release/doc/tei-p5-doc/html/ref-<lb/>biblScope.html) <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>&lt;email&gt;…&lt;/email&gt; <lb/>&lt;/author&gt; <lb/>&lt;/analytic&gt; <lb/>&lt;monogr&gt; <lb/>&lt;title level=&quot;j&quot; type=&quot;main&quot;&gt;…&lt;/title&gt; <lb/>&lt;idno type=&quot;ISSN&quot;&gt;…&lt;/idno&gt; <lb/>&lt;imprint&gt; <lb/>&lt;publisher&gt;…&lt;/publisher&gt; <lb/>&lt;pubPlace&gt;…&lt;/pubPlace&gt; <lb/>&lt;date when=&quot;2009-02-03&quot;/&gt; <lb/>&lt;biblScope type=&quot;fpage&quot;&gt;…&lt;/biblScope&gt; <lb/>&lt;/imprint&gt; <lb/>&lt;/monogr&gt; <lb/>&lt;idno type=&quot;DOI&quot;&gt;…&lt;/idno&gt; <lb/>&lt;/biblStruct&gt; <lb/>Consequences for article micro-structure <lb/>As can easily be seen, the bibliographical format presented above is generic enough to <lb/>cover all needs for structuring inline bibliographical references. Basically, this would <lb/>correspond to exactly the same structure with possible simplifications regarding author <lb/>affiliation. As elucidated in the TEI guidelines, the &lt;biblStruct&gt; element actually covers a <lb/>wide range of bibliographical types ranging from conference papers to books and can <lb/>impact at two major places within a journal paper: <lb/>a. In the list of bibliographical references of a paper, which can be very uniformly <lb/>represented as a &lt;listBibl&gt; of &lt;biblStruct&gt;s; <lb/>b. In inline citation, for which the TEI typically offer a generic construct outlined in <lb/>the following example where one can see how precise bibliographic reference can <lb/>be association with the quoted text: <lb/>&lt;cit&gt; <lb/>&lt;quote&gt;Wer A sagt, der muß nicht B sagen. Er kann auch erkennen, <lb/>daß A falsch war&lt;/quote&gt; <lb/>&lt;biblStruct&gt; <lb/>&lt;monogr&gt; <lb/>&lt;author&gt; <lb/>&lt;persName&gt; <lb/>&lt;forename&gt;Bertolt&lt;/forename&gt; <lb/>&lt;surname&gt;Brecht&lt;/surname&gt; <lb/>&lt;/persName&gt; <lb/>&lt;/author&gt; <lb/>&lt;title&gt;Der Jasager und der Neinsager -Vorlagen, Fassungen und <lb/>Materialien&lt;/title&gt; <lb/>&lt;imprint&gt; <lb/>&lt;publisher&gt;Edition Suhrkamp&lt;/publisher&gt; <lb/>&lt;date type=&quot;Published&quot; when=&quot;1981&quot;/&gt; <lb/>&lt;/imprint&gt; <lb/>&lt;/monogr&gt; <lb/>&lt;idno type=&quot;ISBN&quot;&gt;9783518101711&lt;/idno&gt; <lb/>&lt;/biblStruct&gt; <lb/>&lt;/cit&gt; <lb/>Without going any further here in the precise description of TEI mechanisms, we hope <lb/>we have made it clear how the TEI guidelines could match the needs of scholarly <lb/>publishing by providing generic mechanisms which can in turn be tuned (probably with <lb/>additional recommendations) for journal papers. The next step for us is to identify how to <lb/>articulate these facilities with the actual design of a journal publishing workflow. <lb/></body>

			<note place="footnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>Approaches to creating a TEI-based schema <lb/>In the sections above, we have given some suggestions as to how an ideal schema for <lb/>journal markup could be based on TEI. We might call such a schema &quot;teiJournal&quot;. Most <lb/>likely, this would be a stripped-down form of TEI, meaning that customization would <lb/>consist only of the application of constraints: in other words, a teiJournal document <lb/>would be fully TEI-compliant (meaning that it would validate under the &quot;full&quot; tei_all <lb/>schema which incorporates all the available modules in TEI). There is considerable value <lb/>in this; a fully TEI-compliant schema provides instant interoperability with any system <lb/>that understands TEI. At the same time, the requirements of a journal schema are <lb/>considerably restricted compared with the huge range of needs that the TEI itself attempts <lb/>to answer. For instance, since a journal schema would be used primarily to encode born-<lb/>digital documents, it might not require many of the TEI elements and attributes related to <lb/>(for instance) manuscript description, or &quot;certainty and responsibility&quot;. At the same time, <lb/>we would expect that a teiJournal schema would be more prescriptive than the general <lb/>TEI Guidelines with regard to certain specific encoding problems. For instance, most <lb/>journal articles include some kind of sources list or bibliography, and it would be a <lb/>primary requirement of any processing engine that such a list be rendered into a highly <lb/>formalized output format, conforming to the prescriptions of a style guide such as MLA, <lb/>APA or Chicago. In order to do this, a highly-structured markup format would be <lb/>required, and we have argued that the TEI &lt;biblStruct&gt; element would be most <lb/>appropriate for this task, so the looser &lt;bibl&gt; and &lt;biblFull&gt; elements which TEI also <lb/>provides for different usage scenarios could be discarded from the schema in the interests <lb/>of simplicity. <lb/>At this point, we will look at a primary requirement of any journal publishing engine: to <lb/>render different types of document in different ways, as prescribed by the various style <lb/>guides in use in the academic publishing realm. For instance, when rendering the content <lb/>of an article&apos;s bibliography in XHTML or PDF for the end user, journal titles may have to <lb/>be italicized, while article titles should appear in quotation marks. From our previous <lb/>work designing applications to render bibliographical lists like this 32 , we have identified <lb/>at least 60 different types of document 33 which may need to be handled in different or <lb/>idiosyncratic ways by a rendering system in order to comply with the differing <lb/>requirements of the various style guides. A natural way to distinguish different types of <lb/>document would be to use the @type attribute on the &lt;biblStruct&gt; tag: <lb/>&lt;biblStruct type=&quot;book&quot;&gt;...&lt;/biblStruct&gt; <lb/>&lt;biblStruct type=&quot;journalArticle&quot;&gt;...&lt;/biblStruct&gt; <lb/>The TEI Guidelines say that @type &quot;characterizes the element in some sense, using any <lb/>convenient classification scheme or typology,&quot; and its type is data.enumerated; <lb/>&quot;Typically, the list of documented possibilities will be provided (or exemplified) by a <lb/></body>

			<note place="footnote">32 The Scandinavian Canadian Studies journal, and the IALLT Journal, among other similar projects. <lb/></note>

			<note place="footnote">33 A preliminary list can be seen here: <lb/>http://www.tapor.uvic.ca/~mholmes/teiJournal/bibliographical_markup.htm#N10071 <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>value list in the associated attribute specification, expressed with a valList element.&quot; The <lb/>problem then is generating this value list, and typically this would involve a process of <lb/>trying to predict every possible required value, and negotiate an agreement on the exact <lb/>form of each. Any attempt to create a standard will inevitably expend a great deal of time <lb/>and effort on devising and refining feature lists such as this, and the results are rarely <lb/>completely satisfactory; no sooner is a standard released than real-world users discover <lb/>needs that the standard cannot yet accommodate. <lb/>However, a recent contribution to the TEI toolset by Sebastian Rahtz has opened the way <lb/>to a new approach we might take to solving problems like this. Rahtz has released an <lb/>XSLT transformation called &quot;oddbyexample.xsl&quot; which is designed to &quot;read a corpus of <lb/>TEI P5 documents and construct an ODD customization file which expresses the subset <lb/>of the TEI you need to validate that corpus.&quot; 34 (An ODD file is an XML file which <lb/>expresses the details of a TEI customization: which elements and attributes from the <lb/>overall TEI system are included and excluded from the schema, and what their values and <lb/>behaviour might be.) This tool has the potential to allow rapid generation of restricted <lb/>TEI schemas based on a corpus of documents -essentially an approach based entirely <lb/>on &quot;codification&quot; as defined above. Using oddbyexample.xsl, we can generate a &quot;tight&quot; <lb/>schema from a collection of documents, and then validate new documents against that <lb/>schema. We can now consider a much more bottom-up, community-based approach to <lb/>the generation of a teiJournal schema, which might work like this: <lb/>1. A group of users concerned with using TEI to encode journal articles agree to <lb/>work initially with a large TEI schema --perhaps even tei_all, but most likely a <lb/>version with some irrelevant modules removed. <lb/>2. They agree on some basic rules (overall document structure, use of &lt;biblStruct&gt;, <lb/>etc.). <lb/>3. They begin encoding. Each completed document is submitted to a central corpus. <lb/>4. At a certain point, oddbyexample.xsl (or something similar) is run against the <lb/>corpus, generating a very stripped-down schema. At this point, all completed <lb/>documents will validate against this schema; it represents the range of what <lb/>encoders are actually doing. <lb/>5. The community can examine this schema, and look specifically for places where <lb/>more than one competing approach is being taken to the same encoding issue. To <lb/>take a trivial instance, perhaps some people are using &lt;hi rend=&quot;italic&quot;&gt; and <lb/>others are using &lt;hi rend=&quot;italics&quot;&gt;, because the content of the @rend attribute is <lb/>not restricted in the standard TEI schema. The new, generated schema will <lb/>provide an enumeration as the content of @rend, but that enumeration will be <lb/>based on what has been used, so both &quot;italic&quot; and &quot;italics&quot; will be permitted; this <lb/>is clearly not a desirable situation. A decision can be made to standardize on one <lb/>of these, or on something else (perhaps &lt;hi rend=&quot;font-style: italic;&quot;&gt;). Then all <lb/></body>

			<note place="footnote">34 Comment inside the oddbyexample.xsl file, available from <lb/>http://tei.svn.sourceforge.net/viewvc/tei/trunk/Stylesheets2/tools2/ <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>existing documents are converted to use the standard format, and a new schema is <lb/>generated using oddbyexample. <lb/>6. All future encoding proceeds based on the new, restricted schema. Then, when a <lb/>novel need arises -someone needs to encode something which is not handled by <lb/>the schema -they can simply switch back to the original TEI schema, and use <lb/>elements and attributes from the larger set. <lb/>7. Periodically, oddbyexample is run on the corpus again. Any elements and <lb/>attributes from the larger set which have been incorporated in new documents will <lb/>now find their way into the restricted schema, which grows a little based on need. <lb/>Over two or three years, assuming enough encoders and projects are involved with this <lb/>project, a tight but powerful schema should emerge from a process like this. In addition, <lb/>the work itself is less time-consuming and stressful than a traditional working-group <lb/>approach, since the schema emerges naturally over time, and encoders are able to proceed <lb/>with their projects throughout. The only minimal disruption would be the occasional <lb/>necessity to transform existing documents whenever &quot;arbitration&quot; takes place to select <lb/>one approach out of several that are in use. XSLT should be able to handle most such <lb/>cases. <lb/>Once again, we can see how, with its built-in support for schema customization, TEI is <lb/>particularly suited to schema-development that proceeds in such an &quot;evolutionary&quot; <lb/>manner, because TEI has such a wide range of existing elements, attributes and encoding <lb/>strategies from which the process can draw whenever there is a need to handle a new <lb/>feature. <lb/>Pros and cons of using distinct flavours of the schema for <lb/>authoring and publication. <lb/>One question that should be addressed is the issue of distinct schema variants for <lb/>different purposes. It is notable that both DHQ and NLM have one schema for authoring, <lb/>and one for publishing. It is worth quoting at length from the explanation on the NLM <lb/>website explaining how the authoring schema differs from the publishing schema: <lb/>The Article Authoring Tag Set creates a standardized format for new journal articles that can be <lb/>used by authors to submit publications to journals and to archives such as PubMed Central. While <lb/>in theory the document scope is the same as for the Publishing Tag Set, in practice Authoring <lb/>defines elements and attributes that describe the content of typical research-style journal articles. <lb/>This is a Tag Set optimized for authorship of new journal articles, where regularization and control <lb/>of content is important, and where it is useful rather than harmful to have only one way to tag a <lb/>structure. Therefore Authoring is more prescriptive than descriptive and includes many elements <lb/>whose content must occur in a specified order. <lb/>Since an author is assumed to be creating and submitting an article for submission to a journal or <lb/>journals, no publishing history or journal-specific information has been included in this Authoring <lb/>Tag Set. <lb/></body>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>Since no assumptions can be made concerning the processing software or editorial situation that <lb/>will receive an article authored in this Tag Set, tagging that forces specific formatting has also <lb/>been avoided. There is no way for an author to number his/her lists explicitly, for example, or to <lb/>manually number the cited references, since many journals have their own citation policies and <lb/>publication styles. Numbers for the cited references must be generated by the publisher&apos;s software <lb/>to match editorial policy and established practice. 35 <lb/>In fact, in practical terms, the differences are of minor importance; in the case of the three <lb/>example marked-up documents provided on the NLM website as part of the tagset <lb/>documentation (two &quot;publishing&quot; and one &quot;authoring&quot;), all three validate under both <lb/>schemas. In an additional test, we took nine sample documents converted from a TEI <lb/>schema to the NLM publishing tagset as part of another project, and successfully <lb/>validated all nine under both the publishing and authoring schemas. The case of DHQ <lb/>seems to be very similar; the documentation for the DHQpublish schema suggests that <lb/>the only difference is that &quot;the DHQheader element is required, and contains a superset of <lb/>the elements allowed in the DHQauthor header.&quot; 36 Also, the sample DHQ-<lb/>MonkeyHouse.xml document provided for users of the DHQ schemas also validates <lb/>under both schemas, with the sole exception of a missing &lt;publicationStmt&gt; element in <lb/>the header, and this turns out to be in the document, but commented out; when included, <lb/>the document validates under the publication schema but not the authoring schema, and <lb/>when excluded, vice versa. DHQ does complicate the process a little more, actually, by <lb/>the provision of two root tags for authoring: <lb/>The document element or &quot;root element&quot; of a DHQauthor document will be either DHQdraft or <lb/>DHQarticle. The only difference between them is that in DHQdraft, the DHQheader element is <lb/>optional. You can encode your article using the DHQdraft element to begin with, but all articles <lb/>submitted to DHQ must use the DHQarticle structure and must include a DHQheader. 37 <lb/>Frankly, this seems like unnecessary complexity, since even if the author starts off using <lb/>DHQdraft, the document will have to be converted to DHQarticle before submission <lb/>anyway. <lb/>So the distinction between authoring and publishing schemas is apparently trivial, and <lb/>appears to be an attempt to be kind to authors, avoiding distracting them from their work <lb/>by intruding aspects of publication formatting and metadata into their authoring process. <lb/>However, we have already noted the tendency for authors writing for modern online <lb/>journals to be more involved in the markup and layout process; 38 in a sense, many authors <lb/>are now full participants in the construction of the published artefact. They will imagine <lb/>their contributions in publication form, and proof them in something approaching it. So <lb/>why remove publication-related markup features from their schema? Editors may surely <lb/>35 http://dtd.nlm.nih.gov/articleauthoring/ <lb/>36 (DHQpublish RelaxNG schema, version &quot;beta&quot;, October 2007) <lb/>37 http://digitalhumanities.org/view/DHquarterly/TagLibrary <lb/>38 See Blesius et al, 2005, and also the editorial process of the Scandinavian Canadian Studies Journal, <lb/>discussed above, in which authors proof their documents through the publication engine, seeing them in <lb/>the exact form they will appear when published. <lb/></body>

			<note place="footnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>edit markup just as easily as text, and the final decision on all aspects of an article lies <lb/>with the editor, but there is no reason to prevent an author from contributing to the <lb/>creation of publication metadata, layout decisions, and other aspects of markup currently <lb/>reserved for the publication schema. <lb/>Another distinction maintained by NLM is that between new, straight-to-NLM content, <lb/>and documents intended for archiving and interchange. The Archiving and Interchange <lb/>tagset &quot;enables an archive to capture structural and semantic components of existing <lb/>material without modeling any particular sequence or textual format&quot; <lb/>(http://dtd.nlm.nih.gov/archiving/). This aim is, on the face of it, similar to some aspects <lb/>of the TEI&apos;s purpose: to preserve in digital form material which was originally created in <lb/>print or some other analogue format. (However, the TEI of course goes further, allowing <lb/>for as much descriptive information as possible about the original document to be <lb/>captured along with its structure and semantics.). For such a markup schema, there is no <lb/>particular inherent output target or intended processing engine. This aim is largely <lb/>irrelevant to the current discussion, because it is essentially preservative, while markup <lb/>for born-digital publication is essentially original and creative. Also, in the case of <lb/>digitizing old content or converting other formats for archive, we are no longer <lb/>interacting with the content and changing it. Modern online journals, by contrast, appear <lb/>to be evolving in the direction of greater involvement on the part of a larger number of <lb/>interested parties -authors, editors, readers, reviewers, collaborators, commenters -all <lb/>of whom potentially affect the evolution of a published piece. However, it is worth noting <lb/>that the TEI&apos;s origins and primary function make it peculiarly suited to the digitization of <lb/>existing print content, and it would be perfectly practical to mark up a historical article <lb/>using TEI such that it would conform to a teiJournal schema (and thus be manageable by <lb/>a publication content engine), while at the same time including all the descriptive <lb/>information that a traditional digitization project would wish to record about a historical <lb/>document. The TEI can perform both functions simultaneously. <lb/>It seems, then, that we should be able to settle on one schema for born-digital content, <lb/>and stick to it, rather than elaborating the system with variants for authoring, editing, <lb/>archiving and so on. If we have the desire to avoid distracting authors by the inclusion of <lb/>editorial publication features in a schema they will use, then we can certainly create a <lb/>more stripped-down variant, supply default placeholder values in a skeleton document, or <lb/>use some similar mechanism to achieve the same aim. After all, an authoring schema that <lb/>produces only documents which validate under the publication schema -which is <lb/>simply a subset of the publishing schema -is arguably not really a different schema at <lb/>all. Whether it makes sense to do this at all is another question. In the case of the DHQ <lb/>schema, for instance, is it really that distracting for the author to encounter the need for a <lb/>publicationStmt tag: <lb/>&lt;publicationStmt&gt; <lb/>&lt;idno type=&quot;DHQarticle-id&quot;&gt;001&lt;/idno&gt; <lb/>&lt;idno type=&quot;volume&quot;&gt;1&lt;/idno&gt; <lb/>&lt;idno type=&quot;issue&quot;&gt;1&lt;/idno&gt; <lb/>&lt;issueTitle&gt;Summer 2008&lt;/issueTitle&gt; <lb/>&lt;articleType&gt;article&lt;/articleType&gt; <lb/>&lt;date when=&quot;2008-07&quot;&gt;July 2008&lt;/date&gt; <lb/>&lt;availability&gt; <lb/></body>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>&lt;cc:License rdf:about=&quot;http://creativecommons.org/licenses/by-nc-<lb/>nd/2.5/&quot;/&gt; <lb/>&lt;/availability&gt; <lb/>&lt;/publicationStmt&gt; 39 <lb/>and have to supply some default values? It&apos;s certainly no bad thing to be reminded that <lb/>your article will be released under such-and-such a Creative Commons licence, and it&apos;s <lb/>hardly confusing to know that it will eventually have a volume and issue number, and a <lb/>publication date. <lb/>Implementing a publication engine <lb/>Given the choice of XML as an encoding format, a wide range of tools for storage, <lb/>retrieval and delivery of content are available. For a back-end storage engine, it could be <lb/>said that almost anything will do, since XML is &quot;text&quot; and can be queried through any <lb/>traditional text query engine. However, as we have seen, among the great strengths of <lb/>XML are its hierarchical structure and conceptual tagging, and a good publication engine <lb/>should be able to take advantage of these features, both for querying and searching, and <lb/>for delivery of the content in a variety of different forms. XQuery (XML Query <lb/>Language) is the natural way to do this; it was designed specifically for precise searching, <lb/>extraction and restructuring of XML data. Increasing numbers of conventional relational <lb/>database engines, including Oracle and Microsoft SQL Server, and are now adding <lb/>support for XML through implementation of interfaces based on XQuery. Another class <lb/>of database includes &quot;pure&quot; XML databases such as the open-source eXist, 40 in which <lb/>data is stored not in a set of two-dimensional tables with rows and columns, but in a <lb/>&quot;collection&quot;, which consists of nested subcollections of documents, together constituting <lb/>a single XML hierarchy, with an index of every single tag and attribute in the hierarchy. <lb/>Once data is extracted through XQuery -whether a complete document, a small fragment <lb/>of a document, or a collection of related fragments from across the collection -it must be <lb/>formatted for delivery to the end-user. XML itself is not really an end-user format; <lb/>although it can be quite attractively styled with the direct application of CSS, such a <lb/>simple delivery mechanism is unlikely to be full-featured enough, since it will lack <lb/>features such as hyperlinking and interactivity. More commonly, the content will be <lb/>transformed, through the use of XSLT, another XML standard language, whose purpose is <lb/>to convert XML structures into other types of output. Typical output targets will be <lb/>XHTML (for display in a browser), PDF (for printing, or display in an eBook reader), <lb/>and perhaps also plain text (for input into text analysis engines, or for a Project <lb/>Gutenberg-style electronic text). Production of a PDF is typically a two-stage process, in <lb/>which the initial XSLT transformation creates an XSL:FO document, which is then <lb/>transformed by a PDF generator engine such as XEP 41 or FOP 42 into a PDF or PostScript <lb/>document. <lb/></body>

			<note place="footnote">39 DHQ-MonkeyHouse.xml sample document, <lb/>http://digitalhumanities.org/twiki/pub/DHquarterly/DownloadCentral/DHQ-MonkeyHouse.xml <lb/></note>

			<note place="footnote">40 eXist Open Source Native XML Database, http://exist-db.org/ <lb/></note>

			<note place="footnote">41 http://www.renderx.com/tools/xep.html <lb/></note>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>The diagram in Illustration 1 demonstrates the process described above as it is <lb/>implemented in the case of the Scandinavian Canadian Studies journal 43 . On the journal <lb/>web site, XHTML, plain text, PDF and XML versions of the journal articles are <lb/>available, all generated on-the-fly from the XML database; the list of contributors with <lb/>their biographies is also generated from the XML collection, and the search system <lb/>queries the same system to retrieve document fragments as &quot;hits&quot;. The print version of <lb/>each issue of the journal is generated from the same XML source documents via a more <lb/>complex XSLT-to-XSL:FO-to-PDF transformation which automatically generates the <lb/>Table of Contents, indexes, page numbering and so on, with the final stage being <lb/>accomplished by the commercial XEP engine (although open-source PDF generators <lb/>such as FOP are available too). <lb/>This is the solution to the dilemma posed by Thom Lieb in his 1999 article &quot;Q. A.: <lb/>HTML, PDF and TXT: The Format Wars&quot;. 44 Lieb&apos;s brief article concludes thus: &quot;The <lb/></body>

			<note place="footnote">42 http://www.renderx.com/tools/xep.html <lb/></note>

			<note place="footnote">43 http://scancan.net/ <lb/></note>

			<listBibl>44 Thom Lieb: &quot;Q. A.: HTML, PDF and TXT: The Format Wars.&quot; The Journal of Electronic Publishing. <lb/>Vol. 5, no. 1, Sept., 1999. http://quod.lib.umich.edu/cgi/t/text/text-<lb/>idx?c=jep;cc=jep;q1=xml;rgn=main;view=text;idno=3336451.0005.108 <lb/>Illustration 1: The publication engine of the Scandinavian Canadian <lb/>Studies journal <lb/></listBibl>

			<note place="headnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>ideal for many online publications would be a combination of all three: a plain-text e-<lb/>mail alert, an HTML version for fast loading and online reading, and a downloadable <lb/>PDF version for offline reading.&quot; We can now provide all three from the same source. <lb/>Among the many advantages of a system like this are these: <lb/> As new export formats come along, new output paths can easily be added to the <lb/>system, generating new document types from the same source. Transient Web <lb/>format-fashions can easily be added to the system -creating an RSS feed of titles <lb/>and abstracts of articles as they are published, or Twitter &quot;tweets&quot; announcing <lb/>new articles would be simple tasks, and such features can be turned off when their <lb/>moment has passed. <lb/> If it becomes necessary, the whole document collection can be migrated (via <lb/>XSLT) to another format/schema, and inserted into a different publication engine. <lb/> If it is desirable to serve this content through a system such as an older OJS <lb/>install, which requires a static file in (for instance) PDF format for each article, <lb/>the PDF output from the XML-based system can simply be injected into the other <lb/>engine. <lb/> Authorial and editorial practices, as well as compliance with a styleguide, will be <lb/>built into the system at the level of the XQuery and XSLT operations, so changes <lb/>to these systems can be made in a single centralized location, and immediately <lb/>apply to all the articles in the system. For instance, if the editorial board decides <lb/>to change the journal styleguide from APA to Chicago, the documents themselves <lb/>will not need to be changed; only the output transformations will need to be <lb/>revised. In a system in which documents are stored in a static format such as MS <lb/>Word, such a change would require re-editing of all the existing journal articles. <lb/> The collection can be treated as a single composite source document, so for <lb/>example a unified bibliography can be compiled automatically from all the <lb/>references in all the documents. This has obvious scholarly value. <lb/> The nature of XML tagging in a schema such as TEI allows for highly <lb/>sophisticated search systems which target specific tags at particular locations in <lb/>the hierarchy. For example, you could limit a query so that it searches only inside <lb/>the names of individuals, or the names of organizations; or you could search for <lb/>all the documents published within a particular date range whose bibliographies <lb/>list works by one specific author. <lb/>Conclusion <lb/>In this article, we have argued that there is a strong need for a single standard format for <lb/>scholarly and scientific articles, and that current &quot;archive&quot; formats such as PDF and DOC <lb/>are unsuitable for this purpose; XML is a better option. We have further proposed that, <lb/>despite the fact that at least two existing XML standards (NLM and DocBook) are <lb/>already in use for this purpose, a format based on the Text-Encoding Initiative schema <lb/></body>

			<note place="footnote">hal-00390966, version 1 -3 Jun 2009 <lb/></note>

			<body>would be a better alternative for a variety of reasons. We have given some details of what <lb/>a TEI-based document structure for journal articles might look like, and examined some <lb/>of the specific encoding issues that are particularly relevant to sphere of scholarly <lb/>journals, and we have outlined a bottom-up, rather than top-down, procedure in which the <lb/>TEI community might be able to evolve a new standard, rather than striking a committee <lb/>to sit down and devise one. Finally, we have looked at the kind of publication engine that <lb/>can be built around an XML document collection, and outlined some of its advantages. <lb/></body>

			<note place="footnote">hal-00390966, version 1 -3 Jun 2009 </note>


	</text>
</tei>
