<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="_0"/>
	</teiHeader>
	<text xml:lang="en">
			<titlePage>University of Maryland <lb/>College Park <lb/>Institute for Advanced Computer Studies <lb/>TR{95{93 <lb/>Department of Computer Science <lb/>TR{3535 <lb/>On the Perturbation of <lb/>LU and Cholesky Factors <lb/>G. W. Stewart y <lb/>October, 1995 <lb/>ABSTRACT <lb/>In a recent paper, Chang and Paige have shown that the usual per-<lb/>turbation bounds for Cholesky factors can systematically overestimate <lb/>the errors. In this note we sharpen their results and extend them to <lb/>the factors of the LU decomposition. The results are based on a new <lb/>formula for the rst order terms of the error in the factors. <lb/>This report is available by anonymous ftp from thales.cs.umd.edu in the directory <lb/>pub/reports. <lb/>y Department of Computer Science and Institute for Advanced Computer Studies, University <lb/>of Maryland, College Park, MD 20742. This work was supported in part by the National Science <lb/>Foundation under grant CCR 95503126. <lb/></titlePage>

			<front>On the Perturbation of <lb/>LU and Cholesky Factors <lb/>G. W. Stewart <lb/>ABSTRACT <lb/>In a recent paper, Chang and Paige have shown that the usual per-<lb/>turbation bounds for Cholesky factors can systematically overestimate <lb/>the errors. In this note we sharpen their results and extend them to <lb/>the factors of the LU decomposition. The results are based on a new <lb/>formula for the rst order terms of the error in the factors. <lb/></front>

			<body>1. Introduction <lb/>Let A be a positive de nite matrix of order n. Then A has a unique Cholesky <lb/>factorization of the form A = R T R, where R is upper triangular with positive <lb/>diagonal elements. <lb/>LetÃ = A + E be a perturbation of A in which E is symmetric. If E is <lb/>su ciently small, thenÃ also has a Cholesky factorization: <lb/>A + E = (R + F R ) T (R + F R ): <lb/>Several workers 1, 3, 4, 7] have given bounds on the matrix F R . The common <lb/>result is essentially that <lb/>kF R k F <lb/>kRk 2 <lb/>1 <lb/>p 2 2 (A) kEk F <lb/>kAk 2 <lb/>+ O(kEk 2 <lb/>2 ): <lb/>(1.1) <lb/>Recently Chang and Paige 2] have shown that (1.1) can consistently overesti-<lb/>mate the error in the Cholesky factor and have proposed new bounds. Following <lb/>3], they note that <lb/>E = R T F R + F T <lb/>R R + O(kF R k 2 ): <lb/>(1.2) <lb/>Consequently if one de nes the linear operator T R on the space of upper triangular <lb/>matrices by <lb/>T R (F ) = R T F + F T R; <lb/>then <lb/>F R = F R T 1 <lb/>R (E); <lb/></body>

			<page>1 <lb/></page>

			<page>2 <lb/></page>

			<note place="headnote">Perturbation of LU Factorizations <lb/></note>

			<body>and <lb/>kF R k &lt; kT 1 <lb/>R kkEk; <lb/>where k k denotes a suitably chosen norm. By examining the matrix representa-<lb/>tion of T R , Chang and Paige were able to show that bounds based on kT 1 <lb/>R k are <lb/>sharper than the conventional bounds. They also derive a lower bound for kT 1 <lb/>R k, <lb/>and show by example that the failure of (1.1) is somehow connected with pivoting <lb/>in the computation of the decomposition. <lb/>The purpose of this note is to generalize and strengthen the results of Chang <lb/>and Paige. We do so by exhibiting an explicit matrix representation of F R . The <lb/>representation is invariant under a certain kind of diagonal scaling, and by adjust-<lb/>ing the scaling we can improve the usual bound. Since the approach works for the <lb/>more general LU decomposition, we will treat that case rst and then specialize <lb/>to the Cholesky decomposition. <lb/>Throughout this note k k will denote an absolute norm, such as the 1-norm, <lb/>the 1-norm, or the Frobenius norm, which will also be denoted by k k F . The <lb/>matrix 2-norm, which is not absolute, will be denoted by k k 2 . For any nonsingular <lb/>matrix X we will de ne <lb/>(X) = kXk kX 1 k : <lb/>For more on norms see 5]. <lb/>2. The LU Decomposition <lb/>Let A be a matrix of order n whose leading principal submatrices are nonsingular. <lb/>Then A can be written in the form <lb/>A = LU; <lb/>where L is lower triangular and U is upper triangular. The decomposition is not <lb/>unique, but it can be made so by specifying the diagonal elements of L. (The <lb/>conventional choice is to require them to be one.) <lb/>If E is su ciently small, A + E has an LU factorization: <lb/>A + E = (L + F L )(U + F U ): <lb/>(2.1) <lb/>Again, the factorization is not unique, but it can be made so, say by requiring <lb/>that the diagonals of L remain unaltered. <lb/></body>

			<note place="headnote">Perturbation of LU Factorizations <lb/></note>

			<page>3 <lb/></page>

			<body>Multiplying out the right hand side of (2.1) and ignoring higher order terms, <lb/>we obtain a linear matrix equation for rst order approximations F L and F U to <lb/>F L and F U : <lb/>L F U + U F L = E: <lb/>We shall show how to solve this equation in terms of two matrix operators. <lb/>Let 0 p 1, and de ne L p and U p as illustrated below for a 3 3 matrix: <lb/>L p (X) = <lb/>0 <lb/>B @ <lb/>px 11 0 0 <lb/>x 21 px 22 0 <lb/>x 31 x 32 px 33 <lb/>1 <lb/>C A and U p (X) = <lb/>0 <lb/>B @ <lb/>px 11 x 12 x 13 <lb/>0 px 22 x 23 <lb/>0 <lb/>0 px 33 <lb/>1 <lb/>C A : <lb/>It then follows that for any matrix X, <lb/>X = L p (X) + U 1 p (X); <lb/>(2.2) <lb/>and <lb/>kL p (X)k; kU p (X)k kXk: <lb/>Finally, if X is symmetric <lb/>kU1 <lb/>2 (X)k F <lb/>1 <lb/>p <lb/>2 kXk F : <lb/>(2.3) <lb/>Our basic result is the following: <lb/>F L = LL p (L 1 EU 1 ) and F U = U 1 p (L 1 EU 1 )U: <lb/>To see this, write <lb/>L U 1 p (L 1 EU 1 )U] + LL p (L 1 EU 1 )]U <lb/>= L U 1 p (L 1 EU 1 ) + L p (L 1 EU 1 )]U <lb/>= L(L 1 EU 1 )U <lb/>by (2.2) <lb/>= E: <lb/>The number p is a normalizing parameter, controling how much of the perturba-<lb/>tion is attached to the diagonals of L and U. If p = 0, the diagonal elements of L <lb/>do not change. If p = 1, the diagonal elements of U do not change. <lb/>We can take norms in the expressions F L and F U to get rst order perturbation <lb/>bounds for the LU decomposition. But it is possible to introduce degrees of free-<lb/>dom in the expressions that can later be used to reduce the bounds. Speci cally, <lb/>for any nonsingular diagonal matrix D L , we have <lb/>F L = LD L L 0 (D 1 <lb/>L L 1 EU 1 ) L L 0 (L 1 EU 1 ) <lb/></body>

			<page>4 <lb/></page>

			<note place="headnote">Perturbation of LU Factorizations <lb/></note>

			<body>Consequently <lb/>k F L k kLkkL 1 kkU 1 kkEk; <lb/>or <lb/>k F L k <lb/>kLk <lb/>(L) (U)kEk <lb/>kLkkUk : <lb/>(2.4) <lb/>Since kAk kLkkUk, we have <lb/>k F L k <lb/>kLk (L) (U) kEk <lb/>kAk : <lb/>(2.5) <lb/>Similarly, if D U is a nonsingular diagonal matrix and we set <lb/>U = D U U; <lb/>then <lb/>k F U k <lb/>kUk (L) (Û) kEk <lb/>kAk : <lb/>(2.6) <lb/>The bounds (2.5) and (2.6) di er from the usual bounds (e.g., see 4]) by the <lb/>substitution ofL orÛ for L or U. However, if the diagonal matrices D L and D U <lb/>are chosen appropriately, (L) and (Û) can be far less that (L) or (U). For <lb/>example, if <lb/>U = 1 <lb/>0 <lb/>! <lb/>; <lb/>(2.7) <lb/>then 1 (U) = 1= . But if we set D U = diag(1; 1= ), then (Û) = 1. <lb/>Poorly scaled but essentially well-conditioned matrices like U in (2.7) occur <lb/>naturally. If A is ill-conditioned and the LU decomposition of A is computed <lb/>with pivoting, the ill-conditioning of A will usually reveal itself in the diagonal <lb/>elements of U. In 6] the author has shown that such upper triangular matrices <lb/>are arti cially ill conditioned in the sense that they can be made well conditioned <lb/>by scaling their rows. <lb/>If (L) = 1 (it cannot be less), then the bound (2.4) reduces to <lb/>k F L k kU 1 kkEk: <lb/>(2.8) <lb/>It is reasonable to ask if there are problems for which we can replace kU 1 k by an <lb/>even smaller number and still have inequality for all E. The answer depends on <lb/>p. For example, suppose that k k is the 1-norm. Let e i be the unit coordinate <lb/></body>

			<note place="headnote">Perturbation of LU Factorizations <lb/></note>

			<page>5 <lb/></page>

			<body>vectors, and let k be such that ke T <lb/>k U 1 k = kU 1 k. Let E = e n e T <lb/>k , so that kEk = 1 <lb/>Then it is easy to see that <lb/>kLL p (L 1 EU 1 )k = kL p (e n e T <lb/>k U 1 )k <lb/>Hence <lb/>kU 1 kkEk k F L k pkU 1 kkEk: <lb/>(2.9) <lb/>Consequently, if p is near one, (2.8) is essentially the smallest bound that holds <lb/>uniformly for all E. <lb/>The reason for the appearance of the factor p in (2.9) is that the error may <lb/>concentrate in the last column of L 1 EU 1 , in which case it is reduced by a factor <lb/>of at least p by the operator L p . This can happen, for example, when L = I and <lb/>U = diag(I n 1 ; ) for small. However, if p si small, the perturbation will show <lb/>up in F U , for which the factor is 1 p. <lb/>The bounds (2.5) and (2.6) suggest a strategy for estimating the condition <lb/>of the LU factorizations. Van der Sluis 8] has shown that in the 2-norm, the <lb/>condition number is approximately minimized when the rows or columns of the <lb/>matrix are scaled to have norm one. Thus the strategy is to so scaleL andÛ and <lb/>use a condition estimator to estimate the condition of L,L, U,Û. <lb/>In 4] it is shown how to obtain rigorous bounds for the errors in the rst order <lb/>approximations F L and F U . Since the second order terms decay rapidly, the error <lb/>bounds are less important than the condition that insures their existence: namely, <lb/>kL 1 kkU 1 kkEk 1 <lb/>4 : <lb/>3. The Cholesky Decomposition <lb/>We now return to the Cholesky decomposition. In analyzing the perturbation <lb/>of the the Cholesky factor R it is natural to take p = 1 <lb/>2 so that symmetry is <lb/>preserved. In this case the solution of the perturbation equation becomes <lb/>F R = U1 <lb/>2 (R T ER 1 )R: <lb/>Hence ifR is de ned in analogy withL andÛ, it follows from (2.3) that <lb/>k F R k F <lb/>kRk 2 <lb/>1 <lb/>p <lb/>2 2 (R) 2 (R) kEk F <lb/>kAk 2 <lb/>: <lb/></body>

			<page>6 <lb/></page>

			<note place="headnote">Perturbation of LU Factorizations <lb/></note>

			<body>Moreover, by a variant of the argument that lead to (2.9), for any A, there is an <lb/>E such that <lb/>kR 1 k 2 kEk F k F R k F <lb/>1 <lb/>2 kR 1 k 2 kEk F <lb/>which shows that we cannot reduce the constant in the bound <lb/>k F R k F kEk F <lb/>to less than 1 <lb/>2 kR 1 k. <lb/></body>

			<listBibl>References <lb/>1] A. Barrland. Perturbation bounds for the LDL H and the LU factorizations. <lb/>BIT, 31:358{363, 1991. <lb/>2] X-W. Chang and C. C. Paige. A new perturbaton analysis for the Cholesky <lb/>factorization. School of Computer Science, McGill University. To appear in <lb/>the IMA Journal of Numerical Analysis., 1995. <lb/>3] G. W. Stewart. Perturbation bounds for the QR factorization of a matrix. <lb/>SIAM Journal on Numerical Analysis, 1977:509{518, 1977. <lb/>4] G. W. Stewart. On the perturbation of LU, Cholesky, and QR factorizations. <lb/>SIAM Journal on Matrix Analysis and Applications, 14:1141{1146, 1993. <lb/>5] G. W. Stewart and J.-G. Sun. Matrix Perturbation Theory. Academic Press, <lb/>Boston, 1990. <lb/>6] G. W. Stwart. The triangular matrices of Gaussian elimination and related de-<lb/>compositions. Technical Report CS-TR-3533 UMIACS-TR-95-91, University <lb/>of Maryland, Department of Computer Science, 1995. <lb/>7] J.-G. Sun. Rounding-error and perturbation bounds for the Cholesky and <lb/>LDL T factorizations. Linear Algebra and Its Applications, 173:77{98, 1992. <lb/>8] A. van der Sluis. Condition numbers and equilibration of matrices. Numerische <lb/>Mathematik, 14:14{23, 1969. </listBibl>


	</text>
</tei>
