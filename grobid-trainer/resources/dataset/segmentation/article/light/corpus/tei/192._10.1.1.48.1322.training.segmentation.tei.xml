<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="_0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Eaton&apos;s Markov Chain, its Conjugate Partner <lb/>and P-admissibility <lb/>James P. Hobert <lb/>Department of Statistics <lb/>University of Florida <lb/>Gainesville, FL 32611 <lb/>jhobert@stat.ufl.edu <lb/>C. P. Robert <lb/>Laboratoire de Statistique <lb/>CREST, INSEE <lb/>75675 Paris cedex 14, France <lb/>robert@ensae.fr <lb/>August 1997 <lb/>The rst author acknowledges partial support from the Center for Research in Economics and <lb/>Statistics (CREST) at the French National Institute of Statistics and Economic Studies (INSEE), <lb/>Paris, France. <lb/>AMS 1991 subject classi cations. Primary 62C15; secondary 60J05 <lb/>Key words and phrases. Bilinear model, Branching process with immigration, Exponential <lb/>family, Improper prior, Null recurrence, Random walk, Stochastic di erence equation, Transience <lb/>Abbreviated title. Markov Chains and P-admissibility <lb/>Abstract <lb/>Suppose that X is a random variable with density f(xj ) and that ( jx) is a proper <lb/>posterior corresponding to an improper prior ( ). The prior is called P-admissible if the <lb/>generalized Bayes estimator of every bounded function of is almost--admissible under <lb/>squared error loss. Eaton (1992) showed that recurrence of the Markov chain with transition <lb/>density R( j ) = <lb/>R ( jx)f(xj )dx is a su cient condition for P-admissibility of ( ). We <lb/>show that Eaton&apos;s Markov chain is recurrent if and only if its conjugate partner, with <lb/>transition densityR(yjx) = <lb/>R f(yj ) ( jx)d , is recurrent. This provides a new method <lb/>of establishing P-admissibility. Often, one of these two Markov chains corresponds to a <lb/>standard stochastic process for which there are known results on recurrence and transience. <lb/>For example, when X is Poisson( ) and an improper gamma prior is placed on , the <lb/>Markov chain de ned byR(yjx) is equivalent to a branching process with immigration. We <lb/>use this type of argument to establish P-admissibility of some priors when f is a negative <lb/>binomial mass function, and when f is a gamma density with known shape. <lb/></front>

			<body>1 Introduction <lb/>We will be interested in the following univariate decision problem. Suppose that X is a <lb/>single observation from the probability density (or mass) function f (xj ) whose support <lb/>X &lt; does not depend on the parameter , which we assume belongs to the set <lb/>&lt;. <lb/> Suppose that ( ) is an improper prior density (or mass) function with support that <lb/>yields a proper posterior, ( jx); that is, we assume that for all x 2 X <lb/>m(x) := <lb/>Z <lb/>f (xj ) ( )d &lt; 1: <lb/>This setup is a special case of the decision problem considered by Eaton (1992) who rst <lb/>introduced what we call P-admissibility. <lb/>De nition 1. The prior, ( ), is called P-admissible if the generalized Bayes estimate of <lb/>every bounded function of is almost--admissible (Stein, 1965) under squared error loss. <lb/>Of course, the generalized Bayes estimate of g( ) under squared error loss is the posterior <lb/>expectation <lb/>g (X) := <lb/>Z <lb/>g( ) ( jx)d : <lb/>Also, since has support , almost--admissibility implies admissibility as long as all nite <lb/>valued risk functions are continuous (Berger, 1985, Section 8.8). <lb/>Note that P-admissibility is an endorsement of the improper prior itself and not just <lb/>an individual estimator based on the prior. This is quite di erent from a typical result <lb/>concerning admissibility where a single function of the parameter is of interest, and an <lb/>improper prior is judged indirectly through its generalized Bayes estimator. See Eaton <lb/>(1982) for more on this point of view. <lb/>Eaton (1992) established that P-admissibility is implied by the recurrence of a Markov <lb/>chain constructed using f and . This su cient condition is an essential tool for establishing <lb/> P-admissibility because a direct proof is often quite di cult to obtain. The Markov chain <lb/>is now described. Suppose for the moment that f and are both density functions and <lb/>note that, for xed , the function ( jx)f(xj ) is a joint density in the variable ( ; x) with <lb/>support <lb/>X. Therefore, for any 2 , <lb/>R( j ) := <lb/>Z <lb/>X <lb/>( jx)f(xj )dx <lb/>(1) <lb/>is a density function in the variable with support . Let W = (W 0 ; W 1 ; W 2 ; : : : ) be a <lb/>time-homogeneous Markov chain on the in nite product space 1 with transition density <lb/>given by R( j ); that is, <lb/>P(W t 2 Ajw t?1 ) = <lb/>Z <lb/>A <lb/>R( jw t?1 )d : <lb/>Eaton (1992) showed that recurrence of this Markov chain, which we call the R-chain, <lb/>implies P-admissibility of ( ). More speci cally, he developed a su cient condition, C, for <lb/></body>

			<page>1 <lb/></page>

			<body>P-admissibility of , akin to the drift condition of Meyn and Tweedie (1993, p.174), and <lb/>then showed that C is equivalent to recurrence of the R-chain. Since we are not directly <lb/>interested in C, we do not state it explicitly. <lb/>Example 1.1. Let Xj N( ; 1) and ( ) / exp ?b 2 =2 + ab . Then the posterior is <lb/>normal with mean (x + ab)=(b+1) and variance 1=(b + 1). Thus, we have an improper prior <lb/>yielding a proper posterior whenever b 2 (?1; 0]. Using (1) it follows that <lb/>j N + ab <lb/>b + 1 ; b + 2 <lb/>(b + 1) 2 : <lb/>Therefore, the R-chain can be written as an autoregressive process of order one; that is, for <lb/>t = 0; 1; 2; : : : <lb/>W t+1 = 1 <lb/>b + 1 W t + U t+1 <lb/>where U 1 ; U 2 ; U 3 ; : : : is an independent and identically distributed (iid) sequence of normal <lb/>random variables with mean ab=(b + 1) and variance (b + 2)=(b + 1) 2 . When b = 0, this <lb/>is a standard random walk with a mean-zero increment, and is therefore null recurrent. <lb/>When b 2 (?1; 0), the coe cient of W t is larger than 1, and W is transient (Meyn and <lb/>Tweedie, 1993, p.221). Thus, P-admissibility holds when b = 0; that is, when the prior is <lb/>Lebesgue measure. Indeed, Eaton (1992, p.1157) shows that, under very minimal conditions, <lb/>P-admissibility holds when Lebesgue measure is used as a prior for a translation parameter. <lb/>We return to this example below. <lb/>Other works regarding relationships between admissibility and recurrence include Brown <lb/>(1971), who related admissibility of estimators of the multivariate normal mean to recur-<lb/>rence of associated di usions, and Johnstone (1984), who reported similar results for Poisson <lb/>means and associated birth and death processes (see also Johnstone, 1986). Both of these <lb/>authors considered continuous time Markov processes on the sample space while, in con-<lb/>trast, Eaton (1992) looked at discrete time Markov chains on the parameter space. We <lb/>will show that an obvious counterpart to the R-chain, which lives on the sample space, is <lb/>recurrent if and only if the R-chain is recurrent. Therefore, at least in our context, Eaton&apos;s <lb/>results can be viewed as involving a Markov chain on the sample space. The counterpart <lb/>of Eaton&apos;s R-chain is now described. <lb/>Using arguments similar to those above, it follows that for any x 2 X, <lb/>R(yjx) := <lb/>Z <lb/>f(yj ) ( jx)d <lb/>(2) <lb/>is a density function in the variable y with support X. Let V = (V 0 ; V 1 ; V 2 ; : : : ) be a <lb/>time-homogeneous Markov chain on the in nite product space X 1 with transition densitá»¹ <lb/>R(yjx). Eaton (1992) did not study this Markov chain, which we call theR-chain, but did <lb/>mention it (p.1171). <lb/></body>

			<page>2 <lb/></page>

			<body>Example 1.1 cont. Using (2), we nd that the transitions for theR-chain are given by <lb/>yjx N x + ab <lb/>b + 1 ; b + 2 <lb/>b + 1 : <lb/>Thus, theR-chain is equal in distribution to the following autoregressive process of order <lb/>one <lb/>V t+1 = 1 <lb/>b + 1 V t + U 0 <lb/>t <lb/>where U 0 <lb/>1 ; U 0 <lb/>2 ; U 0 <lb/>3 ; : : : is an iid sequence of normal random variables with mean ab=(b+1) and <lb/>variance (b + 2)=(b + 1). Except for a slight di erence in the variance of the error sequence <lb/>(b + 2)=(b + 1) 2 vs. (b + 2)=(b + 1)], the R andR-chains are the same in this case, and it <lb/>follows that theR-chain is recurrent when b = 0 and transient when b 2 (?1; 0). <lb/>While the R andR-chains are always either both recurrent or both transient (see Sec-<lb/>tion 2), the similarity in form exhibited in the previous example is not typical. In many <lb/>situations one of the chains is much easier analyze than the other, and this is the case in <lb/>the following example. <lb/>Example 1.2. Suppose that Xj <lb/>Poisson( ) and ( ) / a?1 e ?b . Then jx <lb/>Gamma(x + a; b + 1). Thus, we have an improper prior yielding a proper posterior when <lb/>a &gt; 0 and b 2 (?1; 0]. A simple calculation shows that <lb/>R( j ) = <lb/>1 <lb/>X <lb/>x=0 <lb/>e ? x <lb/>x! <lb/>(b + 1) x+a <lb/>?(x + a) <lb/>x+a?1 e ? (b+1) : <lb/>(3) <lb/>for ; 2 (0; 1). Feller (1971, p.58) calls (3) a randomized gamma density. When b = ?1=2 <lb/>and a is a multiple of 1=2, it is the noncentral chi squared density. Eaton (1992, p.1165) <lb/>considered the case in which b = 0, and proved directly that the condition C holds when <lb/>a 2 (0; 1]. It follows that, in this speci c case, P-admissibility holds, and the R-chain is <lb/>null recurrent. <lb/>In Remark 5.1, Eaton (1992) reveri es null recurrence of the R-chain (when b = 0 and <lb/>a 2 (0; 1]) using a theorem of Lamperti (1960). There is a problems with this application, <lb/>however, as Lamperti&apos;s regularity condition (3.11) is not satis ed. Although Kersting (1986) <lb/>removes some of Lamperti&apos;s regularity conditions, thereby justifying Eaton&apos;s application <lb/>when b = 0 and a 2 (0; 1), even Kersting&apos;s results are not applicable when a = 1. On the <lb/>other hand, Kersting&apos;s results can be used to show transience when b 6 = 0 and when b = 0 <lb/>and a &gt; 1. <lb/>In contrast to the rather complicated form of the R-chain in this example, theR-chain <lb/>has a simple interpretation, and results concerning its recurrence and transience have been <lb/>around for over 25 years. The transition density for theR-chain is given bá»¹ <lb/>R(yjx) = ?(y + x + a) <lb/>y!?(x + a) p x+a (1 ? p) y <lb/></body>

			<page>3 <lb/></page>

			<body>where p = (b + 1)=(b + 2) and x; y 2 f0; 1; 2; :::g. This is a generalized negative binomial <lb/>mass function (Feller, 1968, p.269). Indeed, when a is a positive integer, it is the usual <lb/>negative binomial mass function. If Z is a random variable supported on the non-negative <lb/>integers and <lb/>P(Z = z) = ?(z + c) <lb/>z!?(c) d c (1 ? d) z <lb/>for d 2 (0; 1) and c &gt; 0, we write Z NB(c; d). Note that E Z] = c(1 ? d)=d and <lb/>Var(Z) = c(1 ? d)=d 2 . It follows from the form of the probability generating function <lb/>that if Z 1 ; Z 2 ; : : : ; Z n are independent random variables with Z i NB(c i ; d), then <lb/>P Z i <lb/>NB( <lb/>P c i ; d). Using these facts, it is clear that theR-chain can be written is a branching <lb/>process with immigration; that is, <lb/>V t+1 = <lb/>Vt <lb/>X <lb/>i=1 <lb/>N i;t + M t+1 <lb/>where N 1;t ; N 2;t ; : : : ; N Vt;t are iid NB(1; p) and M t+1 (independent of the N i;t &apos;s) is NB(a; p). <lb/>Think of the chain as follows. At generation t, there are V t animals in the population. Each <lb/>animal, independently of all others, has a random number of o spring whose distribution <lb/>is NB(1; p). Also at generation t, a random number (NB(a; p)) of animals migrate into the <lb/>society. The population at the (t + 1)st generation consists of all of those o spring and <lb/>the immigrants. The mean and variance of the o spring distribution are 1=(b + 1) and <lb/>(b + 2)=(b + 1) 2 , respectively. <lb/>Results in Pakes (1971) show that this branching process is null recurrent if b = 0 and <lb/>a 2 (0; 1], and is transient otherwise. This is intuitively reasonable because when b 2 (?1; 0), <lb/>the mean number of o spring per person is larger than one (super-critical case) and the <lb/>population explodes. On the other hand, when b = 0 each person averages a single o spring <lb/>(critical case), and the stability of the population depends upon the rate of immigration. <lb/>Again, the recurrence/transience behavior of theR-chain is the same as that of the R-chain. <lb/>We have extended Eaton&apos;s (1992) analysis of this example by showing that P-admissibility <lb/>cannot be established through recurrence of the R-chain when b = 0 and a &gt; 1 nor when <lb/>b 2 (?1; 0). <lb/>The rest of the paper is laid out as follows. The theorem showing that the R andR-chains <lb/>are always either both recurrent or both transient is presented in Section 2. In Section 3 <lb/>we consider the case in which X has a gamma density with known shape parameter and an <lb/>improper gamma prior is placed on the unknown scale. Here theR-chain turns out to be <lb/>a bilinear model (Meyn and Tweedie, 1993, p.30), and recent results of Babillot, Bougerol <lb/>and Elie (1997) can be used to establish recurrence, and hence P-admissibility. Section 4 <lb/>studies the case of the NB(k; p) distribution (with k known) and an improper beta prior on <lb/>the unknown success probability, p. A transformation of the R-chain gives another bilinear <lb/>model and the results of Babillot et al. (1997) can again be applied. Because the success <lb/>probability is bounded, our results yield a class of admissible estimators of p. Finally, <lb/>conclusions and avenues for future research are discussed in Section 5. <lb/></body>

			<page>4 <lb/></page>

			<body>2 Recurrence Duality <lb/>Let B( ) and B(X) be the appropriate -algebras on and X; that is, the Borel -algebra <lb/>if the set is uncountable, and the set of all subsets in the countable case. Let be Lebesgue <lb/>or counting measure on B( ) as appropriate, and de ne X similarly. Put S = X <lb/>and <lb/>let S be the product measure on the product -algebra B(S). <lb/>De ne (V n ; W n ), n = 0; 1; 2; : : : , to be the bivariate, discrete time, time homogeneous <lb/>Markov chain on the product space S 1 de ned by the Markov transition density <lb/>M (y; jx; ) = ( jy)f(yj ) <lb/>(4) <lb/>where we use (x; ) and (y; ), instead of (v n ; w n ) and (v n+1 ; w n+1 ), respectively, to avoid <lb/>excessive subscripting. This Markov chain, which we call this the extended chain, is similar <lb/>to that used in data augmentation (Tanner and Wong, 1987; Liu, Wong and Kong, 1994). <lb/>For any xed (x; ) 2 S, M (y; jx; ) is strictly positive on S. Thus, the extended chain is <lb/>S -irreducible and aperiodic. <lb/>It is clear from (4) that given W n , (V n+1 ; W n+1 ) is conditionally independent of V n ; that <lb/>is, x does not appear on the right side of (4). Similarly, given V n , (W n ; V n+1 ) is conditionally <lb/>independent of W n?1 . As a result, fW n : n = 0; 1; 2; : : : g and fV n : n = 0; 1; 2; : : : g are both <lb/>univariate Markov chains and, following Liu et al. (1994), we call them conjugate Markov <lb/>chains. Indeed, fW n : n = 0; 1; 2; : : : g is the R-chain and its Markov transition density is <lb/>R( j ) = <lb/>Z <lb/>X <lb/>( jx)f(xj ) X (dx): <lb/>It follows directly from the S -irreducibility of the extended chain that the R-chain is -<lb/>irreducible and aperiodic. Also, it is easy to derive from the detailed balance condition <lb/>R( j ) ( ) = R( j ) ( ) <lb/>(5) <lb/>that ( ) = <lb/>R R( j ) ( ) (d ), which means that the prior, , is an invariant density for <lb/>the R-chain. We note in passing that Eaton refers to a chain satisfying (5) as -symmetric. <lb/>Analogously, fV n : n = 0; 1; 2; : : : g is theR-chain whose transition density is <lb/>R(yjx) = <lb/>Z <lb/>f(yj ) ( jx) (d ): <lb/>TheR-chain is X -irreducible and aperiodic, and has m( ) as an invariant density. <lb/>A recurrent Markov chain possesses a unique (up to constant multiples) invariant mea-<lb/>sure. When the invariant measure is nite, the chain is called positive (Meyn and Tweedie, <lb/>1993, Chapter 10). A consequence of uniqueness is that a Markov chain possessing an in-<lb/>variant measure with in nite mass can not be positive recurrent. (Such a chain is either <lb/>null recurrent or transient.) Thus, the R-chain is positive recurrent only when is proper <lb/>and, similarly, theR-chain is positive recurrent only when m is proper. (This makes sense <lb/>from a decision-theoretic standpoint because unique proper Bayes estimators are admissi-<lb/>ble (Lehmann, 1983, p.263) and Eaton&apos;s (1992) results deal with the more challenging case <lb/></body>

			<page>5 <lb/></page>

			<body>where is improper.) Since m is proper if and only if is proper, it follows that the R-chain <lb/>is positive recurrent if and only if theR-chain is positive recurrent. This correspondence <lb/>can be viewed as a special case of the Duality Principle (Diebolt and Robert, 1994). Our <lb/>main result shows that this connection between the chains can be extended. Before stating <lb/>this result, we consider an example in which X is nite. <lb/>Example 2.1. Suppose that Xj Binomial(n; ) where n is known and 2 (0; 1). It is <lb/>well-known that an irreducible Markov chain on a nite state space is positive recurrent. <lb/>Therefore, since X is nite in this case, the R andR-chain are both positive recurrent. This <lb/>is consistent with the fact that any improper prior on will lead to an in nite marginal <lb/>(hence, an improper posterior) for at least one value of x. On the other hand, suppose <lb/>Xj NB(k; ) where k is known. The sample space is in nite in this case, and there are <lb/>improper priors that lead to proper posteriors. This setup is considered in Section 4. <lb/>Theorem 1. The R-chain is recurrent if and only if theR-chain is recurrent. <lb/>Proof. Let B + ( ) be the class of sets in B( ) with positive measure, and de ne B + (X ) <lb/>similarly. Suppose that theR-chain is recurrent; that is, for any B 2 B + (X ) and any <lb/>starting value <lb/>1 <lb/>X <lb/>n=1 <lb/>E I B (V n )] = 1 <lb/>(Meyn and Tweedie, 1993, p.496). Now for A 2 B + ( ), there exists an &gt; 0 such that <lb/>X (B ) &gt; 0 where <lb/>B := fx 2 X : <lb/>Z <lb/>A <lb/>( jx) (d ) &gt; g: <lb/>This is true since if no such exists, then <lb/>R <lb/>A ( jv) (d ) = 0 almost everywhere ( X ) <lb/>which contradicts the fact that A 2 B + ( ). Therefore, <lb/>1 <lb/>X <lb/>n=1 <lb/>E I A (W n )] = <lb/>1 <lb/>X <lb/>n=1 <lb/>E E I A (W n )jV n ]] <lb/>1 <lb/>X <lb/>n=1 <lb/>E I B (V n )E I A (W n )jV n ]] <lb/>1 <lb/>X <lb/>n=1 <lb/>E I B (V n )] = 1: <lb/>This shows that recurrence of theR-chain implies recurrence of the R-chain. The reverse <lb/>implication can be shown using the same type of argument. <lb/>Theorem 1 shows that, at least for the models that we consider, Eaton&apos;s (1992) result <lb/>may be regarded as concerning a Markov chain on the sample space, which is the domain <lb/></body>

			<page>6 <lb/></page>

			<body>of the Markov processes constructed by Brown (1971) and Johnstone (1984). More impor-<lb/>tantly, our result is useful in situations where recurrence of theR-chain is easier to establish <lb/>than recurrence of the R-chain. In Example 1.2, theR-chain turned out to be a standard <lb/>Markov chain for which the transience/recurrence behavior is already known. The next <lb/>section concerns a similar example. <lb/>3 Gamma-Gamma Model <lb/>Suppose that Xj <lb/>Gamma( ; ) ( &gt; 0 known) and ( ) / a?1 e ?b . Then jx <lb/>Gamma( + a; b + x). In this case, we have an improper prior yielding a proper posterior <lb/>when b = 0 and a &gt; ? and when b &gt; 0 and a 2 (? ; 0]. Most of the admissibility <lb/>and domination results for gamma models concern estimators of or the scale parameter <lb/>1= (e.g. Berger, 1980, 1985 (p.255, 305); Das Gupta, 1984), whereas our results concern <lb/>P-admissibility of improper conjugate priors. <lb/>The transition density for the R-chain is given by <lb/>R( j ) = <lb/>+a?1 e ? b <lb/>?( + a)?( ) <lb/>Z 1 <lb/>0 <lb/>(b + x) +a x ?1 e ?x( + ) dx; <lb/>for ; 2 (0; 1). This density involves an integral that can not be written in closed form <lb/>unless b = 0. On the other hand, the transition density for theR-chain has a closed form <lb/>expression for all values of a and b <lb/>R(yjx) = ?(2 + a)(b + x) +a <lb/>?( + a)?( ) <lb/>y ?1 <lb/>(x + y + b) 2 +a <lb/>for x; y 2 (0; 1). We now state the result. <lb/>Theorem 2. The Markov chains are recurrent if and only if a = 0. Thus, P-admissibility <lb/>holds when a = 0. <lb/>Proof. Consider theR-chain. By noting that the random variable Z = Y=(x + b) has a <lb/>density that is independent of x, we may write theR-chain as a bilinear model (Meyn and <lb/>Tweedie, 1993, p.30) <lb/>V t+1 = (V t + b)Z t+1 <lb/>(6) <lb/>where Z 1 ; Z 2 ; Z 3 ; : : : is an iid sequence of random variables with density <lb/>f Z (z) = ?(2 + a) <lb/>?( + a)?( ) <lb/>z ?1 <lb/>(z + 1) 2 +a <lb/>for z 2 (0; 1) and zero otherwise. The random variable ( + a)Z= has an F(2 ; 2( + a)) <lb/>distribution, which implies that Z has an in nite mean whenever + a 1. <lb/>First, consider the case b = 0. A log transformation of (6) leads to the following random <lb/>walk on &lt; <lb/>L t+1 = L t + log Z t+1 <lb/>(7) <lb/></body>

			<page>7 <lb/></page>

			<body>where L t = log V t , t = 0; 1; 2; : : : . Suppose B 2 B(X), then V t 2 B if, and only if, L t 2 B <lb/>where B = fy 2 &lt; : e y 2 Bg. Then since B has positive Lebesgue measure if and only if <lb/>B has positive Lebesgue measure, it follows that (6) and (7) are either both recurrent or <lb/>both transient. <lb/>The random walk (7) is recurrent if and only if log Z has mean zero (Meyn and Tweedie, <lb/>1993, p.247). Feller (1971, p.50) shows that Z has the same distribution as B ?1 ? 1 where <lb/>B is Beta( + a; ), from which it follows that the moment generating function of log Z <lb/>exists. Now <lb/>E log Z] = ?(2 + a) <lb/>?( + a)?( ) <lb/>Z 1 <lb/>0 <lb/>z ?1 log z <lb/>(z + 1) 2 +a dz + <lb/>Z 1 <lb/>1 <lb/>z ?1 log z <lb/>(z + 1) 2 +a dz <lb/>= ?(2 + a) <lb/>?( + a)?( ) <lb/>Z 1 <lb/>0 <lb/>z ?1 log z <lb/>(z + 1) 2 +a (1 ? z a )dz <lb/>which implies that the mean of log Z is negative when a &gt; 0, zero when a = 0, and positive <lb/>when a &lt; 0. Thus, (6) is recurrent when a = b = 0 and transient when b = 0 and a 6 = 0. <lb/>We now present a result of Babillot et al. (1997) that will enable us to deal with the <lb/>remaining cases; that is, when b &gt; 0. Let f(A t ; B t )g t 1 be an iid sequence of random <lb/>variables taking values in &lt; + &lt;. Consider the Markov chain X 0 ; X 1 ; X 2 ; : : : de ned by <lb/>the stochastic di erence equation X t+1 = A t+1 X t + B t+1 , t = 0; 1; 2; : : : . The following <lb/>proposition is part of Babillot et al.&apos;s (1997) Corollary 4.2. <lb/>Proposition 1. Suppose that <lb/>(i) For all x 2 &lt;, P(A 1 x + B 1 = x) &lt; 1, <lb/>(ii) For some &gt; 0, <lb/>E <lb/>h ? <lb/>j log A 1 j + (log jB 1 j) + 2+ i <lb/>&lt; 1 <lb/>where x + = max(0; x), and <lb/>(iii) E log A 1 ] = 0 and P(A 1 = 1) &lt; 1. <lb/>Then the Markov chain X 0 ; X 1 ; X 2 ; : : : is recurrent. <lb/>When E log A 1 ] &lt; 0, the chain is positive recurrent (Brandt, 1986). On the other hand, if <lb/>E log A 1 ] &gt; 0, then the random walk <lb/>P t <lb/>i=1 log A i , and hence <lb/>Q t <lb/>i=1 A i , diverge to in nity <lb/>w.p. 1. Note that <lb/>X t = X 0 <lb/>t <lb/>Y <lb/>i=1 <lb/>A i + B t + <lb/>t?1 <lb/>X <lb/>i=1 <lb/>B i <lb/>t <lb/>Y <lb/>j=i+1 <lb/>A j : <lb/>Therefore, when E log A 1 ] &gt; 0 and P(B 1 0) = 1, the Markov chain X 0 ; X 1 ; X 2 ; : : : is <lb/>transient. <lb/>Now consider again theR-chain. When b &gt; 0, (6) ts into the Babillot et al. (1997) <lb/>framework with A t = Z t and B t = bZ t . Assumptions (i) and (ii) of Proposition 1 are clearly <lb/>satis ed, and we conclude that, in the case of strictly positive b, theR-chain is recurrent <lb/>when a = 0 and transient when a 2 (? ; 0). <lb/></body>

			<page>8 <lb/></page>

			<body>Note that when = 1, f(xj ) is an exponential density, which is a scale family with <lb/>support (0; 1), and the Markov chains are recurrent under the prior ( ) = 1= . This is <lb/>actually true quite generally. Speci cally, suppose that X = = (0; 1) and that <lb/>f(xj ) = 1 f x : <lb/>A standard prior density for this scale parameter is the right invariant Haar density given <lb/>by ( ) = 1= (Berger, 1985, p.409). The posterior density is given by <lb/>( jx) = x <lb/>2 f x <lb/>and, after making a change of variables, the transition density for the R-chain is given by <lb/>R( j ) = <lb/>Z 1 <lb/>0 <lb/>v <lb/>2 f v f(v)dv: <lb/>Now, because the density of = is free of , it is clear that the R-chain can be written as <lb/>W t+1 = W t Z t+1 <lb/>where Z 1 ; Z 2 ; Z 3 ; : : : is an iid sequence of random variables with density function <lb/>f(z) = <lb/>Z 1 <lb/>0 <lb/>v <lb/>z 2 f v <lb/>z f(v)dv: <lb/>As in the previous proof, this Markov chain is recurrent if and only if E log Z] = 0, but this <lb/>follows from the fact that the density of log Z is symmetric about the origin. Therefore, the <lb/>R-chain is recurrent and P-admissibility holds. When dealing with exponential families, <lb/>there is, of course, no loss of generality in restricting attention to a single observation. This <lb/>is not the case, however, for a general scale family, and this result is therefore of limited <lb/>interest. <lb/>4 Negative Binomial-Beta Model <lb/>Suppose that Xj NB(k; ) and that ( ) / a?1 (1? ) b?1 . Then jx Beta(a+k; b+x), <lb/>and we have an improper prior yielding a proper posterior as long as b &gt; 0 and a 2 (?k; 0]. <lb/>Theorem 3. For b k, the Markov chains are recurrent if and only if a = 0. Thus, <lb/>P-admissibility holds when b k and a = 0. <lb/>Proof. The transition density for the R-chain is given by <lb/>R( j ) = <lb/>k+a?1 (1 ? ) b?1 k <lb/>?(k + a)?(k) <lb/>1 <lb/>X <lb/>x=0 <lb/>?(k + a + b + x)?(x + k) <lb/>x!?(b + x) <lb/>(1 ? )(1 ? )] x <lb/>for ; 2 (0; 1). When k = b, the summand is the kernel of a NB(k +a+b; 1?(1? )(1? )) <lb/>mass function, and we have <lb/>R( j ) = ?(k + a + b) <lb/>?(k + a)?(k) <lb/>k+a?1 (1 ? ) b?1 k <lb/>(1 ? (1 ? )(1 ? )) k+a+b : <lb/></body>

			<page>9 <lb/></page>

			<body>By noting that the density of ?1 (1 ? ) ?1 is free of , we may write the R-chain as a <lb/>nonlinear state space model (Meyn and Tweedie, 1993, p.29) <lb/>W t+1 = W t <lb/>Z t+1 + W t <lb/>(8) <lb/>where Z 1 ; Z 2 ; Z 3 ; : : : is an iid sequence of random variables such that (k + a)Z 1 =k has an <lb/>F(2k; 2(k + a)) distribution. Letting I t = 1=W t , equation (8) becomes <lb/>I t+1 = I t Z t+1 + 1 <lb/>for t = 0; 1; 2; : : : and by an argument similar to that used in Section 3, this Markov chain is <lb/>recurrent if and only if the R-chain is recurrent. We know from Section 3 that E log Z] = 0 <lb/>when a = 0 and is strictly positive when a &lt; 0. Appealing to Proposition 1, the chain I t , <lb/>and hence the R-chain, are recurrent when a = 0 and transient when a &lt; 0. <lb/>Now consider the case in which b &gt; k. Let 1 Beta(a + k; b ? k) and 2 Beta(a + <lb/>b; k + x). It is straightforward to show that if 1 and 2 are independent, then 1 2 has a <lb/>Beta(a + k; b + x) distribution. We can therefore write the R-chain as <lb/>W t+1 = B t+1 <lb/>W t <lb/>Z t+1 + W t <lb/>(9) <lb/>where Z 1 ; Z 2 ; Z 3 ; : : : is an iid sequence of random variables such that (a + b)Z 1 =k has an <lb/>F(2k; 2(a + b)) distribution, and B 1 ; B 2 ; B 3 ; : : : is an iid sequence of Beta(a + k; b ? k) <lb/>random variables, which are independent of the Z&apos;s. Again, letting I t = 1=W t , equation (9) <lb/>becomes <lb/>I t+1 = I t <lb/>Z t+1 <lb/>B t+1 <lb/>+ 1 <lb/>B t+1 <lb/>for t = 0; 1; 2; : : : . The behavior of this chain depends upon the expectation of the logarithm <lb/>of Z t+1 =B t+1 . Using moment generating functions, one can show that <lb/>E log Z t+1 <lb/>B t+1 <lb/>= (k) ? (a + k) <lb/>where is the derivative of the log gamma function; that is, (x) = ? 0 (x)=?(x). Now, <lb/>since ( ) is increasing, E log (Z t+1 =B t+1 )] = 0 when a = 0 and is strictly positive when <lb/>a 2 (?k; 0). Another application of Proposition 1 yields the result. <lb/>Most of the admissibility and domination results for negative binomial models concern <lb/>estimators of (e.g. Hwang, 1982a, 1982b). Since is a bounded parameter in this example, <lb/>Theorem 3 shows that if b k <lb/>(X) = k=(X + k + b) <lb/>is an admissible estimator of under squared error loss. Although admissibility of general-<lb/>ized Bayes estimates of the negative binomial success probability based on conjugate priors <lb/></body>

			<page>10 <lb/></page>

			<body>seems like an obvious question, we were unable to nd this result in the literature. (A direct <lb/>computation of the generalized Bayes risk shows that it is nite, but P-admissibility implies <lb/>that admissibility also holds for every bounded transform of .) <lb/>Finally, the transition density for theR-chain is given bá»¹ <lb/>R(yjx) = ?(y + k)?(k + a + b + x)?(2k + a)?(b + x + y) <lb/>y!?(k)?(k + a)?(b + x)?(2k + a + b + x + y) <lb/>for y; x 2 f0; 1; 2; : : : g. It is called the generalized Waring distribution (Johnson, Kotz and <lb/>Kemp, 1992, p.242). When b and k are positive integers and a 2 f?k+1; ?k+2; : : : ; ?1; 0g, <lb/>theR-chain has a Polya urn representation (Panaretos and Xekalaki, 1986). Suppose that <lb/>V t represents the current state of the Markov chain. Consider an urn containing k + a <lb/>white balls and k black balls. A ball is drawn at random, its color is noted, and the ball <lb/>is replaced along with one additional ball of the same color before the next ball is drawn. <lb/>This procedure is continued until V t + b white balls have been drawn, and V t+1 is de ned <lb/>to be the number of black balls drawn before the (V t + b)th white ball is drawn. Note that <lb/>a negative value of a would mean more black balls than white at the start. Thus, it makes <lb/>sense that the chain is recurrent when a = 0 and transient when a is negative. <lb/> 5 Discussion <lb/>We have shown that Eaton&apos;s (1992) Markov chain is recurrent if and only if its conjugate <lb/>partner is recurrent. This result may be viewed as an extension of Diebolt and Robert&apos;s <lb/>(1994) Duality Principle. It is interesting from a theoretical standpoint in that Eaton&apos;s <lb/>(1992) results can now be viewed as concerning a Markov chain on the sample space, which <lb/>is the domain of the chains constructed Brown (1971) and Johnstone (1984). From a <lb/>practical point of view, this result is useful because it allows one to prove P-admissibility <lb/>by establishing the recurrence of theR-chain, which can be much easier than doing the <lb/>same for the R-chain. Finally, we have used Eaton&apos;s (1992) theory and our extensions <lb/>to establish that certain priors for the gamma scale parameter and the negative binomial <lb/>success probability are P-admissible. <lb/>As Eaton (1992, p.1170) pointed out, it is unknown whether or not P-admissibility of <lb/>implies recurrence of the R-chain. However, the condition C is based on Blyth&apos;s (1951) <lb/>su cient condition, and Farrell (1968) has shown that, under some additional assumptions, <lb/>Blyth&apos;s condition is also necessary. This result suggests that C may also be necessary and <lb/>su cient under appropriate assumptions. <lb/></body>

			<listBibl>References <lb/>Babillot, M., Bougerol, P. and Elie, L. (1997). The random di erence equation X n = <lb/>A n X n?1 + B n in the critical case, The Annals of Probability 25: 478{493. <lb/>Berger, J. O. (1980). Improving on inadmissible estimators in continuous exponential fam-<lb/>ilies with applications to simultaneous estimation of gamma scale parameters, The <lb/>Annals of Statistics 8: 545{571. <lb/></listBibl>

			<page>11 <lb/></page>

			<listBibl>Berger, J. O. (1985). Statistical Decision Theory and Bayesian Analysis, Springer-Verlag, <lb/>New York. <lb/>Blyth, C. R. (1951). On minimax statistical decision procedures and their admissibility, <lb/>The Annals of Mathematical Statistics 22: 22{42. <lb/>Brandt, A. (1986). The stochastic equation Y n+1 = A n Y n + B n with stationary coe cients, <lb/>Advances in Applied Probability 18: 211{220. <lb/>Brown, L. D. (1971). Admissible estimators, recurrent di usions, and insoluble boundary <lb/>value problems, The Annals of Mathematical Statistics 42: 855{904. <lb/>Das Gupta, A. (1984). Admissibility in the gamma distribution: Two examples, Sankhy a, <lb/>Series A 46: 395{407. <lb/>Diebolt, J. and Robert, C. P. (1994). Estimation of nite mixture distributions by Bayesian <lb/>sampling, Journal of the Royal Statistical Society, Series B 56: 363{375. <lb/>Eaton, M. L. (1982). A method for evaluating improper prior distributions, in S. S. Gupta <lb/>and J. O. Berger (eds), Statistical Decision Theory and Related Topics III, Vol. 1, <lb/>Academic, New York. <lb/>Eaton, M. L. (1992). A statistical diptych: Admissible inferences-recurrence of symmetric <lb/>Markov chains, The Annals of Statistics 20: 1147{1179. <lb/>Farrell, R. H. (1968). On a necessary and su cient condition for admissibility of estimators <lb/>when strictly convex loss is used, The Annals of Mathematical Statistics 38: 23{28. <lb/>Feller, W. (1968). An Introduction to Probability Theory and its Applications, Vol. I, 3rd. <lb/>edn, John Wiley &amp; Sons, New York. <lb/>Feller, W. (1971). An Introduction to Probability Theory and its Applications, Vol. II, 2nd. <lb/>edn, John Wiley &amp; Sons, New York. <lb/>Hwang, J. T. (1982a). Improving upon standard estimators in discrete exponential families <lb/>with applications to Poisson and negative binomial cases, The Annals of Statistics <lb/>10: 857{867. <lb/>Hwang, J. T. (1982b). Semi tail upper bounds on the class of admissible estimators in <lb/>discrete exponential families with applications to Poisson and negative binomial dis-<lb/>tributions, The Annals of Statistics 10: 1137{1147. <lb/>Johnson, N. L., Kotz, S. and Kemp, A. W. (1992). Univariate Discrete Distributions, 2nd <lb/>edn, John Wiley &amp; Sons, New York. <lb/>Johnstone, I. (1984). Admissibility, di erence equations, and recurrence in estimating a <lb/>Poisson mean, The Annals of Statistics 12: 1173{1198. <lb/></listBibl>

			<page>12 <lb/></page>

			<listBibl>Johnstone, I. (1986). Admissible estimation, Dirichlet principles, and recurrence of birth-<lb/>death chains on Z p <lb/>t , Probability Theory and Related Fields 71: 231{269. <lb/>Kersting, G. (1986). On recurrence and transience of growth models, Journal of Applied <lb/>Probability 23: 614{625. <lb/>Lamperti, J. (1960). Criteria for the recurrence or transience of stochastic processes, I, <lb/>Journal of Mathematical Analysis and Applications 1: 314{330. <lb/>Lehmann, E. L. (1983). Theory of Point Estimation, Wadsworth &amp; Brook/Cole, Paci c <lb/>Grove, CA. <lb/>Liu, J. S., Wong, W. H. and Kong, A. (1994). Covariance structure of the Gibbs sampler with <lb/>applications to the comparisons of estimators and augmentation schemes, Biometrika <lb/>81: 27{40. <lb/>Meyn, S. P. and Tweedie, R. L. (1993). Markov Chains and Stochastic Stability, Springer-<lb/>Verlag, London. <lb/>Pakes, A. G. (1971). On the critical Galton-Watson process with immigration, Journal of <lb/>the Australian Mathematical Society 12: 476{482. <lb/>Panaretos, J. and Xekalaki, E. (1986). On some distributions arising from certain general-<lb/>ized sampling schemes, Communications in Statistics, Part A -Theory and Methods <lb/>15: 873{891. <lb/>Stein, C. (1965). Approximation of improper prior measures by prior probability measures, <lb/>in J. Neyman and L. Le Cam (eds), Bernoulli-Bayes-Laplace Festschrift, Springer-<lb/>Verlag, New York, pp. 217{240. <lb/>Tanner, M. A. and Wong, W. H. (1987). The calculation of posterior distributions by <lb/>data augmentation (with discussion), Journal of the American Statistical Association <lb/>52: 528{550. <lb/></listBibl>

			<page>13 </page>


	</text>
</tei>
