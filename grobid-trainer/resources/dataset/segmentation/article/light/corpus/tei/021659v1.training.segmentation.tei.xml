<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="_0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>A simple method for automated equilibration detection in molecular simulations <lb/>John D. Chodera , * <lb/>Computational Biology Program, Sloan Kettering Institute, <lb/>Memorial Sloan Kettering Cancer Center, New York, NY <lb/>(Dated: June , <lb/>) <lb/>Molecular simulations intended to compute equilibrium properties are o en initiated from configurations <lb/>that are highly atypical of equilibrium samples, a practice which can generate a distinct initial transient <lb/>in mechanical observables computed from the simulation trajectory. Traditional practice in simulation <lb/>data analysis recommends this initial portion be discarded to equilibration, but no simple, general, and <lb/>automated procedure for this process exists. Here, we suggest a conceptually simple automated procedure <lb/>that does not make strict assumptions about the distribution of the observable of interest, in which the <lb/>equilibration time is chosen to maximize the number of e ectively uncorrelated samples in the production <lb/>timespan used to compute equilibrium averages. We present a simple Python reference implementation of <lb/>this procedure, and demonstrate its utility on typical molecular simulation data. <lb/>Keywords: molecular dynamics (MD); Metropolis-Hastings; Monte Carlo (MC); Markov chain Monte Carlo <lb/>(MCMC); equilibration; burn-in; timeseries analysis; statistical ine iciency; integrated autocorrelation time <lb/></front>

			<body>INTRODUCTION <lb/>Molecular simulations use Markov chain Monte Carlo <lb/>(MCMC) techniques [ ] to sample configurations x from an <lb/>equilibrium distribution π(x), either exactly (using Monte <lb/>Carlo methods such as Metropolis-Hastings) or approx-<lb/>imately (using molecular dynamics integrators without <lb/>Metropolization) [ ]. <lb/>Due to the sensitivity of the equilibrium probability den-<lb/>sity π(x) to small perturbations in configuration x and the <lb/>di iculty of producing su iciently good guesses of typical <lb/>equilibrium configurations x ∼ π(x), these molecular sim-<lb/>ulations are o en started from highly atypical initial con-<lb/>ditions. For example, simulations of biopolymers might be <lb/>initiated from a fully extended conformation unrepresenta-<lb/>tive of behavior in solution, or a geometry derived from a fit <lb/>to di raction data collected from a cryocooled crystal; sol-<lb/>vated systems may be prepared by periodically replicating <lb/>a small solvent box equilibrated under di erent conditions, <lb/>yielding atypical densities and solvent structure; liquid mix-<lb/>tures or lipid bilayers may be constructed by using methods <lb/>that fulfill spatial constraints (e.g. PackMol [ ]) but create lo-<lb/>cally aytpical geometries, requiring long simulation times to <lb/>relax to typical configurations. <lb/>As a result, traditional practice in molecular simulation <lb/>has recommended some initial portion of the trajectory be <lb/>discarded to equilibration (also called burn-in in the MCMC <lb/>literature [ ]). While the process of discarding initial sam-<lb/>ples is strictly unnecessary for the time-average of quanti-<lb/>ties of interest to eventually converge to the desired expec-<lb/>tations [ ], this nevertheless o en allows the practitioner to <lb/>avoid what may be impractically long run times to eliminate <lb/>the bias in computed properties in finite-length simulations <lb/></body>

			<front> * Corresponding author; john.chodera@choderalab.org <lb/></front>

			<note place="footnote">The term burn-in comes from the field of electronics, in which a <lb/>short &quot;burn-in&quot; period is used to ensure that a device is free of faulty <lb/>components-which o en fail quickly-and is operating normally [ ]. <lb/></note>

			<body>induced by atypical initial starting conditions. It is worth <lb/>noting that a similar procedure is not a practice universally <lb/>recommended by statisticians when sampling from poste-<lb/>rior distributions in statistical inference [ ]; the di erences <lb/>in complexity of probability densities typically encountered <lb/>in statistics and molecular simulation may explain the dif-<lb/>ference in historical practice. <lb/>As a motivating example, consider the computation of <lb/>the average density of liquid argon under a given set of re-<lb/>duced temperature and pressure conditions shown in Fig-<lb/>ure . To initiate the simulation, an initial dense liquid ge-<lb/>ometry at reduced density ρ * ≡ ρσ 3 = 0.960 was pre-<lb/>pared and subjected to local energy minimization. The up-<lb/>per panel of Figure depicts the average relaxation behav-<lb/>ior of simulations initiated from the same configuration with <lb/>di erent random initial velocities and integrator random <lb/>number seeds (see Simulation Details). The average (black <lb/>line) and % confidence interval (shaded grey) of <lb/>re-<lb/>alizations of this process show a characteristic relaxation <lb/>behavior away from the initial density toward the equilib-<lb/>rium density. The expectation of the running average of the <lb/>density over many realizations of this procedure (Figure , <lb/>lower panel) significantly deviates from the true expecta-<lb/>tion (dashed line), leading to significantly biased estimates <lb/>of the expectation unless simulations are su iciently long to <lb/>eliminate this starting point dependent bias-a surprisingly <lb/>long ns in this case. Note that this bias is present even in <lb/>the average of many realizations because the same atypical <lb/>starting condition is used for every realization of this simu-<lb/>lation process. <lb/>
			STATEMENT OF THE PROBLEM <lb/>Consider T successively sampled configurations x t from <lb/>a molecular simulation, with t = 1, . . . , T . We presume we <lb/>are interested in computing the expectation <lb/>A ≡ dx A(x) π(x) <lb/>( ) <lb/>0.75 <lb/>0.80 <lb/>0.85 <lb/>0.90 <lb/>0.95 <lb/>1.00 <lb/>reduced density ρ * <lb/>0 <lb/>10 <lb/>20 <lb/>30 <lb/>40 <lb/>50 <lb/>simulation time / ns <lb/>0.75 <lb/>0.80 <lb/>0.85 <lb/>0.90 <lb/>0.95 <lb/>1.00 <lb/>reduced density ρ * <lb/>true expectation <lb/>cumulative average <lb/>discarding first 100 samples to equilibration <lb/>FIG. 1. Illustration of the motivation for discarding data to equilibration. To illustrate the bias in expectations induced by relax-<lb/>ation away from initial conditions, <lb/>replicates of a simulation of liquid argon were initiated from the same energy-minimized initial <lb/>configuration constructed with initial reduced density ρ * ≡ ρσ 3 = 0.960 but di erent random number seeds for stochastic integration. <lb/>Top: The average of the reduced density (black line) over the replicates relaxes to the region of typical equilibrium densities over the first <lb/>few ns of simulation time. Bottom: If the average density is estimated by a cumulative average from the beginning of the simulation (red <lb/>dotted line), the estimate will be heavily biased by the atypical starting density even beyond ns. Discarding even a small amount of <lb/>initial data-in this case <lb/>initial samples (∼ . ns, blue solid line)-results in a cumulative average estimate that converges to the true <lb/>average (black dashed line) much more rapidly. Shaded regions denote % confidence intervals. <lb/>0 <lb/>25 <lb/>50 <lb/>75 <lb/>100 <lb/>125 <lb/>g <lb/>/ iterations <lb/>0 <lb/>10 <lb/>20 <lb/>30 <lb/>40 <lb/>50 <lb/>N <lb/>eff <lb/>0 <lb/>2 <lb/>4 <lb/>6 <lb/>8 <lb/>10 <lb/>12 <lb/>14 <lb/>initial simulation time t 0 / ns <lb/>0.778 <lb/>0.782 <lb/>0.786 <lb/>0.790 <lb/>0.794 <lb/>ρ * <lb/>[t <lb/>0 ,T] <lb/>true expectation <lb/>discarding initial [0,t 0 ] <lb/>FIG. 2. Statistical ine iciency, number of uncorrelated samples, and bias for di erent equilibration times. Trajectories of length <lb/>T = <lb/>iterations (∼ ns) for the argon system described in Fig. were analyzed as a function of equilibration time choice t0. Averages <lb/>over all <lb/>replicate simulations (all starting from the same initial conditions) are shown as dark lines, with shaded lines showing standard <lb/>deviation of estimates among replicates. Top: The statistical ine iciency g as a function of equilibration time choice t0 is initially very <lb/>large, but diminishes rapidly a er the system has relaxed to equilibrium. Middle: The number of e ectively uncorrelated samples N eff = <lb/>(T − t0 + 1)/g shows a maximum at t0 ∼ 200 iterations (∼ ns), suggesting the system has equilibrated by this time. The red vertical line <lb/>in all plots marks this choice of t0 ∼ 200. Bottom: The cumulative density average ρ * computed over the span [t0, T ] shows that the <lb/>bias (deviation from the true estimate, shown as red dashed lines) is minimized for choices of t0 ≥ 200 iterations (∼ ns). The standard <lb/>deviation among replicates (shaded region) grows with t0 because fewer data are included in the estimate. The choice of optimal t0 that <lb/>maximizes N eff (red vertical line) strikes a good balance between bias and variance. The true estimate (red dashed lines) is computed <lb/>from averaging over the range [ <lb/>, <lb/>] iterations over all <lb/>replicates. <lb/>of a mechanical property A(x). For convenience, we will re-<lb/>fer to the timeseries a t ≡ A(x t ), with t ∈ [1, T ]. The esti-<lb/>mator Â ≈ A constructed from the entire dataset is given <lb/>by <lb/>Â[1,T ] ≡ <lb/>1 <lb/>T <lb/>T <lb/>t=1 <lb/>a t . <lb/>( ) <lb/>While lim T →∞ Â[1,T ] = A for an infinitely long simula-<lb/>tion , the bias in Â[1,T ] may be significant in a simulation of <lb/>finite length T . <lb/>By discarding samples t &lt; t 0 to equilibration, we hope to <lb/>exclude the initial transient from our sample average, and <lb/>provide a less biased estimate of A , <lb/>Â[t0,T ] ≡ <lb/>1 <lb/>T − t 0 + 1 <lb/>T <lb/>t=t0 <lb/>a t . <lb/>( ) <lb/>We can quantify the overall error in an estimator Â in <lb/>a sample average that starts at x 0 and excludes samples <lb/>where t &lt; t 0 by the expected error δ 2 Â, <lb/>δ 2 Â ≡ E x0 <lb/>Â[t0,T ] − A <lb/>2 <lb/>( ) <lb/>= E x0 <lb/>Â − E x0 [ Â[t0,T ] ] <lb/>2 <lb/>+ E x0 [ Â[t0,T ] ] − A <lb/>2 <lb/>where E x0 [•] denotes the expectation over independent re-<lb/>alizations of the specific simulation process initiated from <lb/>configuration x 0 , but with di erent velocities and random <lb/>number seeds. <lb/>The first term denotes the variance in the estimator Â, <lb/>var x0 ( Â[t0,T ] ) ≡ E x0 Â[t0,T ] − E x0 [ Â[t0,T ] ] <lb/>2 <lb/>( ) <lb/>while the second term denotes the contribution from the <lb/>squared bias, <lb/>bias 2 <lb/>x0 ( Â[t0,T ] ) ≡ E x0 [ Â[t0,T ] ] − A <lb/>2 <lb/>( ) <lb/>
			BIAS-VARIANCE TRADEOFF <lb/>With increasing equilibration time t 0 , bias is reduced, but <lb/>the variance-the contribution to error due to random varia-<lb/>tion from having a finite number of uncorrelated samples-<lb/>will increase because less data is included in the estimate. <lb/>This can be seen in the bottom panel of Figure , where the <lb/>shaded region (denoting the % confidence interval of the <lb/></body>

			<note place="footnote">We note that this equality only holds for simulation schemes that sam-<lb/>ple from the true equilibrium density π(x), such as Metropolis-Hastings <lb/>Monte Carlo or Metropolized dynamical integration schemes such as hy-<lb/>brid Monte Carlo (HMC). Molecular dynamics simulations utilizing finite <lb/>timestep integration without Metropolization will produce averages that <lb/>may deviate from the true expectation A [ ]. <lb/></note>

			<body>mean, computed from twice the standard deviation among <lb/>sample estimates) increases in width with increasing equili-<lb/>bration time t 0 . <lb/>To examine the tradeo between bias and variance ex-<lb/>plicitly, Figure plots the bias and variance (here, shown as <lb/>standard error) contributions against each other as a func-<lb/>tion of t 0 (denoted by color) as computed from statistics <lb/>over all <lb/>replicates. At t 0 = 0, the bias is large but <lb/>variance is minimized. With increasing t 0 , bias is eventu-<lb/>ally eliminated but then variance rapidly grows as fewer un-<lb/>correlated samples are included in the estimate. There is a <lb/>clear optimal choice at t 0 ∼ 150 iterations that minimizes <lb/>variance while also e ectively eliminating bias. <lb/>
			SELECTING THE EQUILIBRATION TIME <lb/>Is there a simple approach to choosing an optimal equi-<lb/>libration time t 0 that provides a significantly improved es-<lb/>timate Â[t0,T ] , even when we do not have access to multi-<lb/>ple realizations of the same process? At worst, we hope that <lb/>such a procedure would at least give some improvement <lb/>over the naive estimate, such that δ 2 <lb/>Â[t0,T ] &lt; δ 2 <lb/>Â[1,T ] ; <lb/>at best, we hope that we can achieve a reasonable bias-<lb/>variance tradeo close to the optimal point identified in Fig-<lb/>ure that minimizes bias without greatly increasing vari-<lb/>ance. We remark that, for cases in which the simulation is <lb/>not long enough to reach equilibrium, no choice of t 0 will <lb/>eliminate bias completely; the best we can hope for is to <lb/>minimize this bias. <lb/>While several automated methods for selecting the equili-<lb/>bration time t 0 have been proposed, these approaches have <lb/>shortcomings that have greatly limited their use. The re-<lb/>verse cumulative averaging method [ ], for example, uses <lb/>a statistical test for normality to determine the point be-<lb/>fore which which the observable timeseries deviates from <lb/>normality. While this concept may be reasonable for ex-<lb/>perimental data, where measurements o en represent the <lb/>sum of many random variables such that the central limit <lb/>theorem&apos;s guarantee of asymptotic normality ensures the <lb/>distribution of the observable will be approximately nor-<lb/>mal, there is no such guarantee that instantaneous mea-<lb/>surements of a simulation property of interest will be nor-<lb/>mally distributed. In fact, many properties will be decidedly <lb/>non-normal. For a biomolecule such as a protein, for exam-<lb/>ple, the radius of gyration, end-to-end distance, and torsion <lb/>angles sampled during a simulation will all be highly non-<lb/>normal. Instead, we require a method that makes no as-<lb/>sumptions about the nature of the distribution of the prop-<lb/>erty under study. <lb/>
			AUTOCORRELATION ANALYSIS <lb/>The set of successively sampled configurations {x t } and <lb/>their corresponding observables {a t } compose a correlated <lb/>timeseries of observations. To estimate the statistical er-<lb/>ror or uncertainty in a stationary timeseries free of bias, <lb/>we must be able to quantify the e ective number of un-<lb/>correlated samples present in the dataset. This is usually <lb/>accomplished through computation of the statistical ine i-<lb/>ciency g, which quantifies the number of correlated time-<lb/>series samples needed to produce a single e ectively un-<lb/>correlated sample of the observable of interest. While these <lb/>concepts are well-established for the analysis of both Monte <lb/>Carlo and molecular dynamics simulations [ -], we re-<lb/>view them here for the sake of clarity. <lb/>For a given equilibration time choice t 0 , the statistical un-<lb/>certainty in our estimator Â[t0,T ] can be written as, <lb/>δ 2 <lb/>Â[t0,T ] ≡ E x0 <lb/>Â[t0,T ] − Â <lb/>2 <lb/>= E x0 <lb/>Â2 <lb/>[t0,T ] − E x0 Â[t0,T ] <lb/>2 <lb/>= <lb/>1 <lb/>T 2 <lb/>t0 <lb/>T <lb/>t,t =t0 <lb/>{E x0 [a t a t ] − E x0 [a t ] E x0 [a t ]} <lb/>= <lb/>1 <lb/>T 2 <lb/>t0 <lb/>T <lb/>t=t0 <lb/>E x0 x 2 <lb/>t − E x0 [x t ] <lb/>2 <lb/>( ) <lb/>+ <lb/>1 <lb/>T 2 <lb/>t0 <lb/>T <lb/>t =t =t0 <lb/>{E x0 [a t a t ] − E x0 [a t ] E x0 [a t ]} , <lb/>where T t0 ≡ T − t 0 + 1, the number of correlated samples <lb/>in the timeseries {a t } T <lb/>t0 . In the last step, we have split the <lb/>double-sum into two separate sums-a term capturing the <lb/>variance in the observations a t , and a remaining term cap-<lb/>turing the correlation between observations. <lb/>If t 0 is su iciently large for the initial bias to be eliminated, <lb/>the remaining timeseries {a t } T <lb/>t0 will obey the properties of <lb/>both stationarity and time-reversibility, allowing us to write, <lb/>δ 2 Âequil <lb/>[t0,T ] = <lb/>1 <lb/>T t0 <lb/>a 2 <lb/>t − a t <lb/>2 <lb/>+ <lb/>2 <lb/>T t0 <lb/>T −t0 <lb/>n=1 <lb/>T t0 − n <lb/>T t0 <lb/>[ a t a t+n − a t a t+n ] <lb/>≡ <lb/>σ 2 <lb/>t0 <lb/>T t0 <lb/>(1 + 2τ t0 ) = <lb/>σ 2 <lb/>t0 <lb/>T t0 /g t0 <lb/>, <lb/>( ) <lb/>where the variance σ 2 , statistical ine iciency g, and inte-<lb/>grated autocorrelation time τ (in units of the sampling in-<lb/>terval) are given by <lb/>σ 2 ≡ a 2 <lb/>t − a t <lb/>2 , <lb/>( ) <lb/>τ ≡ <lb/>T −1 <lb/>t=1 <lb/>1 − <lb/>t <lb/>T <lb/>C t , <lb/>( ) <lb/>g ≡ 1 + 2τ , <lb/>( ) <lb/>with the discrete-time normalized fluctuation autocorrela-<lb/>tion function C t defined as <lb/>C t ≡ <lb/>a n a n+t − a n <lb/>2 <lb/>a 2 <lb/>n − a n 2 . <lb/>( ) <lb/>In practice, it is di icult to estimate C t for t ∼ T , due to <lb/>growth in the statistical error, so common estimators of g <lb/>make use of several additional properties of C t to provide <lb/>useful estimates (see Practical Computation of Statistical In-<lb/>e iciencies). <lb/>The t 0 subscript for the variance σ 2 , the integrated auto-<lb/>correlation time τ , and the statistical ine iciency t 0 mean <lb/>that these quantities are only estimated over the production <lb/>portion of the timeseries, {a t } T <lb/>t=t0 . Since we assumed that <lb/>the bias was eliminated by judicious choice of the equilibra-<lb/>tion time t 0 , this estimate of the statistical error will be poor <lb/>for choices of t 0 that are too small. <lb/>
			THE ESSENTIAL IDEA <lb/>Suppose we choose some arbitrary time t 0 and discard <lb/>all samples t ∈ [0, t 0 ) to equilibration, keeping [t 0 , T ] as the <lb/>dataset to analyze. How much data remains? We can deter-<lb/>mine this by computing the statistical ine iciency g t0 for the <lb/>interval [t 0 , T ], and computing the e ective number of un-<lb/>correlated samples N eff (t 0 ) ≡ (T − t 0 + 1)/g t0 . If we start <lb/>at t 0 ≡ T and move t 0 to earlier and earlier points in time, <lb/>we expect that the e ective number of uncorrelated sam-<lb/>ples N eff (t 0 ) will continue to grow until we start to include <lb/>the highly atypical initial data. At that point, the integrated <lb/>autocorrelation time τ (and hence the statistical ine iciency <lb/>g) will greatly increase, and the e ective number of samples <lb/>N eff will start to plummet. <lb/>Figure demonstrates the application of this concept to <lb/>the liquid argon system described above, using averages of <lb/>the statistical ine iciency g t0 and N eff (t 0 ) computed over <lb/>independent replicate trajectories. At short t 0 , the aver-<lb/>age statistical ine iciency g (Figure , top panel) is large due <lb/>to the contribution from slow relaxation from atypical initial <lb/>conditions, while at long t 0 the statistical ine iciency esti-<lb/>mate is much shorter and nearly constant of a large span of <lb/>time origins. As a result, the average e ective number of un-<lb/>correlated samples N eff (Figure , middle panel) has a peak <lb/>at t 0 ∼ 222 iterations (Figure , vertical red lines). The ef-<lb/>fect on bias in the estimated average reduced density ρ * <lb/>(Figure , bottom panel) is striking-the bias is essentially <lb/>eliminated for the choice of equilibration time t 0 that maxi-<lb/>mizes the number of uncorrelated samples N eff . <lb/>This suggests an alluringly simple algorithm for identify-<lb/>ing the optimal equilibration time-pick the t 0 which maxi-<lb/>mizes the number of uncorrelated samples N eff . In mathe-<lb/>matical terms, <lb/>t opt <lb/>0 <lb/>= argmax <lb/>t0 <lb/>N eff (t 0 ) <lb/>( ) <lb/>= argmax <lb/>t0 <lb/>T − t 0 + 1 <lb/>g t0 <lb/>( ) <lb/>Bias-variance tradeo . But how will this strategy work <lb/>for cases where we do not know the statistical ine iciency g <lb/>as a function of the equilibration time t 0 precisely? When <lb/>all that is available is a single simulation, our best esti-<lb/>mate of g t0 is derived from that simulation alone over the <lb/>0.000 0.002 0.004 0.006 <lb/>bias <lb/>0.000 <lb/>0.002 <lb/>0.004 <lb/>0.006 <lb/>standard error <lb/>0 <lb/>200 <lb/>400 <lb/>600 <lb/>800 <lb/>1000 <lb/>1200 <lb/>1400 <lb/>1600 <lb/>1800 <lb/>FIG. 3. Bias-variance tradeo for fixed equilibration time <lb/>versus automatic equilibration time selection. Trajectories of <lb/>length T = <lb/>iterations (∼ ns) for the argon system de-<lb/>scribed in Fig. were analyzed as a function of equilibration time <lb/>choice t0, with colors denoting the value of t0 (in iterations) corre-<lb/>sponding to each plotted point. Using <lb/>replicate simulations, <lb/>the average bias (average deviation from true expectation) and <lb/>standard deviation (random variation from replicate to replicate) <lb/>were computed as a function of a prespecified fixed equilibration <lb/>time t0, with colors running from t0 = 0 (violet) to t0 = <lb/>iter-<lb/>ations (red). As is readily discerned, the bias for small t0 is initially <lb/>large, but minimized for larger t0. By contrast, the standard error (a <lb/>measure of variance, estimated here by standard deviation among <lb/>replicates) grows as t0 grows above a certain critical time (here, <lb/>∼ <lb/>iterations). If the t0 that maximizes N eff is instead chosen in-<lb/>dividually for each trajectory based on that trajectory&apos;s estimates <lb/>of statistical ine iciency g [t 0 ,T ] , the resulting bias-variance trade-<lb/>o (black triangle) does an excellent job minimizing bias and vari-<lb/>ance simultaneously, comparable to what is possible for a choice <lb/>of equilibration time t0 based on knowledge of the true bias and <lb/>variance among many replicate estimates. <lb/>span [t 0 , T ]-will this a ect the quality of our estimate of <lb/>equilibration time? Empirically, this does not appear to be <lb/>the case-the black triangle in Figure shows the bias and <lb/>variance contributions to the error for estimates computed <lb/>over the <lb/>replicates where t 0 is individually determined <lb/>from each simulation using this simple scheme based on se-<lb/>lecting t 0 to maximize N eff for each individual realization. <lb/>Despite not having knowledge about multiple realizations, <lb/>this strategy e ectively achieves a near-optimal balance be-<lb/>tween minimizing bias without increasing variance. <lb/>Overall RMS error. How well does this strategy perform <lb/>in terms of decreasing the overall error δ Â[t0,T ] compared <lb/>to δ Â[1,T ] ? Fiigure compares the expected standard er-<lb/>ror (denoted δ Â in the figure) as a function of a fixed initial <lb/>equilibration time t 0 (black line with shaded region denot-<lb/>ing % confidence interval) with the strategy of selecting t 0 <lb/>to maximize N eff for each realization (red line with shaded <lb/>region denoted % confidence interval). While the mini-<lb/>mum error for the fixed-t 0 strategy ( . <lb/>± . <lb/>) is <lb/>achieved in the range of -ns-a fact that could only be de-<lb/>termined from knowledge of multiple realizations-the sim-<lb/>ple strategy of selecting t 0 using Eq. achieves a minimum <lb/>error that is only % worse (compared to % worse should <lb/>no data have been discarded). While this is certainly statis-<lb/>tically significant in being worse than the optimal t 0 given <lb/>all <lb/>replicates, it is remarkably good for a simple method <lb/>employing data from a single simulation. <lb/>DISCUSSION <lb/>The scheme described here-in which the equilibration <lb/>time t 0 is computed using Eq. as the choice that maxi-<lb/>mizes the number of uncorrelated samples in the produc-<lb/>tion region [t 0 , T ]-is both conceptually and computation-<lb/>ally straightforward. It provides an approach to determining <lb/>the optimal amount of initial data to discard to equilibration <lb/>in order to minimize variance while also minimizing initial <lb/>bias, and does this without employing statistical tests that <lb/>require generally unsatisfiable assumptions of normality of <lb/>the observable of interest. As we have seen, this scheme em-<lb/>pirically appears to select a practical compromise between <lb/>bias and variance even when the statistical ine iciency g is <lb/>estimated directly from the trajectory using Eq. . <lb/>A word of caution is necessary. One can certainly envision <lb/>pathological scenarios where this algorithm for selecting an <lb/>optimal equilibration time will break down. In cases where <lb/>the simulation is not long enough to reach equilibrium-let <lb/>alone collect many uncorrelated samples from it-no choice <lb/>of equilibration time will bestow upon the experimenter the <lb/>ability to produce an unbiased estimate of the true expecta-<lb/>tion. Similarly, in cases where insu icient data is available <lb/>for the statistical ine iciency to be estimated well, this al-<lb/>gorithm is expected to perform poorly. However, in these <lb/>cases, the data itself should be suspect if the trajectory is <lb/>not at least an order of magnitude longer than the minimum <lb/>estimated autocorrelation time. <lb/>
			SIMULATION DETAILS <lb/>All molecular dynamics simulations described here were <lb/>performed with OpenMM . [ ] (available at openmm.org) <lb/>using the Python API. All scripts used to retrieve the so ware <lb/>versions used here, run the simulations, analyze data, and <lb/>generate plots-along with the simulation data itself and <lb/>scripts for generating figures-are available on GitHub . <lb/></body>

			<note place="footnote">All Python scripts necessary to reproduce this work-along with data <lb/>plotted in the published version-are available at: <lb/>http://github.com/choderalab/automatic-equilibration-detection <lb/></note>

			<body>0 <lb/>2 <lb/>4 <lb/>6 <lb/>8 <lb/>10 <lb/>12 <lb/>14 <lb/>t 0 / ns <lb/>0.000 <lb/>0.001 <lb/>0.002 <lb/>0.003 <lb/>0.004 <lb/>0.005 <lb/>0.006 <lb/>δ <lb/>Â <lb/>FIG. 4. RMS error for fixed equilibration time versus automatic equilibration time selection. Trajectories of length T = <lb/>iterations (∼ ns) for the argon system described in Fig. were analyzed as a function of fixed equilibration time choice t0. Using <lb/>replicate simulations, the root-mean-squared (RMS) error (Eq. ) was computed (black line) along with % confidence interval (gray <lb/>shading). The RMS error is minimized for fixed equilibration time choices in the range -ns. If the t0 that maximizes N eff is instead <lb/>chosen individually for each trajectory based on that trajectory&apos;s estimated statistical ine iciency g [t 0 ,T ] using Eq. , the resulting RMS <lb/>error (red line, % confidence interval shown as red shading) is quite close to the minimum RMS error achieved from any particular fixed <lb/>choice of equilibration time t0, suggesting that this simple automated approach to selecting t0 achieves close to optimal performance. <lb/>The LennardJonesFluid model system in the openmm-<lb/>tools package was used with parameters appropriate for <lb/>liquid argon (σ = . Å, = . <lb/>kcal/mol), though all <lb/>results are reported in reduced (universal) units. A cubic <lb/>switching function was employed, with the potential gen-<lb/>tly switched to zero over r ∈ [σ, 3σ], and a long-range <lb/>isotropic dispersion correction accounting for this switch-<lb/>ing behavior used to include neglected contributions. Sim-<lb/>ulations were performed using a periodic box of N = 500 <lb/>atoms at reduced temperature T * ≡ k B T / = 0.850 and <lb/>reduced pressure p * ≡ pσ 3 / = 1.266 using a Langevin <lb/>integrator [ ] with timestep ∆t = 0.01τ and collision <lb/>rate ν = 1.5τ −1 , with characteristic oscillation timescale <lb/>τ = <lb/>mr 2 <lb/>0 /72 and r 0 = 2 1/6 σ [ ]. A molecular scal-<lb/>ing Metropolis Monte Carlo barostat with Gaussian simu-<lb/>lation volume change proposal moves attempted every <lb/>timesteps, along with an adaptive algorithm that adjusts <lb/>the proposal width during the initial part of the simula-<lb/>tion [ ]. Densities were recorded every <lb/>timesteps, with <lb/>each set of <lb/>timesteps termed an &quot;iteration&quot; of the sim-<lb/>ulation. The true expectation ρ * was estimated from the <lb/>sample average over all <lb/>realizations over [ <lb/>, <lb/>] <lb/>iterations. <lb/>The automated equilibration detection scheme is also <lb/>available in the timeseries module of the pymbar pack-<lb/>age as detectEquilibration(), and can be accessed us-<lb/>ing the following code: <lb/>from pymbar.timeseries import detectEquilibration <lb/># determine equilibrated region <lb/>[t0, g, Neff_max] = detectEquilibration(A_t) <lb/># discard initial samples to equilibration <lb/>A_t = A_t[t0:] <lb/></body>

			<note place="footnote">available at http://github.com/choderalab/openmmtools <lb/></note>

			<body>PRACTICAL COMPUTATION OF STATISTICAL INEFFICIENCIES <lb/>The robust computation of the statistical ine iciency g <lb/>(defined by Eq. ) for a finite timeseries a t , t = 1, . . . , T <lb/>deserves some comment. There are, in fact, a variety of <lb/>schemes for estimating g described in the literature, and <lb/>their behaviors for finite datasets may di er, leading to dif-<lb/>ferent estimates of the equilibration time t 0 using the algo-<lb/>rithm of Eq. . <lb/>The main issue is that a straightforward approach to esti-<lb/>mating the statistical ine iciency using Eqs. -in which <lb/>the expectations are simply replaced with sample estimates <lb/>causes the statistical error in the estimated correlation func-<lb/>tion C t to grow with t in a manner that allows this error to <lb/>quickly overwhelm the sum of Eq. . As a result, a num-<lb/>ber of alternative schemes-generally based on controlling <lb/>the error in the estimated C t or truncating the sum of Eq. <lb/>when the error grows too large-have been proposed. <lb/>For stationary, irreducible, reversible Markov chains, <lb/>Geyer observed that a function Γ k ≡ γ 2k + γ 2k+1 of the <lb/>unnormalized fluctuation autocorrelation function γ t ≡ <lb/>a i a i+t − a i <lb/>2 has a number of pleasant properties (The-<lb/>orem . of [ ]): It is strictly positive, strictly decreasing, <lb/>and strictly convex. Some or all of these properties can be <lb/>exploited to define a family of estimators called initial se-<lb/>quence methods (see Section . of [ ] and Section . . <lb/>of [ ]), of which the initial convex sequence (ICS) estimator is <lb/>generally agreed to be optimal, if somewhat more complex <lb/>to implement. <lb/>All computations in this manuscript used the fast mul-<lb/>tiscale method described in Section . of [ ], which we <lb/>found performed equivalently well to the Geyer estimators <lb/>(data not shown). This method is related to a multiscale <lb/></body>

			<note place="footnote">Implementations of these methods are provided with the code dis-<lb/>tributed with this manuscript. <lb/></note>

			<body>variant of the initial positive sequence (IPS) method of Geyer <lb/>[ ], where contributions are accumulated at increasingly <lb/>longer lag times and the sum of Eq. is truncated when the <lb/>terms become negative. We have found this method to be <lb/>both fast and to provide useful estimates of the statistical <lb/>ine iciency, but it may not perform well for all problems. <lb/></body>

			<div type="acknowledgement">ACKNOWLEDGMENTS <lb/>We are grateful to William C. Swope (IBM Almaden Re-<lb/>search Center) for his illuminating introduction to the use <lb/>of autocorrelation analysis for the characterization of sta-<lb/>tistical error, as well as Michael R. Shirts (University of Vir-<lb/>ginia), David L. Mobley (University of California, Irvine), Kyle <lb/>A. Beauchamp (MSKCC), and Robert C. McGibbon (Stan-<lb/>ford University) for valuable discussions on this topic, and <lb/>Joshua L. Adelman (University of Pittsburgh) for helpful <lb/>feedback and encouragement. <lb/></div>

			<listBibl>[ ] J. S. Liu, Monte Carlo strategies in scientific computing, nd ed. <lb/>ed. (Springer-Verlag, New York, <lb/>). <lb/>[ ] D. Sivak, J. Chodera, and G. Crooks, Physical Review X , <lb/>( <lb/>), bibtex: Sivak: <lb/>:Phys.Rev.X. <lb/>[ ] L. Martínez, R. Andrade, E. G. Birgin, and J. M. Martínez, J. <lb/>Chem. Theor. Comput. , <lb/>( <lb/>). <lb/>[ ] S. Brooks, A. Gelman, G. L. Jones, and X.-L. Meng, in Hand-<lb/>book of Markov chain Monte Carlo, Chapman &amp; Hall/CRC Hand-<lb/>books of Modern Statistical Methods (CRC Press, ADDRESS, <lb/>), Chap. Introduction to Markov chain Monte Carlo. <lb/>[ ] C. Geyer, Burn-in is unnecessary., http://users.stat.umn. <lb/>edu/~geyer/mcmc/burn.html. <lb/>[ ] W. Yang, R. Bittetti-Putzer, and M. Karplus, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] H. Müller-Krumbhaar and K. Binder, J. Stat. Phys. , ( <lb/>). <lb/>[ ] W. C. Swope, H. C. Andersen, P. H. Berens, and K. R. Wilson, J. <lb/>Chem. Phys. , <lb/>( <lb/>). <lb/>[ ] W. Janke, in Quantum Simulations of Complex Many-Body Sys-<lb/>tems: From Theory to Algorithms, edited by J. Grotendorst, D. <lb/>Marx, and A. Murmatsu (John von Neumann Institute for Com-<lb/>puting, ADDRESS, <lb/>), Vol. , pp. <lb/>-<lb/>. <lb/>[ ] J. D. Chodera, W. C. Swope, J. W. Pitera, C. Seok, and K. A. Dill, <lb/>J. Chem. Theor. Comput. , ( <lb/>). <lb/>[ ] P. Eastman, M. Friedrichs, J. D. Chodera, R. Radmer, C. Bruns, <lb/>J. Ku, K. Beauchamp, T. J. Lane, L.-P. Wang, D. Shukla, T. Tye, <lb/>M. Houston, T. Stitch, and C. Klein, J. Chem. Theor. Comput. , <lb/>( <lb/>). <lb/>[ ] D. A. Sivak, J. D. Chodera, and G. E. Crooks, J. Phys. Chem. B <lb/>, <lb/>( <lb/>). <lb/>[ ] B. Veytsman and M. Kotelyanskii, Lennard-Jones poten-<lb/>tial revisited., http://borisv.lk.net/matsc597c-1997/ <lb/>simulations/Lecture5/node3.html. <lb/>[ ] C. J. Geyer, Stat. Sci. , <lb/>( <lb/>). <lb/>[ ] C. J. Geyer and E. A. Thompson, J. Royal Stat. Soc. B , <lb/>( <lb/>). </listBibl>


	</text>
</tei>
