<?xml version="1.0" ?>
<tei>
	<teiHeader>
		<fileDesc xml:id="__D08-1073"/>
	</teiHeader>
	<text xml:lang="en">
			<note place="footnote"> Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 698â€“706, <lb/>Honolulu, October 2008. c <lb/> 2008 Association for Computational Linguistics <lb/></note>

			<front> Jointly Combining Implicit Constraints Improves Temporal Ordering <lb/> Nathanael Chambers and Dan Jurafsky <lb/> Department of Computer Science <lb/>Stanford University <lb/>Stanford, CA 94305 <lb/> {natec,jurafsky}@stanford.edu <lb/> Abstract <lb/> Previous work on ordering events in text has <lb/>typically focused on local pairwise decisions, <lb/>ignoring globally inconsistent labels. How-<lb/>ever, temporal ordering is the type of domain <lb/>in which global constraints should be rela-<lb/>tively easy to represent and reason over. This <lb/>paper presents a framework that informs lo-<lb/>cal decisions with two types of implicit global <lb/>constraints: transitivity (A before B and B be-<lb/>fore C implies A before C) and time expression <lb/>normalization (e.g. last month is before yes-<lb/>terday). We show how these constraints can <lb/>be used to create a more densely-connected <lb/>network of events, and how global consis-<lb/>tency can be enforced by incorporating these <lb/>constraints into an integer linear programming <lb/>framework. We present results on two event <lb/>ordering tasks, showing a 3.6% absolute in-<lb/>crease in the accuracy of before/after classifi-<lb/>cation over a pairwise model. <lb/></front> 
			
			<body>1 Introduction <lb/> Being able to temporally order events is a neces-<lb/>sary component for complete document understand-<lb/>ing. Interest in machine learning approaches for this <lb/>task has recently been encouraged through the cre-<lb/>ation of the Timebank Corpus (Pustejovsky et al., <lb/>2003). However, most work on event-event order-<lb/>ing has focused on improving classifiers for pair-<lb/>wise decisions, ignoring obvious contradictions in <lb/>the global space of events when misclassifications <lb/>occur. A global framework to repair these event or-<lb/>dering mistakes has not yet been explored. <lb/>This paper addresses three main factors involved <lb/>in a global framework: the global optimization al-<lb/>gorithm, the constraints that are relevant to the task, <lb/>and the level of connectedness across pairwise de-<lb/>cisions. We employ Integer Linear Programming to <lb/>address the first factor, drawing from related work <lb/>in paragraph ordering (Bramsen et al., 2006). After <lb/>finding minimal gain with the initial model, we ex-<lb/>plore reasons for and solutions to the remaining two <lb/>factors through temporal reasoning and transitivity <lb/>rule expansion. <lb/>We analyze the connectivity of the Timebank Cor-<lb/>pus and show how textual events can be indirectly <lb/>connected through a time normalization algorithm <lb/>that automatically creates new relations between <lb/>time expressions. We show how this increased con-<lb/>nectivity is essential for a global model to improve <lb/>performance. <lb/>We present three progressive evaluations of our <lb/>global model on the Timebank Corpus, showing a <lb/> 3.6% gain in accuracy over its original set of re-<lb/>lations, and an 81% increase in training data size <lb/>from previous work. In addition, we present the first <lb/>results on Timebank that include an unknown rela-<lb/>tion, establishing a benchmark for performance on <lb/>the full task of document ordering. <lb/> 2 Previous Work <lb/> Recent work on classifying temporal relations <lb/>within the Timebank Corpus built 6-way relation <lb/>classifiers over 6 of the corpus&apos; 13 relations (Mani et <lb/>al., 2006; Mani et al., 2007; Chambers et al., 2007). <lb/>A wide range of features are used, ranging from sur-<lb/>face indicators to semantic classes. Classifiers make <lb/>

			<page>698 <lb/></page>

			local pairwise decisions and do not consider global <lb/>implications between the relations. <lb/>The TempEval-07 (Verhagen et al., 2007) contest <lb/>recently used two relations, before and after, in a <lb/>semi-complete textual classification task with a new <lb/>third relation to distinguish relations that can be la-<lb/>beled with high confidence from those that are un-<lb/>certain, called vague. The task was a simplified clas-<lb/>sification task from Timebank in that only one verb, <lb/>the main verb, of each sentence was used. Thus, the <lb/>task can be viewed as ordering the main events in <lb/>pairwise sentences rather than the entire document. <lb/>This paper uses the core relations of TempEval <lb/>(before,after,vague) and applies them to a full docu-<lb/>ment ordering task that includes every labeled event <lb/>in Timebank. In addition, we extend the previous <lb/>work by including a temporal reasoning component <lb/>and embedding it within a global constraint model. <lb/> 3 The Timebank Corpus <lb/> The Timebank Corpus (Pustejovsky et al., 2003) is <lb/>a corpus of 186 newswire articles that are tagged <lb/>for events, time expressions, and relations between <lb/>the events and times. The individual events are fur-<lb/>ther tagged for temporal information such as tense, <lb/>modality and grammatical aspect. Time expressions <lb/>use the TimeML (Ingria and Pustejovsky, 2002) <lb/>markup language. There are 6 main relations and <lb/>their inverses in Timebank: before, ibefore, includes, <lb/>begins, ends and simultaneous. <lb/> This paper describes work that classifies the re-<lb/>lations between events, making use of relations be-<lb/>tween events and times, and between the times <lb/>themselves to help inform the decisions. <lb/> 4 The Global Model <lb/> Our initial model has two components: (1) a pair-<lb/>wise classifier between events, and (2) a global con-<lb/>straint satisfaction layer that maximizes the confi-<lb/>dence scores from the classifier. The first is based <lb/>on previous work (Mani et al., 2006; Chambers et <lb/>al., 2007) and the second is a novel contribution to <lb/>event-event classification. <lb/> 4.1 Pairwise Classification <lb/> Classifying the relation between two events is the <lb/>basis of our model. A soft classification with confi-<lb/>dence scores is important for the global maximiza-<lb/>tion step that is described in the next section. As <lb/>in Chambers et al. (2007), we build support vec-<lb/>tor machine (SVM) classifiers and use the probabili-<lb/>ties from pairwise SVM decisions as our confidence <lb/>scores. These scores are then used to choose an op-<lb/>timal global ordering. <lb/>Following our previous work, we use the set of <lb/>features summarized in figure 1. They vary from <lb/>POS tags and lexical features surrounding the event, <lb/>to syntactic dominance, to whether or not the events <lb/>share the same tense, grammatical aspect, or aspec-<lb/>tual class. These features are the highest performing <lb/>set on the basic 6-way classification of Timebank. <lb/> Feature <lb/>Description <lb/>Word* <lb/>The text of the event <lb/>Lemma* <lb/>The lemmatized head word <lb/>Synset* <lb/>The WordNet synset of head word <lb/>POS* <lb/>4 POS tags, 3 before, and 1 event <lb/>POS bigram* The POS bigram of the event and its <lb/>preceding tag <lb/>Prep* <lb/>Preposition lexeme, if in a preposi-<lb/>tional phrase <lb/>Tense* <lb/>The event&apos;s tense <lb/>Aspect* <lb/>The event&apos;s grammatical aspect <lb/>Modal* <lb/>The modality of the event <lb/>Polarity* <lb/>Positive or negative <lb/>Class* <lb/>The aspecual class of the event <lb/>Tense Pair <lb/>The two concatenated tenses <lb/>Aspect Pair <lb/>The two concatenated aspects <lb/>Class Pair <lb/>The two concatenated classes <lb/>POS Pair <lb/>The two concatenated POS tags <lb/>Tense Match <lb/>true if the events have the same tense <lb/>Aspect Match true if the events have the same as-<lb/>pect <lb/>Class Match <lb/>true if the events have the same class <lb/>Dominates <lb/>true if the first event syntactically <lb/>dominates the second <lb/>Text Order <lb/>true if the first event occurs first in <lb/>the document <lb/>Entity Match <lb/>true if they share an entity as an ar-<lb/>gument <lb/>Same Sent <lb/>true if both events are in the same <lb/>sentence <lb/>Figure 1: The features to learn temporal relations be-<lb/>tween two events. Asterisks (*) indicate features that are <lb/>duplicated, one for each of the two events. <lb/> We use Timebank&apos;s hand tagged attributes in the <lb/>feature values for the purposes of this comparative <lb/>

			<page> 699 <lb/></page>

			before after unknown <lb/>A r1 B <lb/>.5 <lb/>.3 <lb/>.2 <lb/>B r2 C <lb/>.4 <lb/>.3 <lb/>.3 <lb/>A r3 C <lb/>.4 <lb/>.5 <lb/>.1 <lb/>total <lb/> 1.3 <lb/> 1.1 <lb/>.6 <lb/>A r1 B <lb/>.5 <lb/>.3 <lb/>.2 <lb/>B r2 C <lb/>.4 <lb/>.3 <lb/>.3 <lb/>A r3 C <lb/>.2 <lb/>.7 <lb/>.1 <lb/>total <lb/>1.1 <lb/> 1.3 <lb/> .6 <lb/> Figure 2: Two sets of confidence scores. The first set <lb/>chooses before for all three labels, and the second chooses <lb/> after. Other lower-scoring valid relation sets also exist, <lb/>such as before, unknown, and before. <lb/> study of global constraints, described next. <lb/> 4.2 Global Constraints <lb/> Pairwise classifiers can make contradictory classifi-<lb/>cations due to their inability to consider other deci-<lb/>sions. For instance, the following three decisions are <lb/>in conflict: <lb/> A before B <lb/>B before C <lb/>A after C <lb/> Transitivity is not taken into account. In fact, there <lb/>are several ways to resolve the conflict in this exam-<lb/>ple. Given confidence scores (or probabilities) for <lb/>each possible relation between the three pairs, we <lb/>can compute an optimal label assignment. Differ-<lb/>ent scores can lead to different conflict resolutions. <lb/>Figure 2 shows two resolutions given different sets <lb/>of scores. The first chooses before for all three rela-<lb/>tions, while the second chooses after. <lb/> Bramsen et al. (2006) presented a variety of ap-<lb/>proaches to using transitivity constraints to help in-<lb/>form pairwise decisions. They found that Integer <lb/>Linear Programming (ILP) performed the best on a <lb/>paragraph ordering task, consistent with its property <lb/>of being able to find the optimal solution for a set <lb/>of constraints. Other approaches are variations on <lb/>a greedy strategy of adding pairs of events one at a <lb/>time, ordered by their confidence. These can lead to <lb/>suboptimal configurations, although they are guar-<lb/>anteed to find a solution. Mani et al. (2007) sub-<lb/>sequently proposed one of these greedy strategies as <lb/>well, but published results are not available. We also <lb/>implemented a greedy best-first strategy, but found <lb/>ILP outperformed it. <lb/>Our Integer Linear Programming framework uses <lb/>the following objective function: <lb/> max <lb/> i <lb/> j <lb/> p  ij  x  ij <lb/> (1) <lb/>with added constraints: <lb/> âˆ€iâˆ€j x  ij  âˆˆ {0, 1} <lb/> (2) <lb/> âˆ€i x  i1  + x  i2  + ... + x  im  = 1 <lb/> (3) <lb/>where x  ij  represents the ith pair of events classified <lb/>as the jth relation of m relations. Thus, each pair <lb/>of events generates m variables. Given n pairs of <lb/>events, there are n  *  m variables. p  ij  is the proba-<lb/>bility of classifying pair i with relation j. Equation <lb/>2 (the first constraint) simply says that each variable <lb/>must be 0 or 1. Equation 3 contains m variables for <lb/>a single pair of events i representing its m possible <lb/>relations. It states that one relation must be set to 1 <lb/> and the rest to 0. In other words, a pair of events <lb/>cannot have two relations at the same time. Finally, <lb/>a transitivity constraint is added for all connected <lb/>pairs i, j, k, for each transitivity condition that infers <lb/>relation c given a and b: <lb/>x  ia  + x  jb  âˆ’ x  kc  &lt;= 1 <lb/> (4) <lb/>We generated the set of constraints for each doc-<lb/>ument and used lpsolve 1 to solve the ILP constraint <lb/>problem. <lb/>The transitivity constraints are only effective if <lb/>the available pairwise decisions constitute a con-<lb/>nected graph. If pairs of events are disconnected, <lb/>then transitivity makes little to no contribution be-<lb/>cause these constraints are only applicable to con-<lb/>nected chains of events. <lb/> 4.3 Transitive Closure <lb/> In order to connect the event graph, we draw on <lb/>work from (Mani et al., 2006) and apply transitive <lb/>closure to our documents. Transitive closure was <lb/>first proposed not to address the problem of con-<lb/>nected event graphs, but rather to expand the size <lb/>of training data for relations such as before. Time-<lb/>bank is a relatively small corpus with few examples <lb/>

			<note place="footnote"> 1 http://sourceforge.net/projects/lpsolve <lb/></note>

			<page> 700 <lb/></page>

			Total Event-Event Relations After Closure <lb/> before after <lb/> Timebank <lb/> 592 <lb/>656 <lb/>+ closure <lb/>3919 3405 <lb/> Figure 3: The number of event-event relations after tran-<lb/>sitive closure. <lb/> of each relation. One way of expand the training <lb/>set is through transitive rules. A few rules are given <lb/>here: <lb/> A simultaneous B âˆ§ A bef ore C â†’ B bef ore C <lb/>A includes B âˆ§ A ibef ore C â†’ B bef ore C <lb/>A bef ore B âˆ§ A ends C â†’ B af ter C <lb/> While the original motivation was to expand the <lb/>training size of tagged relations, this approach also <lb/>creates new connections in the graph, replacing pre-<lb/>viously unlabeled event pairs with their true rela-<lb/>tions. We adopted this approach and closed the orig-<lb/>inal set of 12 relations to help connect the global <lb/>constraint model. <lb/> 4.4 Initial Experiment <lb/> The first evaluation of our global temporal model <lb/>is on the Timebank Corpus over the labeled rela-<lb/>tions before and after. We merged ibefore and iafter <lb/> into these two relations as well, ignoring all oth-<lb/>ers. We use this task as a reduced evaluation to <lb/>study the specific contribution of global constraints. <lb/>We also chose this strict ordering task because it is <lb/>well defined from a human understanding perspec-<lb/>tive. Snow et al. (2008) shows that average inter-<lb/>net users can make before/after decisions with very <lb/>high confidence, although the distinction with an un-<lb/>known relation is not as clear. An evaluation includ-<lb/>ing unknown (or vague as in TempEval) is presented <lb/>later. <lb/>We expanded the corpus (prior to selecting the be-<lb/>fore/after relations) using transitive closure over all <lb/>12 relations as described above. Figure 3 shows the <lb/>increase in data size. The number of before and after <lb/> relations increase by a factor of six. <lb/>We trained and tested the system with 10-fold <lb/>cross validation and micro-averaged accuracies. The <lb/>folds were randomly generated to separate the 186 <lb/>files into 10 folds (18 or 19 files per fold). The same <lb/>10-way split is used for all the evaluations. We used <lb/> Comparative Results <lb/> Training Set <lb/>Accuracy <lb/>Timebank Pairwise <lb/> 66.8% <lb/> Global Model <lb/> 66.8% <lb/> Figure 4: Using the base Timebank annotated tags for <lb/>testing, accuracy on before/after tags in the two models. <lb/> libsvm 2 to implement our SVM classifiers. <lb/>Figure 4 shows the results from our ILP model <lb/>with transitivity constraints. The first row is the <lb/>baseline pairwise classification trained and tested on <lb/>the original Timebank relations. The second row <lb/>gives performance with ILP. The model shows no <lb/>improvement. The global ILP constraints did affect <lb/>local decisions, changing 175 of them (out of 7324), <lb/>but the changes cancelled out and had no affect on <lb/>overall accuracy. <lb/> 4.5 Loosely Connected Graph <lb/> Why didn&apos;t a global model help? The problem lies <lb/>in the graph structure of Timebank&apos;s annotated rela-<lb/>tions. The Timebank annotators were not required <lb/>to annotate relations between any particular pair of <lb/>events. Instead, they were instructed to annotate <lb/>what seemed appropriate due to the almost insur-<lb/>mountable task of annotating all pairs of events. A <lb/>modest-sized document of 30 events, for example, <lb/>would contain <lb/>  30 <lb/> 2 <lb/> = 435 possible pairs. Anno-<lb/>tators thus marked relations where they deemed fit, <lb/>most likely between obvious and critical relations to <lb/>the understanding of the article. The vast majority of <lb/>possible relations are untagged, thus leaving a large <lb/>set of unlabeled (and disconnected) unknown rela-<lb/>tions. <lb/>Figure 5 graphically shows all relations that are <lb/>annotated between events and time expressions in <lb/>one of the shorter Timebank documents. Nodes rep-<lb/>resent events and times (event nodes start with the <lb/>letter &apos;e&apos;, times with &apos;t&apos;), and edges represent tempo-<lb/>ral relations. Solid lines indicate hand annotations, <lb/>and dotted lines indicate new rules from transitive <lb/>closure (only one, from event e4 to time t14). As <lb/>can be seen, the graph is largely disconnected and <lb/>a global model contributes little information since <lb/>transitivity constraints cannot apply. <lb/>

			<note place="footnote"> 2 http://www.csie.ntu.edu.tw/Ëœcjlin/libsvm <lb/></note>

			<page> 701 <lb/></page>

			Timebank Annotation of wsj 0551 <lb/> Figure 5: Annotated relations in document wsj 0551. <lb/> The large amount of unlabeled relations in the <lb/>corpus presents several problems. First, building a <lb/>classifier for these unknown relations is easily over-<lb/>whelmed by the huge training set. Second, many of <lb/>the untagged pairs have non-unknown ordering rela-<lb/>tions between them, but were missed by the annota-<lb/>tors. This point is critical because one cannot filter <lb/>this noise when training an unknown classifier. The <lb/>noise problem will appear later and will be discussed <lb/>in our final experiment. Finally, the space of an-<lb/>notated events is very loosely connected and global <lb/>constraints cannot assist local decisions if the graph <lb/>is not connected. The results of this first experiment <lb/> illustrate this latter problem. <lb/>Bethard et al. (2007) strengthen the claim that <lb/>many of Timebank&apos;s untagged relations should not <lb/>be left unlabeled. They performed an independent <lb/>annotation of 129 of Timebank&apos;s 186 documents, <lb/>tagging all events in verb-clause relationships. They <lb/>found over 600 valid before/after relations that are <lb/>untagged in Timebank, on average three per docu-<lb/>ment. One must assume that if these nearby verb-<lb/>clause event pairs were missed by the annotators, <lb/>the much larger number of pairs that cross sentence <lb/>boundaries were also missed. <lb/>The next model thus attempts to fill in some of the <lb/>gaps and further connect the event graph by using <lb/>two types of knowledge. The first is by integrating <lb/>Bethard&apos;s data, and the second is to perform tempo-<lb/>ral reasoning over the document&apos;s time expressions <lb/>(e.g. yesterday or january 1999). <lb/> 5 A Global Model With Time <lb/> Our initial model contained two components: (1) a <lb/>pairwise classifier between events, and (2) a global <lb/>constraint satisfaction layer. However, due to the <lb/>sparseness in the event graph, we now introduce <lb/>a third component addressing connectivity: (3) a <lb/>temporal reasoning component to inter-connect the <lb/>global graph and assist in training data expansion. <lb/>One important aspect of transitive closure in-<lb/>cludes the event-time and time-time relations during <lb/>closure, not just the event-event links. Starting with <lb/>5,947 different types of relations, transitive rules in-<lb/>crease the dataset to approximately 12,000. How-<lb/>ever, this increase wasn&apos;t enough to be effective in <lb/>global reasoning. To illustrate the sparsity that still <lb/>remains, if each document was a fully connected <lb/>graph of events, Timebank would contain close to <lb/>160,000 relations 3 , more than a 13-fold increase. <lb/>More data is needed to enrich the Timebank event <lb/>graph. Two types of information can help: (1) more <lb/>event-event relations, and (2) a separate type of in-<lb/>formation to indirectly connect the events: event-<lb/>X-event. We incorporate the new annotations from <lb/>Bethard et al. (2007) to address (1) and introduce <lb/>a new temporal reasoning procedure to address (2). <lb/>The following section describes this novel approach <lb/>to adding time expression information to further <lb/>connect the graph. <lb/> 5.1 Time-Time Information <lb/> As described above, we use event-time relations to <lb/>produce the transitive closure, as well as annotated <lb/>time-time relations. It is unclear if Mani et al. (2006) <lb/>used these latter relations in their work. <lb/>However, we also add new time-time links that <lb/>are deduced from the logical time intervals that they <lb/>describe. Time expressions can be resolved to time <lb/>intervals with some accuracy through simple rules. <lb/>New time-time relations can then be added to our <lb/>space of events through time stamp comparisons. <lb/>Take this newswire example: <lb/> The Financial Times 100-share index shed 47.3 points to <lb/>close at 2082.1, down 4.5% from the previous Friday, <lb/> and 6.8% from Oct. 13, when Wall Street&apos;s plunge helped <lb/>spark the current weakness in London. <lb/> 
			
			<note place="footnote"> 3 Sum over the # of events n  d  in each document d, <lb/>  n  d <lb/> 2 <lb/></note>

			<page> 702 <lb/></page>

			The first two expressions (&apos;previous Friday&apos; <lb/> and &apos;Oct. 13&apos;) are in a clear before relation-<lb/>ship that Timebank annotators captured. <lb/>The <lb/> &apos;current&apos; expression, is correctly tagged with the <lb/> PRESENT REF attribute to refer to the document&apos;s <lb/>timestamp. Both &apos;previous Friday&apos; and &apos;Oct. 13&apos; <lb/> should thus be tagged as being before this expres-<lb/>sion. However, the annotators did not tag either <lb/>of these two before relations, and so our timestamp <lb/>resolution procedure fills in these gaps. This is a <lb/>common example of two expressions that were not <lb/>tagged by the annotators, yet are in a clear temporal <lb/>relationship. <lb/>We use Timebank&apos;s gold standard TimeML an-<lb/>notations to extract the dates and times from the <lb/>time expressions. In addition, those marked as <lb/> PRESENT REF are resolved to the document times-<lb/>tamp. Time intervals that are strictly before or after <lb/>each other are thus labeled and added to our space <lb/>of events. We create new before relations based on <lb/>the following procedure: <lb/> if event1.year &lt; event2.year <lb/>return true <lb/>if event1.year == event2.year <lb/>if event1.month &lt; event2.month <lb/>return true <lb/>if event1.month == event2.month <lb/>if event1.day &lt; event2.day <lb/>return true <lb/>end <lb/>end <lb/>return false <lb/> All other time-time orderings not including the <lb/> before relation are ignored (i.e. includes is not cre-<lb/>ated, although could be with minor changes). <lb/>This new time-time knowledge is used in two sep-<lb/>arate stages of our model. The first is just prior to <lb/>transitive closure, enabling a larger expansion of our <lb/>tagged relations set and reduce the noise in the un-<lb/>known set. The second is in the constraint satisfac-<lb/>tion stage where we add our automatically computed <lb/>time-time relations (with the gold event-time rela-<lb/>tions) to the global graph to help correct local event-<lb/>event mistakes. <lb/> Total Event-Event Relations After Closure <lb/> before after <lb/> Timebank <lb/>3919 3405 <lb/>+ time-time <lb/>5604 5118 <lb/>+ time/bethard 7111 6170 <lb/> Figure 6: The number of event-event before and after re-<lb/>lations after transitive closure on each dataset. <lb/> Comparative Results with Closure <lb/> Training Set <lb/>Accuracy <lb/>Timebank Pairwise <lb/> 66.8% <lb/> Global Model <lb/> 66.8% <lb/> Global + time/bethard <lb/> 70.4% <lb/> Figure 7: Using the base Timebank annotated tags for <lb/>testing, the increase in accuracy on before/after tags. <lb/> 5.2 Temporal Reasoning Experiment <lb/> Our second evaluation continues the use of the two-<lb/>way classification task with before and after to ex-<lb/>plore the contribution of closure, time normaliza-<lb/>tion, and global constraints. <lb/>We augmented the corpus with the labeled rela-<lb/>tions from Bethard et al. (2007) and added the au-<lb/>tomatically created time-time relations as described <lb/>in section 5.1. We then expanded the corpus using <lb/>transitive closure. Figure 6 shows the progressive <lb/>data size increase as we incrementally add each to <lb/>the closure algorithm. <lb/>The time-time generation component automati-<lb/>cally added 2459 new before and after time-time re-<lb/>lations into the 186 Timebank documents. This is <lb/>in comparison to only 157 relations that the human <lb/>annotators tagged, less than 1 per document on av-<lb/>erage. The second row of figure 6 shows the dras-<lb/>tic effect that these time-time relations have on the <lb/>number of available event-event relations for train-<lb/>ing and testing. Adding both Bethard&apos;s data and <lb/>the time-time data increases our training set by 81% <lb/> over closure without it. <lb/>We again performed 10-fold cross validation with <lb/>micro-averaged accuracies, but each fold tested only <lb/>on the transitively closed Timebank data (the first <lb/>row of figure 6). The training set used all available <lb/>data (the third row of figure 6) including the Bethard <lb/>data as well as our new time-time links. <lb/>

			<page> 703 <lb/></page>

			Figure 7 shows the results from the new model. <lb/>The first row is the baseline pairwise classification <lb/>trained and tested on the original relations only. Our <lb/>model improves by 3.6% absolute. This improve-<lb/>ment is statistically significant (p &lt; 0.000001, Mc-<lb/>Nemar&apos;s test, 2-tailed). <lb/> 5.3 Discussion <lb/> To further illustrate why our model now improves <lb/>local decisions, we continue our previous graph ex-<lb/>ample. The actual text for the graph in figure 5 is <lb/>shown here: <lb/> docstamp: 10/30/89 (t14) <lb/> Trustcorp Inc. will become(e1) Society Bank &amp; Trust <lb/>when its merger(e3) is completed(e4) with Society Corp. <lb/>of Cleveland, the bank said(e5). Society Corp., which is <lb/>also a bank, agreed(e6) in June(t15) to buy(e8) Trustcorp <lb/>for 12.4 million shares of stock with a market value of <lb/>about $450 million. The transaction(e9) is expected(e10) <lb/>to close(e2) around year end(t17). <lb/> The automatic time normalizer computes and adds <lb/>three new time-time relations, two connecting t15 <lb/>and t17 with the document timestamp, and one con-<lb/>necting t15 and t17 together. These are not other-<lb/>wise tagged in the corpus. <lb/> Time-Time + Closure <lb/> Figure 8: Before and after time-time links with closure. <lb/> Figure 8 shows the augmented document. The <lb/>double-line arrows indicate the three new time-time <lb/>relations and the dotted edges are the new relations <lb/>added by our transitive closure procedure. Most crit-<lb/>ical to this paper, three of the new edges are event-<lb/>event relations that help to expand our training data. <lb/>If this document was used in testing (rather than <lb/>training), these new edges would help inform our <lb/>transitive rules during classification. <lb/>Even with this added information, disconnected <lb/>segments of the graph are still apparent. However, <lb/>the 3.6% performance gain encourages us to move <lb/>to the final full task. <lb/> 6 Final Experiment with Unknowns <lb/> Our final evaluation expands the set of relations to <lb/>include unlabeled relations and tests on the entire <lb/>dataset available to us. The following is now a clas-<lb/>sification task between the three relations: before, <lb/>after, and unknown. <lb/> We duplicated the previous evaluation by adding <lb/>the labeled relations from Bethard et al. (2007) and <lb/>our automatically created time-time relations. We <lb/>then expanded this dataset using transitive closure. <lb/>Unlike the previous evaluation, we also use this en-<lb/>tire dataset for testing, not just for training. Thus, all <lb/>event-event relations in Bethard as well as Timebank <lb/>are used to expand the dataset with transitive closure <lb/>and are used in training and testing. We wanted to <lb/>fully evaluate document performance on every pos-<lb/>sible event-event relation that logically follows from <lb/>the data. <lb/>As before, we converted IBefore and IAfter into <lb/> before and after respectively, while all other rela-<lb/>tions are reduced to unknown. This relation set co-<lb/>incides with TempEval-07&apos;s core three relations (al-<lb/>though they use vague instead of unknown). <lb/> Rather than include all unlabeled pairs in our un-<lb/>known set, we only include the unlabeled pairs that <lb/>span at most one sentence boundary. In other words, <lb/>events in adjacent sentences are included in the un-<lb/>known set if they were not tagged by the Timebank <lb/>annotators. The intuition is that annotators are more <lb/>likely to label nearby events, and so events in adja-<lb/>cent sentences are more likely to be actual unknown <lb/> relations if they are unlabeled. It is more likely that <lb/>distant events in the text were overlooked by con-<lb/>venience, not because they truly constituted an un-<lb/>known relationship. <lb/>The set of possible sentence-adjacent unknown re-<lb/>lations is very large (approximately 50000 unknown <lb/> compared to 7000 before), and so we randomly se-<lb/>lect a percentage of these relations for each evalu-<lb/>

			<page> 704 <lb/></page>

			Classification Accuracy <lb/> % unk base <lb/>global global+time <lb/>0 <lb/>72.0% 72.2% <lb/>74.0% <lb/>1 <lb/>69.4% 69.5% <lb/>71.3% <lb/>3 <lb/>65.5% 65.6% <lb/>67.1% <lb/>5 <lb/>63.7% 63.8% <lb/>65.3% <lb/>7 <lb/>61.2% 61.6% <lb/>62.8% <lb/>9 <lb/>59.3% 59.5% <lb/>60.6% <lb/>11 <lb/>58.1% 58.4% <lb/>59.4% <lb/>13 <lb/>57.1% 57.1% <lb/>58.1% <lb/> Figure 9: Overall accuracy when training with different <lb/>percentages of unknown relations included. 13% of un-<lb/>knowns is about equal to the number of befores. <lb/> ation. We used the same SVM approach with the <lb/>features described in section 4.1. <lb/> 6.1 Results <lb/> Results are presented in figure 9. The rows in the <lb/>table are different training/testing runs on varying <lb/>sizes of unknown training data. There are three <lb/>columns with accuracy results of increasing com-<lb/>plexity. The first, base, are results from pairwise <lb/>classification decisions over Timebank and Bethard <lb/>with no global model. The second, global, are re-<lb/>sults from the Integer Linear Programming global <lb/>constraints, using the pairwise confidence scores <lb/>from the base evaluation. Finally, the global+time <lb/> column shows the ILP results when all event-time, <lb/>time-time, and automatically induced time-time re-<lb/>lations are included in the global graph. <lb/>The ILP approach does not alone improve perfor-<lb/>mance on the event-event tagging task, but adding <lb/>the time expression relations greatly increases the <lb/>global constraint results. This is consistent with the <lb/>results from out first two experiments. The evalua-<lb/>tion with 1% of the unknown tags shows an almost <lb/> 2% improvement in accuracy. The gain becomes <lb/>smaller as the unknown set increases in size (1.0% <lb/>gain with 13% unknown). Unknown relations will <lb/>tend to be chosen as more weight is given to un-<lb/>knowns. When there is a constraint conflict in the <lb/>global model, unknown tends to be chosen because <lb/>it has no transitive implications. All improvements <lb/>from base to global+time are statistically significant <lb/>(p &lt; 0.000001, McNemar&apos;s test, 2-tailed). <lb/> Base Pairwise Classification <lb/> precision recall f1-score <lb/>before <lb/>61.4 <lb/>55.4 <lb/>58.2 <lb/>after <lb/>57.6 <lb/>53.1 <lb/>55.3 <lb/>unk <lb/>53.0 <lb/>62.8 <lb/>57.5 <lb/> Global+Time Classification <lb/> precision <lb/>recall <lb/>f1-score <lb/>before 63.7 (+2.3) 57.1 (+2.2) 60.2 (+2.0) <lb/> after <lb/>60.3 (+2.7) 54.3 (+2.9) 57.1 (+1.8) <lb/> unk <lb/>52.0 (-1.0) 62.9 (+0.1) 56.9 (-0.6) <lb/>Figure 10: Precision and Recall for the base pairwise de-<lb/>cisions and the global constraints with integrated time in-<lb/>formation. <lb/> The first row of figure 9 corresponds to the re-<lb/>sults in our second experiment in figure 7, but shows <lb/>higher accuracy. The reason is due to our different <lb/>test sets. This final experiment includes Bethard&apos;s <lb/>event-event relations in testing. The improved per-<lb/>formance suggests that the clausal event-event rela-<lb/>tions are easier to classify, agreeing with the higher <lb/>accuracies originally found by Bethard et al. (2007). <lb/>Figure 10 shows the precision, recall, and f-score <lb/>for the evaluation with 13% unknowns. This set was <lb/>chosen for comparison because it has a similar num-<lb/>ber of unknown labels as before labels. We see an <lb/>increase in precision in both the before and after de-<lb/>cisions by up to 2.7%, an increase in recall up to <lb/> 2.9%, and an fscore by as much as 2.0%. The un-<lb/>known relation shows mixed results, possibly due to <lb/>its noisy behavior as discussed throughout this pa-<lb/>per. <lb/> 6.2 Discussion <lb/> Our results on the two-way (before/after) task show <lb/>that adding additional implicit temporal constraints <lb/>and then performing global reasoning results in <lb/>significant improvements in temporal ordering of <lb/>events (3.6% absolute over simple pairwise deci-<lb/>sions). <lb/>Both before and after also showed increases in <lb/>precision and recall in the three-way evaluation. <lb/>However, unknown did not parallel this improve-<lb/>ment, nor are the increases as dramatic as in the two-<lb/>way evaluation. We believe this is consistent with <lb/>the noise that exists in the Timebank corpus for un-<lb/>labeled relations. Evidence from Bethard&apos;s indepen-<lb/>

			<page> 705 <lb/></page>

			dent annotations directly point to missing relations, <lb/>but the dramatic increase in the size of our closure <lb/>data (81%) from adding a small amount of time-time <lb/>relations suggests that the problem is widespread. <lb/>This noise in the unknown relation may be damp-<lb/>ening the gains that the two way task illustrates. <lb/>This work is also related to the task of event-time <lb/>classification. While not directly addressed in this <lb/>paper, the global methods described within clearly <lb/>apply to pairwise models of event-time ordering as <lb/>well. <lb/>Further progress in improving global constraints <lb/>will require new methods to more accurately iden-<lb/>tify unknown events, as well as new approaches to <lb/>create implicit constraints over the ordering. We ex-<lb/>pect such an improved ordering classifier to be used <lb/>to improve the performance of tasks such as summa-<lb/>rization and question answering about the temporal <lb/>nature of events. <lb/> 
			
		</body>
		
		<back>
				
			<div type="acknowledgement">Acknowledgments <lb/> This work is funded in part by DARPA through IBM <lb/>and by the DTO Phase III Program for AQUAINT. <lb/>We also thank our anonymous reviewers for many <lb/>helpful suggestions. <lb/></div>


			<listBibl> References <lb/> Steven Bethard, James H. Martin, and Sara Klingenstein. <lb/>2007. Timelines from text: Identification of syntac-<lb/>tic temporal relations. In International Conference on <lb/>Semantic Computing. <lb/> Philip Bramsen, Pawan Deshpande, Yoong Keok Lee, <lb/>and Regina Barzilay. 2006. Inducing temporal graphs. <lb/>In Proceedings of EMNLP-06. <lb/> Nathanael Chambers, Shan Wang, and Dan Jurafsky. <lb/>2007. Classifying temporal relations between events. <lb/>In Proceedings of ACL-07, Prague, Czech Republic. <lb/>R Ingria and James Pustejovsky. 2002. TimeML specifi-<lb/>cation 1.0. In http://www.time2002.org. <lb/> Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min <lb/>Lee, and James Pustejovsky. 2006. Machine learning <lb/>of temporal relations. In Proceedings of ACL-06, July. <lb/>Inderjeet Mani, Ben Wellner, Marc Verhagen, and James <lb/>Pustejovsky. 2007. Three approaches to learning <lb/>tlinks in timeml. Technical Report CS-07-268, Bran-<lb/>deis University. <lb/>James Pustejovsky, Patrick Hanks, Roser Sauri, Andrew <lb/>See, David Day, Lisa Ferro, Robert Gaizauskas, Mar-<lb/>cia Lazo, Andrea Setzer, and Beth Sundheim. 2003. <lb/>The timebank corpus. Corpus Linguistics, pages 647â€“ <lb/>656. <lb/>Rion Snow, Brendan O&apos;Connor, Dan Jurafsky, and An-<lb/>drew Ng. 2008. Cheap and fast -but is it good? <lb/>evaluating non-expert annotations for natural language <lb/>tasks. In Proceedings of EMNLP-08, Waikiki, Hawaii, <lb/>USA. <lb/>Marc Verhagen, Robert Gaizauskas, Frank Schilder, <lb/>Mark Hepple, Graham Katz, and James Pustejovsky. <lb/>2007. Semeval-2007 task 15: Tempeval temporal re-<lb/>lation identification. In Workshop on Semantic Evalu-<lb/>ations. <lb/></listBibl>

			<page> 706 </page>

		</back>
	</text>
</tei>
