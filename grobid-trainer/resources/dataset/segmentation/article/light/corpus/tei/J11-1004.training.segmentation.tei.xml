<?xml version="1.0" ?>
<tei>
	<teiHeader>
		<fileDesc xml:id="__J11-1004"/>
	</teiHeader>
	<text xml:lang="en">
			<front> An Investigation of Interruptions and <lb/>Resumptions in Multi-Tasking Dialogues <lb/> Fan Yang  * <lb/> Nuance Communications, Inc. <lb/> Peter A. Heeman <lb/> Oregon Health &amp; Science University <lb/> Andrew L. Kun <lb/> University of New Hampshire <lb/> In this article we focus on human–human multi-tasking dialogues, in which pairs of con-<lb/>versants, using speech, work on an ongoing task while occasionally completing real-time tasks. <lb/>The ongoing task is a poker game in which conversants need to assemble a poker hand, and the <lb/>real-time task is a picture game in which conversants need to find out whether they have a certain <lb/>picture on their displays. We employ empirical corpus studies and machine learning experiments <lb/>to understand the mechanisms that people use in managing these complex interactions. First, <lb/>we examine task interruptions: switching from the ongoing task to a real-time task. We find <lb/>that generally conversants tend to interrupt at a less disruptive context in the ongoing task <lb/>when possible. We also find that the discourse markers oh and wait occur in initiating a task <lb/>interruption twice as often as in the conversation of the ongoing task. Pitch is also found to be <lb/>statistically correlated with task interruptions; in fact, the more disruptive the task interruption, <lb/>the higher the pitch. Second, we examine task resumptions: returning to the ongoing task after <lb/>completing an interrupting real-time task. We find that conversants might simply resume the <lb/>conversation where they left off, but sometimes they repeat the last utterance or summarize the <lb/>critical information that was exchanged before the interruption. Third, we apply machine learn-<lb/>ing to determine how well task interruptions can be recognized automatically and to investigate <lb/>the usefulness of the cues that we find in the corpus studies. We find that discourse context, pitch, <lb/>and the discourse markers oh and wait are important features to reliably recognize task interrup-<lb/>tions; and with non-lexical features one can improve the performance of recognizing task inter-<lb/>ruptions with more than a 50% relative error reduction over a baseline. Finally, we discuss the <lb/>implication of our findings for building a speech interface that supports multi-tasking dialogue. <lb/></front> 
			
			<body>1. Introduction <lb/> Existing speech interfaces have mostly been used to perform a single task, where <lb/>the user finishes with one task before moving on to the next. We envision that <lb/>  </body>
			
			<front>*  Nuance Communications, Inc., 505 First Ave. South, Suite 700, Seattle, WA 98104. <lb/>E-mail: fan.yang@nuance.com. <lb/></front> 
			
			<front>Submission received: 26 July 2009; revised submission received: 22 July 2010; accepted for publication: <lb/>13 October 2010. <lb/></front>

			<front>© 2011 Association for Computational Linguistics <lb/></front>

			<front>Computational Linguistics <lb/>Volume 37, Number 1 <lb/></front> 
			
			<body>next-generation speech interfaces will be able to work with the user on multiple tasks <lb/>at the same time, which is especially useful for real-time tasks. For instance, a driver in <lb/>a car might use a speech interface to catch up on e-mails, while occasionally checking <lb/>upcoming traffic conditions, and receiving navigation instructions; or a police officer <lb/>might need to be alerted to a nearby accident while accessing a database during a <lb/>routine traffic stop. <lb/>Several speech interfaces that allow multi-tasking dialogues have been built (e.g., <lb/>Traum and Rickel 2002; Kun, Miller, and Lenharth 2004; Lemon and Gruenstein 2004; <lb/>Larsson 2003). However, it is unclear that the mechanisms of managing multiple ver-<lb/>bal tasks in these systems resemble human conventions or do the best to help users <lb/>with task switching. For complex domains, the user might be confused about which <lb/>task the interface is talking about, or might be confused about where they left off in <lb/>a task. <lb/>In order to build a speech interface that supports multi-tasking dialogue, we need to <lb/>determine a set of conventions that the user and interface can follow in task switching. <lb/>We propose to start with conventions that are actually used in human–human speech <lb/>conversations, which are natural for users to follow and probably efficient in problem-<lb/>solving. Once we understand the human conventions, we can try to implement them in <lb/>a dialogue manager and run user studies to verify the effectiveness of such conventions <lb/>in human–computer dialogue. <lb/>In this article we focus on understanding the human conventions of managing <lb/>multiple tasks. Multi-tasking dialogues, where multiple independent topics overlap <lb/>with each other in time, regularly arise in human–human conversation: For example, <lb/>a driver and a passenger in a car might be talking about their summer plans, while <lb/>occasionally interjecting road directions or conversation about what music to listen to. <lb/>However, little is known about how people manage multi-tasking dialogues. Given the <lb/>scenario where a real-time task with a time constraint arises during the course of an <lb/>ongoing task, we are specially interested in two switching behaviors: task interruption, <lb/> which is to suspend the ongoing task and switch to a waiting real-time task, and task <lb/>resumption, which is to return to the interrupted ongoing task after completing a real-<lb/>time task. <lb/>The first question we ask is how quickly conversants respond to a real-time task. <lb/>Intuitively if the real-time task is very urgent (e.g., the driver is about to miss a turn), <lb/>the passenger might want to immediately cut off the ongoing conversation, and notify <lb/>the driver of the turn. However, if the real-time task is less urgent, for example, the <lb/>driver does not like the music and wants the passenger to load another CD, do conver-<lb/>sants still immediately interrupt the ongoing conversation? If conversants do vary how <lb/>quickly they interrupt, are there any regularities of where conversants switch from the <lb/>ongoing task to the real-time task? We hypothesize that, given the choice, conversants <lb/>interrupt the ongoing task where the interruption is less disruptive to the ongoing <lb/>task. <lb/>The second question we ask is how conversants signal task interruptions. Previous <lb/>research showed that conversants signal the start of a new topic in single-tasking speech <lb/>(monologue and dialogue) with discourse markers and prosodic cues. We thus hypothe-<lb/>size that conversants also use these cues to signal task interruptions. We also investigate <lb/>whether conversants vary the intensity of the cues, and under what circumstances. <lb/>The third question we ask is what conversants do immediately upon resuming the <lb/>ongoing task. Switching to a real-time task causes the ongoing task to be temporarily <lb/>suspended. On completing the real-time task and returning to the ongoing task, do <lb/>conversants simply continue on from where they were interrupted? We hypothesize that <lb/>

			<page>76 <lb/></page>

			<note place="headnote"> Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note>

			conversants might sometimes perform certain actions to recover from the interruption. <lb/>For example, it is imaginable that conversants might ask where were we at for summer <lb/>plans, and then review what was discussed before the interruption. <lb/>To answer these questions, we collect the MTD corpus, which consists of a set <lb/>of human–human dialogues where pairs of conversants have multiple overlapping <lb/>verbal tasks to perform. In our research, we keep things relatively simple by having <lb/>conversants talk to each other to play two games on computers. The first game, the <lb/>ongoing task, is a poker game in which conversants need to assemble a poker hand, <lb/>which usually takes a relatively long time to complete. The second game, the real-time <lb/>task, is a picture game in which conversants need to find out whether they have a <lb/>certain picture on their displays, which can be done in a couple of turns but has a time <lb/>constraint. In Section 3, we describe the task setup and corpus collection. In Section 4, <lb/>we examine when and where conversants suspend the ongoing task and switch to the <lb/>real-time task. In Section 5, we examine how conversants signal task interruptions. In <lb/>Section 6, we examine the behavior of context restoration in task resumptions. <lb/>In addition to the three questions we have asked, in Section 7, we use machine <lb/>learning to automatically recognize task interruptions. Recognizing task interruptions <lb/>is an important component in building speech interfaces that support multi-tasking <lb/>dialogue. For example, the speech interface can accordingly switch the language model <lb/>when it detects that the user has switched to another task, which should improve <lb/>speech recognition performance (Iyer and Ostendorf 1999) and utterance understand-<lb/>ing, leading to higher user satisfaction (Walker, Passonneau, and Boland 2001). We run <lb/>machine learning experiments to determine how well we can automatically recognize <lb/>task interruptions and to understand the utility of the features that we found in our <lb/>corpus studies. Finally, we conclude the paper in Section 8. This paper includes and <lb/>extends Heeman et al. (2005), Yang, Heeman, and Kun (2008), and Yang and Heeman <lb/>(2009) with more corpus data, more robust statistical analysis, more machine learning <lb/>experiments, and more comprehensive discussions. <lb/> 2. Related Research <lb/>2.1 Existing Systems for Multi-Tasking Dialogues <lb/> There is some initial research effort in building speech interfaces to support multi-<lb/>tasking dialogue. Kun, Miller, and Lenharth (2004) developed a system called Project54, <lb/>which allowed a user to interact with multiple devices in a police cruiser using speech. <lb/>The architecture of Project54 allowed for handling multiple tasks overlapped in time. <lb/>For example, when pulling over a vehicle, an officer could first issue a spoken command <lb/>to turn on the lights and siren, then issue spoken commands to initiate a data query, <lb/>go back to interacting with the lights and siren (perhaps to change the pattern after <lb/>the vehicle has been pulled over), and finally receive the spoken results of the data <lb/>query. This example shows that system responses related to different tasks could be <lb/>interleaved: The system responded to the data query after the user had already switched <lb/>back to interacting with the lights and siren. <lb/>Lemon and Gruenstein (2004) also explored multi-tasking in a speech interface. <lb/>They built a speech interface for a human operator to direct a robotic helicopter on <lb/>executing multiple tasks, such as searching for a car and flying to a tower. The interface <lb/>kept an ordered set of active dialogue tasks, and interpreted the user utterance in terms <lb/>of the most active task for which the utterance made sense. Conversely, during the <lb/>

			<page>77 <lb/></page>

			<note place="headnote">Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note> 
			
			interface&apos;s turn of speaking, it could produce an utterance for any of the dialogue tasks <lb/>and thus intermixed utterances from different tasks. <lb/>In Kun, Miller, and Lenharth (2004) or Lemon and Gruenstein (2004), the systems <lb/>did not explicitly signal tasks switching, either for task interruptions or for task re-<lb/>sumptions, but instead relied on semantic interpretation to determine which task an <lb/>utterance belonged to. Larsson (2003) built the GoDis system which hard-coded two <lb/>types of signals when resuming an interrupted conversation. The first type of signal was <lb/>to use the discourse marker so to implicitly signal a topic resumption. The second type of <lb/>signal was to use the phrase returning to the issue of to explicitly resume an interrupted <lb/>topic. For example, when searching for the price of an air ticket with GoDis, the user <lb/>could suspend the system&apos;s question when do you want to travel by interjecting a question <lb/> do I need a visa. The system, after a short dialogue answering the user&apos;s question about <lb/>a visa, would resume the ticket booking by returning to the issue of price. <lb/> Traum and his colleagues (Rickel et al. 2002; Traum and Rickel 2002) developed the <lb/>Mission Rehearsal Exercise system in which the user and virtual humans collaborated <lb/>on multiple tasks that could interrupt each other. They created a scenario in which a <lb/>lieutenant (the user) was sent to a village for an Army peacekeeping task. However, <lb/>on his way, he encountered an auto accident in which his platoon&apos;s vehicle crashed <lb/>into a civilian vehicle, injuring a local boy. The boy&apos;s mother and an Army medic were <lb/>hunched over him, and a sergeant approached the lieutenant to brief him on the situ-<lb/>ation. These multiple virtual humans could interrupt or be involved in conversations <lb/>with the lieutenant. The authors proposed and partially implemented a multi-level <lb/>dialogue manager, with levels for turn-taking, initiative, grounding, topic management, <lb/>negotiation, and rhetorical structure. In their view, topic management included where <lb/>one topic is started before an old one is completed. They described how topic shifts <lb/>in general can be signaled with cue phrases, such as now and anyways, and with non-<lb/>verbal cues. <lb/>These research works show the usefulness of a spoken dialogue system being able to <lb/>handle multiple tasks, and promote a thorough examination of multi-tasking dialogue. <lb/>In this article we examine the conventions of task switching in human–human dialogue <lb/>as the first step towards understanding the practice of managing tasking switching in a <lb/>computer dialogue system. <lb/> 2.2 Insights from Non-Verbal Task Switching <lb/> Research in cognitive science suggests that task interruptions and resumptions are <lb/>complicated behavior and warrant investigation. There is extensive research on the <lb/>disruptiveness of interruptions, in which individuals switch between multiple manual-<lb/>visual tasks. For example, Gillie and Broadbent (1989) found that the length (in time) <lb/>of an interruption is not an important factor, but that the real-time task&apos;s complexity <lb/>and similarity to the ongoing task contribute to the disruptiveness. On the other hand, <lb/>in their study of checklists, Linde and Goguen (1987) found that it is not the number <lb/>of interruptions but the length of interruptions that affects the disruptiveness. Cutrell, <lb/>Czerwinski, and Hovitz (2001) examined the influence of instant messaging on users <lb/>performing ongoing computing tasks, and found that interruptions unrelated to the <lb/>ongoing task resulted in longer task resumptions. Although these results do not appear <lb/>to always converge on the same conclusions, they suggest that task switching can be <lb/>disruptive to users. <lb/>Researchers have been trying to minimize the disruptive effect of task switching <lb/>in human–computer interaction. McFarlane (1999) explored four alternatives for when <lb/>

			<page>78 <lb/></page>

			<note place="headnote">Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note> 
			
			to suspend the ongoing task and switch to the interruption, namely, immediate, negoti-<lb/>ated, mediated, and scheduled, and found mixed results. Renaud (2000) argued for, and <lb/>built, a prototype of a visualization tool to help users restore the context of the ongoing <lb/>task when returning from an interruption. Hess and Detweiler (1994) and Gopher, <lb/>Greenshpan, and Armony (1996) found that the disruptive effects are reduced as people <lb/>gain more experience with interruptions. These studies suggest that it is worthwhile to <lb/>investigate how a computer dialogue system should manage task switching. <lb/> 2.3 Insights from Discourse Structure Research <lb/> Research in discourse structure also sheds light on task switching. It is important to <lb/>understand the conventions that people use to manage discourse structure as these <lb/>might also be used for managing multiple tasks. According to Grosz and Sidner (1986), <lb/>the structure of a discourse is a combination of linguistic structure, intentional structure, <lb/>and attentional state. The linguistic structure is a hierarchical segmentation of the <lb/>dialogue. Each segment has a purpose, which is established by the conversant who <lb/>initiates the segment. The purposes come together to form the intentional structure. <lb/>The attentional state contains the objects, properties, and relations that are most salient <lb/>at any point in the dialogue. The attentional state is claimed to work like a stack. When <lb/>a new segment is started, a new focus space is created on top of the attentional stack. <lb/>When the segment completes, the focus space is popped off. 1 <lb/> Signaling discourse structure in single-tasking speech is about signaling the bound-<lb/>ary of related discourse segments that contribute to the achievement of a discourse <lb/>purpose. Two types of cues have been identified. The first type is discourse markers <lb/>(Grosz and Sidner 1986; Schiffrin 1987; Moser and Moore 1995; Passonneau and Litman <lb/>1997; Bangerter and Clark 2003). Discourse markers can be used to signal the start of a <lb/>new discourse segment and its relation to other discourse segments. For example, now <lb/> might signal moving on to the next topic, and well might signal a negative or unexpected <lb/>response. <lb/>The second type of cue is prosody. In read speech, Grosz and Hirschberg (1992) <lb/>studied broadcast news and found that pause length is the most important factor that <lb/>indicates a new discourse segment. Ayers (1992) found that pitch range appears to cor-<lb/>relate more closely with hierarchical topic structure in read speech than in spontaneous <lb/>speech. In spontaneous monologue, Butterworth (1972) found that the beginning of a <lb/>discourse segment exhibits slower speaking rate; Swerts (1995) and Passonneau and <lb/>Litman (1997) found that pause length correlates with discourse segment boundaries; <lb/>Hirschberg and Nakatani (1996) found that the beginning of a discourse segment corre-<lb/>lates with higher pitch. In human–human dialogue, similar behavior has been observed: <lb/>The pitch value tends to be higher for starting a new discourse segment (Nakajima and <lb/>Allen 1993). In human–computer dialogue, Swerts and Ostendorf (1995) found that the <lb/>first utterance of a discourse segment correlates with slower speaking rate and longer <lb/>preceding pause. Thus, we are interested in whether discourse markers and prosodic <lb/>cues are also used in signaling task interruptions in multi-tasking dialogue. <lb/>

			<note place="footnote"> 1 Grosz and Sidner (1986) also briefly talked about interruptions. In their discourse structure theory, <lb/>interruptions are modeled as special discourse segments. When a task interruption happens, an <lb/>attentional state is created for the real-time task and pushed on top of the discourse stack. There is <lb/>an impenetrable separation between the attentional state of the real-time task and the interrupted <lb/>ongoing task, so that the real-time task cannot access the ongoing task. When the real-time task is <lb/>completed, its attentional state is popped off and the ongoing task becomes salient. <lb/></note>

			<page> 79 <lb/></page>

			<note place="headnote"> Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note> 
			
			3. The MTD Corpus <lb/> In order to better understand multi-tasking human–human dialogue, we collected the <lb/>MTD corpus, in which pairs of players perform overlapping verbal tasks. <lb/> 3.1 Design of Tasks <lb/> For the MTD corpus, we decided to have players complete two types of tasks via <lb/>conversation: an ongoing task and real-time tasks. The ongoing task needs to build up <lb/>significant context that players have to keep in mind. On task resumption, this context <lb/>is needed to finish the task, and so might need to be re-established. The task should <lb/>also encourage both players to equally participate as we believe that mixed-initiative <lb/>will be the conversational mode in future speech interfaces. The real-time task can be <lb/>kept simple: It does not build up much context and can be finished in a couple turns. <lb/>However, we vary the urgency of this task. <lb/>For the ongoing task, a pair of players collaborate to assemble as many poker <lb/>hands as possible, where a poker hand consists of a full house, flush, straight, or four <lb/>of a kind. Each player initially has three cards in hand, which the other cannot see. <lb/>Players take turns drawing an extra card and then discarding one, until they find a <lb/>valid poker hand, for which they earn 50 points; they then start over to form another <lb/>poker hand. To discourage players from rifling through the cards to look for a specific <lb/>one without talking, one point is deducted for each picked-up card, and ten points for a <lb/>missed or incorrect poker hand. To complete this game, players converse to share card <lb/>information, and explore and establish strategies based on the combined cards in their <lb/>hands (Toh, Yang, and Heeman 2006). The poker game is played on computers. The <lb/>game display, which each player sees, is shown in Figure 1. The player with four cards <lb/>can click on a card to discard it. The card disappears from the screen, and a new card <lb/>is automatically dealt to the other player. Once they find a poker hand the player with <lb/>four cards clicks the Done Poker Hand button to start a new game. <lb/>The real-time task is a picture game. From time to time, the computer prompts one <lb/>of the players to determine whether the other has a certain picture on the bottom of the <lb/>display. The picture task has a time constraint of 10, 25, or 40 seconds, which is (pseudo) <lb/>randomly determined. Two solid bars above and below the player&apos;s cards flash when <lb/>there is a pending picture game. This should alert the player to a pending picture game <lb/>without taking the attention away from the poker game. The color of the flashing bars <lb/>depends on how much time remains: green for 26–40 seconds, yellow for 11–25 seconds, <lb/>and red for 0–10 seconds. The player can see the exact amount of time left in the heading <lb/>of the picture game. In Figure 1, the player needs to find out whether the other player <lb/>has a blue circle, with 6 seconds left. The players get 5 points if the correct answer is <lb/>given in time. The overall goal of the players is to earn as many points as possible from <lb/>the two tasks. <lb/> 3.2 Corpus Collection <lb/> We recruited six pairs of players, who each received US $10 for completing the data <lb/>collection. All players were native American English speakers, and had a bachelor&apos;s <lb/>degree or higher in computer science or electrical engineering. None of the players were <lb/>in our research lab, and there was no evidence that any player knew about our research <lb/>program before they participated. <lb/>

			<page>80 <lb/></page>

			<note place="headnote">Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note> 
			
			Figure 1 <lb/> The game display for players. <lb/> The data collection for each pair of players lasted about one hour. Players were <lb/>separated so that they could not see each other and they talked to each other through <lb/>headsets. After a short orientation, the players played the poker game for about 5 <lb/>minutes to become familiar with the rules. They then had a practice conversation with <lb/>both the poker game and the picture game for about 15 minutes, so that they got used to <lb/>managing both tasks. Finally, they had two more conversations, each lasting for about <lb/>15 minutes. In each conversation, nine picture games, three for each urgency level, were <lb/>prompted for each player. In this research, we analyze the last two conversations, but <lb/>not the practice one. Thus we have a total of about 180 minutes of conversation from <lb/>the six pairs of players. <lb/>For each dialogue, we recorded both channels of speech (each in an audio file) and <lb/>created a log file. The log file contains all the events of the computer dealer and the <lb/>GUI actions of the two players for each task with time-stamps. For the poker game, it <lb/>contains information of when a card is dealt or discarded, and information of when a <lb/>poker hand is achieved or missed; for the real-time task, it contains each question, the <lb/>time it is generated, the answer, and the time it is answered. <lb/>A post-experiment survey was conducted in which players were given the follow-<lb/>ing questions: (1) Did you ever play poker before you participated in this experiment? <lb/>(2) Did you always immediately notice the flashing that signaled a new picture task? <lb/>

			<page>81 <lb/></page>

			<note place="headnote">Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note> 
			
			Table 1 <lb/> Summary statistics of game, card, and picture segments for each pair of players. <lb/>R1 <lb/>R2 <lb/>R3 <lb/>R4 <lb/>R5 R6 Total <lb/>Game segments <lb/>7 <lb/>13 <lb/>39 <lb/>35 11 <lb/>15 <lb/>120 <lb/>Card segments <lb/>40 118 227 225 82 <lb/>89 <lb/>781 <lb/>Picture segments 30 <lb/>36 <lb/>36 <lb/>35 35 <lb/>36 <lb/>208 <lb/> (3) Did you ever purposefully ignore a picture task? (4) How did you make use of the <lb/>different urgency levels (40, 25, or 10 seconds)? (5) How did the picture task affect the <lb/>poker game? (6) Do you have any other comments? All players had at least some poker <lb/>experience. All players reported that they always noticed the bars immediately when <lb/>they started to flash, and that they never ignored a real-time task on purpose. Some <lb/>players also mentioned that they enjoyed the games. <lb/> 3.3 Dialogue Segmentation <lb/> We segmented each dialogue into utterances using consensus annotations (see Yang and <lb/>Heeman [2010] for more details), following the guidelines of the Trains corpus (Heeman <lb/>and Allen 1995). We also annotated each utterance as to whether or not it is a trivial <lb/>utterance. We define trivial utterances as those that are just a stall (such as uh and um) <lb/> or a simple acknowledgement (such as okay, uh-huh, and alright). According to Strayer, <lb/>Heeman, and Yang (2003), annotators reached high inter-coder agreement on a similar <lb/>annotation scheme. 2 There are in total about 4,300 non-trivial utterances in playing the <lb/>poker game. <lb/>The ongoing task can be naturally divided into individual poker games, in which <lb/>the players successfully complete a poker hand. Each poker game can be further divided <lb/>into a sequence of card segments, in which players discuss which card to discard, or <lb/>players identify a poker hand. In total, there are 120 game segments and 781 card <lb/>segments in the corpus. We also group the utterances involved in each picture game <lb/>into a segment. Of the 216 prompted picture games, 8 were never started, although <lb/>players reported that they never ignored a picture game. Hence we have 208 picture <lb/>games. Table 1 shows the statistics for each pair of players (R1, R2, ..., R6). <lb/>Figure 2 shows an excerpt from an MTD dialogue with the segmentations. Here b7 <lb/>is a game segment in which players get a poker hand of a flush; and b8, b10, b11, b12, <lb/>and b14, inside of b7, are card segments. Also embedded in b7 are b9 and b13, each of <lb/>which is a segment for a picture game. As can be seen, players switch from the ongoing <lb/>poker-playing to a picture game. After the picture game is completed, the conversation <lb/>on the poker-playing resumes. <lb/>Most of the segments can be automatically derived from the log file. For example, <lb/>the time a new hand is dealt is usually the start of a new game segment; the time a <lb/>new card is dealt is usually the start of a new card segment. We then manually fixed <lb/>any mistakes. For example, a mis-generated segment is removed where a player simply <lb/>discarded a card without any discussion; and a segment boundary is moved if an <lb/>utterance about the card being discarded, typically an acknowledgment, is said after <lb/>the new card is dealt. <lb/>

			<note place="footnote"> 2 They reported an inter-annotator agreement of 92%, which corresponded to  κ =  0.83. <lb/></note>

			<page> 82 <lb/></page>

			<note place="headnote">Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note> 
			
			Figure 2 <lb/> An excerpt of an MTD dialogue. <lb/> The game, card, and picture segments are cohesive units of discourse in which the <lb/>conversants attempt to complete a domain task, that of winning the card game, deciding <lb/>what card to discard, or identifying a picture. Thus they follow Grosz and Sidner&apos;s <lb/>(1986) definition of discourse segments. <lb/> 3.4 Discourse Context <lb/> We define discourse context on the task level. We distinguish three types of discourse <lb/>context where a player suspends the poker playing and switches to a pending picture <lb/>game: (G) immediately after completing a poker game (at the end of a game), (C) <lb/>immediately after discarding a card (at the end of a card discussion), and (E) embedded <lb/>in a card discussion, where players are deciding which card to discard. Corresponding <lb/>to our dialogue segmentations, an interruption at the end of a game is thus a picture <lb/>game segment between two poker game segments; an interruption at the end of a card <lb/>is a picture segment between two card segments; and an interruption embedded in a <lb/>

			<page>83 <lb/></page>

			<note place="headnote">Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note> 
			
			card discussion is a picture segment embedded in a card segment. As shown in Figure 2, <lb/>both b9 and b13 are interruptions at the end of a card discussion. <lb/> 4. Where to Interrupt <lb/> In this section, we examine whether players wait for certain discourse contexts in the <lb/>poker playing to interrupt with a picture game. <lb/> 4.1 Response Delay <lb/> During poker playing, if a picture game is prompted, the bars around the cards flash in <lb/>different colors depending on the amount of time left. It is up to the player to decide <lb/>when to start the picture game (by asking the other player whether there is a certain <lb/>picture at the bottom of the display). The players can start the picture game as soon <lb/>as they notice it, for example, within one second; or they can delay the picture game, <lb/>for example, for 35 seconds, if the time constraint allows. We thus examine the response <lb/>delay, defined as the time interval between when a picture game is prompted and when <lb/>the player starts it, to understand how soon a player responds to a picture game. We are <lb/>particularly interested in how players respond to different urgency levels, i.e., whether <lb/>players wait longer when they are given more time. <lb/>Figure 3 shows the average response delay for each player for the urgency levels of <lb/>10 sec (black), 25 sec (gray), and 40 sec (white), with the actual values displayed in the <lb/>columns below. There are certainly individual differences. Player 5A seems to respond <lb/>to a real-time task as soon as the bars start flashing, regardless of the urgency levels. <lb/>In fact, in 17 out of the 18 picture games, 5A has less than three seconds of response <lb/>delay; and the longest response delay is only 3.22 seconds. Player 4B also has interesting <lb/>behavior: He waits a significant amount of time under the urgency level of 25 sec, but <lb/>promptly responds under the urgency level of 40 sec. However, overall the response <lb/>delay under the urgency levels of 40 sec (M = 12.5 sec) or 25 sec (M = 9.7 sec) is much <lb/>higher than under the urgency level of 10 sec (M = 2.8 sec). The response delay for 40 sec <lb/>is significantly higher than for 10 sec, t(11) = 4.2, p  &lt;  0.001; as is for 25 sec versus 10 sec, <lb/>t(11) = 6.36, p  &lt;  0.001. In fact, for question (4) how did you make use of the different urgency <lb/>levels (40, 25, or 10 seconds) in the post-experiment survey, all players but 5A answered <lb/>that they waited to initiate the picture game when they were given 25 sec or 40 sec (5A <lb/>answered &quot; not really. &quot; ) The 10 sec urgency level requires players to start a picture game <lb/>very quickly in order to complete it in time. On the other hand, when given 25 sec or <lb/>40 sec, players are in less of a hurry to switch. <lb/> 4.2 Urgency Level and Discourse Context <lb/> The results on response delay show that players do not always start the real-time <lb/>picture game as soon as the bars start flashing, especially when players are given 25 sec <lb/>or 40 sec. Of course there are individual differences: Some players wait longer, some <lb/>players wait less time, and one does not even wait. The more interesting question, <lb/>however, is if players do not immediately start the picture game, what is the purpose of <lb/>delaying the switch to this real-time task? Are players delaying the switch just because <lb/>they feel that they have time and thus do not need to rush, or because they want to <lb/>interrupt at a certain point in the ongoing task? <lb/>

			<page>84 <lb/></page>

			<note place="headnote"> Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note> 
			
			Figure 3 <lb/> Response delay for different urgency levels. <lb/> Figure 4 <lb/> Distribution of discourse contexts for task interruptions under different urgency levels. <lb/> We now examine how the urgency level affects where in the discourse context <lb/>players interrupt the ongoing task and switch to the real-time task. Because we do not <lb/>find a statistically significant difference of response delay under the urgency levels of <lb/>25 sec and 40 sec, t(11) = 1.51, p = 0.16, we combine these two urgency levels in this <lb/>analysis. 3 <lb/> Figure 4 shows the distribution of the discourse contexts of task interruptions for the <lb/>urgency levels. Overall the percentage of embedded interruptions for the 10 sec urgency <lb/>level (M  =  76%) is significantly higher than for 25/40 sec (M  =  47%), t(11) = 4.46, p  &lt; <lb/> 0.001. In fact, all players except 4A have a higher percentage of embedded interruptions <lb/>for 10 sec than for 25/40 sec. The percentage of interruptions at the end of a game for <lb/>10 sec (M  =  3%) is significantly lower than for 25/40 sec (M  =  20%), t(11) = 4.16, p  &lt; <lb/> 0.001. In fact, all players have a higher or equal percentage of interruptions at the end <lb/>of a game for 25/40 sec than for 10 sec. These results suggest an answer to our question <lb/>about why players delay switching to the ongoing task. When players are given more <lb/>time, that is, when the picture game is less urgent, players often utilize the additional <lb/>

			<note place="footnote"> 3 In fact, we find that under the urgency levels of 25 sec and 40 sec, players behave similarly in terms of <lb/>the discourse context of task interruptions. The reason for the lack of difference might be that it takes on <lb/>average 90 seconds to complete a poker hand and 14 seconds to complete a card segments. Hence, there <lb/>is little to be gained from separately reasoning about the 25 sec versus 40 sec urgency levels. In hindsight, <lb/>we should have used a longer time for the lowest urgency level. <lb/></note>

			<page> 85 <lb/></page>

			<note place="headnote">Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note> 
			
			time to delay the switch to the real-time task such that this switch would happen at the <lb/>end of a game or a card rather than in the middle of a card discussion. <lb/> 4.3 Response Delay and Discourse Context <lb/> In Section 4.2, we find that players tend to interrupt more often at the end of a card or a <lb/>poker game when they are given more time. However, players do not necessarily wait <lb/>for more time when the picture game is less urgent. For example, player 5A seems to <lb/>always start a picture game as soon as the bars start flashing, regardless of how urgent <lb/>the picture game is. To better understand the rationale of delaying a prompted picture <lb/>game, we next examine the correlation between response delay and the discourse <lb/>context where the switch to the real-time task occurs. <lb/>We assume that if the response delay is shorter than some amount of time, say t  1 , <lb/>players intend to start the picture game as soon as possible; we also assume that if the <lb/>response delay is longer than some other time, say t  2 , players intend to delay the picture <lb/>game. For the window between t  1 and t  2 , it is unclear as to what players are doing due <lb/>to individual differences. In this article, we set t  1 to 3 seconds and t  2 to 6 seconds. From <lb/>listening to the dialogues, it seems to us that when players interrupt within 3 seconds, <lb/>they intend to do so right away, and when players wait at least 6 seconds, they do not. <lb/>These two time points are also consistent with human performance in task switching <lb/>(Meiran, Chorev, and Sapir 2000). This gives us 77 cases of interruptions with a response <lb/>delay of less than 3 seconds, 88 cases greater than 6 seconds, and 43 cases in between. <lb/>We have also examined other time thresholds, and find similar results. <lb/>Figure 5 shows the distribution of the discourse contexts of task interruptions <lb/>regarding the response delay. Because 5A always starts a picture game as soon as the <lb/>bars start flashing, we do not have data for when he waits for more than 6 seconds. We <lb/>thus exclude 5A from this analysis. The percentage of embedded interruptions for less <lb/>than 3 sec response delay (M  =  71%) is significantly higher than for more than 6 sec <lb/>response delay (M  =  41%), t(10) = 3.54, p = 0.002. The percentage of interruptions at the <lb/>end of a game for less than 3 sec response delay (M  =  5%) is significantly lower than <lb/>for more than 6 sec response delay (M  =  23%), t(11) = 3.49, p = 0.003. Compared with <lb/>immediately starting a picture game, if players wait for a certain amount of time, they <lb/>are more likely to suspend the ongoing task at the end of a poker game or a card than <lb/>to suspend the ongoing task in the middle of a card discussion. <lb/> Figure 5 <lb/> Distribution of discourse contexts for task interruptions under different response delays. <lb/>
			
			<page> 86 <lb/></page>

			<note place="headnote">Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note> 
			
			4.4 Discussion <lb/> In our research, we define task-level discourse contexts, and investigate the discourse <lb/>contexts where task interruptions of different urgency occur. We first examine the <lb/>response delay, and find that players do not always interrupt the poker playing as soon <lb/>as a picture game starts flashing, but instead they tend to wait longer for less urgent <lb/>picture games. We then examine the correlation between discourse context and urgency <lb/>level, and find that when given more time players tend to switch more often to a picture <lb/>game at the end of a (poker) game or a card. We finally examine the correlation between <lb/>discourse context and response delay, and find that if players wait for at least a certain <lb/>amount of time, they tend to switch more often to a picture game at the end of a (poker) <lb/>game or a card. These results suggest that players prefer to interrupt at the end of a <lb/>game or a card rather than interrupt in the middle of a card discussion. In fact, after the <lb/>practice session, player pair R3 explicitly decided that they should try to delay a picture <lb/>game until the end of a poker game. In other work, Shyrokov, Kun, and Heeman (2007) <lb/>examined the correlation between task interruption and conversational-level discourse <lb/>context. Similarly, they found that conversants try to avoid interrupting adjacency <lb/>pairs. <lb/>Discourse context is probably not the only factor that determines when players <lb/>switch tasks. We observed that sometimes players had time but still chose to interrupt <lb/>inside a card discussion; or that sometimes players waited past a card segment and then <lb/>interrupted inside the new card discussion. One guess is that at certain points in a card <lb/>discussion, players have less cognitive load and so switch tasks. Another guess is that <lb/>at certain points during poker playing, players get frustrated and decide to switch to a <lb/>pending picture game. However, these analyses are beyond the scope of this article. <lb/> 5. Signaling Task Interruption <lb/> In this section, we examine how players signal that they are switching from the ongoing <lb/>task to a real-time task. In Section 2.3, we discussed how people use certain cues, such as <lb/>discourse markers and prosody, to signal discourse structure in single-tasking speech. <lb/>This suggests that people might also signal task interruptions in multi-tasking dialogues <lb/>and might even use similar cues. <lb/> 5.1 Discourse Markers <lb/> First, we examine whether discourse markers co-occur with task interruptions. For this <lb/>exploratory study, we treat any word that can serve as a discourse maker and that <lb/>precedes a task interruption as a discourse marker, even though their roles in dialogue <lb/>are sometimes ambiguous, such as and, now, and okay (Gravano et al. 2007). We also <lb/>include the fillers uh and um, which were shown to sometimes have a discourse function <lb/>(Swerts 1998). <lb/>Of the total 208 task interruptions, 76 are initiated with a discourse marker, which <lb/>accounts for 36.5%. We list these discourse markers in Table 2 grouped by their discourse <lb/>function. For their use in task interruptions, column 2 shows the number of occurrences <lb/>of each group and column 3 shows the number of players who use them. The first <lb/>group consists of oh and wait, which are usually used to signal a sudden or urgent <lb/>event (Heritage 1984; Schiffrin 1987; Byron and Heeman 1997). This group has the <lb/>most frequently uttered discourse markers in task interruption with 27 occurrences, and <lb/>seven players utter them at least once. The second group consists of the fillers uh and <lb/>

			<page>87 <lb/></page>

			<note place="headnote">Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note> 
			
			Table 2 <lb/> List of discourse markers used in task interruptions. <lb/>Discourse Markers <lb/>Total Occurrences Number of Players <lb/>oh wait <lb/>27 <lb/>7 <lb/>um uh <lb/>23 <lb/>10 <lb/>now okay alright <lb/>13 <lb/>8 <lb/>and <lb/>10 <lb/>5 <lb/>OTHERS (so but hey) <lb/>3 <lb/>3 <lb/> um. This group is uttered by the most players with 23 occurrences. The third group <lb/>consists of now, okay, and alright, which can signal the end of the current topic and <lb/>moving on to the next (Hirschberg and Litman 1987; Gravano et al. 2007). This group <lb/>has 13 occurrences by eight players. The word and is uttered 10 times by five players. <lb/>Finally there is one occurrence of so, one of but, and one of hey. Interestingly, there are <lb/>also two cases of calling the name of the other player, such as Gary do you have a blue <lb/>triangle? <lb/> We next examine the discourse markers oh and wait in more depth. We choose them <lb/>because this group co-occurs most frequently with task interruptions, and because task <lb/>interruptions involve starting a new and urgent task, which fits their discourse function. <lb/>Verifying whether oh and wait are being used as discourse markers is straightforward. <lb/>We manually verified that all 27 instances of oh and wait that initiated a picture game <lb/>are discourse markers, and we also identified all usages of oh and wait in poker playing <lb/>that are discourse markers. For each player, we calculated the rate of task interruptions <lb/>initiated with an oh or wait, and compared it with two baselines: (1) the rate of non-<lb/>trivial utterances in poker playing that are initiated with an oh or wait, and (2) the rate <lb/>of card segments that are initiated with an oh or wait. The rate of task interruptions <lb/>initiated with an oh or wait (M  =  12.7%) is significantly higher than the rate of utterances <lb/>initiated with an oh or wait (M  =  5.7%), t(11) = 1.80, p = 0.05. It is also higher than the rate <lb/>of card segments initiated with an oh or wait (M  =  7.1%), which is marginally significant <lb/>t(11) = 1.66, p = 0.06. These results suggest that the discourse markers oh and wait are <lb/>sometimes used in signaling task interruptions. <lb/> 5.2 Prosody <lb/> To understand the prosodic cues in initiating a topic, traditionally researchers compared <lb/>the prosody of the first utterance in each topic with other utterances (e.g., Nakajima and <lb/>Allen 1993; Hirschberg and Nakatani 1996). For example, they calculated the average <lb/>pitch in the utterance or the first part of the utterance that initiates a topic and found <lb/>that it is higher than the other utterances in the topic. This approach encounters two <lb/>problems here. First, the words in an utterance might affect the prosody. For example, <lb/>the duration and energy of bat are usually larger than bit. Thus a large amount of data are <lb/>required to balance out these differences. Second, in the MTD corpus, players typically <lb/>switch to a picture game by using a yes–no question, such as do you have a blue circle, <lb/> whereas most non-trivial utterances in the ongoing task are statements or proposals. As <lb/>questions have very different prosody than statements or proposals, a direct comparison <lb/>is further biased. <lb/>Examination of the MTD corpus finds that 82% (170/208) of the picture games are <lb/>initiated by do you have ... with optional discourse markers at the beginning. While in <lb/>

			<page>88 <lb/></page>

			<note place="headnote">Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note> 
			
			Figure 6 <lb/> Average pitch of do you have for task interruptions and poker playing. <lb/> the poker game, players use do you have ... 115 times to ask whether the other has certain <lb/>cards, such as do you have a queen? This abundance of utterances with identical initial-<lb/>wording and speech-act-type inspired us to compare the prosody of the phrase do you <lb/>have in switching to a picture game and during poker-playing. 4 This avoids comparing <lb/>prosody of different words or of different types of utterances. <lb/>We measure pitch, energy (local root mean squared measurement), and duration <lb/>of each case of do you have. We aggregate on each individual player and calculate the <lb/>average values. Figure 6 shows the average pitch of the phrase do you have in task inter-<lb/>ruption (INT) and poker-playing (PKR) of each player, with the actual values displayed <lb/>in the columns below. For task interruption, players&apos; average pitch is significantly <lb/>higher than poker-playing, t(11) = 4.82, p  &lt;  0.001. In fact, for each of the 12 players, <lb/>the average pitch of do you have in task interruption is higher than in poker-playing. <lb/>These results show a strong correlation between task interruption and higher pitch. <lb/>We also examine energy and duration (speaking rate) for the phrase do you have in <lb/>task interruption and poker-playing. However, we do not find a statistically significant <lb/>difference in energy, t(11) = 1.53, p = 0.16, or in duration t(11) = 1.67, p = 0.12. <lb/> 5.3 Intensity of Cues <lb/> To better understand how pitch is used in signaling task interruptions, we next examine <lb/>whether it correlates with the discourse context of interruptions, namely, interrupting <lb/>at the end of a game, at the end of a card discussion, or embedded in a card discussion. <lb/>Because there are relatively fewer data for interrupting at the end of a game, we combine <lb/>interruptions at the end of a game and at the end of a card discussion (G/C). <lb/>Figure 7 shows the average pitch of do you have when switching to a picture game <lb/>embedded in a card discussion, at the end of a game or card discussion, and during <lb/>poker-playing (i.e., no task switching involved), with the actual values displayed in the <lb/>columns below. The difference between these three conditions is statistically significant, <lb/> F(2, 11)  =  21.60, p  &lt;  0.001. Interruptions embedded in a card discussion has a signifi-<lb/>cantly higher pitch than at the end of a game or card discussion, t(11) = 5.74, p  &lt;  0.001, <lb/>

			<note place="footnote"> 4 It would have been interesting to compare the prosody of utterances that initiate a picture game and <lb/>those that initiate a card segment. However, we do not have enough utterances that initiate a card <lb/>segment that begin with do you have. <lb/></note>

			<page> 89 <lb/></page>

			<note place="headnote">Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note> 
			
			Figure 7 <lb/> Average pitch of do you have for different discourse contexts. <lb/> which in turn has a significantly higher pitch than during poker-playing, t(11) = 3.56, <lb/>p = 0.002. These results suggest a statistical correlation between discourse context of <lb/>task interruption and intensity of cues. 5 <lb/> 5.4 Discussion <lb/> We find that discourse markers are sometimes used to mark task interruptions, but for <lb/>less than 40%. For the discourse markers oh and wait, we find a statistical correlation <lb/>between their use and task interruptions. This result should not be surprising as task <lb/>interruptions involve a sudden change of the conversation topic, and previous research <lb/>found that conversants use oh to mark a change of state in orientation or awareness. <lb/> wait is used to mark a discontinuity in the ongoing topic, which is also required by <lb/>task switching. Thus, it seems natural for people to use these discourse markers to <lb/>signal switching to a real-time task. The use of the other discourse markers is less clear, <lb/>but we have some speculations about their use with task interruptions. The discourse <lb/>markers now, okay, and alright tend to start a new topic in single-tasking speech, which <lb/>is consistent with initiating a task interruption. The fillers um and uh might be used to <lb/>hold the floor giving the player who initiates the picture game extra time to mentally <lb/>switch tasks; or they might be used to help mark the switch itself, similar to how they <lb/>sometimes mark topic shifts (Swerts 1998). Calling the name of the other player or <lb/>saying hey might be used to alert the other player of the task switching. <lb/>We also find that players signal task interruptions with prosodic cues. Pitch turns <lb/>out to be the most prominent feature. Not only do we find a strong correlation between <lb/>higher pitch and task interruption, but we also find a correlation between pitch and <lb/>the discourse context of the interruption. Switching embedded in a card segment has a <lb/>higher pitch than switching at the end of a card segment or a game, which in turn has <lb/>a higher pitch than non-switching (poker-playing). We speculate that pitch, as well as <lb/>discourse markers and calling the name of the other player, is used to disengage the <lb/>hearer from the ongoing task, signaling an unexpected event (see Section 8.1 for more <lb/>discussion). <lb/>

			<note place="footnote"> 5 We are also interested in whether players alter their use of discourse markers depending on the place of <lb/>interruption. However, perhaps due to a lack of data, we do not find a statistical difference. <lb/></note>

			<page> 90 <lb/></page>

			<note place="headnote">Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note> 
			
			On the other hand, we do not find a statistically significant correlation between <lb/>energy and task interruption, or between speaking rate and task interruption. It would <lb/>be interesting to understand why pitch is used yet not other prosodic cues. In another <lb/>study, in which we examined initiative conflicts, where both conversants speak at the <lb/>same time trying to steer the conversation in different directions, we found that energy <lb/>is the dominant device for resolving who wins the conflict (Yang and Heeman 2010). <lb/>Probably conversants use different prosodic devices, such as pitch, energy, and speaking <lb/>rate, for different conversational functions. Further research is needed to explore this <lb/>hypothesis. <lb/>Finally, it is also interesting to investigate whether players signal the urgency of the <lb/>real-time task. In our task setup, besides the urgency level, which is the time (10 sec, <lb/>25 sec, or 40 sec) initially given to the players to complete a picture game, a more <lb/>important factor that defines urgency is the remaining time, which is the time left <lb/>to complete a picture game when players switch to it. Intuitively, when players start <lb/>a picture game, the more time that is remaining to finish the task, the less hurried <lb/>they need to be. However, we were not able to find a statistical correlation between <lb/>urgency level and pitch, or between remaining time and pitch. Nor was there a statistical <lb/>correlation with volume or speaking rate. Our explanation is that our task setup might <lb/>not be complicated enough. It only takes a couple utterances to finish a picture game, <lb/>and players were able to start the picture task far enough ahead that remaining time <lb/>was rarely a factor. <lb/> 6. Context Restoration <lb/> On completing an interrupting picture game, players resume poker playing. Due to <lb/>our task setup, players tend to mutually know when a picture game ends. Thus we do <lb/>not examine how players signal task resumption, but instead we focus on how players <lb/>restore the context of the ongoing task, that is, how players re-establish the conversation <lb/>on poker playing after being interrupted by a picture game. We use the same distinction <lb/>of discourse contexts as we use in examining task interruptions: (1) restoration in the <lb/>middle of a card discussion, which corresponds to the players interrupting embedded <lb/>in a card discussion; (2) restoration at the beginning of a card, which corresponds to the <lb/>players interrupting after a card discussion, and then resuming to poker playing with <lb/>one of the players having a new card; and (3) restoration at the beginning of a game, <lb/>which corresponds to the players interrupting at the end of a poker game, and then <lb/>resuming to poker playing with the beginning of another poker game. <lb/> 6.1 Restoration in the Middle of a Card Discussion <lb/> We start by investigating context restoration in the middle of a card discussion, because <lb/>these have the most context. We explored the corpus to look for signs of context restora-<lb/>tion behavior after an embedded interruption, by examining informational redundancy <lb/>(Walker 1996) of the first non-trivial utterance after completing a picture game. <lb/>Probably due to the simplicity of the picture game, especially that it can be com-<lb/>pleted in a couple turns, we find that after completing an embedded picture game <lb/>players usually continue poker playing without a clear indication of context restoration. <lb/>As shown in Example (1), B suspends his own question in poker playing and interrupts <lb/>with a picture game. After the completion of the picture game, A gives the answer to <lb/>B&apos;s original question right away: The dialogue on poker playing continues as if the <lb/>interruption never happened. <lb/>

			<page>91 <lb/></page>

			<note place="headnote"> Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note> 
			
			Example 1 (Continuation) <lb/> B: what do you have to make a high straight with? <lb/>B: <lb/>you got a red circle? <lb/>A: no <lb/>A: I have a ten of diamonds and an ace of clubs <lb/> We do, however, find two types of utterances at the beginning of a resumption that <lb/>are informationally redundant (Walker 1996), as listed here. <lb/> Utterance Restatement: The first non-trivial utterance after the interruption is a re-<lb/>statement of the last non-trivial utterance before the interruption. This can be <lb/>further divided into three sub-categories: A) self-repetition: the player repeats <lb/>(part of) his or her own utterance, as shown in Example (2); B) other-repetition: <lb/>the player repeats (part of) the other&apos;s utterance, as shown in Example (3); and C) <lb/>clarification: the player asks for a repetition with a clarification question, as shown <lb/>in Example (4). <lb/> Example 2 (Self-Repetition) <lb/> B: I have three clubs right now <lb/>B: do you have a yellow square? <lb/>A: yes <lb/>B: I have three clubs <lb/>B: do you have any clubs? <lb/> Example 3 (Other-Repetition) <lb/> B: I have jack and two queens <lb/>B: um do you have a yellow plus sign? <lb/>A: yes <lb/>A: a jack and two queens <lb/>A: I have a ten <lb/> Example 4 (Clarification) <lb/> A: I have a six of clubs a nine of spades and a four of diamonds <lb/>B: okay <lb/>B: okay how about a uh red cross <lb/>A: no <lb/>B: okay <lb/>B: four diamonds six something? <lb/>A: clubs <lb/> Card Review: The player re-communicates what cards are in hand, as shown in Exam-<lb/>ple (5). We define card review as utterances that inform of all of the cards in the <lb/>player&apos;s hand, and where this information has already been communicated. <lb/> Example 5 (Card Review) <lb/> A: so I got a ten of spades <lb/>B: alright <lb/>B: and do you have a red circle? <lb/>A: um yes <lb/>B: I mean no no a blue circle <lb/>A: oh yes <lb/>A: and okay I have a queen of spades a ten of I mean a queen <lb/>of diamonds a ten of spades a king of clubs and a two of clubs <lb/>

			<page> 92 <lb/></page>

			<note place="headnote">Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note> 
			
			For the 115 embedded interruptions, we find 34 cases of utterance restatement (20 <lb/>self-repetitions, 4 other-repetitions, and 10 clarifications) and 9 cases of card review. <lb/>Figure 8 shows the rate of each category, aggregated on each pair of players (R1-R6). <lb/>The rate of utterance restatements, calculated as the number of embedded inter-<lb/>ruptions that are followed by an utterance restatement divided by the total number <lb/>of embedded interruptions, ranges from 22% to 37% among the player pairs. To make <lb/>sense of these numbers, we annotate each non-trivial utterance in the poker games to <lb/>mark whether it is a restatement of the immediate previous one within a card segment, <lb/>and calculate the baseline as the rate of performing utterance restatement without being <lb/>interrupted by a picture game. From Figure 8, we see that for all six pairs of players, the <lb/>rate of utterance restatement after an embedded interruption is higher than the baseline, <lb/>and it is statistically significant, t(5) = 13.52, p  &lt;  0.001. This suggests that utterance <lb/>restatement after an embedded interruption is not a random behavior, but it is part of <lb/>the resumption to the ongoing task. <lb/>We next examine card review, which does not seem to be a common behavior in all <lb/>player pairs. The pairs R1, R4, and R6 never performed it in resuming poker playing, <lb/>and R2 only performed it once. The pairs with the highest rates are R5 and R3, with <lb/>26% (6/23) and 17% (2/12), respectively. Interestingly, these two pairs have the lowest <lb/>rates of performing utterance restatement, with 22% and 27%, respectively. This might <lb/>suggest that card review might be complementary to utterance restatement for context <lb/>restoration, although more data are needed to validate this hypothesis. <lb/> 6.2 Restoration at the Beginning of a Card Segment <lb/> For restoration at the beginning of a card segment, we find that players mostly just <lb/>continue poker playing without a clear indication of being affected by the interruption, <lb/>as illustrated by card segments b10 and b14 in Figure 2. Some players might perform an <lb/>act similar to card review, in that they communicate all of the cards in his or her hand. <lb/>However, the version here differs as it includes the new card just picked up, which has <lb/>not been communicated before. Thus we refer to this act as card review + new card. <lb/> Table 3 shows the rate of performing card review + new card after an interruption for <lb/>each pair, respectively. The baseline is the rate of performing this action at the beginning <lb/> Figure 8 <lb/> Restoration in the middle of a card discussion. <lb/>

			<page> 93 <lb/></page>

			<note place="headnote">Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note> 
			
			Table 3 <lb/> Restoration at the beginning of a card segment. <lb/>R1 <lb/>R2 <lb/>R3 <lb/>R4 <lb/>R5 <lb/>R6 <lb/>Card review + new card 0% <lb/>19% <lb/>9% <lb/>8% <lb/>0% <lb/>42% <lb/>(0/2) <lb/>(3/16) (1/11) <lb/>(1/13) <lb/>(0/9) <lb/>(5/12) <lb/>B a s e l i n e <lb/>0 % <lb/>6 % <lb/>1 % <lb/>3 % <lb/>0 % <lb/>5 % <lb/>(0/31) (5/89) (2/177) (5/177) (0/62) (3/62) <lb/> of a card segment (excluding the first card segment of a poker game) not following an <lb/>interruption of a picture game. Player pairs R1 and R5 never performed this action at <lb/>all. R3 and R4 performed this action only once after interruptions at the end of a card <lb/>discussion and have a very low overall rate of performing this action during poker <lb/>playing. However, for player pairs that have a high overall rate of using this action (R2 <lb/>and R6), they have an even higher rate of using this action after an interruption. For R6 <lb/>in particular, the rate of performing this action after an interruption at the end of a card <lb/>segment is significantly higher than the baseline,  χ  2 (1)  =  6.81, p = 0.01. This suggests <lb/>that if players use card review + new card in conversation, they tend to use it more often <lb/>after an interruption at the end of a card segment probably for context restoration. <lb/> 6.3 Restoration at the Beginning of a Game <lb/> For interruptions at the beginning of a poker game, we do not find any behavior <lb/>associated with context restoration. This is not surprising because there is really no <lb/>context that needs to be carried over to the next game. <lb/> 6.4 Discussion <lb/> In this section, we examine the behavior of context restoration when players complete <lb/>an interrupting picture game and resume poker playing. Probably due to the simplicity <lb/>of the picture game, we find that players mostly just have a smooth continuation as if <lb/>the interruption did not happen. However, we do find that players sometimes make <lb/>two types of context restorations—utterance restatements and card reviews—and we <lb/>find that players have a higher rate of performing these when returning to the ongoing <lb/>task. <lb/>Card review seems to be refreshing the critical information needed to complete a <lb/>task, while utterance restatement is refreshing the last utterance. Both types of restora-<lb/>tion behavior are similar to the informationally redundant units that Walker (1996) <lb/>studied. In Walker&apos;s work, she posited a limited memory model in which information <lb/>will eventually fade away. This might be the explanation here as well. On resuming to <lb/>a task that was discussed several utterances ago, the conversant might feel that some <lb/>of the critical information might have been forgotten, and so might use card review to <lb/>refresh the information. Conversely, the conversant might feel that just the last utterance <lb/>needs to be refreshed. Depending on whether it is the same conversant who resumes the <lb/>ongoing task and who says the last utterance before the interruption, it takes the form <lb/>of a self-repetition, other-repetition, or request-repetition if clarification is needed. This <lb/>explanation for card review and utterance restatement is consistent with the results of <lb/>our post-experiment survey, in which some players reported that they had difficulties <lb/>

			<page>94 <lb/></page>

			<note place="headnote">Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note> 
			
			remembering the context of poker playing when they were interrupted by a picture <lb/>game. <lb/>In a more complex domain, conversants will probably perform context restoration <lb/>more frequently when returning to an interrupted task (Gillie and Broadbent 1989; <lb/>Villing 2010), and might use even higher-level summarization beyond utterance restate-<lb/>ment and information review, such as reviewing the agreements or decisions that have <lb/>been made so far in the conversation. <lb/> 7. Recognizing Task Interruption: A Machine Learning Approach <lb/> Recognizing task switching is important for a speech interface; for example, the speech <lb/>interface can accordingly switch the language model when it detects that the user has <lb/>switched to another task. In this section, we describe two machine learning experiments <lb/>of recognizing task interruptions using prosody, discourse context, and discourse mark-<lb/>ers. The purpose of the first experiment is to understand how these features contribute <lb/>to the automatic identification of task interruptions; here, we only include utterances <lb/>that start with do you have for better extracting prosodic features. The purpose of the <lb/>second experiment is to investigate how well interruptions can be identified without <lb/>using lexical features, as could be used in an actual system. <lb/> 7.1 Recognizing Task Interruptions on Do You Have Utterances <lb/> In the previous sections, we examined players&apos; behavior of task switching in the MTD <lb/>corpus. We found that players favor certain discourse contexts in the ongoing task for <lb/>task interruptions, and that they signal task interruptions with prosodic cues and some-<lb/>times with certain discourse markers (oh and wait). We thus conduct a machine learning <lb/>experiment to understand how these features contribute to the automatic identification <lb/>of task interruptions. In this experiment, we focus on the 285 cases of do you have, 170 <lb/>for task interruption and 115 for poker playing. As we argued in Section 5.2, this allows <lb/>us to better extract and understand prosodic features of task interruptions. <lb/>We extract the following features: 1) discourse context: whether the utterance before <lb/> do you have is the end of a poker game, the end of a card segment, or in the middle of a <lb/>card segment; 2) oh/wait: whether the discourse marker oh/wait precedes do you have; <lb/> 3) normalized pitch: the pitch of do you have divided by the average pitch of the speaker <lb/>during the dialogue. We refer to these features as the core feature set, which we found <lb/>to be correlated with task interruptions (Section 4 and 5). We also include the following <lb/>additional features: 4) discourse markers: whether a discourse marker precedes do you <lb/>have; 5) normalized energy: the energy of do you have divided by the average energy of <lb/>the speaker during the dialogue; and 6) duration: the duration of do you have. <lb/> We use a decision tree classifier (C4.5) to discriminate task interruption from poker <lb/>playing (Quinlan 1986). C4.5 builds a decision tree by using a top–down, greedy pro-<lb/>cedure to (locally) optimize mutual information, and prunes the tree with a confidence <lb/>level (of 25%). We use C4.5 because its output is interpretable and we have found its <lb/>performance comparable to other discriminative classifiers for this task. <lb/>We use three re-sampling methods in training and testing the decision tree learn-<lb/>ing, which we refer to as general-leave-one-out, speaker-leave-one-out, and leave-one-<lb/>speaker-out. In the general leave-one-out method, each data point is tested with the <lb/>decision tree trained on all other data points. This approach allows decision trees to <lb/>be built with as much training data as possible, which in our case is 284 data points. <lb/>

			<page>95 <lb/></page>

			<note place="headnote">Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note> 
			
			Table 4 <lb/> Performance for general-leave-one-out. <lb/>Accuracy <lb/>Recall <lb/>Precision <lb/>F <lb/>Baseline <lb/>59.6% <lb/>100.0% <lb/>59.6% <lb/>74.7% <lb/>Core features <lb/>81.4% <lb/>89.4% <lb/>81.3% <lb/>85.2% <lb/>Core + discourse markers <lb/>80.7% <lb/>88.2% <lb/>81.1% <lb/>84.5% <lb/>Core + energy + duration <lb/>80.7% <lb/>85.3% <lb/>82.9% <lb/>84.6% <lb/>All features <lb/>80.4% <lb/>84.7% <lb/>82.8% <lb/>83.7% <lb/> In the speaker-leave-one-out method, each data point is tested with the decision tree <lb/>trained on the other data points of the same player. This approach is a speaker-specific <lb/>model that evaluates the performance of training a decision tree and testing on the same <lb/>speaker. In the leave-one-speaker-out method, each player&apos;s data are tested with the <lb/>decision tree trained on the other 11 players. This approach is a speaker-independent <lb/>model that evaluates the performance of a learned decision tree on a new speaker. <lb/>Table 4 shows the results with the general-leave-one-out method. The decision tree <lb/>learning with the core feature set obtains an accuracy of 81.4% in recognizing whether <lb/>a do you have initiates a task interruption or belongs to poker playing; and the recall, <lb/>precision, and F-score for task interruption are 89.4%, 81.3%, and 85.2%, respectively. <lb/>For comparison, we use a naive baseline that assumes that all cases of do you have are <lb/>task interruptions, which has an accuracy of 59.6%. Thus we achieve 54.0% relative error <lb/>reduction in comparison to the baseline. These results show that our machine learning <lb/>approach substantially improves the recognition of task interruptions. <lb/>Also from Table 4 we see that there is no improvement by adding more features, <lb/>namely, discourse markers, energy and duration, or all of them. This suggests that <lb/>these features are not adding more information to this discrimination task, which is <lb/>not surprising as we did not find them strongly correlated with task interruption in our <lb/>corpus study. <lb/>Table 5 shows the results for each player with the general-leave-one-out, the <lb/>speaker-leave-one-out, and the leave-one-speaker-out, using the core feature set. <lb/> Table 5 <lb/> Accuracy for the three re-sampling methods. <lb/>Player General-leave-one-out Speaker-leave-one-out Leave-one-speaker-out <lb/>1A <lb/>75.0% <lb/>66.7% <lb/>75.0% <lb/>1B <lb/>84.6% <lb/>69.2% <lb/>73.1% <lb/>2A <lb/>77.8% <lb/>74.1% <lb/>77.8% <lb/>2B <lb/>100.0% <lb/>90.0% <lb/>95.0% <lb/>3A <lb/>88.0% <lb/>88.0% <lb/>88.0% <lb/>3B <lb/>76.7% <lb/>76.7% <lb/>72.6% <lb/>4A <lb/>94.4% <lb/>94.4% <lb/>94.4% <lb/>4B <lb/>64.7% <lb/>64.7% <lb/>64.7% <lb/>5A <lb/>73.9% <lb/>69.6% <lb/>73.9% <lb/>5B <lb/>92.9% <lb/>71.4% <lb/>92.9% <lb/>6A <lb/>89.5% <lb/>84.2% <lb/>78.9% <lb/>6B <lb/>63.6% <lb/>90.9% <lb/>63.6% <lb/>Mean <lb/>81.8% <lb/>78.3% <lb/>79.2% <lb/>

			<page> 96 <lb/></page>

			<note place="headnote"> Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note>
			
			Overall, all the three reach an accuracy of about 80%, which is much higher than the <lb/>baseline performance. The performance with the leave-one-speaker-out (M  =  79.2%), <lb/>which is a speaker-independent model, is particulary encouraging, because in building <lb/>a speech interface, it is not always possible to collect speaker-specific data. On the <lb/>other hand, we see that the performance with the speaker-leave-one-out (M  =  78.3%) <lb/>is slightly lower than the leave-one-speaker-out (M  =  79.2%). Although this could <lb/>be interpreted as that interruption recognition is a speaker-independent task, we <lb/>think that a more viable explanation is that for some players, we do not have enough <lb/>data to build speaker-specific decision trees. The general-leave-one-out (M  =  81.8%), <lb/>which uses the most data for training, out-performs the leave-one-speaker-out and <lb/>the speaker-leave-one-out. In fact, the general-leave-one-out can also be viewed as a <lb/>naive speaker-adaptive model by simply combining speaker-independent data and <lb/>speaker-specific data together for training. We speculate that more improvement can be <lb/>achieved by interpolating a speaker-independent model with a speaker-specific model, <lb/>which we leave for future work. <lb/>Finally, we examine the structure of the decision trees learned. Here, we build a <lb/>single tree from all 285 cases of do you have with the core feature set, shown in Figure 9. <lb/>In the decision tree, the first query is about pitch. If pitch is low it is for poker playing, <lb/>otherwise it queries about oh/wait. If the utterance starts with a oh or wait, it is for task <lb/>interruptions, otherwise it queries about discourse context. If the discourse context is at <lb/>the end of a game or a card discussion, it is for task interruption, otherwise it queries <lb/>pitch again. If pitch is lower than a threshold it is for poker playing, otherwise it is for <lb/>task interruptions. The structure of the learned tree and its performance confirm that <lb/>discourse context, the discourse markers oh and wait, and normalized pitch are useful <lb/>features for recognizing task interruptions. <lb/> Figure 9 <lb/> The learned decision tree. <lb/>

			<page> 97 <lb/></page>

			<note place="headnote"> Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note> 
			
			7.2 Recognizing Task Interruptions on All Utterances <lb/> The previous experiment helped us determine which features are useful for recognizing <lb/>task interruptions. However, the experiment was based only on utterances that start <lb/>with do you have, yet not all task interruptions are initiated with do you have. We <lb/>thus conduct a further machine learning experiment on recognizing task interruptions <lb/>involving any utterances. We extend our feature set to help make up for not limiting <lb/>ourselves to do you have utterances. We purposely do not use any lexical features of <lb/>the current utterance so that our approach can be applied before speech recognition is <lb/>performed. <lb/>We extract the following features for all non-trivial utterances: 1) discourse context: <lb/>whether the previous utterance is the end of a poker game, the end of a card segment, <lb/>or in the middle of a card segment; 6 2) overlap: whether the utterance overlaps with the <lb/>previous non-trivial utterances; 3) duration: the length in time of the utterance; 4) nor-<lb/>malized pitch: the average normalized pitch of the first 100 msec/200 msec/500 msec <lb/>and the whole utterance (four features); 5) normalized energy: the average normalized <lb/>energy of the first 100 msec/200 msec/500 msec and the whole utterance (four features); <lb/>and 6) pitch range: the pitch range of the first 100 msec/200 msec/500 msec and the <lb/>whole utterance (four features). In total we have 15 features. <lb/>The data that we have are highly skewed. We have 208 cases of task interruptions <lb/>but more than 4,000 non-interrupting utterances. We thus perform down-sampling so <lb/>that both classes have the same number of data points. In the first down-sampling, <lb/>which we refer to as general down-sampling, we use all 208 cases of task interruptions, <lb/>and we randomly select 208 non-interrupting utterances. A concern with the general <lb/>down-sampling is that 82% of the task interruptions are do you have questions, and do <lb/>you have questions are only about 2.5% of the non-interrupting utterances. It is unclear <lb/>whether a classifier trained from such a data set discriminates task interruptions or <lb/>discriminates do you have utterances. Thus in the second down-sampling, which we <lb/>refer to as DYH down-sampling, we use all 208 cases of task interruptions, and we also <lb/>use all 105 cases of non-interrupting do you have utterances, then finally we randomly <lb/>select 103 other non-interrupting utterances. The DYH down-sampling, however, still <lb/>has imbalanced do you have utterances in the two classes. Thus we further introduce <lb/>the Balanced-DYH down-sampling, in which we use all 105 do you have utterances <lb/>in the poker playing and 38 other (i.e., non do you have) utterances in task interrup-<lb/>tions, and randomly select 105 do you have utterances from task interruptions and <lb/>38 other utterances from poker playing. We run the experiments with decision tree <lb/>learning (C4.5) (Quinlan 1986) and support vector machine (SVM) (Chang and Lin <lb/>2001). <lb/>We evaluate the performance using general-leave-one-out. The procedure of <lb/>down-sampling and general-leave-one-out is repeated 10 times, and then we calculate <lb/>the average performance. Note that in our evaluation, the distribution of task inter-<lb/>ruption (which is 50%) is different from the true distribution in the corpus (which is less <lb/>than 5%). We adopt some metrics from medical diagnostic tests that do not involve <lb/>prior distributions. Sensitivity is defined as TruePositive/(TruePositive  +  FalseNegative), <lb/> which, in our case, is the recall of task interruptions. It measures the percentage <lb/>of task interruptions that the classifier correctly identifies as such. Specificity is <lb/>

			<note place="footnote"> 6 Card and game segments could be determined fairly accurately from the mouse clicks even without <lb/>the speech. <lb/></note>

			<page> 98 <lb/></page>

			<note place="headnote">Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note> 
			
			defined as TrueNegative/(TrueNegative  +  FalsePositive), which, in our case, is the re-<lb/>call of non-interruptions. It measures the percentage of non-interruptions that the <lb/>classifier correctly identifies as such. These two metrics can then be combined <lb/>using the likelihood ratio, which provides a direct estimate of how much a prediction <lb/>will change the odds. The likelihood ratio for a positive result (LR+) is defined as <lb/> LR+  =  sensitivity/(1  −  specificity). It tells us how much the odds of a task interruption <lb/>increase when the classifier predicts positive (task interruption). The likelihood ratio <lb/>for a negative result (LR−) is defined as LR−  =  specificity/(1  −  sensitivity). It tells us <lb/>how much the odds of a task interruption decrease when the classifier predicts negative <lb/>(non-interruption). <lb/>Table 6 shows the results. If we assume a naive baseline with no knowledge, its <lb/>sensitivity and specificity are both 50%, and LR+ and LR− are both 1.0. For all three <lb/>down-sampling settings, SVM performs slightly better than C4.5, and both are much <lb/>better than the baseline. The result for SVM with general down-sampling shows how <lb/>well we can recognize task interruptions for our MTD domain, for which we achieve a <lb/>sensitivity of 78.6% and a specificity of 76.9%. For the Balanced-DYH down-sampling, <lb/>in which we have the same number of do you have utterances in both the classes, SVM <lb/>cannot make use of the features that distinguish do you have from other utterances. <lb/>Hence, its result might be more indicative of performance in other domains, where <lb/>task interruptions might not be marked by the same introductory words. Even here, <lb/>we obtain a sensitivity of 75.3%, a specificity of 75.8%, and 3.11 in LR+ and 3.07 in LR−, <lb/>which is more than a 50% relative error reduction over the baseline. <lb/>Overall, our results show that non-lexical features are useful for the recognition of <lb/>task interruptions. Because the features used in our machine learning experiments do <lb/>not require the lexical information of the current utterance, we can make use of the <lb/>identification of task interruptions to benefit automatic speech recognition (ASR). For <lb/>example, we can build two language models, one for the ongoing task, and one for the <lb/>real-time task. For each utterance, we can calculate the likelihood of the utterance being <lb/>a task interruption, using the decision tree classifier or the SVM classifier. We can then <lb/>use this likelihood to dynamically interpolate the two language models in the speech <lb/>decoding. This should be able to improve the accuracy of ASR, which we leave for <lb/>future work. <lb/> 8. Conclusion <lb/> In this article we describe a series of empirical studies of human–human multi-tasking <lb/>dialogues, where people perform multiple verbal tasks overlapped in time. We first <lb/> Table 6 <lb/> Performance for non-lexical features. <lb/>Sensitivity Specificity LR+ LR− <lb/>Baseline <lb/>50.0% <lb/>50.0% <lb/>1.0 <lb/>1.0 <lb/>C4.5 + general down-sampling <lb/>77.5% <lb/>75.3% <lb/>3.14 <lb/>3.35 <lb/>C4.5 + DYH down-sampling <lb/>72.9% <lb/>73.2% <lb/>2.72 <lb/>2.70 <lb/>C4.5 + B-DYH down-sampling <lb/>69.4% <lb/>71.8% <lb/>2.46 <lb/>2.35 <lb/>SVM + general down-sampling <lb/>78.6% <lb/>76.9% <lb/>3.40 <lb/>3.59 <lb/>SVM + DYH down-sampling <lb/>78.6% <lb/>78.4% <lb/>3.64 <lb/>3.66 <lb/>SVM + B-DYH down-sampling <lb/>75.3% <lb/>75.8% <lb/>3.11 <lb/>3.07 <lb/>

			<page> 99 <lb/></page>

			<note place="headnote">Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note> 
			
			examined the discourse context of task interruptions, that is, where conversants sus-<lb/>pend the ongoing task and switch to a real-time task. Our analysis shows that people <lb/>are more likely to wait until the end of a card or game segment for task switching. <lb/>We then examined the cues that people use to signal task interruptions. We find that <lb/>task interruptions correlate with certain discourse markers and prosodic variations. <lb/>More interestingly, the intensity of pitch depends on the discourse context of the task <lb/>interruption. We next conducted an exploratory study on context restoration in task <lb/>resumption. We find that when returning to an interrupted task, conversants sometimes <lb/>re-synchronize the interrupted ongoing conversation by either restating a previous <lb/>utterance or summarizing the critical information. Finally, our machine learning ex-<lb/>periments show that discourse context, pitch, and the discourse markers oh and wait <lb/> are useful features to reliably recognize task interruptions; and, more importantly, with <lb/>non-lexical features one can improve the performance of recognizing task interruptions <lb/>with more than a 50% relative error reduction over the baseline. <lb/> 8.1 Disruptiveness of Task Interruption <lb/> In our study on multi-tasking dialogues, we distinguish three types of discourse con-<lb/>texts where players suspend the poker player and switch to a picture game. We claim <lb/>that these discourse contexts differ in terms of players&apos; engagement and memory load in <lb/>the ongoing task. First, we feel that players are more engaged in the ongoing task during <lb/>card discussion. In the middle of a card discussion, players actively share information, <lb/>explore different (potential) poker hands, and decide what to discard if no poker hand <lb/>is found. Second, we feel that players also have a higher memory load in the middle <lb/>of a card discussion. Across poker games, players do not have to remember anything; <lb/>across card segments, players need to remember what cards each other has; while inside <lb/>of a card discussion, players need to also remember what card is being discussed, and <lb/>how far they are into deciding which card to discard. <lb/>Engagement can be used to explain the intensity of cues in task interruptions. As we <lb/>found in Section 5, when players interrupt in the middle of a card discussion, they use a <lb/>higher pitch than in the case when they interrupt at the end of a game or a card, which <lb/>is also marked with a higher pitch than non-task-switching (during poker playing). <lb/>According to Miyata and Norman (1986), a more intrusive signal is needed to attract <lb/>the attention of people heavily engaged in an ongoing task. Sussman, Winkler, and <lb/>Schr <lb/>oger (2003) found that higher pitch can serve as a more intrusive signal. Thus when <lb/>interrupting in the middle of a card discussion, the speaker uses higher pitch probably <lb/>because the hearer is more engaged in the ongoing task. <lb/>Memory load can explain the context restoration behavior in task resumptions. As <lb/>we found in Section 6, after a picture game that is at the end of a game, players smoothly <lb/>start a new poker game as if nothing happened; after a picture game that is at the end <lb/>of a card segment, players might sometimes use information summary to remind each <lb/>other of what cards they have in hand; and after a picture game that is in the middle <lb/>of a card segment, players might even repeat or clarify the previous utterance that has <lb/>been said before the interruption. These observations are consistent with the memory <lb/>load of discourse contexts. If players are interrupted in a discourse context where the <lb/>memory load is high, because of the limited working memory, players would need to <lb/>spend extra effort to recover the memory after completing the interruptions. <lb/>Engagement and memory can also explain our finding on the discourse context <lb/>of task interruptions. According to Miyata and Norman (1986), interruptions where <lb/>

			<page>100 <lb/></page>

			<note place="headnote">Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note>
			
			people are deeply engaged in the ongoing task, or where people have a high memory <lb/>load, should be disruptive. Thus interruptions at the end of a card game are the least <lb/>disruptive, with those at the end of a card discussion being more disruptive, and those <lb/>embedded inside of a card discussion being the most disruptive. A more disruptive <lb/>interruption tends to have a higher cost to the ongoing task. The disruptiveness of inter-<lb/>ruptions thus explains players&apos; behavior of delaying the picture game. For task inter-<lb/>ruptions, players do not always switch to a real-time task when it is prompted, but <lb/>instead they take into account the discourse context of the ongoing task. They strive to <lb/>switch to a picture game at the end of a (poker) game or a card when possible. According <lb/>to Clark and Wilkes-Gibbs (1986), players would try to minimize their collaborative <lb/>effort in dialogue. The reason that players try to avoid interrupting in the middle of a <lb/>card discussion probably is because such interruptions have a higher cost to the ongoing <lb/>task, i.e. these interruptions are more disruptive. Delaying the switch to the real-time <lb/>task is thus used as a tool to reduce the disruptiveness of the switch. <lb/>Our studies thus suggest that conversants strive to interrupt at a discourse context <lb/>where the cost of interruption is low, but if they interrupt in a more intensive context <lb/>they use stronger cues to mark the more disruptive interruption. <lb/> 8.2 Implication for Speech Interface Design <lb/> By understanding people&apos;s conventions in task interruptions and context restoration, <lb/>we can implement these conventions into a speech interface to allow natural and <lb/>smooth task switching in human-computer dialogue. Based on our findings, we propose <lb/>the following principles for building a speech interface that supports multi-tasking <lb/>dialogue: <lb/> r  Minimize the disruptiveness of task switching. Delay task switching till <lb/>the user&apos;s engagement and memory load in the ongoing task are low so <lb/>that the interruption is less disruptive, while still accomplishing the <lb/>interruption task in a timely matter. Minimizing the disruptiveness <lb/>reduces the cost of interruptions to the ongoing task. <lb/> r  Signal task switching. Discourse markers, such as oh and wait, and <lb/>prosodic variations, especially high pitch, can be used to signal task <lb/>switching. These devices help to disengage the user&apos;s attention from the <lb/>ongoing task so that the user is aware of the task switching. Use stronger <lb/>cues (e.g., higher pitch) when the task switching is more disruptive <lb/>(i.e., when the user is more engaged in the ongoing task). <lb/> r  Recognize task switching. The speech interface can make use of non-lexical <lb/>features, such as contextual information and the user&apos;s pitch, together with <lb/>discourse markers if available, to help recognize the user&apos;s initiation of <lb/>task interruptions. Recognizing task switching helps the speech interface <lb/>to interpret the user&apos;s utterance in the correct context, which should lead <lb/>to higher speech recognition accuracy and better language understanding. <lb/> r  Restore context after an interruption. Utterance restatement and <lb/>information summary are two effective devices. Context restoration is <lb/>needed, especially after a disruptive interruption where the memory <lb/>load in the ongoing task is high, in order to help resolve or prevent <lb/>misunderstandings and forgetting. <lb/>

			<page>101 <lb/></page>

			<note place="headnote">Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note> 
			
			8.3 Future Work <lb/> There are obviously a lot of open questions regarding multi-tasking dialogue that are <lb/>not solved in this article. In this research, we only examined a domain where an ongoing <lb/>task, rich in context, is interrupted by real-time tasks, which are short and simple in <lb/>nature. Psychological research showed that the complexity of the real-time task and its <lb/>similarity to the ongoing task play an important role in the disruptiveness of interrup-<lb/>tions (Gillie and Broadbent 1989); thus we can vary these factors in future research. First, <lb/>we can vary the complexity of the real-time tasks; for example, for some interruptions, <lb/>the player needs to find out whether the other player has a combination of pictures, such <lb/>as a black square but not a white triangle (񮽙  ∧ ¬).  This will allow us to examine the <lb/>correlation between the length of interruptions and context restoration. Second, we can <lb/>use real-time tasks that are less structured, so that people do not mutually know when <lb/>it ends. This will allow us to examine whether and how people signal task resumptions. <lb/>Third, we can introduce ambiguity between the ongoing task and the real-time task: for <lb/>example, to put the card suits (♥♣♦♠) into the picture game, where an utterance such <lb/>as do you have a heart? can belong to either task. This will allow us to see a wider range <lb/>of task switching behavior. <lb/>Furthermore, in this research we do not investigate how multi-tasking dialogue <lb/>would be affected by a manual-visual task, such as driving. This is an important ques-<lb/>tion, because for hands-busy, eyes-busy situations such as driving, speech interfaces <lb/>may provide a human–computer interaction modality that interferes the least with the <lb/>execution of the manual–visual task (Weng et al. 2006; Villing et al. 2008). We expect <lb/>that the presence of the manual–visual task will even further necessitate a good under-<lb/>standing of the natural and efficient human conventions for managing multi-tasking so <lb/>as not to adversely affect the manual–visual task. <lb/>Finally, it was pointed out that human–computer dialogue is not exactly the same as <lb/>human–human dialogue—that is, people might change their behavior when talking to <lb/>a computer (Doran et al. 2001). It will thus be useful to build an actual speech interface <lb/>for multi-tasking dialogue, or perhaps first simulate such a system with Wizard of Oz <lb/>experiments, and to examine whether following the principles that we derived from <lb/>human–human dialogue does lead to improvements. <lb/> 
			
		</body>
		
		<back>	
			
			<div type="acknowledgement">Acknowledgments <lb/> This work was funded by the National <lb/>Science Foundation under grant IIS-0326496. <lb/>The authors thank Alex Shyrokov, David <lb/>Traum, Elizabeth Shriberg, and members of <lb/>CSLU for helpful discussions. The authors <lb/>also wish to thank the reviewers for their <lb/>constructive comments. <lb/></div>

			<listBibl> References <lb/> Ayers, Gayle M. 1992. Discourse functions <lb/>of pitch range in spontaneous and read <lb/>speech. Presented at the Linguistic Society <lb/>of America Annual Meeting. 9–12 January, <lb/>Philadelphia, PA. <lb/>Bangerter, Adrian and Herbert H. Clark. <lb/>2003. Navigating joint projects with <lb/>dialogue. Cognitive Science, 27:195–229. <lb/>Butterworth, Brian. 1972. Hesitation and <lb/>semantic planning in speech. Journal of <lb/>Psycholinguistic Research, 4:75–87. <lb/>Byron, Donna K. and P. Heeman. 1997. <lb/>Discourse marker use in task-oriented <lb/>spoken dialog. In Proceedings of the 5th <lb/>EUROSPEECH, pages 2223–2226, Rhodes. <lb/>Chang, Chih-Chung and Chih-Jen Lin. <lb/>2001. LIBSVM: a library for support <lb/>vector machines. Software available at <lb/> www.csie.ntu.edu.tw/  ∼  cjlin/libsvm. <lb/> Clark, Herbert H. and Deanna Wilkes-Gibbs. <lb/>1986. Referring as a collaborative process. <lb/> Cognitive Science, 22:1–39. <lb/>Cutrell, Edward, Mary Czerwinski, <lb/>Eric Horvitz. 2001. Notification, <lb/>disruption, and memory: Effects of <lb/>messaging interruptions on memory <lb/>and performance. In Proceedings of <lb/>INTERACT, pages 263–269, Tokyo. <lb/>

			<page> 102 <lb/></page>

			<note place="headnote">Yang, Heeman, and Kun <lb/>Multi-Tasking Dialogues <lb/></note>
			
			Doran, Christine, John Aberdeen, Laurie <lb/>Damianos, and Lynette Hirschman. <lb/>2001. Comparing several aspects of <lb/>human–computer and human–human <lb/>dialogues. In 2nd SigDial Workshop on <lb/>Discourse and Dialogue, pages 1–10, <lb/>Aalborg, Denmark. <lb/>Gillie, Tony and Donald Broadbent. 1989. <lb/>What makes interruptions disruptive? A <lb/>study of length, similarity, and complexity. <lb/> Psychological Research, 50(4):243–250. <lb/>Gopher, Daniel, Yaakov Greenshpan, and <lb/>Lilach Armony. 1996. Switching attention <lb/>between tasks: Exploration of the <lb/>components of executive control and their <lb/>development with training. In Proceedings <lb/>of the Human Factors and Ergonomics Society <lb/>40th Annual Meeting, pages 1060–1064, <lb/>Santa Monica, CA. <lb/>Gravano, Agustin, Stefan Benus, Julia <lb/>Hirschberg, Shira Mitchell, and Illa <lb/>Vovsha. 2007. Classification of discourse <lb/>functions of affirmative words in spoken <lb/>dialogue. In Proceedings of INTERSPEECH, <lb/> pages 1613–1616, Antwerp, Belgium. <lb/>Grosz, Barbara J. and Julia Hirschberg. <lb/>1992. Some intonational characteristics <lb/>of discourse structure. In Proceedings <lb/>of 2nd International Conference on Spoken <lb/>Language Processing, pages 429–432, Banff. <lb/>Grosz, Barbara J. and Candace L. Sidner. <lb/>1986. Attention, intentions, and the <lb/>structure of discourse. Computational <lb/>Linguistics, 12(3):175–204. <lb/>Heeman, Peter A. and James F. Allen. 1995. <lb/>The Trains 93 dialogues. Trains Technical <lb/>Note 94-2, Department of Computer <lb/>Science, University of Rochester. <lb/>Heeman, Peter A., Fan Yang, Andrew L. <lb/>Kun, and Alexander Shyrokov. 2005. <lb/>Conventions in human–human <lb/>multithreaded dialogues: A preliminary <lb/>study. In Proceedings of Intelligent User <lb/>Interface, pages 293–295, San Diego, CA. <lb/>Heritage, John. 1984. A change-of-state <lb/>token and aspects of its sequential <lb/>placement. In J. Maxwell Atkinson and <lb/>John Heritage, editors, Structures of Social <lb/>Action: Studies in Conversation Analysis. <lb/> Cambridge University Press, chapter 13, <lb/>pages 299–345. <lb/>Hess, Stephen M. and Mark C. Detweiler. <lb/>1994. Training to reduce the disruptive <lb/>effects of interruptions. In Proceedings of <lb/>the Human Factors and Ergonomics Society <lb/>38th Annual Meeting, pages 1173–1177, <lb/>Nashville, TN. <lb/>Hirschberg, Julia and Diane Litman. 1987. <lb/>Now let&apos;s talk about now: Identifying cue <lb/>phrases intonationally. In Proceedings of the <lb/>25th Annual Meeting of the Association for <lb/>Computational Linguistics, pages 163–171, <lb/>Stanford, California. <lb/>Hirschberg, Julia and Christine H. Nakatani. <lb/>1996. A prosodic analysis of discourse <lb/>segments in direction-giving monologues. <lb/>In Proceedings of 34th Annual Meeting of the <lb/>Association for Computational Linguistics, <lb/> pages 286–293, Santa Cruz, CA. <lb/>Iyer, Rukmini M. and Mari Ostendorf. 1999. <lb/>Modeling long distance dependence in <lb/>language: Topic mixtures versus dynamic <lb/>cache models. IEEE Transactions on Speech <lb/>and Audio Process, 7(1):30–39. <lb/>Kun, Andrew L., W. Thomas Miller, and <lb/>William H. Lenharth. 2004. Computers in <lb/>police cruisers. IEEE Pervasive Computing, <lb/> 3(4):34–41. <lb/>Larsson, Staffan. 2003. Interactive <lb/>communication management in an <lb/>issue-based dialogue system. In <lb/> Proceedings 7th Workshop on the Semantics <lb/>and Pragmatics of Dialogue, pages 75–83, <lb/>Saarbr <lb/>ucken. <lb/>Lemon, Oliver and Alexander Gruenstein. <lb/>2004. Multithreaded context for <lb/>robust conversational interfaces: <lb/>Context-sensitive speech recognition and <lb/>interpretation of corrective fragments. <lb/> ACM Transactions on Computer-Human <lb/>Interaction, 11(3):241–267. <lb/>Linde, Charlotte and Joseph Goguen. 1987. <lb/>Checklist interruption and resumption: <lb/>A linguistic study. Technical Report <lb/>CR-177460, National Aeronautics and <lb/>Space Administration. <lb/>McFarlane, Daniel C. 1999. Coordinating <lb/>the interruption of people in <lb/>human–computer interaction. In <lb/> Proceedings of INTERACT, pages 295–303, <lb/>Edinburgh, Scotland. <lb/>Meiran, Nacshon, Ziv Chorev, and Ayelet <lb/>Sapir. 2000. Component processes in <lb/>task switching. Cognitive Psychology, <lb/> 41:211–253. <lb/>Miyata, Yoshiro and Donald A. Norman. <lb/>1986. Psychological issues in support of <lb/>multiple activities. In D. A. Norman and <lb/>S. W. Draper, editors, Participant Centered <lb/>Design: New Perspectives on Human <lb/>Computer Interaction. Lawrence Erlbaum, <lb/>Hillsdale, NJ, chapter 13, pages 265–284. <lb/>Moser, Megan and Johanna D. Moore. 1995. <lb/>Investigating cue selection and placement <lb/>in tutorial discourse. In Proceedings of <lb/>33rd Annual Meeting of the Association for <lb/>Computational Linguistics, pages 130–135, <lb/>Cambridge, MA. <lb/>

			<page> 103 <lb/></page>

			<note place="headnote">Computational Linguistics <lb/>Volume 37, Number 1 <lb/></note>
			
			Nakajima, Shin&apos;ya and James F. Allen. <lb/>1993. A study on prosody and discourse <lb/>structure in cooperative dialogues. <lb/>TRAINS Technical Note 93-2, University <lb/>of Rochester, Rochester, NY. <lb/>Passonneau, Rebecca J. and Diane J. Litman. <lb/>1997. Discourse segmentation by human <lb/>and automated means. Computational <lb/> Linguistics, 23(1):103–139. <lb/>Quinlan, J. R. 1986. Induction of decision <lb/>trees. Machine Learning, 1(1):81–106. <lb/>Renaud, Karen. 2000. Expediting rapid <lb/>recovery from interruptions by providing <lb/>a visualisation of application activity. In <lb/> Proceedings of OzCHI, pages 348–355, <lb/>Sydney. <lb/>Rickel, Jeff, Stacy Marsella, Jonathan Gratch, <lb/>Randall Hill, David Traum, and William <lb/>Swartout. 2002. Towards a new generation <lb/>of virtual humans for interactive <lb/>experiences. IEEE Intelligent Systems, <lb/> 17(4):32–38. <lb/>Schiffrin, Deborah. 1987. Discourse Markers. <lb/> Cambridge University Press. <lb/>Shyrokov, Alexander, Andrew Kun, and <lb/>Peter Heeman. 2007. Experiments <lb/>modeling of human–human <lb/>multi-threaded dialogues in the presence <lb/>of a manual–visual task. In Proceedings of <lb/>8th SIGdial Workshop on Discourse and <lb/>Dialogue, pages 190–193, Antwerp. <lb/>Strayer, Susan E., Peter A. Heeman, and <lb/>Fan Yang. 2003. Reconciling control and <lb/>discourse structure. In J. van Kuppevelt <lb/>and R. W. Smith, editors, Current and <lb/>New Directions in Discourse and Dialogue. <lb/> Kluwer Academic Publishers, Dordrecht, <lb/>chapter 14, pages 305–323. <lb/>Sussman, E., I. Winkler, and E. Schr <lb/>oger. <lb/>2003. Top–down control over involuntary <lb/>attention switching in the auditory <lb/>modality. Psychonomic Bulletin &amp; Review, <lb/> 10(3):630–637. <lb/>Swerts, Marc. 1995. Combining statistical <lb/>and phonetic analyses of spontaneous <lb/>discourse segmentation. In Proceedings of <lb/>the 12th ICPhS, volume 4, pages 208–211, <lb/>Stockholm. <lb/>Swerts, Marc. 1998. Filled pauses as markers <lb/>of discourse structure. Journal of <lb/>Pragmatics, 30:485–496. <lb/>Swerts, Marc and Mari Ostendorf. 1995. <lb/>Discourse prosody in human–machine <lb/>interactions. In Proceedings of ESCA <lb/>Workshop on Spoken Dialogue Systems: <lb/>Theories and Applications, pages 205–208, <lb/>Visgo. <lb/>Toh, Siew Leng, Fan Yang, and Peter A. <lb/>Heeman. 2006. An annotation scheme for <lb/>agreement analysis. In Proceedings of 9th <lb/>International Conference on Spoken Language <lb/>Processing, pages 201–204, Pittsburgh, PA. <lb/>Traum, David and Jeff Rickel. 2002. <lb/>Embodied agents for multi-party dialogue <lb/>in immersive virtual world. In Proceedings <lb/>of the First International Joint Conference on <lb/>Autonomous Agents and Multi-agent <lb/>Systems, pages 766–773, Bologna. <lb/>Villing, Jessica. 2010. Now, where was I? <lb/>Resumption strategies for an in-vehicle <lb/>dialogue system. In Proceedings of the <lb/>48th Annual Meeting of the Association for <lb/>Computational Linguistics, pages 798–805, <lb/>Uppsala. <lb/>Villing, Jessica, Cecilia Holtelius, Staffan <lb/>Larsson, Anders Lindstr <lb/>om, Alexander <lb/>Seward, and Ninå <lb/>Aberg. 2008. <lb/>Interruption, resumption and domain <lb/>switching in in-vehicle dialogue. In <lb/> Proceedings of the 6th International <lb/>Conference on Advances in Natural <lb/>Language Processing, pages 488–499, <lb/>Berlin. <lb/>Walker, Marilyn A. 1996. The effect of <lb/>resource limits and task complexity on <lb/>collaborative planning in dialogue. <lb/> Artificial Intelligence Journal, 85:181–243. <lb/>Walker, Marilyn A., Rebecca Passonneau, <lb/>and Julie E. Boland. 2001. Quantitative <lb/>and qualitative evaluation of DARPA <lb/>communicator spoken dialogue systems. <lb/>In Proceedings of the Association of <lb/>Computational Linguistics, pages 515–522, <lb/>Toulouse, France. <lb/>Weng, Fuliang, Sebastian Varges, Badri <lb/>Raghunathan, Florin Ratiu, Heather <lb/>Pon-barry, Brian Lathrop, Qi Zhang, <lb/>Harry Bratt, Tobias Scheideck, Kui Xu, <lb/>Matthew Purver, and Rohit Mishra. <lb/>2006. CHAT: A conversational helper <lb/>for automotive tasks. In Proceedings of <lb/>9th International Conference on Spoken <lb/>Language Processing, pages 1061–1064, <lb/>Pittsburgh, PA. <lb/>Yang, Fan and Peter A. Heeman. 2009. <lb/>Context restoration in multi-tasking <lb/>dialogue. In Proceedings of 13th International <lb/>Conference on Intelligent User Interfaces, <lb/> pages 373–377, Sanibel, FL. <lb/>Yang, Fan and Peter A. Heeman. 2010. <lb/>Initiative conflicts in task-oriented <lb/>dialogue. Computer Speech and Language, <lb/> 24:175–189. <lb/>Yang, Fan, Peter A. Heeman, and Andrew <lb/>Kun. 2008. Switching to real-time tasks in <lb/>multi-tasking dialogue. In Proceedings of <lb/>International Conference on Computational <lb/>Linguistics, pages 1025–1032, Manchester. <lb/></listBibl>

			<page> 104 </page>

		</back>
	</text>
</tei>
