<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="_0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>1 <lb/>Open Community Challenge Reveals Molecular <lb/>Network Modules with Key Roles in Diseases <lb/>Sarvenaz Choobdar, 1,2,X Mehmet E. Ahsen, 3,X Jake Crawford, 4,X Mattia Tomasoni, 1,2 David <lb/>Lamparter, 1,2,5 Junyuan Lin, 6 Benjamin Hescott, 7 Xiaozhe Hu, 6 Johnathan Mercer, 8,9 Ted <lb/>Natoli, 10 Rajiv Narayan, 10 The DREAM Module Identification Challenge Consortium, 11 <lb/>Aravind Subramanian, 10 Gustavo Stolovitzky, 3,12 Zoltán Kutalik, 2,13 Kasper Lage, 8,9,14 <lb/>Donna K. Slonim, 4 Julio Saez-Rodriguez, 15,16 Lenore J. Cowen, 4,6 Sven Bergmann, 1,2,17,Y,* <lb/>and Daniel Marbach 1,2,18,Y,Z,* <lb/>1 Department of Computational Biology, University of Lausanne, Lausanne, Switzerland. <lb/>2 Swiss Institute of Bioinformatics, Lausanne, Switzerland. <lb/>3 Icahn Institute for Genomics and Multiscale Biology and Department of Genetics and Genomic <lb/>Sciences, Icahn School of Medicine at Mount Sinai, New York, NY, USA. <lb/>4 Department of Computer Science, Tufts University, Medford, MA, USA. <lb/>5 Verge Genomics, San Francisco, CA, USA. <lb/>6 Department of Mathematics, Tufts University, Medford, MA, USA. <lb/>7 College of Computer and Information Science, Northeastern University, Boston, MA, USA. <lb/>8 Department of Surgery, Massachusetts General Hospital, Harvard Medical School, Boston, <lb/>MA, USA. <lb/>9 Stanley Center at the Broad Institute of MIT and Harvard, Cambridge, MA, USA. <lb/>10 Broad Institute of Harvard and MIT, Cambridge, MA, USA. <lb/>11 Full list of members appears at the end of the paper. <lb/>12 IBM T.J. Watson Research Center, Yorktown Heights, New York 10598, USA. <lb/>13 Institute of Social and Preventive Medicine (IUMSP), Lausanne University Hospital, Lausanne, <lb/>Switzerland. <lb/>14 Institute for Biological Psychiatry, Mental Health Center Sct. Hans, University of Copenhagen, <lb/>Roskilde, Denmark. <lb/>15 European Bioinformatics Institute, European Molecular Biology Laboratory, Cambridge, UK <lb/>16 RWTH Aachen University, Faculty of Medicine, Joint Research Center for Computational <lb/>Biomedicine, Aachen, Germany <lb/>17 Department of Integrative Biomedical Sciences, University of Cape Town, Cape Town, South <lb/>Africa <lb/>18 Roche Pharma Research and Early Development, Pharmaceutical Sciences, Roche <lb/>Innovation Center Basel, F. Hoffmann-La Roche Ltd, 4070 Basel, Switzerland. <lb/>X Co-first author <lb/>Y <lb/>Co-last author <lb/>Z <lb/>Lead contact <lb/>*Correspondence: sven.bergmann@unil.ch (S.B.), daniel.marbach.dm1@roche.com (D.M.) <lb/></front>

			<page>2 <lb/></page>

			<div type="toc">Table of contents <lb/>Summary <lb/>Keywords <lb/>Highlights <lb/>Introduction <lb/>Results <lb/>A crowdsourced challenge for empirical assessment of module identification methods <lb/>Community-based collection of module identification methods <lb/>Top methods from different categories achieve comparable performance <lb/>Consensus predictions outperform individual methods <lb/>Complementarity of different module identification approaches <lb/>Multi-network module identification methods did not provide added power <lb/>Network modules reveal shared pathways between traits <lb/>Trait-associated modules implicate core disease genes and pathways <lb/>Discussion <lb/>Consortia <lb/>Author contributions <lb/>Acknowledgments <lb/>References <lb/>Table 1 <lb/>Figure 1 <lb/>Figure 2 <lb/>Figure 3 <lb/>Figure 4 <lb/>Figure 5 <lb/>Figure 6 <lb/>Methods <lb/>Network compendium <lb/>Challenge structure <lb/>Challenge scoring <lb/></div>

			<page>3 <lb/></page>

			<div type="toc">Module identification methods <lb/>Consensus module predictions <lb/>Similarity of module predictions <lb/>Overlap between trait-associated modules <lb/>Trait similarity network <lb/>Evaluation of candidate trait genes <lb/>Functional enrichment analysis <lb/>Data and software availability <lb/>Supplementary Figures and Tables <lb/>Figure S1 <lb/>Figure S2 <lb/>Figure S3 <lb/>Figure S4 <lb/>Figure S5 <lb/>Table S1 <lb/>Table S2 <lb/>Table S3 <lb/>Table S4 <lb/></div>

			<page>4 <lb/></page>

			<front>Summary <lb/>Identification of modules in molecular networks is at the core of many current analysis methods <lb/>in biomedical research. However, how well different approaches identify disease-relevant <lb/>modules in different types of networks remains poorly understood. We launched the &quot;Disease <lb/>Module Identification DREAM Challenge&quot;, an open competition to comprehensively assess <lb/>module identification methods across diverse gene, protein and signaling networks. Predicted <lb/>network modules were tested for association with complex traits and diseases using a unique <lb/>collection of 180 genome-wide association studies (GWAS). While a number of approaches <lb/>were successful in terms of discovering complementary trait-associated modules, consensus <lb/>predictions derived from the challenge submissions performed best. We find that most of these <lb/>modules correspond to core disease-relevant pathways, which often comprise therapeutic <lb/>targets and correctly prioritize candidate disease genes. This community challenge establishes <lb/>benchmarks, tools and guidelines for molecular network analysis to study human disease <lb/>biology (https://synapse.org/modulechallenge). <lb/>Keywords <lb/>• Network biology <lb/>• Module identification <lb/>• Community detection algorithms <lb/>• Pathway analysis <lb/>• Genome-wide association studies <lb/>• Crowdsourced challenge <lb/>• Open science <lb/>Highlights <lb/>• Crowdsourced challenge enables critical assessment of module identification methods <lb/>• Top approaches recover complementary disease modules in diverse molecular networks <lb/>• Community-established benchmarks, user guidelines and tools for network analysis <lb/>• Molecular network modules reveal core pathways underlying complex traits and <lb/>diseases <lb/></front>

			<page>5 <lb/></page>

			<body>Introduction <lb/>Understanding the mechanisms and pathways underlying complex human diseases remains a <lb/>difficult problem, hindering the development of targeted therapeutics. Complex diseases involve <lb/>many genes and molecules that interact within context-specific cellular networks (Califano et al., <lb/>2012). These densely interconnected networks sense and propagate perturbations from genetic <lb/>variants and environmental factors, giving rise to disease states that may be difficult to <lb/>understand at the level of individual genes (Schadt, 2009). Indeed, it has become apparent that <lb/>the majority of genetic variants underlying complex traits and diseases lie in noncoding regions <lb/>of the genome where they presumably disrupt gene regulatory networks (Pickrell, 2014), lending <lb/>further support to the long-recognized importance of molecular network analysis for <lb/>understanding disease biology (Ideker and Sharan, 2008; Vidal et al., 2011). <lb/>Experimental and computational techniques for mapping molecular networks, including physical <lb/>interaction networks (e.g., protein-protein interaction, signaling and regulatory networks) as well <lb/>as functional gene networks (e.g., co-expression and genetic interaction networks), have been a <lb/>major focus of systems biology. Recent studies have further introduced comprehensive <lb/>collections of tissue-specific networks (Greene et al., 2015; Marbach et al., 2016). Network-<lb/>based approaches are now widely used for systems-level analyses in diverse fields ranging <lb/>from oncology (Chen et al., 2014; Tsherniak et al., 2017) to cell differentiation (Cahan et al., <lb/>2014; Ciofani et al., 2012). A key problem in biological network analysis is the identification of <lb/>functional units, called modules or pathways. It is well known that molecular networks have a <lb/>high degree of modularity (i.e., subsets of nodes are more densely connected than expected by <lb/>chance), and that the corresponding modules often comprise genes or proteins that are involved <lb/>in the same biological functions (Hartwell et al., 1999). Moreover, biological networks are <lb/>typically too large to be examined and visualized as a whole. Consequently, module <lb/>identification is often a crucial step to gain biological insights from network data (Chen et al., <lb/>2008; Langfelder and Horvath, 2008; Padi and Quackenbush, 2017; Pe&apos;er et al., 2001). <lb/>Module identification, also called community detection or graph clustering, is a key problem in <lb/>network science for which a wide range of methods have been proposed (Fortunato and Hric, <lb/>2016). These methods are typically assessed on in silico generated benchmark graphs (Girvan <lb/>and Newman, 2002). However, how well different approaches uncover biologically relevant <lb/>modules in real molecular networks remains poorly understood. Crowdsourced open-data <lb/>competitions (known as challenges) have proven an effective means to rigorously assess <lb/>methods and, in the process, foster collaborative communities and open innovation. The <lb/></body>

			<page>6 <lb/></page>

			<body>Dialogue on Reverse Engineering and Assessment (DREAM) is a community-driven initiative <lb/>promoting open-data challenges in systems biology and translational medicine <lb/>(http://dreamchallenges.org). DREAM challenges have established standardized resources and <lb/>robust methodologies for diverse problems, including the inference of gene regulatory and <lb/>signaling networks (Hill et al., 2016; Marbach et al., 2012). But, so far there has been no <lb/>community effort addressing the downstream analysis of molecular networks. <lb/>Here we present the results of the Disease Module Identification DREAM Challenge (Fig. 1). <lb/>The aim of this challenge is to comprehensively assess module identification methods across <lb/>diverse molecular networks. Six research groups contributed unpublished molecular networks <lb/>and over 400 participants from all over the world developed and applied module identification <lb/>methods. Teams predicted disease-relevant modules both within individual networks (Sub-<lb/>challenge 1) and across multiple, layered networks (Sub-challenge 2). In the final round, 75 <lb/>submissions, including method descriptions and code, were made across the two sub-<lb/>challenges, providing a broad sampling of state-of-the-art methods. We employed a novel <lb/>approach to assess the performance of these methods based on the number of discovered <lb/>modules associated with complex traits or diseases. In this paper, we discuss the top-<lb/>performing approaches, show that they recover complementary modules, and introduce a <lb/>method to generate robust consensus modules. Finally, we explore the biology and therapeutic <lb/>relevance of trait-associated network modules. <lb/>All challenge data, including the networks, GWAS datasets, team submissions and code are <lb/>available as a community resource at https://www.synapse.org/modulechallenge. <lb/>Results <lb/>A crowdsourced challenge for empirical assessment of module <lb/>identification methods <lb/>We developed a panel of diverse, human molecular networks for the challenge, including <lb/>custom versions of two protein-protein interaction and a signaling network extracted from the <lb/>STRING (Szklarczyk et al., 2015), InWeb (Li et al., 2017) and OmniPath (Türei et al., 2016) <lb/>databases, a co-expression network inferred from 19,019 tissue samples from the GEO <lb/>repository (Barrett et al., 2011), a network of genetic dependencies derived from genome-scale <lb/>loss-of-function screens in 216 cancer cell lines (Cowley et al., 2014; Tsherniak et al., 2017), <lb/>and a homology-based network built from phylogenetic patterns across 138 eukaryotic species <lb/></body>

			<page>7 <lb/></page>

			<body>(Li et al., 2014) (Methods). These networks have varying size, link density and structural <lb/>properties, making a heterogeneous benchmark resource (Fig. 1A). <lb/>Each network was generated specifically for the challenge and released in anonymized form <lb/>(i.e., we did not disclose the gene names and the identity of the networks). Using unpublished <lb/>networks made it impossible for participants to infer the gene identities, thus enabling rigorous <lb/>&quot;blinded&quot; assessment. That is, participants could only use the provided network structures, <lb/>without having access to any additional information such as known disease genes. <lb/>We solicited participation in two types of module identification challenges (Fig. 1B). In Sub-<lb/>challenge 1, solvers were asked to run module identification on each of the provided networks <lb/>individually (single-network module identification). Thus, they were asked to submit one set of <lb/>modules for each of the six networks. This is a typical problem in biomedical research, where <lb/>one is often presented with a single network derived from a given dataset. In Sub-challenge 2, <lb/>the networks were re-anonymized in a way that the same gene identifier represented the same <lb/>gene across all six networks. Solvers were then asked to identify a single set of non-overlapping <lb/>modules by sharing information across the six networks (multi-network module identification). <lb/>This is also common problem, as network-based approaches are often used to integrate <lb/>disparate molecular datasets (Krishnan et al., 2016). In both sub-challenges, predicted modules <lb/>had to be non-overlapping and comprise between 3 and 100 genes (modules with over one <lb/>hundred genes are typically less useful to gain specific biological insights). <lb/>We developed a framework to empirically assess module identification methods based on the <lb/>number of predicted modules that show significant association with complex traits and diseases <lb/>(called trait-associated modules, Fig. 1C). To this end, predicted modules were scored on <lb/>GWAS data using the Pascal tool (Lamparter et al., 2016), which takes into account <lb/>confounders such as linkage disequilibrium within and between genes (Methods). Since we are <lb/>employing a large collection of 180 GWAS datasets ranging over diverse disease-related <lb/>human phenotypes (Table S1), this approach covers a broad spectrum of molecular processes. <lb/>In contrast to evaluation of module enrichment using existing gene and pathway annotations, <lb/>where it is sometimes difficult to ascertain that annotations were not derived from similar data <lb/>types as the networks, the GWAS-based approach provides an orthogonal means to assess <lb/>disease-relevant modules. <lb/>The challenge was run using the open-science Synapse platform (Derry et al., 2012). Over a <lb/>two-month period, teams could make repeated submissions and see their performance on a <lb/></body>

			<page>8 <lb/></page>

			<body>real-time leaderboard to iteratively improve their methods. The total number of leaderboard <lb/>submissions per team was limited to 25 and 41 for the two sub-challenges, respectively. In the <lb/>final round, teams could make a single submission for each sub-challenge, which had to include <lb/>detailed method descriptions and code for reproducibility. The scoring of the final submissions <lb/>was based on a separate set of GWAS data sets that were not used during the leaderboard <lb/>round (Methods). <lb/>Community-based collection of module identification methods <lb/>The community contributed 42 single-network and 33 multi-network module identification <lb/>methods in the final round of the two sub-challenges. Single-network module identification <lb/>methods are listed in Table 1, top-performing approaches are detailed in Methods, and full <lb/>descriptions and code of all methods are available on the Synapse platform <lb/>(https://www.synapse.org/modulechallenge). In the following sections we first discuss the single-<lb/>network methods (Sub-challenge 1). <lb/>We grouped methods into seven broad categories: (i) kernel clustering, (ii) modularity <lb/>optimization, (iii) random-walk based, (iv) local methods, (v) ensemble methods, (vi) hybrid <lb/>methods and (vii) other methods (Fig. 2A, Table 1). While many teams adapted existing <lb/>algorithms for community detection, other teams --including the best performers --developed <lb/>novel approaches. <lb/>Top methods from different categories achieve comparable <lb/>performance <lb/>In Sub-challenge 1, teams submitted a separate set of predicted modules for each of the six <lb/>networks. We scored these predictions based on the number of trait-associated modules at 5% <lb/>false discovery rate (FDR; Methods). The overall score used to rank methods in the challenge <lb/>was defined as the total number of trait-associated modules across the six networks. (Module <lb/>predictions, scoring scripts and full results are available in on the challenge website.) <lb/>The top five methods achieved comparable performance with scores between 55 and 60, while <lb/>the remaining methods did not get to scores above 50 (Fig. 2B). To assess the robustness of <lb/>the challenge ranking, we further scored all methods on 1,000 subsamples of the GWAS hold-<lb/>out set (Methods). This analysis revealed a significant difference between the top-scoring <lb/>method K1 (method IDs are defined in Table 1) and the remaining methods (Fig. 2C). In <lb/>addition, we repeated the scoring using four different FDR cutoffs: method K1 ranked 1st in <lb/></body>

			<page>9 <lb/></page>

			<body>each case, while the performance of other methods varied (Fig. S1A). Moreover, method K1 <lb/>also obtained the top score in the leaderboard round. We conclude that although the final <lb/>scores of the top 5 methods are close, method K1 performed more robustly in diverse settings. <lb/>The top teams used different approaches: the best performers (K1) developed a novel kernel <lb/>approach leveraging a diffusion-based distance metric (Cao et al., 2013, 2014) and spectral <lb/>clustering (Ng et al., 2001); the runner-up team (M1) extended different modularity optimization <lb/>methods with a resistance parameter that controls the granularity of modules (Arenas et al., <lb/>2008); and the third-ranking team (R1) used a random-walk method based on multi-level <lb/>Markov clustering with locally adaptive granularity to balance module sizes (Satuluri et al., <lb/>2010). Interestingly, teams employing the widely-used Weighted Gene Co-expression Network <lb/>Analysis tool (WGCNA) (Langfelder and Horvath, 2008), which relies on hierarchical clustering <lb/>to detect modules, did not perform competitively in this challenge (rank 35, 37 and 41). <lb/>Four different method categories are represented among the top five performers, suggesting <lb/>that no single approach is inherently superior for module identification in molecular networks. <lb/>Rather, performance depends on the specifics of each individual method, including the strategy <lb/>used to define the resolution of the modular decomposition (the number and size of modules). <lb/>Most teams used the leaderboard round to determine an appropriate resolution to capture <lb/>disease-relevant pathways. Notably, the two runner-up teams (M1 and R1) both used methods <lb/>specifically designed to control the resolution of modules, and the top three teams all subdivided <lb/>large modules (&gt;100 genes) by recursively applying their methods to the corresponding <lb/>subnetworks. Pre-processing steps also affected performance: many of the top teams first <lb/>sparsified the networks by discarding weak edges. A notable exception is the top method (K1), <lb/>which performed robustly without any pre-processing of the networks. <lb/>The challenge also allows us to explore how informative different types of molecular networks <lb/>are for finding modules underlying complex traits. In absolute numbers, methods recovered the <lb/>most trait-associated modules in the co-expression and protein-protein interaction networks <lb/>(Fig. S1B). However, relative to the network size, the signaling network contained the most trait-<lb/>associated modules (Fig. 2D). The cancer-related and homology-based networks, on the other <lb/>hand, were less informative for the considered traits. These results are consistent with the <lb/>importance of signaling pathways for many of the considered traits and diseases. <lb/></body>

			<page>10 <lb/></page>

			<body>Consensus predictions outperform individual methods <lb/>Integration of multiple team submissions sometimes leads to winning predictions in <lb/>crowdsourced challenges (Marbach et al., 2012). We therefore developed an ensemble <lb/>approach to derive consensus modules from team submissions. To this end, module predictions <lb/>from different methods were integrated in a consensus matrix C, where each element cij is <lb/>proportional to the number of methods that put gene i and j together in the same module. The <lb/>consensus matrix was then clustered using the top-performing module identification method <lb/>from the challenge (Fig. S2A, Methods). <lb/>When applied to the top 50% of methods from the leaderboard round, the consensus indeed <lb/>leads to a new best-scoring prediction (Fig. 2B,C). However, when applied to fewer methods, <lb/>the performance of the consensus drops (Fig. S2C), suggesting that further work is needed to <lb/>make this approach practical outside of a challenge context. <lb/>Complementarity of different module identification approaches <lb/>We next asked whether predictions from different methods and networks tend to capture the <lb/>same or complementary modules. To this end, we developed a pairwise similarity metric for <lb/>module predictions, which we applied to the complete set of 252 module predictions from Sub-<lb/>challenge 1 (42 methods x 6 networks, Methods). We find that similarity of module predictions is <lb/>primarily driven by the underlying network and not the method category (Fig. 3A). When <lb/>comparing module predictions of different methods across networks, we find that the top-<lb/>performing methods produce dissimilar clusterings, suggesting that they capture complementary <lb/>functional modules (Fig. S3A). <lb/>These observations can be confirmed by evaluating the overlap between trait-associated <lb/>modules from different methods. Within the same network, only 46% of trait modules are <lb/>recovered by multiple methods with good agreement (high overlap or submodules, Fig. 3B). <lb/>Across different networks, the number of recovered modules with substantial overlap is even <lb/>lower (17%). Thus, the majority of trait modules are method-and network-specific. This <lb/>suggests that users should not rely on a single method or network to find trait-relevant modules. <lb/>The modules produced by different methods also vary in terms of their structural properties. For <lb/>example, the average module size ranges from 7 to 66 genes across methods and does not <lb/>correlate with performance in the challenge (Figs. 3C, S3B-D). This implies that trait-relevant <lb/>pathways can be captured at different levels of granularity (indeed, 26% of trait modules are <lb/></body>

			<page>11 <lb/></page>

			<body>submodules of larger trait modules, Fig. 3B). Topological quality metrics of modules such as <lb/>modularity showed only modest correlation with the challenge score (Fig. 3D), highlighting the <lb/>need to empirically assess module identification methods for a given task. <lb/>Multi-network module identification methods did not provide added <lb/>power <lb/>In Sub-challenge 2, teams submitted a single modularization of the genes, for which they could <lb/>leverage information from all six networks together. While some teams developed dedicated <lb/>multi-network (multi-layer) community detection methods (De Domenico et al., 2015; Didier et <lb/>al., 2015), the majority of teams first merged the networks in some way and then applied single-<lb/>network methods. <lb/>It turned out to be very difficult to effectively leverage complementary networks for module <lb/>identification. While three teams achieved marginally higher scores than single-network module <lb/>predictions, the difference is not significant (Figs. 3E, S1C). Moreover, the best-scoring team <lb/>simply merged the two protein interaction networks (the two most similar networks, Fig. S2E), <lb/>discarding the other types of networks. Since no significant improvement over single-network <lb/>methods was achieved, the winning position of Sub-challenge 2 was declared vacant. <lb/>We nevertheless also applied our consensus method to integrate team submissions across <lb/>networks. The exact same consensus method as we employed for Sub-challenge 1 was used, <lb/>except that a cross-network consensus matrix was formed by taking the sum of the six network-<lb/>specific consensus matrices (Fig. S2B, Methods). This resulted in the best-scoring module <lb/>prediction of Sub-challenge 2 (Fig. 3E), the only multi-network prediction that significantly <lb/>outperforms single-network predictions, thus confirming the robustness of the consensus <lb/>method and demonstrating that the multi-network methods can be further improved. <lb/>Network modules reveal shared pathways between traits <lb/>We next sought to explore biological properties of trait-associated modules discovered by the <lb/>challenge participants. In what follows, we focus on the single-network predictions from Sub-<lb/>challenge 1. The most trait-associated modules were found for immune-related, psychiatric, <lb/>blood cholesterol and anthropometric traits, for which high-powered GWAS are available that <lb/>are known to show strong pathway enrichment (Fig. 4A). <lb/></body>

			<page>12 <lb/></page>

			<body>Significant GWAS loci often show association to multiple traits. Across our GWAS compendium, <lb/>we found that 46% of trait-associated genes but only 28% of trait-associated modules are <lb/>associated with multiple traits (Fig. 4B). Thus, mapping genes onto network modules may help <lb/>disentangling trait-specific pathways at shared loci. <lb/>We further asked which traits are similar in terms of the implicated network components. To this <lb/>end, we considered the union of all genes within network modules associated with a given trait <lb/>(called &quot;trait-module genes&quot;). We then evaluated the pairwise similarity of traits based on the <lb/>significance of the overlap between the respective trait-module genes (Methods). Trait <lb/>relationships thus inferred are consistent with known biology and comorbidities between the <lb/>considered traits and diseases (Fig. 4C). For example, consistent with its pathophysiological <lb/>basis, age-related macular degeneration shares network components with cholesterol and <lb/>immune traits, while coronary artery disease shows similarity with established risk factors <lb/>(cholesterol levels, body mass index) and osteoporosis, which is epidemiologically and <lb/>biologically linked (atherosclerotic calcification and bone mineralization involve related <lb/>pathways). <lb/>Trait-associated modules implicate core disease genes and pathways <lb/>Trait-associated modules typically include many genes that do not show any signal in the <lb/>respective GWAS. A key question is whether modules correctly predict such genes as being <lb/>relevant for that trait or disease. We first consider a module from the consensus method that <lb/>shows association to height --a classic polygenic trait --as an example. In the GWAS that was <lb/>used to identify this module there are only three module genes that show association to height, <lb/>while the remaining genes are predicted to play a role in height solely because they are <lb/>members of this module (Fig. 5A). We sought to evaluate such candidate genes for height as <lb/>well as other traits using higher-powered GWASs, ExomeChip data, monogenic disease genes <lb/>and functional annotations. <lb/>There are eight traits for which we have both an older (lower-powered) and more recent (higher-<lb/>powered) GWAS in our hold-out set: height, schizophrenia, ulcerative colitis, Crohn&apos;s disease, <lb/>rheumatoid arthritis, and three blood lipid traits (Fig. S4A). We can thus identify trait modules <lb/>and candidate genes using the lower-powered GWAS and then evaluate how well they are <lb/>supported in higher-powered GWAS (a common approach used to assess methods for GWAS <lb/>gene prioritization, see Methods). Indeed, while only 3 genes in the height module introduced <lb/>above are associated to height in the lower-powered GWAS (Randall et al., 2013), 13 module <lb/></body>

			<page>13 <lb/></page>

			<body>genes are confirmed in the higher-powered GWAS (Wood et al., 2014) and 6 module genes <lb/>further comprise coding variants associated to height in an independent ExomeChip study <lb/>(Marouli et al., 2017) (Fig 5B). Similar results are obtained when evaluating module predictions <lb/>from all challenge methods across the eight above-mentioned traits: a substantial fraction of <lb/>module genes that do not show any signal and are located far from any significant locus in the <lb/>lower-powered GWAS are subsequently confirmed by the higher-powered GWAS (Fig. 5C). <lb/>This demonstrates that modules are predictive for trait-associated genes and could thus be <lb/>used to prioritize candidate genes for follow-up studies, for instance. <lb/>We next explored the biological function and clinical relevance of identified trait modules. For <lb/>example, the height module discussed above consists of two submodules comprising <lb/>extracellular matrix proteins responsible for, respectively, collagen fibril and elastic fibre <lb/>formation --pathways that are essential for growth (Fig. 5D). Indeed, mutations of homologous <lb/>genes in mouse lead to abnormal elastic fiber morphology (Table S2) and one out of four <lb/>module genes are known to cause monogenic skeletal growth disorders in human (Fig. 5D). For <lb/>example, the module gene BMP1 (Bone Morphogenic Protein 1) causes osteogenesis <lb/>imperfecta, which is associated with short stature. Interestingly, BMP1 does not show <lb/>association to height in current GWAS and ExomeChip studies (Fig. 5A,B), demonstrating how <lb/>network modules can implicate additional disease-relevant pathway genes (see Fig. S4B for a <lb/>systematic comparison of trait modules with independent disease gene sets from the literature). <lb/>To evaluate more generally whether trait-associated modules correspond to generic or disease-<lb/>specific pathways, we visualized and tested modules for functional enrichment of Gene <lb/>Ontology (GO) annotations, mouse mutant phenotypes, and diverse pathway databases. In <lb/>order to account for annotation bias of well-studied genes (Glass and Girvan, 2014), we <lb/>employed a noncentral hypergeometric test (Methods). We find that the majority of trait modules <lb/>reflect core disease-specific pathways. For example, in the first protein-protein interaction <lb/>network only 33% of trait modules from the consensus method have generic functions, such as <lb/>epigenetic gene silencing for modules associated with schizophrenia and body mass index; the <lb/>remaining 66% of trait modules correspond to core disease-specific pathways, some of which <lb/>are therapeutic targets (Fig. 6 and Tables S3, S4). Examples include a module associated with <lb/>rheumatoid arthritis that comprises the B7:CD28 costimulatory pathway required for T cell <lb/>activation, which is blocked by an approved drug (Fig. 6A); a module associated with <lb/>inflammatory bowel disease corresponding to cytokine signalling pathways mediated by Janus <lb/>kinases (JAKs), which are therapeutically being targeted at multiple levels (Fig. 6B); and a <lb/>module associated with myocardial infarction that includes the NO/cGMP signaling cascade, <lb/></body>

			<page>14 <lb/></page>

			<body>which plays a key role in cardiovascular pathophysiology and therapeutics (Fig. 6C). We further <lb/>applied our pipeline to a GWAS on IgA nephropathy (IgAN) obtained after the challenge, a <lb/>disease with poorly understood etiology and no effective therapy (Kiryluk et al., 2014). IgAN is <lb/>an autoimmune disorder that manifests itself by deposition of immune complexes in the kidney&apos;s <lb/>glomeruli, triggering inflammation (glomerulonephritis) and tissue damage. The best-performing <lb/>challenge method (K1) revealed one IgAN-specific module. The module implicates complement <lb/>and coagulation cascades, pointing to the chemokine PF4V1 as a novel candidate gene (Fig. <lb/>6D). In support of the function of this module in IgAN, top enriched mouse mutant phenotypes <lb/>for module gene homologs are precisely &quot;glomerulonephritis&quot; and &quot;abnormal blood coagulation&quot; <lb/>(Fig. S5). <lb/>Discussion <lb/>Large-scale network data are becoming pervasive in many areas ranging from the digital <lb/>economy to the life sciences. While analysis goals vary across fields, robust detection of <lb/>network communities remains an essential task in many applications of interest. We have <lb/>conducted a critical assessment of module identification methods on real-world networks, <lb/>providing much-needed guidance for users. The community-based challenge enabled <lb/>comprehensive and impartial assessment, avoiding the &quot;self-assessment trap&quot; that leads <lb/>researchers to consciously or unconsciously overestimate performance when evaluating their <lb/>own algorithms (Norel et al., 2011). While it is important to keep in mind that the exact ranking <lb/>of methods --as in any benchmark --is specific to the task and datasets considered, we believe <lb/>that the resulting collection of top-performing module identification tools and methodological <lb/>insights will be broadly useful for modular analysis of complex networks in biology and other <lb/>domains. <lb/>In addition to providing a cross section of established approaches, the collection of contributed <lb/>methods also includes novel algorithms that further advance the state-of-the-art (notably, the <lb/>best-performing method). Kernel clustering, modularity optimization, random-walk-based and <lb/>local methods were all represented among the top performers, suggesting that no single type of <lb/>approach is inherently superior. In contrast, basic approaches such as hierarchical clustering, <lb/>which is widely used for gene network analysis, did not perform competitively. Consensus <lb/>modules obtained by integrating multiple team submissions achieved the top score, <lb/>demonstrating that method performance can be further improved. However, this strategy was <lb/>only successful when integrating predictions from over twenty methods, explaining why <lb/>ensemble approaches applied by individual teams, which integrated only few methods, did not <lb/></body>

			<page>15 <lb/></page>

			<body>perform well. Indeed, our analysis showed that top-performing methods produced very different <lb/>modular decompositions, capturing complementary pathways at varying resolutions that may be <lb/>difficult to merge in a single consensus prediction. <lb/>Published studies in biology that apply network analysis tools typically rely on a single clustering <lb/>method. The results of this challenge call for a different approach. We recommend that users <lb/>apply top methods from several categories, enabling the detection of different types of modules <lb/>and making results less prone to biases of any single approach. We find that the top four <lb/>challenge methods (K1, M1, R1 and M2) already offer substantial diversity (Fig. S3E). The <lb/>generated modules should be considered as is, without forming a consensus prediction. It <lb/>should be noted that the larger number of modules also results in a higher multiple testing <lb/>burden in any subsequent analyses (e.g., functional enrichment testing) and that modules from <lb/>different methods may overlap. When a single non-overlapping partition is needed, the best-<lb/>performing challenge method (K1) is a good choice as it functioned robustly in diverse settings <lb/>(notably, it was also used to cluster the consensus matrices, leading to the top-scoring <lb/>consensus predictions in both sub-challenges). <lb/>The challenge also emphasized the importance of the resolution (size and number of modules), <lb/>which critically affected results. Biological networks typically have a hierarchical modular <lb/>structure, which implies that disease-relevant pathways can be captured at different levels <lb/>(Ravasz et al., 2002). Our results showed that the optimal resolution is method-and network-<lb/>specific (Fig. S3B-D). Top-performing challenge methods allowed the resolution to be tuned. <lb/>Although setting the &quot;right&quot; resolution can be challenging for users, this critical point should not <lb/>be sidestepped. We recommend that users experiment with different resolutions and use the <lb/>settings optimized by teams for the different types of networks as guidance. <lb/>Our analysis showed that signaling, protein-protein interaction and co-expression networks <lb/>comprise complementary trait-relevant modules (Fig. 3A,B). Considering different types of <lb/>networks is thus clearly advantageous. However, multi-network module identification methods <lb/>that attempted to reveal integrated modules across these networks failed to significantly <lb/>improve predictions compared to methods that considered each network individually. Possibly, <lb/>the networks of the challenge were not sufficiently related --multi-network methods may <lb/>perform better on networks from the same tissue-and disease-context (Krishnan et al., 2016). <lb/>The benchmark datasets and results of the challenge provide a reference point for future <lb/>method improvements. We see many promising avenues for future work, such as: (i) top-<lb/></body>

			<page>16 <lb/></page>

			<body>performing challenge methods can potentially be further enhanced with ensemble approaches <lb/>that sample multiple partitions of the same method to generate stable results (Lancichinetti and <lb/>Fortunato, 2012); (ii) top teams recursively broke down large &quot;supermodules&quot; by iteratively <lb/>applying their clustering methods, a heuristic that worked well, but more principled approaches <lb/>to globally balance module sizes may improve accuracy (exemplified by method R1); and (iii) <lb/>methods for detection of overlapping modules (Ihmels et al., 2002) may also be assessed using <lb/>the benchmarks of this challenge. <lb/>An important observation about these results is that the module identification tasks were <lb/>performed on completely blinded networks; gene identities and even the type of relationship <lb/>captured was unknown to challenge participants. The fact that meaningful modules can be <lb/>identified in such a context is perhaps surprising, revealing how much functional information is <lb/>present strictly in the topological structure of biological networks. It remains to be seen whether <lb/>an un-blinded approach that allows integration of prior knowledge about gene functions, <lb/>relationships, and the source of network edges might further improve the quality of inferred <lb/>modules, especially when integrating data from multiple types of networks. <lb/>The collective effort of over 400 challenge participants resulted in a unique compendium of <lb/>modules for the different types of molecular networks considered. By leveraging the &quot;wisdom of <lb/>crowds&quot; we generated robust consensus modules, which captured disease-relevant pathways <lb/>better than any individual method. While most modules partly reflect known pathways or <lb/>functional gene categories, which they reorganize and expand with additional genes, other <lb/>modules may correspond to yet uncharacterized pathways. The consensus modules (gene sets) <lb/>thus constitute a novel data-driven pathway collection, which may complement existing pathway <lb/>collections in a range of applications (e.g., for interpretation of gene expression data using gene <lb/>set enrichment analysis). <lb/>There is continuing debate over the value of GWASs for revealing disease mechanisms and <lb/>therapeutic targets. Indeed, the number of GWAS hits continues to grow as sample sizes <lb/>increase, but the bulk of these hits may not correspond to core genes with specific roles in <lb/>disease etiology. An &quot;omnigenic&quot; model recently proposed by Boyle et al. (2017) explains this <lb/>observation by the high interconnectivity of molecular networks, which implies that most of the <lb/>expressed genes in a disease-relevant tissue are likely to be at least weakly connected to core <lb/>genes and may thus have non-zero effects on that disease. Indeed, disease-associated genes <lb/>tend to coalesce in regulatory networks of tissues that are specific to that disease (Marbach et <lb/>al., 2016). Our analysis of 180 GWAS datasets across six molecular networks demonstrated <lb/></body>

			<page>17 <lb/></page>

			<body>that, although thousands of genes may show association for a given disease, at the network <lb/>level specific disease modules comprising only dozens of genes can be identified. We have <lb/>shown that these modules are more disease-specific than individual genes, reveal pathway-<lb/>level similarity between diseases, accurately prioritize candidate genes, and correspond to core <lb/>disease pathways in the majority of cases. These results are consistent with the omnigenic <lb/>model and the robustness of biological networks: presumably, the many genes that influence <lb/>disease indirectly are broadly distributed across network modules, while core disease genes <lb/>cluster in specific pathways underlying pathophysiological processes (Sullivan and Posthuma, <lb/>2015). Our analysis also demonstrated that GWASs with larger sample size are extremely <lb/>useful for the identification of key core modules and SNP effect size (explained variance) is not <lb/>necessarily an indicator of core-ness. <lb/>In this study we used global networks because the focus was on method assessment across <lb/>diverse disorders. Global networks mostly comprise pathways that are either broadly expressed <lb/>or specific to well-studied tissues, such as blood or immune cells. In the near future, we expect <lb/>much more detailed maps of cell-and tissue-specific networks, along with diverse high-powered <lb/>genetic datasets, to become available. We hope that the challenge resources will be <lb/>instrumental in dissecting these networks and will provide a solid foundation for developing <lb/>integrative methods to reveal the cell types and causal circuits implicated in human disease. <lb/></body>

			<div type="annex">Consortia <lb/>The contributing members of the DREAM Module Identification Challenge Consortium are: <lb/>Fabian Aicheler, 1 Nicola Amoroso, 2,3 Alex Arenas, 4 Karthik Azhagesan, 5-,7 Aaron Baker, 8-10 Michael <lb/>Banf, 11 Serafim Batzoglou, 12 Anaïs Baudot, 13 Roberto Bellotti, 2,3,14 Sven Bergmann, 15,16 Keith A. <lb/>Boroevich, 17 Christine Brun, 18-19 Stanley Cai, 20,93,94 Michael Caldera, 21 Alberto Calderone, 22 Gianni <lb/>Cesareni, 22 Weiqi Chen, 23 Christine Chichester, 24 Sarvenaz Choobdar, 15-16 Lenore Cowen, 25-26 Jake <lb/>Crawford, 25 Hongzhu Cui, 27 Phuong Dao, 46 Manlio De Domenico, 4,29 Andi Dhroso, 27 Gilles Didier, 13 <lb/>Mathew Divine, 1 Antonio del Sol, 36 Xuyang Feng, 30 Jose C. Flores-Canales, 31-32 Santo Fortunato, 33 <lb/>Anthony Gitter, 8,9,10 Anna Gorska, 34 Yuanfang Guan, 35 Alain Guénoche, 13 Sergio Gómez, 4 Hatem <lb/>Hamza, 24 András Hartmann, 36 Shan He, 23 Anton Heijs, 37 Julian Heinrich, 1 Benjamin Hescott, 38 Xiaozhe <lb/>Hu, 26 Ying Hu, 39 Xiaoqing Huang, 46 V. Keith Hughitt, 40-41 Minji Jeon, 42 Lucas Jeub, 33 Nathan Johnson, 27 <lb/>Keehyoung Joo, 32,43 InSuk Joung, 31-32 Sascha Jung, 36 Susana G. Kalko, 36 Piotr J. Kamola, 17 Jaewoo <lb/>Kang, 42,44 Benjapun Kaveelerdpotjana, 23 Minjun Kim, 45 Yoo-Ah Kim, 46 Oliver Kohlbacher, 1,47-48 Dmitry <lb/>Korkin, 27,49-50 Kiryluk Krzysztof, 51 Khalid Kunji, 52 Zoltàn Kutalik, 16,53 Kasper Lage, 54-56 David Lamparter, 15-<lb/>16,57 Sean Lang-Brown, 58 Thuc Duy Le, 59-60 Jooyoung Lee, 31-32 Sunwon Lee, 42 Juyong Lee, 61 Dong Li, 23 <lb/>Jiuyong Li, 60 Junyuan Lin, 26 Lin Liu, 60 Antonis Loizou, 62 Zhenhua Luo, 63 Artem Lysenko, 17 Tianle Ma, 64 <lb/>Raghvendra Mall, 52 Daniel Marbach, 15-16 Tomasoni Mattia, 15-16 Mario Medvedovic, 65 Jörg Menche, 21 <lb/>Johnathan Mercer, 54,56 Elisa Micarelli, 22 Alfonso Monaco, 3 Felix Müller, 21 Rajiv Narayan, 66 Oleksandr <lb/>Narykov, 50 Ted Natoli, 66 Thea Norman, 67 Sungjoon Park, 42 Livia Perfetto, 22 Dimitri Perrin, 68 Stefano <lb/>Pirrò, 22 Teresa M. Przytycka, 46 Xiaoning Qian, 69 Karthik Raman, 5-7 Daniele Ramazzotti, 12 Balaraman <lb/>Ravindran, 70,6,7 Philip Rennert, 71 Julio Saez-Rodriguez, 7-,73 Charlotta Schärfe , 1 Roded Sharan, 74 Ning <lb/></div>

			<page>18 <lb/></page>

			<div type="annex">Shi, 23 Wonho Shin, 44 Hai Shu, 75 Himanshu Sinha, 5,6,7 Donna K. Slonim, 25 Lionel Spinelli, 18 Suhas <lb/>Srinivasan, 49 Aravind Subramanian, 66 Christine Suver, 76 Damian Szklarczyk, 77 Sabina Tangaro, 3 Suresh <lb/>Thiagarajan, 78 Laurent Tichit, 13 Thorsten Tiede, 1 Beethika Tripathi, 70,6,7 Aviad Tsherniak, 66 Tatsuhiko <lb/>Tsunoda, 17,79,80 Dénes Türei, 72 Ehsan Ullah, 52 Golnaz Vahedi, 20,93,94 Alberto Valdeolivas, 13,82 Jayaswal <lb/>Vivek, 83 Christian von Mering, 77 Andra Waagmeester, 37 Bo Wang, 12 Yijie Wang, 46 Barbara A. Weir, 84-85 <lb/>Shana White, 65 Sebastian Winkler, 1 Ke Xu, 86 Taosheng Xu, 87 Chunhua Yan, 39 Liuqing Yang, 88 Kaixian <lb/>Yu, 75 Xiangtian Yu, 89 Gaia Zaffaroni, 36 Mikhail Zaslavskiy, 90 Tao Zeng, 89 Lu Zhang, 12 Weijia Zhang, 60 Lixia <lb/>Zhang, 65 Xinyu Zhang, 86 Junpeng Zhang, 91 Xin Zhou, 12 Jiarui Zhou, 23 Hongtu Zhu, 75 Junjie Zhu, 92 Guido <lb/>Zuccon, 68 <lb/>1 <lb/>Applied Bioinformatics, Center for Bioinformatics, University of Tuebingen, Sand 14, 72076 Tuebingen, <lb/>Germany. 2 Department of Physics &apos;Michelangelo Merlin&apos;, University of Bari &apos;Aldo Moro&apos;, Via G. Amendola <lb/>173, 70126 Bari, Italy. 3 INFN, Sezione di Bari, Via A. Orabona 4, 70125 Bari, Italy. 4 Departament <lb/>d&apos;Enginyeria Informàtica i Matemàtiques, Universitat Rovira i Virgili, Tarragona, Spain. 5 Department of <lb/>Biotechnology, Bhupat and Jyoti Mehta School of Biosciences, Indian Institute of Technology Madras, <lb/>Chennai, India. 6 Initiative for Biological Systems Engineering (IBSE), Indian Institute of Technology <lb/>Madras. 7 Robert Bosch Centre for Data Science and Artificial Intelligence(RBC-DSAI), Indian Institute of <lb/>Technology Madras. 8 Department of Biostatistics and Medical Informatics, University of Wisconsin-<lb/>Madison, Madison, Wisconsin, USA. 9 Department of Computer Sciences, University of Wisconsin-<lb/>Madison, Madison, Wisconsin, USA. 10 Morgridge Institute for Research, Madison, Wisconsin, USA. <lb/>11 <lb/>Department of Plant Biology, Carnegie Institution for Science, Stanford, USA. 12 Department of <lb/>Computer Science, Stanford University, USA. 13 Aix Marseille Univ, CNRS, Centrale Marseille, I2M, UMR <lb/>7373, Marseille, France. 14 Centro TIRES, Via G. Amendola 173, 70126 Bari, Italy. 15 Department of <lb/>Computational Biology, University of Lausanne, Lausanne, Switzerland. 16 Swiss Institute of <lb/>Bioinformatics, Lausanne, Switzerland. 17 RIKEN Center for Integrative Medical Sciences, Yokohama, <lb/>Japan. 18 Aix Marseille Univ, INSERM, TAGC, UMR1090, Marseille, France. 19 CNRS, Marseille, France. <lb/>20 <lb/>Department of Genetics, Perelman School of Medicine at the University of Pennsylvania, Philadelphia, <lb/>Pennsylvania, USA. 21 CeMM Research Center for Molecular Medicine of the Austrian Academy of <lb/>Sciences, Vienna, Austria. 22 Bioinformatics and Computational Biology Unit, Department of Biology, Tor <lb/>Vergata University, Italy. 23 School of Computer Science, The University of Birmingham, Birmingham, UK. <lb/>24 <lb/>Nestle Institute of Health Sciences, Lausanne, Switzerland. 25 Department of Computer Science, Tufts <lb/>University, Medford, MA, USA. 26 Department of Mathematics, Tufts University, Medford, MA, USA. <lb/>27 <lb/>Bioinformatics and Computational Biology Program, Worcester Polytechnic Institute, Worcester, MA, <lb/>USA. 29 Fondazione Bruno Kessler, Via Sommarive 18, 38123 Povo, Italy. 30 Department of Cancer <lb/>Biology, University of Cincinnati, Cincinnati, OH, USA. 31 Center for In Silico Protein Science, Korea <lb/>Institute for Advanced Study, Seoul, Korea. 32 School of Computational Sciences, Korea Institute for <lb/>Advanced Study, Seoul, Korea. 33 School of Informatics, Computing and Engineering, Indiana University, <lb/>Bloomington, USA. 34 Algorithms in Bioinformatics, Center for Bioinformatics, University of Tuebingen, <lb/>Sand 14, 72076 Tuebingen, Germany. 35 Department of Computational Medicine and Bioinformatics, <lb/>University of Michigan, Ann Arbor, MI, 48109. 36 LCSB -Luxembourg Centre for Systems Biomedicine, <lb/>University of Luxembourg, Esch-sur-Alzette, Luxembourg. 37 Micelio, 2180 Antwerp, Belgium. 38 College of <lb/>Computer and Information Science, Northeastern University, Boston, MA, USA. 39 National Cancer <lb/>Institute, Center for Biomedical Informatics &amp; Information Technology, 9609 Medical Center Drive, <lb/>Bethesda, MD 20850, USA. 40 Center for Bioinformatics and Computational Biology, University of <lb/>Maryland, College Park, Maryland, USA. 41 Department of Cell Biology and Molecular Genetics, University <lb/>of Maryland, College Park, Maryland, USA. 42 Department of Computer Science and Engineering, Korea <lb/>University, Seoul, Korea. 43 Center for Advanced Computation, Korea Institute for Advanced Study, Seoul, <lb/>Korea. 44 Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, Korea. <lb/>45 <lb/>Community High School, 401 N Division St, Ann Arbor, MI, 48104. 46 National Center for Biotechnology <lb/>Information, National Institute of Health (NCBI/NLM/NIH), USA. 47 Biomolecular Interactions, Max Planck <lb/>Institute for Developmental Biology, Spemannstr. 38, 72076 Tuebingen, Germany. 48 Quantitative Biology <lb/></div>

			<page>19 <lb/></page>

			<div type="annex">Center, University of Tuebingen, Auf der Morgenstelle 8, 72076 Tuebingen, Germany. 49 Data Science <lb/>Program, Worcester Polytechnic Institute, Worcester, MA, USA. 50 Department of Computer Science, <lb/>Worcester Polytechnic Institute, Worcester, MA, USA. 51 Department of Medicine, College of Physicians &amp; <lb/>Surgeons, Columbia University, New York, NY, USA. 52 Qatar Computing Research Institute, Hamad Bin <lb/>Khalifa University, Doha, Qatar. 53 Institute of Social and Preventive Medicine (IUMSP), Lausanne <lb/>University Hospital, Lausanne, Switzerland. 54 Department of Surgery, Massachusetts General Hospital, <lb/>Harvard Medical School, Boston, Massachusetts, USA. 55 Institute for Biological Psychiatry, Mental Health <lb/>Center Sct. Hans, University of Copenhagen, Roskilde, Denmark. 56 Stanley Center at the Broad Institute <lb/>of MIT and Harvard, Cambridge, Massachusetts, USA. 57 Verge Genomics, San Francisco, CA, USA. <lb/>58 <lb/>Division of Geriatrics, Department of Medicine, University of California, San Francisco, USA. 59 Centre <lb/>for Cancer Biology, University of South Australia. 60 School of Information Technology and Mathematical <lb/>Sciences, University of South Australia. 61 Department of Chemistry, Kangwon National University, 1 <lb/>Kangwondaehak-gil, Chuncheon, 24341, Republic of Korea. 62 BlueSkyIt, Amsterdam, the Netherlands. <lb/>63 <lb/>The Liver Care Center and Divisions of Gastroenterology, Hepatology and Nutrition, Cincinnati <lb/>Children&apos;s Hospital Medical Center, Cincinnati, OH, USA. 64 Department of Computer Science and <lb/>Engineering, University at Buffalo, Buffalo, NY, USA. 65 Dept. of Env. Health, Division of Biostatistics and <lb/>Bioinformatics, University of Cincinnati, OH, USA. 66 Broad Institute of Harvard and MIT, Cambridge, MA. <lb/>67 <lb/>Bill and Melinda Gates Foundation. 68 School of Electrical Engineering and Computer Science, <lb/>Queensland University of Technology, Brisbane, Australia. 69 Dept. of Electrical &amp; Computer Engineering, <lb/>Texas A&amp;M University, USA. 70 Department of Computer Science and Engineering, Indian Institute of <lb/>Technology Madras, Chennai, India. 71 Rockville, MD, USA (No affiliation). 72 European Molecular Biology <lb/>Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Genome Campus, Cambridge <lb/>CB10 1SD, UK. 73 RWTH Aachen University, Faculty of Medicine, Joint Research Centre for <lb/>Computational Biomedicine, 52057 Aachen, Germany. 74 Blavatnik School of Computer Science, Tel Aviv <lb/>University, Tel Aviv 69978, Israel. 75 Department of Biostatistics, the University of Texas MD Anderson <lb/>Cancer Center, Houston, TX, USA. 76 Sage Bionetworks, Seattle, Washington 98109, USA. 77 Institute of <lb/>Molecular Life Sciences and Swiss Institute of Bioinformatics, University of Zurich, Zurich, Switzerland. <lb/>78 <lb/>Memphis, TN, USA (No affiliation). 79 CREST, JST, Tokyo, Japan. 80 Department of Medical Science <lb/>Mathematics, Medical Research Institute, Tokyo Medical and Dental University, Tokyo, Japan. <lb/>82 <lb/>ProGeLife, Marseille, France. 83 Disease Science &amp; Technology, Biocon Bristol-Myers Squibb Research <lb/>Centre, Bangalore, India. 84 Broad Institute of Harvard and MIT, Cambridge, MA. 85 Janssen Research and <lb/>Development. 86 Department of Psychiatry, Yale School of Medicine, West Haven, CT, USA. 87 Institute of <lb/>Intelligent Machines, Hefei Institutes of Physical Science, Chinese Academy of Sciences, Hefei, Anhui, <lb/>China. 88 Department of Statistics and Operations Research, University of North Carolina at Chapel Hill, <lb/>Chapel Hill, NC, USA. 89 Key Laboratory of Systems Biology, Institute of Biochemistry and Cell Biology, <lb/>Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences. 90 Computational biology <lb/>consulting, avenue Kleber 100, Paris, France. 91 School of Engineering, Dali University. 92 Department of <lb/>Electrical Engineering, Stanford University, USA. 93 Institute for Immunology, Perelman School of Medicine <lb/>at the University of Pennsylvania, Philadelphia, Pennsylvania, USA. 94 Epigenetics Institute, Perelman <lb/>School of Medicine at the University of Pennsylvania, Philadelphia, Pennsylvania, USA. <lb/></div>

			<div type="annex">Author contributions <lb/>S.C., D.L., Z.K., G.S., J.M., K.L., J.S.-R., S.B. and D.M. conceived the challenge; S.C., G.S., <lb/>J.S.-R., S.B. and D.M. organized the challenge; S.C. and D.M. performed team scoring; S.C., <lb/>M.E.A., J.C., M.T., D.K.S., L.J.C. and D.M. analyzed results; J.M., T.N., R.N., A.S., K.L. and <lb/>J.S.-R. constructed networks; J.C., J.L., B.H., X.H., D.K.S. and L.J.C. designed the top-<lb/>performing method; the DREAM Module Identification Consortium provided data and performed <lb/></div>

			<page>20 <lb/></page>

			<div type="annex">module identification; S.B. and D.M. designed the study; and D.M. prepared the manuscript. All <lb/>authors discussed the results and implications, and commented on the manuscript at all stages. <lb/></div>

			<div type="acknowledgement">Acknowledgments <lb/>The challenge was hosted on Sage Bionetwork&apos;s Synapse platform (https://synapse.org/). The <lb/>computations were performed at the Vital-IT (http://www.vital-it.ch) Center for high-performance <lb/>computing of the SIB Swiss Institute of Bioinformatics. This work was supported by the Swiss <lb/>National Science Foundation (grant FN 310030_152724/1 to S.B. and grant FN 31003A-169929 <lb/>to Z.K.), SystemsX.ch (grant SysGenetiX to S.B. and grant AgingX to Z.K.), the Swiss Institute <lb/>of Bioinformatics (Z.K. and S.B.) and the Leenaards Foundation (Z.K.). <lb/></div>

			<listBibl>References <lb/>Arenas, A., Fernández, A., and Gómez, S. (2008). Analysis of the structure of complex networks at <lb/>different resolution levels. New J. Phys. 10, 053039. <lb/>Barrett, T., Troup, D.B., Wilhite, S.E., Ledoux, P., Evangelista, C., Kim, I.F., Tomashevsky, M., Marshall, <lb/>K.A., Phillippy, K.H., Sherman, P.M., et al. (2011). NCBI GEO: archive for functional genomics data sets--<lb/>10 years on. Nucleic Acids Res. 39, D1005-1010. <lb/>Blake, J.A., Eppig, J.T., Kadin, J.A., Richardson, J.E., Smith, C.L., and Bult, C.J. (2017). Mouse Genome <lb/>Database (MGD)-2017: community knowledge resource for the laboratory mouse. Nucleic Acids Res. 45, <lb/>D723-D729. <lb/>Blondel, V.D., Guillaume, J.-L., Lambiotte, R., and Lefebvre, E. (2008). Fast unfolding of communities in <lb/>large networks. J. Stat. Mech. Theory Exp. 2008, P10008. <lb/>Boyle, E.A., Li, Y.I., and Pritchard, J.K. (2017). An Expanded View of Complex Traits: From Polygenic to <lb/>Omnigenic. Cell 169, 1177-1186. <lb/>Cahan, P., Li, H., Morris, S.A., Lummertz da Rocha, E., Daley, G.Q., and Collins, J.J. (2014). CellNet: <lb/>Network Biology Applied to Stem Cell Engineering. Cell 158, 903-915. <lb/>Cai, J., Candès, E., and Shen, Z. (2010). A Singular Value Thresholding Algorithm for Matrix Completion. <lb/>SIAM J. Optim. 20, 1956-1982. <lb/>Califano, A., Butte, A.J., Friend, S., Ideker, T., and Schadt, E. (2012). Leveraging models of cell <lb/>regulation and GWAS data in integrative network-based association studies. Nat. Genet. 44, 841-847. <lb/>Cao, M., Zhang, H., Park, J., Daniels, N.M., Crovella, M.E., Cowen, L.J., and Hescott, B. (2013). Going <lb/>the distance for protein function prediction: a new distance metric for protein interaction networks. PloS <lb/>One 8, e76339. <lb/>Cao, M., Pietras, C.M., Feng, X., Doroschak, K.J., Schaffner, T., Park, J., Zhang, H., Cowen, L.J., and <lb/>Hescott, B.J. (2014). New directions for diffusion-based network prediction of protein function: <lb/>incorporating pathways with confidence. Bioinforma. Oxf. Engl. 30, i219-227. <lb/>Chen, J.C., Alvarez, M.J., Talos, F., Dhruv, H., Rieckhof, G.E., Iyer, A., Diefes, K.L., Aldape, K., Berens, <lb/>M., Shen, M.M., et al. (2014). Identification of causal genetic drivers of human disease through systems-<lb/>level analysis of regulatory networks. Cell 159, 402-414. <lb/>Chen, Y., Zhu, J., Lum, P.Y., Yang, X., Pinto, S., MacNeil, D.J., Zhang, C., Lamb, J., Edwards, S., <lb/>Sieberts, S.K., et al. (2008). Variations in DNA elucidate molecular networks that cause disease. Nature <lb/>452, 429-435. <lb/>Ciofani, M., Madar, A., Galan, C., Sellars, M., Mace, K., Pauli, F., Agarwal, A., Huang, W., Parkurst, C.N., <lb/>Muratet, M., et al. (2012). A validated regulatory network for th17 cell specification. Cell 151, 289-303. <lb/></listBibl>

			<page>21 <lb/></page>

			<listBibl>Clauset, A., Moore, C., and Newman, M.E.J. (2008). Hierarchical structure and the prediction of missing <lb/>links in networks. Nature 453, 98-101. <lb/>Cowley, G.S., Weir, B.A., Vazquez, F., Tamayo, P., Scott, J.A., Rusin, S., East-Seletsky, A., Ali, L.D., <lb/>Gerath, W.F., Pantel, S.E., et al. (2014). Parallel genome-scale loss of function screens in 216 cancer cell <lb/>lines for the identification of context-specific genetic dependencies. Sci. Data 1, 140035. <lb/>De Domenico, M., Lancichinetti, A., Arenas, A., and Rosvall, M. (2015). Identifying Modular Flows on <lb/>Multilayer Networks Reveals Highly Overlapping Organization in Interconnected Systems. Phys. Rev. X 5, <lb/>011027. <lb/>Derry, J.M.J., Mangravite, L.M., Suver, C., Furia, M.D., Henderson, D., Schildwachter, X., Bot, B., Izant, <lb/>J., Sieberts, S.K., Kellen, M.R., et al. (2012). Developing predictive molecular maps of human disease <lb/>through community-based modeling. Nat. Genet. 44, 127-130. <lb/>Didier, G., Brun, C., and Baudot, A. (2015). Identifying communities from multiplex biological networks. <lb/>PeerJ 3, e1525. <lb/>Fortunato, S., and Hric, D. (2016). Community detection in networks: A user guide. Phys. Rep. 659, 1-44. <lb/>Fuchsberger, C., Flannick, J., Teslovich, T.M., Mahajan, A., Agarwala, V., Gaulton, K.J., Ma, C., <lb/>Fontanillas, P., Moutsianas, L., McCarthy, D.J., et al. (2016). The genetic architecture of type 2 diabetes. <lb/>Nature 536, 41-47. <lb/>Girvan, M., and Newman, M.E.J. (2002). Community structure in social and biological networks. Proc. <lb/>Natl. Acad. Sci. 99, 7821-7826. <lb/>Glass, K., and Girvan, M. (2014). Annotation Enrichment Analysis: An Alternative Method for Evaluating <lb/>the Functional Properties of Gene Sets. Sci. Rep. 4. <lb/>Greene, C.S., Krishnan, A., Wong, A.K., Ricciotti, E., Zelaya, R.A., Himmelstein, D.S., Zhang, R., <lb/>Hartmann, B.M., Zaslavsky, E., Sealfon, S.C., et al. (2015). Understanding multicellular function and <lb/>disease with human tissue-specific networks. Nat. Genet. 47, 569-576. <lb/>Hartwell, L.H., Hopfield, J.J., Leibler, S., and Murray, A.W. (1999). From molecular to modular cell <lb/>biology. Nature 402, C47-52. <lb/>Hill, S.M., Heiser, L.M., Cokelaer, T., Unger, M., Nesser, N.K., Carlin, D.E., Zhang, Y., Sokolov, A., Paull, <lb/>E.O., Wong, C.K., et al. (2016). Inferring causal molecular networks: empirical assessment through a <lb/>community-based effort. Nat. Methods 13, 310-318. <lb/>Ideker, T., and Sharan, R. (2008). Protein networks in disease. Genome Res. 18, 644-652. <lb/>Ihmels, J., Friedlander, G., Bergmann, S., Sarig, O., Ziv, Y., and Barkai, N. (2002). Revealing modular <lb/>organization in the yeast transcriptional network. Nat. Genet. 31, 370-377. <lb/>Jiang, P., and Singh, M. (2010). SPICi: a fast clustering algorithm for large biological networks. <lb/>Bioinforma. Oxf. Engl. 26, 1105-1111. <lb/>Jin, J. (2015). Fast community detection by SCORE. Ann. Stat. 43, 57-89. <lb/>Kiryluk, K., Li, Y., Scolari, F., Sanna-Cherchi, S., Choi, M., Verbitsky, M., Fasel, D., Lata, S., Prakash, S., <lb/>Shapiro, S., et al. (2014). Discovery of new risk loci for IgA nephropathy implicates genes involved in <lb/>immunity against intestinal pathogens. Nat. Genet. 46, 1187-1196. <lb/>Kondor, R.I., and Lafferty, J.D. (2002). Diffusion Kernels on Graphs and Other Discrete Input Spaces. In <lb/>Proceedings of the Nineteenth International Conference on Machine Learning, (San Francisco, CA, USA: <lb/>Morgan Kaufmann Publishers Inc.), pp. 315-322. <lb/>Kraehling, J.R., and Sessa, W.C. (2017). Contemporary Approaches to Modulating the Nitric Oxide-cGMP <lb/>Pathway in Cardiovascular Disease. Circ. Res. 120, 1174-1182. <lb/>Krishnan, A., Taroni, J.N., and Greene, C.S. (2016). Integrative Networks Illuminate Biological Factors <lb/>Underlying Gene-Disease Associations. Curr. Genet. Med. Rep. 4, 155-162. <lb/>Lamparter, D., Marbach, D., Rico, R., Kutalik, Z., and Bergmann, S. (2016). Fast and rigorous <lb/>computation of gene and pathway scores from SNP-based summary statistics. PLoS Comput Biol 12, <lb/>e1004714. <lb/>Lancichinetti, A., and Fortunato, S. (2012). Consensus clustering in complex networks. Sci. Rep. 2, <lb/>srep00336. <lb/></listBibl>

			<page>22 <lb/></page>

			<listBibl>de Lange, K.M., Moutsianas, L., Lee, J.C., Lamb, C.A., Luo, Y., Kennedy, N.A., Jostins, L., Rice, D.L., <lb/>Gutierrez-Achury, J., Ji, S.-G., et al. (2017). Genome-wide association study implicates immune activation <lb/>of multiple integrin genes in inflammatory bowel disease. Nat. Genet. 49, 256-261. <lb/>Langfelder, P., and Horvath, S. (2008). WGCNA: an R package for weighted correlation network analysis. <lb/>BMC Bioinformatics 9, 559. <lb/>Lee, J., Gross, S., and Lee, J. (2012). Mod-CSA: Modularity optimization by conformational space <lb/>annealing. Phys Rev E 85. <lb/>Li, D., He, S., Pan, Z., and Hu, G. (2016). Active modules for multilayer weighted gene co-expression <lb/>networks: a continuous optimization approach. BioRxiv 056952. <lb/>Li, T., Wernersson, R., Hansen, R.B., Horn, H., Mercer, J., Slodkowicz, G., Workman, C.T., Rigina, O., <lb/>Rapacki, K., Staerfeldt, H.H., et al. (2017). A scored human protein-protein interaction network to catalyze <lb/>genomic interpretation. Nat. Methods 14, 61-64. <lb/>Li, Y., Calvo, S.E., Gutman, R., Liu, J.S., and Mootha, V.K. (2014). Expansion of biological pathways <lb/>based on evolutionary inference. Cell 158, 213-225. <lb/>Madhusudhan, T., Kerlin, B.A., and Isermann, B. (2016). The emerging role of coagulation proteases in <lb/>kidney disease. Nat. Rev. Nephrol. 12, 94-109. <lb/>Marbach, D., Costello, J.C., Küffner, R., Vega, N.M., Prill, R.J., Camacho, D.M., Allison, K.R., Kellis, M., <lb/>Collins, J.J., and Stolovitzky, G. (2012). Wisdom of crowds for robust gene network inference. Nat. <lb/>Methods 9, 796-804. <lb/>Marbach, D., Lamparter, D., Quon, G., Kellis, M., Kutalik, Z., and Bergmann, S. (2016). Tissue-specific <lb/>regulatory circuits reveal variable modular perturbations across complex diseases. Nat. Methods 13, 366-<lb/>370. <lb/>Marouli, E., Graff, M., Medina-Gomez, C., Lo, K.S., Wood, A.R., Kjaer, T.R., Fine, R.S., Lu, Y., <lb/>Schurmann, C., Highland, H.M., et al. (2017). Rare and low-frequency coding variants alter human adult <lb/>height. Nature 542, 186-190. <lb/>Neurath, M.F. (2017). Current and emerging therapeutic targets for IBD. Nat. Rev. Gastroenterol. <lb/>Hepatol. 14, 269-278. <lb/>Newman, M.E.J., and Girvan, M. (2004). Finding and evaluating community structure in networks. Phys. <lb/>Rev. E 69, 026113. <lb/>Ng, A.Y., Jordan, M.I., and Weiss, Y. (2001). On Spectral Clustering: Analysis and an algorithm. In <lb/>Advances in Neural Information Processing Systems, (MIT Press), pp. 849-856. <lb/>Norel, R., Rice, J.J., and Stolovitzky, G. (2011). The self-assessment trap: can we all be better than <lb/>average? Mol. Syst. Biol. 7, 537. <lb/>Padi, M., and Quackenbush, J. (2017). Phenotype-Driven Transitions In Regulatory Network Structure. <lb/>BioRxiv 142281. <lb/>Parisi, F., Strino, F., Nadler, B., and Kluger, Y. (2014). Ranking and combining multiple predictors without <lb/>labeled data. Proc. Natl. Acad. Sci. 201219097. <lb/>Pe&apos;er, D., Regev, A., Elidan, G., and Friedman, N. (2001). Inferring subnetworks from perturbed <lb/>expression profiles. Bioinforma. Oxf. Engl. 17 Suppl 1, S215-224. <lb/>Perozzi, B., Al-Rfou, R., and Skiena, S. (2014). DeepWalk: Online Learning of Social Representations. <lb/>ArXiv14036652 Cs 701-710. <lb/>Pickrell, J.K. (2014). Joint analysis of functional genomic data and genome-wide association studies of 18 <lb/>human traits. Am. J. Hum. Genet. 94, 559-573. <lb/>Pons, P., and Latapy, M. (2005). Computing communities in large networks using random walks (long <lb/>version). ArXiv:Physics/0512106. <lb/>Randall, J.C., Winkler, T.W., Kutalik, Z., Berndt, S.I., Jackson, A.U., Monda, K.L., Kilpeläinen, T.O., Esko, <lb/>T., Mägi, R., Li, S., et al. (2013). Sex-stratified genome-wide association studies including 270,000 <lb/>individuals show sexual dimorphism in genetic loci for anthropometric traits. PLoS Genet. 9, e1003500. <lb/>Ravasz, E., Somera, A.L., Mongru, D.A., Oltvai, Z.N., and Barabási, A.L. (2002). Hierarchical organization <lb/>of modularity in metabolic networks. Science 297, 1551-1555. <lb/></listBibl>

			<page>23 <lb/></page>

			<listBibl>Rosvall, M., Axelsson, D., and Bergstrom, C.T. (2009). The map equation. Eur. Phys. J. Spec. Top. 178, <lb/>13-23. <lb/>Satuluri, V., Parthasarathy, S., and Ucar, D. (2010). Markov Clustering of Protein Interaction Networks <lb/>with Improved Balance and Scalability. In Proceedings of the First ACM International Conference on <lb/>Bioinformatics and Computational Biology, (New York, NY, USA: ACM), pp. 247-256. <lb/>Schadt, E.E. (2009). Molecular networks as sensors and drivers of common human diseases. Nature <lb/>461, 218-223. <lb/>Shao, J., Yang, Q., Liu, J., and Kramer, S. (2016). Graph Clustering with Density-Cut. ArXiv160600950 <lb/>Phys. <lb/>Shiokawa, H., Fujiwara, Y., and Onizuka, M. (2015). SCAN++: Efficient Algorithm for Finding Clusters, <lb/>Hubs and Outliers on Large-scale Graphs. Proc VLDB Endow 8, 1178-1189. <lb/>Subramanian, A., Narayan, R., Corsello, S.M., Peck, D.D., Natoli, T.E., Lu, X., Gould, J., Davis, J.F., <lb/>Tubelli, A.A., Asiedu, J.K., et al. (2017). A Next Generation Connectivity Map: L1000 Platform and the <lb/>First 1,000,000 Profiles. Cell 171, 1437-1452.e17. <lb/>Sullivan, P.F., and Posthuma, D. (2015). Biological pathways and networks implicated in psychiatric <lb/>disorders. Curr. Opin. Behav. Sci. 2, 58-68. <lb/>Szklarczyk, D., Franceschini, A., Wyder, S., Forslund, K., Heller, D., Huerta-Cepas, J., Simonovic, M., <lb/>Roth, A., Santos, A., Tsafou, K.P., et al. (2015). STRING v10: protein-protein interaction networks, <lb/>integrated over the tree of life. Nucleic Acids Res. 43, D447-452. <lb/>Tang, J., Qu, M., Wang, M., Zhang, M., Yan, J., and Mei, Q. (2015). LINE: Large-scale Information <lb/>Network Embedding. In Proceedings of the 24th International Conference on World Wide Web, (Republic <lb/>and Canton of Geneva, Switzerland: International World Wide Web Conferences Steering Committee), <lb/>pp. 1067-1077. <lb/>Tsherniak, A., Vazquez, F., Montgomery, P.G., Weir, B.A., Kryukov, G., Cowley, G.S., Gill, S., Harrington, <lb/>W.F., Pantel, S., Krill-Burger, J.M., et al. (2017). Defining a Cancer Dependency Map. Cell 170, 564-<lb/>576.e16. <lb/>Türei, D., Korcsmáros, T., and Saez-Rodriguez, J. (2016). OmniPath: guidelines and gateway for <lb/>literature-curated signaling pathway resources. Nat. Methods 13, 966-967. <lb/>Vidal, M., Cusick, M.E., and Barabási, A.-L. (2011). Interactome networks and human disease. Cell 144, <lb/>986-998. <lb/>Wang, Y., and Qian, X. (2017). Finding low-conductance sets with dense interactions (FLCD) for better <lb/>protein complex prediction. BMC Syst. Biol. 11. <lb/>Wood, A.R., Esko, T., Yang, J., Vedantam, S., Pers, T.H., Gustafsson, S., Chu, A.Y., Estrada, K., Luan, <lb/>J., Kutalik, Z., et al. (2014). Defining the role of common variation in the genomic and biological <lb/>architecture of adult human height. Nat. Genet. 46, 1173-1186. <lb/>Young, M.D., Wakefield, M.J., Smyth, G.K., and Oshlack, A. (2010). Gene ontology analysis for RNA-seq: <lb/>accounting for selection bias. Genome Biol. 11, R14. <lb/></listBibl>

			<page>24 <lb/></page>

			<body>Table 1 <lb/>Table 1. Module identification methods <lb/>ID a Description <lb/>Score b <lb/>Pre-/ post-<lb/>processing <lb/>Kernel clustering: (i) the weighted adjacency matrix is transformed into a gene similarity matrix; (ii) a clustering algorithm is applied. <lb/>K1 (i) Diffusion State Distance metric (Cao et al., 2013); (ii) spectral clustering. <lb/>R <lb/>K2 (i) Singular Value Thresholding (Cai et al., 2010) maps the graph into a latent feature space; (ii) hierarchical clustering using <lb/>Ward&apos;s method. <lb/>W, R <lb/>K3 (i) Large-scale Information Network Embedding (LINE) (Tang et al., 2015); (ii) K-means clustering. <lb/>-<lb/>K4 (i) Extension of Spectral Clustering On Ratios-of-Eigenvectors (SCORE) (Jin, 2015) allowing for weighted networks and <lb/>hierarchical structure of submodules; (ii) spectral clustering. <lb/>R <lb/>K5 (i) SCORE (Jin, 2015); (ii) spectral clustering. <lb/>-<lb/>K6 (i) Diffusion kernel is applied to graph Laplacian (Kondor and Lafferty, 2002); (ii) Weighted Gene Coexpression Network <lb/>Analysis (WGCNA) (Langfelder and Horvath, 2008). <lb/>M <lb/>Modularity optimization: search algorithms are employed to find modules that maximize a modularity quality function. <lb/>M1 Modularity optimization algorithms are extended with a multiresolution technique (Arenas et al., 2008). <lb/>S, R <lb/>M2 Louvain community detection algorithm (Blondel et al., 2008). <lb/>S,W,R,M <lb/>M3 Extension of a multi-network module identification method (Didier et al., 2015), here applied to single-layer networks. <lb/>R <lb/>M4 PageRank algorithm is used to create an initial partition for the Louvain method. <lb/>W, R <lb/>M5 A hierarchical module tree is generated using the Louvain method, optimal partitions are selected using modularity, <lb/>conductance and connectivity metrics. <lb/>W,R,M,F <lb/>M6 Greedy agglomerative clustering approach optimizes a score based on total weight of intra-module edges and module size. <lb/>S,W, M <lb/>M7 Fast greedy clustering algorithm (Clauset et al., 2008) that iteratively divides modules to optimize the modularity. <lb/>-<lb/>M8 Modularity optimization by Conformational Space Annealing (Mod-CSA) (Lee et al., 2012) using the weighted adjacency matrix. <lb/>S, R <lb/>M9 Louvain algorithm is used for optimization of a generalized modularity metric with a resolution parameter. <lb/>R <lb/>M10 Louvain algorithm. <lb/>R <lb/>Random-walk-based: modules are identified using diffusion processes over the network. <lb/>R1 Multi-level Markov clustering is extended with a regularization matrix to balance module sizes (Satuluri et al., 2010). <lb/>S, W, R <lb/>R2 Walktrap algorithm (Pons and Latapy, 2005), output modules are filtered based on the median node degree. <lb/>S, R <lb/>R3 Walktrap algorithm. <lb/>S, R <lb/>R4 A machine learning approach for predicting disease genes from graph features is combined with the Infomap algorithm (Rosvall <lb/>et al., 2009) for community detection. <lb/>S,R,F <lb/>R5 Walktrap algorithm with varying number of steps. <lb/>S, F, M <lb/>R6 Infomap algorithm, Markov-time parameter is optimized to yield maximum number of modules of valid size. <lb/>R,M <lb/>R7 Markov clustering, output modules are filtered based on conductance and module size. <lb/>S, w <lb/>R8 Recursive local graph sparsification and clustering using Infomap for scalable community detection. <lb/>S, R <lb/>R9 Walktrap is used for the first network, Infomap for the remaining networks. <lb/>R <lb/>R10 Modules detected using Walktrap and Infomap are combined. <lb/>S <lb/>Local methods: agglomerative algorithms that grow modules from seed nodes. <lb/>L1 <lb/>Topological overlap matrix is clustered using the fast agglomerative SPICi (Jiang and Singh, 2010) and SCAN++ algorithms <lb/>(Shiokawa et al., 2015). <lb/>S, W,R <lb/>L2 <lb/>Basic agglomerative approach assigning genes to connected modules until the module size limit is reached. <lb/>W,R,M <lb/>L3 <lb/>Local method that grows modules from seed nodes using a novel Triangle based Community Expansion (TCE) method. <lb/>M <lb/>Ensemble clustering: alternative clusterings sampled either from stochastic runs or from a set of different methods are merged. <lb/>E1 Various clustering methods are applied on network embeddings created using DeepWalk (Perozzi et al., 2014), consensus <lb/>modules are obtained using a bagging method. <lb/>S,W,M <lb/>E2 Consensus modules are derived from two flat clustering algorithms: ClusterOne and Finding Low-Conductance set with Dense <lb/>interactions (FLCD) (Wang and Qian, 2017). <lb/>S,W,F <lb/>E3 Ensemble approach applied to integrate multiple Markov clustering runs. <lb/>S,R <lb/>Hybrid methods: different clustering methods are selected for each network based on leaderboard performance or structural quality scores. <lb/>H1 Either Louvain, Infomap, or a continuous optimization method (Li et al., 2016) are selected for each network. <lb/>R, F <lb/>H2 Either Louvain, Infomap, SPICi, or DCut (Shao et al., 2016) are selected for each network. <lb/>W,R <lb/>H3 Up to five different methods are applied to cluster networks, followed by filtering of modules based on structural quality metrics. <lb/>W,R, M, F <lb/>H4 Up to nine different methods are applied in different combinations, followed by module filtering and post-processing steps. <lb/>H5 Up to seven different methods are applied including an ensemble approach, followed by filtering and post-processing steps. <lb/>S,W,R,M,F <lb/>H6 WGCNA followed by fast greedy community detection to refine modules. <lb/>R <lb/>H7 No detailed description provided. <lb/>-<lb/>Others <lb/>O1 Agglomerative algorithm that joins clusters based on the number of shared neighbors and the cluster sizes. <lb/>W,F <lb/>O2 Two-way modules (dense bipartite subgraphs) are mined using a heuristic algorithm. <lb/>W,F <lb/>O3 No detailed description provided. <lb/>-<lb/></body>

			<note place="footnote">(legend on next page) <lb/></note>

			<page>25 <lb/></page>

			<body>Table 1. The 42 module identification methods applied in Sub-challenge 1 grouped by category (see Fig. 2A). <lb/>a Identifier (ID) of the method used throughout the paper. <lb/>b Overall score of the method as defined in Fig. 2B. <lb/>c Common pre-and post-processing steps. Pre-processing steps are coded as: (S) sparsification of networks and (W) <lb/>rescaling of edge weights. Post-processing steps are coded as: (R) recursive break-down of large modules, (M) <lb/>merging modules of invalid size followed by re-modularization, and (F) filtering modules according to a quality metric. <lb/></body>

			<page>26 <lb/></page>

			<body>Figure 1 <lb/>Figure 1: The Disease Module Identification DREAM Challenge. <lb/>We launched an open-participation community challenge, where teams competed to predict groups of functionally <lb/>related genes (i.e., modules) within diverse molecular networks. <lb/>(A) The challenge comprised six networks, including protein-protein interaction, signaling, co-expression, cancer <lb/>dependency, and homology-based gene networks. As the networks were all unpublished, we could anonymize them <lb/>by removing the gene labels. This prevented participants from using existing knowledge of gene functions, thus <lb/>enabling rigorous, blinded assessment. <lb/>(B) The aim of the challenge was to identify disease-relevant modules within the provided networks. Teams could <lb/>participate in either or both sub-challenges: 42 teams predicted modules for individual networks (Sub-challenge 1) and <lb/>33 teams predicted integrated modules across multiple networks (Sub-challenge 2). <lb/>(C) The submitted modules were tested for association with complex traits and diseases using a comprehensive <lb/>collection of 180 GWAS datasets. The final score for each method was the number of trait-associated modules that it <lb/>discovered. Since GWAS are based on data completely different from those used to construct the networks, they can <lb/>provide independent support for biologically relevant modules. <lb/></body>

			<page>27 <lb/></page>

			<body>Figure 2 <lb/>Figure 2: Assessment of module identification methods. <lb/>(A) Main types of module identification approaches used in the challenge: kernel clustering methods transform and <lb/>cluster the network adjacency matrix; modularity optimization methods rely on search algorithms to find modular <lb/>decompositions that maximize a structural quality metric; random-walk-based methods take inspiration from diffusion <lb/>processes over the network; local methods use agglomerative processes to grow modules from seed nodes; and <lb/>ensemble methods merge alternative clusterings sampled either from stochastic runs of a given method or from a set <lb/>of different methods. In addition, hybrid methods employ more than one of the above approaches and then pick the <lb/>best modules according to a quality metric. See also Table 1. <lb/>(B) Final scores of the 42 module identification methods applied in Sub-challenge 1 for each of the six networks, as <lb/>well as the overall score summarizing performance across networks (same method identifiers as in Table 1). Scores <lb/>correspond to the number of unique trait-associated modules identified by a given method in a network (evaluated <lb/>using the hold-out GWAS set at 5% FDR, see Methods). Ranks are indicated for the top ten methods. The last two <lb/>rows show the performance of consensus predictions derived from the challenge submissions and randomly <lb/>generated modules, respectively. <lb/>(C) Robustness of the overall ranking was evaluated by subsampling the GWAS set used for evaluation 1,000 times. <lb/>For each method, the resulting distribution of ranks is shown as a boxplot. The rankings of method K1 are substantially <lb/>better than those of the remaining teams (Bayes factor &lt; 3, see Methods). <lb/>(D) Number of trait-associated modules per network. Boxplots show the number of trait-associated modules across <lb/>methods, normalized by the size of the respective network. See also Fig. S1B. <lb/></body>

			<page>28 <lb/></page>

			<body>Figure 3 <lb/>Figure 3: Complementarity of module predictions from different methods and networks. <lb/>(A) Similarity of module predictions from different methods (color) and networks (shape). The closer two points are in <lb/>the plot, the more similar are the corresponding module predictions (multidimensional scaling, see Methods). Top <lb/>performing methods tend to be located far from the origin (the top three methods are highlighted for each network). <lb/>Top methods do not cluster close together, suggesting dissimilar modular decompositions (see also Fig. S3A). <lb/>(B) Comparison of GWAS trait-associated modules identified by all challenge methods. Pie-charts show the <lb/>percentage of trait modules that show overlap with at least one trait module from a different method in the same <lb/>network (top) and in different networks (bottom). We distinguish between strong overlap, sub-modules, weak but <lb/>significant overlap, and insignificant overlap (Methods). <lb/>(C) Total number of predicted modules versus average module size for each method (same color scheme as in Panel <lb/>A). There is a roughly inverse relationship between module number and size because modules had to be non-<lb/>overlapping and did not have to cover all genes. The top five methods (highlighted) produced modular decompositions <lb/>of varying granularity. See also Figs. S3B-D. <lb/>(D) Challenge score (number of trait-associated modules) versus modularity is shown for each method (same color <lb/>scheme as in Panel A). Modularity is a topological quality metric for modules based on the fraction of within-module <lb/>edges (Newman and Girvan, 2004). While there is modest correlation between the two metrics (r=0.45), the methods <lb/>with the highest challenge score are not necessarily those with the highest modularity, presumably because the <lb/>intrinsic scale of modularity is not optimal for the task considered in the challenge. <lb/>(E) Final scores of multi-network module identification methods in Sub-challenge 2 (evaluated using the hold-out <lb/>GWAS set at 5% FDR, see Methods). For comparison, the overall best-performing method from Sub-challenge 1 is <lb/>also shown (method K1, purple). Teams used different combinations of the six challenge networks for their multi-<lb/>network predictions (shown on the left): the top-performing team relied exclusively on the two protein-protein <lb/>interaction networks. The difference between the top single-network module predictions and the top multi-network <lb/>module predictions is not significant when sub-sampling the GWASs (Fig. S1D). The last two rows show the <lb/>performance of multi-network consensus predictions (obtained by integrating single-network submissions from Sub-<lb/>challenge 1 across networks) and randomly generated module predictions, respectively. <lb/></body>

			<page>29 <lb/></page>

			<body>Figure 4 <lb/>Fig. 4: Overlap between modules associated with different traits and diseases. <lb/>(A) Average number of trait-associated modules identified by challenge methods for each trait. For traits where <lb/>multiple GWASs were available, results for the best-powered study are shown. <lb/>(B) Histograms showing the number of distinct traits per trait-associated module (brown) and gene (grey). 72% of trait-<lb/>associated modules are specific to a single trait, while the remaining 28% are hits for multiple traits. In contrast, only <lb/>54% of trait-associated genes are specific to a single trait. <lb/>(C) Trait network showing similarity between GWAS traits based on overlap of associated modules (force-directed <lb/>graph layout). Node size corresponds to the number of genes in trait-associated modules and edge width corresponds <lb/>to the degree of overlap (Jaccard index; only edges for which the overlap is significant are shown, see Methods). <lb/>Traits without any edges are not shown. Traits of the same type (color) tend to cluster together, indicating shared <lb/>pathways. <lb/></body>

			<page>30 <lb/></page>

			<body>Figure 5 <lb/>Figure 5: Support of trait-module genes in diverse datasets. <lb/>(A) Example module of the consensus method in the STRING protein interaction network (force-directed graph layout). <lb/>The module shows modest association to height (q-value = 0.04) in the GWAS by Randall et al. (2013) (lower-<lb/>powered than the GWAS shown in Panel B). Color indicates GWAS gene scores. The signal is driven by three genes <lb/>from different loci with significant scores (pink), while the remaining genes (grey) are predicted to be involved in height <lb/>because of their module membership. <lb/>(B) The module from Panel A is supported in the higher-powered GWAS (Wood et al., 2014) (q-value = 0.005). 45% <lb/>of candidate trait genes (grey in Panel A) are confirmed (pink). In addition, 28% of module genes have coding variants <lb/>associated to height in an independent ExomeChip study published after the challenge (Marouli et al., 2017) (black <lb/>squares, enrichment p-value = 1.9E-6). See also Fig. S4B. <lb/>(C) Support of candidate trait genes across eight different traits for which lower-and higher-powered GWASs are <lb/>available in our hold-out set. The lower-powered GWASs were used to predict candidate trait genes, i.e., genes within <lb/>trait modules that do not show any signal (GWAS gene score &lt;4) and that are located far away (&gt;1mb) from any <lb/>significant GWAS locus (cf. grey genes in Panel A). The plot shows the cumulative distribution of gene scores in the <lb/>higher-powered GWASs for candidate trait genes (red line) and all other genes (grey line, see Methods). <lb/>(D) Functional annotation of genes in the height-associated module from Panel A. Genes implicated in monogenic <lb/>skeletal growth disorders are highlighted (red squares, enrichment p-value = 7.5E-4). See also Table S2. <lb/></body>

			<page>31 <lb/></page>

			<body>Figure 6 <lb/>Figure 6: Example trait modules comprising therapeutically relevant pathways. <lb/>(A, B and C) Three trait-associated modules in the STRING protein interaction network identified using the consensus <lb/>method (similar results were obtained for other modules and traits, Tables S3, S4). Node colors correspond to gene <lb/>scores in the respective GWAS. For the two inflammatory disorders (A and B), red squares indicate genes causing <lb/>monogenic immunodeficiency disorders (enrichment p-values of 4.1E-8 and 1.2E-6, respectively). <lb/>(A) Module associated with rheumatoid arthritis (q-value = 0.04) involved in T cell activation. A costimulatory pathway <lb/>is highlighted green: T cell response is regulated by activating (CD28) and inhibitory (CTLA4) surface receptors, which <lb/>bind B7 family ligands (CD80 and CD86) expressed on the surface of activated antigen-presenting cells. The <lb/>therapeutic agent CTLA4-Ig binds and blocks B7 ligands, thus inhibiting T cell response. <lb/>(B) A cytokine signalling module associated with inflammatory bowel disease (q-value = 0.0006). The module includes <lb/>the four known Janus kinases (JAK1-3 and TYK2, highlighted green), which are engaged by cytokine receptors to <lb/>mediate activation of specific transcription factors (STATs). Inhibitors of JAK-STAT signaling are being tested in <lb/>clinical trials for both ulcerative colitis and Crohn&apos;s disease (Neurath, 2017). <lb/>(C) Module associated with myocardial infarction (q-value = 0.0001). The module includes two main components of <lb/>the NO/cGMP signaling pathway (highlighted green): endothelial nitric oxide synthases (NOS1-3), which produce the <lb/>gas nitric oxide (NO) used as signal transmitter, and soluble guanylate cyclases (GUCY1A2, GUCY1A3 and <lb/>GUCY1B3), which sense NO leading to formation of cGMP. The cGMP signal inhibits platelet aggregation and leads <lb/>to vascular smooth muscle cell relaxation; it is a therapeutic target for cardiovascular disease as well as erectile <lb/>dysfunction (Kraehling and Sessa, 2017). <lb/>(legend continued on next page) <lb/></body>

			<page>32 <lb/></page>

			<body>(D) Module associated to IgA nephropathy (IgAN; q-value = 0.04). The module was identified using the best-<lb/>performing method (K1) in the InWeb protein interaction network. Besides finding complement factors that are known <lb/>to play a role in the disease (CFB and C4A), the module implicates novel candidate genes such as the chemokine <lb/>Platelet Factor 4 Variant 1 (PF4V1) from a sub-threshold locus, and is enriched for coagulation cascade, a process <lb/>known to be involved in kidney disease (Madhusudhan et al., 2016) (see also Fig. S5). <lb/></body>

			<page>33 <lb/></page>

			<body>Methods <lb/>Network compendium <lb/>A collection of six gene and protein networks for human were provided by different groups for <lb/>this challenge. The two protein-protein interaction and signaling networks are custom or new <lb/>versions of existing interaction databases that were not publicly available at the time of the <lb/>challenge. The remaining networks were yet unpublished at the time of the challenge. This was <lb/>important to prevent participants from deanonymizing challenge networks by aligning them to <lb/>the original networks. The original networks, anonymized networks and the mappings from gene <lb/>symbols to anonymized IDs are available on the challenge website. <lb/>Networks were released for the challenge in anonymized form. Anonymization consisted in <lb/>replacing the gene symbols with randomly assigned ID numbers. In Sub-challenge 1 each <lb/>network was anonymized individually, i.e., node k of network A and node k of network B are <lb/>generally not the same genes. In Sub-challenge 2 all networks were anonymized using the <lb/>same mapping, i.e., node k of network A and node k of network B are the same gene. Since the <lb/>networks were unpublished, it was practically impossible for participants to infer the gene <lb/>identities. Participants also agreed not to attempt to infer gene identities as part of the challenge <lb/>rules. <lb/>All networks are undirected and weighted, except for the signaling network, which is directed <lb/>and weighted. Basic properties and similarity between the networks are shown in Figs. 1A and <lb/>S2E. Below we briefly summarize each of the six networks. Detailed descriptions of networks 4, <lb/>5 and 6 are available on GeNets, a web platform for network-based analysis of genetic data <lb/>(http://apps.broadinstitute.org/genets). <lb/>Network 1: STRING protein-protein interaction network <lb/>The first network was obtained from STRING, a database of known and predicted protein-<lb/>protein interactions (Szklarczyk et al., 2015). STRING includes aggregated interactions from <lb/>primary databases as well as computationally predicted associations. Both physical protein <lb/>interactions (direct) and functional associations (indirect) are included. The challenge network <lb/>corresponds to the human protein-protein interactions of STRING version 10.0, where <lb/>interactions derived from text-mining were removed. Edge weights correspond to the STRING <lb/>association score after removing evidence from text mining. The network was provided by <lb/>Damian Szklarczyk and Christian von Mering (University of Zürich). <lb/></body>

			<page>34 <lb/></page>

			<body>Network 2: InWeb protein-protein interaction network <lb/>The second network is the InWeb protein-protein interaction network (Li et al., 2017). InWeb <lb/>aggregates physical protein-protein interactions from primary databases and the literature. The <lb/>challenge network corresponds to InWeb version 3. Edge weights correspond to a confidence <lb/>score that integrates the evidence of the interaction from different sources. <lb/>Network 3: OmniPath signaling network <lb/>The third network is the OmniPath signaling network (Türei et al., 2016). OmniPath integrates <lb/>literature-curated human signaling pathways from 27 different sources, of which 20 provide <lb/>causal interaction, 7 deliver undirected interactions. These data were integrated to form a <lb/>directed weighted network. The edge weights correspond to a confidence score that <lb/>summarizes the strength of evidence from the different sources. <lb/>Network 4: GEO co-expression network <lb/>The fourth network is a co-expression network based on Affymetrix HG-U133 Plus 2 arrays <lb/>extracted from the Gene Expression Omnibus (GEO) (Barrett et al., 2011). In order to adjust for <lb/>non-biological variation, data were rescaled by fitting a loess-smoothed power law curve to a <lb/>collection of 80 reference genes (ten sets of ~8 genes each, representing different strata of <lb/>expression) using nonlinear least squares regression within each sample. All samples were then <lb/>quantile normalized together as a cohort. This approach is described fully in (Subramanian et <lb/>al., 2017). After filtering out samples that did not pass quality control, a gene expression matrix <lb/>of 22,268 probesets by 19,019 samples was obtained. Probes were mapped to genes by <lb/>averaging and the pairwise Spearman correlation of genes across samples was computed. The <lb/>matrix was thresholded to include the top 1M strongest positive correlations resulting in an <lb/>undirected, weighted network. The edge weights correspond to the correlation coefficients. <lb/>Network 5: Achilles cancer co-dependency network <lb/>The fifth network is a functional gene network derived from the Project Achilles dataset v2.4.3 <lb/>(Cowley et al., 2014). Project Achilles performed genome-scale loss-of-function screens in 216 <lb/>cancer cell lines using massively parallel pooled shRNA screens. Cell lines were infected with a <lb/>library of 54,000 shRNAs, each targeting one of 11,000 genes for RNAi knockdown (~5 shRNAs <lb/>per gene). The proliferation effect of each shRNA in a given cell line could be assessed using <lb/>Next Generation Sequencing. From these data, the dependency of a cell line on each gene (the <lb/></body>

			<page>35 <lb/></page>

			<body>gene essentiality) was estimated using the ATARiS method. This led to a gene essentiality <lb/>matrix of 11,000 genes by 216 cell lines. Pairwise correlations between genes were computed <lb/>and the resulting co-dependency network was thresholded to the top 1M strongest positive <lb/>correlations, analogous to how the co-expression network was constructed. Project Achilles <lb/>data was kindly provided by Aviad Tsherniak and Barbara Weir (Broad Institute). <lb/>Network 6: CLIME homology-based network <lb/>The sixth network is a functional gene network based on phylogenetic relationships identified <lb/>using the CLIME (clustering by inferred models of evolution) algorithm (Li et al., 2014). CLIME <lb/>can be used to expand pathways (gene sets) with additional genes using an evolutionary model. <lb/>Briefly, given a eukaryotic species tree and homology matrix, the input gene set is partitioned <lb/>into evolutionarily conserved modules (ECMs), which are then expanded with new genes <lb/>sharing the same evolutionary history. To this end, each gene is assigned a log-likelihood ratio <lb/>(LLR) score based on the ECMs inferred model of evolution. CLIME was applied to 1,025 <lb/>curated human gene sets from GO and KEGG using a 138 eukaryotic species tree, which <lb/>resulted in 13,307 expanded ECMs. The network was constructed by adding an edge between <lb/>every pair of genes that co-occurred in at least one ECM. Edge weights correspond to the mean <lb/>LLR scores of the two genes. <lb/>Challenge structure <lb/>Participants were challenged to apply network module identification methods to predict <lb/>functional modules (gene sets) based on network topology. Valid modules had to be non-<lb/>overlapping (a given gene could be part of either zero or one module, but not multiple modules) <lb/>and comprise between 3 and 100 genes. Modules did not have to cover all genes in a network. <lb/>The number of modules per network was not fixed: teams could submit any number of modules <lb/>for a given network (the maximum number was limited due to the fact that modules had to be <lb/>non-overlapping). In Sub-challenge 1, teams were required to submit a separate set of modules <lb/>for each of the six networks. In Sub-challenge 2, teams were required to submit a single set of <lb/>modules by integrating information across multiple networks (it was permitted to use only a <lb/>subset of the six networks). <lb/>The challenge consisted of a leaderboard phase and the final evaluation. The leaderboard <lb/>phase was organized in four rounds, where teams could make repeated submissions and see <lb/>their score on each network. Due to the high computational cost of scoring the module <lb/>predictions on a large number of GWAS datasets (see next section), a limit for the number of <lb/></body>

			<page>36 <lb/></page>

			<body>submissions per team was set in each round taking into consideration our computational <lb/>resources and the number of participating teams. The total number of submissions that any <lb/>given team could make over the four leaderboard rounds was thus limited to only 25 and 41 for <lb/>the two sub-challenges, respectively. For the final evaluation, a single submission including <lb/>method descriptions and code was required per team, which was scored on a separate set of <lb/>GWASs after the challenge closed to determine the top performers. <lb/>The submission format and rules are described in detail on the challenge website <lb/>(https://www.synapse.org/modulechallenge). <lb/>Challenge scoring <lb/>We have developed a novel framework to empirically assess module identification methods on <lb/>molecular networks using GWAS data. In contrast to functional gene annotations and pathway <lb/>databases such as GO, which sometimes originate from similar types of functional genomics <lb/>data as the network modules, GWAS data are orthogonal to the networks and thus provide an <lb/>independent means of validation. In order to cover diverse molecular processes, we compiled a <lb/>large collection of 180 GWAS datasets from public sources. The collection was split into two <lb/>sets of 76 and 104 GWASs used for the leaderboard phase and the final evaluation, <lb/>respectively (Table S1). <lb/>Gene and module scoring using Pascal <lb/>SNP-trait association p-values from a given GWAS were integrated across genes and modules <lb/>using the Pascal (pathway scoring algorithm) tool (Lamparter et al., 2016). Briefly, Pascal <lb/>combines analytical and numerical solutions to efficiently compute gene and module scores <lb/>from SNP p-values, while properly correcting for linkage disequilibrium (LD) correlation structure <lb/>prevalent in GWAS data. To this end, LD information from a reference population is used (here, <lb/>the European population of the 1000 Genomes Project was employed as we only included <lb/>GWASs with predominantly European cohorts). Compared to alternative gene scoring methods <lb/>that rely on Monte Carlo simulations, Pascal is about 100 times faster and more precise <lb/>(Lamparter et al., 2016). The fast gene scoring is critical as it allows module genes that are in <lb/>LD, and can thus not be treated independently, to be dynamically rescored. This amounts to <lb/>fusing the genes of a given module that are in LD and computing a new score that takes the full <lb/>LD structure of the corresponding locus into account. Finally, Pascal tests modules for <lb/>enrichment in high-scoring (potentially fused) genes using a modified Fisher method, which <lb/>avoids any p-value cutoffs inherent to standard binary enrichment tests. As background gene <lb/></body>

			<page>37 <lb/></page>

			<body>set, the genes of the given network were used. Lastly, the resulting nominal module p-values <lb/>were adjusted to control the FDR via the Benjamini-Hochberg procedure. A snapshot of the <lb/>Pascal version used for the challenge is available on the challenge website. <lb/>Scoring metric <lb/>In Sub-challenge 1, the score for a given network was defined as the number of modules with <lb/>significant Pascal p-values at a given FDR cutoff in at least one GWAS (called trait-associated <lb/>modules). Thus, modules that were hits for multiple GWAS traits were only counted once. The <lb/>overall score was defined as the sum of the scores obtained on the six networks (i.e., the total <lb/>number of trait-associated modules across all networks). For the official challenge ranking a 5% <lb/>FDR cutoff was defined, but performance was further reported at 10%, 2.5% and 1% FDR. <lb/>Module predictions in Sub-challenge 2 were scored using the exact same methodology and <lb/>FDR cutoffs. The only difference to Sub-challenge 1 was that submissions consisted of a single <lb/>set of modules (instead of one for each network) and there was thus no need to define an <lb/>overall score. As background gene set, the union of all genes across the six networks was used. <lb/>Robustness analysis of challenge ranking <lb/>To gain a sense of the robustness of the ranking with respect to the GWAS data, we <lb/>subsampled the set of 104 GWASs used for the final evaluation (called the &quot;test set&quot;) by <lb/>drawing 76 GWASs (same number of GWASs as in the leaderboard set; note that we have to <lb/>do subsampling rather than resampling of GWASs because the scoring counts the number of <lb/>modules that are associated to at least one GWAS, i.e., including the same GWASs multiple <lb/>times does not affect the score). We applied this approach to create 1,000 subsamples of the <lb/>test set. The methods were then scored on each subsample. <lb/>The performance of every method m was compared to the highest-scoring method across the <lb/>subsamples by the paired Bayes factor Km. That is, the method with the highest overall score in <lb/>the test set (all 104 GWASs) was defined as reference (i.e., method K1 in Sub-challenge 1). <lb/>The score S(m, k) of method m in subsample k was thus compared with the score S(ref, k) of <lb/>the reference method in the same subsample k. The Bayes factor Km is defined as the number <lb/>of times the reference method outperforms method m, divided by the number of times method m <lb/>outperforms or ties the reference method over all subsamples. Methods with Km &lt; 3 were <lb/>considered a tie with the reference method (i.e., method m outperforms the reference in more <lb/>than 1 out of 4 subsamples). <lb/></body>

			<page>38 <lb/></page>

			<body>Module identification methods <lb/>Here we provide an overview of module identification approaches applied in the two sub-<lb/>challenges, including a detailed description of the top-performing method. Full descriptions and <lb/>code of all methods are available on the challenge website <lb/>(https://www.synapse.org/modulechallenge). <lb/> Overview of module identification methods in Sub-challenge 1 <lb/>Based on descriptions provided by participants, module identification methods were classified <lb/>into different categories (Fig. 2A). Categories and corresponding module identification methods <lb/>are summarized in Table 1. In the following, we first give an overview of the different categories <lb/>and top-performing methods, and then describe common pre-and post-processing steps used <lb/>by these methods: <lb/>• Kernel clustering. Instead of working directly on the networks themselves, these <lb/>methods cluster a kernel matrix, where each entry (i, j) of that matrix represents the <lb/>closeness of nodes i and j in the network according to the particular similarity function, or <lb/>kernel that was applied. Some of the kernels that were applied are well-known for <lb/>community detection, such as the exponential diffusion kernel based on the graph <lb/>Laplacian (Kondor and Lafferty, 2002) employed by method K6. Others, such as the <lb/>LINE embedding algorithm (Tang et al., 2015) employed by method K3 and the kernel <lb/>based on the inverse of the weighted diffusion state distance (Cao et al., 2013, 2014) <lb/>employed by method K1, were more novel. Method K1 was the best-performing method <lb/>of the challenge and is described in detail below. <lb/>• Modularity optimization. This method category was, along with random-walk-based <lb/>methods (see below), the most popular type of method contributed by the community. <lb/>Modularity optimization methods use search algorithms to find a partition of the network <lb/>that maximizes the modularity Q (commonly defined as the fraction of within-module <lb/>edges minus the expected fraction of such edges in a random network with the same <lb/>node degrees) (Newman and Girvan, 2004). The most popular algorithm was Louvain <lb/>community detection (Blondel et al., 2008). At least eight teams employed this algorithm <lb/>in some form as either their main method or one of several methods. The top team of the <lb/>category (method M1), which ranked second overall, first sparsified networks by <lb/>removing low confidence edges. A mixture of several established community detection <lb/>algorithms was then employed in order to search for a partition that optimized <lb/></body>

			<page>39 <lb/></page>

			<body>modularity. Importantly, these algorithms were extended with an additional resistance <lb/>parameter that penalized merging of communities (Arenas et al., 2008); increasing the <lb/>resistance parameter thus led to partitions with a larger number of communities. <lb/>Communities above the size limit (100 nodes) were subdivided recursively by reapplying <lb/>the same community detection algorithms to the corresponding subnetworks (see <lb/>below). <lb/>• Random-walk-based methods. These methods take inspiration from random walks or <lb/>diffusion processes over the network. Several teams used the established Walktrap <lb/>(Pons and Latapy, 2005) and Infomap (Rosvall et al., 2009) algorithms. The top team of <lb/>this category (method R1) used a sophisticated random-walk method based on multi-<lb/>level Markov clustering (Satuluri et al., 2010). The method modifies basic Markov <lb/>Clustering in two ways. First, a hierarchical view of the graph is considered by <lb/>successively coarsening neighborhoods into fewer supernodes. The clustering is first run <lb/>on the coarsened graph, enabling the detection of communities at varying scales. <lb/>Second, a balance parameter is introduced that adjusts for nodes to preferentially join <lb/>smaller communities, thus leading to more balanced community sizes. Similar to method <lb/>M1 described above, networks were first sparsified and communities above the size limit <lb/>were recursively subdivided. While we did not include kernel methods in the &quot;random <lb/>walk&quot; category, several of the successful kernel clustering methods used random-walk-<lb/>based measures within their kernel functions. <lb/>• Local methods. Only three teams used local community detection methods, including <lb/>agglomerative clustering and seed set expansion approaches. The top team of this <lb/>category (method L1) first converted the adjacency matrix into a topology overlap matrix <lb/>(Ravasz et al., 2002), which measures the similarity of nodes by their topological overlap <lb/>based on the number of neighbor they have in common. The team then used the SPICi <lb/>algorithm (Jiang and Singh, 2010), which iteratively adds adjacent genes to cluster <lb/>seeds such as to improve their local density. <lb/>• Hybrid methods. Seven teams employed hybrid methods that leveraged clusterings <lb/>produced by several of the different main approaches listed above. These teams applied <lb/>more than one community detection method to each network in order to get larger and <lb/>more diverse sets of predicted modules. The most common methods applied were <lb/>Louvain (Blondel et al., 2008) hierarchical clustering, and Infomap (Rosvall et al., 2009). <lb/>Two different strategies were used to select a final set of modules for submission: (1) <lb/>choose a single method for each network according to performance in the leaderboard <lb/></body>

			<page>40 <lb/></page>

			<body>round, and (2) select modules from all applied methods according to a topological quality <lb/>score such as the modularity or conductance (Fortunato and Hric, 2016). <lb/>• Ensemble methods. Much like hybrid methods, ensemble methods leverage clusterings <lb/>obtained from multiple community detection methods (or multiple stochastic runs of a <lb/>single method). However, instead of selecting individual modules according to a quality <lb/>score, ensemble methods merge alternative clusterings to obtain potentially more robust <lb/>consensus predictions (Lancichinetti and Fortunato, 2012). Our method to derive <lb/>consensus module predictions from team submissions is an example of an ensemble <lb/>approach (described in detail below). <lb/>Besides the choice of the community detection algorithm, there are other steps that critically <lb/>affected performance, including pre-processing of the network data, setting of method <lb/>parameters, and post-processing of predicted modules. We describe successful approaches <lb/>employed by challenge participants to address these issues below (pre-and post-processing <lb/>steps of challenge methods are also summarized in Table 1): <lb/>• Pre-processing. Data pre-processing often plays a key role in the analysis of noisy <lb/>data, such as biological network data. Most networks in the challenge were densely <lb/>connected, including many edges of low weight that are likely noisy. Some of the top <lb/>teams (e.g., M1, R1, L1) benefitted from sparsifying these networks by discarding weak <lb/>edges before applying their community detection methods. An added benefit of <lb/>sparsification is that it typically reduces computation time. Few teams also normalized <lb/>the edge weights of a given network to make them either normally distributed or fall in <lb/>the range between zero and one. Not all methods required pre-processing of networks, <lb/>for example the top performing method (K1) was applied to the original networks without <lb/>any sparsification or normalization steps. <lb/>• Parameter setting. Most community detection methods have parameters that need to <lb/>be specified, typically to control the resolution of the clustering (the number and size of <lb/>modules). While some methods have parameters that explicitly set the number of <lb/>modules (e.g., the top-performing method K1), other methods have parameters that <lb/>indirectly control the resolution (e.g., the resistance parameter of the runner-up method <lb/>M1). Teams used the leaderboard phase to optimize the parameters of their method. <lb/>Note that teams could make at most 25 submissions during the leaderboard phase, <lb/>which limited the parameter space that could be explored in particular for methods with <lb/>multiple parameters. While there were also methods that had no parameters to set (e.g., <lb/></body>

			<page>41 <lb/></page>

			<body>the classic Louvain algorithm), these methods have an intrinsic resolution that may not <lb/>always be optimal for a given network and target application. <lb/>• Post-processing. Depending on the target application, the output of community <lb/>detection methods may need to be post-processed. In biological networks, most <lb/>methods typically lead to highly imbalanced module sizes. That is, some modules may <lb/>be very small (e.g., just one or two genes), while others are extremely large (e.g., <lb/>thousands of genes). Both extremes are generally not useful to gain biological insights at <lb/>the pathway level. In the challenge, module sizes were thus required to be between 3 <lb/>and 100 genes. Since current community detection methods generally do not allow such <lb/>constraints on module size to be specified, teams used different post-processing steps <lb/>to deal with modules outside of this range. A successful strategy employed by teams to <lb/>break down large modules was to recursively apply their method to each of these <lb/>modules. Alternatively, all modules of invalid size were merged and the community <lb/>detection method was re-applied to the corresponding subnetwork. Finally, modules with <lb/>less than three genes were often discarded (i.e., the corresponding genes were not <lb/>included in any of the submitted modules). Some teams also discarded larger modules <lb/>that were deemed low quality according to a topological metric, although this strategy <lb/>was generally not beneficial. <lb/>Top-performing team method <lb/>The top-performing team developed a kernel clustering approach (method K1) based on a <lb/>distance measure called Diffusion State Distance (DSD) (Cao et al., 2013, 2014), which they <lb/>further improved for this challenge (Crawford et al., in preparation). DSD produces a more <lb/>informative notion of proximity than the typical shortest path metric, which measures distance <lb/>between pairs of nodes by the number of hops on the shortest path that joins them in the <lb/>network. More formally, consider the undirected network 𝐺(𝑉, 𝐸) on the node set 𝑉 = <lb/>{𝑣 1 , 𝑣 2 , 𝑣 3 , . . . , 𝑣 𝑛 } with |𝑉| = 𝑛. 𝐻𝑒 𝑡 (𝑣 𝑥 , 𝑣 𝑦 ) is defined as the expected number of times that a <lb/>random walk (visiting neighboring nodes in proportion to their edge weights) starting at node 𝑣 𝑥 <lb/>and proceeding for some fixed t steps will visit node 𝑣 𝑦 (the walk includes the starting point, i.e., <lb/>0th step). Taking a global view, we define the n-dimensional vector 𝐻𝑒 𝑡 (𝑣 𝑥 ) whose 𝑖th entry is <lb/>the 𝐻𝑒 𝑡 (𝑣 𝑥 , 𝑣 𝑖 ) value to network node 𝑣 𝑖 . Then the 𝐷𝑆𝐷 𝑡 distance between two nodes 𝑣 𝑥 and 𝑣 𝑦 <lb/>is defined as the 𝐿1 norm of the difference of their 𝐻𝑒 𝑡 vectors, i.e. <lb/>𝐷𝑆𝐷 𝑡 (𝑣 𝑥 , 𝑣 𝑦 ) = ||𝐻𝑒 𝑡 (𝑣 𝑥 ) − 𝐻𝑒 𝑡 (𝑣 𝑦 )|| 1 . <lb/></body>

			<page>42 <lb/></page>

			<body>It can be shown that DSD is a metric and converges as 𝑡 → ∞, allowing DSD to be defined <lb/>independently from the value t (Cao et al., 2013). The converged DSD matrix can be computed <lb/>tractably, with an eigenvalue computation, as <lb/>𝐷𝑆𝐷(𝑣 𝑥 , 𝑣 𝑦 ) = ||(1 𝑥 − 1 𝑦 )(𝐼 − 𝐷 −1 𝐴 + 𝑊) −1 || 1 , <lb/>where 𝐷 is the diagonal degree matrix, 𝐴 is the adjacency matrix, and 𝑊 is the matrix where <lb/>each row is a copy of 𝜋, the degrees of each of the nodes, normalized by the sum of all the <lb/>vertex degrees (in the unweighted case; weighted edges can be normalized proportional to their <lb/>weight), and 1x and 1y are the vectors that are zero everywhere except at position x and y, <lb/>respectively. The converged DSD matrix was approximated using algebraic multigrid techniques <lb/>(Crawford et al., in preparation). Note that for the signaling network, edge directions were kept <lb/>and low-weight back edges were added so that the network was strongly connected; i.e. if there <lb/>was a directed edge from 𝑣 𝑥 to 𝑣 𝑦 , an edge from 𝑣 𝑦 to 𝑣 𝑥 of weight equal to 1/100 of the lowest <lb/>edge weight in the network was added. <lb/>A spectral clustering algorithm (Ng et al., 2001) was used to cluster the DSD matrix of a given <lb/>network. Note that the spectral clustering algorithm operates on a similarity matrix (i.e., entries <lb/>that are most alike have higher values in the matrix). However, the DSD matrix is a distance <lb/>matrix (i.e., similar entries have low DSD values). The radial basis function kernel presents a <lb/>standard way to convert the DSD matrix to a similarity matrix; it maps low distances to high <lb/>similarity scores and vice-versa. Since the spectral clustering algorithm employed uses k-means <lb/>as the underlying clustering mechanism, it takes a parameter k specifying the number of cluster <lb/>centers. The leaderboard rounds were utilized to measure the performance of different k. Also <lb/>note that spectral clustering produces clusters of size less than 3, and clusters of size more than <lb/>100. Whenever a cluster of size less than 3 was produced, those vertices were not included in <lb/>any cluster for that network. Whenever a cluster of size more than 100 was produced, spectral <lb/>clustering was called recursively to split that cluster into two subclusters (i.e., k=2) until all <lb/>clusters were of size &lt; 100. <lb/>The top-performing team also used a different algorithm to search for dense bipartite subgraph <lb/>module structure in half of the challenge networks. However, a post-facto analysis of their <lb/>results showed that this step contributed few modules and the score would have been similar <lb/>with this additional procedure omitted (Crawford et al., in preparation). <lb/></body>

			<page>43 <lb/></page>

			<body>Overview of module identification methods in Sub-challenge 2 <lb/>In Sub-challenge 2, few teams employed dedicated multi-network community detection methods <lb/>(De Domenico et al., 2015; Didier et al., 2015). The majority of teams first built an integrated <lb/>network by merging either all six or a subset of the challenge networks, and then applied single-<lb/>network methods (typically the same method as in Sub-challenge 1) to modularize the <lb/>integrated network. For example, the team with highest score in Sub-challenge 2 merged the <lb/>two protein interaction networks and then applied the Louvain algorithm to identify modules in <lb/>the integrated network. The top performing team from Sub-challenge 1 also performed <lb/>competitively in Sub-challenge 2. They applied their single-network method (K1) to an <lb/>integrated network consisting of the union of all edges from the two protein interaction networks <lb/>and the coexpression network. <lb/>Similar to Sub-challenge 1, teams used the leaderboard phase to set parameters of their <lb/>methods. However, besides the parameters of the community detection method, there were <lb/>additional choices to be made, whether to use all or only a subset of the six networks and how <lb/>to integrate them. <lb/>Consensus module predictions <lb/>We developed an ensemble approach to derive consensus modules from a given set of team <lb/>submissions (see Fig. S2A for a schematic overview). In Sub-challenge 1, a consensus matrix <lb/>C n was defined for each network n, where each element cij corresponds to the fraction of teams <lb/>that put gene i and j together in the same module in this network. That is, cij equals one if all <lb/>teams clustered gene i and j together, and cij equals zero if none of the teams clustered the two <lb/>genes together. The top-performing module identification method (K1) was used to cluster the <lb/>consensus matrix (i.e., the consensus matrix was considered a weighted adjacency matrix <lb/>defining a functional gene network, which was clustered using the top module identification <lb/>method of the challenge). Method K1 has only one parameter to set, which is the number of <lb/>cluster centers used by the spectral clustering algorithm (see previous section). This parameter <lb/>was set to the median number of modules submitted by the considered teams for the given <lb/>network. The consensus module predictions described in the main text were derived from the <lb/>submissions of the top 50% teams (i.e., 21 teams) with the highest overall score on the <lb/>leaderboard GWAS set. (Results for different cutoffs regarding the percentage of teams <lb/>included are reported in Fig. S2C.) <lb/></body>

			<page>44 <lb/></page>

			<body>Multi-network consensus modules were obtained by integrating team submissions from Sub-<lb/>challenge 1 across all six networks using the same approach (see Fig. S2B). The same set of <lb/>teams was considered (i.e., top 50% on the leaderboard GWAS set). First, a multi-network <lb/>consensus matrix was obtained by taking the mean of the six network-specific consensus <lb/>matrices C n . The multi-network consensus matrix was then clustered using method K1 as <lb/>described above, where the number of cluster centers was set to the median number of <lb/>modules submitted by the considered teams across all networks. <lb/>Two additional, more sophisticated approaches to construct consensus matrices C n were tested: <lb/>(1) normalization of the contribution of each module by the module size led to similar results as <lb/>the basic approach described above, and (2) unsupervised estimation of module prediction <lb/>accuracy using the Spectral Meta Learner ensemble method (Parisi et al., 2014) did not perform <lb/>well in this context (Fig. S2D). <lb/>Similarity of module predictions <lb/>To define a similarity metric between module predictions from different methods, we <lb/>represented module predictions as vectors. Namely, the set of modules predicted by method 𝑚 <lb/>in network 𝑘 was represented as a prediction vector 𝑃 𝑚𝑘 of length 𝑁 𝑘 (𝑁 𝑘 − 1)/2, where 𝑁 𝑘 is the <lb/>number of genes in the network. Each element of this vector corresponds to a pair of genes and <lb/>equals 1 if the two genes are in the same module and 0 otherwise. Accordingly, for any two <lb/>module predictions (method 𝑚 1 applied to network 𝑘 1 , and method 𝑚 2 applied to network 𝑘 2 ), <lb/>we calculated the distance as follows: <lb/>𝐷(𝑚 1 𝑘 1 , 𝑚 2 𝑘 2 ) = 1 − <lb/>&lt;𝑃 𝑚 1 𝑘 1 ,𝑃 𝑚 2 𝑘 2 &gt; <lb/>||𝑃 𝑚 1 𝑘 1 || 2 ||𝑃 𝑚 2 𝑘 2 || 2 <lb/>, <lb/>(1) <lb/>where &lt;. , . &gt; is the Euclidean inner product, ||. || 2 is the Euclidean norm, and 𝐷is the (symmetric) <lb/>distance matrix between the 252 module predictions submitted in Sub-challenge 1 (i.e., 42 <lb/>methods applied to each of six networks). The distance matrix 𝐷was used as input to the <lb/>Multidimensional Scaling (MDS) analysis for dimensionality reduction in Fig. 3A. <lb/>Similarity between method predictions across networks was calculated in the same way. To this <lb/>end, the prediction vectors 𝑃 𝑚𝑘 of method 𝑚 for the six networks (𝑘 = 1,2, . . . ,6) were <lb/>concatenated, forming a single vector 𝑃 𝑚 that represents the module predictions of that method <lb/>for all six networks. A corresponding distance matrix between the 42 methods was computed <lb/></body>

			<page>45 <lb/></page>

			<body>using the same approach as described above (Equation 1) and used as input for hierarchical <lb/>clustering in Fig. S3A. <lb/>Overlap between trait-associated modules <lb/>Three different metrics were considered to quantify the overlap between trait-associated <lb/>modules from different methods and networks. The first metric was the Jaccard index, which is <lb/>defined as the size of the intersection divided by the size of the union of two modules (gene <lb/>sets) 𝐴 and 𝐵: <lb/>𝐽(𝐴, 𝐵) = <lb/>|𝐴∩𝐵| <lb/>|𝐴∪𝐵| . <lb/>The Jaccard index measures how similar two modules are, but does allow the detection of sub-<lb/>modules. For example, consider a module 𝐴 of size 10 that is a submodule of a module 𝐵 of <lb/>size 100. In this case, even though 100% of genes of the first module are comprised in the <lb/>second module, the Jaccard index is rather low (0.1). To capture sub-modules, we thus <lb/>considered in addition the percentage of genes of the first module that are comprised in the <lb/>second module: <lb/>𝑆(𝐴, 𝐵) = <lb/>|𝐴∩𝐵| <lb/>|𝐴| . <lb/>Lastly, we also evaluated the significance of the overlap. To this end, we computed the p-value <lb/>𝑝 𝐴𝐵 for the overlap between the two modules using the hypergeometric distribution. P-values <lb/>were adjusted using Bonferroni correction given the number of module pairs tested. <lb/>Based on these three metrics, we categorized the type of overlap that a given trait-module 𝐴 <lb/>had with another trait-module 𝐵 as: <lb/>(1) strong overlap if 𝐽(𝐴, 𝐵) ≥ 0.5 and 𝑝 𝐴𝐵 &lt; 0.05; <lb/>(2) submodule if 𝐽(𝐴, 𝐵) &lt; 0.5 and 𝑆(𝐴, 𝐵) − 𝐽(𝐴, 𝐵) ≥ 0.5 and 𝑝 𝐴𝐵 &lt; 0.05; <lb/>(3) partial overlap if 𝐽(𝐴, 𝐵) &lt; 0.5 and 𝑆(𝐴, 𝐵) − 𝐽(𝐴, 𝐵) &lt; 0.5 and 𝑝 𝐴𝐵 &lt; 0.05; <lb/>(4) insignificant overlap if 𝑝 𝐴𝐵 ≥ 0.05. <lb/>This categorization was used to get a sense of the type of overlap between trait modules from <lb/>all methods (see Fig. 3B). <lb/>Trait similarity network <lb/>We defined a network level similarity between GWAS traits based on overlap between trait-<lb/>associated modules. To this end, we only considered the most relevant networks for our <lb/>collection of GWAS traits, i.e., the two protein interaction, the signaling and the co-expression <lb/>network (see Fig. 2D). For a given network, the set of &quot;trait-module genes&quot; 𝐺 𝑇 was obtained for <lb/></body>

			<page>46 <lb/></page>

			<body>every trait 𝑇by taking the union of the modules associated with that trait across all challenge <lb/>methods. (If different GWASs were available for the same trait type (see Table S1), the union of <lb/>all corresponding trait-associated modules was taken). The overlap between every pair of trait-<lb/>module gene sets 𝐺 𝑇 1 and 𝐺 𝑇 2 was evaluated using the Jaccard index 𝐽(𝐺 𝑇 1 , 𝐺 𝑇 2 ) and the <lb/>hypergeometric p-value 𝑝 𝑇 1 𝑇 2 as described in the previous section. P-values were adjusted using <lb/>Bonferroni correction. For the visualization as a trait-trait network in Fig. 4C, an edge between <lb/>traits 𝑇 1 and 𝑇 2 was added if the overlap was significant (𝑝 𝑇 1 𝑇 2 &lt; 0.05) in at least three out of the <lb/>four considered networks, and node sizes and edge weights were set proportional to the <lb/>average number of trait-module genes and the average Jaccard index across the four networks, <lb/>respectively. <lb/>Evaluation of candidate trait genes <lb/>Trait-associated modules comprise many genes that show only borderline or no signal in the <lb/>corresponding GWAS (called &quot;candidate trait genes&quot;). To assess whether modules correctly <lb/>prioritized candidate trait genes, we considered eight traits for which older (lower-powered) and <lb/>more recent (higher-powered) GWAS datasets were available in our test set (Fig. S4A). This <lb/>allowed us to evaluate how well trait-associated modules and candidate trait genes predicted <lb/>using the lower-powered GWAS datasets were supported in the higher-powered GWAS <lb/>datasets. <lb/>We only considered candidate trait genes that were predicted solely because of their <lb/>membership in a trait-associated module, i.e., that did not show any signal in the lower-powered <lb/>GWAS as defined by: (i) a high gene p-value (p &gt; 1E-4, i.e., two orders of magnitude above the <lb/>genome-wide significance threshold of 1E-6) and (ii) genomic location of more than one <lb/>megabase away from the nearest significant locus of the corresponding GWAS. Gene p-values <lb/>were computed using Pascal as described above (see &quot;Gene and module scoring using the <lb/>Pascal tool&quot;). Finally, the Pascal p-value of all candidate trait genes was evaluated for the <lb/>higher-powered GWAS. Since there is a genome-wide tendency for p-values to become more <lb/>significant in higher-powered GWAS data (Boyle et al., 2017), Pascal p-values were also <lb/>evaluated for a background gene set (all genes that meet the two conditions (i, ii) but do not <lb/>belong to trait-associated modules of the lower-powered GWAS). Fig. 5C shows the cumulative <lb/>distribution of Pascal p-values for the candidate trait genes as well as the background genes. <lb/></body>

			<page>47 <lb/></page>

			<body>Functional enrichment analysis <lb/>In order to test network modules for enrichment in known gene functions and pathways, we <lb/>considered diverse annotation and pathway databases. GO annotations for biological process, <lb/>cellular component, and molecular functions were downloaded from the GO website <lb/>(http://geneontology.org, accessed on January 20, 2017). Curated pathways (KEGG, <lb/>Reactome, and BioCarta) were obtained from MSigDB version 5.2 <lb/>(http://software.broadinstitute.org/gsea). We also created a collection of gene sets reflecting <lb/>mouse mutant phenotypes, as defined by the Mammalian Phenotype Ontology (Blake et al., <lb/>2017). We started with data files HMD_HumanPhenotype.rpt and MGI_GenePheno.rpt, <lb/>downloaded from the Mouse Genome Informatics database (http://www.informatics.jax.org) on <lb/>February 21, 2016. The first file contains human-mouse orthology data and some phenotypic <lb/>information; we then integrated more phenotypic data from the second file, removing the two <lb/>normal phenotypes MP:0002169 (&quot;no abnormal phenotype detected&quot;) and MP:0002873 <lb/>(&quot;normal phenotype&quot;). For each remaining phenotype, we then built a list of all genes having at <lb/>least one mutant strain exhibiting that phenotype, which we considered as a functional gene set. <lb/>Annotations from curated databases are known to be biased towards certain classes of genes. <lb/>For example, some genes have been much more heavily studied than others and thus tend to <lb/>have more annotations assigned to them. This and other biases lead to an uneven distribution <lb/>of the number of annotations per genes (annotation bias). On the other hand, the gene sets <lb/>(modules) tested for enrichment in these databases typically also exhibit bias for certain classes <lb/>of genes (selection bias) (Glass and Girvan, 2014; Young et al., 2010). Standard methods for <lb/>GO enrichment analysis use the hypergeometric distribution (i.e., Fisher&apos;s exact test), the <lb/>underlying assumption being that, under the null hypothesis, each gene is equally likely to be <lb/>included in the gene set (module). Due to selection bias, this is typically not the case in practice, <lb/>leading to inflation of p-values (Glass and Girvan, 2014; Young et al., 2010). Following Young et <lb/>al. (2010), we thus used the Wallenius non-central hypergeometric distribution to account for <lb/>biased sampling. Corresponding enrichment p-values were computed for all network modules <lb/>and annotation terms (pathways). The genes of the given network were used as a background <lb/>gene set. For each network, module identification method, and annotation database, the 𝑀 × 𝑇 <lb/>nominal p-values of the 𝑀 modules and 𝑇 annotation terms (pathways) were adjusted using <lb/>Bonferroni correction. <lb/></body>

			<page>48 <lb/></page>

			<div type="availability">Data and software availability <lb/>Challenge data, results, and code are available from the challenge website <lb/>(https://synapse.org/modulechallenge). This includes: <lb/>• Official challenge rules; <lb/>• Gene scores for the compendium of 180 GWASs used in the challenge plus 5 additional <lb/>GWASs obtained after the challenge (GWAS SNP p-values are available upon request); <lb/>• The molecular network collection (anonymized and deanonymized versions); <lb/>• Module identification method descriptions and code provided by teams; <lb/>• The final module predictions of all teams for both sub-challenges; <lb/>• Consensus module predictions for both sub-challenges; <lb/>• Method scores at varying FDR cutoffs; <lb/>• Individual module scores for all GWASs; <lb/>• Enriched functional annotations for all modules (GO, mouse mutant phenotypes, and <lb/>diverse pathway databases); <lb/>• A snapshot of the PASCAL tool and scoring scripts. <lb/>The latest version of PASCAL and the source code is also available from the PASCAL website <lb/>(https://www2.unil.ch/cbg/index.php?title=Pascal) and GitHub <lb/>(https://github.com/dlampart/Pascal). <lb/></div>

			<page>49 <lb/></page>

			<div type="annex">Supplementary Figures and Tables <lb/></div>

			<page>50 <lb/></page>

			<div type="annex">Figure S1 <lb/>Figure S1. Assessment of Module Identification Methods, Related to Figures 2 and 3. <lb/>(legend on next page) <lb/></div>

			<page>51 <lb/></page>

			<div type="annex">Figure S1. Assessment of Module Identification Methods, Related to Figures 2 and 3. <lb/>(A) Overall scores of the 42 module identification methods applied in Sub-challenge 1 at four different FDR cutoffs <lb/>(10%, 5%, 2.5%, and 1% FDR). For explanation see legend of Fig. 2B, which shows the scores at 5% FDR (the <lb/>predefined cutoff used for the challenge ranking). The top-performing method (K1) ranks first at all four cutoffs. The <lb/>consensus prediction achieves the top score at 10% and 5% FDR, but not at the more stringent cutoffs. <lb/>(B) Average number of trait-associated modules across all methods for each of the six networks. The most trait <lb/>modules are found in the two protein-protein interaction (PPI) and the co-expression networks. Related to Fig. 2D, <lb/>which shows the average number of trait modules relative to network size. <lb/>(C) Final scores of multi-network module identification methods in Sub-challenge 2 at four different FDR cutoffs (10%, <lb/>5%, 2.5%, and 1% FDR). For explanation see legend of Fig. 3E, which shows the scores at 5% FDR (the predefined <lb/>cutoff used for the challenge ranking). Ranks are indicated for the top five teams (ties are broken according to <lb/>robustness analysis described in Panel D). The multi-network consensus prediction (red) achieves the top score at <lb/>each FDR cutoff. <lb/>(D) Robustness of the overall ranking in Sub-challenge 2 was evaluated by subsampling the GWAS set used for <lb/>evaluation 1,000 times. For each method, the resulting distribution of ranks is shown as a boxplot (using the 5% FDR <lb/>cutoff for scoring). Related to Fig. 2C, which shows the same analysis for Sub-challenge 1. The difference between <lb/>the top single-network module prediction and the top multi-network module predictions is not significant when sub-<lb/>sampling the GWASs (Bayes factor &lt; 3). <lb/></div>

			<page>52 <lb/></page>

			<div type="annex">Figure S2 <lb/>Figure S2. Consensus Module Predictions, Related to Figures 2 and 3. <lb/>(A) Schematic of the approach used to generate single-network consensus module predictions for Sub-challenge 1. <lb/>For each network, module predictions from the top 50% of teams were integrated in a consensus matrix C, where <lb/>each element cij gives the fraction of teams that clustered gene i and j together in the same module in the given <lb/>network (performance as the percentage of considered teams is varied is shown in Panel C). The overall score from <lb/>the leaderboard round was used to select the top 50% of teams, i.e., the same set of teams was used for each <lb/>network. The consensus matrix of each network was then clustered using the top-performing module identification <lb/>method of the challenge (method K1; see Methods). <lb/>(B) The approach used to generate multi-network consensus module predictions for Sub-challenge 2 was exactly the <lb/>same as for single-network predictions, except that team submissions from all networks were integrated in the <lb/>consensus matrix C. In other words, as input we still used the single-network predictions of the top 50% of teams from <lb/>Sub-challenge 1, but instead of forming a consensus matrix for each network, a single cross-network consensus <lb/>matrix was formed. This cross-network consensus matrix is then clustered using method K1 as described above (see <lb/>Methods). <lb/>(C) Scores of the single-network consensus predictions as the percentage of integrated teams is varied. We <lb/>considered the top 25%, 50%, 75% and 100% of teams, as well as the top eight (19%) teams (these are the teams <lb/>that ranked 2nd, or tied with the team that ranked 2nd, at any of the considered FDR cutoffs). <lb/>(D) Performance of different methods to construct the consensus matrix C. In addition to the basic approach described <lb/>above (Standard), two more sophisticated approaches to construct the consensus matrix were evaluated (Normalized <lb/>and SML). In each case, the same set of team submissions were integrated (top 50%) and method K1 was applied to <lb/>cluster the resulting consensus matrix. <lb/>The first alternative (Normalized) is similar to the basic method but further assumes that appearing together in a <lb/>smaller cluster is stronger evidence that a pair of genes is associated than appearing together in a larger cluster. <lb/>(legend continued on next page) <lb/></div>

			<page>53 <lb/></page>

			<div type="annex">Thus, each cluster&apos;s contribution to the consensus matrix was normalized by the size of the cluster. Furthermore, we <lb/>normalized the ij-entry of the consensus matrix by the number of methods that assigned gene i to a cluster, thus taking <lb/>the presence of background genes into account. We found that the consensus still achieved the top score with these <lb/>normalizations, but there was no improvement compared to the basic approach. <lb/>The second method is a very different approach called Spectral Meta Learner (SML) (Parisi et al., 2014). SML is an <lb/>unsupervised ensemble method designed for two-class classification problems. Briefly, it takes a matrix of predictions, <lb/>𝑃, where each row corresponds to different samples being classified and the columns correspond to different <lb/>methods. Accordingly, each matrix element 𝑃 𝑖𝑗 is the class (0 or 1) assigned to sample 𝑖 by method 𝑗. Under the <lb/>assumption of conditional independence of methods given class labels, SML can estimate the balanced accuracy of <lb/>each classifier in a totally unsupervised manner using only the prediction matrix 𝑃. The algorithm then uses this <lb/>information to construct an ensemble classifier in which the contribution of each classifier is proportional to its <lb/>estimated performance (balanced accuracy). The module identification problem is an unsupervised problem by its <lb/>nature and we applied the SML algorithm as a new way for constructing consensus modules. For each method 𝑚 and <lb/>network 𝑘, we created a vector of prediction 𝑃 𝑚𝑘 , of size 𝑁 𝐺 𝑘 by 𝑁 𝐺 𝑘 , where 𝑁 𝐺 𝑘 is the number genes in network as <lb/>follows: <lb/>𝑃 𝑚𝑘 (𝑖, 𝑗) = 1, 𝑖𝑓 𝑚𝑒𝑡ℎ𝑜𝑑 𝑚 𝑝𝑢𝑡𝑠 𝑔𝑒𝑛𝑒𝑠 𝑖 𝑎𝑛𝑑 𝑗 𝑖𝑛 𝑡ℎ𝑒 𝑠𝑎𝑚𝑒 𝑚𝑜𝑑𝑢𝑙𝑒 (1) <lb/>𝑃 𝑚𝑘 (𝑖, 𝑗) = 0, 𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒. <lb/>For each network, we constructed the prediction matrix 𝑃with each column 𝑃 𝑚 defined as above. We then provided this <lb/>matrix as input to the SML algorithm. The SML algorithm outputs a consensus matrix, which assigns a weight between <lb/>each pair of genes. We found that SML did not perform well in the context of this challenge, likely because the <lb/>underlying assumption of SML is that top-performing methods converge to similar predictions, which was not the case <lb/>here (see Figs. 3 and S3). <lb/>(E) Pairwise similarity of networks. The upper triangle of the matrix shows the percent of shared links (the Jaccard <lb/>index multiplied by 100) and the lower triangle shows the fold-enrichment of shared links compared to the expected <lb/>number of shared links at random. The two protein-protein interaction networks are the two most similar networks with <lb/>8% of shared edges. <lb/></div>

			<page>54 <lb/></page>

			<div type="annex">Figure S3 <lb/></div>

			<page>55 <lb/></page>

			<div type="annex">Figure S3. Complementarity of Module Identification Methods, Related to Figure 3. <lb/>(legend on next page) <lb/>Figure S3. Complementarity of Module Identification Methods, Related to Figure 3. <lb/>All panels show results for single-network module identification methods (Sub-challenge 1). <lb/>(A) Pairwise similarity of module predictions from different methods, averaged over all networks. Similarity was <lb/>computed based on whether the same genes were clustered together by the two methods (see Methods). The <lb/>resulting similarity matrix was hierarchically clustered using Ward&apos;s method. The top row shows the method type. The <lb/>top five methods (1-5) and the consensus (C) are highlighted. The top methods did not converge to similar module <lb/>predictions (they are not all grouped together in the hierarchical clustering). Related to Fig. 3, which shows similarity of <lb/>module predictions from individual networks. <lb/>(B) Average module size versus score for each method. The x-axis shows the average module size of a given method <lb/>across the six networks. The y-axis shows the overall score of the method. Top teams (highlighted) produced modules <lb/>of varying size, i.e., they did not converge to a similar module size during the leaderboard round. Methods that <lb/>generated very small modules (average size &lt; 10) were not among the top performers. <lb/>(C) Comparison of module sizes between networks. For each network, the boxplot shows the distribution of average <lb/>module sizes of the 42 challenge methods. On average, modules were smallest in the signaling network and largest in <lb/>the co-expression network. <lb/>(D) Comparison of module sizes between method types. For each network, boxplots show the distribution of average <lb/>module sizes for kernel clustering, modularity optimization, random-walk-based, and hybrid methods (the remaining <lb/>categories are not shown because they comprise only three methods each). Note that teams tuned the resolution <lb/>(average module size) of their method during the leaderboard round. The variation in module size between different <lb/>method categories and networks suggests that the optimal resolution is method-and network-specific. For example, <lb/>teams using random-walk-based methods tended to choose a higher resolution (smaller average module size) than <lb/>teams using kernel clustering or modularity optimization methods. <lb/>(E) Number of distinct trait-associated modules recovered by the top K methods. Given the top K methods, we <lb/>considered the set including all modules predicted by these methods and scored them with the same pipeline as used <lb/>for the individual methods in the challenge. We then evaluated how many &quot;distinct&quot; trait-associated modules were <lb/>recovered by these methods. Distinct modules were defined as modules that do not show any significant overlap <lb/>among each other. Overlap between pairs of modules was evaluated using the hypergeometric distribution and called <lb/>significant at 5% FDR (Benjamini-Hochberg adjusted p-value &lt; 0.05). From the set of trait-associated modules <lb/>discovered by the top K methods, we thus derived the subset of distinct trait-associated modules (when several <lb/>modules overlapped significantly, only the module with the most significant GWAS p-value was retained). Although the <lb/>resulting scores (number of distinct trait-associated modules) cannot be directly compared with the challenge scores <lb/>(because module predictions had to be strictly non-overlapping in the challenge), it is instructive to see how many <lb/>distinct trait modules can be recovered when applying multiple methods. The stacked bars (colors) further show how <lb/>many of the distinct trait modules are contributed by each method category. The number of distinct trait modules is not <lb/>monotonically increasing as more methods are added because the larger sets of modules also increase the multiple <lb/>testing burden of the GWAS scoring. The top four methods together discover 78 distinct trait-associated modules. <lb/>Relatively little is gained by adding a higher number of methods. <lb/></div>

			<page>56 <lb/></page>

			<div type="annex">Figure S4 <lb/>Figure S4. Support of Trait Modules in Diverse Datasets, Related to Figures 5 and 6. <lb/>(A) Pairs of older (lower-powered) and more recent (higher-powered) GWASs used for the evaluation of module-based <lb/>gene prioritization in Fig. 5C. The first column gives the trait and the second and third columns indicate the <lb/>approximate cohort sizes of the respective GWASs. The bar plot shows the percentage of trait-associated modules <lb/>from the first GWAS that are also trait-associated modules in the second GWAS. At the bottom, the expected <lb/>percentage of confirmed modules at random is shown (i.e., assuming the trait-associated modules in the second <lb/>GWAS were randomly selected from the set of predicted modules). <lb/>(B) Enrichment of trait-associated modules in six curated gene sets from three recent studies. The first two gene sets <lb/>were taken from Marouli et al., (2017) and correspond to genes comprising height-associated ExomeChip variants and <lb/>genes known to be involved in skeletal growth disorders, respectively. The third gene set was taken from de Lange et <lb/>al., (2017) and corresponds to genes causing monogenic immunodeficiency disorders. Lastly, three gene sets relevant <lb/>for type 2 diabetes (T2D) were taken from Fuchsberger et al. (2016) and correspond to genes in literature-curated <lb/>pathways that are believed to be linked to T2D (we distinguished between genes in cytokine signalling pathways and <lb/>other pathways) and genes causing monogenic diabetes. We then considered corresponding GWAS traits in our hold-<lb/>out set, namely height, all immune-related disorders, and T2D. We then tested all modules associated with these <lb/>GWAS traits for enrichment in these six external gene sets. Enrichment was tested using the hypergeometric <lb/>distribution and p-values were adjusted to control FDR using the Benjamini-Hochberg method. The heatmap shows for <lb/>each GWAS (row) the fraction of trait-associated modules that significantly overlap with a given gene set (column). It <lb/>can be seen that modules associated with a given trait predominantly overlap the external gene sets that are expected <lb/>to be relevant for that trait. <lb/></div>

			<page>57 <lb/></page>

			<div type="annex">Figure S5 <lb/>Figure S5. Modules Associated with IgA Nephropathy, Related to Fig. 6D. <lb/>(legend on next page) <lb/></div>

			<page>58 <lb/></page>

			<div type="annex">Figure S5. Modules Associated with IgA Nephropathy, Related to Fig. 6D. <lb/>The top ten enriched GO biological processes, Reactome pathways and mouse mutant phenotypes are shown for two <lb/>IgA nephropathy (IgAN) associated modules. P-values were computed using the non-central hypergeometric <lb/>distribution, see Methods. <lb/>(A) IgAN-associated module identified using the consensus method in the InWeb protein-protein interaction network. <lb/>The module comprises immune-related NF-κB signaling pathways. Enriched mouse mutant phenotypes for module <lb/>gene homologs include perturbed immunoglobulin levels (IgM and IgG1). The module implicates in particular the NF-<lb/>κB subunit REL as a candidate gene. The REL locus does not reach genome-wide significance in current GWASs for <lb/>IgAN but is known to be associated with other immune disorders such as rheumatoid arthritis. <lb/>(B) Enriched annotations for the IgAN-associated module shown in Fig. 6D. The module comprises complement and <lb/>coagulation cascades. The top two enriched mouse mutant phenotypes are precisely &quot;abnormal blood coagulation&quot; <lb/>and &quot;glomerulonephritis&quot;. See main text for discussion. <lb/></div>

			<page>59 <lb/></page>

			<div type="annex">Table S1 <lb/>Provided as Excel file (Table_S1.xlsx) <lb/>Table S1: Collection of GWAS Datasets used for the Challenge. <lb/>The table lists the GWAS datasets used for the module scoring. The first column indicates whether the GWAS was <lb/>used during the &quot;leaderboard&quot; or &quot;final&quot; evaluation phase. The five GWAS listed in the end (&quot;extra&quot;) were not used for <lb/>the scoring as they were added to the collection after the challenge. The PASCAL gene scores for all GWAS are <lb/>available for download from the challenge website (file names are given in the last column). The original GWAS SNP <lb/>summary statistics can be downloaded individually from the indicated sources or we can share the complete collection <lb/>upon request. <lb/></div>

			<page>60 <lb/></page>

			<div type="annex">Table S2 <lb/>Table S2: Functional Enrichment for Example Modules, Related to Figs. 5 and 6. <lb/>Enrichment p-values for mouse mutant phenotypes, Reactome pathways and GO biological processes are shown for <lb/>four example modules discussed in the main text (Figs. 5 and 6). P-values were computed using the non-central <lb/>hypergeometric distribution and adjusted using the Bonferroni method (Methods). Results for the remaining trait-<lb/>associated modules from the consensus method in the STRING protein interaction network are shown in Table S4. <lb/>Functional enrichment analysis for additional pathway databases and modules from all methods and networks are <lb/>available on the challenge website. <lb/></div>

			<page>61 <lb/></page>

			<div type="annex">Table S3 <lb/>Table S3: Overview of Consensus Trait-modules in the STRING Network, Related to Fig. 6. <lb/>Overview of all 21 trait-associated modules discovered by the consensus method in the STRING protein-protein <lb/>interaction network. The first three columns give the module ID, the trait type, and the specific GWAS trait that the <lb/>module is associated to. We tested all modules for enrichment in GO annotation, mouse mutant phenotypes, and <lb/>other pathway databases using the noncentral hypergeometric test (Methods). The putative function of each module <lb/>based on this enrichment analysis is summarized in the fourth column (see Figs. 5, 6 and Tables S2, S4 for details). <lb/>Two thirds of the modules have functions that correspond to core pathways underlying the respective traits, while the <lb/>remaining modules correspond either to generic pathways that play a role in diverse traits or to pathways without an <lb/>established connection to the considered trait or disease. Only pathways with a well-established link to the trait were <lb/>considered core pathways. Generic pathways, such as cell-cycle-related or epigenetic pathways, were not considered <lb/>core pathways because they are relevant for many traits and tissues, making them more difficult to target <lb/>therapeutically. For example, modules 77 and 109 are both associated with schizophrenia and comprise pathways <lb/>related to epigenetic gene silencing and nucleosome organization, respectively. Although there is evidence that <lb/>epigenetic mechanisms may play a role in schizophrenia, we considered this to be a generic pathway. <lb/></div>

			<page>62 <lb/></page>

			<div type="annex">Table S4 <lb/>Provided as Excel file (Table_S4.xlsx) <lb/>Table S4: Functional Enrichment of Consensus Trait Modules. <lb/>For each of the 21 consensus trait-modules shown in Table S3, all categories with a Bonferroni-corrected P-value <lb/>below 0.05 are listed (Methods). Only results for mouse mutant phenotypes, Reactome pathways and GO biological <lb/>process annotations are included for brevity. Full results including all tested pathway databases and all challenge <lb/>modules are available on the challenge website. </div>


	</text>
</tei>
