<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="_0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Shade: A Fast Instruction-Set Simulator <lb/>for Execution Profiling <lb/>Bob Cmelik <lb/>Sun Microsystems, Inc. <lb/>rfc@eng.sun.com <lb/>David Keppel <lb/>University of Washington <lb/>pardo@cs.washington.edu <lb/>Abstract <lb/>Tracing tools are used widely to help analyze, design, and tune <lb/>both hardware and software systems. This paper describes a tool <lb/>called Shade which combines efficient instruction-set simulation <lb/>with a flexible, extensible trace generation capability. Efficiency <lb/>is achieved by dynamically compiling and caching code to simu-<lb/>late and trace the application program. The user may control the <lb/>extent of tracing in a variety of ways; arbitrarily detailed applica-<lb/>tion state information may be collected during the simulation, but <lb/>tracing less translates directly into greater efficiency. Current <lb/>Shade implementations run on SPARC systems and simulate the <lb/>SPARC (Versions 8 and 9) and MIPS I instruction sets. This <lb/>paper describes the capabilities, design, implementation, and per-<lb/>formance of Shade, and discusses instruction set emulation in <lb/>general. <lb/></front>

			<body>1. Introduction <lb/>Tracing tools are used widely to help in the analysis, design, and <lb/>tuning of both hardware and software systems. Tracing tools can <lb/>provide detailed information about the behavior of a program; that <lb/>information is used to drive an analyzer that analyzes or predicts <lb/>the behavior of a particular system component. That, in turn, pro-<lb/>vides feedback that is used to improve the design and implemen-<lb/>tation of everything from architectures to compilers to applica-<lb/>tions. Analyzers can consume many kinds of trace information. <lb/>For example, address traces are used for studies of memory <lb/>hierarchies, register and operand usage for pipeline design, in-<lb/>struction combinations for superscalar and deep-pipe designs, in-<lb/>struction counts for optimization studies, operand values for <lb/>memoizing studies, and branch behavior for branch prediction. <lb/>Several features can improve the utility of a tracing tool. First, <lb/>the tool should be easy to use and avoid dependencies on particu-<lb/>lar languages and compilers. Ideally it should also avoid poten-<lb/>tially cumbersome preprocessing steps. Second, it should be able <lb/>to trace a wide variety of applications including those that use sig-<lb/>nals, exceptions and dynamically-linked libraries. Third, trace <lb/>generation should be fast, both so that traces can be recreated on <lb/>demand, instead of being archived on bulk storage, and so that it <lb/>is possible to study realistic workloads, since partial workloads <lb/>may not provide representative information [BKW90]. Fourth, a <lb/>tracing tool should provide arbitrarily detailed trace information <lb/></body>

            <front>To appear in the 1994 ACM SIGMETRICS Conference on Measurement <lb/>and Modeling of Computer Systems. <lb/>Copyright Â© 1994, Association for Computing Machinery (ACM, Inc.) <lb/></front>

            <body>so that it is useful for a wide variety of analyzers; in general, this <lb/>means that it must be extensible [NG88] so that it can be pro-<lb/>grammed to collect specialized information. Finally, it should be <lb/>possible to trace applications for machines that do not yet exist. <lb/>These features are often at odds with each other. For example, <lb/>static cross-compilation can produce fast code, but purely static <lb/>translators cannot simulate and trace all details of dynamically-<lb/>linked code. Also, improved tracing flexibility generally means <lb/>reduced performance. An interpreter that saves address trace in-<lb/>formation may be reasonably fast, but adding control over wheth-<lb/>er the interpreter saves an address trace will slow the simulation, <lb/>if at every instruction the simulator must check whether to save <lb/>trace information. Providing finer control over where to save <lb/>trace data slows simulation even more; adding the flexibility to <lb/>save other kinds of trace information slows simulation yet further. <lb/>Because of the conflict between generality and performance, most <lb/>tools provide only a subset of the features listed above. Shade <lb/>provides the features together in one tool and uses five general <lb/>techniques to achieve the needed flexibility and performance. <lb/>First, Shade dynamically cross-compiles executable code for the <lb/>target machine into executable code that runs directly on the host <lb/>machine. Second, the host code is cached for reuse so that the <lb/>cost of cross-compiling can be amortized. Third, simulation and <lb/>tracing code are integrated so that the host code saves trace infor-<lb/>mation directly as it runs. Fourth, Shade gives the analyzer de-<lb/>tailed control over what is traced: the tracing strategy can be <lb/>varied dynamically by opcode and address range. Shade then <lb/>saves just the information requested by the analyzer, so clients <lb/>that need little trace information pay little overhead. Finally, <lb/>Shade can call special-purpose, analyzer-supplied code to extend <lb/>Shade&apos;s default data collection capabilities. <lb/>This paper makes several contributions. We introduce dynamic <lb/>compilation and caching techniques used for building fast cross-<lb/>architecture simulators. We show how a tracing tool can be made <lb/>extensible, and thus more flexible. Finally, we show how simula-<lb/>tion and instrumentation code can be integrated to save trace in-<lb/>formation efficiently. We show these ideas using Shade, which <lb/>performs cross-architecture simulation, collects many kinds of <lb/>trace information, allows fine control over the tracing, is extensi-<lb/>ble, which simulates and traces the target machine in detail (in-<lb/>cluding tricky things like signals and self-modifying code), and <lb/>which, despite all of the above flexibility, has performance com-<lb/>petitive with tools that just cross-simulate without tracing, with <lb/>tools that do only simple tracing, and even with those that omit <lb/>details to improve simulation and tracing efficiency. Thus, Shade <lb/>shows that a general-purpose tool can be efficient enough to effec-<lb/>tively replace many other tools. This paper also presents a frame-<lb/>work for describing simulation and tracing tools. <lb/>
            The remainder of this paper is organized as follows: Section 2 <lb/>describes the interface seen by programmers who use Shade to <lb/>write analyzers. Section 3 describes the implementation of Shade, <lb/>focusing on compilation, caching and instrumentation. Section 4 <lb/>discusses cross-architecture simulation. Section 5 reports on the <lb/>performance of Shade both for native and cross-architecture trac-<lb/>ing. Section 6 compares the capabilities and implementation of <lb/>other simulation and tracing tools. <lb/>2. Analyzer Interface <lb/>A Shade analyzer is a program (or that part of a program) which <lb/>utilizes the simulation and, to varying degrees, the tracing capabil-<lb/>ities provided by Shade. Shade analyzers have been used for pure <lb/>simulation (no tracing), to generate memory address traces for use <lb/>by other tools, provide a debugger interface to a simulated target <lb/>machine for compiler cross-development [Evans92], observe in-<lb/>struction operand values [Richardson92], analyze memory cache <lb/>performance, analyze microprocessor pipeline performance, and <lb/>analyze Shade&apos;s own performance. <lb/>Analyzers see Shade as a collection of library functions <lb/>[Cmelik93]. Analyzers call these functions to identify the applica-<lb/>tion program to be simulated, specify the level of tracing detail, <lb/>and to simulate one or more application instructions while collect-<lb/>ing the specified trace information. <lb/>Shade &quot;knows&quot; how to efficiently collect common trace informa-<lb/>tion such as the instruction address and text, data addresses for <lb/>memory operations, and the contents of registers used by an in-<lb/>struction. Other information may be collected by analyzer-<lb/>supplied trace functions. Shade arranges for these functions to be <lb/>called before and/or after simulating an application instruction. <lb/>The functions have access to the application&apos;s simulated registers <lb/>and memory. <lb/>The analyzer may specify what trace information to collect and <lb/>what trace functions to call on a per-opcode or per-instruction-<lb/>address basis. So, for example, an analyzer which wishes to <lb/>analyze memory systems might request tracing of just instruction <lb/>and data addresses. Tracing selections may change during the <lb/>course of the simulation. Thus, an analyzer can skip tracing dur-<lb/>ing application initialization, or can trace only in particularly in-<lb/>teresting application or library code. The less trace data the <lb/>analyzer requests, the faster Shade runs. <lb/>3. Implementation <lb/>This section describes the basic implementation of Shade. Sec-<lb/>tion 3.1 first describes the overall structure of Shade. Section 3.2 <lb/>describes dynamic compilation of translations that directly simu-<lb/>late and trace the application program. Section 3.3 describes how <lb/>translations are cached for reuse to reduce compilation overhead. <lb/>Finally, Section 3.4 concludes with some special problems and <lb/>considerations and the general techniques used in Shade. <lb/>3.1. Simulating and Tracing <lb/>
            The heart of Shade is a small main loop that repeatedly maps the <lb/>current target (application) PC to a corresponding fragment of <lb/>Shade host (simulator) code, called a translation. Each transla-<lb/>tion simulates the target instruction, optionally saves trace data, <lb/>updates the target PC and returns to the main loop. Shade builds <lb/>translations by cross-compiling target instructions into host <lb/>machine code. Shade translates application memory references to <lb/>refer to simulated memory and, similarly, translates updates of <lb/>target registers into updates of simulated registers. Figure 1 sum-<lb/>marizes the primary data structures used by Shade. <lb/>The main loop, translations, and most utility functions called by <lb/>translations all share a common register window and stack frame. <lb/>Several host registers are reserved for special purposes. Register <lb/>vs is a pointer to the application&apos;s virtual state structure which <lb/>holds the simulated registers; vpc is the application&apos;s virtual pro-<lb/>gram counter (this is part of the virtual state, but is used enough to <lb/>warrant its own host register); vmem is the base address of the <lb/>application&apos;s memory; tr is a pointer to the current trace buffer <lb/>entry; ntr is the number of unused trace buffer entries; and tlb <lb/>is a pointer to the TLB (described below). <lb/>Shade maps the target PC to its corresponding translation using a <lb/>data structure called the Translation Lookaside Buffer (TLB). <lb/>The main loop does a fast, partial TLB lookup. If that fails, a <lb/>function is called to do a slower, full TLB lookup. If that fails, <lb/>the translation compiler is invoked to generate a new translation <lb/>in the Translation Cache (TC) and update the TLB. <lb/>The main loop also checks for pending signals that need to be <lb/>delivered to the application. Depending on how the application <lb/>wishes to handle the signal, Shade may terminate the application <lb/>at this point, or arrange for invocation of an application signal <lb/>handler. In the latter case, Shade continues simulating and trac-<lb/>ing, but now in the application&apos;s signal handler. <lb/>Text <lb/>Data <lb/>Stack <lb/>VMEM <lb/>â¢ <lb/>â¢ <lb/>â¢ <lb/>cond codes <lb/>fp regs <lb/>int regs <lb/>VS <lb/>â <lb/>â <lb/>â <lb/>â <lb/>â <lb/>â <lb/>TLB <lb/>TC <lb/>Figure 1. Shade data structures (not to scale) <lb/>3.2. Translations <lb/>Application instructions are typically translated in chunks which <lb/>extend from the current instruction through the next control <lb/>transfer instruction and accompanying delay slot. Translation also <lb/>stops at tricky instructions such as software trap and memory syn-<lb/>chronization instructions and Shade arbitrarily limits the number <lb/>of application instructions per translation in order to simplify <lb/>storage allocation. The user&apos;s trace buffer size also limits transla-<lb/>tion size. Therefore, a translation may represent more or less than <lb/>one basic block of application code, and one fragment of applica-<lb/>tion code may be simultaneously represented by more than one <lb/>translation. Each translation consists of a prologue, a body with a <lb/>fragment for each application instruction, and an epilogue. <lb/>3.2.1. Translation Prologue <lb/>
            The translation prologue (see Figure 2) allocates trace buffer <lb/>space for the translation. If there is not enough space, the transla-<lb/>tion returns control to the main loop, which then returns control to <lb/>the analyzer. Prologues are generated only for translations that <lb/>collect trace information for at least one target instruction. <lb/>The trace space requirements for each translation could be stored <lb/>in a data structure and tested by the main loop. That would save <lb/>the code space now used for translation prologues, but would re-<lb/>quire executing additional instructions to address and load count, <lb/>and would be inconsistent with translation chaining (described <lb/>below) in which translations branch directly to each other, bypass-<lb/>ing the main simulator loop. <lb/>prologue: <lb/>subcc <lb/>%ntr, count, %ntr <lb/>bgeu <lb/>body <lb/>! if enough space, run body <lb/>nop <lb/>! (branch delay slot) <lb/>add <lb/>%ntr, count, %ntr <lb/>return to main loop <lb/>body: <lb/>Figure 2. Translation prologue <lb/>3.2.2. Translation Body <lb/>The translation body contains code to simulate and (optionally) <lb/>trace application instructions. Simulation consists of updating the <lb/>virtual state (registers plus memory) of the application program. <lb/>Tracing consists of filling in the current trace buffer entry and ad-<lb/>vancing to the next. <lb/>Figure 3 shows a sample application instruction, and Figure 4 <lb/>shows code that simulates it. The translation body first loads the <lb/>contents of application registers r1 and r2 from the application&apos;s <lb/>virtual state structure into host scratch registers s1 and s2. Next, <lb/>the translation performs the add operation. Then, the translation <lb/>writes the result in host scratch register s3 back to the virtual <lb/>state structure location for application register r3. Finally, the <lb/>translation updates the application&apos;s virtual PC. <lb/>add <lb/>%r1, %r2, %r3 <lb/>Figure 3. Sample application code <lb/>ld <lb/>[%vs + vs_r1], %s1 <lb/>ld <lb/>[%vs + vs_r2], %s2 <lb/>add <lb/>%s1, %s2, %s3 <lb/>st <lb/>%s3, [%vs + vs_r3] <lb/>inc <lb/>4, %vpc <lb/>Figure 4. Translation body (no tracing) <lb/>The code that is generated to actually perform the application <lb/>operation is very often one and the same instruction, but with dif-<lb/>ferent register numbers. Where the host machine is a poor match <lb/>to the virtual target machine, or where we wish to virtualize the <lb/>target machine operations, several instructions, or even a call to a <lb/>simulation function may be used. At the other extreme, no in-<lb/>structions need be generated to simulate useless application in-<lb/>structions (e.g. nop). <lb/>Shade allocates host registers to represent target registers; alloca-<lb/>tion is on a per-translation basis and can thus span several target <lb/>instructions. The host registers hold target register values from <lb/>one translated application instruction to the next in order to reduce <lb/>memory traffic to and from the virtual state structure. Host regis-<lb/>ters are lazily loaded from the virtual state structure, then later la-<lb/>zily stored back, but no later than the translation epilogue. <lb/>Conceptually, Shade updates the virtual PC for each application <lb/>instruction, as shown here. In practice, the virtual PC is only up-<lb/>dated in the translation epilogue, or as needed in the translation <lb/>body for tracing application instruction addresses. <lb/>For application instructions that access memory, Shade translates <lb/>the application memory address to a host memory address by ad-<lb/>ding a base address offset (which applies for all application <lb/>memory). <lb/>3.2.3. Tracing <lb/>Shade minimizes the amount of tracing code by giving analyzers <lb/>precise control over which application instructions should be <lb/>traced and what information should be collected for each instruc-<lb/>tion. For example, if the analyzer requests tracing for only data <lb/>memory addresses from load instructions in a particular library <lb/>(an address range), then Shade translates the library&apos;s load in-<lb/>structions to directly save the memory address in the trace record. <lb/>No other trace information is saved for load instructions, and no <lb/>trace information is saved for other instructions or for load in-<lb/>structions outside of the library. <lb/>Shade compiles the simulation and tracing code together. For ex-<lb/>ample, Figure 5 shows code that simulates the sample application <lb/>code, and, under analyzer control, traces the instruction address, <lb/>instruction text, source and destination registers, and calls both <lb/>pre-and post-instruction trace functions supplied by the analyzer. <lb/>Whenever a translation calls an analyzer-supplied trace function, <lb/>it first returns live application state to the virtual state structure for <lb/>use by the trace function. <lb/>st <lb/>%vpc, [%tr + tr_pc] ! trace instr addr <lb/>set <lb/>0x86004002, %o0 <lb/>st <lb/>%o0, [%tr + tr_iw] <lb/>! trace instr text <lb/>ld <lb/>[%vs + vs_r1], %s1 <lb/>! load 1st src reg <lb/>ld <lb/>[%vs + vs_r2], %s2 <lb/>! load 2nd src reg <lb/>st <lb/>%s1, [%tr + tr_rs1] ! trace 1st src reg <lb/>st <lb/>%s2, [%tr + tr_rs2] ! trace 2nd src reg <lb/>mov <lb/>%tr, %o0 <lb/>! arg1: trace buf <lb/>mov <lb/>%vs, %o1 <lb/>! arg2: virt. state <lb/>call pre-instruction trace function <lb/>add <lb/>%s1, %s2, %s3 <lb/>! simulate add <lb/>st <lb/>%s3, [%vs + vs_r3] <lb/>! save dst reg <lb/>st <lb/>%s3, [%tr + tr_rd] <lb/>! trace dst reg <lb/>mov <lb/>%tr, %o0 <lb/>! arg1: trace buf <lb/>mov <lb/>%vs, %o1 <lb/>! arg2: virt. state <lb/>call post-instruction trace function <lb/>inc <lb/>4, %vpc <lb/>inc <lb/>trsize, %tr ! advance in trace buffer <lb/>Figure 5. Translation body (some tracing) <lb/>3.2.4. Translation Epilogue <lb/>The translation epilogue (see Figure 6) updates the virtual state <lb/>structure and returns control either to the main simulator loop or <lb/>jumps directly to the next translation. The epilogue saves host re-<lb/>gisters that hold modified virtual register values. If the virtual <lb/>condition codes have been modified, they too must be saved. The <lb/>epilogue also updates the trace buffer registers tr and ntr if <lb/>necessary. The virtual PC remains in a host register across trans-<lb/>lation calls. Upon leaving a translation, it contains the address of <lb/>the next application instruction to be executed. <lb/>epilogue: <lb/>update virtual state structure <lb/>update virtual PC <lb/>inc <lb/>count * trsize, %tr <lb/>go to main loop or next translation <lb/>Figure 6. Translation epilogue <lb/>Often, the execution of one translation always dynamically fol-<lb/>lows that of another. The two translations, predecessor and suc-<lb/>cessor, can be directly connected or chained to save a pass <lb/>through the main simulator loop. The predecessor and successor <lb/>can be compiled in any order. If the successor is compiled first, <lb/>the predecessor is compiled to branch directly to the successor. If <lb/>the predecessor is compiled first, then at the time the successor is <lb/>compiled the predecessor&apos;s return to the main simulator loop is <lb/>overwritten with a branch to the successor. <lb/>Translations for conditional branches are compiled with two <lb/>separate exits instead of a single common exit, so that both legs <lb/>may be chained. Translations for register indirect jumps and <lb/>software traps (which might cause a control transfer) cannot be <lb/>chained since the successor translation may vary. <lb/>3.3. Translation Caching <lb/>The translation cache (TC) is the memory where translations are <lb/>stored. Shade simply compiles translations into the TC one after <lb/>the other, and the translation lookaside buffer (TLB) associates <lb/>application code addresses with the corresponding translations. <lb/>
            When more TC space is needed than is available, Shade frees all <lb/>entries in the TC and clears the TLB. Full flushing is used be-<lb/>cause translation chaining makes most other freeing strategies <lb/>tedious [CK93]. Since full flushing deletes useful translations, the <lb/>TC is made large so that freeing is rare [CK93]. Shade also flushes <lb/>the TC and TLB when the analyzer changes the tracing strategy <lb/>(typically rare), since tracing is hardcoded into the translations. <lb/>If an application uses self-modifying code, the TC, TLB, and <lb/>translation chaining entries for the modified code become invalid <lb/>and must be flushed. SPARC systems provide the flush instruc-<lb/>tion to identify code that has changed; many other systems pro-<lb/>vide equivalent primitives [Keppel91]. When the application exe-<lb/>cutes the modified instructions, Shade compiles new translations <lb/>for the changed code. <lb/>The TLB is an array of lists of &lt;target, host&gt; address pairs. Each <lb/>pair associates an application instruction address with the <lb/>corresponding translation address. To find a translation, Shade <lb/>hashes the vpc to produce a TLB array index, then searches this <lb/>TLB entry (address pair list) for the given application address. If <lb/>the search succeeds, the list is reorganized so that the most recent-<lb/>ly accessed address pair is at the head of the list. If the search <lb/>fails, a translation is generated, and a new address pair is placed at <lb/>the head of the list. <lb/>Lists are actually implemented as fixed length arrays, which <lb/>makes the TLB simply a two-dimensional array of address pairs. <lb/>The TLB may also be thought of as N-way set associative, where <lb/>N is the list length. Since address pair lists are of fixed length, ad-<lb/>dress pairs can be pushed off the end of a list and lost, which <lb/>makes the corresponding translations inaccessible via the TLB. <lb/>The TLB is large enough that this is not usually a problem [CK93] <lb/>and translations are also likely to still be accessible via chaining <lb/>from other translations. <lb/>3.4. Other Considerations <lb/>The decision to simulate, trace, and analyze all in the same pro-<lb/>cess leads to conflicts over the use of per-process state and <lb/>resources. Conflicts arise between the application program (e.g. <lb/>the code generated by Shade to simulate the application), the <lb/>analyzer, and Shade (translation compiler, etc.). The conflicts are <lb/>resolved in various ways. For example, the host&apos;s memory is par-<lb/>titioned so that Shade uses one part of the memory, and the appli-<lb/>cation another. Resource conflicts can also arise from sharing <lb/>outside of the process. For example, Shade and the application <lb/>use the same file system so files written by one can accidentally <lb/>clobber files written by the other. In general, conflicts are <lb/>resolved by partitioning the resource, by time multiplexing it <lb/>between contenders, or by simulating (virtualizing) the resource. <lb/>Some conflicts are unresolved, usually due to an incomplete <lb/>implementation [CK93]. <lb/>Shade&apos;s target code parser is ad hoc, though machine code parsers <lb/>can be built automatically [Ramsey93]. Shade uses an ad hoc code <lb/>generator which generates code in roughly one pass. Some minor <lb/>backpatching is later performed to chain translations and replace <lb/>nops in delay slots. The resulting code could no doubt be im-<lb/>proved, but the time spent in the user-supplied analyzer usually <lb/>dwarfs the time spent in Shade&apos;s code generation, simulation, and <lb/>tracing combined. <lb/>Many of the implementation issues and choices, as well as some <lb/>of the implementation alternatives, are described elsewhere <lb/>[CK93], as are details of the signal and exception handling and im-<lb/>plementation of the system call interface. <lb/>4. Cross Shades <lb/>In the previous section we focused on the Shade (subsequently re-<lb/>ferred to as Shade-V8.V8) for which the host and target architec-<lb/>tures were both Version 8 SPARC, and for which the host and tar-<lb/>get operating systems were both SunOS 4.x [SunOS4]. Other <lb/>Shades have been developed. The first (Shade-MIPS.V8) runs <lb/>UMIPS-V [UMIPSV], MIPS I [Kane87] binaries, and the second <lb/>(Shade-V9.V8) runs SunOS 4.x, Version 9 SPARC [SPARC9] <lb/>binaries. The host system for both is SunOS 4.x, Version 8 <lb/>SPARC. There are also versions of Shade-V8.V8 and Shade-<lb/>V9.V8 where both the host and target operating systems are <lb/>Solaris 2.x [SunOS5]. All of these Shades are at least complete to <lb/>the extent that they can run SPEC89 binaries compiled for the <lb/>respective target systems. <lb/>4.1. Shade-MIPS.V8 <lb/>Shade-MIPS.V8 provides Shade&apos;s custom tracing capabilities for <lb/>
            MIPS binaries. Given Shade-V8.V8 and ready access to SPARC <lb/>systems, SPARC was the natural choice for the host architecture. <lb/>As a rule, MIPS instructions are straightforward to simulate with <lb/>just a few SPARC instructions. This is possible because both the <lb/>MIPS and SPARC architectures are RISC architectures, both sup-<lb/>port IEEE arithmetic, and the MIPS architecture lacks integer <lb/>condition codes. <lb/>Little attention was paid to simulation efficiency, beyond the <lb/>efficient simulation techniques already used in Shade. On aver-<lb/>age, 1 Shade-MIPS.V8 executes about 10 SPARC instructions to <lb/>simulate a MIPS instruction. <lb/>Some differences between the host and target machines make <lb/>Shade-MIPS.V8 less faithful, slower, or more complicated. For <lb/>example, MIPS systems support both big-endian and little-endian <lb/>byte ordering [James90], but V8 SPARC only supports the former. <lb/>Shade-MIPS.V8 currently runs only code that has been compiled <lb/>for MIPS systems running in big-endian mode. Shade thus avoids <lb/>the more complicated simulation of little-endian access. Similar-<lb/>ly, Shade-MIPS.V8 does not check for overflows that would cause <lb/>exceptions on MIPS systems. Several MIPS features such as <lb/>unaligned memory access instructions and details of floating-point <lb/>rounding have no direct V8 SPARC counterparts, so Shade-<lb/>MIPS.V8 simulates them, albeit more slowly. Many immediate <lb/>fields are 16 bits on the MIPS and 13 bits on the SPARC; where <lb/>target immediates do not fit in 13 bits, extra SPARC instructions <lb/>are used to place the immediate value in a host scratch register. <lb/>This difference complicates the translation compiler. <lb/>Some host/target differences help Shade-MIPS.V8&apos;s efficiency. <lb/>In particular, the MIPS architecture employs values stored in gen-<lb/>eral purpose integer registers in place of integer condition codes. <lb/>This reduces contention for the host condition codes [CK93]. <lb/>4.2. Shade-V9.V8 <lb/>Shade-V9.V8 simulates a V9 SPARC target and runs on a V8 <lb/>SPARC host. The principal problems of simulating V9 applica-<lb/>tions on V8 hosts are wider integer registers and additional condi-<lb/></body>

			<note place="footnote">1. Here and elsewhere, &quot;on average&quot; means the geometric mean of dynamically <lb/>weighted values over the SPEC89 benchmarks. <lb/></note>

			<body>_ ___________________________________________________________________________________________________ <lb/>native <lb/>icount0 <lb/>icount1 <lb/>icount2 <lb/>icount3 <lb/>icount4 <lb/>icount5 <lb/>Shade <lb/>app <lb/>inst time <lb/>inst time <lb/>inst time <lb/>inst time <lb/>inst time <lb/>inst time <lb/>inst time <lb/>_ ___________________________________________________________________________________________________ <lb/>_ ___________________________________________________________________________________________________ <lb/>gcc <lb/>1.0 1.0 <lb/>5.5 6.1 <lb/>5.9 6.6 <lb/>8.8 14.3 <lb/>13.5 21.7 <lb/>15.5 31.2 <lb/>63.7 84.2 <lb/>V8.V8 doduc <lb/>1.0 1.0 <lb/>2.8 2.8 <lb/>2.9 3.1 <lb/>5.5 8.8 <lb/>9.4 14.0 <lb/>11.5 24.1 <lb/>36.3 60.3 <lb/>_ ___________________________________________________________________________________________________ <lb/>_ ___________________________________________________________________________________________________ <lb/>espresso <lb/>1.0 NA <lb/>9.5 1.2K <lb/>9.8 1.2K 11.5 2.2K 15.8 3.0K 17.8 4.8K 42.0 8.5K <lb/>V9.V8 doduc <lb/>1.0 NA <lb/>6.1 1.1K <lb/>6.3 1.2K <lb/>8.1 2.4K 11.8 3.3K 13.9 5.4K 38.5 11.5K <lb/>_ ___________________________________________________________________________________________________ <lb/>Table 1. Dynamic expansion: instructions and CPU time <lb/>tion codes. Simulating a 64-bit address space would be a prob-<lb/>lem, but so far it has been avoided. <lb/>The new V9 instructions present few new problems, but there are <lb/>many new instructions. As a rough measure of relative simula-<lb/>tion complexity, consider that, given Shade-V8.V8, it took about <lb/>3 weeks to develop Shade-MIPS.V8 and about 3 months to <lb/>develop Shade-V9.V8 to the point where each could run SPEC89. <lb/>Shade usually generates a short sequence of V8 instructions for <lb/>each V9 instruction. For example, Figure 7 shows the translation <lb/>body fragment for a V9 add instruction. Complicated instruc-<lb/>tions are compiled as calls to simulation functions. <lb/>ldd <lb/>[%vs + vs_r1], %s0 ! s0/s1: virt. r1 <lb/>ldd <lb/>[%vs + vs_r2], %s2 ! s2/s3: virt. r2 <lb/>addcc <lb/>%s1, %s3, %s5 <lb/>! add lower 32 bits <lb/>addx <lb/>%s0, %s2, %s4 <lb/>! add upper 32 bits <lb/>std <lb/>%s4, [%vs + vs_r3] ! virt. r3: s4/s5 <lb/>inc <lb/>4, %vpc <lb/>Figure 7. Shade-V9.V8 translation body <lb/>The V9 target&apos;s 64-bit registers are simulated with register pairs <lb/>on the V8 host. This doubles memory traffic for each register <lb/>moved between the virtual state structure and the host registers. It <lb/>also increases the number of such moves, since only half as many <lb/>target registers can be cached in the host&apos;s registers. <lb/>V9 SPARC has two sets of condition codes. One set is based on <lb/>the low order 32 bits of the result (just as in V8), and the other on <lb/>the full 64 bits of the result. The host integer condition codes are <lb/>often required (as in the add example above) to simulate 64-bit <lb/>operations which themselves do not involve condition codes. <lb/>This increases the number of contenders for the host condition <lb/>codes [CK93]. <lb/>Shade-V9.V8&apos;s performance is likely to degrade as compilers take <lb/>advantage of more V9 features. For example, V9 supports more <lb/>floating point registers and floating point condition codes than V8. <lb/>V9 compilers that make better use of these registers will increase <lb/>register pressure on the V8 host. Also, under Shade-V9.V8, ap-<lb/>plications are only allowed access to the lower 4GB of virtual <lb/>memory. Thus, although programs manipulate 64-bit pointers, <lb/>Shade-V9.V8 ignores the upper 32-bits of addresses during the <lb/>actual accesses (load, store, register indirect jump, system call). <lb/>Shade-V9.V8 will run slower if and when it needs to simulate a <lb/>full 64-bit address space. <lb/>5. Performance <lb/>This section reports on the performance of Shade. For Shade-<lb/>V8.V8, performance is reported relative to native execution. <lb/>Since SPARC V9 platforms are still under construction, Shade-<lb/>V9.V8 figures do not include relative performance. The standard <lb/>Shade configuration used in these tests is a 4MB TC that holds 2 20 <lb/>host instructions, and a 256KB TLB that holds 2 13 (8K) lines, <lb/>each with 4 address pairs. <lb/>The benchmarks are from SPEC89, compiled with optimizations <lb/>on. For Shade-V8.V8, the 001.gcc1.35 and 015.doduc bench-<lb/>marks were used; for Shade-V9.V8, 008.espresso and 015.doduc <lb/>were used. <lb/>The measurements use six Shade analyzers, each performing a <lb/>different amount of tracing. The analyzers use Shade to record <lb/>varying amounts of information, but everything Shade records is <lb/>then ignored. This &quot;null analysis&quot; was done to show the break-<lb/>down of time in Shade. With real analyzers, analysis dominates <lb/>the run time and Shade is not the bottleneck. The analyzers are: <lb/>icount0: no tracing, just application simulation. <lb/>icount1: no tracing, just update the traced instruction counter <lb/>(ntr) to permit instruction counting. <lb/>icount2: trace PC for all instructions (including annulled); trace <lb/>effective memory address for non-annulled loads and stores. This <lb/>corresponds to the tracing required for cache simulation. <lb/>icount3: same as icount2 plus instruction text, decoded op-<lb/>code value, and, where appropriate, annulled instruction flag and <lb/>taken branch flag. <lb/>icount4: same as icount3 plus values of all integer and float-<lb/>ing point registers used in instruction. <lb/>icount5: same as icount4 plus call an empty user trace func-<lb/>tion before and after each application instruction. <lb/>Table 1 shows how much slower applications run under Shade <lb/>compared to native execution. The inst column shows the aver-<lb/>age number of instructions that were executed per application in-<lb/>struction. The time column shows the CPU (user + system) time; <lb/>for Shade-V8.V8 as a ratio to native time, for Shade-V9.V8 as ab-<lb/>solute time in seconds. 2 <lb/>Shade is usually more efficient on floating-point code (doduc) <lb/>than on integer code (gcc and espresso). Floating-point code has <lb/>larger basic blocks, which both improves host register allocation <lb/>and reduces the number of branches and thus the number of look-<lb/>up operations to map the target PC to the corresponding transla-<lb/>tion. Floating-point code also uses more expensive operations, so <lb/>relatively more time is spent doing useful work. The relative <lb/>costs are closer for higher levels of tracing, since the overhead of <lb/>tracing is nearly independent of the instruction type. <lb/>Shade-V9.V8 is less efficient than Shade-V8.V8, and less efficient <lb/>for integer than floating point applications. The wider V9 words <lb/>cause more memory traffic and more contention for host registers. <lb/>V9 also has more condition codes and is thus more work to simu-<lb/>late. On average, Shade-V9.V8 simulates V8 (sic) integer <lb/>SPEC89 benchmarks 12.2 times slower than they run native, and <lb/>V8 floating point SPEC89 benchmarks 4.0 times slower. Shade-<lb/>V8.V8 simulates these same benchmarks 6.2 and 2.3 times slower <lb/>than they run native, respectively. <lb/>Table 2 shows how much larger dynamically (i.e. weighted by <lb/>number of times executed) a translation is than the application <lb/>code it represents. Input size is the dynamically-weighted average <lb/>size of a target basic block. Output size is the dynamically-<lb/>weighted average number of instructions in a translation and the <lb/></body>

			<note place="footnote">2. Instruction counts were gathered by running Shade on itself: the superior Shades <lb/>ran the icount1 analyzer while the subordinate (traced) Shades ran the indicat-<lb/>ed analyzers and benchmarks. Overall running times were collected using <lb/>elapsed time timers on the host. Percentage time distribution (shown below) was <lb/>measured using conventional profiling with cc -p and prof. <lb/></note>

			<body>____________________________________________________________________________________ <lb/>input <lb/>output size <lb/>___________________________________________________________ <lb/>Shade <lb/>app <lb/>size <lb/>icount0 <lb/>icount1 <lb/>icount2 <lb/>icount3 <lb/>icount4 <lb/>icount5 <lb/>____________________________________________________________________________________ ____________________________________________________________________________________ <lb/>gcc <lb/>5.1 <lb/>20 4.7x 26 6.2x 41 9.1x <lb/>67 15x <lb/>77 17x 193 40x <lb/>V8.V8 doduc <lb/>12.5 <lb/>33 4.1x 39 5.1x 73 8.0x 126 13x 153 15x 427 39x <lb/>____________________________________________________________________________________ ____________________________________________________________________________________ <lb/>espresso <lb/>6.1 <lb/>44 8.2x 49 9.5x 61 11.6x <lb/>91 17x 104 19x 246 44x <lb/>V9.V8 doduc <lb/>13.6 <lb/>63 5.5x 69 6.4x 94 8.3x 147 13x 177 15x 432 37x <lb/>____________________________________________________________________________________ <lb/>Table 2. Code translation expansion, dynamically weighted <lb/>___________________________________________________________________________________ <lb/>Shade <lb/>app <lb/>location <lb/>icount0 <lb/>icount1 <lb/>icount2 <lb/>icount3 <lb/>icount4 <lb/>icount5 <lb/>___________________________________________________________________________________ ___________________________________________________________________________________ <lb/>Compiler <lb/>8.77% 10.14% <lb/>5.82% <lb/>4.59% <lb/>3.86% 25.05% <lb/>TC <lb/>51.13% 52.56% 74.62% 82.22% 86.33% 61.26% <lb/>Sim <lb/>39.00% 36.09% 19.01% 12.83% <lb/>9.55% <lb/>4.97% <lb/>gcc <lb/>Analyzer <lb/>0.00% <lb/>0.03% <lb/>0.01% <lb/>0.00% <lb/>0.00% <lb/>8.61% <lb/>___________________________________________________________________________ <lb/>Compiler <lb/>0.22% <lb/>0.35% <lb/>0.16% <lb/>0.11% <lb/>0.08% <lb/>0.06% <lb/>TC <lb/>80.69% 81.56% 91.50% 95.20% 96.37% 87.87% <lb/>Sim <lb/>19.04% 17.97% <lb/>8.32% <lb/>4.67% <lb/>3.55% <lb/>2.11% <lb/>V8.V8 <lb/>doduc <lb/>Analyzer <lb/>0.00% <lb/>0.07% <lb/>0.00% <lb/>0.00% <lb/>0.00% <lb/>9.96% <lb/>___________________________________________________________________________________ ___________________________________________________________________________________ <lb/>Compiler <lb/>0.30% <lb/>0.35% <lb/>0.23% <lb/>0.20% <lb/>0.13% <lb/>0.10% <lb/>TC <lb/>61.92% 62.73% 78.98% 84.26% 89.90% 81.27% <lb/>Sim <lb/>37.74% 36.84% 20.76% 15.52% <lb/>9.95% <lb/>5.43% <lb/>espresso <lb/>Analyzer <lb/>0.00% <lb/>0.04% <lb/>0.00% <lb/>0.01% <lb/>0.00% 13.19% <lb/>___________________________________________________________________________ <lb/>Compiler <lb/>0.11% <lb/>0.15% <lb/>0.09% <lb/>0.07% <lb/>0.05% <lb/>0.05% <lb/>TC <lb/>61.92% 64.35% 80.55% 85.93% 90.65% 85.82% <lb/>Sim <lb/>37.96% 35.47% 19.35% 14.00% <lb/>9.30% <lb/>4.77% <lb/>V9.V8 <lb/>doduc <lb/>Analyzer <lb/>0.00% <lb/>0.03% <lb/>0.00% <lb/>0.01% <lb/>0.00% <lb/>9.36% <lb/>___________________________________________________________________________________ <lb/>Table 3. Run-time execution profile summary <lb/>_ _______________________________________________________________________ <lb/>Shade <lb/>app <lb/>icount0 icount1 icount2 icount3 icount4 icount5 <lb/>_ _______________________________________________________________________ <lb/>_ _______________________________________________________________________ <lb/>gcc <lb/>179.7 <lb/>171.25 <lb/>127.2 <lb/>94.0 <lb/>87.5 <lb/>51.4 <lb/>V8.V8 doduc <lb/>245.4 <lb/>271.2 <lb/>162.6 <lb/>111.9 <lb/>102.1 <lb/>58.9 <lb/>_ _______________________________________________________________________ <lb/>_ _______________________________________________________________________ <lb/>espresso <lb/>451.1 <lb/>486.7 <lb/>423.6 <lb/>331.3 <lb/>308.4 <lb/>191.7 <lb/>V9.V8 doduc <lb/>123.5 <lb/>151.4 <lb/>123.7 <lb/>91.9 <lb/>84.2 <lb/>84.6 <lb/>_ _______________________________________________________________________ <lb/>
            Table 4. Code generator instructions per instruction generated <lb/>code space expansion over the input size. Output sizes don&apos;t <lb/>directly correlate to running time, since portions of most transla-<lb/>tions are conditionally executed, and since some instructions are <lb/>executed outside of the TC in the translation compiler, simulation <lb/>functions, and the analyzer. <lb/>Table 3 shows the percentage of total run time spent in various <lb/>phases of execution. Compiler denotes the time spent in the <lb/>translation compiler, TC the time spent executing code in the <lb/>Translation Cache, Sim the time spent in functions which are <lb/>called from the TC to simulate, or assist in simulating application <lb/>instructions, and Analyzer the time spent in the user&apos;s analyzer, <lb/>including user trace functions which are called from the TC. <lb/>The time distribution is determined by several factors. Better op-<lb/>timization takes longer and produces faster running code, both of <lb/>which increase the percentage of time spent in code generation. <lb/>The simulation time (Sim) comes mostly from saving and restor-<lb/>ing condition codes [CK93], simulating save and restore, and <lb/>from main loop execution; larger target basic blocks tend to <lb/>reduce condition code and main loop overheads. A small TC in-<lb/>creases the frequency with which useful translations are discard-<lb/>ed. A small or ineffective TLB increases the frequency with <lb/>which useful translations are lost. Translations that collect a lot of <lb/>information take longer to run, and thus reduce the percentage of <lb/>time spent in simulation functions, even though their absolute run-<lb/>ning time is unchanged. All analyzers used in these tests are trivi-<lb/>al, though icount5 includes null functions that are called before <lb/>and after each application instruction. <lb/>Table 4 shows the average number of instructions that are execut-<lb/>ed by the code generator in order to generate one host instruction. <lb/>The number of instructions per instruction in the code generator is <lb/>a function of the instruction set architecture of the host and target <lb/>machines and the level of tracing. Note that without translation <lb/>caching, the compiler would be invoked every time a target in-<lb/>struction was run and applications would run hundreds or <lb/>thousands of times slower. Measurements of the TC and TLB ef-<lb/>fectiveness are reported elsewhere [CK93]. <lb/>6. Related Work <lb/>This section describes related work and summarizes the capabili-<lb/>ties and implementation techniques of other simulators, virtual <lb/>machines and tracing tools. In most cases we try to evaluate the <lb/>capabilities of each tools&apos; technology, but as we are evaluating ac-<lb/>tual tools, we sometimes (necessarily) evaluate limits of a particu-<lb/>lar implementation. <lb/>6.1. Capabilities and Implementation <lb/>Table 5 summarizes the capabilities and implementations for a <lb/>number of tools. The columns show particular features of each <lb/>tool and are grouped in three sections. The first group, Purpose <lb/>and Input Rep. describe the purpose of the tool and how a user <lb/>prepares a program in order to use the tool. The second group of <lb/>columns, Detail, MD, MP, Signals and SMC OK, shows the level <lb/>of detail of the simulation, and thus the kinds of programs that can <lb/>be processed by the tool. The third group of columns, <lb/>Technology and Bugs OK shows the implementation technology <lb/>used and the tool&apos;s robustness in the face of application errors. <lb/>The columns are described in more detail below. <lb/>Purpose describes how the tool is used: for cross-architecture <lb/>simulation (sim); debugging (db); for address tracing or memory <lb/>hierarchy analysis (atr); or for other, more detailed kinds of trac-<lb/>ing (otr). Tools marked tb C are tool-building tools and usually <lb/>use C as the extension language [NG88]. <lb/>Input describes the input to the tool. Processing a high-level <lb/>language input (hll) can have the best portability and best optimi-<lb/>zation but the tool can only be used for source programs written in <lb/>the supported languages [VF94] and can&apos;t generally be used for <lb/>_ __________________________________________________________________________________________________________________________ <lb/>
            Input <lb/>SMC <lb/>Bugs <lb/>Name <lb/>Reference(s) <lb/>Purpose <lb/>Rep. <lb/>Detail MD MP <lb/>Signals <lb/>OK <lb/>Technology <lb/>OK <lb/>_ __________________________________________________________________________________________________________________________ <lb/>_ __________________________________________________________________________________________________________________________ <lb/>Accelerator <lb/>[AS92] <lb/>sim <lb/>exe <lb/>us <lb/>Y <lb/>N <lb/>Y <lb/>Y <lb/>scc+gi <lb/>Y <lb/>ATOM <lb/>[SE94] <lb/>tb C <lb/>exe * <lb/>u <lb/>N <lb/>N <lb/>Y <lb/>N <lb/>aug <lb/>N <lb/>ATUM <lb/>[ASH86] <lb/>sim/atr <lb/>exe <lb/>us <lb/>Y <lb/>Y= <lb/>Y <lb/>Y <lb/>emu <lb/>Y <lb/>dis+mod+run <lb/>[FC88] <lb/>sim/atr <lb/>asm <lb/>u <lb/>N <lb/>N <lb/>N <lb/>N <lb/>scc <lb/>N <lb/>Dynascope <lb/>[SosiÄ92] <lb/>db/atr/otr <lb/>hll <lb/>u <lb/>N <lb/>N <lb/>S <lb/>Y <lb/>pdi <lb/>Y <lb/>Executor <lb/>[Hostetter93] <lb/>sim <lb/>exe <lb/>u <lb/>N <lb/>N <lb/>Y <lb/>Y <lb/>pdi <lb/>Y <lb/>g88 <lb/>[Bedichek90] <lb/>sim/db <lb/>exe <lb/>usd <lb/>Y <lb/>N <lb/>Y <lb/>Y <lb/>tci <lb/>Y <lb/>gsim <lb/>[Magnusson93, Magnusson94] sim/db/atr/otr/tb C exe <lb/>usd <lb/>Y <lb/>Y1 <lb/>Y <lb/>Y <lb/>tci+dcc <lb/>Y <lb/>Mable <lb/>[DLHH93] <lb/>sim/db/atr <lb/>exe <lb/>u <lb/>N <lb/>Y1 <lb/>N <lb/>Y <lb/>ddi <lb/>N <lb/>mg88 <lb/>[Bedichek94] <lb/>sim/db/atr/otr/tb C exe <lb/>usd <lb/>Y <lb/>Y1 <lb/>Y <lb/>Y <lb/>tci <lb/>Y <lb/>Migrant <lb/>[SE93] <lb/>sim <lb/>exe <lb/>u <lb/>Y <lb/>N <lb/>Y <lb/>Y <lb/>scc+emu <lb/>Y <lb/>Mimic <lb/>[May87] <lb/>sim <lb/>exe <lb/>u <lb/>N <lb/>N <lb/>N <lb/>N <lb/>dcc <lb/>N <lb/>MINT <lb/>[VF94] <lb/>atr <lb/>exe <lb/>u <lb/>N <lb/>Y1 <lb/>Y <lb/>N <lb/>pdi+dcc <lb/>Y * <lb/>Moxie <lb/>[CHKW86] <lb/>sim <lb/>exe <lb/>u <lb/>N <lb/>N <lb/>Y <lb/>N <lb/>scc <lb/>N <lb/>MX/Vest <lb/>[SCKMR93] <lb/>sim <lb/>exe <lb/>u <lb/>N <lb/>Y= <lb/>Y <lb/>Y <lb/>scc+gi <lb/>Y <lb/>Purify <lb/>[HJ92] <lb/>db <lb/>exe * <lb/>u <lb/>N <lb/>N <lb/>Y <lb/>N <lb/>aug <lb/>Y <lb/>qp/qpt <lb/>[LB94] <lb/>atr/otr <lb/>exe <lb/>u <lb/>N <lb/>N <lb/>N <lb/>N <lb/>aug <lb/>N <lb/>SELF <lb/>[CUL89] <lb/>sim <lb/>exe <lb/>u <lb/>N <lb/>N <lb/>Y <lb/>Y <lb/>dcc <lb/>Y <lb/>SoftPC <lb/>[Nielsen91] <lb/>sim <lb/>exe <lb/>u(s)d <lb/>N <lb/>N <lb/>Y <lb/>Y <lb/>dcc <lb/>Y <lb/>Spa <lb/>[Irlam93] <lb/>atr <lb/>exe <lb/>u <lb/>N <lb/>N <lb/>S <lb/>Y <lb/>ddi <lb/>N <lb/>SPIM <lb/>[HP93] <lb/>sim/atr <lb/>exe <lb/>u <lb/>N <lb/>N <lb/>Y <lb/>N <lb/>pdi <lb/>Y <lb/>ST-80 <lb/>[DS84] <lb/>sim <lb/>exe <lb/>u <lb/>N <lb/>N <lb/>Y <lb/>Y <lb/>dcc <lb/>Y <lb/>MPtrace <lb/>[EKKL90] <lb/>atr <lb/>asm <lb/>u <lb/>N <lb/>Y= <lb/>S <lb/>N <lb/>aug <lb/>N <lb/>Pixie <lb/>[MIPS86] <lb/>atr <lb/>exe * <lb/>u <lb/>Y <lb/>N <lb/>Y <lb/>N <lb/>aug <lb/>N <lb/>Pixie-II <lb/>[Killian94] <lb/>atr/otr/db <lb/>exe * <lb/>us <lb/>Y <lb/>N <lb/>Y <lb/>S <lb/>scc <lb/>N <lb/>Proteus <lb/>[BDCW91] <lb/>atr <lb/>hll <lb/>u <lb/>N <lb/>Y1 <lb/>N <lb/>S <lb/>aug <lb/>N <lb/>RPPT <lb/>[CMMJS88] <lb/>atr <lb/>hll <lb/>u <lb/>N <lb/>Y1 <lb/>N <lb/>N <lb/>aug <lb/>N <lb/>Titan <lb/>[BKW90] <lb/>atr <lb/>exe <lb/>us <lb/>Y <lb/>N <lb/>Y <lb/>N <lb/>aug <lb/>N <lb/>TRAPEDS <lb/>[SJF92] <lb/>atr <lb/>asm <lb/>us <lb/>Y <lb/>Y= <lb/>S <lb/>N <lb/>aug <lb/>N <lb/>Tango Lite <lb/>[GH92] <lb/>atr <lb/>asm <lb/>u <lb/>N <lb/>Y1 <lb/>N <lb/>S <lb/>aug <lb/>N <lb/>WWT <lb/>[RHLLLW93] <lb/>atr/otr <lb/>exe <lb/>u <lb/>Y <lb/>Y+ <lb/>Y <lb/>N <lb/>emu+aug+ddi <lb/>Y <lb/>Z80MU <lb/>[Baumann86] <lb/>sim <lb/>exe <lb/>u(s) <lb/>N <lb/>N <lb/>Y <lb/>Y <lb/>ddi <lb/>Y <lb/>_ __________________________________________________________________________________________________________________________ <lb/>Shade <lb/>[CK93] <lb/>sim/atr/otr/tb C <lb/>exe <lb/>u <lb/>N <lb/>N <lb/>Y <lb/>Y <lb/>dcc <lb/>N <lb/>_ __________________________________________________________________________________________________________________________ <lb/>
            Table 5. Summary of some related systems <lb/>studying the behavior of other translation tools (compilers, etc.). <lb/>Consuming assembly code (asm) is less portable than a high-level <lb/>language but can provide more detailed information. To the ex-<lb/>tent that assembly languages are similar, such tools may be rela-<lb/>tively easy to retarget, though detailed information may still be <lb/>obscured. Finally, using executable code as input (exe) frees the <lb/>user from needing access to the source and the (possibly complex) <lb/>build process. However, information is usually reported in <lb/>machine units, not source constructs. Some tools use symbol <lb/>table information to report trace information symbolically. Others <lb/>also need symbolic information to perform translation (exe * ). <lb/>Detail describes how much of the machine is simulated. Most <lb/>tools work with only user-level code (u); some also run system-<lb/>level code (s); and system mode simulation generally requires <lb/>device emulation (d). Some target machines have no system <lb/>mode, so simulation can avoid the costs of address translation and <lb/>protection checks; these machines have the system mode marked <lb/>in parenthesis. <lb/>MD reports whether the tool supports multiple protection domains <lb/>and multitasking (multiple processes per target processor). This <lb/>usually implies support for system mode operation and address <lb/>translation. Target systems that multitask in a single protection <lb/>domain are listed as N. MP tells whether the tool supports multi-<lb/>ple processor execution; Y1 indicates that the tool uses a single <lb/>host processor, Y= indicates that the tool runs as many target pro-<lb/>cessors as host processors, Y+ that it can run more target proces-<lb/>sors than host processors. Simulating a multiprocessor generally <lb/>introduces additional slowdown at least as big as the number of <lb/>target processors divided by the number of host processors. <lb/>Supporting signals is generally difficult since execution can be in-<lb/>terrupted at any instruction and resumed at any other instruction, <lb/>but analysis and instrumentation may use groups of instructions to <lb/>improve simulation efficiency. The Signals column is Y for tools <lb/>that can handle asynchronous and exceptional events. S indicates <lb/>that the tool is able to deal with some but not all aspects; for ex-<lb/>ample, signals may be processed so the program&apos;s results are <lb/>correct, but no address trace information is generated. <lb/>SMC OK describes whether the tool is able to operate on pro-<lb/>grams where the instruction space changes dynamically. Dynam-<lb/>ic linking is the most common reason, but there are a number of <lb/>other uses [KEH91]. Static rewrite tools can sometimes (S) link <lb/>dynamically to statically-rewritten code, but the dynamically-<lb/>formed link can&apos;t be rewritten statically and thus may go untraced. <lb/>Technology describes the general implementation techniques used <lb/>in the tool [Pittman87]. An &quot;obvious&quot; implementation executes <lb/>programs by fetching, decoding, and then interpreting each in-<lb/>struction in isolation. Most of the implementations optimize by <lb/>predecoding and then caching the decoded result; by translating to <lb/>host code to make direct use of the host&apos;s prefetch and decode <lb/>hardware [DS84]; and by executing target instructions in the con-<lb/>text of their neighbors so that target state (e.g. simulated registers) <lb/>can be accessed efficiently (e.g. from host registers) across target <lb/>instruction boundaries. The implementations are: <lb/>â¢ Hardware emulation including both dedicated hardware and mi-<lb/>crocode (emu). <lb/>â¢ The &quot;obvious&quot; implementation, a decode and dispatch inter-<lb/>preter (ddi). <lb/>â¢ Predecode interpreters (pdi) that pre-convert to a quick-to-<lb/>decode intermediate representation. The IR can be many <lb/>forms; a particularly fast, simple, and common form is threaded <lb/>code (tci). <lb/>_____________________________________________________________________________________________________________ <lb/>Translation <lb/>Performance <lb/>Name <lb/>Reference(s) <lb/>Units <lb/>Assumptions <lb/>(Slowdown) <lb/>Notes <lb/>_____________________________________________________________________________________________________________ _____________________________________________________________________________________________________________ <lb/>
            Accelerator <lb/>[AS92] <lb/>ebb <lb/>nr, bo, ph, regs <lb/>3 <lb/>pages <lb/>dis+mod+run <lb/>[FC88] <lb/>bb <lb/>nr <lb/>10 <lb/>Executor <lb/>[Hostetter93] <lb/>proc <lb/>nr <lb/>10 <lb/>mixed code <lb/>g88 <lb/>[Bedichek90] <lb/>i <lb/>nr, bo <lb/>30 <lb/>pages <lb/>gsim <lb/>[Magnusson93, Magnusson94] bb <lb/>nr, bo <lb/>30 <lb/>pages <lb/>Mable <lb/>[DLHH93] <lb/>i <lb/>20-80 <lb/>mg88 <lb/>[Bedichek94] <lb/>i <lb/>nr, bo <lb/>80 <lb/>pages <lb/>Migrant <lb/>[SE93] <lb/>ebb <lb/>nr,bo <lb/>â <lb/>Mimic <lb/>[May87] <lb/>ebb <lb/>nr, bo, regs <lb/>4 <lb/>no fp, no align, +compile <lb/>Moxie <lb/>[CHKW86] <lb/>bb <lb/>nr <lb/>2 <lb/>MX/Vest <lb/>[SCKMR93] <lb/>ip <lb/>bo <lb/>2 <lb/>mixed code, fp prec <lb/>SELF <lb/>[CUL89] <lb/>ip <lb/>none <lb/>N/A <lb/>VM spec <lb/>SoftPC <lb/>[Nielsen91] <lb/>10 <lb/>SPIM <lb/>[HP93] <lb/>i <lb/>nr, bo <lb/>25 <lb/>ST-80 <lb/>[DS84] <lb/>proc <lb/>none <lb/>N/A <lb/>VM spec <lb/>Z80MU <lb/>[Baumann86] <lb/>i <lb/>nr, bo, regs <lb/>â <lb/>mixed code <lb/>_____________________________________________________________________________________________________________ <lb/>3-6 <lb/>same machine <lb/>Shade <lb/>[CK93] <lb/>ebb <lb/>nr, bo <lb/>8-15 <lb/>different machines (tracing off) <lb/>_____________________________________________________________________________________________________________ <lb/>Table 6. Summary of some cross-architecture simulators <lb/>â¢ Static cross-compilation (scc) which decodes and dispatches <lb/>during cross-compilation, avoiding essentially all runtime <lb/>dispatch costs. As a special case, where the host and target are <lb/>the same, the static compiler merely annotates or augments <lb/>(aug) the original program with code to save trace data or emu-<lb/>late missing instructions. Note that conversion is limited by <lb/>what the tool can see statically. For example, dynamic linking <lb/>may be hard to instrument statically. Limited static information <lb/>also limits optimization. For example, a given instruction may <lb/>in practice never be a branch target, but proving that is often <lb/>hard, so the static compiler may be forced to produce overly-<lb/>conservative code. <lb/>â¢ Dynamic cross-compilation (dcc) is performed at runtime and <lb/>thus can work with any code including dynamically-linked li-<lb/>braries. Also, dynamic cross-compilers can perform optimistic <lb/>optimizations and recompile if the assumptions were too strong <lb/>[Johnston79, SW79, May87, HCU91, CK93]. However, since the <lb/>compiler is used at run time, translation must be fast enough <lb/>that the improved performance more than pays for the overhead <lb/>of dynamic compilation [KEH91]; in addition, code quality may <lb/>be worse than that of a static cross-compiler [AS92, SCKMR93] <lb/>since dynamic code analysis may need to &quot;cut corners&quot; in order <lb/>to minimize the compiler&apos;s running time. <lb/>Where interpreter specifics are unavailable the tool is listed as us-<lb/>ing a general interpreter (gi). Many tools listed as aug and emu <lb/>execute most instructions using host hardware. <lb/>Note that input forms lacking symbolic information -exe espe-<lb/>cially -can be hard to process statically because static tools have <lb/>trouble determining what is code and what is data and also have <lb/>trouble optimizing over multiple host instructions [May87, LB94]. <lb/>By contrast, tools that perform dynamic analysis (including both <lb/>interpreters and dynamic cross-compilers) can discover the <lb/>program&apos;s structure during execution. Translation techniques can <lb/>be mixed by using one technique optimistically for good perfor-<lb/>mance and another as a fallback when the first fails. However, <lb/>such implementations have added complexity because they rely <lb/>on having two translators [AS92, SCKMR93, Magnusson94, VF94]. <lb/>Bugs OK describes whether the tool is robust in the face of appli-<lb/>cation errors such as memory addressing errors or divide-by-zero <lb/>errors. Typically, a simulator that checks for addressing errors re-<lb/>quires extra checks on every instruction that writes memory. In <lb/>some systems the checks are simple range checks; tools that sup-<lb/>port multiple address spaces and sparse address spaces generally <lb/>require full address translation [Bedichek90]. Y * indicates that <lb/>checking can be turned on but performance is worse. <lb/>6.2. Cross-Architecture Simulation <lb/>Table 6 summarizes various features of tools that are used for <lb/>cross-architecture simulation. The Translation Units column <lb/>shows translation-time tradeoffs between analysis complexity and <lb/>performance. Assumptions shows assumptions about the relation-<lb/>ship between the host and target machines; these assumptions are <lb/>usually used to simplify and speed the simulator. Performance <lb/>shows the approximate slowdown of each tool compared to native <lb/>execution. Notes shows special or missing features of each simu-<lb/>lator. The columns are described in detail below. <lb/>Translation units are the number of (target) instructions that are <lb/>translated at a time. Using bigger chunks reduces dispatching <lb/>costs and increases opportunities for optimization between target <lb/>instructions. Larger translation units also typically require better <lb/>analysis or dynamic flexibility in order to ensure that the program <lb/>jumps always take a valid path [May87, SCKMR93, LB94]. Trans-<lb/>lation units include: individual instructions (i), basic blocks (bb), <lb/>extended basic blocks with a single entry but many exits (ebb), <lb/>procedural (proc), or interprocedural (ip). <lb/>
            Assumptions describes assumptions that a tool makes about the <lb/>relationship between the host and target machines, including byte <lb/>ordering (bo); numeric representation (nr), including size and for-<lb/>mat; the number of registers on the host and target machines <lb/>(regs), and access to the host machine&apos;s privileged hardware (ph) <lb/>in order to implement system-level simulation. <lb/>Performance is an estimate of the number of (simple) instruc-<lb/>tions executed per (simple) simulated instruction. N/A indicates <lb/>&quot;not applicable&quot; because the target is a virtual machine. A dash <lb/>(â) indicates unknown or unreported performance. These esti-<lb/>mates are necessarily inexact because performance for the dif-<lb/>ferent tools is reported in different ways. <lb/>Notes describes particular features: pages for detailed memory <lb/>simulation; no fp for simulation that omits floating-point numbers; <lb/>fp prec for simulation that can be set either to run fast or to faith-<lb/>fully emulate the target machine; no align for tools that omit <lb/>simulation of unaligned accesses; +compile for dynamic com-<lb/>pilers where compile time is not included in the performance but <lb/>where it would likely have a large effect; VM spec for tools that <lb/>emulate a virtual machine that has been designed carefully to im-<lb/>prove portability and simulation speed; mixed code for simulators <lb/>that can call between host and target code so that the application <lb/>can, e.g., dynamically link fast-running host-code libraries. <lb/>6.3. Comparison <lb/>Shade improves over many other tools by simulating important <lb/>machine features such as signals and dynamic linking. It im-<lb/>proves over many dynamic compilation tools by using techniques <lb/>that reduce simulation overhead while maintaining the flexibility <lb/>and code quality of dynamic compilation. It improves over many <lb/>tracing tools by dynamically integrating cross-simulation and trac-<lb/>ing code so that it can trace dynamically-linked code, can handle <lb/>dynamic changes in tracing level, and yet can still save detailed <lb/>trace information efficiently. <lb/>Most tools avoid cross-architecture execution or omit some <lb/>machine features. These choices improve execution efficiency but <lb/>limit the tool&apos;s applicability. Some exceptions are g88 deriva-<lb/>tives [Bedichek90, Magnusson93, Bedichek94, Magnusson94] which <lb/>are somewhat less efficient than Shade and also Accelerator <lb/>
            [AS92] and MX/Vest [SCKMR93] which do not perform any trac-<lb/>ing and which use two translators, one optimistic and one conser-<lb/>vative, to achieve high efficiency. Shade supports cross-<lb/>architecture execution, and faithfully executes important machine <lb/>features such as signals and self-modifying code (and thus dynam-<lb/>ic linking), so it can be used on a wide variety of applications. <lb/>Simulators that use dynamic compilation are typically flexible and <lb/>the compiled code performs well. However, many previous sys-<lb/>tems have imposed limitations that Shade eliminates. For exam-<lb/>ple, Mimic&apos;s compiler [May87] produces high-quality code, but at <lb/>such an expense that overall performance is worse than Shade; <lb/>Shade reduces compilation overhead by allowing multiple transla-<lb/>tions per application instruction, by using chaining to reduce the <lb/>cost of branches, and using a TLB to minimize the space overhead <lb/>of branches. MINT [VF94] is unable to simulate changing code <lb/>and never reclaims space used by inactive translations. <lb/>Tracing tools typically produce only address traces, and often run <lb/>only on the machine for which the trace is desired. Even tools <lb/>that allow cross-architecture simulation tend to limit the generali-<lb/>ty of the machine simulation or of the tracing facilities in order to <lb/>maintain efficiency [FC88, HP93]. Shade supports cross-<lb/>architecture tracing and simulates user-mode operation in detail. <lb/>It currently lacks kernel-mode tracing facilities provided by some <lb/>other tools though some of these tools limit machine features <lb/>and/or require hand-instrumentation of key kernel code. Shade <lb/>collects more trace information than most other tools, though it <lb/>lacks the timing-level simulation of mg88 [Bedichek94]. With <lb/>Shade, the analyzer can select the amount of trace data that it col-<lb/>lects, and analyzers that consume little trace data pay little tracing <lb/>overhead. Thus, it is typically the analysis tools that limit overall <lb/>performance. <lb/>Of the tool building tools listed, all permit extended tracing; <lb/>Shade provides the most efficient yet variable extensibility, and <lb/>only Shade also inlines common trace operations. Shade <lb/>analyzers have used both C and C++ as the extension language <lb/>[NG88]. We note also that although Shade is not designed for de-<lb/>bugging, Shade-V9.V8 has been used as the back end of a de-<lb/>bugger [Evans92]. <lb/>Shade&apos;s flexibility and performance does come at a penalty. For <lb/>example, Shade performs inter-instruction analysis and host code <lb/>generation; this makes Shade more complex and less portable <lb/>than, e.g., g88. Shade also presently lacks multiprocessor and <lb/>kernel mode; supporting them would make Shade slower since <lb/>they complicate simulation (e.g. with address translation on loads <lb/>and stores) and would increase translated code size. <lb/>7. Conclusions <lb/>Shade is a custom trace generator that is both fast and flexible, <lb/>providing the individual features of other tracing tools together in <lb/>one tool. Shade achieves its flexibility by using dynamic compila-<lb/>tion and caching, and by giving analyzers detailed control over <lb/>data collection. Thus analyzers pay for only the data they use. <lb/>Since Shade is fast, analyzers can recreate traces on demand in-<lb/>stead of using large stored traces. Shade&apos;s speed also enables the <lb/>collection and analysis of realistically long traces. Finally, Shade <lb/>simulates many machine details including dynamic linking, asyn-<lb/>chronous signals and synchronous exceptions. By providing a de-<lb/>tailed simulation and by freeing the user from preprocessing steps <lb/>that require source code and complicated build procedures, Shade <lb/>satisfies a wide variety of analysis needs in a single tool. <lb/></body>

			<div type="acknowledgement">8. Acknowledgements <lb/>Shade owes much to its predecessors, particularly its immediate <lb/>predecessor Shadow, which was created by Peter Hsu [Hsu89]. <lb/>Robert Cmelik developed Shade, with numerous suggestions from <lb/>David Keppel. Steve Richardson, Malcolm Wing, and others in <lb/>the Shade user community provided useful user interface feed-<lb/>back and helped debug Shade. Robert Bedichek, Alex Klaiber, <lb/>Peter Magnusson and the anonymous SIGMETRICS referees <lb/>gave helpful comments on earlier versions of this paper. Finally, <lb/>authors of many of the systems in the related work section went <lb/>out of their way to help us understand their tools; we apologize <lb/>for errors and omissions. This work was supported by Sun Mi-<lb/>crosystems, NSF #CDA-8619-663 and NSF PYI #MIP-9058-439. <lb/></div>

			<listBibl>References <lb/>[AS92] Kristy Andrews and Duane Sand, &quot;Migrating a CISC <lb/>Computer Family onto RISC via Object Code Translation,&quot; <lb/>Proc. of the Fifth International Conference on Architectural <lb/>Support for Programming Languages and Operating Systems <lb/>(ASPLOS-V), 213-222, Oct. 1992. <lb/>[ASH86] Anant Agarwal, Richard L. Sites, and Mark Horowitz, <lb/>&quot;ATUM: A New Technique for Capturing Address Traces Us-<lb/>ing Microcode,&quot; Proc. of the 13th International Symposium on <lb/>Computer Architecture, 119-127, Jun. 1986. <lb/>[Baumann86] Robert A. Baumann, &quot;Z80MU,&quot; Byte, 203-216, <lb/>Oct. 1986. <lb/>[BDCW91] Eric A. Brewer, Chrysanthos N. Dellarocas, Adrian <lb/>Colbrook, and William E. Weihl, &quot;PROTEUS: A High-<lb/>Performance Parallel-Architecture Simulator,&quot; MIT/LCS/TR-<lb/>516, Massachusetts Institute of Technology, 1991. <lb/>[Bedichek90] Robert Bedichek, &quot;Some Efficient Architecture <lb/>Simulation Techniques,&quot; Winter 1990 USENIX Conference, <lb/>Jan. 1990. <lb/>[Bedichek94] Robert Bedichek, &quot;The Meerkat Multicomputer: <lb/>Tradeoffs in Multicomputer Architecture,&quot; Doctoral Disserta-<lb/>tion, University of Washington Department of Comp. Sci. and <lb/>Eng., 1994 (in preparation). <lb/>[BKW90] Anita Borg, R. E. Kessler, and David W. Wall, &quot;Gen-<lb/>eration and Analysis of Very Long Address Traces,&quot; Proc. of <lb/>the 17th Annual Symposium on Computer Architecture, 270-<lb/>279, May 1990. <lb/>[CHKW86] F. Chow, M. Himelstein, E. Killian, and L. Weber, <lb/>&quot;Engineering a RISC Compiler System,&quot; IEEE COMPCON, <lb/>Mar. 1986. <lb/>[CK93] Robert F. Cmelik and David Keppel, &quot;Shade: A Fast <lb/>Instruction-Set Simulator for Execution Profiling,&quot; SMLI 93-<lb/>12, UWCSE 93-06-06, Sun Microsystems Laboratories, Inc., <lb/>and the University of Washington, 1993. <lb/>[Cmelik93] Robert F. Cmelik, The Shade User&apos;s Manual, Sun <lb/>Microsystems Laboratories, Inc., Feb. 1993. <lb/>[CMMJS88] R. C. Covington, S. Madala, V. Mehta, J. R. Jump, <lb/>and J. B. Sinclair, &quot;The Rice Parallel Processing Testbed,&quot; <lb/>ACM SIGMETRICS, 4-11, 1988. <lb/>[CUL89] Craig Chambers, David Ungar, and Elgin Lee, &quot;An <lb/>Efficient Implementation of SELF, a Dynamically-Typed <lb/>Object-Oriented Language Based on Prototypes,&quot; OOPSLA &apos;89 <lb/>Proceedings, 49-70, Oct. 1989. <lb/>[DLHH93] Peter Davies, Philippe LaCroute, John Heinlein, and <lb/>Mark Horowitz, &quot;Mable: A Technique for Efficient Machine <lb/>Simulation,&quot; (to appear), Quantum Effect Design, Inc., and <lb/>Stanford University. <lb/>[DS84] Peter Deutsch and Alan M. Schiffman, &quot;Efficient Imple-<lb/>mentation of the Smalltalk-80 System,&quot; 11th Annual Symposi-<lb/>um on Principles of Programming Languages, 297-302, Jan. <lb/>1984. <lb/>[EKKL90] Susan J. Eggers, David Keppel, Eric J. Koldinger, <lb/>and Henry M. Levy, &quot;Techniques for Efficient Inline Tracing <lb/>on a Shared-Memory Multiprocessor,&quot; ACM SIGMETRICS, <lb/>37-47, May 1990. <lb/>[Evans92] Doug Evans, Personal comm., Dec. 1992. <lb/>[FC88] Richard M. Fujimoto and William B. Campbell, <lb/>&quot;Efficient Instruction Level Simulation of Computers,&quot; Tran-<lb/>sactions of The Society for Computer Simulation, 5(2): 109-<lb/>124, 1988. <lb/>[GH92] Stephen R. Goldschmidt and John L. Hennessy, &quot;The <lb/>Accuracy of Trace-Driven Simulations of Multiprocessors,&quot; <lb/>CSL-TR-92-546, Stanford University Computer Systems La-<lb/>boratory, Sep. 1992. <lb/>[HCU91] Urs H&quot; olzle, Craig Chambers, and David Ungar, &quot;Op-<lb/>timizing Dynamically-Typed Object-Oriented Languages With <lb/>Polymorphic Inline Caches,&quot; Proc. of the European Conference <lb/>on Object-Oriented Programming (ECOOP), Jul. 1991. <lb/>[HJ92] Reed Hastings and Bob Joyce, &quot;Purify: Fast Detection of <lb/>Memory Leaks and Access Errors,&quot; Proc. of the Winter Usenix <lb/>Conference, 125-136, Jan. 1992. <lb/>[Hostetter93] Mat Hostetter, Personal comm., Jul. 1993. <lb/>[HP93] John Hennessy and David Patterson, Computer Organi-<lb/>zation and Design: The Hardware-Software Interface (Appen-<lb/>dix A, by James R. Larus), Morgan Kaufman, 1993. <lb/>[Hsu89] Peter Hsu, Introduction to Shadow, Sun Microsystems, <lb/>Inc., 28 Jul. 1989. <lb/>[Irlam93] Gordon Irlam, Personal comm., Feb. 1993. <lb/>[James90] David James, &quot;Multiplexed Busses: The Endian Wars <lb/>Continue,&quot; IEEE Micro Magazine, 9-22, Jun. 1990. <lb/>[Johnston79] Ronald L. Johnston, &quot;The Dynamic Incremental <lb/>Compiler of APL\3000,&quot; APL Quote Quad, 9(4): 82-87, Asso-<lb/>ciation for Computing Machinery (ACM), Jun. 1979. <lb/>[Kane87] Gerry Kane, MIPS R2000 RISC Architecture, <lb/>Prentice-Hall, Englewood Cliffs, New Jersey, 1987. <lb/>[KEH91] David Keppel, Susan J. Eggers, and Robert R. Henry, <lb/>&quot;A Case for Runtime Code Generation,&quot; University of Wash-<lb/>ington Comp. Sci. and Eng. UWCSE TR 91-11-04, Nov. 1991. <lb/>[Keppel91] David Keppel, &quot;A Portable Interface for On-The-Fly <lb/>Instruction Space Modification,&quot; Proc. of the 1991 Symposium <lb/>on Architectural Support for Programming Languages and <lb/>Operating Systems (ASPLOS-IV), 86-95, Apr. 1991. <lb/>[Killian94] Earl Killian, Personal comm., Feb. 1994. <lb/>[LB94] James R. Larus and Thomas Ball, &quot;Rewriting Executable <lb/>Files to Measure Program Behavior,&quot; Software â Practice and <lb/>Experience, 24(2): 197-218, Feb. 1994. <lb/>[Magnusson93] Peter S. Magnusson, &quot;A Design For Efficient <lb/>Simulation of a Multiprocessor,&quot; Proc. of the First Internation-<lb/>al Workshop on Modeling, Analysis, and Simulation of Com-<lb/>puter and Telecommunication Systems (MASCOTS), La Jolla, <lb/>California, Jan. 1993. <lb/>[Magnusson94] Peter S. Magnusson, &quot;Partial Translation,&quot; <lb/>Swedish Institute of Computer Science, Mar. 1994. <lb/>[May87] Cathy May, &quot;Mimic: A Fast S/370 Simulator,&quot; Proc. of <lb/>the ACM SIGPLAN 1987 Symposium on Interpreters and Inter-<lb/>pretive Techniques; SIGPLAN Notices, 22(6): 1-13, Jun. 1987. <lb/>[MIPS86] MIPS, Languages and Programmer&apos;s Manual, MIPS <lb/>Computer Systems, Inc., 1986. <lb/>[NG88] David Notkin and William G. Griswold, &quot;Extension and <lb/>Software Development,&quot; Proc. of the 10th International <lb/>Conference on Software Engineering, 274-283, April 1988. <lb/>[Nielsen91] Robert D. Nielsen, &quot;DOS on the Dock,&quot; NeXTWorld, <lb/>50-51, Mar./Apr. 1991. <lb/>[Pittman87] <lb/>Thomas <lb/>Pittman, <lb/>&quot;Two-Level <lb/>Hybrid <lb/>Interpreter/Native Code Execution for Combined Space-Time <lb/>Program Efficiency,&quot; ACM SIGPLAN Symposium on Inter-<lb/>preters and Interpretive Techniques, 150-152, Jun. 1987. <lb/>[Ramsey93] Norman Ramsey, Personal comm., Jun. 1993. <lb/>[RHLLLW93] S. K. Reinhardt, M. D. Hill, J. R. Larus, A. R. <lb/>Lebeck, J. C. Lewis, and D. A. Wood, &quot;The Wisconsin Wind <lb/>Tunnel: Virtual Prototyping of Parallel Computers on Measure-<lb/>ment and Modeling of Computer Systems,&quot; ACM SIG-<lb/>METRICS, 48-60 , Jun. 1993. <lb/>[Richardson92] Stephen E. Richardson, &quot;Caching Function <lb/>Results: Faster Arithmetic by Avoiding Unnecessary Computa-<lb/>tion,&quot; SMLI TR92-1, Sun Microsystems Laboratories, Inc., <lb/>Sep. 1992. <lb/>[SCKMR93] Richard L. Sites, Anton Chernoff, Matthew B. <lb/>Kerk, Maurice P. Marks, and Scott G. Robinson, &quot;Binary <lb/>Translation,&quot; CACM, 36(2): 69-81, Feb. 1993. <lb/>[SE93] Gabriel M. Silberman and Kemal Ebcioglu, &quot;An Archi-<lb/>tectural Framework for Supporting Heterogeneous Instruction-<lb/>Set Architectures,&quot; IEEE Computer, 39-56, Jun. 1993. <lb/>[SE94] Amitabh Srivastava and Alan Eustace, &quot;ATOM: A Sys-<lb/>tem for Building Customized Program Analysis Tools,&quot; Proc. <lb/>of the 1994 ACM Conference on Programming Language <lb/>Design and Implementation (PLDI), 1994 (to appear). <lb/>[SJF92] Craig B. Stunkel, Bob Janssens, and W. Kent Fuchs, <lb/>&quot;Address Tracing of Parallel Systems via TRAPEDS,&quot; Mi-<lb/>croprocessors and Microsystems, 16(5): 249-261, 1992. <lb/>[SosiÄ92] Rok SosiÄ, &quot;Dynascope: A Tool for Program Direct-<lb/>ing,&quot; Proc. of the 1992 ACM Conference on Programming <lb/>Language Design and Implementation (PLDI), 12-21, Jun. <lb/>1992. <lb/>[SPARC9] &quot;The SPARC Architecture Manual, Version Nine,&quot; <lb/>SPARC International, Inc., 1992. <lb/>[SunOS4] SunOS Reference Manual, Sun Microsystems, Inc., <lb/>Mar. 1990. <lb/>[SunOS5] SunOS 5.0 Reference Manual, SunSoft, Inc., Jun. <lb/>1992. <lb/>[SW79] H. J. Saal and Z. Weiss, &quot;A Software High Performance <lb/>APL Interpreter,&quot; APL Quote Quad, 9(4): 74-81, Jun. 1979. <lb/>[UMIPSV] UMIPS-V Reference Manual, MIPS Computer Sys-<lb/>tems, Inc., 1990. <lb/>[VF94] Jack E. Veenstra and Robert J. Fowler, &quot;MINT: A Front <lb/>End for Efficient Simulation of Shared-Memory Multiproces-<lb/>sors,&quot; Proc. of the Second International Workshop on Model-<lb/>ing, Analysis, and Simulation of Computer and Telecommuni-<lb/>cation Systems (MASCOTS), 201-207, Jan. 1994. </listBibl>


	</text>
</tei>
