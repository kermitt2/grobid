<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="_0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>A Neural Network for Attentiond Spotlight <lb/>W e e Kheng Leowti and Risto Miikkulainent <lb/>tDept. of Computer Sciences, Univ. of Texas at Austin, <lb/>Aust,in, Texas 78712, USA, and <lb/>$Microelectronics and Computer Technology Corporation, <lb/>3500 W. Balcones Center Dr., Austin, Texas 78759, USA. <lb/>leow@cs.utexas.edu, risto@cs.utexas.edu <lb/>Abstract <lb/>According to space-based theory, visual attention is limited to a local region in space called the <lb/>attentional field. Visual information within the attentional field is enhanced for further processing <lb/>while information outside is suppressed. There is evidence that enhancement and suppression are <lb/>achieved with dynamic weighting of network activity. This paper discusses a neural network that <lb/>generates the appropriate weights, called the otfentional spotlight, given the size and the position of <lb/>the intended attentional field. The network has three layers. A hmtingfeedback network serves as the <lb/>output layer and performs a critical task whirh cannot be accomplished by feedforward networks. <lb/></front>

			<body>1 Introduction <lb/>Selective visual attention is an important mechanism in human visual system. Wit,h visual attention, the <lb/>system can allocate its limited rrsources to the processing of the most import.ant visual information and <lb/>avoid getting overwhelmed by unimportant information. Psychological experimenh indicate that attention <lb/>can be directed to different parts of a stimulns and attention shift is independent of the movement of the <lb/>eyes. In other words, visual attention is a different process from visual saccade. <lb/>There are two complementary psychological models of human visual attentmion. According to object-<lb/>based model (Treisman et al., 1983; Duncan, 1984). visual at.tention is always focused on a single object <lb/>or a coherent group of visual information. In space-based model (Eriksen and Yeh, 1985; Eriksen and <lb/>St. James, 1986; Anderson, 1990), visual attention is focused on a region localized in space known as <lb/>the attentional field. Information within t,he attent,ional field is enhanced for further processings, whereas <lb/>information outside is largely suppressed and ignored. There is neurophysiological evidence that selective <lb/>enhancement and suppression are arhieved by a gating mechanism that dynamically weights the inputs to <lb/>neurons (Moran and Desimone, 1985; LaBerge, 1990). There is also evidence that the position and the size <lb/>of the attentional field may vary according to the nature of the visual stimuli and the visual tasks, as well <lb/>as subject&apos;s expectations, etc. (Eriksen and Yeh, 1985; Eriksen and St. James, 1986) <lb/>Several mechanisms for visual attention have been proposed (Ahmad and Omohundro, 1990; Mozer and <lb/>Behrmann, 1990; Sandon, 1990). The mechanism of Mozer and Behrmann uses an optimization process to <lb/>form a continuous region (not necessarily local) of neural act,ivities consistent with bottom-up inputs and <lb/>top-down information about objects. Activities outside t.he region are suppressed. In Sandon&apos;s system, <lb/>inputs compete locally for attention. These systems are more compatible with the object-based model. On <lb/>the other hand, the attention mechanism of Ahmad and Omohundro is consistent with the space-based <lb/>model. In their system, neural units are laid out in a retinotopic map. Each unit receives the values of the <lb/>size and the coordinates of the intended attentional field. and computes an appropriate weighting factor <lb/>for its retinotopic position. Explicit representation of coordinates in the input values and unit activities <lb/>has two shortcomings. First, biological visual systems do not appear to encode coordinates explicitly. <lb/>Instead, they represent positions by the locations of active cells in retinotopic maps, i.e. by value-unit <lb/>encoding (Ballard, 1987). Second, explicit encoding may be problematic for hardware implementation. <lb/></body>

			<front>Authorized licensed use limited to: European Patent Office. Downloaded on July 10, 2009 at 04:34 from IEEE Xplore. Restrictions apply. <lb/></front>

			<body>The operational range and precision of devices&apos; determine the maximum number of locations that can be <lb/>encoded, which in turn limits the size of the largest map. Judging by the number of neurons in biological <lb/>map and the amount of noise in neural activity, one may speculate that valueunit encoding could well <lb/>be nature&apos;s solution to the hardware prohlem. Our network encodes position with value-units and size <lb/>explicitly. Explicit encoding of size is acceptable because the largest possible attentional field depends on <lb/>the largest amount of information that can be processed in parallel, instead of the size of the input layer. <lb/>Before describing the network architecture and the simulation results, let us analyze space-based model <lb/>of visual attention from the compiitational perspective. <lb/>2 Computational Model of Space-Based Visual Attention <lb/>Two fundamental processes are involved in spacebased model: the selection of the size and the position <lb/>of the attentional field, and the generation of the appropriate weighting factors. The selection process <lb/>depends on both bottom-up information and topdown knowledge. Psychological research (Eriksen and <lb/>Yeh, 1985; Eriksen and St. James, 1986) suggests t.hat many factors, such as the nature of the visual <lb/>stimuli and the visual tasks, as well as the subject&apos;s expectations, affect the size and the position. After <lb/>deciding on where to focus attention, the selection mechanism passea the information to the generation <lb/>mechanism. The generation mechanism produces appropriate weighting factors that filter the information <lb/>flowing across the modules. Information within the at,tent.ional field is strongly weighted and transmitted <lb/>to the receiving module while other information is suppressed. <lb/>This paper concentrates on the design of the generation mechanism. The computational task can be <lb/>formulated as follows: <lb/>Given the size and the position of the desired at,tentional field, compute the weighting factors <lb/>for space-based visual att,ent,ion. <lb/>We shall call the weighting factors the altentional spotlight.2 A visual system typically consists of modules <lb/>organized in maps. The output units of a module connect to the input units at the corresponding positions <lb/>in another module. The output units of the generation mechanism connect to the pathways between <lb/>modules, weighting the signal flow. Consequent,ly, the generation mechanism is most naturally organized <lb/>in maps as well. This architecture is consistent with neurophysiological mechanism of visual attention <lb/>(Moran and Desimone, 1985; LaRerge, 1990) and is assumed in some of the artificial mechanism discussed <lb/>in Section 1. <lb/>Our generation mechanism has to meet the following implementational requirements as well: <lb/>1. The position of the spotlight is indicated by a positive input value at the desired location and zero <lb/>values elsewhere. <lb/>2. The size of the spotlight increases monotonically with the positive input value. <lb/>3. The strength of the spotlight should be roughly uniform in the central region (information in this <lb/>region is roughly equally important), and should decrease gradually with distance from the center of <lb/>the spotlight (Eriksen and St. James, 1986; Anderson, 1990). In other words, a cr-section <lb/>of the <lb/>spotlight should have approximately a bell-shaped or inverted-U-shaped profile. The position and <lb/>the size of the spotlight are defined respectively as the coordinates of its center and the radius of its <lb/>base. <lb/>Our network is used in a vision system for image understanding. The system extracts features such <lb/>as the strengths and the orientations of intensity contrasts in parallel and encodes them in maps. Based <lb/>on bottom-up features and top-down information, the system focuses its attention on different portions <lb/>of the maps to integrate the features and recognize the objects. This paper only discusses the generation <lb/>mechanism. The selection mechanism and the overall visual system will be reported elsewhere. <lb/> </body>

			<note place="footnote">&apos;All analog devices have a finite range over which they can operate properly. The precision is determined by the errors <lb/>in discretizing analog signals. For digital devices, the operational range and precision are determined by the number of bits <lb/>used in computation. <lb/></note>

			<note place="footnote">&apos;The word spotlight w u d y refers to the apotlight model (Duncan, 1984; Erikeen and St. James, 1986) of visual attention. <lb/>We extend its meaning to refer to the wrighting factors. <lb/></note>

			<page>437 <lb/></page>

			<note place="footnote">Authorized licensed use limited to: European Patent Office. Downloaded on July 10, 2009 at 04:34 from IEEE Xplore. Restrictions apply. <lb/></note>

			<body>n , <lb/>weight distribution W&amp; <lb/>shunting <lb/>feedmck network <lb/>threshold units i <lb/>. , <lb/>(4 <lb/>Iinput I, 0 c I d 1 <lb/>@)<lb/>Figure 1: (a) Network architecture. (b) Weight distribution function Wir. <lb/>3 Network Architecture and Dynamics <lb/>In the following discussion, the network is assumed to he I-D for simplicity and clarity. Extension of the <lb/>network to 2-D is straightforward. <lb/>3.1 Network Architecture <lb/>What is required in a network to produce the bell-shaped profile? The task can be divided into three <lb/>subtasks. Recall that only one of the input units has a positive value while all others have zero values <lb/>(Requirement 1). The first twk is to distrihiite the non-zero input activity over a group of units in the <lb/>next layer (Fig. la). The distrihiition weights W,, should decrease with distance from the center of the <lb/>group. One possible form is the triangular distrihiition (Fig. lb): <lb/>(1) <lb/>1 <lb/>R <lb/>If&apos;,, = --(R -li -kl), 0 5 li -kI 5 R <lb/>where R is a positive constant parameter. In this case, 0 5 W,, 5 1. <lb/>The second task is to enforce the monotonic relationship hetween the radius r of the spotlight and the <lb/>strength of the input Z (Requirement 2). This task is performed by thresholding the distributed activity: <lb/>b, = <lb/>W t r~ -81. <lb/>(2) <lb/>[, <lb/>I &apos; <lb/>where b, and or are activities of threshold unit i and inpiit unit k, respectively; 8, is a global positive <lb/>constant threshold that influences radius r (Ceow and Miikkulainen, 1991), and [ . I + = max(z,O). The <lb/>monotonic relationship is enforced in the following manner. Suppose that input unit c is non-zero, i.e. <lb/>ac = I . Then, the activities of the threshold units are <lb/>b, = [WicI -8-1&apos; <lb/>(3) <lb/>In effect, the threshold 8, cuts the triangular input pattern to produce a triangular output pattern. The <lb/>radius r of the spotlight is identical to the radius of the output pattern, and increases with Z (Fig. 2a). <lb/>The equation of r in terms of I is derived in (Leow and Miikkulainen, 1991). <lb/>The third task is to flatten the central region of the activity pattern. It turns out to be rather tricky <lb/>and a feedback network is required. Feedforward networks cannot perform the task successfully because <lb/>the only possibility is to use units whose activities saturate at large input values. However, for small input <lb/>values, saturation would not occur and a peak would be produced at the center of the spotlight (Leow and <lb/>Miikkulainen, 1991). <lb/>3.2 Shunting Feedback Network <lb/>A shunting feedback network (Grossberg, 1973) consists of units whose outputs feed back to themselves <lb/>(Fig. la). Both the inputs and the feedback are weighted by the activities of the receiving units (hence the <lb/></body>

			<page>438 <lb/></page>

			<note place="headnote">Authorized licensed use limited to: European Patent Office. Downloaded on July 10, 2009 at 04:34 from IEEE Xplore. Restrictions apply. <lb/></note>

			<body>threshold unit activity b, <lb/>I <lb/>large I <lb/>small I <lb/>(9 O w i <lb/>c <lb/>r <lb/>Figure 2: (a) Activities of threshold units bi. (b) Output function f ( e i ) . <lb/>term shunting). The dynamics of the network that we use is given by: <lb/>ei = -Aei + ( R -e i ) f ( e i ) -ei f ( e b ) + bi <lb/>k f i <lb/>(4) <lb/>where e, and b, are the activities of the shunting fwdhack unit and threshold unit, respectively; A and E <lb/>are positive constants, and f ( e , ) is the output function. For the proper operation of the network, the input <lb/>I, and consequently b,, is only switched on very hriefly. After I is switched off (i.e. I = 0), the network <lb/>gradually converges to an equilihriiim state. <lb/>The type of the output function f ( e , ) is critical to the performance of the network (Grossberg, 1973). <lb/>In this case, it has the following form (Fig 2b). <lb/>where D and Do are positive constants with D &gt; Do, and 0, is a positive constant parameter which <lb/>influences the shape of the spotlight ( h o w and Miikkulainen, 1991). f ( e i ) is linear for 0 5 ei &lt; Oe and <lb/>slower-than-linear for Be 5 ei 5 R . With this type of f ( e i ) , two critical values of relative activity determine <lb/>the equilibrium state of the shunting feetlhark layer (Grossherg, 1973). One of them is the uniformitation <lb/>threshold: if all relative activities of the units are above this t,hreshold, then the equilibrium activities will <lb/>be uniform (effect of the slower-than-linear portion of f ( e i ) ) . The other critical value is the fair distribution <lb/>limit: if all relative activities are below this limit,, then they will remain unchanged a t equilibrium (effect <lb/>of the linear portion of f ( e i ) ) . In general, not all relat.ive act,ivities are above the uniformization threshold, <lb/>and not all of them are below the fair distribution limit. In this case, our simulation results suggest <lb/>that somewhere between the critical values, there is a partial uniformitation threshold that combine their <lb/>effects. Relative activities above this threshold (the cent,ral region of the spotlight) become uniform, <lb/>and sub-threshold relative activities (t,lie houndary region) retain their original patterns. Since the fair <lb/>distribution limit can be computed easily (Grossberg, 1973), we use it as the lower bound for the partial <lb/>uniformization threshold. In the simulations, the threshold is adjusted upwards to obtain the desired shape <lb/>for the spotlight. <lb/>The activity of the network is always bounded between 0 and E and normalized. Since ei changes sign <lb/>when ei reaches the bounds (with bi = 0), it prevents ei from getting beyond the hounds. It has also been <lb/>shown that under certain mild condit,ions, the activities can reverberate (i.e. be sustained) indefinitely <lb/>even after the inputs are switched off. When the network reaches an equilibrium state, its total activity is <lb/>automatically normalized to a value that depends on the network parameters and the relative strength of <lb/>the inputs (i.e. bi/ Ci bi). <lb/>The response of the shunting feedback layer is determined by the shape of its initial activity rather <lb/>than the absolute values of its activity. Since its input comes from the threshold units whose output shape <lb/>is independent of the network input I, the shape of its response is the same for all values of I . Hence, the <lb/>peaking effect observed in feedforward network is avoided. A more detailed mathematical treatment of the <lb/>network dynamics is given in (Leow and Miikkulainen, 1991). <lb/></body>

			<page>439 <lb/></page>

			<note place="footnote">Authorized licensed use limited to: European Patent Office. Downloaded on July 10, 2009 at 04:34 from IEEE Xplore. Restrictions apply. <lb/></note>

			<body>(9 <lb/>21 <lb/>I <lb/>Figure 3: Response of shunting feedhark nrt.work. (a)-(d) Transformation of activity through time with <lb/>I = 1.0. (a) t = 0.0, (b) t = 0.2, (c) f = 0.4, (d) t = 0.6. (e)-(h) Spotlights of different radii. (e) I = 0.8, <lb/>t = 0.0; (f) I = 0.8, t = 0.6; (g) I = 0.55, t = 0.0; (h) I = 0.55, t = 0.6. <lb/>4 Simulations <lb/>The spotlight generation network was simulated numerically using forward Euler method with A t = 0.02. <lb/>The threshold parameter 0, of the threshold units (Eq. 2) was set at 0.5. Thus, the smallest spotlight is <lb/>produced with I just above 0.5 (Eqs. 1 and 3). When I 5 0.5, no spotlight is generated since there is no <lb/>activity in the threshold and shunting feedhack layers. I = 1.0 produces the largest spotlight. The other <lb/>parameter values are given in (Leow and Miikkulainen, 1991). <lb/>Simulation results for different values of I are shown in Fig. 3. Figures 3a-d illustrate the transformation <lb/>of the activity of the shunting feedback layer through time. The input 8trengt.h I in this case was 1.0 and <lb/>the radius r of the spotlight was 20. Over time, the central region of the spotlight became roughly uniform <lb/>while the border regions retained their gadrlal decrease in activity. Figure 3 also shows how the radius of <lb/>the spotlight can be controlled through the input strength. For stronger input, the network generates a <lb/>larger spotlight. Note that even when the input is as small as 0.55, the central region of the spotlight is <lb/>still uniform. <lb/>Figure 3 indicates that narrower spotlights are taller. This phenomenon is due to the normalization of <lb/>total activity (Section 3.2), i.e., the area under the curve is the same for different radii. Consequently, the <lb/>relative strength of the spotlight, instead of its absolute strength, should be used in weighting information <lb/>flowing acmw visual modules. If the input layer of the receiving module is a shunting network (feedforward <lb/>or feedback), then it automatically usw the relative input, and renormalization is not required. <lb/>The shape of the spotlight can be changed in several ways. The parameter 0. in the output function <lb/>f(ej) (Eq. 6) has an inverse relationship with the size of the central region (Leow and Miikkulainen, 1991). <lb/>By adjusting Be, we can either expand or reduce the central region compared to the boundary regions. The <lb/>weight distribution function w i k determines the shape of the spotlight at the boundary regions since the <lb/>shape is retained in the spotlight. <lb/>The parameter 0, de0 affects the equilibrium state of the spotlight. If 0, is large enough (about 0.5 in <lb/>our simulation), the spotlight at equilibrium has a flat central region (trapezoidal shape). This observation <lb/>indicates that the partial uniformization threshold indeed exists. If 0. is small, then the equilibrium state <lb/>tends to be uniform, i.e. the (total) uniformisation threshold takes effect. In either case, an intermediate <lb/></body>

			<note place="headnote">Authorized licensed use limited to: European Patent Office. Downloaded on July 10, 2009 at 04:34 from IEEE Xplore. Restrictions apply. <lb/></note>

			<body>state of the spotlight has a curved central region (Fig. 3). An additional gating layer can be added to <lb/>the network to control the gating ftme at which the output of the shunting feedback layer is released. In <lb/>other words, the network can output either the equilibrium state or an intermediate state depending on <lb/>the desired shape of the spotlight. The appropriate gating time can be easily determined in simulation. <lb/>5 Conclusions <lb/>The architecture and dynamics of a neural network that generates an attentional spotlight has been dis-<lb/>cussed. The network has three layers. The drsired position of the spotlight is indicated by activating <lb/>one of the input units. The activity of the unit represents the desired size of the spotlight. A shunting <lb/>feedback network serves as the output layer and produces a spotlight of the desired shape. The spotlight <lb/>has a fixed maximum size (determined by network parameters) which corresponds to the largest amount <lb/>of information that a vision system can procm in parallel. <lb/></body>

			<listBibl>References <lb/>Ahmad, S. and Omohundro, S. (1990). Equilateral trianglrs: A challenge for connectionist vision. In <lb/>Proceedings of 12th Annual Conference of Cognitiue Science Society. <lb/>Anderson, G. J. (1990). Focused attent,ion in three-dimensional space. Perception d Psychophysics, 47:112-<lb/>120. <lb/>Ballard, D. H. (1987). Cortical connections and parallel processing: Structure and function. In Arbib, <lb/>M. A. and Hanson, A. R., edit,ors, Vision, Brain, and Coopemfive Computation, pages 563-621. MIT <lb/>Press. <lb/>Duncan, J. (1984). Selective attent,ion and the organization of visual information. Ezpen&apos;menial Psychology: <lb/>General, 113:501-517. <lb/>Eriksen, C. W. and St. James, J. D. (1986). Visiial att.ention within and around the field of focal attention: <lb/>A zoom lens model. Perception B Psychophysics, 40(1):225-240. <lb/>Eriksen, C. W. and Yeh, Y. Y. (1985). Allocation of attention in the visual field. Ezperimental Psychology: <lb/>Human Perception and Performanre, 11 (5):583-597. <lb/>Grossberg, S. (1973). Contour enhancement, short. term memory, and constancies in reverberating neural <lb/>networks. Studies in Applied Mathemaiirs, 52:217-257. <lb/>LaBerge, D. (1990). Thalamic and cort,ical mechanisms of attention suggested by recent positron emission <lb/>tomographic experiments. Cognitive Neuroscience, 2(1):358-372. <lb/>Leow, W. K. and Miikkulainen, R. (1991). Neural network for attentional spot,light. Technical report, <lb/>Dept. of Computer Sciences, Univ. of Texas at Austin, Austin, TX. <lb/>Moran, J. and Desimone, R. (198.5). Selective attent.ion gates visual processing in the extrastriate cortex. <lb/>Science, 229~782-784. <lb/>Mozer, M. C. and Behrmann, M. (1990). On the interaction of selective attention and lexical knowledge: <lb/>A connectionist account of neglect dyslexia. Cogniiirre Neuroscience, 2(2):96-123. <lb/>Sandon, P. A. (1990). Simulating visual attention. Cognitive Neuroscience, 2(3):213-231. <lb/>Treisman, A. M., Kahneman, D., and Burkell, J. (1983). Perceptual objects and the cost of filtering. <lb/>Perception B Psychophysirs, 33:527-532. <lb/></listBibl>

			<page>441 <lb/></page>

			<note place="footnote">Authorized licensed use limited to: European Patent Office. Downloaded on July 10, 2009 at 04:34 from IEEE Xplore. Restrictions apply. </note>


	</text>
</tei>
