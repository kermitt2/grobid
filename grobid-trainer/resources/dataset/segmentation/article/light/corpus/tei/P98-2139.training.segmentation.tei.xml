<?xml version="1.0" ?>
<tei>
	<teiHeader>
		<fileDesc xml:id="__P98-2139"/>
	</teiHeader>
	<text xml:lang="en">
			<front> Deriving Transfer Rules from Dominance-Preserving Alignments <lb/> Adam Meyers, Roman Yangarber, Ralph Grishman, <lb/>Catherine Macleod, Antonio Moreno-Sandoval t <lb/>New York University <lb/>715 Broadway, 7th Floor, NY, NY 10003, USA <lb/>tUniversidad Aut6noma de Madrid <lb/>Cantoblanco, 28049-Madrid, SPAIN <lb/> meyers/roman/grishman/macleod©cs, nyu. edu <lb/>sandoval©lola, lllf. uam. es <lb/></front>

			<body> 1 Introduction <lb/>Automatic acquisition of translation rules from <lb/>parallel sentence-aligned text takes a variety of <lb/>forms. Some machine translation (MT) systems <lb/>treat aligned sentences as unstructured word se-<lb/>quences. Other systems, including our own ((Gr-<lb/>ishman, 1994) and (Meyers et al., 1996)), syn-<lb/>tactically analyze sentences (parse) before ac-<lb/>quiring transfer rules (cf. (Kaji et hi., 1992), <lb/>(Matsumoto et hi., 1993), and (Kitamura and <lb/>Matsumoto, 1995)). This has the advantage of <lb/>acquiring structural as well as lexical correspon-<lb/>dences. A syntactically analyzed, aligned cor-<lb/>pus may serve as an example base for a form of <lb/>example-based NIT (cf. (Sato and Nagao, 1990), <lb/>(l(aji et al., 1992), and (Furuse and Iida. 1994)). <lb/>This paper 1 describes: (1) an efficient algo-<lb/>rithm for aligning a pair of source/target lan-<lb/>guage parse trees; and (9) a procedure for de-<lb/>riving transfer rules from this alignment. Each <lb/>transfer rule consists of a pair of tree fragments <lb/>derived by &quot;cutting up&quot; the source and target <lb/>trees. A set of transfer rules whose left-hand <lb/>sides match a source language parse tree is used <lb/>to generate a target language parse tree from <lb/>their set of right-hand sides, which is a transla-<lb/>tion of the source tree. This technique resembles <lb/>work on NIT using synchronous Tree-Adjoining <lb/>Grammars (cf. (Abeille et al.. 1990)). <lb/>The Proteus translation system learns transfer <lb/>rules from pairs of aligned source and target  reg-<lb/> ularized parses,  Proteus&apos;s representation of pred-<lb/>icate argument structure (cf. Figure 1). 2 Then <lb/>it uses these transfer rules to map source tan-<lb/></body>

			<div type="acknowledgement">l We thank Cristina Olmeda Moreno for work on pars-<lb/>ing our Spanish text. This research was supported by <lb/> National Science Fotmdation Grant IRI-9303013. <lb/></div>
			
			<note place="footnote">2Regularized parses (henceforth, &quot;parse trees&quot;) are <lb/>like F-structures of Lexical Ftmction Grammar (LFG), <lb/>except, that a dependency structure is used.&quot; <lb/></note>
			
			<body>guage regularized parses generated by our source <lb/>language parser into target language regularized <lb/>parses. Finally a generator converts target reg-<lb/>ularized parses into target language sentences. <lb/>An alignment f is a 1-to-1 partial mapping <lb/>from source nodes to target nodes. We con-<lb/>sider only alignments which preserve the dom-<lb/>inance relationship: If node a dominates node <lb/>b in the source tree, then  f(a)  dominates  f(b) <lb/> in the target tree. In Figure 1. source nodes .4. <lb/>B, C and D map to the corresponding target <lb/>nodes, marked with a prime, e.g.,  f(A) = A&apos;. <lb/> The alignment may be represented by the set <lb/>{(d, A&apos;), (B, B&apos;), (C, C&apos;), (D, D&apos;)}. We can as-<lb/>sign a  score  to each alignment f, based on the <lb/>(weighted) number of pairs in f; finding the best <lb/>alignment translates into finding the alignment <lb/>with the highest score. Our algorithms are based <lb/>on (Farach et al., 1995) and related work. <lb/>We needed efficient alignment algorithms be-<lb/>cause: (1) Corpus-based training requires pro-<lb/>cessing a lot of text; and (2) An exhaustive <lb/>search of all alignments is too computationally <lb/>expensive for realistically sized parse trees. <lb/>Eliminating dominance violations greatly re-<lb/>duced our search space. Similar work (e.g., <lb/>(Matsumoto et hi., 1993)) considers all possible <lb/>matches. Although. our system cannot account <lb/>for actual dominance violations in a given bi-<lb/>text, there are no such violations in our corpus <lb/>and many hypothetical cases can be avoided by <lb/>adopting the appropriate grammar. Cases of ad-<lb/>juncts aligning with heads and vice versa are not <lb/>dominance violations if we replace our depen-<lb/>dency analysis with one in which internal nodes <lb/>have category labels and the head constituents <lb/>are marked by  HEAD  arcs and we assume the <lb/>following Categorial Grammar (CG) style anal-<lb/>yses. Suppose that verb (Vi) maps to adverb <lb/>(A&apos;I) and adverb (A2) maps to verb (V&apos;2), where <lb/>

			<page> 843 <lb/></page>

			SourceTree <lb/> Target Tree <lb/>(&quot;&apos;D= voiver <lb/>~ <lb/> ...................... &quot;~ <lb/> ..... <lb/> iiiiiiii: ...................... <lb/> Excel vuelve a calcular valores en libro de trabajo <lb/>Excel recalculates values in workbook <lb/> Figure l:  A  Pair of Aligned Trees <lb/>A2 modifies V1 and A&apos;l modifies V&apos;2. We as-<lb/>sume the following structures: [VP [VP1 V1 ...] <lb/>A2] and [VP [VP2 V&apos;2...] A&apos;I]. No dominance <lb/>violation exists because no dominance relation <lb/>holds between VI and A2 or V&apos;2 and A&apos;L Y. <lb/>Matsumoto (p.c.) notes that the subordinate <lb/>clause of a source sentence may align with the <lb/>main clause of a target language and vice versa, <lb/>e.g.,  X after Y  aligns with Y&apos;  before X&apos;.  where <lb/>X, X&apos;, Y and Y&apos; are all clauses. Assuming a CG <lb/>style analysis, [S X [after Y]] aligns with [S Y&quot; <lb/>[before X&apos;]] with no dominance violations. <lb/>2 The Least-Common-Ancestor <lb/>Constraint <lb/>Our earlier tree alignment algorithms (cf. (Mey-<lb/>ers et al., 1996)) were designed to produce align-<lb/>ments which preserve the least common ancestor <lb/>relationship: If nodes a and b map into nodes <lb/> a&apos; = f(a)  and b&apos; =  f(b),  then  f(LCA(a,b)) = <lb/>LCA(f(a), f(b)) = LCA(a&apos;, b&apos;).  The least com-<lb/>mon ancestor (LCA) of a and b is the lowest node <lb/>in the tree dominating both a and b. The LCA-<lb/>preserving approach imposes limitations on the <lb/>quality of the resulting alignments. [n Figure 1, <lb/>the LCA-preserving algorithm will match node <lb/>E with node D&apos; and report that as the best match <lb/>overall. The score  S(D; D&apos;I  would take into ac-<lb/>count only the match (E, D~), which in turn in-<lb/>cludes (B, B&apos;) and  (C, C&apos;). (S(D, D&apos;)  would be <lb/>penalized for collapsing the arc from D to E.) <lb/>We seek a better alignment scheme, in which <lb/>the score  S(D, D&apos;)  could benefit from S(A, A&apos;). <lb/>We are willing to pay a small penalty to collapse <lb/>the path from D to E, and align the resulting <lb/>structure. This leads to new algorithms where <lb/>the LeA-preserving restriction is replaced by the <lb/>weaker, dominance-preserving constraint. The <lb/>rationale behind allowing an edge, say (v, u) to <lb/>be collapsed when matching two nodes v and v ~, <lb/>is that we may find some children of u which cor-<lb/>respond well to some children of v&apos;, while other <lb/>children of v correspond well to  other  children of <lb/>v&apos;. (This is not possible if LCA&apos;s are preserved.) <lb/>The algorithm relies on the assumption that two <lb/>different children of v will not match well with <lb/> the same  child of v&apos;. <lb/>3 The Dominance-Preserving <lb/>Algorithm <lb/>Let T and T&apos; be the source and the target trees. <lb/>We use a dynamic programming algorithm to <lb/>compute, in a bottom-up fashion, the scores for <lb/>matching each node in T against each node in T&apos;. <lb/>There are  O(n 2)  such scores, n = max(IT[, IT&apos;]) <lb/>is number of nodes in the trees. Let the  d(v)  be <lb/>the degree of a node v. We denote children of u <lb/>by  vi, i = 1,..., d(v),  and arc (v, v{) by if{. <lb/>For all pairs of nodes v E T and v&apos; E T&apos;, the <lb/>algorithm computes the score function  S(v, v&apos;). <lb/>S(v, v ~)  corresponds to the best match found be-<lb/>tween the subtrees rooted at v in T and at v ~ in <lb/>T&apos;. The values of S are stored in a. [T[ x IT&apos; I ma-<lb/>trix, also denoted by S. [nitially, we fill the ma-<lb/>trix S with undefined values, and invoke the pro-<lb/>cedure  SCOREdom,  described below, to com-<lb/>pute  S(root(T), root(T&apos;)),  the score for matching <lb/>the root nodes of the trees. During the compu-<lb/>tation of the score for the roots, the procedure <lb/>recursively finds the best-scoring matches for  all <lb/> the nodes in the trees. This yields the best align-<lb/>ment of the entire trees. <lb/>Table l(a) shows the values of S for the trees <lb/>in Figure 1. Whenever we compute a score fox&quot; <lb/>internal nodes, we also record the best way of <lb/>pairing up their children in Table l(b). 3 The <lb/>

			<note place="footnote"> 3 Children  pairings include child/child pairs and par-<lb/>ent/child pairs: (D.D&apos;)&apos;s pairing is {(A, A&apos;), (E, D&apos;)}. <lb/></note>

			<page> 844 <lb/></page>

			alignment, implicit in these children pairings, is <lb/>used in a later phase (Section 4) to recover the <lb/>alignment for the entire trees. <lb/>Procedure  SCOREdorn:  For a pair of nodes, <lb/>(v, v~), recursively compute the score  S(v, v&apos;): <lb/> Construct an intermediate  child-scoring  ma-<lb/>trix  M = M(v, v&apos;),  for the children of v and v~; <lb/>the dimensions of M are  (d(v) +  i) x  (d(v&apos;) +  t). <lb/>That is, the number of rows in M is one more <lb/>than the number of children of v, and the number <lb/>of columns is one more than number of children <lb/>of v ¢. V~re label row  d(v)  + 1 and column  d(v ~) + 1 <lb/> with a &quot;*&quot;. Fill the matrix M: <lb/> 1. Vi, j,  where  1 &lt;_ i &lt;_ d(v),t &lt; j &lt;_ d(¢) <lb/> compute the corresponding entry in  Mij: <lb/> The function  Lex,~od~.(v,v ~) &gt;_ 0  (used be-<lb/>low) is the quality of translation, i.e. the <lb/>measure of how closely the label (word) at <lb/>source node v corresponds to the label at <lb/>target node v ~ in the bilingual dictionary, <lb/>and  Lex~c( ff, ff~) &gt;__ 0  is the corresponding <lb/>measure for arc labels. <lb/>2. Fill the last column as follows: Vi, where <lb/> t &lt;_ i &lt; d(v)  compute the entries: <lb/> Mi. = S(vi, v&apos;) - Pen(ffi) <lb/> Pen(ffi) &gt;_ 0  is the penalty for collapsing the <lb/>edge ffi, which depends on the value of the <lb/>label of that edge. <lb/>3. Symmetrically, Vj s.t. <lb/>t _&lt; j <lb/>&lt;_ <lb/> d(v ~)  fill the last row with the entries: <lb/> M.j  =  S(v, v;)  -Pen(~;) <lb/> 4. The entry M.. is disfavored: ~,&apos;l~. = -~c <lb/>For example, during the calculation of the <lb/>scores  S(D, D&apos;)  and  S(E, D&apos;)  from Table t; the <lb/>corresponding matrices  M(D, D ~)  and  M(E, D t) <lb/> are filled in as in Table 2. The proper values for <lb/>the  parameter  functions used above, such as the <lb/>penalty function  Pen  and the translation inea-<lb/>sures, are chosen empirically, and constitute the <lb/>tunable parameters of the procedure. Normally, <lb/>we will expect that the values of  Lexr, ode  will be <lb/>much larger than the values of  Lex~rc  and  Pen. <lb/> In the example we used the following settings: <lb/> 1. Lexnode  = 100 for an exact translation, as for <lb/>(,4, .4&apos;), (B, B t) and (C, C&apos;), and 0 otherwise. <lb/>2. all values of  Lex~c  are set to zero <lb/>3. all penalties  Pen  are set to 1 <lb/>Now, using the values in M, compute the score <lb/>for matching v and ¢: <lb/> S(v, v&apos;) = Lex,~od~(V, v&apos;) +  max  ~ iYI~j  (1) <lb/> PEEP (i,j)EP <lb/> Here P is a  legitimate  pairing of v and its chil-<lb/>dren against v&apos; and its children. A legitimate <lb/>pairing P is a set of elements of the matrix M. <lb/>that conform to the following conditions: <lb/>1. each row and each column of M may con-<lb/>tribute at most one element to P, except <lb/>that the row and the column labeled * may <lb/>contribute more than one element to P <lb/>2. if P contains an element  Mij  correspond-<lb/>ing to the node pair (w. w&apos;), and some child <lb/>node u appears in the Children-Pairing for <lb/>(w, w&apos;), then the row or column of u may <lb/>not contribute any elements to P. <lb/>We use/.7 ) =  £7)(v.  v&apos;) to denote the set of all <lb/>legitimate pairings. There are  O(d!)  such pair-<lb/>ings, where d is the greater of the degrees of u <lb/>and v&apos;. The summation in (l) ranges over all <lb/>the pairs (i, j) that appear in a legitimate pair-<lb/>ing P E /.7)(v, v&apos;). We evaluate this summation <lb/>for all  O(d!)  legitimate pairings in/.7), and then <lb/>select the pairing  Pbe~t  with the maximum score. <lb/> Pbest  is then stored in the Children-Pairing ma-<lb/>trix entry for (v, v&apos;). <lb/>Table 2 shows how scores are calculated. The <lb/>best score for  S(E, D ~)  is 200, the sum of the <lb/>scores for (B,B&apos;) and (C,C&apos;). <lb/> S(D.D&apos;) = <lb/> 299  = S(A, A&apos;) + S(E,  D&apos;) -t, a penalty of t <lb/>for collapsing the edge from D to E. <lb/>We can reduce the computation time of the <lb/>max term in (1), if we do not consider  all O(d!) <lb/> pairings of the children of v and v&apos;. Instead <lb/>of exhaustively computing the maximal-scoring <lb/>pairing  Pbest  in (t), we can build it in a  greedy <lb/> fashion: successively choos the d highest-scoring, <lb/>mutually disjoint pairs from the  O(d 2)  possible <lb/>pairs of children of v and v&apos;. <lb/>1. Initialize the set of highest scoring pairs <lb/> Pb,=~t e-0 <lb/> 2. Phi.st e-Pbestu{ (i,j) }  where  Mij  is the next <lb/>largest entry in the matrix, which that sat-<lb/>isfies both conditions 1 and 2 of legitimate <lb/>pairings <lb/>

			<page> 845 <lb/></page>

			Source <lb/> Nodes <lb/>Target Nodes <lb/>A&apos; <lb/>B&apos; <lb/>C&quot; <lb/>D&apos; <lb/>A&apos; <lb/> A <lb/> 100 <lb/>0 <lb/>0 <lb/>0 <lb/>A <lb/>B <lb/>0 <lb/>100 <lb/>0 <lb/>0 <lb/>B <lb/>C <lb/>0 <lb/>0 <lb/>t00 <lb/>0 <lb/> Source <lb/>C <lb/> D <lb/>0 <lb/>0 <lb/>0 <lb/>299 <lb/> Nodes <lb/>D <lb/> E <lb/>0 <lb/>0 <lb/>0 <lb/>2OO <lb/>E <lb/>F <lb/>0 <lb/>0 <lb/>0 <lb/>0 <lb/>F <lb/> Target Nodes <lb/>B&apos; <lb/>C&apos; <lb/>D&apos; <lb/>-<lb/> (d, A&apos;)(E, D&apos;) <lb/> -<lb/> (B, B&apos;)(C, C&apos;) <lb/> Table 1: (a) A Final Score Matrix; (b) Children-Pairing Matrix <lb/> Source <lb/> Chil-<lb/>dre n <lb/>Target Children <lb/> t: A&apos; 2: B&apos; 3: C&apos; <lb/>*: D&apos; <lb/> t: B <lb/>0 <lb/>100 <lb/>0 <lb/> 99 <lb/>2: C <lb/>0 <lb/>0 <lb/>100 <lb/>99 <lb/>*: E <lb/>0 <lb/>99 <lb/>99 <lb/>-~ <lb/> The Score  S( <lb/>t = tO0+ tO0 --200 <lb/> Source <lb/> Chil-<lb/>dren <lb/>Target Children <lb/> 1: A&apos; 2: B&apos; 3: C&apos; <lb/>*: D&apos; <lb/>1: A <lb/>100 <lb/>0 <lb/>0 <lb/>99 <lb/>2:  E <lb/>0 <lb/> 99 <lb/>99 <lb/>199 <lb/>*: D <lb/>99 <lb/>98 <lb/>98 <lb/>-oc <lb/> The Score S( <lb/>=  t99+ 100 = 299 <lb/>Table 2: Computing Child-Scoring Matrices <lb/>3. Repeat the above step until no more pairs <lb/>can be added to  Pbest,  at most d times. <lb/>where d = min(d(v),  d(vl)). <lb/> 4. Compute the result: <lb/> S(V,  Y&apos;) --LeZnode(V. V&apos;) -4:-~(i,j)ePb,.~, :tiiJ <lb/> The greedy algorithm aligns trees with n <lb/>nodes and maximal degree d in  O(n2d 2)  time. <lb/>4 Acquiring Transfer Rules <lb/>This section describes the procedure for deriving <lb/>transfer rules from aligned parse trees. <lb/>First, the best-scoring alignment is recovered <lb/>from the Children-Pairing matrix, (Table t(b)). 4 <lb/>Start by including the root node-pair in the <lb/>alignment, (here (D, DI)). Then, for each pair <lb/>(v, v ~) already in the alignment, repeat the fol-<lb/>lowing steps, until no more pairs can be added to <lb/>the alignment: (t) look up the Children:Pairing <lb/>for  (v.v&apos;);  (2) for each pair in the children-<lb/>pairing, if it does not include either v or v ~, add <lb/>the pair to the alignment, (e.g. (A, At), etc.). <lb/> 
			
			<note place="footnote">4When sentences in the bitext have multiple parses, <lb/>we align structure sharing forests of trees. If one pair <lb/>of trees has the highest scoring alignment, we acquire <lb/>transfer rules from that alignment. When more than one <lb/>pair of trees tie for the highest score, we acquire transfer <lb/>rules from the set of pairs of aligned subtrees which are <lb/>shared by each of these high scoring alignments. <lb/></note> 
			
			In the running example, the final align-<lb/>ment (FA)is {(D, D&apos;), (A, A&apos;), (B, S&apos;), (C, C&apos;)}. <lb/>Based on this alignment we can &quot;chop up&quot; the <lb/>trees into fragments, or  substructures  ((Mat-<lb/>sumoto et hi., 1993)), where each substructure <lb/>of a tree is a connected group of nodes in the <lb/>tree, together with their joining arcs. In Fig-<lb/>ure i, dashed arrows connect aligned pairs of <lb/>source and target substructures. These corre-<lb/>spondences become our transfer rules. <lb/>For each pair of aligned nodes (v, v&apos;) in  FA, <lb/> there is a pair of substructures in Figure t such <lb/>that v and v ~ are the roots of the source and tar-<lb/>get substructures. These substructures include <lb/>all unaligned source and target nodes v~ and <lb/>&apos; below v and v&apos;, which have no intervening <lb/> V u <lb/> aligned nodes y or y&apos; dominating v, or v~u. <lb/>The transfer rules derived from Figure t may <lb/>be written as follows: <lb/> 1. &lt; root : Excel &gt; --+ &lt; root : Excel &gt; <lb/>2. &lt; root : valores &gt; ~ &lt; root : values &gt; <lb/>3. &lt; root : libro, de : trabajo &gt; -+ &lt; root : <lb/>workbook &gt; <lb/>4. <lb/>&lt; root : volver, subj : xl,a  :&lt;  root : <lb/>calcular, obj : x2, en : x3 &gt; &gt; <lb/>&lt; root : recalculate;subj <lb/>: Tr(xl),obj <lb/>: <lb/>Tr(x2), in : Tr(x3) &gt; <lb/> Each substructure is represented as a list con-<lb/>

			<page>846 <lb/></page>

			taining a root lexical item, and a set of arc-<lb/>value pairs. An arc (role) al with head (value) <lb/>h is written as al : h, where h is a fixed la-<lb/>bel (word), a substructure or a variable. If the <lb/>source substructure has n of the leaves labeled <lb/>with variables xl, • •., x~, the target will have <lb/>n of the leaves labeled with  Tr(xl),...,  Tr(x~), <lb/>where Tr(x) is the texical translation function. <lb/>This general structure allows us to capture re-<lb/>lations between multi-word expressions in the <lb/>source and target languages. <lb/>5 Translation <lb/>The described procedure for acquisition of trans-<lb/>fer rules from corpora is the basis for our trans-<lb/>lation system. A large collection of transfer rules <lb/>are collected from a training corpus. When new <lb/>text is to be translated, it is first parsed. The <lb/>source tree is matched against the left hand sides <lb/>of the transfer rules which have been collected. <lb/>If a set of transfer rules whose left-hand sides <lb/>match the parse tree is found, the corresponding <lb/>target structure is generated from the right hand <lb/>sides of these transfer rules. Typically, several <lb/>sets of transfer rules meet this criterion. They <lb/>are ranked by their frequency in the training cor-<lb/>pus. Once a target tree has been produced, it is <lb/>converted to a word sequence by a target lan-<lb/>guage generator. We have applied this approach <lb/>to the translation of Microsoft Help files in En-<lb/>glish and Spanish. The sentences are moderately <lb/>simple and quite parallel in structure, which has <lb/>made the corpus suitable for our initial system <lb/>development. To date, we have been using a <lb/>training corpus of about 1,000 sentences, and a <lb/>test corpus of about 100 sentences. <lb/>6 <lb/>Evaluation <lb/>Real evaluation of performance of MT systems <lb/>is time consuming and subjective. Neverthe-<lb/>less, some evaluation system is needed to insure <lb/>that incremental changes are for the better, or <lb/>at least, are not detrimental. We measured the <lb/>success of our translation by how closely we re-<lb/>produced Microsoft&apos;s English (target language) <lb/>text. Our evaluation procedure computes the <lb/>ratio between (a) the complement of the inter-<lb/>section set of words in our translation and the <lb/>actual Microsoft sentence; and (b) the combined <lb/>lengths of these two sentences. An exact trans-<lb/>lation gives a score of 0. If the system generates <lb/>the sentence &quot;A B C D E&quot; and the actual sen-<lb/>tence is &quot;A B C F&quot;, the score is 3/9 (the length <lb/>of D E F divided by the combined lengths of <lb/>A B C D E and A B C F.) The dominance-<lb/>preserving version of the program produced out-<lb/>put for 88 out of 91 test sentences. The average <lb/>score for these 88 sentences was 0.29:0.21 due <lb/>to incorrect word matches and 0.08 due to failure <lb/>to translate because insufficient confidence levels <lb/>were reached. The LCA-preserving version pro-<lb/>duced output for only 83 sentences with an aver-<lb/>age score of over 0.30: about 0.23 due to incor-<lb/>rect word matches and about 0.08 due to insuffi-<lb/>cient confidence levels. This crude scoring tech-<lb/>nique suggests that the dominance-preserving al-<lb/>gorithm improved our results: more sentences <lb/>were translated with higher quality. One limita-<lb/>tion of this scoring technique is that paraphrases <lb/>are penalized. An imperfect score (even .20) <lb/>may signify an adequate translation. <lb/></body>

			<listBibl>References <lb/>A. Abeille, Y. Schabes. and A. K. Joshi. 1990. <lb/>Using Lexicalized Tags for Machine Transla-<lb/>tion. In  COLING90. <lb/> M. Farach, T. M. Przytycka, and M. Thorup. <lb/>1995. On the agreement of many trees.  Infor-<lb/>mation Processing Letters,  55:297-301. <lb/>O. Furuse and H. lida. 1994. Constituent <lb/>Boundary Parsing for Example-Based Ma-<lb/>chine Translation. In  COLING94. <lb/> R. Grishman. 1994. lterative Alignment of Syn-<lb/>tactic Structures for a Bilingual Corpus: In <lb/> Proceedings of the Second Annual Workshop <lb/>for Very Large Corpora,  Tokyo. <lb/>H. Kaji, Y. Kida, and Y. Morimoto. 1992. <lb/>Learning Translation Templates fi&apos;om Bilin-<lb/>gual Text. In  COLING92. <lb/> M. Kitamura and Y. Matsumoto. 1995. A Ma-<lb/>chine Translation System based on Transla-<lb/>tion Rules Acquired from Parallel Corpora. In <lb/> RANLP95. <lb/> Y. Matsumoto, H. Ishimoto. T. Utsuro, and <lb/>M. Nagao. 1993. Structural Matching of Par-<lb/>allel Texts. In  ACL93. <lb/> A. Meyers, R. Yangarber, and R. Grishman. <lb/>1996. Alignment of Shared Forests for Bilin-<lb/>gual Corpora. In  COLING96,  pages 460-465. <lb/>S. Sato and M. Nagao. 1990. Toward Memory-<lb/>based Translation. In  COLING90,  volume 3, <lb/>pages 247-252. <lb/></listBibl>

			<page> 847 </page>


	</text>
</tei>
