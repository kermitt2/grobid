<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="_0"/>
	</teiHeader>
	<text xml:lang="en">
			<titlePage>Utility Models for Goal-Directed <lb/>Decision-Theoretic Planners <lb/>Peter Haddawy 1 , Steve Hanks <lb/>Department of Computer Science and Engineering <lb/>University of Washington <lb/>Seattle, WA 98195 <lb/>Technical Report 93{06{04 <lb/>June 15, 1993 <lb/>1 Department of EE &amp; CS, University of Wisconsin{Milwaukee, Milwaukee WI 53201 <lb/></titlePage>

            <front>Utility Models for Goal-Directed <lb/>Decision-Theoretic Planners <lb/>Peter Haddawy <lb/>Department of EE &amp; CS <lb/>University of Wisconsin{Milwaukee <lb/>Milwaukee WI 53201 <lb/>haddawy@cs.uwm.edu <lb/>Steve Hanks <lb/>Department of CS&amp;E, FR{35 <lb/>University of Washington <lb/>Seattle WA 98195 <lb/>hanks@cs.washington.edu <lb/>June 22, 1993 <lb/>University of Washington <lb/>Department of Computer Science &amp; Engineering <lb/>Technical report 93-06-04 <lb/>Abstract <lb/>AI planning agents are goal-directed: success is measured in terms of whether or <lb/>not an input goal is satis ed, and the agent&apos;s computational processes are driven by <lb/>those goals. A decision-theoretic agent, on the other hand, has no explicit goals| <lb/>success is measured in terms of its preferences or a utility function that respects those <lb/>preferences. <lb/>The two approaches have complementary strengths and weaknesses. Symbolic plan-<lb/>ning provides a computational theory of plan generation, but under unrealistic assump-<lb/>tions: perfect information about and control over the world and a restrictive model of <lb/>actions and goals. Decision theory provides a normative model of choice under uncer-<lb/>tainty, but o ers no guidance as to how the planning options are to be generated. This <lb/>paper uni es the two approaches to planning by describing utility models that support <lb/>rational decision making while retaining the goal information needed to support plan <lb/>generation. <lb/>We develop an extended model of goals that involves temporal deadlines and main-<lb/>tenance intervals, and allows partial satisfaction of the goal&apos;s temporal and atemporal <lb/>Thanks to Tony Barrett, Denise Draper, Dan Weld, Mike Wellman, and Mike Williamson for many useful <lb/>comments. Thanks to Meliani Suwandi for helping develop the re nement planning example. Haddawy was <lb/>supported in part by NSF grant IRI{9207262 and in part by a grant from the graduate school of the University <lb/>of Wisconsin-Milwaukee. Hanks is supported in part by NSF Grant IRI{9008670. <lb/>i <lb/>components. We then incorporate that goal information into a utility model for the <lb/>agent. Goal information can be used to establish whether one plan has higher expected <lb/>utility than another, but without computing the expected utility values directly; we <lb/>present a variety of results showing how plans can be compared rationally, but using <lb/>information only about the probability that they will satisfy goal-related propositions. <lb/>We then demonstrate how this model can be exploited in the generation and re nement <lb/>of plans. <lb/></front>

            <page>ii <lb/></page>

			<div type="toc">Contents <lb/>1 Introduction <lb/>1.1 Contributions : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>1.2 Outline : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>2 Classical Goal-Directed Agents <lb/>2.1 Limitation of goal-directed behavior : : : : : : : : : : : : : : : : : : : : : : : <lb/>3 Utility Models for Goal-Directed Agents <lb/>3.1 Syntactic forms for goals : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>3.1.1 The language L tca : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>3.1.2 Goal expressions : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>3.1.3 Utility function for individual goals : : : : : : : : : : : : : : : : : : : <lb/>4 Partial Goal Satisfaction <lb/>11 <lb/>4.1 Partial satisfaction of the atemporal component : : : : : : : : : : : : : : : : <lb/>4.1.1 Goals with symbolic attributes : : : : : : : : : : : : : : : : : : : : : : <lb/>4.1.2 Goals with quantitative attributes : : : : : : : : : : : : : : : : : : : : <lb/>4.1.3 Conjunctive quantitative attributes : : : : : : : : : : : : : : : : : : : <lb/>4.1.4 Summary : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>4.2 Partial satisfaction of the temporal component : : : : : : : : : : : : : : : : : <lb/>4.2.1 Deadlines : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>4.2.2 Maintenance intervals : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>4.2.3 Summary : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>5 Utility Functions for Individual Goals <lb/>5.1 Combining the temporal coe cient and the atemporal degree of satisfaction <lb/>5.1.1 Deadline goals : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>5.1.2 Maintenance goals : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>5.2 Summary : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>6 Using the Utility Functions to Rank Plans <lb/>6.1 Deadline goals : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>6.1.1 Bounds for symbolic attributes : : : : : : : : : : : : : : : : : : : : : <lb/>6.1.2 Bounds for quantitative attributes : : : : : : : : : : : : : : : : : : : : <lb/>6.1.3 Bounds for strictly ordered atemporal attributes : : : : : : : : : : : : <lb/>6.1.4 Example : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>6.2 Maintenance goals : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>6.2.1 Bounds for symbolic attributes : : : : : : : : : : : : : : : : : : : : : <lb/>6.2.2 Bounds for quantitative attributes : : : : : : : : : : : : : : : : : : : : <lb/>6.2.3 Bounds for strictly ordered atemporal attributes : : : : : : : : : : : : <lb/>6.3 Summary : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>iii <lb/>Multiple Goals, Residual Utility, and Computational Issues <lb/>7.1 Plan generation and re nement : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>7.1.1 Partial-order planning and search control : : : : : : : : : : : : : : : : <lb/>7.1.2 Re nement planning : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>8 Summary and Related Work <lb/>8.1 Related work : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>8.1.1 Goals and utility models : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>8.1.2 Decision-theoretic planning and control : : : : : : : : : : : : : : : : : <lb/>8.1.3 Fuzzy decision theory : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/>8.2 Future work : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : <lb/></div>

            <page>iv <lb/></page>

			<body>1 Introduction <lb/>Reasoning about and planning for an uncertain world raises both representational and algo-<lb/>rithmic problems: we need to represent change, uncertainty, and value or utility, and to use <lb/>those concepts to represent various plans of action. And given such a representation for the <lb/>world and for plans that might be executed in the world, we further need an e cient way <lb/>to generate plausible plans, anticipate their results, improve their performance, and choose <lb/>the best option from among them. <lb/>Decision theory addresses the representational problem, providing a rational basis for <lb/>choice under uncertainty. The framework starts with the agent&apos;s preferences over an abstract <lb/>set of possible outcomes, and guarantees the existence of probability and utility functions <lb/>such that acting to maximize expected utility is rational in the sense that it respects those <lb/>preferences. (The planner need not explicitly perform the decision-theoretic analysis|it <lb/>su ces that the planner act according to the recommendations that such an analysis would <lb/>make.) <lb/>Decision theory does not, however, constitute a theory of reasoning about plans. The the-<lb/>ory does not provide a vocabulary for describing planning problems, a method for generating <lb/>options, or a computational model for choosing among plan alternatives. It merely dictates <lb/>a rational choice given such a capability. Decision analysis|the study of applying decision-<lb/>theoretic framework|addresses these limitations, but in a subjective and non-algorithmic <lb/>fashion. <lb/>The capabilities provided by symbolic planning and decision theory are therefore com-<lb/>plementary: the former provides methods for representing planning problems and generating <lb/>alternative plans in response to externally supplied goals (but under restrictive conditions <lb/>that don&apos;t include uncertainty); the latter provides a method for choosing among alterna-<lb/>tives and a language that allows reasoning with uncertainty, but provides (1) no guidance in <lb/>structuring planning knowledge, (2) no way of generating alternatives, and more generally, <lb/>(3) no computational model. The rst step toward integrating these two methodologies is <lb/>to reconcile the two representations. <lb/>Planning problems are described in terms of <lb/>a set of operators that e ect change in the world, <lb/>a description of some initial world state (usually expressed in some logical or quasi-<lb/>logical language), and <lb/>a goal state description. <lb/>Decision-theoretic problems, on the other hand, are stated in terms of <lb/>a probability distribution over possible outcomes, and <lb/>preferences over those outcomes. <lb/></body>

            <page>1 <lb/></page>

            <body>The relationship between the probabilistic model of the world and the operators and <lb/>initial state has been studied as a problem of probabilistic temporal inference, Haddawy, <lb/>1991b], Hanks and McDermott, 1993], Hanks, 1993]. The relationship between the goal <lb/>state description and the agent&apos;s utility model has received less attention, and is the topic <lb/>of this paper. <lb/>1.1 Contributions <lb/>This paper presents a utility model for goal-directed agents that allows rational choice among <lb/>planning alternatives but that also can be exploited by a plan-generation algorithm to guide <lb/>the process of building e ective plans. It therefore directly addresses the gap between AI <lb/>and decision-theoretic planners, providing a richer representation language for the former <lb/>and a computational framework for the latter. <lb/>The main contributions of the paper are: <lb/>1. A detailed analysis and taxonomy of goal forms. We break a goal into atemporal and <lb/>temporal components: what is to be true and when it is to be true. We consider two <lb/>main forms of temporal constraints: deadline goals and maintenance goals, and various <lb/>forms of atemporal constraints, including symbolic and numeric goals. <lb/>2. A model of partial satisfaction that allows reasoning about partial satisfaction of a <lb/>goal&apos;s atemporal component, temporal component or both. Partial satisfaction infor-<lb/>mation for a goal is supplied in terms of <lb/>A function DSA measuring the extent to which the goal&apos;s atemporal component <lb/>is satis ed at a point in time. <lb/>A function measuring the extent to which the goal&apos;s temporal component is sat-<lb/>is ed: <lb/>{ For deadline goals, a function CT that measures the extent to which a time <lb/>point meets the deadline. <lb/>{ For maintenance goals, a function CP that measures the extent to which a <lb/>time interval satis es the maintenance constraint. <lb/>We develop a method for combining these two pieces of information into a coherent <lb/>assessment of the goal&apos;s level of satisfaction. <lb/>3. A utility model for an agent that allows reasoning about trading o (partial) success <lb/>in achieving one goal against (partial) success in achieving another, and trading o <lb/>success in achieving goals with resource consumption. <lb/>4. E ective methods for comparing two plans: relationships that imply that one plan has <lb/>higher expected utility than another, but that do not require computing the expected <lb/>utilities directly. <lb/></body>

            <page>2 <lb/></page>

            <body>5. An example of how the model can be exploited by a planning algorithm to prune the <lb/>space of partial plans explicitly considered. <lb/>1.2 Outline <lb/>Section 2 begins by de ning a goal-directed agent, and pointing out the limitations of a <lb/>planning strategy guided only by conjunctive goal expressions. Section 3 de nes an extended <lb/>utility model for goal-directed agents, which includes a richer notion of goal than the one <lb/>typically used by classical planners. Section 4 confronts the problem of specifying preferences <lb/>over partially satis ed goals, and Section 5 de nes a model that allows partial satisfaction <lb/>of a goal&apos;s temporal and atemporal components simultaneously. <lb/>Sections 6 and 7 address the question of how the goal-based utility model can be ex-<lb/>ploited in comparing and building plans. Section 6 presents a variety of results describing <lb/>circumstances under which deciding that one plan is preferable to another amounts to estab-<lb/>lishing a relationship between probabilities involving the respective goal expressions. Section <lb/>7 discusses how the model might be used in generating plans, exploring extensions to the <lb/>classical partial-order generation algorithm and the idea of planning by re nement. Section <lb/>8 summarizes and discusses related work. <lb/>2 Classical Goal-Directed Agents <lb/>Before we proceed with a formal analysis of goals and utilities we need to de ne more <lb/>precisely what role these concepts will play in a planning system. Goals play three roles in <lb/>automated planning systems: <lb/>Goals act as a device for communicating information about the planning problem. In <lb/>particular they provide a concise de nition of what constitutes a successful plan. <lb/>Goals act as a means of limiting inference in the planning process by allowing the <lb/>planner to backchain over goal propositions. In that sense they de ne exactly what is <lb/>relevant to the planning problem. <lb/>Goals limit the temporal scope of the planning problem, imposing a temporal \hori-<lb/>zon,&quot; beyond which planning is irrelevant. <lb/>In the rst case goals can be communicated more easily than utility functions, and in the <lb/>second and third cases the goals&apos; symbolic content can aid the search for good plans. <lb/>Figure 1 makes the relationship more clear: let us assume some manager, who has a <lb/>utility function over outcome states. He is designing an agent, and has a model of the <lb/>agent&apos;s capabilities. The manager wants to communicate information to the agent that will <lb/>cause it to act so as to increase the manager&apos;s utility; he uses goal expressions to communicate <lb/>that information to the agent. The agent uses this goal information|along with information <lb/>like the anticipated state of the world at execution time and the cost of various resources <lb/>|to produce a utility function that serves to guide its actions. <lb/></body>

            <page>3 <lb/></page>

            <body>Manager&apos;s <lb/>Utility <lb/>Function <lb/>Agent&apos;s <lb/>Utility <lb/>Function <lb/>Domain model <lb/>(resource costs) <lb/>Action <lb/>Utility / Goal <lb/>Information <lb/>Figure 1: Goals as a means of communication <lb/>This model applies classical goal-directed agents as well as decision-theoretic agents. The <lb/>question is what language the manager should use to convey the utility/goal information, and <lb/>how that information restricts the possible behaviors available to the agent. The classical <lb/>planning model restricts this information to a conjunction of goal propositions, which are <lb/>supposed to hold at the end of plan execution. We will show that restricting the form of <lb/>utility information to goal conjunctions of this form places severe restrictions on the agent&apos;s <lb/>problem-solving abilities, then develop more expressive forms of goal expressions that still <lb/>allow the agent to be an e ective problem solver. <lb/>2.1 Limitation of goal-directed behavior <lb/>Suppose the manager communicates only symbolic goal expressions to the agent|he tells <lb/>the agent to achieve some goal G, a conjunction g 1^g2 : : : g n , and the agent builds a plan <lb/>that maximizes the probability that satisfying G will be true at the end of executing the <lb/>plan. (This is the probabilistic analogue of logical goal-directed planning, in which the agent <lb/>constructs a plan that provably achieves G.) What limits does this model place on the agent&apos;s <lb/>preference struture? In other words, under what circumstances is planning to maximize <lb/>expected utility equivalent to planning to maximize the probability of goal satisfaction? <lb/>We start by introducing some notation. We will talk about time points t, and can talk <lb/>about a proposition being true over an interval of time t 1 ; t 2 ] by saying HOLDS( ; t 1 ; t 2 ) <lb/>(see Section 3.1.1 for more details). <lb/>A plan P can be viewed as de ning a probability distribution over chronicles, where a <lb/>chronicle is a set of time points representing one possible course of execution for the plan. <lb/>We can therefore talk about the probability P(cjP). 1 We will generally be interested in <lb/>the time point representing the moment the plan nishes executing; we will use end(c) to <lb/>represent this point. The probability of success in the classical paradigm is the probability <lb/>that the goal conjunction will hold when the plan nishes executing: <lb/>P(P succeeds) P(GjP) <lb/>X <lb/>c:HOLDS (G;end(c);end(c)) <lb/>P(cjP) <lb/>(1) <lb/></body>

			<note place="footnote">1 McDermott, 1982] de nes chronicles in terms of a temporal logic, and Hanks, 1990] and Haddawy, <lb/>1991b] extend the notion to a probabilistic framework. <lb/></note>

			<page>4 <lb/></page>

			<body>and the planner will try to nd the plan maximizing that value. <lb/>A decision-theoretic planner has the same probabilistic model as the probabilistic planner, <lb/>but it has an explicit utility function over chronicles, a function U(c) that maps chronicles <lb/>into real values. The expected utility of a plan is de ned to be <lb/>EU(P) <lb/>X <lb/>c <lb/>U(c) P(cjP) <lb/>(2) <lb/>and the decision-theoretic planner will try to nd the plan maximizing that value. <lb/>The question arises as to under what circumstances the two models are equivalent: for <lb/>what utility models (de nitions of U(c)) is it the case that the plan that maximizes the prob-<lb/>ability of goal achievement (Equation (1)) will always be the plan that maximizes expected <lb/>utility (Equation (2))? <lb/>The answer is that this relationship holds only for simple step utility functions, functions <lb/>for which utility is a constant low value UG for chronicles in which the goal does not hold <lb/>at the end of plan execution and a constant high value UG for chronicles in which it does. <lb/>Figure 2 shows such a function|utility is represented along the vertical axis and the space <lb/>of chronicles along the horizontal axis. G and G designate the set of all chronicles in which <lb/>the goal holds and does not hold, respectively. <lb/>Previous work, Haddawy and Hanks, 1990], demonstrates the correspondence between <lb/>these two policies, showing that the simple class of step functions pictured in Figure 2 is the <lb/>only class of utility functions for which <lb/>P(GjP 1 ) &gt; P(GjP 2 ) ) EU(P 1 ) &gt; EU(P 2 ) <lb/>(3) <lb/>holds for any plans P 1 and P 2 . In other words, describing the desired state of the world in <lb/>terms of a goal conjunction restricts a problem-solver&apos;s preference structure to those that <lb/>can be characterized by a simple step function. ( Haddawy and Hanks, 1990] explores the <lb/>relationship between goal satisfaction and probability maximization for other situations, <lb/>e.g. cases in which goal expressions are combined with some preference information about <lb/>resource consumption.) <lb/>The analysis points out four obvious limitations to the endeavor of planning to achieve <lb/>a goal conjunction: <lb/>1. Temporal extent <lb/>De ning plan success in terms of what is true at the end of execution|de ning a <lb/>successful chronicle only in terms of whether the goal holds at end(c))|rules out goals <lb/>like deadlines (have g 1 true by noon and g 2 true by midnight), maintenance (keep g <lb/>true continuously between noon and midnight), and prevention (make g 1 true, but <lb/>without allowing g 2 to become true in the meantime). (The last is a combination of <lb/>deadline and maintenance goals.) It is important not only what is accomplished, but <lb/>also when or for how long. <lb/>2. Tradeo s among the goals <lb/>The classical model dictates that the satisfaction of all goal conjuncts is necessary and <lb/></body>

            <page>5 <lb/></page>

            <body>chronicles (c) <lb/>U(c) <lb/>G <lb/>G <lb/>UG <lb/>UG <lb/>Figure 2: Step utility function <lb/>su cient for success. More realistic is the view that satisfying some of the conjuncts is <lb/>preferable to satisfying none, motivating the idea that success in achieving one conjunct <lb/>could be traded o against success in achieving others. <lb/>3. Partial satisfaction <lb/>Symbolic goals imply an all-or-nothing success criterion, either the goal form holds at <lb/>the end of execution or it does not. This criterion is re ected in the step function: <lb/>utility is either at a constant high value or at a constant low value. A realistic repre-<lb/>sentation should allow the manager to communicate the fact that satisfying G is most <lb/>preferred, but satisfying G partially is better than not satisfying it at all. <lb/>4. Incidental costs and bene ts <lb/>Symbolic goals imply that the goal attributes are the only aspects of an outcome that <lb/>are relevant to assessing utility, which rules out the possibility that plan P 1 is preferable <lb/>to P 2 because it is as e ective at achieving the goal as P 2 , but does so more cheaply. <lb/>Symbolic goals provide no way to specify the \more cheaply&quot; part, nor do they provide <lb/>the language to express the tradeo between e ectiveness in achieving the goal and <lb/>the cost involved in doing so. <lb/>The analysis in this section demonstrates the steps necessary to unify goal-directed and <lb/>decision-theoretic plan evaluation: <lb/>The language of goals needs to be extended to represent partial goal satisfaction and <lb/>resource-related utility. <lb/>In order to e ectively use these extended goal forms (more complicated utility func-<lb/>tions) in planning we need to establish relationships like Equation 3: circumstances <lb/>under which planning to maximize the probability of goal satisfaction ensures rational <lb/>behavior in the decision-theoretic sense. <lb/>We need to exploit these relationships as we build or re ne plans. <lb/></body>

            <page>6 <lb/></page>

            <body>This paper will have four concerns: <lb/>Presenting a framework for analyzing a goal-directed agent&apos;s utility function, which <lb/>includes goal and resource components. <lb/>De ning a language for goals that provides for expressing preferences among situations <lb/>involving partial satisfaction of the goals. <lb/>Developing relationships that allow the agent to build plans based on the symbolic <lb/>content of its goals, while simultaneously guaranteeing that following those plans will <lb/>cause it to act so as to maximize expected utility. <lb/>Demonstrating how those relationships can be exploited by a planning algorithm. <lb/>3 Utility Models for Goal-Directed Agents <lb/>This section de nes a utility model for a goal-directed agent by describing the form of the <lb/>function U(c) mentioned in the previous section. The task is simple for the simple goal <lb/>model in the previous section: <lb/>U(c) = <lb/>( 1 if HOLDS(G,end(c),end(c)) <lb/>0 otherwise <lb/>(4) <lb/>But we want our model to capture the fact that goal satisfaction can be measured at other <lb/>time points and over intervals, that goals can be partially satis ed, that (partial) satisfaction <lb/>of one goal can be traded o against (partial) satisfaction of other goals, and that resource <lb/>costs a ect the extent to which a plan succeeds as well. <lb/>In that case what can we say about a goal&apos;s role in the utility function? There are two <lb/>main properties we want to capture: <lb/>1. That satisfying a goal to a greater extent is preferable to satisfying it to a lesser extent, <lb/>all other things being equal 2 . <lb/>2. That success in satisfying one goal component can be traded o against success in <lb/>satisfying another goal, or against consuming resources. <lb/>We begin by de ning a goal-oriented agent in terms of its top-level utility function: <lb/>De nition 1 A goal-directed agent is a decision maker whose preferences correspond to the <lb/>following utility function: <lb/>U(c) = n <lb/>i=1 k i UG i (c) + k r UR(c) <lb/>(5) <lb/></body>

            <note place="footnote">2 See Wellman and Doyle, 1991] for a more general interpretation of this criterion. <lb/></note>

            <page>7 <lb/></page>

            <body>The utility function is de ned in terms of n subutility functions UG i associated with <lb/>the agent&apos;s n explicit goals. Each of these functions maps the chronicle into a real number <lb/>between 0 and 1, where 0 represents the situation in which the goal is satis ed not at all in <lb/>the chronicle and 1 indicates that the chronicle satis es the goal fully. <lb/>The function UR (for \residual&quot; or \resource&quot; attributes) also maps a chronicle into 0; 1], <lb/>and measures the extent to which the chronicle produces or consumes non-goal attributes, <lb/>e.g. time, fuel, wear and tear on equipment, money lost or gained. A value of 1 indicates the <lb/>best possible use of non-goal attributes; a value of 0 indicates that resources were consumed <lb/>at the theoretical maximum. <lb/>The model is also de ned in terms of n + 1 numeric parameters: k 1 ; k 2 ; : : :k n ; k r . These <lb/>parameters make explicit the tradeo s among the component goals and between the goals <lb/>and resource consumption. The ratio of any two of these numbers indicates the amount <lb/>the agent is willing to sacri ce in satisfaction of one goal in order to satisfy another, or <lb/>the amount of satisfaction in resource consumption he is willing to \spend&quot; in order to <lb/>accomplish an increase in satisfaction for a goal. We return to these tradeo s in Section 7. <lb/>Equation (5) also implies that the agent&apos;s preferences over the component goals are <lb/>additive independent: preferences over lotteries on the goals depend only on the marginal <lb/>probability distributions for the goals and not on their joint probability distribution Keeney <lb/>and Rai a, 1976, Sect 6.2]. In other words we assume that preference for a particular level of <lb/>satisfaction for one goal does not depend on the extent to which the other goals are satis ed. <lb/>The function furthermore implies that goal satisfaction is additive independent in resource <lb/>consumption: the agent&apos;s preferences over patterns of resource consumption are the same <lb/>regardless of the extent to which the top-level goals are satis ed. <lb/>The power of the independence assumption is that it allows us to reason easily about the <lb/>tradeo between levels of the various goals, and also about how much additional resource we <lb/>would be willing to expend to improve the chances of satisfying a goal or to satisfy it more <lb/>fully (see Section 7). <lb/>The independence restriction on top-level goals seems troubling on the surface, since AI <lb/>planning research has focused mainly on interactions among the goals, and our assumption <lb/>seems to rule out those interactions. In particular the assumption runs counter to the analysis <lb/>of conjunctive-goal planning we presented in the previous section. Equation (5) means, for <lb/>example, that we cannot represent conjunctive goals like \have the truck fueled and loaded <lb/>by 7AM&quot; as two separate top-level goals, since presumably satisfying either one without the <lb/>other a ords low utility but their conjunction a ords high utility. This is indeed the case, <lb/>and our argument is that these two statements do not involve two goals, but rather two <lb/>components of a single goal. Section 4.1.1 addresses the problem of dealing with interactions <lb/>among symbolic interacting components that comprise a goal|that section demonstrate how <lb/>to represent traditional goals of the form \G is satis ed only if its components g 1 : : :g n are <lb/>all satis ed.&quot; <lb/>We should also note that the assumption of utility independence does not imply that <lb/>that goals are probabilistically independent. One might object that two goals, say \have the <lb/>truck at the depot by noon&quot; and \have the truck clean,&quot; interact strongly if the only road <lb/></body>

			<page>8 <lb/></page>

			<body>to the depot is muddy and there&apos;s no way to wash the truck once at the depot. In particular <lb/>there&apos;s no plan that might make them both true. But this is not a violation of probabilistic <lb/>independence, not utility independence. The assumption of additive utility independence <lb/>implies only that the utility derived from satisfying one top-level goal does not depend on <lb/>the extent to which the other goals are achieved; it does not comment on the likelihood <lb/>of achieving either in isolation or both simultaneously. In this example there might be no <lb/>chronicle in which both propositions are true, in which case the likelihood of achieving the <lb/>goal, and presumably the expected utility of any plan, will be low. But this interaction is <lb/>properly re ected in the probabilistic model of the domain and the operators|it does not <lb/>involve the agent&apos;s preferences. <lb/>The main implication of the additive independence is that the decision maker has to <lb/>structure his preferences, identifying those that are utility independent and those that are <lb/>not. The former are divided into separate goals and the latter become components of indi-<lb/>vidual goals. Subsequent sections provide methods for describing interactions among goal <lb/>components. <lb/>We now turn to the question of how the goal information|the UG i (c) functions|is <lb/>expressed. We will temporarily ignore the top-level utility function U(c) as well as the residual <lb/>utility function UR(c), and concentrate on how to build utility functions for individual goals. <lb/>3.1 Syntactic forms for goals <lb/>Goals in classical planning algorithms consist of a symbolic expression to be achieved. We <lb/>want to extend the idea in several directions: <lb/>Goals should have a temporal extent|a time at which or an interval over which the <lb/>proposition is to be achieved. The classical goal representation has the planner achieve <lb/>the goal by the end of plan execution. <lb/>Goals should be partially satis able|if the goal is to produce 10 widgets it might be <lb/>better to produce 5 than none at all. Partial satisfaction can extend to the temporal <lb/>component as well: if the deadline is noon, nishing by 12:05 might be better than <lb/>nishing the next morning. <lb/>3.1.1 The language L tca <lb/>In order to talk about temporally quali ed sentences in a probabilistic setting, we need a <lb/>logic that can represent both time and probability. The logic of time, chance, and action <lb/>L tca is well suited to our purposes. A simpli ed version of the logic is described in Haddawy, <lb/>1991a] and the full logic is described in Haddawy, 1991b]. We describe here just that portion <lb/>of the language relevant to this paper. We will use the single predicate HOLDS to associate <lb/>facts with temporal intervals. The sentence HOLDS(FA; t 1 ; t 2 ) is true if fact FA holds over <lb/>the time interval t 1 to t 2 . We impose the constraint that if a fact holds over an interval it <lb/>holds over any subinterval. <lb/></body>

            <page>9 <lb/></page>

            <body>Probability is treated as a sentential operator so it can be combined freely with other <lb/>logical operators. We write P t ( ) to denote the probability of a formula at time t. The <lb/>probability of a formula is de ned as the probability of the set of chronicles in which the <lb/>formula is satis ed. Although the language can represent the dynamics of probability over <lb/>time by allowing the probability operator to be indexed by any time point, in this paper we <lb/>will only index it by the current time (now) and sometimes will omit the index altogether: <lb/>P( ) understood to mean P now ( ). <lb/>3.1.2 Goal expressions <lb/>We begin by breaking a goal into atemporal and temporal components. The former indicates <lb/>what is to be achieved, the latter when it is to be achieved. <lb/>We de ne two types of temporal goals: deadline goals and maintenance goals. A deadline <lb/>goal is a function of the deadline time point t d , and its atemporal component is just a formula <lb/>containing only the HOLDS predicate with only temporal parameter t d . For shorhand we <lb/>will notate a formula that contains only temporal parameters t; t 0 as (t; t 0 ). A deadline <lb/>goal says only that should hold at the deadline point, but we will discuss below ways of <lb/>expressing preferences over making \partially true&quot; at t d or making true \shortly after&quot; <lb/>t d , or both. Two examples of deadline goals are: <lb/>Have block A on block B on block C by noon. <lb/>HOLDS(on(A,B); noon; noon)^HOLDS(on(B,C); noon; noon) <lb/>Have two tons of rocks to the depot by 2:00 this afternoon. <lb/>HOLDS(=(tons-delivered-to-depot,2); 2PM ; 2PM ) <lb/>A maintenance goal represents a desire to keep a proposition true over an interval of <lb/>time. It is a formula containing only the HOLDS predicate with temporal arguments t b and <lb/>t e , the begin and end points of the maintenance interval. An example of a maintenance goal <lb/>would be \keep the temperature between 65 and 75 degrees from 9am until 5pm: <lb/>HOLDS( (temp, 65); 9am; 5pm)^HOLDS ( (temp, 75); 9am; 5pm) <lb/>3.1.3 Utility function for individual goals <lb/>The i th individual goal appears in the top-level utility function as a function UG i (c) of a <lb/>chronicle. Above we made the distinction between a goal&apos;s temporal and atemporal com-<lb/>ponents, and that distinction is re ected in the UG i function as well. We will explore this <lb/>function in more detail below, but begin by dividing it into two components: <lb/>A function DSA i (t) which is a measure of the extent to which the atemporal component <lb/>of the i th goal is satis ed at time t (where t is implicitly a member of some chronicle <lb/>c). DSA stands for \degree of satisfaction of the atemporal component.&quot; <lb/></body>

			<page>10 <lb/></page>

			<body>A function that de nes the extent to which the goal&apos;s temporal component is satis ed, <lb/>which depends on the form of the temporal component. For deadline goals we de ne a <lb/>temporal coe cient CT i (t), measuring the extent to which the deadline is satis ed at <lb/>time t. For maintenance goals we de ne a persistence coe cient CP i (t; t 0 ) measuring <lb/>the extent to which the maintenance condition is satis ed over the interval t; t 0 . <lb/>Subsequent analysis addresses how the DSA, CT, and CP functions are speci ed and exactly <lb/>how they are combined to form the utility function for the i th goal, UG i (c). <lb/>We next address the problems associated with specifying and reasoning with preferences <lb/>over partial satisfaction of goal forms. <lb/>4 Partial Goal Satisfaction <lb/>So far we have de ned the syntactic goal expressions in terms of an atemporal formula <lb/>and a temporal parameter (time point or interval). We still need a language for expressing <lb/>preferences over partial satisfaction of both. Partial satisfaction of the atemporal component <lb/>might be possible by satisfying most but not all of the members of a conjunctive goal or by <lb/>almost satisfying a numerical equality or inequality constraint. Partial satisfaction of the <lb/>temporal component might be possible by achieving the atemporal component at a time <lb/>soon after the deadline point, or keeping it true through most of the maintenance interval. <lb/>We start by considering in turn partial satisfaction of the atemporal component of the <lb/>goal and partial satisfaction of the temporal (deadline or maintenance) component. <lb/>4.1 Partial satisfaction of the atemporal component <lb/>In the next sections we show how to specify partial satisfaction of two types of atemporal <lb/>components: <lb/>symbolic attributes|a conjunction of symbolic propositions like \a big red cylinder on <lb/>the table,&quot; and <lb/>quantitative attributes|the value of a real-or integer-valued quantity like the truck&apos;s <lb/>fuel level or the number of items in a box. <lb/>In focusing on the atemporal goal component we are addressing the question of what <lb/>form the goal&apos;s atemporal component, DSA i (t), should take. <lb/>4.1.1 Goals with symbolic attributes <lb/>Here we consider how to de ne a function specifying partial satisfaction of symbolic-attribute <lb/>goals. A symbolic attribute is any logical formula containing only the HOLDS predicate. <lb/>For example, the (deadline) goal of having block A on top of a red block by noon would be <lb/>represented as <lb/>9x HOLDS (On(A; x); noon; noon)^HOLDS (Red(x); noon; noon) <lb/></body>

            <page>11 <lb/></page>

            <body>We want to represent situations like one in which it is important to have A on an object, <lb/>but perhaps less important that the object be red. <lb/>The degree of satisfaction (DSA) function for a symbolic-attribute goal is de ned in <lb/>terms of an application-supplied sequence S of mutually exclusive and exhaustive formulas <lb/>( 1 ; 2 ; :::; n ) such that <lb/>n is the actual atemporal component of the goal (thus representing complete satisfac-<lb/>tion), and <lb/>i represents a greater degree of satisfaction than j if i &gt; j. <lb/>The application also provides a function dsa( ) that associates a degree of satisfaction <lb/>value with each i . The function must have the property that dsa( 1 ) = 0 and dsa( n ) = 1. <lb/>For the above example S might be <lb/>i <lb/>i <lb/>dsa( i ) <lb/>1 :9xHOLDS(On(A; x); t; t) <lb/>0.0 <lb/>2 9xHOLDS(On(A; x); t; t)^:HOLDS(Red(x); t; t) <lb/>0.7 <lb/>3 9xHOLDS(On(A; x); t; t)^HOLDS(Red(x); t; t) <lb/>1.0 <lb/>(Note that t is a free variable in these expressions; it is not the deadline point. We will <lb/>discuss below the matter of what times the function should be evaluated at.) <lb/>The simplest such function would be one that admits no partial satisfaction of the goal. <lb/>Recall the example from Section 3, to have the truck loaded and fueled by 7AM, where <lb/>accomplishing one without the other yields no utility. The dsa function would be <lb/>i <lb/>i <lb/>dsa( i ) <lb/>1 :(HOLDS(truck-loaded; t; t)^HOLDS(truck-fueled; t; t)) <lb/>0.0 <lb/>2 HOLDS(truck-loaded; t; t)^HOLDS(truck-fueled; t; t) <lb/>1.0 <lb/>Note that as we suggested, some partial satisfaction is accrued from making the ON <lb/>relationship true even without the RED, but no satisfaction is accrued if RED is true without <lb/>ON. <lb/>To be clear about the notation: the function DSA i for the i th goal is a function of <lb/>a time point. It is de ned in terms of a function dsa i which is a function of the goal&apos;s <lb/>atemporal component, e.g. a symbolic goal component. We integrate the two by taking <lb/>DSA i (t) = dsa i ( ), where is the (unique) formula among the i that is true at time t. <lb/>There must be a unique such formula since the i are mutually exclusive and exhaustive. <lb/>For some specialized types of symbolic goal structures the degree of satisfaction function <lb/>can be de ned more succinctly than by supplying the full table of i and dsa values. For <lb/>example, if the atemporal component is a conjunction of atomic formulas not sharing any <lb/>variables, and if preferences over changes in the degree of satisfaction associated with each <lb/>of the conjuncts are additive independent, then we can de ne the degree of satisfaction for <lb/>each conjunct individually, and the utility associated with a time point is the sum of the <lb/>utilities taken over all the conjuncts. <lb/></body>

            <page>12 <lb/></page>

            <body>4.1.2 Goals with quantitative attributes <lb/>A quantitative attribute is a special kind of symbolic attribute: a logical formula containing <lb/>only the HOLDS predicate in which the rst argument expresses equality or inequality be-<lb/>tween a term and a numeric quantity. An example of a quantitative-attribute deadline goal <lb/>is to have two tons of rocks at the depot by noon: <lb/>HOLDS(= (tons-rocks-delivered-to-depot 2); noon; noon) <lb/>The dsa function for such a goal could in principle be de ned in the same way as we did <lb/>for symbolic attributes above, but such a de nition would be unmanageably large. Since <lb/>the degree of satisfaction for quantitative attributes is simply a function of the quantity&apos;s <lb/>magnitude, we can de ne the dsa function directly in terms of that magnitude. The degree of <lb/>satisfaction for the goal to deliver a ton of rocks would simply be a function of the quantity <lb/>of rocks delivered, e.g. dsa(r) = 1? 2000?r <lb/>2000 where r is the weight of rocks delivered, measured <lb/>in pounds. We again de ne DSA(t) = dsa(r), where r is the number of rocks delivered at <lb/>time t. <lb/>4.1.3 Conjunctive quantitative attributes <lb/>Things get a little more complicated when a goal&apos;s temporal component consists of a con-<lb/>junction of quantitative attributes. Suppose we have the goal of delivering 12,000 pounds of <lb/>polystyrene, 480 pounds of colorant, and 120 pounds of UV stabilizer to a plastics manufac-<lb/>turing plant by time t 2 : <lb/>HOLDS(= (poly-delivered 12,000); t 2 ; t 2 )Ĥ <lb/>OLDS(= (colorant-delivered 480); t 2 ; t 2 )Ĥ <lb/>OLDS(= (UV-delivered 120); t 2 ; t 2 ) <lb/>These quantities were not chosen arbitrarily; they represent the quantities of materials <lb/>needed to manufacture 2000 units of a particular product. They need to be present at the <lb/>plant in a particular proportion in order to be useful. That is to say, only that quantity <lb/>that is present in the right proportion can be used. This is a common characteristic of <lb/>conjunctive quantitative attributes. Consequently, degree of satisfaction will be a function <lb/>of the maximum amount of the materials that have been delivered in the required proportion. <lb/>In this case, the necessary proportion is 100:4:1. So to derive the degree of satisfaction of a <lb/>time in a chronicle, we let <lb/>q = min(x=100; y=4; z) <lb/>where x,y, and z are the quantities of polystyrene, colorant, and UV stabilizer, respectively. <lb/>Then if we require 6 pounds of polystyrene to manufacture one unit, the degree of satisfaction <lb/>would be some nondecreasing function of b100q=6c, normalized to range between 0 and 1. <lb/></body>

            <page>13 <lb/></page>

            <body>4.1.4 Summary <lb/>We have de ned the atemporal part of a goal&apos;s component in the utility function, for sym-<lb/>bolic, quantitative, and conjunctive quantitative goals. This representation applies both to <lb/>deadline and maintenance goals. The function DSA i (t) measures the extent to which the <lb/>atemporal component is satis ed at a particular time point (implicitly within a particular <lb/>chronicle). In each case DSA(t) is de ned in terms of an application-supplied function dsa( ), <lb/>where is speci c to the goal&apos;s atemporal form: for symbolic goals the programmer supplies <lb/>a dsa function in the form of a table with entries for various combinations of the symbolic <lb/>components, along with a partial-satisfaction number for each. For quantitative attributes <lb/>he supplies a dsa function directly in terms of the quantity&apos;s value. <lb/>4.2 Partial satisfaction of the temporal component <lb/>Each goal&apos;s utility function also contains a weighting coe cient, CT i for deadlines and CP i for <lb/>maintenance intervals, measuring the extent to which the deadline or maintenance interval <lb/>was respected. CT i is a function of a time point within a chronicle and measures the extent <lb/>to which that time point meets the deadline. CP i is a function of two time points, and <lb/>measures the extent to which the maintenance interval was respected. These coe cients are <lb/>speci ed independent of the goals&apos; atemporal components. We now consider in turn partial <lb/>satisfaction of deadline and maintenance constraints. <lb/>4.2.1 Deadlines <lb/>We rst have to be precise about what is meant by a goal involving a deadline, for example <lb/>\have the report on my desk by 10 tomorrow morning.&quot; We interpret the goal as a transfer <lb/>of control over a resource, in this case the report. The deadline is the earliest time at which <lb/>the transfer has value to the agent; in other words I am saying that I will be able to use the <lb/>report at 10, but no earlier. So there is no utility associated directly with making the goal <lb/>true before the deadline; there might or might not be utility associated with making it true <lb/>after the deadline. <lb/>The word \directly&quot; refers to the fact that there is obviously some advantage to delivering <lb/>the report early. But that advantage is indirectly accrued: planning to have the report <lb/>delivered an hour early makes it more likely that it will indeed be available at the deadline; <lb/>in most cases the more slack built into the plan, the more likely the plan is to meet the <lb/>deadline, even if things get behind schedule. <lb/>Of course there are also circumstances in which it is best to accomplish the goal as close <lb/>to the deadline as possible. Perhaps the report is likely to be stolen if it is delivered early, <lb/>or perhaps it has to be stored between the time it is delivered and the deadline, and storage <lb/>incurs a cost. Both of these e ects are indirect too, however, and should not be a part of <lb/>the goal-related utility measure. Suppose that the probability of theft increases with the <lb/>amount of time the report is delivered before the deadline. In that case projecting the plan <lb/>will generate a chronicle in which the report is stolen and chronicles in which it is not. The <lb/></body>

			<page>14 <lb/></page>

			<body>1 <lb/>0 <lb/>t d <lb/>t d <lb/>(a) <lb/>(b) <lb/>CT(t) <lb/>CT(t) <lb/>t <lb/>t <lb/>Figure 3: Two partial-satisfaction functions for deadlines <lb/>chronicle in which the report is stolen will not satisfy the goal at all, thus will have low <lb/>utility. The chronicle in which it is not stolen will satisfy the goal fully (since the report <lb/>will be available at the deadline) and will have high utility. Delivering the report earlier will <lb/>increase the probability of the chronicle in which the report is stolen, thus will lower the <lb/>expected utility of the plan, all else being equal. <lb/>In the second case the cost of storing the report is a resource, which is measured in the UR <lb/>utility function. The earlier it is delivered the more storage cost is incurred, again lowering <lb/>the utility of the plan. <lb/>To summarize: the deadline represents the earliest point at which satisfying the goal has <lb/>any direct value. At the deadline point itself the temporal component is fully satis ed. There <lb/>might or might not be utility in satisfying the goal after the deadline|that will depend on <lb/>the goal itself. <lb/>The coe cient CT i (t) measure the degree to which the deadline is considered to be <lb/>satis ed at time t. Our analysis requires that for a goal i with a deadline point t d , <lb/>CT i (t) = 0 for all t &lt; t d . <lb/>CT i (t d ) = 1 <lb/>CT i (t) is a nonincreasing function of t for all t t d . <lb/>If the deadline is absolute, then CT i (t) will be 0 for all points t 6 = t d . CT i need not be strictly <lb/>decreasing. A at region on the curve over some time interval after the deadline represents <lb/>indi erence about which time in that region the goal is satis ed. <lb/>Figure 3 shows two examples: the rst (a) shows a situation in which full satisfaction is <lb/>guaranteed for some period of time after the deadline, then decreases thereafter. The second <lb/>(b) shows an absolute deadline: satisfying the goal is useful at the deadline point but at no <lb/>others. <lb/></body>

            <page>15 <lb/></page>

            <body>0 <lb/>(a) <lb/>(b) <lb/>1 <lb/>0 <lb/>0 <lb/>CP(t,t&apos;) <lb/>interval width <lb/>interval width <lb/>te − tb <lb/>te − tb <lb/>Figure 4: Two partial-satisfaction functions for maintenance goals <lb/>4.2.2 Maintenance intervals <lb/>A maintenance goal speci es that a condition must hold throughout an interval, t b ; t e . The <lb/>analogue to the temporal weighting coe cient CT for a deadline goal (evaluated at a time <lb/>point) is a function CP i (t; t 0 ) over subintervals of (t b , t e ) that de nes to what extent the <lb/>interval satis es the maintenance condition. We consider only the case in which CP i is a <lb/>function of the width of the interval, and require it to range between 0 and 1. Two analogous <lb/>situations to Figure 3 would be (a) one in which satisfaction of the maintenance restriction <lb/>declines gradually with the percentage of the interval covered, and (b) one in which any <lb/>violation of the atemporal component renders the goal totally unsatis ed. Figure 4 shows <lb/>these two cases. <lb/>4.2.3 Summary <lb/>At this point we have described the additional information the application must provide to <lb/>de ne partial goal satisfaction for individual deadline and maintenance goals. For each goal <lb/>i we require: <lb/>1. For the goal&apos;s atemporal component, a function DSA i (t) that de nes the extent to which <lb/>the goal&apos;s symbolic component is satis ed at that point in time. DSA i (t) = 0 indicates <lb/>no satisfaction of the goal formula at t; a value of 1 indicates complete satisfaction. <lb/>DSA in turn is de ned in terms of an application-supplied function dsa speci c to the <lb/>goal&apos;s atemporal content. For symbols this information will take the form of a table <lb/>associating a number between 0 and 1 for formulas that represent partial satisfaction <lb/>of the goal formula. For quantitative attributes the dsa function can be de ned directly <lb/>in terms of the attribute itself. <lb/>2. For the temporal component, either <lb/></body>

			<page>16 <lb/></page>

			<body>a function CT i (t) that speci es the extent to which time t satis es the deadline, <lb/>or <lb/>a function CP i (t; t 0 ) that speci es the extent to which the interval (t; t 0 ) satis es <lb/>the maintenance requirement. <lb/>The utility function UG i for an individual goal is a combination of these two functions, <lb/>and the next section confronts the problem of how and when to combine them. <lb/>5 Utility Functions for Individual Goals <lb/>We have now supplied functional forms for describing satisfaction of a goal&apos;s atemporal and <lb/>temporal component. The former is supplied in the form of a function DSA i (t), de ned in <lb/>terms of the atemporal attribute. The DSA function varies between 0.0 and 1.0, representing <lb/>respectively no satisfaction and complete satisfaction. The latter is supplied in terms of a <lb/>weighting coe cient, either CT i (t) or CP i (t 1 ; t 2 ) depending on whether the goal is a deadline <lb/>or a maintenance interval. <lb/>5.1 Combining the temporal coe cient and the atemporal de-<lb/>gree of satisfaction <lb/>Both of the partial-satisfaction functions are functions of time points, whereas the goal&apos;s con-<lb/>tribution to the utility function (the UG i function) is de ned in terms of an entire chronicle. <lb/>To form the utility function for a deadline goal we need to evaluate and combine DSA and <lb/>CT values at selected time points within the chronicle and to form the utility function for a <lb/>maintenance goal we need to evaluate and combine the DSA i and CP i values over selected <lb/>intervals within the chronicle. <lb/>The real problem therefore is when to evaluate the functions, and this is a di cult question <lb/>only when partial satisfaction is allowed both in the atemporal and temporal components. <lb/>Take a deadline goal, for example|if we were to allow partial satisfaction of the atemporal <lb/>component but not the temporal component, we could just evaluate the atemporal goal ex-<lb/>pression DSA at the deadline point. Likewise, if we allow partial satisfaction of the temporal <lb/>component but not the atemporal component then we could just evaluate the CT component <lb/>at the earliest time point (at or after the deadline) at which the atemporal component is <lb/>fully satis ed. But suppose that we allow partial satisfaction in both components|at what <lb/>time point(s) should we evaluate and combine the DSA function and the CT coe cient? <lb/>5.1.1 Deadline goals <lb/>We motivate our solution with an example. Suppose we are employing a delivery agent <lb/>whose task it is to deliver two tons of rocks to the depot by 2PM. Several trips might be <lb/>required. Abstractly we can think about how to structure payments to the driver so that if <lb/>he acts rationally he will act so as to maximize our utility. <lb/></body>

            <page>17 <lb/></page>

            <body>A reasonable way to reward the driver is to pay him in proportion to each quantity of <lb/>rocks he delivers on each trip, up to a total of two tons. The pay for each delivery would be <lb/>discounted by an amount proportional to the amount of time by which each delivery misses <lb/>the deadline. The amount the driver gets paid is then the sum of the rewards for all the <lb/>deliveries he makes up to two tons. If the driver acts to maximize his expected pay, we will <lb/>also be maximizing our utility relative to the goal. <lb/>Even though the deadline goal is stated in terms of the level of a quantity, it is important <lb/>to note that it is proper to reward the driver for the quantities delivered, and not for the level <lb/>attained. Otherwise the driver would be penalized if rocks were removed. But we also have to <lb/>make sure that there is no incentive for the driver to remove rocks then immediately deliver <lb/>them. So the proper reward structure is to pay for deliveries that increase the attribute&apos;s <lb/>level of satisfaction. A delivery is analogous to an increase in the dsa value of the atemporal <lb/>component, not directly to a dsa value. <lb/>We also make the following assumptions about changes in atemporal utility: <lb/>All preferences for lotteries over changes in dsa at any time t are the same as preferences <lb/>for lotteries at any other time t 0 . <lb/>There are a countable number of changes in the dsa over the course of a chronicle. <lb/>Under these assumptions the appropriate reward structure for the agent|and by analogy <lb/>the proper expression for the goal&apos;s utility|is an additive utility function: <lb/>UG i (c) = DSA i (t d ) + <lb/>(6) <lb/>X <lb/>ft&gt;t D : :9t 0 (t D t 0 &lt;t)^DSA i (t 0 ) DSA i (t)g <lb/>(DSA i (t) ? max t D t &lt;t DSA i (t)) CT i (t) <lb/>where t d is the time of the deadline. The intuition is that we accrue utility for the level of <lb/>satisfaction that is true at the deadline point (thus rewarding early satisfaction), and also for <lb/>every time the DSA function increases over a previous value. The amount of utility accrued <lb/>for a change is the increase in atemporal utility over the previous maximum, weighted by <lb/>the CT function that discounts the change according to how well it satis es the deadline. <lb/>The basic form of this utility function is similar to that presented by Meyer Keeney and <lb/>Rai a, 1976, Sect. 9.3.2] for the utility of a consumption stream. The only di erence is that <lb/>Meyer&apos;s formulation de nes utility directly in terms of consumption|which is the change in <lb/>the agent&apos;s wealth|while our DSA functions specify this change in utility indirectly. Another <lb/>minor di erence is that Meyer&apos;s formulation allows consumption to be negative, indicating <lb/>a loss of wealth, whereas we are only interested in positive changes in degree of satisfaction. <lb/>Consider, for example, the goal to have two tons of rocks at the depot by noon. We can <lb/>use one of two trucks. The big truck carries two tons in one load but is slow: it will get <lb/>all two tons to the depot by 2pm. The small truck carries only one ton but is fast: it will <lb/>get one ton there by 1pm and two tons there by 2pm. Which plan a ords higher utility? <lb/>The answer depends, of course, on the utility decay associated with missing the deadline <lb/>compared to the utility decay associated with missing some rocks. Suppose that the degree <lb/></body>

            <page>18 <lb/></page>

            <body>of satisfaction of zero tons is 0.0, the degree of satisfaction of one ton is 0.5 and the degree <lb/>of satisfaction of two tons is 1.0. Suppose further that the temporal coe cient is a linearly <lb/>decreasing function that goes from 1.0 at noon to 0.0 at 3pm. So CT(t) = 1 ? t=3, where <lb/>t is the number of hours past noon. Based on these values, the utility of the chronicle that <lb/>results from using the big truck is (1)(1/3) = 1/3 and the utility of the chronicle that results <lb/>from using the small truck is (1/2)(2/3)+(1/2)(1/3) = 1/2. Hence we prefer to use the small <lb/>truck over the big truck. This preference ts our intuition since based on the speci cations <lb/>of the atemporal utility function and the temporal coe cient, we associate some bene t with <lb/>having some portion of the two tons of rocks at the depot earlier. <lb/>This example is an instance of a general probabilistic dominance relation that holds for <lb/>deadline goal utility functions as de ned above. If <lb/>8i; t; n: P(fc : DSA i (t) ngjP 1 ) &lt; P(fc : DSA i (t) ngjP 2 ); <lb/>where i ranges over all goals and fc : DSA i (t) ng denotes the set of chronicles in which <lb/>DSA i (t) n, then P 1 has higher expected utility than P 2 and is thus preferred. <lb/>5.1.2 Maintenance goals <lb/>A maintenance goal states that a condition should be maintained over an interval of time. <lb/>Partial atemporal satisfaction of a maintenance goal is expressed (as in deadline goals) in <lb/>terms of the degree of satisfaction of the atemporal component. Partial temporal satisfaction <lb/>is expressed in terms of the length of the interval or intervals over which the atemporal <lb/>component is partially satis ed. Partial temporal satisfaction can be a non-linear function <lb/>of interval length. For example, we may wish to keep a machine running from 9:00 until <lb/>5:00 and if it has a production cycle time of 30 minutes, we may not accrue any reward for <lb/>having it running for intervals shorter than 30 minutes. So we de ne a persistence coe cient <lb/>function CP that maps a temporal interval into a number between zero and one. <lb/>The question again is how to combine the atemporal and temporal satisfaction into a <lb/>utility function for the maintenance goal. We need to measure how long the atemporal <lb/>component persists at each level of partial satisfaction. Since we are measuring the amount <lb/>of time over which a quantity persists, we need to x the quantity and nd the intervals <lb/>over which the quantity is at that level. If we have a DSA function that is only either 0 <lb/>or 1, we simply sum the CP values of the intervals over which the atemporal component is <lb/>satis ed. If the DSA can have intermediate value the procedure is roughly to integrate over <lb/>all possible DSA values and nd intervals over which DSA is maintained at a given level. <lb/>Notice that if the satisfaction level is low over some interval and higher over a second <lb/>interval then the atemporal component was at least at that low level of satisfaction over both <lb/>intervals. For example, suppose that the DSA is above some high level, say 0.8, throughout <lb/>the interval of interest but that it uctuates above that level at some high frequency. Suppose <lb/>further that our CP function assigns zero satisfaction to any interval shorter than half of the <lb/>interval of interest. If we measure the utility in terms of the intervals over which the DSA is <lb/>at a given level, we would wind up assigning zero utility to this chronicle even though the <lb/></body>

            <page>19 <lb/></page>

            <body>DSA is above 0.8 for the entire interval. So the following expression assigns utility in terms <lb/>of the intervals over which the DSA is maintained above each possible value. <lb/>UG i (c) = <lb/>Z 1 <lb/>0 <lb/>X <lb/>fI: 8t2I DSA i (t) x^:9I 0 I 8t2I 0 DSA i (t) xg <lb/>CP i (I) dx <lb/>(7) <lb/>where I and I 0 denote temporal intervals. Notice the symmetry between the above expres-<lb/>sion and that for deadline goals. To compute the utility of a deadline goal, we sum changes <lb/>in DSA over time. For maintenance goals, we sum time over DSA i.e., we sum the CP of <lb/>intervals over which DSA exceeds a given value over all values of DSA. <lb/>5.2 Summary <lb/>This section completes the de nition of utility functions for individual goals, providing a <lb/>de nition for the UG i functions. The main problem we solved is how to combine partial <lb/>satisfaction of a goal&apos;s temporal component with partial satisfaction of a goals&apos; atemporal <lb/>component. <lb/>For deadline goals the problem amounts to deciding when to evaluate the DSA function| <lb/>the degree of satisfaction of the goal&apos;s atemporal component. The main idea is to evaluate <lb/>the DSA function once at the deadline point, and then at every time point at which the DSA <lb/>function increases. At every such point the increase in atemporal satisfaction is weighted by <lb/>the temporal coe cient CT i . <lb/>For maintenance goals combining the temporal and atemporal components involves iden-<lb/>tifying the intervals of DSA over which to evaluate CP. The main idea is to evaluate the CP <lb/>of the longest continuous intervals over which the DSA exceeds each possible value. <lb/>Now that we have the basic form of the agent&apos;s top-level utility function we turn to the <lb/>problem of how to use that function to establish qualitative di erences in the quality of <lb/>alternative plans. <lb/>6 Using the Utility Functions to Rank Plans <lb/>One of the main goals of the present work is to use information in the utility function&apos;s sym-<lb/>bolic structure to guide the building of good plans, which generally will involve demonstrating <lb/>that one plan is preferable to another. At worst establishing this relationship involves com-<lb/>puting the expected utility of both plans, a process that requires generating and evaluating <lb/>all possible chronicles for each. <lb/>By exploiting the structure of the utility functions we can establish the same relation-<lb/>ships without performing the full expected-utility calculation. We do so by establishing <lb/>relationships among the individual goals&apos; symbolic components that indicate corresponding <lb/>relationships among the corresponding utility functions. Here is an abstract characterization <lb/>of the sorts of relationships we will establish: <lb/></body>

            <page>20 <lb/></page>

            <body>Suppose that one of the agent&apos;s goals is g and that there are two formulas <lb/>and that bear some relation to g. More particularly, the truth of indicates <lb/>a high goal-related utility (DSA) whereas the truth of indicates a low DSA <lb/>value. Further suppose that there are two alternative plans, P 1 and P 2 . If the <lb/>probability that is true by some time t 1 given P 1 is at least , and if the <lb/>probability that is true at all times before t 2 given P 2 is at least , and if <lb/>exceeds some function of , dsa( ), dsa( ), t 1 , and t 2 , then P 1 &apos;s expected utility <lb/>is guaranteed to be greater than P 2 &apos;s. <lb/>Having established a relationship of that form the planner need only establish two proba-<lb/>bility bounds associated with propositions and in order to eliminate P 2 from further <lb/>consideration. <lb/>Two advantages accrue from this technique: <lb/>1. it reduces the general problem of expected-utility calculations to the more speci c task <lb/>of deciding whether a particular probability exceeds a particular threshold, and <lb/>2. it allows us to perform the expected-utility analysis incrementally|at each stage of <lb/>the planning process we can eliminate some plans from consideration, again limiting <lb/>the amount of inference needed to choose a good course of action. <lb/>We will demonstrate these advantages in Section 7, but rst establish relationships for the <lb/>goal types we de ned in the previous section. <lb/>6.1 Deadline goals <lb/>We rst derive results for deadline goals, attacking symbolic atemporal attributes, then <lb/>quantitative atemporal attributes. <lb/>6.1.1 Bounds for symbolic attributes <lb/>We are comparing two plans on the basis of their performance on a goal whose temporal <lb/>component is a deadline t d and whose atemporal component is symbolic. We have a formula <lb/>that indicates a high level of goal satisfaction (dsa value) and a formula with a low dsa <lb/>value. Consider the case in which P 1 is likely to achieve at some time at or close to the <lb/>deadline, and P 2 is likely to achieve at best only some time well after the deadline. Under <lb/>what circumstances can we say that P 1 has higher expected utility than P 2 ? <lb/>Suppose that the goal&apos;s atemporal component is <lb/>HOLDS(On(A,B); t d ; t d )^HOLDS(On(B,C); t d ; t d ) <lb/>and we de ne the dsa function as follows: <lb/>i <lb/>i <lb/>dsa( i ) <lb/>1 :On(B; C) <lb/>0.0 <lb/>2 :On(A; B)^On(B; C) <lb/>0.5 <lb/>3 On(A; B)^On(B; C) <lb/>1.0 <lb/></body>

            <page>21 <lb/></page>

            <body>In other words we accrue partial satisfaction by achieving On(B,C) alone, but no partial <lb/>satisfaction by achieving On(A,B) alone. In that case the two formulas might be <lb/>= HOLDS (On(B; C); t; t 0 ) <lb/>= :HOLDS(On(B; C); t; t 0 ): <lb/>Now suppose that for plan P 1 we can nd some time point t 1 t d such that <lb/>P( (t 1 ; t 1 )jP 1 ) <lb/>and for plan P 2 we can nd some time point t 2 t d such that <lb/>P(8t;t 0 (t d t t 0 &lt; t 2 ) ! (t; t 0 )jP 2 ) <lb/>. <lb/>Under what conditions can we say that plan P 1 is preferable to plan P 2 ? We must <lb/>determine the lowest value of EU(P 1 ) and the highest value of EU(P 2 ) consistent with these <lb/>two constraints. Let be the formula of lowest dsa consistent with (in the example <lb/>= 3 ). We are guaranteed the existence of such a formula since the i are exhaustive. <lb/>The expected utility of plan P 1 is minimized if <lb/>1. with probability , is achieved at time t 1 and the goal is not partially achieved at <lb/>any time earlier than t 1 , and <lb/>2. with probability 1 ? the goal is completely unsatis ed. <lb/>So by Equation 6 we have <lb/>EU(P 1 ) <lb/>dsa( ) CT(t 1 ) + (1 ? ) 0 <lb/>Now let be the formula of highest dsa consistent with conjunct ( = 2 ). The <lb/>expected utility of plan P 2 is highest if <lb/>1. with probability , is achieved by the deadline and the goal is completely achieved <lb/>immediately after time t 2 , and <lb/>2. with probability 1 ? the goal is completely satis ed at the deadline. <lb/>Again by Equation 6: <lb/>EU(P 2 ) <lb/>dsa( ) + (1 ? dsa( ))CT(t 2 )] + (1 ? ) 1 <lb/>And we therefore know that P 1 &apos;s expected utility is higher than P 2 &apos;s if <lb/>&gt; dsa( ) + (1 ? dsa( ))CT(t 2 )] + (1 ? ) <lb/>dsa( ) CT(t 1 ) <lb/>(8) <lb/>The values for and and the times t 1 and t 2 will determine how useful our probability <lb/>bounds are. A t 1 close to the deadline and a that is inconsistent with low-utility i values <lb/>will give us a high lower bound on EU(P 1 ). Similarly, a t 2 well after the deadline and a <lb/>inconsistent with high utility i values will give us a low upper bound on EU(P 2 ). <lb/></body>

            <page>22 <lb/></page>

            <body>6.1.2 Bounds for quantitative attributes <lb/>Now suppose that our deadline goal is stated in terms of some quantity Q. Assume that the <lb/>dsa is a monotonically increasing function of the quantitative attribute 3 . Suppose we can <lb/>establish that P 1 will achieve some high level of Q by some time close to the deadline, and <lb/>that P 2 can not establish more than some low level of Q until well after the deadline. What <lb/>do the levels and times have to be in order to conclude that P 1 dominates P 2 ? <lb/>Suppose we know that for plan P 1 we nd a time point t 1 t d and some attribute value <lb/>k 1 for which <lb/>P(HOLDS( (Q; k 1 ); t 1 ; t 1 )jP 1 ) <lb/>and for plan P 2 we nd a time point t 2 t d and a value k 2 such that <lb/>P(8t;t 0 (t d t t 0 &lt; t 2 ) ! HOLDS( (Q; k 2 ); t; t 0 )jP 2 ) <lb/>Under what conditions can we say that P 1 dominates plan P 2 ? The expected utility of P 1 <lb/>is lowest if <lb/>1. with probability , we achieve a level k 1 for Q at time t 1 and Q has value zero at all <lb/>times prior to t 1 , and <lb/>2. with probability (1 ? ), Q has its minimum value at all times. <lb/>Under those circumstances we know that <lb/>EU(P 1 ) <lb/>dsa(k 1 ) CT(t 1 ) <lb/>The expected utility of plan P 2 is highest if <lb/>1. with probability , Q attains level k 2 at the deadline and the maximum possible value <lb/>of Q is attained immediately after t 2 , and <lb/>2. with probability 1 ? the maximum possible value of Q is attained by the deadline. <lb/>Then we know that <lb/>EU(P 2 ) <lb/>dsa(k 2 ) + (1 ? dsa(k 2 )) CT(t 2 )] + (1 ? ); <lb/>and P 1 is preferred to P 2 if <lb/>&gt; <lb/>dsa(k 2 ) + (1 ? dsa(k 2 )) CT(t 2 )] + (1 ? ) <lb/>dsa(k 1 ) CT(t 1 ) <lb/>(9) <lb/></body>

            <note place="footnote">3 A symmetric analysis can be performed for monotonically decreasing atemporal utility. <lb/></note>

            <page>23 <lb/></page>

            <body>6.1.3 Bounds for strictly ordered atemporal attributes <lb/>Additional structure in the atemporal component can make dominance relationships easier <lb/>to come by. In this section we will consider a common atemporal component that has an <lb/>additional structural feature: a ordered conjunction of expressions in which each conjunct <lb/>dominates subsequent conjunct|any chronicle that satis es g 1 is preferable to every chron-<lb/>icle that does not satisfy g 1 , even it satis es all the others. For example, if our conjuncts <lb/>are g 1 , g 2 , and g 3 our strictly ordered atemporal utility function would satisfy the constraint <lb/>that satisfying g 1 is preferable to not satisfying it, regardless of whether g 2 or g 3 are satis ed: <lb/>dsa(g 1^g2^g3 ) &gt; dsa(:g 1^g2^g3 ) <lb/>dsa(g 1^: g 2^g3 ) &gt; dsa(:g 1^g2^g3 ) <lb/>dsa(g 1^g2^: g 3 ) &gt; dsa(:g 1^g2^g3 ) <lb/>dsa(g 1^: g 2^: g 3 ) &gt; dsa(:g 1^g2^g3 ) <lb/>dsa(g 1^g2^g3 ) &gt; dsa(:g 1^: g 2^g3 ) <lb/>dsa(g 1^: g 2^g3 ) &gt; dsa(:g 1^: g 2^g3 ) <lb/>. . . <lb/>dsa(g 1^: g 2^: g 3 ) &gt; dsa(:g 1^: g 2^: g 3 ) <lb/>and likewise, given that g 1 is true, it&apos;s always preferable to satisfy g 2 regardless of g 3 &apos;s state: <lb/>dsa(g 1^g2^g3 ) &gt; dsa(g 1^: g 2^g3 ) <lb/>dsa(g 1^g2^: g 3 ) &gt; dsa(g 1^: g 2^g3 ) <lb/>dsa(g 1^g2^g3 ) &gt; dsa(g 1^: g 2^: g 3 ) <lb/>dsa(g 1^g2^: g 3 ) &gt; dsa(g 1^: g 2^: g 3 ) <lb/>Finally we note that if g 1 and g 2 are both true then g 3 is preferable to its negation: <lb/>dsa(g 1^g2^g3 ) &gt; dsa(g 1^g2^: g 3 ) <lb/>Notice that we did not specify that g 2 dominates g 3 in cases where g 1 is false. The reason <lb/>is that we will often assign zero utility to all states in which the most important goal is not <lb/>satis ed. For example, given the goal to have the truck fueled and clean by noon, it might <lb/>do us no good to have it clean if it is not fueled. <lb/>The structure of a utility function of this form allows us to prune away suboptimal plans <lb/>by considering each conjunct individually in the priority order dictated by the dsa values. <lb/>As above suppose that we have a time t 1 at which P 1 is likely to achieve g 1 , but for P 2 <lb/>g 1 is liable to be false until at least t 2 : <lb/>P(g 1 (t 1 ; t 1 )jP 1 ) <lb/>P(8t;t 0 (t d t t 0 &lt; t 2 ) ! :g 1 (t; t 0 )jP 2 ) <lb/></body>

            <page>24 <lb/></page>

            <body>Under what conditions can we say that plan P 1 is preferable to plan P 2 ? We have no <lb/>information about the probabilities of the atemporal component&apos;s other conjuncts, so a lower <lb/>bound on the expected utility of P 1 is <lb/>EU(P 1 ) <lb/>dsa(g 1^i :g i ) CT(t 1 ) <lb/>and an upper bound on the expected utility of plan P 2 is <lb/>EU(P 2 ) <lb/>dsa(:g 1^i g i ) + (1 ? dsa(:g 1^i g i ))CT(t 2 )] + (1 ? ): <lb/>So plan P 1 is preferred to plan P 2 if <lb/>&gt; dsa(:g 1^i g i ) + (1 ? dsa(:g 1^i g i ))CT(t 2 )] + (1 ? ) <lb/>dsa(g 1^i :g i )CT(t 1 ) <lb/>(10) <lb/>In this case we can eliminate some suboptimal plans using based only on their ability <lb/>to satisfy the rst goal conjunct. Having done so we can then compare the probability of <lb/>satisfying the rst and second conjuncts to the probability of satisfying the rst conjunct <lb/>but not the second, and so forth. We continue until we have incorporated all the conjuncts, <lb/>at which point we can compute the expected utility of any remaining plans. <lb/>This ability to consider the conjuncts sequentially has important consequences for the <lb/>projection process. Hanks, 1993] presents a probabilistic projection algorithm demonstrating <lb/>that: <lb/>it can be much cheaper to project a plan with respect to a single proposition (like one <lb/>of our goal conjuncts) than it is to reason about all of the plan&apos;s e ects, <lb/>it can be much cheaper to determine whether the probability of a proposition exceeds <lb/>a speci c threshold than it is to compute the exact value of that probability. <lb/>6.1.4 Example <lb/>Let&apos;s consider a speci c example of how these relationships can be used to compare plans. <lb/>Suppose our goal is to be home by 6:00 with some Thai food and some beer: <lb/>HOLDS(Loc(me,home); 6:00; 6:00)Ĥ <lb/>OLDS(Possess(me,thai-food); 6:00; 6:00)Ĥ <lb/>OLDS(Possess(me,beer); 6:00; 6:00) <lb/>Assume that these propositions persist: any of the goals I achieve before the deadline will <lb/>be true at the deadline. <lb/>Suppose we have the dsa function appearing in Figure 5, and that the temporal coe cient <lb/>function falls o linearly from 1.0 at 6:00pm to 0.0 at 10:00pm, so CT(t) = 1?t=4, where t is <lb/>measured in hours past 6:00pm. Now consider two plans P 1 and P 2 such that for plan P 1 we <lb/>have established a time t 1 prior to which the formula = Loc(me,home) is likely to be true, <lb/></body>

            <page>25 <lb/></page>

            <body>i <lb/>i <lb/>dsa( i ) <lb/>1 :Loc(me,home) <lb/>0.0 <lb/>2 Loc(me,home)^:Possess(me,thai-food)^:Possess(me,beer) <lb/>0.4 <lb/>3 Loc(me,home)^:Possess(me,thai-food)^Possess(me,beer) <lb/>0.5 <lb/>4 Loc(me,home)^Possess(me,thai-food)^:Possess(me,beer) <lb/>0.8 <lb/>5 Loc(me,home)^Possess(me,thai-food)^Possess(me,beer) <lb/>1.0 <lb/>Figure 5: Example atemporal utility function <lb/>and for plan P 2 we have established that will likely not get home ( = :Loc(me,home)) <lb/>before t 2 = 9:00. The precise formulas are: <lb/>P(HOLDS(Loc(me,home);t 1 ; t 1 )jP 1 ) <lb/>P(8t;t 0 (6:00 t t 0 &lt; 9:00) ! :HOLDS(Loc(me,home); t; t 0 )jP 2 ) <lb/>In this case we can apply Equation (8) directly to establish that P 1 dominates P 2 if <lb/>&gt; 1 ? :75 <lb/>:4 <lb/>So if = :9 then for any greater than .8125 plan P 1 will dominate P 2 , and plan P 2 can <lb/>be eliminated from consideration. <lb/>6.2 Maintenance goals <lb/>Now we consider a similar analysis for maintenance goals|those in which the temporal <lb/>component requires that the atemporal component hold over an interval. The general rela-<lb/>tionship we will establish is between a plan P 1 that is likely to keep a proposition true <lb/>over a long subinterval of the maintenance interval, and has a high dsa value. About P 2 <lb/>we have established that some low-dsa formula is likely to hold over all subintervals (i.e. <lb/>is the best that P 2 is likely to achieve). In that case, if is su ciently good compared to <lb/>, and if the interval over which is maintained is su ciently long, and if P 1 is su ciently <lb/>likely to actually achieve , then we can prove that P 1 dominates P 2 . <lb/> 6.2.1 Bounds for symbolic attributes <lb/>For symbolic attributes we once again measure degree of satisfaction on the basis of formulas <lb/>related to the goal, and their associated dsa values. For maintenance goals we are supposed <lb/>to make the formulas true over an interval t b ; t e ]. Suppose that for plan P 1 we have constants <lb/>t 1 ; t 0 <lb/>1 such that (t b t 1 t 0 <lb/>1 <lb/>t e ) for which we can establish that <lb/>P( (t 1 ; t 0 <lb/>1 )jP 1 ) <lb/></body>

            <page>26 <lb/></page>

            <body>(P 1 is likely to make true over a subinterval t 1 ; t 0 <lb/>1 ] of the maintenance interval t b ; t e ]), and <lb/>for plan P 2 we have constants t 2 ; t 0 <lb/>2 such that (t B t 2 t 0 <lb/>2 <lb/>t E ) for which we can establish <lb/>that <lb/>P( (t 2 ; t 0 <lb/>2 )jP 2 ) <lb/>(P 2 is likely to make hold over subinterval t 2 ; t 0 <lb/>2 ] of the maintenance interval t b ; t e ].) <lb/>Under what conditions can we say that P 1 dominates P 2 ? Again we must determine the <lb/>lowest value of EU(P 1 ) and the highest value of EU(P 2 ) consistent with these two constraints. <lb/>Let be the formula of lowest dsa consistent with . The expected utility of plan P 1 is <lb/>lowest if <lb/>1. with probability , holds throughout t 1 ; t 0 <lb/>1 and the atemporal component is not <lb/>partially satis ed at any time outside of t 1 ; t 0 <lb/>1 ], and <lb/>2. with probability 1 ? the atemporal component is completely unsatis ed throughout <lb/>t b ; t e ]. <lb/>So by Equation (7) we have <lb/>EU(P 1 ) <lb/>Z dsa( ) <lb/>0 <lb/>CP(t 1 ; t 0 <lb/>1 ) dx <lb/>= <lb/>CP(t 1 ; t 0 <lb/>1 ) dsa( ) <lb/>Now let be the formula of highest dsa consistent with . The expected utility of plan <lb/>P 2 is highest if <lb/>1. with probability , holds throughout t 2 ; t 0 <lb/>2 ] and the atemporal component is com-<lb/>pletely satis ed at all time outside t 2 ; t 0 <lb/>2 ], and <lb/>2. with probability 1? the atemporal component is completely satis ed throughout the <lb/>interval t b ; t e ]. <lb/>Again by Equation (7): <lb/>EU(P 2 ) <lb/>&quot; Z dsa( ) <lb/>0 <lb/>CP(t B ; t E ) dx + <lb/>Z 1 <lb/>dsa( ) <lb/>CP(t B ; t 2 ) + CP(t 0 <lb/>2 ; t E ) dx <lb/># <lb/>+ (1 ? )(1) <lb/>= dsa( ) + (CP(t B ; t 2 ) + CP(t 0 <lb/>2 ; t E )) (1 ? dsa( )) ? 1] + 1 <lb/>and then P 1 dominates P 2 if <lb/>&gt; dsa( ) + (CP(t B ; t 2 ) + CP(t 0 <lb/>2 ; t E )) (1 ? dsa( )) ? 1] + 1 <lb/>CP(t 1 ; t 0 <lb/>1 ) dsa( ) <lb/>(11) <lb/></body>

            <page>27 <lb/></page>

            <body>6.2.2 Bounds for quantitative attributes <lb/>In this case our atemporal goal is stated in terms of some quantity Q, and the dsa function <lb/>associated with Q is monotonically increasing. We discover that P 1 is likely to achieve a <lb/>level of Q at least equal to k 1 throughout some subinterval t 1 ; t 0 <lb/>1 ] of the maintenance interval <lb/>t b ; t e ]; P 2 is likely to achieve a level of Q at most k 2 throughout some subinterval t 2 ; t 0 <lb/>2 ] of <lb/>t b ; t e ]. The two equations are: <lb/>P(HOLDS( (Q; k 1 ); t 1 ; t 0 <lb/>1 )jP 1 ) <lb/>P(HOLDS( (Q; k 2 ); t 2 ; t 0 <lb/>2 )jP 2 ) <lb/>Under what conditions can we say that P 1 &apos;s expected utility is greater than P 2 &apos;s? The <lb/>expected utility of P 1 is lowest if <lb/>1. with probability , a level k 1 for Q is maintained throughout the interval t 1 ; t 0 <lb/>1 ] and <lb/>Q has the value corresponding to a dsa of zero at all times outside of t 1 ; t 0 <lb/>1 ], and <lb/>2. with probability (1 ? ) Q has the value corresponding to a dsa of zero at all times <lb/>during t b ; t e ]. <lb/>Under those circumstances we know that <lb/>EU(P 1 ) <lb/>CP(t 1 ; t 0 <lb/>1 ) dsa(k 1 ) <lb/>The expected utility of plan P 2 is highest if <lb/>1. with probability , Q maintains a level of k 2 throughout the interval t 2 ; t 0 <lb/>2 and Q <lb/>maintains the value corresponding to complete satisfaction at all times outside t 2 ; t 0 <lb/>2 , <lb/>and <lb/>2. with probability 1 ? Q maintains the value corresponding to complete satisfaction <lb/>throughout the interval t B ; t E . <lb/>Then we know that <lb/>EU(P 2 ) <lb/>dsa(k 2 ) + (CP(t B ; t 2 ) + CP(t 0 <lb/> 2 ; t E )) (1 ? dsa(k 2 )) ? 1] + 1 <lb/>and then P 1 is preferred to P 2 if <lb/> &gt; dsa(k 2 ) + (CP(t B ; t 2 ) + CP(t 0 <lb/>2 ; t E )) (1 ? dsa(k 2 )) ? 1] + 1 <lb/>CP(t 1 ; t 0 <lb/>1 ) dsa(k 1 ) <lb/>(12) <lb/></body>

            <page>28 <lb/></page>

            <body>6.2.3 Bounds for strictly ordered atemporal attributes <lb/>Finally we reconsider the case of Section 6.1.3, where the atemporal component consists of a <lb/>conjunction of formulas that can be ordered such that each conjunct dominates those later <lb/>in the sequence. This time we establish that P 1 is likely to make the dominant attribute g 1 <lb/>true over some subinterval t 1 ; t 0 <lb/>1 ], and P 2 is likely to make that same attribute false over the <lb/>subinterval t 2 ; t 0 <lb/>2 ]: <lb/>P(g 1 (t 1 ; t 0 <lb/>1 )jP 1 ) <lb/>P(:g 1 (t 2 ; t 0 <lb/>2 )jP 2 ) <lb/>Under what conditions can we say that plan P 1 is preferable to plan P 2 ? This is just a <lb/>special case of an atemporal attribute, where the formula of lowest dsa consistent with g 1 is <lb/>g 1^i :g i and the formula of highest dsa consistent with :g 1 is <lb/>:g 1^i g i . So by <lb/>the results of section 6.2.1 plan P 1 is preferred to plan P 2 if <lb/>&gt; <lb/>dsa(:g 1^i g i ) + (CP(t B ; t 2 ) + CP(t 0 <lb/>2 ; t E )) (1 ? dsa(:g 1^i g i )) ? 1] + 1 <lb/>CP(t 1 ; t 0 <lb/>1 ) dsa(g 1^i :g i ) <lb/>(13) <lb/>6.3 Summary <lb/>The main point of this section was to establish circumstances under which the question of <lb/>whether one plan is preferable to another (in the sense of having higher expected utility) could <lb/>be answered by determining bounds on the probabilities of goal-related propositions. The <lb/>general procedure for determining that a plan P 1 dominates a plan P 2 is to nd a proposition <lb/>associated with high (atemporal) satisfaction that P 1 is likely to achieve and a proposition <lb/>associated with low atemporal satisfaction that P 2 is likely to achieve. We then compare <lb/>the worst case for P 1 (that it establishes with low probability, and otherwise provides <lb/>no atemporal goal satisfaction) agains the best case for P 2 (that it establishes with low <lb/>probability, and the rest of the time provides complete goal satisfaction). This analysis leads <lb/>to an inequality involving the probabilities of and , indicating circumstances under which <lb/>P 1 dominates P 2 . We provided equations for symbolic, numeric, and ordered conjunctive <lb/>atemporal attributes, rst for deadline goals (Equations (8), (9), and (10)) and analogously <lb/>for maintenance goals (Equations (11), (12), and (13)). <lb/>The analysis in this section studies a single goal in isolation; we next consider a multi-goal <lb/>utility model, and how it can be exploited in the process of generating plans. <lb/>7 Multiple Goals, Residual Utility, and Computational <lb/>Issues <lb/>The previous sections established bounds on the probabilities of outcomes that could be used <lb/>to determine whether one plan is preferable to another. These analyses were performed on <lb/></body>

			<page>29 <lb/></page>

			<body>the utility functions for individual goals, implicitly assuming that utility for other goals and <lb/>for resource consumption were the same. <lb/>The assumption that global utility is linear additive in the goal utilities (Section 3) <lb/>makes explicit the tradeo between satisfying the top-level goals, and between satisfying a <lb/>goal and consuming resources. The assumption that resource consumption (counted in the <lb/>residual utility term) is independent of the goal utilities means that we can regard resource <lb/>consumption as a goal as well. Take the two-goal case, for example, for which we can write <lb/>the equation for the expected utility of a plan P as follows: <lb/>EU(P) = k 1 EU 1 (P) + k 2 EU 2 (P) + k r EU r (P) <lb/>(14) <lb/>where <lb/>EU i (P) = c UG i (c)P(cjP): <lb/>Now suppose that we have already generated a plan P 1 and we know its expected utility <lb/>EU(P 1 ) = u 1 . <lb/>Further suppose that we have begun generating an alternative plan P 2 , in particular we <lb/>have generated a subplan that achieves the rst goal. From this subplan we can compute <lb/>1. an upper bound on the utility associated with rst goal, EU 1 (P 2 ) u 12 , and <lb/>2. a minimum level of resource consumption which provides us with an upper bound on <lb/>residual utility, EU r (P 2 ) u r2 . <lb/>We can then calculate that for P 2 to be preferred to P 1 it must at least satisfy goal two to <lb/>the degree <lb/>EU 2 (P 2 ) u 1 ? k 1 u 12 ? k r u r2 <lb/>k 2 <lb/>which represents the required utility level for the second goal assuming no additional resource <lb/>consumption. Examining the symbolic structure of the second goal may indicate exactly <lb/>what propositions must be made true or what quantity level must be attained, and by when, <lb/>in order to attain that level of utility. The ratio between k r and k 2 along with the residual <lb/>utility function indicates how e ciently the second goal must be satis ed as well. <lb/>7.1 Plan generation and re nement <lb/>The results in previous sections all involved comparing two complete plans; the relationships <lb/>we provided reduced the question of which was preferable in the sense of maximizing utility <lb/>to one of establishing a relationship between probabilities over the symbolic attributes that <lb/>comprise one of the goal expressions. The algorithm in Hanks, 1993] exploits both the sym-<lb/>bolic content of the relationship and the numeric threshold to limit inference in establishing <lb/>whether or not this relationship holds. Therefore deciding which of two partial plans is <lb/>preferable might be considerably cheaper than computing the expected utility of each. <lb/></body>

            <page>30 <lb/></page>

            <body>The result earlier in this section demonstrates that given one complete plan and a partial <lb/>plan we can characterize the interesting possible completions of the partial plan|the ones <lb/>that satisfy the remaining goals with a certain probability and with a certain e ectiveness if <lb/>the second plan is to be preferred to the rst. Therefore deciding if a partial plan is worth <lb/>pursuing can be considerably cheaper than examining all of its completions. <lb/>The question arises in general, however, as to what extent these relationships can aid the <lb/>planning process. What can we say about the relationship between two partial plans? The <lb/>next two sections discuss how our model might be applied to two plan-generation paradigms: <lb/>partial-order planning and re nement planning. <lb/>7.1.1 Partial-order planning and search control <lb/>The buridan planner Kushmerick et al., 1993] is an extension to classical nonlinear planners <lb/>that allows uncertainty in the initial world state and in the e ects of operators. The buridan <lb/>algorithm takes as input a problem description (a goal formula and a probability distribution <lb/>over initial world states) and a probability threshold, and produces a plan that satis es <lb/>the goal with probability at least equal to the threshold. The analysis in this paper is <lb/>complementary: it is a theory of how to generate the threshold values, but does not suggest <lb/>an algorithm for exploiting them. <lb/>Two problems (at least) complicate the problem of applying our theory of utility to a <lb/>probabilistic planner like buridan. The rst is that the buridan algorithm generates a <lb/>lower bound on the probability that the current plan or its completions satisfy the goal, and <lb/>generally the lower the threshold the less work buridan need do to generate an appropriate <lb/>plan. A lower bound is of limited use in and of itself, however: you generally can&apos;t prove <lb/>one plan superior to another without a lower bound on the performance of one and an upper <lb/>bound on the other. The problem with a generative or transformational planner is that it is <lb/>can be impossible to establish the point at which the plan cannot be further improved. <lb/>The second limitation in applying our theory to buridan is that its notion of a goal is <lb/>limited to propositional formulas, so concepts of partial satisfaction, deadlines, and resources <lb/>are di cult to represent. Ongoing work is directed toward enhancing buridan&apos;s represen-<lb/>tation language so it can naturally represent the concepts developed in this paper, and <lb/>also to explore how this framework can be used to provide the planner with search-control <lb/>information. <lb/>7.1.2 Re nement planning <lb/>One special case of partial planning that is amenable to our analysis is that in which the <lb/>planner&apos;s only operation is to re ne its current plan, which amounts to replacing an abstract <lb/>action in the plan with a more speci c version of that action. More precisely a re nement <lb/>operator can never increase the set of possible outcomes consistent with the plan&apos;s execution, <lb/>and thus tends to resolve uncertainty about its quality. An abstract plan&apos;s outcomes are sets <lb/>of outcomes of more concrete plans. Since di erent probability and utility values may be <lb/>associated with each speci c outcome, in general a probability range and a utility range will <lb/></body>

			<page>31 <lb/></page>

			<body>be associated with each abstract outcome. Thus the expected utility of an abstract plan is <lb/>represented by an interval, which includes the expected utilities of all possible instantiations <lb/>of that abstract plan. Re ning the plan, i.e. choosing an instantiation, tends to narrow the <lb/>interval. Comparing two abstract plans can stop as soon as their expected-utility intervals <lb/>no longer overlap 4 . <lb/>The type of abstraction we use has been formalized by Tenenberg 1991] within the frame-<lb/>work of the STRIPS representation and termed inheritance abstraction. He contrasts this to <lb/>the type of abstraction used in ABSTRIPS Sacerdoti, 1974], which Tenenberg calls relaxed <lb/>model abstraction. For examples of the use of inheritance abstraction in plan generation <lb/>in a deterministic setting see Nau, 1987, Anderson and Farley, 1988]. The present work <lb/>generalizes the notion of inheritance abstraction by introducing time, probability, and utility <lb/>into the representation. <lb/>We illustrate the planning technique with an example. Consider the following problem <lb/>of planning a delivery task. We wish to generate the best plan for delivering two tons of <lb/>tomatoes from a farm to a warehouse within 85 minutes. The utility of a plan outcome is a <lb/>function of the deadline goal and the residual utility, which is determined by the amount of <lb/>fuel consumed. The components of the utility function are shown in Figure 7. The overall <lb/>utility is <lb/>U(c) = UG(c) + (:02)UR(c) <lb/>The delivery plan will consist of driving a truck from the depot to the farm, loading the <lb/>truck, and driving the loaded truck to the warehouse. Planning is the process of generating <lb/>this plan as well as choosing among the various ways this plan can be realized in such a <lb/>way that expected utility is maximized. The descriptions of the available actions are shown <lb/>in Figure 6. The action descriptions are similar to those in Hanks, 1990]. Actions have <lb/>conditional e ects, and are represented by a tree with conditions labeling the branches. The <lb/>leaves of the tree are labeled with the outcomes of the action. Deterministic actions are <lb/>labeled with a single outcome. The probability of an outcome is the probability conditioned <lb/>on the action and the conjunction of all conditions on all branches leading to the outcome. <lb/>Outcomes are described in terms of a duration, as well as any changes in attribute values. <lb/>Attributes are represented as functions of time. The variable t represents the beginning time <lb/>of the action, making the action descriptions temporally indexical. <lb/>There are two possible routes we can take from the depot to the farm: road A and road <lb/>B. Road A is longer but has no delays, while travel along road B might be delayed due to <lb/>construction. The probability that construction is taking place is 0.2. These options are <lb/>represented by the rst two action descriptions in the Figure 6. <lb/>Once at the farm we must load the truck. We have two trucks at the depot to choose <lb/>from: an open truck and a closed, cushioned truck. The open truck is easy to load, while <lb/>the closed truck can be loaded easily if a special quick-loading device is available. There is <lb/></body>

			<note place="footnote">4 Or when the intervals narrow to the point where the distinction between the two does not warrant <lb/>further attention, as Russell and Wefald, 1991b] point out. <lb/></note>

			<page>32 <lb/></page>

			<body>Go to farm <lb/>on road A <lb/>dur 1 = 30 <lb/>fuel(t+dur 1 ) = fuel(t)-1 <lb/>Go to farm <lb/>on road B <lb/>dur 2 = 15 <lb/>fuel(t+dur 2 ) = fuel(t)-1/2 <lb/>dur 2 = 45 <lb/>fuel(t+dur 2 ) = fuel(t)-1/2 <lb/>P(¬construction)=.8 <lb/>P(construction)=.2 <lb/>Load open <lb/>truck <lb/>Load closed <lb/>truck <lb/>dur 3 = 15 <lb/>tons-in-truck(t+dur 3 ) = 2 <lb/>P(quick-loader)=.8 <lb/>P(¬quick-loader)=.2 <lb/>dur 4 = 10 <lb/>tons-in-truck(t+dur 4 ) = 2 <lb/>dur 4 = 25 <lb/>tons-in-truck(t+dur 4 ) = 2 <lb/>Drive open truck <lb/>on mountain road <lb/>Drive open truck <lb/>on valley road <lb/>dur 5 = 60 <lb/>fuel(t+dur 5 ) = fuel(t)-2 <lb/>tons-delivered(t+dur 5 ) = (.8) tons-in-truck(t) <lb/>dur 6 = 90 <lb/>fuel(t+dur 6 ) = fuel(t)-3 <lb/>tons-delivered(t+dur 6 ) = (.9) tons-in-truck(t) <lb/>dur 6 = 90 <lb/>fuel(t+dur 6 ) = fuel(t)-3 <lb/>tons-delivered(t+dur 6 ) = tons-in-truck(t) <lb/>P(sunny) = .7 <lb/>P(cloudy) = .3 <lb/>Drive closed truck <lb/>on mountain road <lb/>Drive closed truck <lb/>on valley road <lb/>dur 7 = 60 <lb/>fuel(t+dur 7 ) = fuel(t)-2 <lb/>tons-delivered(t+dur 7 ) = tons-in-truck(t) <lb/>dur 7 = 90 <lb/>fuel(t+dur 7 ) = fuel(t)-3 <lb/>tons-delivered(t+dur 7 ) = tons-in-truck(t) <lb/>Figure 6: Action descriptions <lb/></body>

            <page>33 <lb/></page>

            <body>2 <lb/>0 <lb/>dsa <lb/>1 <lb/>tons <lb/>1 <lb/>165 <lb/>85 <lb/>time <lb/>ct <lb/>1 <lb/>UR <lb/>4.5 <lb/>2.5 <lb/>fuel <lb/>Figure 7: Speci cation of delivery utility function. <lb/></body>

			<page>34 <lb/></page>

			<body>an 80% chance this device will be available. The next two diagrams in the Figure 6 depict <lb/>these two actions. <lb/>Once the truck is loaded we must drive it to the warehouse. We have two routes to choose <lb/>from: the mountain road and the valley road. The mountain road is shorter but bumpy. <lb/>If we drive the open truck on the mountain road, the bottom 20% of the tomatoes will be <lb/>crushed. If we drive the open truck on the valley road and the sun is shining, the top 10% <lb/>of the tomatoes will be spoiled by the sun. This combination of options results in the last <lb/>four action descriptions in the Figure 6. <lb/>In order to perform the re nement type planning described, we organize the planning <lb/>knowledge in an abstraction/decomposition network, shown in Figure 8. Solid links show <lb/>decompositions Charniak and McDermott, 1985, Ch9], while dashed links show possible <lb/>re nements. For example the task \deliver tomatoes&quot; is decomposed into the sequence of <lb/>the two actions \go to farm&quot; and \load &amp; drive truck&quot;. The arrow between the actions <lb/>signi es temporal succession. The abstract action \go to farm&quot; can be realized by driving on <lb/>road A or road B. Since both elements of a decomposition must be realized, decomposition <lb/>links are AND links and since either element of an instantiation may be used, instantiation <lb/>links are OR links. So this network forms an AND/OR tree. <lb/>Descriptions of the abstract actions are shown in Figure 9. A set of actions is abstracted <lb/>by grouping together their outcomes into abstract outcomes which represent the range of <lb/>possible outcomes of the instantiations. Care must be taken to group together similar out-<lb/>comes. For example, the \drive open truck&quot; action is an abstraction of \drive open truck on <lb/>mountain road&quot; and \drive open truck on valley road.&quot; Since the single outcome of \drive <lb/>open truck on mountain road&quot; is more similar to the outcome of the upper branch of \drive <lb/>open truck on valley road&quot; than to the outcome of the lower branch, it is grouped with <lb/>the former. While similarity is fairly clear in this case, determining similarity of outcomes <lb/>with multiple attributes may not be straightforward in general. (In fact, one may wish to <lb/>produce more than one abstraction based on di erent similarity measures and try each one <lb/>on a given problem. One would use the hierarchy that resulted in the most pruning for the <lb/>given problem.) The outcomes of the abstract action are now speci ed simply as the range <lb/>of outcomes grouped together. Once the outcomes have been abstracted, probabilities must <lb/>be assigned to them. This is done by taking the range of probabilities of the outcomes in the <lb/>group. So for the \drive open truck&quot; action, the range on the upper branch is min(P(sunny), <lb/>1) max(P(sunny), 1)], which is just P(sunny) 1]. <lb/>Given this representation of the planning problem, we evaluate plans at the abstract level <lb/>and prune suboptimal plans before re ning candidate plans further. There are eight possible <lb/>plans implicitly encoded in the abstraction/decomposition network, and we want to choose <lb/>the one that maximizes expected utility. <lb/>According to the network, the task of delivering tomatoes is rst decomposed into going <lb/>to the farm and loading, then driving the truck. We can rst choose either which road to <lb/>take to the farm or which truck to load and drive. Suppose we make the latter choice rst. <lb/>Because the utility function is a function over chronicles, the value of a particular action in a <lb/>plan depends on when in the plan it occurs, so options can only be evaluated in the context <lb/></body>

			<page>35 <lb/></page>

			<body>deliver tomatoes <lb/>go to farm <lb/>load &amp; drive truck <lb/>road A <lb/>road B <lb/>load &amp; drive <lb/>open truck <lb/>load &amp; drive <lb/>closed truck <lb/>load open <lb/>truck <lb/>drive open truck <lb/>to warehouse <lb/>load closed <lb/>truck <lb/>drive closed truck <lb/>to warehouse <lb/>drive open on <lb/>mountain road <lb/>drive open on <lb/>valley road <lb/>drive closed on <lb/>mountain road <lb/>drive closed on <lb/>valley road <lb/>Figure 8: Abstraction/decomposition network <lb/></body>

            <page>36 <lb/></page>

            <body>Go to farm <lb/>dur 8 = [15 30] <lb/>fuel(t+dur 8 ) = fuel(t)-[1/2 1] <lb/>dur 8 = 45 <lb/>fuel(t+dur 8 ) = fuel(t)-1/2 <lb/>[P(¬construction) 1] <lb/>[0 P(construction)] <lb/>Drive open truck <lb/>dur 9 = [60 90] <lb/>fuel(t+dur 9 ) = fuel(t)-[2 3] <lb/>tons-delivered(t+dur 9 ) = [.8 .9] tons-in-truck(t) <lb/>dur 9 = 90 <lb/>fuel(t+dur 9 ) = fuel(t)-3 <lb/>tons-delivered(t+dur 9 ) = tons-in-truck(t) <lb/>[P(sunny) 1] <lb/>[0 P(cloudy)] <lb/>Drive closed truck <lb/>dur 10 = [60 90] <lb/>fuel(t+dur 10 ) = fuel(t)-[2 3] <lb/>tons-delivered(t+dur 7 ) = tons-in-truck(t) <lb/>Figure 9: Abstract action descriptions <lb/></body>

			<page>37 <lb/></page>

			<body>P 1 : Go to farm ?! Load &amp; drive open truck <lb/>chronicle time <lb/>fuel <lb/>tons U(chronicle) probability <lb/>c 1 <lb/>90 135] 2.5 4] 1.6 1.8] .005 .02] <lb/>.56 1] <lb/>c 2 <lb/>120 135] 3.5 4] <lb/>2 <lb/>.380 .5725] <lb/>0 .3] <lb/>c 3 <lb/>120 150] 2.5 3.5] 1.6 1.8] <lb/>.01 .02] <lb/>0 .2] <lb/>c 4 <lb/>150 <lb/>3.5 <lb/>2 <lb/>.1975 <lb/>0 .06] <lb/>P 2 : Go to farm ?! Load &amp; drive closed truck <lb/>chronicle time <lb/>fuel <lb/>tons U(chronicle) probability <lb/>c 1 <lb/>85 130] 2.5 4] <lb/>2 <lb/>.4425 1.02] <lb/>.64 .8] <lb/>c 2 <lb/>100 145] 2.5 4] <lb/>2 <lb/>.255 .8325] <lb/>.16 .2] <lb/>c 3 <lb/>115 145] 2.5 3.5] <lb/>2 <lb/>.255 .635] <lb/>0 .16] <lb/>c 4 <lb/>130 160] 2.5 3.5] <lb/>2 <lb/>.0675 .4475] <lb/>0 .04] <lb/>Table 1: Highest level abstract plan outcomes. <lb/>of an overall plan. Consequently, we combine the \load &amp; drive open truck&quot; and the \load <lb/>&amp; drive closed truck&quot; actions with the \go to farm&quot; action to obtain a complete abstract <lb/>plan that can be evaluated. <lb/>Each abstract plan results in four chronicles (Table 1). For example, for plan P 1 we <lb/>obtain these chronicles by concatenating the \go to farm,&quot; \load open truck,&quot; and \drive <lb/>open truck&quot; action descriptions. Doing so results in four chronicles, since \go to farm&quot; and <lb/>\drive open truck&quot; each have two branches. Rather than showing the complete chronicles, <lb/>the relevant attributes of the resulting chronicles are summarized in Table 1, which shows <lb/>for each chronicle the range of times, fuel consumption, and tons of tomatos delivered. The <lb/>time refers to the time that the delivery is made. We assume that the plan begins execution <lb/>at time zero and we take the beginning time of an action to be the beginning time of the <lb/>previous action plus its duration. So for example the fuel consumption for chronicle c 1 is <lb/>computed according to <lb/>fuel(dur 8 ) = fuel(0) ? :5 1] <lb/>fuel(dur 8 + dur 9 ) = fuel(dur 8 ) ? 2 3] <lb/>so <lb/>fuel(dur 8 + dur 9 ) = fuel(0) ? 2:5 4] <lb/>We illustrate how the utility range is computed by showing the computation for chronicle <lb/>c 2 of plan P 1 ; the computation for the other chronicles is similar. Let UG min and UG max <lb/>be the lower and upper bounds on the goal utility, respectively, and let UR min and UR max <lb/>be the lower and upper bounds on residual utility, respectively. Since we are computing the <lb/>utility of a deadline goal, we can minimize the utility of the abstract chronicle by choosing <lb/></body>

            <page>38 <lb/></page>

            <body>the latest delivery times and the smallest delivery amounts, we can maximize the utility by <lb/>choosing the earliest delivery times and the largest amounts. So <lb/>UG max (c 2 ) = dsa(2) ct(120) = 0:5625 <lb/>UG min (c 2 ) = dsa(2) ct(135) = 0:375 <lb/>UR min (c 2 ) = 0:25 <lb/>UR max (c 2 ) = 0:5 <lb/>Since our global utility function is U(c) = UG(c) + (0:02)UR(c), we have U(c 2 ) = 0.380 <lb/>0.5725]. <lb/>Using the utility and probability information in the table we can compute the expected <lb/>utility bounds for each plan. Computing a bound for a plan involves choosing the probabili-<lb/>ties within the given ranges that minimize and maximize the expected utility. We can do so <lb/>by solving a small linear programming problem in which the objective function is the expres-<lb/>sion for the expected utility and the constraints are the probability bounds. For example, <lb/>the upper bound for plan P 1 can be computed by maximizing the objective function <lb/>:02p 1 + :5725p 2 + :02p 3 + :1975p 4 <lb/>subject to the constraints <lb/>:56 p 1 1 <lb/>0 p 2 :3 <lb/>0 p 3 :2 <lb/>0 p 4 :06 <lb/>p 1 + p 2 + p 3 + p 4 = 1 <lb/>The maximizing probabilities are <lb/>p 1 = .56 <lb/>p 2 = .3 <lb/>p 3 = .08 <lb/>p 4 = .06 <lb/>So the upper bound on expected utility is <lb/>(:56)(:02) + (:3)(:5725) + (:08)(:02) + (:06)(:1975) = :1964 <lb/>So for plan P 1 and P 2 we obtain the expected utility ranges <lb/></body>

            <page>39 <lb/></page>

            <body>P 2:1 : Go to farm ?! Load closed truck ?! Drive closed on mountain road <lb/>chronicle time <lb/>fuel tons U(chronicle) <lb/>probability <lb/>c 1 <lb/>85 100] 2.5 3] 2 <lb/>.8275 1.02] <lb/>.64 .8] <lb/>c 2 <lb/>100 115] 2.5 3] 2 <lb/>.64 .8325] <lb/>.16 .2] <lb/>c 3 <lb/>115 <lb/>2.5 <lb/>2 <lb/>.645 <lb/>0 .16] <lb/>c 4 <lb/>130 <lb/>2.5 <lb/>2 <lb/>.4575 <lb/>0 .04] <lb/>P 2:2 : Go to farm ?! Load closed truck ?! Drive closed on valley road <lb/>chronicle time <lb/>fuel tons U(chronicle) <lb/>probability <lb/>c 1 <lb/>115 130] 3.5 4] 2 <lb/>.4425 .635] <lb/>.64 .8] <lb/>c 2 <lb/>130 145] 3.5 4] 2 <lb/>.255 .4475] <lb/>.16 .2] <lb/>c 3 <lb/>145 <lb/>3.5 <lb/>2 <lb/>.26 <lb/>0 .16] <lb/>c 4 <lb/>160 <lb/>3.5 <lb/>2 <lb/>.0725 <lb/>0 .04] <lb/>Table 2: Intermediate level abstract plan outcomes. <lb/>EU(P 1 ) = .005 .1964] <lb/>EU(P 2 ) = .3673 .9825]. <lb/>Since the lower bound for P 2 is greater than the upper bound for P 1 , we can eliminate <lb/>from consideration all possible re nements of P 1 and concentrate on re ning P 2 . So at this <lb/>point we have chosen the option of using the closed truck. By making this choice, we have <lb/>pruned away the left-hand subnetwork underneath the \load &amp; drive truck&quot; node in Figure <lb/>8, resulting in pruning half the space of possible plans from consideration. <lb/>We are left with two more actions to re ne: \go to farm&quot; and \drive closed truck to <lb/>warehouse.&quot; Suppose we next choose to re ne the \drive&quot; action. Again the instantiations <lb/>involving the mountain road and the valley road must be evaluated in the context of a <lb/>complete plan. So we compose the descriptions of the concrete actions \drive closed on <lb/>mountain road&quot; and \drive closed on valley road&quot; with the descriptions of the concrete <lb/>action \load closed truck&quot; and the abstract action \go to farm.&quot; Table 2 summarizes the <lb/>outcomes for the two alternative plans. We use this information to compute expected-utility <lb/>bounds for the two alternatives: <lb/>EU(P 2:1 ) = .7533 .9825] <lb/>EU(P 2:2 ) = .3683 .5975]. <lb/>Notice that the EU intervals for the two plans are contained in the EU interval for the <lb/>abstract plan of which they are a re nement. Since the lower bound for plan P 2:1 is greater <lb/>than the upper bound for plan P 2:2 , we can eliminate P 2:2 from consideration, pruning away <lb/>two more possible concrete plans. By eliminating plan P 2:2 , we have chosen to take the <lb/>mountain road. <lb/>Finally we re ne plan P 2:1 . Our two options are taking either road A or road B to the <lb/>farm. The outcomes of the plans incorporating these options are summarized in table 3. <lb/></body>

            <page>40 <lb/></page>

            <body>P 2:1:1 : Go to farm on road A ?! Load closed truck ?! Drive closed on mountain road <lb/>chronicle time fuel tons U(chronicle) <lb/>probability <lb/>c 1 <lb/>100 3 <lb/>2 <lb/>.8275 <lb/>.8 <lb/>c 2 <lb/>115 3 <lb/>2 <lb/>.64 <lb/>.2 <lb/>P 2:1:2 : Go to farm on road B ?! Load closed truck ?! Drive closed on valley road <lb/>chronicle time fuel tons U(chronicle) <lb/>probability <lb/>c 1 <lb/>85 2.5 2 <lb/>1.02 <lb/>.64 <lb/>c 2 <lb/>100 2.5 2 <lb/>.8325 <lb/>.16 <lb/>c 3 <lb/>115 2.5 2 <lb/>.645 <lb/>.16 <lb/>c 4 <lb/>130 2.5 2 <lb/>.4575 <lb/>.04 <lb/>Table 3: Concrete plan outcomes. <lb/>Since the plans now include only concrete actions, the attribute, probability, and utility <lb/>values are now point values. The expected utilites of the two remaining plans are <lb/>EU(P 2:1:1 ) = .79 <lb/>EU(P 2:1:2 ) = .9075 <lb/>so we choose plan P 2:1:2 . Since this is a complete concrete plan, we have generated the plan <lb/>that maximizes expected utility and are nished. <lb/>Although it is probably unrealistic to expect any planner to employ only re nement <lb/>operators, the idea of modeling an execution system using a hierarchy of abstract actions is <lb/>consistent with Firby&apos;s 1989] RAP system, and the architecture for planning and execution <lb/>proposed in Hanks and Firby, 1990]. <lb/>8 Summary and Related Work <lb/>Our goal in this work was to take the concept of goals as they have been used in symbolic <lb/>planning systems and simultaneously extend their functionality and recast the intuitions in <lb/>a form that can be exploited by a decision-theoretic planning algorithm. <lb/>Our framework involves building a utility model rst by identifying the agent&apos;s top-<lb/>level goals plus the residual attributes that measure resource consumption and production <lb/>in service of those goals. The assumption of utility independence among these attributes <lb/>means that their interactions can be summarized by n + 1 numeric parameters representing <lb/>the relative weights for the n goals and residual attributes. <lb/>We then extended the notion of a goal to one that involves both a temporal component <lb/>(deadline or maintenance interval) and an atemporal component (a formula to be achieved <lb/>subject to the temporal constraint). We discussed various forms for the atemporal goal com-<lb/>ponent: symbolic and numeric attributes, conjunctions of numeric attributes, and ordered <lb/>conjunctions. <lb/></body>

            <page>41 <lb/></page>

            <body>For each of the goals the user supplies two components that describe preferences over <lb/>partial-satisfaction scenarios: the atemporal degree of satisfaction function and the tempo-<lb/>ral weighting coe cient. The former de nes what it means to satisfy the goal&apos;s atemporal <lb/>component, either partially or fully. The latter indicates how utility declines as a function <lb/>of missing the deadline or violating the maintenance interval. We described how to com-<lb/>bine those functions to produce a utility function for the entire goal. The problem was how <lb/>to combine partial satisfaction of both the atemporal and the temporal components simul-<lb/>taneously, and we developed model in which utility is accrued each time the value of the <lb/>atemporal component increases over the interval de ned by the temporal coe cient. <lb/>We then showed how the model&apos;s information, both numeric and symbolic, could be <lb/>exploited to compare plans: to decide whether one plan&apos;s expected utility was greater than <lb/>another and to generate bounds on the quality of a partial plan in order that it should be <lb/>chosen over an alternative. The general form of these relationships was to consider a plan P 1 <lb/>that was likely to achieve at worst a high level of satisfaction, and a plan P 2 that was likely <lb/>to achieve at best a low level of satisfaction. The result was a function of the respective <lb/>formulas, their likelihoods, and their times, ensuring that P 1 &apos;s expected utility was greater <lb/>than P 2 &apos;s, regardless of the two plans&apos; other e ects. <lb/>Finally we demonstrated how these relationships could be exploited by two existing plan-<lb/>ning techniques, particularly in the area of re nement planning. <lb/>8.1 Related work <lb/>A discussion of related work should begin with a mention of multiattribute decision theory, <lb/>especially Keeney and Rai a, 1976]. What we have done is built a multiattribute utility <lb/>model for goal-oriented planning problems that feature partial goal satisfaction and dead-<lb/>lines. <lb/>Our discussion of strictly ordered goals was motivated by the work in goal program-<lb/>ming Schniederjans, 1984] a mathematical optimization technique that deals with ordered <lb/>con icting goals. <lb/>8.1.1 Goals and utility models <lb/>In the AI literature the work closest to our own is by Wellman and Doyle 1991], Wellman and <lb/>Doyle, 1992], which also analyzes the relationship between goals and preference structures. <lb/>Their work confronts the question of what it means to say that an agent has some goal. The <lb/>most fundamental di erence between their work and ours is that they begin by examining <lb/>an agent&apos;s preference structure directly and produce a de nition of what it means to say <lb/>that an agent has a goal . In contrast, we adopt various intuitive notions about goals at <lb/>the outset (e.g. that they are utility independent at the top level), and structure the agent&apos;s <lb/>utility function (and therefore his preferences) to accommodate those ideas. Our work is <lb/>mainly oriented toward using the resulting structure to build and exploit representations <lb/>for concepts like partial satisfaction and temporal deadlines in the process of building and <lb/>comparing plans. <lb/></body>

            <page>42 <lb/></page>

            <body>A few e orts have been made in the classical planning literature to extend the form of <lb/>goal expressions: Drummond, 1989] introduces a crudeform of maintenance goals, allowing <lb/>the constraint that a proposition remain true throughout the execution of a plan. Vere, <lb/>1983] implements a concept related to deadline goals: a temporal window or interval within <lb/>which an action must be executed, and Dean et al., 1988] handles deadlines and actions <lb/>with duration. None of these e orts incorporate uncertainty or partial satisfaction into the <lb/>representation, nor do they consider partial satisfaction of the goal&apos;s atemporal component. <lb/>8.1.2 Decision-theoretic planning and control <lb/>Decision-theoretic techniques have been applied both to the planning problem Koenig, 1992], <lb/>Feldman and Sproull, 1975], Dean and Kanazawa, 1989] and to the problem of control-<lb/>ling reasoning|choosing among computational actions as well as those that make physical <lb/>changes to the world Russell and Wefald, 1991a], Boddy, 1991], Etzioni, 1991], Horvitz et <lb/>al., 1989]. <lb/>Most of these works use some variant of the utility model common to Markov decision <lb/>processes Howard, 1960]: there is a reward function associated with certain states and a <lb/>cost function associated with actions. The value of a plan is the value associated with the <lb/>end state less the cost of the actions (e.g. the time they consume) that comprise the plan. <lb/>This model implies a number of assumptions about the agent&apos;s preference structure. <lb/>First it assumes that the value and cost attributes are measured in units that are directly <lb/>comparable. Second the idea that reward is accrued as a result of arriving at a \goal&quot; state <lb/>means that any value or cost associated with achieving the goal must be captured in the <lb/>cost attribute. There is no obvious way to capture maintenance and deadline goals, and no <lb/>model of partial goal satisfaction, either temporal or atemporal. <lb/>Etzioni&apos;s 1991] model is more similar to ours: admitting both partial satisfaction of the <lb/>goals and also the idea that the value of achieving the goal will tend to change over time. <lb/>Both of these elements are supplied directly to the model, in the form of three functions: <lb/>a function i(g) measuring the \intrinsic value&quot; of goal g, <lb/>a function d(s; g) measuring the extent to which goal g is satis ed in state s, and <lb/>a function F (i(g)d(s; g); s) measuring the extent to which the bene t of goal g should <lb/>be realized in state s. <lb/>The rst two functions correspond roughly to our atemporal component, the third to our <lb/>temporal weighting coe cient. There is no analogue in his model to our discussion of main-<lb/>tenance goals. He makes the same assumption we do about the utility independence of <lb/>top-level goals. <lb/>These e orts are basically complementary to ours: they make simplifying assumptions <lb/>about the utility model and concentrate on algorithms to solve the planning problem; we <lb/>develop a richer utility model but provide no algorithm, only relationships implied by the <lb/>model that might guide a planning algorithm. The challenge will be to integrate our model <lb/>and the relationships it implies into these algorithms. <lb/></body>

            <page>43 <lb/></page>

            <body>8.1.3 Fuzzy decision theory <lb/>The notion of partially satis ed goals and their role in the decision-making process appears <lb/>prominently in the literature on fuzzy mathematics and decision analysis. In particular our <lb/>notion of a degree of satisfaction function bears close resemblance to a fuzzy-set membership <lb/>function. The seminal paper in this area is Bellman and Zadeh, 1980]; also see the papers <lb/>in Zimmerman et al., 1984], of which the most relevant to this paper is Dubois and Prade, <lb/>1984]. They discuss the role of aggregation operators in the decision-making process. In the <lb/>language of fuzzy-set theory a goal may be expressed as a fuzzy set, a plan&apos;s membership <lb/>function with respect to that set indicates the extent to which the plan satis es that goal. An <lb/>aggregation operator combines membership functions for individual goals into an aggregate <lb/>membership function which is an indicator of global success|this is called the decision set. <lb/>A decision maker then selects an alternative that is \strongly&quot; a member of the decision set. <lb/>Dubois and Prade categorize and analyze various aggregation functions. <lb/>So our analysis is similar to the e orts in fuzzy decision making in that it emphasizes <lb/>the representation problems associated with expressing partial satisfaction of goals. Fuzzy <lb/>sets may be a more appropriate representation than degree of satisfaction when the latter <lb/>(a numeric function) cannot reasonably be assessed. If we can only assess vague satisfaction <lb/>measures like \reasonably well satis ed,&quot; \utter failure,&quot; and \complete success,&quot; the fuzzy-<lb/>set methodology provides a way to incorporate these measures into a precise analysis. As <lb/>such it is essentially complementary to our analysis. <lb/>8.2 Future work <lb/>The formal model can be extended to cover more types of goals. The representation in this <lb/>paper covers only goals that mention facts but goals can refer to events as well. An example <lb/>might be \ ip the switch at noon.&quot; Goals mentioning events would be restricted to deadline <lb/>goals since it does not make sense to maintain an event over an interval of time. Deadline <lb/>goals involving events could be represented in a way similar the representation of goals with <lb/>a symbolic atemporal component. But the current de nition could not be used unchanged <lb/>since we have de ned DSA in terms of formulas that hold at time points, while events occur <lb/>over time intervals. <lb/>Deadline goals will often have a maintenance component to them: we want to achieve a <lb/>given state by a time and once achieved we want it to persist for a given period of time. The <lb/>expressions for deadline and maintenance goals could be combined to represent such goals. <lb/>We would perform a maintenance goal computation at each time that a term for deadline <lb/>goal utility is calculated, i.e., at each time that DSA changes to a value higher than any <lb/>previous value. At each of these times, we would perform a maintenance goal computation. <lb/>The most important area of future work is to incorporate our model into decision-theoretic <lb/>planning algorithms. We have mentioned several candidates above: the state-space planners <lb/>based on Markov decision processes, and two symbolic algorithms|probabilistic nonlinear <lb/>planning and re nment planning. We are currently working on an implementation of the <lb/>re nement planning algorithm. But to handle a realistic range of problems, the algorithm <lb/></body>

            <page>44 <lb/></page>

            <body>needs to be extended in several ways. In the example, actions have only discrete outcomes but <lb/>more realistically some actions would be described in terms of a continuous distribution over <lb/>outcomes, e.g. a normal distribution over durations. Representing such distributions is not <lb/>di cult but we need to nd ways of grouping such distributions to describe the outcomes of <lb/>abstract actions. Our network decomposed actions into totally ordered sequences of actions. <lb/>We need to incorporate other decompositions such as partial orders. Our example included <lb/>no interacting actions. We need to develop mechanisms to handle interactions such as the <lb/>e ects of one action depending on the choice of a previous action. This particular interaction <lb/>can be handled by an application of abstraction. It is probably unrealistic to expect that <lb/>a planner will explicitly store all possible action decompositions, so we need to integrate <lb/>the re nement algorithm with a nonlinear planner to generate the decompositions on the <lb/>y. Finally we need to test the e ectiveness of both the representation and the planning <lb/>algorithm on some large problems. <lb/></body>

			<listBibl>References <lb/>Anderson and Farley, 1988] J. Anderson and A. Farley. Plan abstraction based on operator <lb/>generalization. In Proceedings AAAI, pages 100{104, 1988. <lb/>Bellman and Zadeh, 1980] R.E. Bellman and L.A. Zadeh. Decision-making in a Fuzzy En-<lb/>vironment. Management Science, 17:B141{B164, 1980. <lb/>Boddy, 1991] Mark Boddy. Solving Time-Dependent Problems: A Decision-Theoretic Ap-<lb/>proachPlanning in Dynamic Environments. Technical Report CS{91{06, Brown Univer-<lb/>sity, Department of Computer Science, May 1991. <lb/>Charniak and McDermott, 1985] E. Charniak and D. McDermott. Introduction to Arti cial <lb/>Intelligence. Addison-Wesley, Reading, MA, 1985. <lb/>Dean and Kanazawa, 1989] Tom Dean and Keiji Kanazawa. A Model for Projection and <lb/>Action. In Proceedings IJCAI, pages 985{990, 1989. <lb/>Dean et al., 1988] T. Dean, J. Firby, and D. Miller. Hierarchical Planning involving dead-<lb/>lines, travel times, and resources. Computational Intelligence, 4(4):381{398, 1988. <lb/>Drummond, 1989] M. Drummond. Situated Control Rules. In Proceedings of the First <lb/>International Conference on Knowledge Representation and Reasoning, May 1989. <lb/>Dubois and Prade, 1984] Didier Dubois and Henri Prade. Criteria Aggregation and Rank-<lb/>ing of Alternatives in the Framework of Fuzzy Set Theory. In H.J Zimmerman, L.A. <lb/>Zadeh, and B.R Gaines, editors, Fuzzy Sets and Decision Analysis, pages 209{240. North <lb/>Holland, 1984. <lb/>Etzioni, 1991] Oren Etzioni. Embedding Decision-analytic Control in a Learning Architec-<lb/>ture. Arti cial Intelligence, 1{3(49):129{160, 1991. <lb/></listBibl>

            <page>45 <lb/></page>

            <listBibl>Feldman and Sproull, 1975] J.R. Feldman and R.F. Sproull. Decision Theory and Arti cial <lb/>Intelligence II: The Hungry Monkey. Cognitive Science, 1:158{192, 1975. <lb/>Firby, 1989] R. James Firby. Adaptive Execution in Complex Dynamic Worlds. Technical <lb/>Report 672, Yale University, Department of Computer Science, January 1989. <lb/>Haddawy and Hanks, 1990] Peter Haddawy and Steve Hanks. Issues in Decision-Theoretic <lb/>Planning: Symbolic Goals and Numeric Utilities. In DARPA Workshop on Innovative <lb/>Approaches to Planning, Scheduling, and Control. Morgan Kaufmann, November 1990. <lb/>Haddawy, 1991a] P. Haddawy. A Temporal Probability Logic for Representing Actions. In <lb/>Richard Fikes James Allen and Erik Sandewall, editors, Principles of Knowledge Represen-<lb/>tation and Reasoning: Proceedings of the Second International Conference, pages 196{207. <lb/>Morgan Kaufman, San Mateo, CA, 1991. <lb/>Haddawy, 1991b] P. Haddawy. Representing Plans Under Uncertainty: A Logic of Time, <lb/>Chance, and Action. PhD thesis, University of Illinois, 1991. (Report no. UIUCDCS-R-<lb/>91-1719). <lb/>Hanks and Firby, 1990] Steve Hanks and R. James Firby. Issues and Architectures for <lb/>Planning and Execution. In DARPA Workshop on Innovative Approaches to Planning, <lb/>Scheduling, and Control. Morgan Kaufmann, November 1990. <lb/>Hanks and McDermott, 1993] Steve Hanks and Drew McDermott. Modeling a Dynamic <lb/>and Uncertain World I: Symbolic and Probabilistic Reasoning about Change. Arti cial <lb/>Intelligence, 1993. To appear. <lb/>Hanks, 1990] Steven Hanks. Projecting Plans for Uncertain Worlds. Technical Report 756, <lb/>Yale University, Department of Computer Science, January 1990. <lb/>Hanks, 1993] Steven Hanks. Modelling a Dynamic and Uncertain World II: Action Repre-<lb/>sentation and Plan Evaluation. Journal of Logic and Computation, 1993. Submitted. <lb/>Horvitz et al., 1989] Eric J. Horvitz, Gregory F. Cooper, and David E. Heckerman. Re ec-<lb/>tion and Action Under Scarce Resources: Theoretical Principles and Empirical Study. In <lb/>Proceedings IJCAI, pages 1121{1127, 1989. <lb/>Howard, 1960] Ronald A. Howard. Dynamic Programming and Markov Processes. MIT <lb/>Press, 1960. <lb/>Keeney and Rai a, 1976] Ralph L. Keeney and Howard Rai a. Decisions with Multiple <lb/>Objectives: Preferences and Value Tradeo s. John Wiley &amp; Sons, 1976. <lb/>Koenig, 1992] Sven Koenig. Optimal Probabilistic and Decision-Theoretic Planning using <lb/>Markovian Decision Theory. Technical Report UCB/CSD 92/685, Computer Science Di-<lb/>vision (EECS), UC Berkeley, May 1992. <lb/></listBibl>

			<page>46 <lb/></page>

			<listBibl>Kushmerick et al., 1993] Nick Kushmerick, Steve Hanks, and Dan Weld. An Algorithm for <lb/>Probabilistic Planning. Arti cial Intelligence, 1993. Submitted. <lb/>McDermott, 1982] Drew McDermott. A Temporal Logic for Reasoning About Processes <lb/>and Plans. Cognitive Science, 6:101{155, 1982. <lb/>Nau, 1987] D. Nau. Hierarchical abstraction for process planning. In Proc. of the Int&apos;s <lb/>Conference on Applications of Arti cial Intelligence in Engineering, 1987. <lb/>Russell and Wefald, 1991a] Stuart J. Russell and Eric H. Wefald. Do the Right Thing: <lb/>Studies in Limited Rationality. MIT Press, 1991. <lb/>Russell and Wefald, 1991b] Stuart J. Russell and Eric H. Wefald. Principles of Metarea-<lb/>soning. Arti cial Intelligence, 1{3(49):361{396, 1991. <lb/>Sacerdoti, 1974] E.D. Sacerdoti. Planning in a hierarchy of abstraction spaces. Arti cial <lb/>Intelligence, 5(2):115{135, 1974. <lb/>Schniederjans, 1984] Marc J. Schniederjans. Linear Goal Programming. Petrocelli Books, <lb/>1984. <lb/>Tenenberg, 1991] J.D. Tenenberg. Reasoning About Plans, chapter Abstraction in Planning, <lb/>pages 213{283. Morgan Kaufmann, San Mateo, CA, 1991. <lb/>Vere, 1983] S. Vere. Planning in Time: Windows and Durations for Activities and Goals. <lb/>IEEE Trans. on Pattern Analysis and Machine Intelligence, 5, 1983. <lb/>Wellman and Doyle, 1991] Michael P. Wellman and Jon Doyle. Preferential Semantics for <lb/>Goals. In Proceedings AAAI, 1991. <lb/>Wellman and Doyle, 1992] Michael P. Wellman and Jon Doyle. Modular Utility Represen-<lb/>tation for Decision-Theoretic Planning. In Proceedings, First International Conference on <lb/>AI Planning Systems, 1992. <lb/>Zimmerman et al., 1984] H.J Zimmerman, L.A. Zadeh, and B.R Gaines, editors. Fuzzy Sets <lb/>and Decision Analysis. North Holland, 1984. TIMS Studies in the Management Sciences, <lb/>Volume 20. <lb/></listBibl>

			<page>47 </page>


	</text>
</tei>
