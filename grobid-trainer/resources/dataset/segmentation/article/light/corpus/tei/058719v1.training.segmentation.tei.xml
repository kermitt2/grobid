<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="_0"/>
	</teiHeader>
	<text xml:lang="en">
			<page>1 <lb/></page>

			<front>Operant Behavior in Model Systems <lb/>Author Contact Information <lb/>Björn Brembs <lb/>Universität Regensburg <lb/>Institute of Zoology -Neurogenetics <lb/>Universitätsstrasse 31 <lb/>93040 Regensburg, Germany <lb/>Phone: +49 941 943 3117 <lb/>bjoern@brembs.net <lb/>Abstract <lb/>In contrast to the long-held assumption that the organization of behavior is <lb/>best characterized as the perception of a sensory stimulus followed by appropriate <lb/>response (i.e., &quot;sensorimotor hypothesis&quot;), recent converging evidence from <lb/>multiple systems and fields of study instead suggests that both ancestral and <lb/>extant general brain function is best described in operant terms. Rather than <lb/>specifying precise behaviors, sensory information -if at all present -interacts <lb/>with ongoing neural activity to instruct the organism which type of spontaneous, <lb/>exploratory behavior to generate. Evaluating the ensuing reafferent feedback <lb/>modifies the nervous system such that ongoing neural activity patterns become <lb/>biased towards activity that has generated increased appetitive and decreased <lb/>aversive feedback in the past. The neurobiological mechanisms underlying both <lb/>the exploratory, spontaneous behaviors as well as those underlying the <lb/>modifications caused by the feedback are becoming increasingly understood, even <lb/>on a molecular level. It is straightforward to hypothesize that the constant <lb/>interaction between ongoing neural activity and the incoming sensory stream <lb/>allows the organism to balance behavioral flexibility with efficiency to accomplish <lb/>adaptive behavioral choice in an often unpredictably changing environment. <lb/>Keywords <lb/>Spontaneous behavior, reafference, operant, feedback, stimulus, response, <lb/>behavioral flexibility. <lb/></front>

			<body>Body text <lb/>1 Operant and Classical Conditioning <lb/>One of the traditional dichotomies in learning and memory research is that <lb/>between operant (instrumental) and classical (Pavlovian) conditioning. The <lb/>distinction between operant and classical conditioning is merely operational: <lb/>these terms denote how a learning experiment was conducted. In classical <lb/>conditioning, the animal&apos; s behavior has no influence over the stimuli it is <lb/></body>

			<page>2 <lb/></page>

			<body>presented with, while in operant conditioning the animal is in control at least of <lb/>the most relevant stimuli. The stimuli and behaviors in both classes of <lb/>experiments can be almost arbitrarily exchanged, as long as these rules are <lb/>obeyed. Already in the 1930s, Skinner and his contemporaries realized that, in <lb/>its simplest form, one could conceptualize what is being learned in a classical <lb/>conditioning experiment in only one single process, namely the association <lb/>between two stimuli. Following Pavlov, this concept can be described as <lb/>&quot; stimulus substitution&quot; where the conditioned stimulus (CS; e.g. a tone) <lb/>receives some of the response-eliciting properties of the unconditioned stimulus <lb/>(US; e.g. food). Note that this does not preclude the design of less minimal <lb/>experiments where the animals are allowed to learn more. Operant conditioning, <lb/>on the other hand, most likely comprises at least two, if not more processes: the <lb/>association between two stimuli and the association between the behavior of the <lb/>animal and one or more stimuli (Skinner, 1935, 1937; Konorski and Miller, 1937a, <lb/>1937b). This is what Skinner called the &quot;three-term-contingency&quot; of (I) the stimuli <lb/>that are present just before and during the behavior, (II) the behavior itself and <lb/>(III) the stimuli that the animal is presented with as a consequence of its behavior <lb/>(Skinner, 1969). Phrased differently, it was Pavlov&apos;s strike of genius to prevent <lb/>his dogs from interfering with the experiment by firmly tying them down, as it <lb/>significantly reduced the number of possible learning processes to those involved <lb/>in processing external stimuli. <lb/>From this brief recapitulation it becomes clear that already 80 years ago, <lb/>there was very little intrinsic reason to specifically juxtapose these two types of <lb/>experiments -the reason these classes of experiments are still taught and <lb/>discussed together today (e.g., Domjan, 2016) are more historical than logical. In <lb/>these eight decades, a wealth of literature has accumulated describing <lb/>experiments in which seemingly every possible relation and detail in the <lb/>configurations of stimuli and behaviors has been tested to compare and contrast <lb/>operant and classical conditioning. Despite all these efforts, until the advent of <lb/>modern neurobiological techniques, the more fundamental questions that Skinner <lb/>and his contemporaries started tossing around in the 1930s remained largely <lb/>unanswered. <lb/>1.1 Spontaneous Actions <lb/>While the relationship of the animal&apos;s behavior to antecedents was always <lb/>intuitively obvious in classical conditioning -after all, the US was chosen such <lb/>as to elicit a clear response -this relationship remained hotly debated in operant <lb/>conditioning until rather recently. Despite emphasizing the exploratory or <lb/>spontaneous nature of the (&apos;emitted&apos;, not &apos;elicited&apos;) behavior in operant <lb/>conditioning experiments (Skinner, 1938), the behavior was nevertheless <lb/>routinely referred to as a &apos;response&apos;, implying some eliciting factor (Dickinson, <lb/>1985). This ambiguity about whether or not one needed to describe the behavior <lb/>of animals in classical and operant conditioning experiments in different terms <lb/>has provoked discussions until this day (Domjan, 2016). Arguably, the ambiguity <lb/></body>

			<page>3 <lb/></page>

			<body>may be traced to the behaviorist effort to separate behaviorism from the <lb/>prevailing animist psychology of the early 20 th century on one side, while at the <lb/>same time emphasizing the difference to the more conventional schools of classical <lb/>conditioning, e.g., reflexology, on the other. As demonstrating spontaneous <lb/>behavior would require to demonstrate the absence of relevant antecedent <lb/>stimuli, making a firm case for operant behavior deserving a separate term proved <lb/>elusive (Domjan, 2016). <lb/>One of the arguments in this debate can be summarized as an argument from <lb/>incredulity: how could a behaving system evolve that produces behavior <lb/>unrelated to its environment, how could such organisms successfully coordinate <lb/>their actions with the world in which they live (e.g., (Domjan, 2016)? Today, we <lb/>know from various observations both in the field and in the laboratory, that <lb/>organisms without the capability to generate spontaneous actions would likely <lb/>not have survived long. Individual behavioral variability has been found to be <lb/>ecologically advantageous in game theoretical studies (McNamara et al., 2004; <lb/>Glimcher, 2005, 2003; Glimcher and Rustichini, 2004; Brembs, 1996), in pursuit-<lb/>evasion <lb/>contests <lb/>such <lb/>as <lb/>predator/prey <lb/>interactions <lb/>(&quot;Protean <lb/>Strategy&quot;)(Grobstein, 1994; Driver and Humphries, 1988; Shultz and Dunbar, <lb/>2006; Miller, 1997), in exploration/foraging (Belanger and Willis, 1996; Hills et <lb/>al., 2013; Humphries and Sims, 2014; Shlesinger, 2009; Reynolds et al., 2016), in <lb/>mobbing attack patterns by birds (Humphries and Driver, 1970) and in the <lb/>variation of male songbirds&apos; songs (Neuringer, 2004). Clearly, invariable <lb/>behavior will be exploited (Miller, 1997; Jabloń ski and Strausfeld, 2000; <lb/>Jablonski and Strausfeld, 2001; Catania, 2009, 2010, 2008; Mitra et al., 2009; <lb/>Corcoran et al., 2009) and leaves the animal helpless in unpredictable situations <lb/>(Brembs, 2009b, 2010; Heisenberg, 1994). <lb/>Two particular cases out of the multitude of examples for the evolutionary <lb/>benefits of spontaneous behavior deserve special mention, both because the <lb/>neurobiological mechanisms underlying the behavior are particularly well <lb/>understood and because these behaviors have been used in operant conditioning <lb/>experiments. <lb/>1.1.1 Aplysia feeding <lb/>The first example is that of the feeding behavior of the marine snail Aplysia. <lb/>These animals feed primarily on different species of seaweed, the texture of which <lb/>can range from mushy to too tough to eat. The animals use their radula, a <lb/>tongue-like organ, to grasp food and push it into the esophagus. The radula <lb/>typically consists of two halves which can be either protracted or retracted while <lb/>they are either open or closed. During initial feeding attempts, the animal <lb/>protracts its radula in the open state, then closes the two radula halves and then <lb/>retracts the radula, hopefully with a large chunk of edible seaweed enclosed in it <lb/>(ingestion). However, if the food-item is too tough to push it further into the <lb/>esophagus, the animal can also protract the radula while it is still closed around <lb/>the food, pushing it out of the mouth. The animal then retracts the radula in its <lb/>open state (rejection). <lb/></body>

			<page>4 <lb/></page>

			<body>There are two aspects to the spontaneous components of this behavior. <lb/>The first one concerns the spontaneous variability in the movement dynamics <lb/>of the first attempts to grasp the food and transport it towards the gut. Aplysia <lb/>initially generates highly variable biting and swallowing movements, in an <lb/>exploratory phase of feeding. During this time, the animal is exploring the state <lb/>space of the motor system in the buccal ganglia controlling the movements of <lb/>the radula. The animal is trying out which movements are most effective in term <lb/>of transporting food into the esophagus (Lum et al., 2005; Horn et al., 2004). <lb/>Reafferent (operant) feedback from dopaminergic fibers in the esophageal nerve <lb/>instruct the buccal ganglia which movements were more or less effective (Nargeot <lb/>et al., 1999c). This initial exploratory variability happens with all novel food <lb/>items, it can thus be said to be independent of the nature of the food stimulus. <lb/>The second aspect concerns biting behavior in the absence of any food. <lb/>Hungry Aplysia will spontaneously emit bites in the complete absence of any <lb/>food stimulus. Clearly, it is always possible to argue that some undefined <lb/>stimulus, commonly insufficient to elicit biting, becomes salient enough to trigger <lb/>biting when the animal is hungry enough. However, in addition to any perceived <lb/>implausibility of this argument, there is experimental evidence of neurons which <lb/>have evolved precisely to generate spontaneous behaviors. Isolated buccal ganglia <lb/>of hungry Aplysia will continue to generate the neural programs controlling the <lb/>radula in the intact animal, when placed in a petri dish with suitable medium <lb/>(Nargeot et al., 1999b, 1999a). These buccal motor programs (BMPs) occur <lb/>spontaneously in the most explicit of terms: all sensory organs have been cut <lb/>away, there cannot be any triggering stimuli in the petri dish. Moreover, the <lb/>timing of BMPs is not rhythmic, the type of BMPs varies between ingestion-and <lb/>rejection-like patterns and the intra-BMP dynamics vary from BMP to BMP. In <lb/>other words, the in vitro experiments validate the in vivo work on spontaneous, <lb/>exploratory biting behavior in Aplysia. <lb/>Physiological work on the neurons involved in generating BMPs identified a <lb/>class of neurons that appears to have evolved to generate crucial aspects of this <lb/>spontaneity (reviewed in (Nargeot and Simmers, 2012). Among the different <lb/>classes of neurons controlling radula movements are two in particular which are <lb/>relevant here. One of them, let&apos; s call them &quot;What&quot; neurons, fires during the <lb/>BMP and determine what type (ingestion-or rejection-like) of BMP will be <lb/>produced, by controlling the timing of activity in the closure motor neuron. A <lb/>second class of neurons, let&apos; s call them &quot;When&quot; neurons, fires right before a BMP <lb/>can be observed in the motor nerves. Experimentally stimulating any of these <lb/>When neurons will lead to the recording of a consecutive BMP in the motor <lb/>neurons immediately following the stimulation. Thus, while the What neurons <lb/>determine the type of behavior, the When neurons determine when a given <lb/>behavior is going to be emitted. Part of the variability in the intra-BMP temporal <lb/>dynamics comes from each BMP being initiated by a different neuron in the <lb/>When class. One reason for the variability in which of the When neurons will <lb/>start a BMP lies in the weak coupling between these neurons, preventing a <lb/>stereotyped sequence of activity from emerging between the When neurons. A <lb/></body>

			<page>5 <lb/></page>

			<body>second crucial contribution to this spontaneous variability besides the weak <lb/>coupling between them is the capability of individual When neurons to generate <lb/>spontaneous bursts of activity even in the complete absence of input from other <lb/>neurons. In contrast to the canonical neurons commonly studied, tonically <lb/>stimulating an experimentally isolated When neuron to near its firing threshold <lb/>leads to arrhythmic firing of the neuron (Nargeot and Simmers, 2012). The <lb/>underlying molecular mechanisms are just being discovered and involve <lb/>mathematically unstable, nonlinear calcium dynamics (Bedecarats et al., 2015). <lb/>In the context of what roles these neurons play in the control of spontaneous <lb/>behavior, it is straightforward to argue that these calcium dynamics have evolved <lb/>to support ecologically relevant behavioral spontaneity. <lb/>In an analogue of the operant feedback described above, one can use any of <lb/>these spontaneously generated BMPs and pair them with contingent stimulation <lb/>of the esophageal nerve (Nargeot et al., 1999b, 1999a). This experiment thus <lb/>establishes an in vitro operant conditioning paradigm out of a behavioral <lb/>observation in freely behaving animals. This fortunate combination of intact and <lb/>in vitro experiments, together with the exquisite physiological accessibility of <lb/>Aplysia, allows for an unmatched rigor in the study of the learning processes <lb/>actually taking place in the nervous system during operant conditioning. Perhaps <lb/>not surprisingly, one such process directly affects the spontaneity of the behavior. <lb/>More on that below. <lb/>Taken together, evidence both from intact animals and deafferentiated <lb/>nervous systems demonstrates which aspects and components of Aplysia feeding <lb/>behaviors are spontaneous in nature and what ultimate and proximate functions <lb/>this spontaneity serves. <lb/>1.1.2 Drosophila flight <lb/>Drosophila fruit flies with one injured wing are perfectly capable of flying <lb/>straight, provided the injury is not too severe to prevent flight completely. This <lb/>must seem like a remarkable feat to anyone steeped in the literature on how fixed <lb/>optomotor reflexes control straight flight in Drosophila. Unless the animal is born <lb/>with the knowledge of exactly which kind and amount of wing damage leads to <lb/>which effect on torque kinematics, there must be some reafferent feedback that <lb/>instructs the flies on the effectiveness of their turning maneuvers. Several <lb/>observations support the conclusion that flying straight is primarily an operant <lb/>behavior (reviewed in, e.g., Brembs, 2009b). For instance, one can experimentally <lb/>eliminate all optomotor responses (without rendering them blind) and the flies <lb/>are still able to fly straight. Crucially, these manipulated flies can do this even if <lb/>the feedback between their behavior and the environment is experimentally <lb/>reversed, i.e., left turning attempts lead to visual feedback that suggests a right <lb/>turn and vice versa (similar to inversion goggles in humans). These experiments <lb/>are done with the flies tethered to a torque meter, which measures the yaw torque <lb/>of the flies without them actually rotating in space. Surrounded by a visual <lb/>panorama that can be rotated around the flies instead, the experimenter has <lb/>exquisite control over the flies&apos; stimulus situation. Tethered optomotor-disabled <lb/></body>

			<page>6 <lb/></page>

			<body>flies manage to keep the visual panorama from rotating (i.e., fly straight) no <lb/>matter how the rotation is coupled to their torque behavior. This is in striking <lb/>difference to unmanipulated flies which need a very long time until they manage <lb/>to keep the panorama steady with inverted feedback (but do so within <lb/>milliseconds in regular coupling). Apparently, the inborn optomotor responses <lb/>impede the wild type flies in this experiment, while the symmetrical behavior of <lb/>the optomotor-impaired flies is evidence that they must use operant behavior to <lb/>minimize the amount of arena rotation in the absence of any sensory system <lb/>telling them the direction of rotation (Wolf and Heisenberg, 1986). As with the <lb/>example of Aplysia above, with these flies being partially deafferentiated, any of <lb/>their turning attempts must be spontaneous as there are no optomotor stimuli <lb/>being perceived that could elicit a turning response. <lb/>Another experiment brings us back to the ability of the flies to compensate <lb/>for one-sided wing injury. The kind of turning maneuvers the optomotor-<lb/>impaired flies are using to control their visual feedback can also be observed in <lb/>tethered wild type animals in a completely uniform environment. Similarly to <lb/>the manipulated flies, there are no visual stimuli known to elicit turning <lb/>attempts. Great care is taken to ensure that all the stimuli that are present, of <lb/>any modality, are as constant as experimentally possible. In fact, from the <lb/>experiments with external stimuli present, it is known that the remaining, <lb/>constant stimuli do not exert any detectable effect on top of the explicit stimuli. <lb/>Again, without complete experimental deafferentiation, it is impossible to be sure <lb/>that these sensory deprived animals are not responding to otherwise <lb/>unphysiological stimuli that bear no relation to flight under normal <lb/>circumstances. One would assume that these stimuli would be occurring <lb/>randomly, without any specific structure or pattern. In that case, the temporal <lb/>dynamics of the attempted turning behavior of such deprived flies should be <lb/>reminiscent of random noise. However, the temporal dynamics of these flies is <lb/>much more reminiscent of the mathematically unstable, nonlinear process <lb/>discovered in Aplysia. In a recent transgenic screen, we are beginning to identify <lb/>candidate circuits comprising the neurons that may be responsible for this <lb/>nonlinear signature. Interestingly, these structures appear to be located in the <lb/>same brain regions as those associated with the temporal structure of walking <lb/>behavior (Martin et al., 2001). Recent optophysiological work on zebrafish is also <lb/>beginning to identify the brain regions in the vertebrate brain where the temporal <lb/>structure spontaneous turning movements is controlled (Dunn et al., 2016). <lb/>Instead of visual feedback, one can use heat as a feedback in the tethered <lb/>flight experiment and let the fly use its turning attempts to control the punishing <lb/>heat beam (in a completely homogeneuous visual environment). When, e.g., left <lb/>turning attempts are punished, the fly shifts its baseline torque towards the <lb/>unpunished (e.g., right) direction, without eliminating superimposed <lb/>bidirectional fluctuations in torque, even after the heat is permanently switched <lb/>off (Wolf and Heisenberg, 1991). This capability is precisely what would be <lb/>required to compensate the reduced torque of a damaged wing: a shift in the <lb/>baseline torque output, operantly matched to the (visual) feedback, without <lb/></body>

			<page>7 <lb/></page>

			<body>eliminating the possibility for left and right turns from this new &apos;straight-flight&apos; <lb/>baseline. <lb/>Taken together, converging evidence from Aplysia and Drosophila suggests <lb/>that spontaneous behavior is controlled by an evolutionary conserved mechanism <lb/>that relies on unstable nonlinearities to explore the state space of the motor <lb/>system in search for favorable behavioral outputs. <lb/>2 Behavior is likely never a &quot;response&quot; <lb/>Given the spontaneous components in even highly stereotyped behaviors such <lb/>as feeding or optomotor control, one is tempted to examine what one may <lb/>consider the simplest stimulus-response systems for evidence of spontaneity. <lb/>2.1 Phototaxis in insects <lb/>One could consider the movement of insects towards a light source <lb/>(phototaxis) as one such system. The fact that insects get trapped at windows <lb/>or the proverbial moth that dies in a candle flame are iconoclastic examples of a <lb/>rigid stimulus-response organization of this behavior. But does insect phototaxis <lb/>stand up to scientific scrutiny? Already a hundred years ago, observations by <lb/>McEwen (1918) suggested that this behavior may be more complex than one <lb/>would at first expect. McEwen found that only startled flies would walk towards <lb/>the light in his small tube. Sitting flies did not seem to find a light very attractive, <lb/>suggesting that more than just light hitting the retina must be responsible for <lb/>triggering phototaxis. He also observed that flies with clipped wings do not <lb/>approach the light anymore, even when compared to walking, intact flies. This <lb/>observation was later confirmed in a different experiment, where the wings were <lb/>not only clipped but also genetically rendered useless for flight (Benzer, 1967). <lb/>Further experimentation revealed that at least for insects, the term &apos;phototaxis&apos; <lb/>may be inappropriate (Gorostiza et al., 2015). Rather than just affecting the <lb/>approach of a light source, the flies&apos; ability to fly affected their light/dark <lb/>preference across several different behavioral tests, none of which tested <lb/>phototaxis, but forced the flies to choose between more or less bright stimuli. If <lb/>flying ability was compromised only temporarily, the flies&apos; photopreference <lb/>reversed concomitantly. Neuronal activity in circuits expressing dopamine and <lb/>octopamine, respectively, doubly dissociated in this case of behavioral flexibility <lb/>(Gorostiza et al., 2015): activity in octopaminergic neurons was necessary and <lb/>sufficient to shift the flies&apos; preference towards darkness, while activity in <lb/>dopaminergic neurons was necessary and sufficient to shift the preference towards <lb/>brightness. The involvement of these biogenic amines suggests that valuation of <lb/>stimuli may play a role in the flies&apos; shifts in photopreference. Apparently, flies <lb/>monitor their ability to fly, and the outcome of this evaluation exerts a <lb/>fundamental effect on action selection -including, but not exclusively in <lb/>phototaxis experiments. This work suggests that even innate preferences which <lb/></body>

			<page>8 <lb/></page>

			<body>appear simple and hard-wired, such as those expressed in classic phototaxis <lb/>experiments, comprise a value-driven decision-making stage, negotiating external <lb/>stimuli with the animal&apos;s internal state and likely other factors as well, before an <lb/>action is selected. This endows the animal with the possibility to decide, for <lb/>example, when it is better to move towards the light or hide in the shadows. <lb/>Moreover, the fact that flies adapt their photopreference in accordance with their <lb/>flying ability shows that flies have the cognitive tools required to evaluate the <lb/>capability to perform an action and to let that evaluation impact other actions -<lb/>an observation reminiscent of meta-cognition. <lb/>Thus, what appears to be a simple response to light, actually contains at <lb/>least one decision-making stage which negotiates and weighs several different <lb/>factors before selecting an action. One may even argue that what was commonly <lb/>described as a taxis, in this case at least, only appears as a simple taxis at a <lb/>superficial glance. Once one peers into the neurobiology of the behavior, the usage <lb/>of terms like &apos;response&apos; or &apos;taxis&apos; appears inadequate. <lb/>2.2 Knee jerk reflexes in mammals <lb/>A similarly iconoclastic input-output system is the &quot;knee jerk&quot; class of spinal <lb/>reflexes. One can hardly imagine a simpler system: the 1a afferents send the <lb/>excitation from the stretched muscle spindles to the γ motor neurons which <lb/>activate the muscle that flexes the leg. On the surface, this seems to be an even <lb/>simpler and more obviously feed-forward case than phototaxis in insects: two <lb/>neurons, one synapse, input from the sensory neuron leads to output from the <lb/>motor neuron and behavior. However, even there, upon closer examination, the <lb/>seemingly dominant stimulus-response organization starts to collapse. <lb/>Implanting cuff electrodes on the mammalian posterior tibial nerve as well as <lb/>electrodes recording the electromyograms from the soleus muscle allows for long-<lb/>term recordings of the electrical analog of the stretch reflex, the H-reflex (or <lb/>Hoffmann&apos; s reflex). The simple textbook case of the knee jerk reflex implies all-<lb/>or-nothing responses to identical stretch stimuli. However, triggering this reflex <lb/>over hours, days or weeks reveals multiple timescales of variability in the <lb/>amplitude of the H-reflex. Moreover, making a food or water reward contingent <lb/>on larger (or smaller, respectively) reflex amplitudes than baselines averages <lb/>leads to an increase (or decrease, respectively) of the reflex amplitude over the <lb/>course of a few days (Wolpaw, 2010; Chen and Wolpaw, 1996; Wolpaw and Chen, <lb/>2006; Carp et al., 2006; Thompson and Wolpaw, 2014a, 2014b). One could say <lb/>that, conceptually, this procedure is the opposite of an omission schedule: to <lb/>eliminate potential operant components in classical conditioning experiments, an <lb/>omission schedule leaves out the unconditioned stimulus (often food or water), <lb/>whenever the conditioned reflex was produced. In operant conditioning of the H-<lb/>reflex, only those reflexes are rewarded that reach the target amplitude. In this <lb/>case, always the same electrical stimulus is eliciting the reflex, so the behavioral <lb/>variability must be either due to internal processes in the animal or due to <lb/>unrelated stimuli in the environment. It is difficult to imagine that, for instance, <lb/></body>

			<page>9 <lb/></page>

			<body>a certain corner of the experimental chamber consistently increases reflex-<lb/>amplitudes throughout the nervous system, such that the animal would always <lb/>seek this corner to increase its amplitudes during conditioning. On the contrary, <lb/>such operant conditioning in humans is used to improve rehabilitation after <lb/>spinal cord injury (Thompson and Wolpaw, 2015, 2014a), such that lasting <lb/>changes in reflex amplitude must be brought about by processes that are <lb/>independent from the current environment of the patients. In fact, the function <lb/>of the spontaneous variability in reflex amplitude is quite well understood: the <lb/>spinal reflexes constantly adapt to the environment in which vertebrates walk. <lb/>They accomplish this feat by constantly changing their amplitude and evaluating <lb/>the sensory consequences of these actions. In other words, even spinal reflexes <lb/>are using spontaneous actions to constantly explore the state space of the motor <lb/>system in order to find the most suitable behavioral output. In this process, the <lb/>spinal reflexes rely on networks that span the cortico-spinal tract all the way into <lb/>the cerebellum and motor cortex. Without these reflexes using these networks to <lb/>constantly probing the environment&apos;s responses to their spontaneous actions, we <lb/>would not be able to walk up the stairs at the end of the hallway or climb down <lb/>a mountain after we reached the summit. <lb/>Thus, the textbook knee jerk reflex only exists in its textbook form if the <lb/>slice of the spinal cord that contains its synapses is removed from the rest of the <lb/>nervous system. However, this isolated state prevents understanding of the <lb/>function of spinal reflexes for locomotion. Describing these spinal reflexes as <lb/>rigidly responding to stretch stimuli seems at best inadequate and at worst <lb/>misleading, considering the large-scale networks within which this sensory-motor <lb/>synapse is embedded and the complex, operant processes these circuits in fact <lb/>mediate. <lb/>2.3 Phototaxis in a polychaete larva <lb/>A less iconoclastic, but perhaps yet simpler and likely one of the most archaic <lb/>of these stimulus-response systems, is also considered a model for the last <lb/>common ancestor of vertebrates and invertebrates, the &apos;Urbilaterian&apos;: the <lb/>planktonic larvae of a marine polychaete worm, Platynereis dumerilii. These egg-<lb/>shaped creatures use a band of ciliated cells around their body to locomote, in <lb/>the first half of larval development preferentially towards the surface. One factor <lb/>in this upward movement is positive phototaxis. When a light is switched on at <lb/>one end of a chamber filled with P. dumerilli larvae, they all start swimming <lb/>towards it (Jé kely et al., 2008). That these animals are capable of phototaxis is <lb/>remarkable as their nervous system does not feature any interneurons. Their <lb/>light-sensitive neurons make direct synaptic connections with the ciliated cells <lb/>that propel the animal. Importantly, the ciliated cells are constantly active, <lb/>propelling the animals sometimes in this directions, sometimes in that. When <lb/>light hits one of their two &apos;eyes&apos;, the synaptic connection between the light-<lb/>sensitive neuron and the ciliated cells inhibits the ciliated cells on the side where <lb/>the light was perceived (Jé kely et al., 2008). Like a rower who stops rowing on <lb/></body>

			<page>10 <lb/></page>

			<body>one side, the animals then rotate towards the side where the light came from. If <lb/>they keep rotating, light will hit their other eye, leading, again, to a rotation <lb/>towards the light. This physiological understanding of the biological mechanisms <lb/>underlying phototaxis in P. dumerilii larvae is necessary for the insight that what <lb/>appears as an external stimulus eliciting an until then inactive behavior is <lb/>organized rather in the reverse fashion: these animals are constantly exploring <lb/>their environment in the search for light, constantly changing directions. The <lb/>external stimulus is then perceived as feedback from this exploratory, <lb/>spontaneous behavior. In stark contrast of the implied activation of a response, <lb/>the stimulus then only serves to eliminate a portion of the ongoing behavioral <lb/>repertoire. <lb/>Thus, it appears as if behavior in a model for the Urbilaterian is organized <lb/>in a fashion antithetical to the stimulus-response organization often assumed for <lb/>nervous systems in general. These animals are first generating ongoing, random(-<lb/>like), exploratory behavior that is modulated by subsequent reafferent feedback. <lb/>This discovery may constitute the simplest, maybe even the earliest instantiation <lb/>of an operant organization of behavior: generating a spontaneous action first and <lb/>then evaluating its outcomes. If that were the case, &apos;responses&apos;, if they actually <lb/>exist, may only be rare and highly specialized, evolutionarily relatively late <lb/>adaptations. In this view, the general concept of a stimulus-response organization <lb/>of behavior is largely due to a combination of selection bias in which animal <lb/>models and experiments are chosen for study and an inevitably superficial <lb/>observation of the behavior. <lb/>2.4 Olfactory Reversal in Nematodes <lb/>If a stimulus-response organization of behavior were a particular evolutionary <lb/>adaptation, e.g., evolved to speed up action selection in predictable situations, <lb/>perhaps one can find examples of them in an animal model where we have an <lb/>indication that evolution may have streamlined the pathways from stimuli to <lb/>responses. One of the most well-studied genetic model organisms and so far the <lb/>only adult animal with a complete connectome of its nervous system is the <lb/>nematode worm Caenorhabditis elegans with its 302 neurons. The C. elegans <lb/>connectome is dominated by feed-forward connections from sensory neurons to <lb/>motor neurons (Qian et al., 2011), so maybe the nervous system of this nematode <lb/>is a promising candidate to find &apos; responses&apos; in the literal meaning of the word. <lb/>One well-characterized behavior in this nematode is reversal behavior. It <lb/>occurs whenever the animal encounters aversive stimuli, such as certain odors. <lb/>The circuit controlling this behavior can be described with just four neurons, <lb/>their 44 chemical connections and their electrical synapses. A central component <lb/>of the system is a neuron called AVA. When AVA is active, the animal reverses <lb/>its course. Sensory input to this neuron is provided by an olfactory neuron, AWC. <lb/>For instance, if AWC is stimulated by an attractive odorant, it stops firing, such <lb/>that AVA loses excitatory input and also stops firing, making reversals less likely. <lb/>Conversely, activating AWC either experimentally or with an aversive odor <lb/></body>

			<page>11 <lb/></page>

			<body>increases the probability of reversals by synaptically activating AVA (Gordus et <lb/>al., 2015). Two additional neurons are involved in this circuit, AIB and RIM, <lb/>and the characterization of their role in the circuit is crucial for understanding <lb/>the organization of olfactory mediated reversal behavior in C. elegans. <lb/>The first interesting observation from the circuit connectivity is that there <lb/>are more connections from the sensory AWC neuron to the AIB interneuron than <lb/>to the reversal neuron AVA. This is unexpected, if the main function of nervous <lb/>systems were to relay sensory information to motor centers. Imaging this circuit <lb/>in immobilized worms in the absence of any stimuli, reveals a complex patterns <lb/>of correlated activity in all neurons. Interestingly, the neurons exhibit a sort of <lb/>binary activity state, that for the most part is either on (neuron is active) or off <lb/>(neuron is inactive). Quantifying the activity fluctuations in this circuit, one finds <lb/>that there are three main states (of the eight theoretically possible) the circuit is <lb/>commonly found in: just over 60% of the time the system is in &apos;all on&apos;, roughly <lb/>20% is &apos;all off&apos; and for the remaining 20% it is in the state &apos;only AIB on&apos;. This <lb/>observation yields two insights: For one, even without any stimulation at all, <lb/>these network dynamics can generate spontaneous reversals without requiring <lb/>any sensory input. Second, each olfactory stimulus reaching AWC will interact <lb/>with the state the circuit currently happens to be in, rather than arriving in a <lb/>quiescent circuit and triggering some neural activity that was not there before. <lb/>The behavioral consequence of this interaction is not only the occurrence of <lb/>spontaneous reversals, but also the occurrence of &apos;spontaneous&apos; non-reversals in <lb/>the presence of an aversive odor. In other words, the reversal circuit is <lb/>probabilistic and without observing the nervous system of the worm, it is <lb/>impossible to tell how spontaneous the observed behavior actually is. <lb/>Experimentally silencing either one or both of the interneurons in this circuit <lb/>reveals that the role of AIB and RIM is to increase the variability of the reversal <lb/>circuit. While the input to the circuit from the olfactory neuron AWC is always <lb/>very precise and predictable if, e.g., an odor is presented, the activity of the <lb/>reversal circuit always varies significantly and this variability is reduced if AIB <lb/>or RIM (or both) are silenced (Gordus et al., 2015). This discovery makes an <lb/>excellent case for RIM and AIB being incorporated into the reversal circuit <lb/>specifically to inject much needed variability into an otherwise maladaptively <lb/>deterministic reversal circuit. Surprisingly, even though the feed-forward <lb/>connections dominate the connectivity also in this little circuit, the variability <lb/>provided by the feed-back connections dominate an adaptive feature of the <lb/>behavior, its variability. This work adds C. elegans to the elongating list of <lb/>animals, whose nervous systems are organized such that ongoing activity is <lb/>merely modulated by external stimuli. In the nematode case, it appears that out <lb/>of the four neurons comprised in this circuit, two exist for the sole reason to <lb/>mitigate the effects that stimuli have on the behavior of the animal, in order to <lb/>make the animal more autonomous with regard to its environment. If an animal <lb/>with only 302 neurons, which, as in all other animals, make up the most <lb/>energetically costly tissue, devotes 50% of a circuit to counter the effects of <lb/>stimulus-response connections in its nervous system, then the implications of this <lb/></body>

			<page>12 <lb/></page>

			<body>discovery for the organization of behavior in animals generally cannot be <lb/>underestimated. <lb/>Thus, contrary to the idea that a connectome dominated by feed-forward <lb/>connections from sensory to motor areas implies that it mainly computes motor <lb/>output from sensory input, also the nervous system of C. elegans is best <lb/>characterized by constantly changing, ongoing activity, much like many other <lb/>nervous systems previously studied in this regard. It seems that even a <lb/>numerically small feed-back component provides a fundamental contribution to <lb/>the overall architecture even of such feed-forward-dominated networks. What <lb/>does this mean for brains, such as those of mammals, whose neuroanatomy <lb/>appears to be dominated by feed-back loops? <lb/>2.5 Escape responses <lb/>Few behaviors are as obviously under evolutionary selection pressures as <lb/>escape responses: the anti-predator behavior of prey in the presence of predators. <lb/>Perhaps not surprisingly, this class of highly refined behaviors is particularly <lb/>well-studied because of their reproducibility in the lab. Be it the C-start response <lb/>in fish, mediated by the largest mammalian neuron, the Mauthner cell (Korn and <lb/>Faber, 2005; Schuster, 2012), the squid escape response mediated by their giant <lb/>fiber system (Young, 1938), the crayfish giant fiber system that allows the animal <lb/>to quickly propel itself out of harm&apos; s way by flipping its tail (Herberholz and <lb/>Marquart, 2012) or the fly escape circuit also mediated by giant fibers originating <lb/>in the optic lobes and making direct connections with the motor neurons that <lb/>lead to both the raising of the wings and to the jump response of the legs <lb/>(Hammond and O&apos; Shea, 2007a; Card and Dickinson, 2008b, 2008a). All of these <lb/>behaviors are easily observed in the lab, are mediated by conspicuous and easy <lb/>to manipulate giant neurons and have, over the decades, shaped the way <lb/>neuroscientists all over the world once conceptualized how behavior is organized: <lb/>eliciting stimulus in, followed by behavioral response out (e.g., &quot;brain function is <lb/>ultimately best understood in terms of input/output transformations&quot; (Mauk, <lb/>2000). However, studies in behavioral ecology and ethology have revealed that <lb/>these famous behaviors are liable to exploitation (see, e.g., (Catania, 2009, 2010; <lb/>Jabloń ski and Strausfeld, 2000; Jablonski and Strausfeld, 2001) and/or are often <lb/>more complex and flexible than initially thought (Card and Dickinson, 2008a, <lb/>2008b; Hammond and O&apos; Shea, 2007a, 2007b; Herberholz and Marquart, 2012; <lb/>Fotowat and Gabbiani, 2007). Searching for more escape behaviors under natural <lb/>conditions in order to compare them with the better known laboratory examples, <lb/>it was discovered that many escape behaviors contain elements of variability in <lb/>order to make the escape trajectory less predictable for the predator (e.g., (Royan <lb/>et al., 2010; Domenici et al., 2008; Bateman and Fleming, 2014; Driver and <lb/>Humphries, 1988; Humphries and Driver, 1970; Guerin and Neil, 2015; Highcock <lb/>and Carter, 2014). This work demonstrates the adaptive value of such &quot;protean&quot; <lb/>escape strategies and suggests that unpredictable prey is not only more difficult <lb/>to catch, but is also capable of injecting additional unpredictability into their <lb/></body>

			<page>13 <lb/></page>

			<body>behavior in the presence of predators. It thus appears as if the technically <lb/>advantageous property of being highly reproducible not only renders an escape <lb/>behavior liable to exploitation in the wild, but has also introduced a bias in <lb/>neuroscience and psychology: reproducible laboratory behaviors are rarely <lb/>representative of behaviors more generally, which tend to be much more variable <lb/>and contain a larger degree of unpredictable spontaneity. <lb/>In the light of such data, it is tempting to postulate that the stimulus-<lb/>response concept of animal behavior is little more than a laboratory artefact <lb/>introduced into those sections of psychology and neuroscience that have isolated <lb/>themselves from non-laboratory behavior. Instead, converging data from multiple <lb/>fields, model and non-model organisms in the laboratory and the wild suggests <lb/>that at least all bilaterians have evolved the capability to inject a controlled <lb/>amount of variability into their behavior in order to accomplish adaptive <lb/>behavioral choice under a variety of situations. The influence of this &quot;random <lb/>number generator&quot; ranges from changing minute aspects in the temporal <lb/>dynamics of very simple behaviors to drawing from a set of different behaviors. <lb/>The hallmark of such behavioral variability, the feature that confers its adaptive <lb/>value is its independence from the environment, i.e., its spontaneity. For <lb/>instance, the presence of a predator may increase a prey&apos; s behavioral variability, <lb/>but not a specific escape trajectory or direction. In a novel environment, an <lb/>animal may increase the variability of its foraging or exploratory behavior, but <lb/>the environment cannot be used to predict the direction or duration of the <lb/>foraging bout or the timing of the next exploratory behavior (see, e.g. (Jacobs <lb/>and Menzel, 2014) for a similar argument in a different research question). <lb/>3 The interaction between &apos;self&apos; and &apos;non-self&apos; <lb/>The observations discussed so far have led to a much more refined and <lb/>sophisticated picture of how nervous systems organize behavior than can be <lb/>circumscribed by the &apos;emitted&apos; and &apos;elicited&apos; dichotomy. From a neurobiological <lb/>perspective, stimuli interact with and modulate ongoing activity in the nervous <lb/>system, rather than triggering always the same cascades of neural activity in a <lb/>more or less quiescent brain. This insight entails a number of important <lb/>consequences. <lb/>For one, as behavior is based on neural activity, it is ongoing and continuous. <lb/>The impression that behavior can be chunked into discrete acts (i.e., &quot;units of <lb/>behavior&quot;) are possibly due to both our tendency to categorize even continuous <lb/>phenomena as well as the scale-free nature of neural activity, allowing us to find <lb/>temporal patterns in behavior at different time scales. <lb/>Another consequence is that sensory information only needs to instruct the <lb/>animal as to which kind of behaviors to favor over others. Which specific <lb/>movements or actions are to be generated do not always have to be explicitly <lb/>specified. Exploratory &apos; trying out&apos; with efficient feedback evaluation (i.e., <lb/></body>

			<page>14 <lb/></page>

			<body>operant behavior) is sufficient to quickly and reliably find the behavior that is <lb/>best suited to solve the task at hand. <lb/>However, it is clear that some stimuli exert a more specific effect on the <lb/>ongoing activity in the brain than others. There appears to be a continuum in <lb/>the urgency or salience of events in an animal&apos; s environment, at one extreme <lb/>end of which are stimuli so potent, that they appear to trigger a behavioral <lb/>response, at least to the casual or superficial observer. Obviously, the coupling <lb/>between a stimulus and an organisms behavior can vary from very loose to very <lb/>tight both in terms of temporal coupling as in terms of which stimuli are followed <lb/>by which behaviors, and vice versa. Most often, speed and efficiency are <lb/>correlated with a tight environmental coupling, not only for stereotypic behaviors <lb/>such as, e.g. escape responses: the well-trained squirrel will much more quickly <lb/>crack the nut than the naï ve one. However, fast, efficient and ultimately <lb/>stereotypic behaviors are inflexible and liable to exploitation. Inasmuch as <lb/>operant conditioning leads to the selection of efficient behavior and later to <lb/>stereotypization of the behavior in a process called habit formation, operant <lb/>processes are central in the animal&apos; s quest to trade off efficiency for flexibility <lb/>and unpredictability. This trade-off is essential for the survival and procreation <lb/>of every organism and likely one of the most important ultimate causations <lb/>behind adaptive behavioral choice. <lb/>Of course, there are ongoing processes inside the organism that can be ranked <lb/>on a similar scale from hardly noticeable to directly influencing behavior. Hunger <lb/>or circadian rhythms have at least as potent an effect on behavior as the presence <lb/>of food, a predator or a potential mating partner. It is the complex interaction <lb/>of processes generated by the animal itself (among which spontaneous behavior <lb/>can be found) with processes generated by events outside of the animal that <lb/>ultimately manifests itself as observable behavior. Importantly, the fact that we <lb/>cannot tickle ourselves suggests that this distinction between self and non-self <lb/>may be much more fundamental than one would at first assume. In their <lb/>&quot; reafference principle&quot; von Holst and Mittelstä dt famously proposed a <lb/>mechanism by which animals use efference copies to distinguish between stimuli <lb/>that are under their control (reafference) from those that are not <lb/>(exafference)(von Holst and Mittelstaedt, 1950). The reafference principle is a <lb/>fundamentally operant process by which animals not only distinguish between <lb/>the stimuli they can control and those they cannot: it is also the beginning of the <lb/>operant process by which animals learn to bring novel stimuli under their <lb/>behavioral control. <lb/>These considerations bring us back to another fundamental question Skinner <lb/>formulated in the 30s of the last century. Given the multitude of learning <lb/>processes engaged during operant conditioning experiments, how many of them <lb/>are similar to those taking place in classical conditioning (i.e., stimulus <lb/>substitution) and how many, if any, are fundamentally different. Skinner himself <lb/>lamented that he could not remove the lever his rats were pressing to eliminate <lb/>one of the confounding factors (Skinner, 1935). Modern behavioral neurobiology <lb/>in genetic model organisms have designed experiments specifically to address this <lb/></body>

			<page>15 <lb/></page>

			<body>problem and have discovered that the distinction between self and non-self is <lb/>central to a purely operant learning mechanism. <lb/>4 Mechanisms of Plasticity in Operant <lb/>Conditioning <lb/>4.1 Isolating the components: self-learning <lb/>As Skinner noted, rats need a lever to press and thus they may learn about <lb/>the food-predicting properties of the lever. Therefore, this experiment is not ideal <lb/>for studying the neurobiology underlying operant learning processes. Any <lb/>memory trace found in the brain cannot be unambiguously attributed to the <lb/>mechanism engaged when learning about the lever or to the learning about the <lb/>behavior required to press the lever. Therefore, preparations had to be developed <lb/>without such environmental &apos; contamination&apos; . One such preparation is tethered <lb/>Drosophila at the torque meter as described above (Brembs, 2009b; Heisenberg <lb/>et al., 2001; Wolf and Heisenberg, 1991; Heisenberg, 1994; Wolf et al., 1992; <lb/>Heisenberg and Wolf, 1984; Wolf and Heisenberg, 1986). In the setup where the <lb/>flies learn to control a punishing heat beam with their yaw torque in a <lb/>homogeneous environment with no directional cues, the only contingency present <lb/>is that between the behavior and the reinforce/punisher. In this experiment, it is <lb/>thus possible to isolate the operant contingency from all environmental <lb/>contaminations. One may term such experiments &apos; pure&apos; operant conditioning <lb/>experiments. <lb/>Using mutant, wildtype and transgenic animals, it was discovered that the <lb/>canonical, cAMP-dependent synaptic plasticity pathway known from other <lb/>learning experiments was not involved in this type of learning, but manipulating <lb/>protein kinase C (PKC) signaling abolished learning in this paradigm completely <lb/>(Brembs and Plendl, 2008). Apparently, the common, evolutionary conserved <lb/>mechanisms, discovered in classical conditioning experiments are not required for <lb/>this pure operant learning. Instead, the animal has to rely on a different <lb/>biochemical process if it is asked to learn about its own behavior, in the absence <lb/>of any external cues. With regard to the fundamental distinction between self <lb/>and non-self discussed above, the content of the learning process is fundamentally <lb/>about the animal&apos; s own behavior. Thus, one may call this process self-learning, <lb/>i.e., the process by which value is assigned to a specific action or movement, such <lb/>as the heat is assigning positive or negative value to left or right turning, <lb/>respectively, in this experiment (Colomb and Brembs, 2010). <lb/>In the search for other components of the biological processes underlying self-<lb/>learning, one may again refer to Skinner. This time his claim that language <lb/>acquisition constituted a form of operant learning (Skinner, 1957): first <lb/>exploratory, highly variable actions are being initiated (i.e., babbling) and then <lb/>sensory feedback shapes the initiation of future behavior, reducing its variability <lb/>(i.e., language). In what may appear at first to be a very superficial analogy, <lb/>&quot; mere homonyms, with at most a vague similarity of meaning&quot; (Chomsky, <lb/></body>

			<page>16 <lb/></page>

			<body>1959), operant self-learning in tethered flying Drosophila mimics these features <lb/>of vocal learning: the animal first initiates highly variable, exploratory actions, <lb/>then sensory feedback shapes the initiation of future behavior, reducing its <lb/>variability. The Forkhead Box P2 (FOXP2) transcription factor is the first gene <lb/>discovered to be involved in the development of speech and language (Fisher and <lb/>Scharff, 2009; Lai et al., 2001). Importantly, the avian orthologue is also involved <lb/>in song learning in birds (Scharff and Haesler, 2005; Haesler et al., 2007; Schulz <lb/>et al., 2010), which has also been described as an operant behavior (Marler, <lb/>1991). The four different FoxP genes in vertebrates probably arose from serial <lb/>duplications of a single ancestral FoxP gene after the separation from the <lb/>invertebrate clades. The invertebrate FoxP orthologue corresponds most closely <lb/>to the ancestral form of the gene at the base of the bilateria (Santos et al., 2011), <lb/>thus lending itself to investigating the depth of the functional conservation <lb/>among the members of the FoxP gene family. Mutant analysis and RNAi-<lb/>mediated knockdown of the Drosophila orthologue, dFoxP, revealed its necessity <lb/>specifically for self-learning (Mendoza et al., 2014), a phenocopy of the PKC <lb/>manipulations described above. Thus, an excellent candidate for the ancestral <lb/>function of FoxP genes, several of which are involved in acquiring the speech <lb/>component of language in humans, is specifically involved in the isolated self-<lb/>learning component of operant conditioning, but not in other forms of learning <lb/>in Drosophila. These results are consistent with the hypothesis that the FoxP-<lb/>dependent component of language evolved from an ancestral operant self-learning <lb/>mechanism. The homology between invertebrate FoxP and its descendant genes, <lb/>together with the similarities between habit formation and birdsong <lb/>crystallization (Costa, 2011) (see also the Chapter on bird learning) prompts the <lb/>postulation that habit formation in vertebrates may also be engaging this same <lb/>mechanism. <lb/>Parallel developments to isolate the operant component have been made in <lb/>the sea slug Aplysia (Nargeot et al., 1997; Nargeot, 2002; Nargeot et al., 2007, <lb/>2009; Nargeot and Simmers, 2010; Brembs et al., 2002; Lorenzetti et al., 2008, <lb/>2006; Nargeot et al., 1999c, 1999b, 1999a). As described above, reward signals <lb/>were made contingent on spontaneous biting behavior, either in the intact animal <lb/>or in isolated buccal ganglia. This procedure also excluded any external stimuli <lb/>from contaminating this pure operant experiment, leading to self-learning. Such <lb/>conditioning brings about two changes in the behavior of the animals/ganglia: <lb/>both the total number of bites/BMPs is increased and the frequency of the <lb/>rewarded behavior increases, relative to the other feeding behaviors. <lb/>Electrophysiological studies discovered learning-related changes both in When <lb/>and in What neurons. While the What neurons changed their excitability such <lb/>that the behavior they promoted became more frequent (Brembs et al., 2002; <lb/>Nargeot et al., 1999b, 1999a), the When neurons increased their electrical <lb/>couplings as well as their excitability (Nargeot et al., 2009), such that not only <lb/>the total number of behaviors increased, but they also became more stereotyped, <lb/>losing the variability described above for the naï ve animals in which the <lb/>coupling between the When neurons was comparatively weak (Nargeot and <lb/></body>

			<page>17 <lb/></page>

			<body>Simmers, 2012). The self-learning mechanism in Aplysia hence entails direct <lb/>modifications of the very neurons controlling the type of behavior being <lb/>generated as well as the variability of the behavior. In this way, we are starting <lb/>to unravel the neuronal mechanisms behind selection by consequences (Skinner, <lb/>1981) (see also the chapter by Aaron Blaisdell). These mechanisms appear to be <lb/>evolutionary conserved as well, raising the possibility of a common, specifically <lb/>operant learning mechanism for all bilaterians. Also in Aplysia, as in Drosophila, <lb/>the canonical cAMP-dependent learning pathway discovered in classical <lb/>conditioning is not involved, but PKC manipulations impair self-learning <lb/>(Lorenzetti et al., 2008). Given that PKC is also involved in song-learning in <lb/>birds (Yoshida et al., 2003; Sakaguchi and Yamaguchi, 1997), as is FoxP2, there <lb/>is now strong evidence for such a conserved self-learning mechanism. <lb/>These results entail that there exists a dedicated biological mechanism that <lb/>only occurs in neurons that are involved in actions and not in those processing <lb/>the environment. With regard to the early questions of Skinner and his <lb/>contemporaries, we can now say that we have learned that the different <lb/>associative processes mediating the content of learning (&quot;what is learned&quot;) in <lb/>operant conditioning are mediated by different biological mechanisms: the <lb/>molecular machinery involved in operant self-learning (i.e., PKC and FoxP to <lb/>date) does not appear to be involved in any of the other types of learning studied <lb/>so far. This insight was made possible by separating and isolating the self-<lb/>learning process from any other processes that may take place during operant <lb/>conditioning. Adding some of these components back to the experiment reveals <lb/>interactions between these components that have a direct relation to the central <lb/>efficiency/flexibility trade-off underlying adaptive behavioral choice discussed <lb/>above. <lb/>4.2 Combining the components: composite learning <lb/>Once the operant component has been isolated in &apos;pure&apos; operant learning <lb/>experiments in which only self-learning can occur, it is comparatively easy to add <lb/>a predictive stimulus and compare the resulting &apos;composite&apos; situation with the <lb/>&apos;pure&apos; experiment. For instance, in tethered Drosophila, whenever the direction <lb/>of turning maneuvers changes (e.g., from left to right turning attempts), the <lb/>entire visual field of the fly instantaneously turns from one color (say, green) to <lb/>another (e.g., blue). Because now the colors change both with the yaw torque <lb/>and the heat, the fly has the additional option to learn that one of the colors <lb/>signals heat, and not only that its own behavior contriols the heat. This situation <lb/>is analogous to how rats in Skinner-boxes may learn that the depressed lever <lb/>signals food (and the undepressed lever no food) as well as that their lever-<lb/>pressing is predictive of the food reward. In contrast to the &apos;pure&apos; experiment, <lb/>this situation now requires the canonical cAMP cascade discovered in classical <lb/>conditioning and is independent of any PKC signaling (Brembs and Plendl, 2008) <lb/>or dFoxP function (Mendoza et al., 2014). Apparently, even though the <lb/>experiment is just as operant as before the colors were added (in fact, if the flies <lb/></body>

			<page>18 <lb/></page>

			<body>were able to close their eyes to the colors, it would be the exact same, &apos;pure&apos; <lb/>experiment), now seemingly &apos;classical&apos; learning mechanisms are engaged. This <lb/>result suggests that as soon as learning of external stimuli becomes possible, these <lb/>will be learned preferentially over behavioral cues, even in otherwise completely <lb/>operant learning situations. As the content of these learning processes is <lb/>fundamentally non-self, one may call these processes &apos;world-learning&apos;, i.e., the <lb/>process by which value is assigned to external stimuli, such as, for instance, <lb/>&apos;green&apos; being assigned an aversive value and blue an appetitive value in this <lb/>experiment (Colomb and Brembs, 2010). In contrast to self-learning, world-<lb/>learning can occur in both operant and classical learning experiments, depending <lb/>on the operant control of the predictive stimuli (this will become a separate point <lb/>of discussion below). Thus, the difference between operant and classical <lb/>conditioning lies not in the procedural differences between the two experiments, <lb/>it lies in the content of the memory being formed: its content (i.e., &apos; what is <lb/>learned&apos; ) decides which learning processes are engaged in the nervous system. <lb/>How this content is learned, appears to be less relevant. <lb/>To ask whether the colors have been learned independently from the behavior <lb/>with which they were learned, one can test the flies&apos; preference of the <lb/>unpunished color with an orthogonal behavior to that used during training. After <lb/>all, to solve the &apos; composite&apos; situation, it is sufficient for the flies to learn that <lb/>one of the colors is associated with the heat and then use whatever behavior <lb/>necessary to avoid this color. Indeed, flies can avoid the punished color even with <lb/>an orthogonal behavior. Conversely, when tested for a preference in turning <lb/>direction (i.e., without colors) after composite conditioning, the flies do not reveal <lb/>any preference (Brembs, 2009a). In the most Pavlovian sense, the flies seem to <lb/>learn the color-heat contingency independently of the behavior with which it was <lb/>acquired. They only learn about the world around them, without leaving much <lb/>of an indication that the behavioral decision-making circuitry itself has been <lb/>significantly altered, even though, of course, the entire situation is still just as <lb/>operant as without the stimuli (Brembs, 2009a; Brembs and Heisenberg, 2000). <lb/>Apparently, there is an inhibitory interaction between the world-and the self-<lb/>learning processes during operant composite conditioning, such that only the <lb/>effects of the world-learning process can be detected after operant composite <lb/>conditioning. For this inhibition to occur, it is not sufficient that the colors are <lb/>merely present: flickering the colors unrelated to the heat does not inhibit self-<lb/>learning and mutants which cannot learn the colors (but are not impaired in self-<lb/>learning) do not show any sign of self-learning inhibition, even if the colors are <lb/>predictive of the heat (unpublished observation). Thus, world-learning must be <lb/>actively engaged, in order to inhibit self-learning. <lb/>To ask whether this inhibition is absolute or depends on other factors, such <lb/>as, e.g. time, one can extend the training to twice the duration used in traditional <lb/>operant conditioning experiments in Drosophila. Testing for world-and self-<lb/>learning effects after such extended training reveals that the inhibition of self-<lb/>learning by world-learning is time-dependent: after extended training, the flies <lb/></body>

			<page>19 <lb/></page>

			<body>prefer generating the previously unpunished turning direction, even in the <lb/>absence of the colors. In what appears to be an analogy to vertebrate &apos; habit <lb/>interference&apos; , the flies can no longer express the preference for the previously <lb/>punished color with an orthogonal behavior (Brembs, 2009a). Interestingly, FoxP <lb/>mutant flies are impaired in this type of habit formation, indicating that the self-<lb/>learning that is taking place in pure operant conditioning is indeed the very same <lb/>self-learning process that is inhibited in composite conditioning. One may <lb/>interpret these results such that habit formation requires repetition because it is <lb/>inhibited by world-learning. After prolonged training, this inhibition is overcome <lb/>and self-learning kicks in to form habits. In flies, a prominent neuropil, which is <lb/>dispensable for both world-and self-learning, is involved in the inhibition of self-<lb/>learning: the mushroom-bodies (Brembs, 2009a). <lb/>Similar relationships have been observed in experiments with other animals. <lb/>For instance, in navigation studies, relatively short training preferentially <lb/>engages an allocentric strategy (the animal orients primarily according to <lb/>environmental cues), while longer training induced an egocentric strategy (the <lb/>animals performed the same sequence of movements)(Packard and McGaugh, <lb/>1996; Hicks, 1964; Ritchie et al., 1950; Tolman et al., 1947, 1946). The analogy <lb/>to world-and self-learning is striking. The terminology of world-and self-learning <lb/>itself was inspired by analogous developments in another research field (Berniker <lb/>and Kording, 2008). There is a third field in which analogous results have been <lb/>obtained. In experiments with rodents in operant chambers, extended training <lb/>abolishes sensitivity to reinforcer devaluation by the process of habit formation <lb/>which transforms goal-directed actions to habitual responses (Yin and Knowlton, <lb/>2006). <lb/>Besides the inhibitory interaction between world-and self-learning, there is <lb/>a second interaction that can only be observed in composite conditioning. These <lb/>experiments take advantage of the fact the world-learning can occur in operant <lb/>conditioning experiments (i.e., if they are composite experiments) and always <lb/>occurs in classical conditioning experiments. If fly learning in composite <lb/>situations is compared to situations where the same stimulus was trained <lb/>classically, it is routinely observed that the stimuli are learned faster and to a <lb/>higher level in the composite, than in the classical situation, even if the sensory <lb/>input during training was identical between groups (Brembs and Heisenberg, <lb/>2000; Brembs and Wiener, 2006). This observation is reminiscent of the <lb/>generation-effect (&quot;learning-by-doing&quot;), i.e., the facilitation of world-learning by <lb/>being in control of the stimuli which are to be learned (Thorndike, 1898; <lb/>Slamecka and Graf, 1978; Kornell and Terrace, 2007; James, 1890; Baden-Powell, <lb/>1908). The mechanism by which this facilitation of world-learning occurs in <lb/>composite conditioning compared to otherwise identical classical conditioning <lb/>remain elusive. The only results so far are negative: none of the mutants and <lb/>transgenes tested in the last two decades shows any deficit in the &apos;generation <lb/>effect&apos;. <lb/>It is straightforward to hypothesize that the difference in world-learning rate <lb/>between classical and operant composite conditioning is due to the stimuli being <lb/></body>

			<page>20 <lb/></page>

			<body>presented exafferently in classical conditioning and reafferently in operant <lb/>situations. Efference copies are generally proposed as one mechanism animals use <lb/>to distinguish between exafferent and reafferent stimuli. If efference copies are <lb/>also used here to accomplish the generation effect in composite conditioning, it <lb/>would entail that efference copies not necessarily always reduce the salience of <lb/>reafferent stimuli as originally proposed (von Holst and Mittelstaedt, 1950), but <lb/>can also enhance it, under certain circumstances, to accomplish a facilitation of <lb/>world-learning. From these considerations it is a small step to postulate that <lb/>when the relationship between a reafferent stimulus and the animal itself is <lb/>concerned (such as in re-afferent self-motion signals, or in self-tickling attempts) <lb/>then efference copies serve to reduce the salience of the stimuli. However, when <lb/>the relationship among different reafferent stimuli is concerned, then efference <lb/>copies serve to increase their salience compared to the same stimuli presented <lb/>exafferently. <lb/>5 Conclusions <lb/>In contrast to the long-held assumption that the organization of behavior is <lb/>best characterized as the perception of a sensory stimulus followed by appropriate <lb/>response (i.e., &quot;sensorimotor hypothesis&quot;), recent converging evidence from <lb/>multiple systems and fields of study instead suggests that both ancestral and <lb/>extant general brain function is best described in operant terms. Rather than <lb/>specifying precise behaviors, sensory information -if at all present -interacts <lb/>with ongoing neural activity to instruct the organism which type of spontaneous, <lb/>exploratory behavior to generate. Evaluating the ensuing reafferent feedback <lb/>modifies the nervous system such that ongoing neural activity patterns become <lb/>biased towards activity that has generated increased appetitive and decreased <lb/>aversive feedback in the past. The neurobiological mechanisms underlying both <lb/>the exploratory, spontaneous behaviors as well as those underlying the <lb/>modifications caused by the feedback are becoming increasingly understood, even <lb/>on a molecular level. It is straightforward to hypothesize that the constant <lb/>interaction between ongoing neural activity and the incoming sensory stream <lb/>allows the organism to balance behavioral flexibility with efficiency to accomplish <lb/>adaptive behavioral choice in an often unpredictably changing environment. The <lb/>centrality of this trade-off is reflected in various fields discussing different aspects <lb/>of this task. Evolutionary biologists study factors specifying whether flexible <lb/>generalists or efficient specialists will prevail, psychologists search for transitions <lb/>between flexible goal-directed actions and efficient habits, ecologists study at <lb/>what point animals cease to efficiently exploit a resource to invest in costly <lb/>exploration, computational neuroscientists unravel interactions between flexible <lb/>model-based and efficient model-free learning processes. Animals and humans <lb/>have evolved over millions of years to become experts in mastering this <lb/>fundamental trade-off. Focusing on only one aspect of it fails to capture essential <lb/>processes controlling behavior. <lb/></body>

			<page>21 <lb/></page>

			<listBibl>References <lb/>Baden-Powell, R. (1908). Scouting for Boys. London: C. Arthur Pearson Ltd. <lb/>Bateman, P. W., and Fleming, P. A. (2014). Switching to Plan B: changes in the escape tactics <lb/>of two grasshopper species (Acrididae: Orthoptera) in response to repeated predatory <lb/>approaches. Behav. Ecol. Sociobiol. 68, 457-465. <lb/>Bedecarats, A., Castro, J., Lade, Q., Cattaert, D., Simmers, J., and Nargeot, R. (2015). No <lb/>Title. in Soc. Neurosci. Abstr (Chicago, Il.), 420.27. <lb/>Belanger, J. H., and Willis, M. A. (1996). Adaptive control of odor-guided locomotion: <lb/>Behavioral flexibility as an antidote to environmental unpredictability. Adapt. Behav. <lb/>4, 217-253. <lb/>Benzer, S. (1967). Behavioral mutants of Drosophila isolated by countercurrent districution. <lb/>Proc. Natl. Acad. Sci. U. S. A. 58, 1112-1119. <lb/>Berniker, M., and Kording, K. (2008). Estimating the sources of motor errors for adaptation <lb/>and generalization. Nat. Neurosci. 11, 1454-61. <lb/>Brembs, B. (1996). Chaos, cheating and cooperation: Potential solutions to the Prisoner&apos; s <lb/>Dilemma. Oikos 76, 14-24. <lb/>Brembs, B. (2009a). Mushroom bodies regulate habit formation in Drosophila. Curr. Biol. 19, <lb/>1351-5. <lb/>Brembs, B. (2009b). The importance of being active. J. Neurogenet. 23, 120-6. <lb/>Brembs, B. (2010). Towards a scientific concept of free will as a biological trait: spontaneous <lb/>actions and decision-making in invertebrates. Proc. R. Soc. B Biol. Sci. <lb/>Brembs, B., and Heisenberg, M. (2000). The Operant and the Classical in Conditioned <lb/>Orientation of Drosophila melanogaster at the Flight Simulator. Learn. Mem. 7, 104-<lb/>115. <lb/>Brembs, B., Lorenzetti, F. D., Reyes, F. D., Baxter, D. A., and Byrne, J. H. (2002). Operant <lb/>reward learning in Aplysia: neuronal correlates and mechanisms. Science (80-. ). 296, <lb/>1706-1709. <lb/>Brembs, B., and Plendl, W. (2008). Double dissociation of pkc and ac manipulations on <lb/>operant and classical learning in drosophila. Curr. Biol. 18, 1168-1171. <lb/>Brembs, B., and Wiener, J. (2006). Context and occasion setting in drosophila visual learning. <lb/>Learn. Mem. 13, 618-628. <lb/>Card, G., and Dickinson, M. (2008a). Performance trade-offs in the flight initiation of <lb/>Drosophila. J. Exp. Biol. 211, 341-53. <lb/>Card, G., and Dickinson, M. H. (2008b). Visually mediated motor planning in the escape <lb/>response of Drosophila. Curr. Biol. 18, 1300-7. <lb/>Carp, J. S., Tennissen, A. M., Chen, X. Y., and Wolpaw, J. R. (2006). H-reflex operant <lb/>conditioning in mice. J. Neurophysiol. 96, 1718-27. <lb/>Catania, K. C. (2010). Born Knowing: Tentacled Snakes Innately Predict Future Prey <lb/>Behavior. PLoS One 5, e10953. <lb/>Catania, K. C. (2009). Tentacled snakes turn C-starts to their advantage and predict future <lb/>prey behavior. Proc. Natl. Acad. Sci. U. S. A. 106, 11183-7. <lb/>Catania, K. C. (2008). Worm Grunting, Fiddling, and Charming-Humans Unknowingly <lb/>Mimic a Predator to Harvest Bait. PLoS One 3, e3472. <lb/>Chen, X. Y., and Wolpaw, J. R. (1996). Reversal of H-reflex operant conditioning in the rat. <lb/>112, 58-62. <lb/>Chomsky, N. (1959). A Review of B. F. Skinner&apos; s Verbal Behavior. Language (Baltim). 35, <lb/>26-58. <lb/>Colomb, J., and Brembs, B. (2010). The biology of psychology: &quot; Simple&quot; conditioning? <lb/>Commun. Integr. Biol. 3, 142-5. <lb/></listBibl>

			<page>22 <lb/></page>

			<listBibl>Corcoran, A. J., Barber, J. R., and Conner, W. E. (2009). Tiger Moth Jams Bat Sonar. Science <lb/>(80-. ). 325, 325-327. <lb/>Costa, R. M. (2011). A selectionist account of de novo action learning. Curr. Opin. Neurobiol. <lb/>21, 579-86. <lb/>Dickinson, A. (1985). Actions and Habits -the Development of Behavioral Autonomy. Philos. <lb/>Trans. R. Soc. London Ser. B-Biological Sci. 308, 67-78. <lb/>Domenici, P., Booth, D., Blagburn, J. M., and Bacon, J. P. (2008). Cockroaches Keep <lb/>Predators Guessing by Using Preferred Escape Trajectories. Curr. Biol. 18, 1792-1796. <lb/>Domjan, M. (2016). Elicited versus emitted behavior: Time to abandon the distinction. J. Exp. <lb/>Anal. Behav. 105, 231-245. <lb/>Driver, P. M., and Humphries, N. (1988). Protean behavior: The biology of unpredictability. <lb/>Oxford, England: Oxford University Press. <lb/>Dunn, T. W., Mu, Y., Narayan, S., Randlett, O., Naumann, E. A., Yang, C.-T., Schier, A. F., <lb/>Freeman, J., Engert, F., and Ahrens, M. B. (2016). Brain-wide mapping of neural <lb/>activity controlling zebrafish exploratory locomotion. Elife 5. <lb/>Fisher, S. E., and Scharff, C. (2009). FOXP2 as a molecular window into speech and language. <lb/>Trends Genet. 25, 166-77. <lb/>Fotowat, H., and Gabbiani, F. (2007). Relationship between the Phases of Sensory and Motor <lb/>Activity during a Looming-Evoked Multistage Escape Behavior. J. Neurosci. 27, <lb/>10047-10059. <lb/>Glimcher, P. (2003). Decisions, uncertainty, and the brain: the science of neuroeconomics. <lb/>Cambridge, MA: MIT. <lb/>Glimcher, P. W. (2005). Indeterminacy in brain and behavior. Annu. Rev. Psychol. 56, 25-<lb/>56. <lb/>Glimcher, P. W., and Rustichini, A. (2004). Neuroeconomics: the consilience of brain and <lb/>decision. Science (80-. ). 306, 447-452. <lb/>Gordus, A., Pokala, N., Levy, S., Flavell, S. W., and Bargmann, C. I. (2015). Feedback from <lb/>Network States Generates Variability in a Probabilistic Olfactory Circuit. Cell 161, <lb/>215-227. <lb/>Gorostiza, E. A., Colomb, J., and Brembs, B. (2015). A value-based behavioural choice <lb/>underlies phototaxis in Drosophila. BioArxiv. <lb/>Grobstein, P. (1994). &quot; Variability in behavior and the nervous system.,&quot; in The Encyclopedia <lb/>of Human Behavior, ed. V. S. Ramachandran (New York: Academic Press), 447-458. <lb/>Guerin, A. J., and Neil, D. M. (2015). Escape trajectories of the rockpool prawn ( Palaemon <lb/>elegans ) in response to visual and mechanosensory stimuli. Mar. Freshw. Behav. <lb/>Physiol. 48, 145-161. <lb/>Haesler, S., Rochefort, C., Georgi, B., Licznerski, P., Osten, P., and Scharff, C. (2007). <lb/>Incomplete and Inaccurate Vocal Imitation after Knockdown of FoxP2 in Songbird <lb/>Basal Ganglia Nucleus Area X. PLoS Biol. 5, 12. <lb/>Hammond, S., and O&apos; Shea, M. (2007a). Escape flight initiation in the fly. J. Comp. Physiol. <lb/>A. Neuroethol. Sens. Neural. Behav. Physiol. 193, 471-6. <lb/>Hammond, S., and O&apos; Shea, M. (2007b). Ontogeny of flight initiation in the fly Drosophila <lb/>melanogaster: implications for the giant fibre system. J. Comp. Physiol. A. Neuroethol. <lb/>Sens. Neural. Behav. Physiol. 193, 1125-37. <lb/>Heisenberg, M. (1994). Voluntariness (Willkü rfä higkeit) and the general organization of <lb/>behavior. Life Sci. Res. Rep. 55, 147-156. <lb/>Heisenberg, M., and Wolf, R. (1984). Vision in Drosophila. Genetics of Microbehavior. Berlin, <lb/>Heidelberg, New York, Tokio: Springer. <lb/>Heisenberg, M., Wolf, R., and Brembs, B. (2001). Flexibility in a single behavioral variable of <lb/>Drosophila. Learn. Mem. 8, 1-10. <lb/>Herberholz, J., and Marquart, G. D. (2012). Decision Making and Behavioral Choice during <lb/>Predator Avoidance. Front. Neurosci. 6, 125. <lb/></listBibl>

			<page>23 <lb/></page>

			<listBibl>Hicks, L. H. (1964). Effects of overtraining on acquisition and reversal of place and response <lb/>learning. Psychol. Rep. 15, 459-462. <lb/>Highcock, L., and Carter, A. J. (2014). Intraindividual Variability of Boldness Is Repeatable <lb/>across Contexts in a Wild Lizard. PLoS One 9, e95179. <lb/>Hills, T. T., Kalff, C., and Wiener, J. M. (2013). Adaptive Lé vy Processes and Area-Restricted <lb/>Search in Human Foraging. PLoS One 8, e60488. <lb/>von Holst, E., and Mittelstaedt, H. (1950). Das Reafferenzprinzip. Wechselwirkungen zwischen <lb/>Zentralnervensystem und Peripherie. Naturwissenschaften 37, 464-476. <lb/>Horn, C. C., Zhurov, Y., Orekhova, I. V, Proekt, A., Kupfermann, I., Weiss, K. R., and <lb/>Brezina, V. (2004). Cycle-to-cycle variability of neuromuscular activity in Aplysia <lb/>feeding behavior. J. Neurophysiol. 92, 157-80. <lb/>Humphries, D. A., and Driver, P. M. (1970). Protean defence by prey animals. Oecologia 5, <lb/>285-302. <lb/>Humphries, N. E., and Sims, D. W. (2014). Optimal foraging strategies: Lé vy walks balance <lb/>searching and patch exploitation under a very broad range of conditions. J. Theor. <lb/>Biol. 358, 179-193. <lb/>Jablonski, P. G., and Strausfeld, N. J. (2001). Exploitation of an ancient escape circuit by an <lb/>avian predator: relationships between taxon-specific prey escape circuits and the <lb/>sensitivity to visual cues from the predator. Brain Behav. Evol. 58, 218-240. <lb/>Jabloń ski, P. G., and Strausfeld, N. J. (2000). Exploitation of an ancient escape circuit by an <lb/>avian predator: prey sensitivity to model predator display in the field. Brain. Behav. <lb/>Evol. 56, 94-106. <lb/>Jacobs, L. F., and Menzel, R. (2014). Navigation outside of the box: what the lab can learn <lb/>from the field and what the field can learn from the lab. Mov. Ecol. 2, 3. <lb/>James, W. (1890). The Principles of Psychology. New York: Holt. <lb/>Jé kely, G., Colombelli, J., Hausen, H., Guy, K., Stelzer, E., Né dé lec, F., and Arendt, D. <lb/>(2008). Mechanism of phototaxis in marine zooplankton. Nature 456, 395-9. <lb/>Konorski, J., and Miller, S. (1937a). Further remarks on two types of conditioned reflex. J. <lb/>Gen. Psychol. 17, 405-407. <lb/>Konorski, J., and Miller, S. (1937b). On two types of conditioned reflex. J. Gen. Psychol. 16, <lb/>264-272. <lb/>Korn, H., and Faber, D. S. (2005). The Mauthner cell half a century later: A neurobiological <lb/>model for decision-making? Neuron 47, 13-28. <lb/>Kornell, N., and Terrace, H. S. (2007). The Generation Effect in Monkeys. Psychol. Sci. 18, <lb/>682-685. <lb/>Lai, C. S., Fisher, S. E., Hurst, J. A., Vargha-Khadem, F., and Monaco, A. P. (2001). A <lb/>forkhead-domain gene is mutated in a severe speech and language disorder. Nature 413, <lb/>519-23. <lb/>Lorenzetti, F. D., Baxter, D. A., and Byrne, J. H. (2008). Molecular Mechanisms Underlying <lb/>a Cellular Analog of Operant Reward Learning. Neuron 59, 815-828. <lb/>Lorenzetti, F. D., Mozzachiodi, R., Baxter, D. A., and Byrne, J. H. (2006). Classical and <lb/>operant conditioning differentially modify the intrinsic properties of an identified <lb/>neuron. Nat. Neurosci. 9, 17-29. <lb/>Lum, C. S., Zhurov, Y., Cropper, E. C., Weiss, K. R., and Brezina, V. (2005). Variability of <lb/>swallowing performance in intact, freely feeding aplysia. J. Neurophysiol. 94, 2427-46. <lb/>Marler, P. (1991). Song-learning behavior: The interface with neuroethology. Trends Neurosci. <lb/>14, 199-206. <lb/>Martin, J.-R., Faure, P., and Ernst, R. (2001). The Power Law Distribution for Walking-Time <lb/>Intervals Correlates with the Ellipsoid-Body in Drosophila. J. Neurogenet. 15, 205-<lb/>219. <lb/>Mauk, M. D. (2000). The potential effectiveness of simulations versus phenomenological <lb/>models. Nat. Neurosci. 3, 649-651. <lb/></listBibl>

			<page>24 <lb/></page>

			<listBibl>McEwen, R. S. (1918). The reactions to light and to gravity in Drosophila and its mutants. J. <lb/>Exp. Zool. 25, 49-106. <lb/>McNamara, J. M., Barta, Z., and Houston, A. I. (2004). Variation in behaviour promotes <lb/>cooperation in the Prisoner&apos; s Dilemma game. Nature 428, 745-748. <lb/>Mendoza, E., Colomb, J., Rybak, J., Pflü ger, H.-J., Zars, T., Scharff, C., and Brembs, B. <lb/>(2014). Drosophila FoxP mutants are deficient in operant self-learning. PLoS One 9, <lb/>e100648. <lb/>Miller, G. F. (1997). &quot; Protean Primates: The Evolution of Adaptive Unpredictability in <lb/>Competition and Courtship,&quot; in Machiavellian Intelligence II: Extensions and <lb/>evaluations, eds. A. Whiten and R. W. Byrne (Cambridge, Ma.: Cambridge University <lb/>Press), 312-340. <lb/>Mitra, O., Callaham, M. ., Smith, M. ., and Yack, J. . (2009). Grunting for worms: seismic <lb/>vibrations cause Diplocardia earthworms to emerge from the soil. Biol. Lett. 5, 16-19. <lb/>Nargeot, R. (2002). Correlation between activity in neuron B52 and two features of fictive <lb/>feeding in Aplysia. Neurosci. Lett. 328, 85-88. <lb/>Nargeot, R., Baxter, D. A., and Byrne, J. H. (1997). Contingent-dependent enhancement of <lb/>rhythmic motor patterns: an in vitro analog of operant conditioning. J. Neurosci. 17, <lb/>8093-105. <lb/>Nargeot, R., Baxter, D. A., and Byrne, J. H. (1999a). In vitro analog of operant conditioning <lb/>in aplysia. I. Contingent reinforcement modifies the functional dynamics of an identified <lb/>neuron. J. Neurosci. 19, 2247-2260. <lb/>Nargeot, R., Baxter, D. A., and Byrne, J. H. (1999b). In vitro analog of operant conditioning <lb/>in aplysia. II. Modifications of the functional dynamics of an identified neuron <lb/>contribute to motor pattern selection. J. Neurosci. 19, 2261-2272. <lb/>Nargeot, R., Baxter, D. A., Patterson, G. W., and Byrne, J. H. (1999c). Dopaminergic synapses <lb/>mediate neuronal changes in an analogue of operant conditioning. J. Neurophysiol. 81, <lb/>1983-7. <lb/>Nargeot, R., Le Bon-Jego, M., and Simmers, J. (2009). Cellular and network mechanisms of <lb/>operant learning-induced compulsive behavior in Aplysia. Curr. Biol. 19, 975-84. <lb/>Nargeot, R., Petrissans, C., and Simmers, J. (2007). Behavioral and in vitro correlates of <lb/>compulsive-like food seeking induced by operant conditioning in Aplysia. J. Neurosci. <lb/>27, 8059-70. <lb/>Nargeot, R., and Simmers, J. (2012). Functional organization and adaptability of a decision-<lb/>making network in aplysia. Front. Neurosci. 6, 113. <lb/>Nargeot, R., and Simmers, J. (2010). Neural mechanisms of operant conditioning and learning-<lb/>induced behavioral plasticity in Aplysia. Cell. Mol. Life Sci. <lb/>Neuringer, A. (2004). Reinforced variability in animals and people: implications for adaptive <lb/>action. Am. Psychol. 59, 891-906. <lb/>Packard, M. G., and McGaugh, J. L. (1996). Inactivation of hippocampus or caudate nucleus <lb/>with lidocaine differentially affects expression of place and response learning. Neurobiol. <lb/>Learn. Mem. 65, 65-72. <lb/>Qian, J., Hintze, A., and Adami, C. (2011). Colored Motifs Reveal Computational Building <lb/>Blocks in the C. elegans Brain. PLoS One 6. <lb/>Reynolds, A. M., Bartumeus, F., Kö lzsch, A., and van de Koppel, J. (2016). Signatures of <lb/>chaos in animal search patterns. Sci. Rep. 6, 23492. <lb/>Ritchie, B. F., Aeschliman, B., and Pierce, P. (1950). Studies in spatial learning. VIII. Place <lb/>performance and the acquisition of place dispositions. J. Comp. Physiol. Psychol. 43, <lb/>73-85. <lb/>Royan, A., Muir, A. P., and Downie, J. R. (2010). Variability in escape trajectory in the <lb/>Trinidadian stream frog and two treefrogs at different life-history stages. Can. J. Zool. <lb/>88, 922-934. <lb/></listBibl>

			<page>25 <lb/></page>

			<listBibl>Sakaguchi, H., and Yamaguchi, A. (1997). Early song-deprivation affects the expression of <lb/>protein kinase C in the song control nuclei of the zebra finch during a sensitive period <lb/>of song learning. Neuroreport 8, 2645-50. <lb/>Santos, M. E., Athanasiadis, A., Leitã o, A. B., DuPasquier, L., and Sucena, E. (2011). <lb/>Alternative splicing and gene duplication in the evolution of the FoxP gene subfamily. <lb/>Mol. Biol. Evol. 28, 237-47. <lb/>Scharff, C., and Haesler, S. (2005). An evolutionary perspective on FoxP2: strictly for the <lb/>birds? Curr. Opin. Neurobiol. 15, 694-703. <lb/>Schulz, S. B., Haesler, S., Scharff, C., and Rochefort, C. (2010). Knockdown of FoxP2 alters <lb/>spine density in Area X of the zebra finch. Genes. Brain. Behav. 9, 732-40. <lb/>Schuster, S. (2012). Fast-starts in hunting fish: decision-making in small networks of identified <lb/>neurons. Curr. Opin. Neurobiol. 22, 279-284. <lb/>Shlesinger, M. F. (2009). Random searching. J. Phys. A Math. Theor. 42, 434001. <lb/>Shultz, S., and Dunbar, R. I. . (2006). Chimpanzee and felid diet composition is influenced by <lb/>prey brain size. Biol. Lett. 2, 505-508. <lb/>Skinner, B. F. (1969). Contingencies of reinforcement: A theoretical analysis. New York: <lb/>Appleton-Century-Crofts. <lb/>Skinner, B. F. (1981). Selection by consequences. Science 213, 501-4. <lb/>Skinner, B. F. (1938). The behavior of organisms. New York: Appleton. <lb/>Skinner, B. F. (1935). Two types of conditioned reflex and a pseudo type. J. Gen. Psychol. 12, <lb/>66-77. <lb/>Skinner, B. F. (1937). Two types of conditioned reflex: A reply to Konorski and Miller. J. Gen. <lb/>Psychol. 16, 272-279. <lb/>Skinner, B. F. (1957). Verbal Behavior. Copley Publishing Group. <lb/>Slamecka, N. J., and Graf, P. (1978). Generation Effect -Delineation of a Phenomenon. J. <lb/>Exp. Psychol. Hum. Learn. Mem. 4, 592-604. <lb/>Thompson, A. K., and Wolpaw, J. R. (2014a). Operant conditioning of spinal reflexes: from <lb/>basic science to clinical therapy. Front. Integr. Neurosci. 8, 25. <lb/>Thompson, A. K., and Wolpaw, J. R. (2015). Targeted neuroplasticity for rehabilitation. Prog. <lb/>Brain Res. 218, 157-72. <lb/>Thompson, A. K., and Wolpaw, J. R. (2014b). The simplest motor skill: mechanisms and <lb/>applications of reflex operant conditioning. Exerc. Sport Sci. Rev. 42, 82-90. <lb/>Thorndike, E. L. (1898). Animal Intelligence. An Experimental Study of the Associative <lb/>Processes in Animals. New York: Macmillan. <lb/>Tolman, E. C., Ritchie, B. F., and Kalish, D. (1946). Studies in spatial learning. II. Place <lb/>learning versus response learning. J. Exp. Psychol. 36, 221-229. <lb/>Tolman, E. C., Ritchie, B. F., and Kalish, D. (1947). Studies in spatial learning. V. Response <lb/>learning vs. place learning by the non-correction method. J. Exp. Psychol. 37, 285-<lb/>292. <lb/>Wolf, R., and Heisenberg, M. (1991). Basic organization of operant behavior as revealed in <lb/>Drosophila flight orientation. J. Comp. Physiol. A. 169, 699-705. <lb/>Wolf, R., and Heisenberg, M. (1986). Visual orientation in motion-blind flies is an operant <lb/>behavior. Nature 323, 154-156. <lb/>Wolf, R., Voss, A., Hein, S., and Heisenberg, M. (1992). Can a fly ride a bicycle? Discussion <lb/>on Natural and Artificial Low-Level Seeing Systems. Philos. Trans. R. Soc. London. <lb/>Ser. B Biol. Sci. 337, 261-269. <lb/>Wolpaw, J. R. (2010). What can the spinal cord teach us about learning and memory? <lb/>Neuroscientist 16, 532-49. <lb/>Wolpaw, J. R., and Chen, X. Y. (2006). The cerebellum in maintenance of a motor skill: a <lb/>hierarchy of brain and spinal cord plasticity underlies H-reflex conditioning. Learn. <lb/>Mem. 13, 208-15. <lb/>Yin, H. H., and Knowlton, B. J. (2006). The role of the basal ganglia in habit formation. Nat. <lb/>Rev. Neurosci. 7, 464-476. <lb/></listBibl>

			<page>26 <lb/></page>

			<listBibl>Yoshida, Y., Yamada, T., and Sakaguchi, H. (2003). Activation of protein kinase C by the <lb/>error signal from a basal ganglia-forebrain circuit in the zebra finch song control nuclei. <lb/>Neuroreport 14, 645-9. <lb/>Young, J. Z. (1938). The Functioning of the Giant Nerve Fibres of the Squid. J. Exp. Biol. <lb/>15, 170-185. </listBibl>


	</text>
</tei>
