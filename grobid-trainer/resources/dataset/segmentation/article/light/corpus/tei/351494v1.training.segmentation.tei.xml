<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="_0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>OpenPathSampling: A Python framework for path sampling simulations. I. Basics <lb/>David W.H. Swenson, , , * Jan-Hendrik Prinz, , , † Frank Noe, , ‡ John D. Chodera, , § and Peter G. Bolhuis , ¶ <lb/>van &apos;t Ho Institute for Molecular Sciences, University of Amsterdam, PO Box <lb/>, <lb/>GD Amsterdam, The Netherlands <lb/>Computational and Systems Biology Program, Sloan Kettering Institute, <lb/>Memorial Sloan Kettering Cancer Center, New York, NY <lb/>, USA <lb/>Department of Mathematics and Computer Science, Arnimallee , Freie Universität Berlin, <lb/>Berlin, Germany <lb/>(Dated: June , <lb/>) <lb/>Transition path sampling techniques allow molecular dynamics simulations of complex systems to focus <lb/>on rare dynamical events, providing insight into mechanisms and the ability to calculate rates inaccessible <lb/>by ordinary dynamics simulations. While path sampling algorithms are conceptually as simple as impor-<lb/>tance sampling Monte Carlo, the technical complexity of their implementation has kept these techniques <lb/>out of reach of the broad community. Here, we introduce an easy-to-use Python framework called Open-<lb/>PathSampling (OPS) that facilitates path sampling for (bio)molecular systems with minimal e ort and yet <lb/>is still extensible. Interfaces to OpenMM and an internal dynamics engine for simple models are provided <lb/>in the initial release, but new molecular simulation packages can easily be added. Multiple ready-to-use <lb/>transition path sampling methodologies are implemented, including standard transition path sampling (TPS) <lb/>between reactant and product states, transition interface sampling (TIS) and its replica exchange variant <lb/>(RETIS), as well as recent multistate and multiset extensions of transition interface sampling (MSTIS, MISTIS). <lb/>In addition, tools are provided to facilitate the implementation of new path sampling schemes built on basic <lb/>path sampling components. In this paper, we give an overview of the design of this framework and illustrate <lb/>the simplicity of applying the available path sampling algorithms to a variety of benchmark problems. <lb/>Keywords: transition path sampling (TPS); transition interface sampling (TIS); molecular dynamics simulation <lb/>(MD); rare events <lb/></front>

			<body>I. INTRODUCTION <lb/>Biomolecular systems, such as proteins and nucleic acids, <lb/>can undergo complex conformational changes on long <lb/>timescales that are challenging for atomistic molecular simu-<lb/>lations to reach. For example, atomistic molecular dynamics <lb/>(MD) must employ timesteps on the scale of femtoseconds to <lb/>faithfully reproduce the fastest vibrational modes to maintain <lb/>simulation stability and fidelity, while the kinetic timescales <lb/>(e.g. of protein folding or binding) can o en range from mi-<lb/>croseconds to seconds or more. In protein-ligand binding, <lb/>mean residence times for bound druglike molecules are o en <lb/>several hours, presenting an enormous challenge to studying <lb/>dissociation mechanisms or predicting unbinding rates by <lb/>straightforward MD [ -]. In these and other situations, sim-<lb/>ulating a su icient number of these rare events (folding/un-<lb/>folding or binding/unbinding) to produce a statistically mean-<lb/>ingful description of the dominant mechanism or estimate <lb/>of rate constants is o en so challenging as to be untenable <lb/>by straightforward means. Slow kinetic time scales primarily <lb/>arise from large kinetic barriers between metastable states [ -<lb/>]. The observed dynamics is dominated by long waiting <lb/>times within metastable basins, punctuated by rare events <lb/>of interest occurring over a short time [ ]. Straightforward <lb/>molecular simulation is highly ine icient as most e ort will <lb/>be wasted simulating uninteresting dynamics as the system <lb/>remains trapped within metastable states [ ]. <lb/> </body>

			<front>* Equal contributor; dwhs@hyperblazer.net <lb/> † Equal contributor; jan.prinz@choderalab.org <lb/> ‡ frank.noe@fu-berlin.de <lb/> § john.chodera@choderalab.org <lb/> ¶ p.g.bolhuis@uva.nl <lb/></front>

			<body>One approach to overcoming the rare event problem is to <lb/>bias the potential energy surface or alter the probability den-<lb/>sity of sampled conformations to enhance the occurrence of <lb/>the rare event. A priori knowledge of a suitable reaction coor-<lb/>dinate allows the use of biasing potentials or higher e ective <lb/>temperatures, reducing e ective free energy barriers. Many <lb/>such enhanced sampling methods have been developed (e.g. <lb/>see Refs. [ -] ). Useful bias potentials capable of enhanc-<lb/>ing the frequency of rare events require (a set of) collective <lb/>variables that approximate the reaction coordinate; poor <lb/>choices will lead to poor sampling of the reactive pathways, <lb/>and hence poor estimates of the dynamical bottlenecks and <lb/>the related barrier heights and rates. Even worse, some meth-<lb/>ods are sensitive to the omission of slow degrees of freedom, <lb/>and may lead to incorrect models of the reactive pathways. <lb/>In general, removing the e ect of the bias potential to yield <lb/>correct dynamics is di icult. <lb/>Path sampling techniques, in paticular transition path sam-<lb/>pling [ , -], provide a solution to the rare event prob-<lb/>lem without requiring the same degree of knowledge of reac-<lb/>tive pathways. Instead of biasing the potential-which leads <lb/>to heavily perturbed dynamics-these techniques bias the <lb/>probability with which a given transition path is sampled, <lb/>without perturbing these paths themselves. This property <lb/>allows the unbiased equilibrium dynamics to be recovered. <lb/>For the simple case of a two-state system separated by a <lb/>single barrier, the straightforward MD simulation time to ob-<lb/>serve a number of transitions scales exponentially in the <lb/>barrier height. In contrast, transition path sampling only fo-<lb/>cuses on short parts of the MD trajectory that traverse the <lb/>barrier, providing exponential acceleration in the sampling of <lb/>rare events [ , ]. Other methods based on trajectory sam-<lb/>pling include forward flux sampling (FFS) [ ], adaptive multi-<lb/>level splitting [ ], milestoning [ ], the RESTART methodol-<lb/>ogy [ ], SPRESS [ ], NEUS [ ], Weighted Ensemble [ , ] <lb/>and many others. <lb/>In addition to studying rare events directly, path sampling <lb/>methods can be combined with other approaches for de-<lb/>scribing statistical conformational dynamics. For example, <lb/>Markov state models (MSMs) have emerged as a popular <lb/>way to represent the long time statistical dynamics of com-<lb/>plex processes involving many distinct metastable confor-<lb/>mational states [ ]. By discretizing conformation space and <lb/>describing stochastic transitions between regions with a tran-<lb/>sition or rate matrix, MSMs can describe the long-time statis-<lb/>tical dynamics of complex systems with bounded approxima-<lb/>tion error [ ]. While standard MSM construction approaches <lb/>utilize large quantities of unbiased simulation data, path <lb/>sampling techniques can be utilized to rapidly construct or <lb/>improve MSM transition matrices by focusing on harvesting <lb/>trajectories for poorly sampled transitions [ , -]. More <lb/>recently, techniques have emerged for combining both bi-<lb/>ased and unbiased dynamics to construct multi-ensemble <lb/>Markov Models (MEMMs) [ -], enabling even richer combi-<lb/>nations of multiple e icient sampling techniques for rapid <lb/>construction of statistical models of dynamics. <lb/>While transition path sampling techniques are very flex-<lb/>ible, the complexity of their implementation and lack of <lb/>a standard tool for applying them has slowed their adop-<lb/>tion. In particular, many path sampling techniques require <lb/>monitoring of dynamics to detect when stopping conditions <lb/>are reached, and the control of and integration with stan-<lb/>dard simulation packages has been a practical obstacle for <lb/>widespread use. As a solution to this, we have developed <lb/>a new framework called OpenPathSampling (OPS) that en-<lb/>ables path sampling techniques to be employed in a flexible, <lb/>general manner. This framework is &quot;batteries included&quot;, with <lb/>a number of di erent path sampling algorithms and worked <lb/>examples available that can help users to apply path sam-<lb/>pling techniques on their own system. Both low-dimensional <lb/>toy model systems and complex molecular systems are sup-<lb/>ported, with complex systems supported using interfaces to <lb/>external simulation codes. Currently, OPS supports the GPU-<lb/>accelerated molecular simulation code OpenMM [ , ], al-<lb/>though support for other codes can be added. The framework <lb/>is flexible and extensible, allowing users to easily explore im-<lb/>plementation of new path sampling algorithms in addition to <lb/>applying or extending existing algorithms or connecting new <lb/>simulation codes. Many other methods, such as FFS or mile-<lb/>stoning, could also be implemented within the framework of <lb/>OPS. For the sake of clarity, however, we will limit ourselves <lb/>here to the transition path sampling based methods . OPS dif-<lb/>fers in scope and versatility from the PyRETIS package[ ], a <lb/></body>

			<note place="footnote">Note that in this work we o en use &apos;transition path sampling&apos; and &apos;path <lb/>sampling&apos; interchangeably. The reason is that the concept of path sam-<lb/>pling is more inclusive, and also covers algorithms that do not imme-<lb/>diately aim to cross (single) barriers. However, it is understood that all <lb/>path sampling methods in this work fall into the larger &apos;transition path <lb/>sampling&apos; family of algorithms. <lb/></note>

			<body>recently developed package to conduct advanced transition <lb/>path sampling simulations. <lb/>In this paper, we first give a brief overview of a variety of <lb/>path sampling techniques that are implemented in the OPS <lb/>framework (Section II); explain how the basic path sampling <lb/>concepts relate to OPS object classes (Section IV); review the <lb/>general workflow associated with setting up, running, and <lb/>analyzing a path sampling calculation (Section V); and then <lb/>provide a number of detailed examples that illustrate the <lb/>flexibility and simplicity of applying various path sampling <lb/>techniques using this framework (Section VI). In the process <lb/>of developing a framework capable of easily implementing a <lb/>multitude of path sampling techniques, we have significantly <lb/>generalized the manner in which path ensembles can be con-<lb/>structed and used within the path sampling mathematical <lb/>framework. While this expressive path ensemble specifica-<lb/>tion language is briefly introduced (Section III) and utilized <lb/>in the examples described here, this approach is described <lb/>in detail in a companion paper in this issue [ ]. <lb/>II. BACKGROUND <lb/>A. The concept of path ensembles <lb/>Here, we presume the reader is somewhat familiar with <lb/>the transition path sampling literature [ , -, ]. While <lb/>we give a brief overview of the main concepts in this section, <lb/>readers not familiar with this topic are encouraged to start <lb/>with a basic review such as Ref. [ ]. <lb/>The types of path sampling considered in this paper-and <lb/>implemented and supported by OpenPathSampling-deal <lb/>with equilibrium dynamics, obeying microscopic reversibility, <lb/>so that the stationary distribution is the Boltzmann distribu-<lb/>tion. Moreover, ergodicity is assumed; that is, an infinitely-<lb/>long trajectory has a nonzero probability to visit every point <lb/>in phase space. This guarantees that (dynamical) averages <lb/>computed in the path ensemble, such as rate constants, are <lb/>identical to those of an infinitely long trajectory. <lb/>A path or trajectory consists of a sequence of L + 1 points <lb/>in configuration or phase space x ≡ {x 0 , x 1 , . . . , x L } gen-<lb/>erated by some dynamical model (such as Hamiltonian, <lb/>Langevin, Brownian, or even Monte Carlo dynamics), with <lb/>the initial configuration x 0 drawn from an initial (equilib-<lb/>rium) distribution ρ(x 0 ). The path ensemble is defined by the <lb/>probability distribution P[x] of such paths (with the length L <lb/>either fixed or varying), and can be sampled using a Markov <lb/>Chain Monte Carlo (MCMC) algorithm. Path sampling algo-<lb/>rithms consist of a few main ingredients: ( ) a scheme for <lb/>initializing the sampler with an initial path; ( ) one or more <lb/>schemes for proposing new trial paths from the current path; <lb/>( ) an acceptance criteria (e.g., based on Metropolis-Hastings) <lb/>used to accept or reject the proposed trial path to generate a <lb/>new sample from the path probability density (ensemble) of <lb/>interest. <lb/>The idea of path sampling is to enhance the probability <lb/>sampling of certain paths, either by biasing the path prob-<lb/>ability or by constraining the path ensemble. Analogous to <lb/>how standard Monte Carlo importance sampling techniques <lb/>can enhance sampling of rare configurations by multiplying <lb/>the probability density by a biasing factor w bias (x) based on <lb/>the instantaneous conformtion x, <lb/>ρ bias (x) ∝ w bias (x)ρ(x), <lb/>( ) <lb/>and subsequently using this bias to unbias the sampled en-<lb/>semble and recover equilibrium expectations, path sampling <lb/>techniques can enhance the sampling of rare trajectories <lb/>by multiplying by a biasing weight w bias [x], based on the <lb/>trajectory x, <lb/>P bias [x] ∝ w bias [x] P[x]. <lb/>( ) <lb/>Many types of path sampling, notably standard transition <lb/>path sampling (TPS) [ , ], define constrained path ensem-<lb/>bles which select trajectories that begin in one region of con-<lb/>figuration space A and end in another region B. OPS supports <lb/>a simple but powerful way of defining path ensembles, de-<lb/>scribed briefly in Section V B and expanded upon in detail <lb/>in a companion paper [ ]. Below, we give a brief overview <lb/>of common kinds of transition path sampling simulations <lb/>supported by OPS. <lb/>B. Transition path sampling <lb/>The transition path sampling (TPS) [ , ] method attempts <lb/>to harvest trajectories connecting two specific regions of con-<lb/>figuration space, such as a reactant and product separated by <lb/>a single free energy barrier. The constrained path ensemble <lb/>for a fixed length L is thus <lb/>P AB [x] ∝ 1 A (x 0 )1 B (x L )P[x]. <lb/>( ) <lb/>Here, x ≡ {x 0 , x 1 , . . . , x L } is a discrete-time trajectory of <lb/>snapshots, 1 A (x 0 ) and 1 B (x L ) are indicator function that <lb/>are unity if the trajectory starts with x 0 ∈ A and ends with <lb/>x L ∈ B and zero otherwise, and P[x] is the equilibrium path <lb/>probability density. In a TPS simulation, new trial trajectories <lb/>are proposed from the current sampled trajectory by select-<lb/>ing a phase space point along the trajectory, applying a per-<lb/>turbation (usually of the momenta), and &quot;shooting&quot; forward <lb/>and backward by integrating the equations of motion until a <lb/>trajectory of the original length is generated. The trial trajec-<lb/>tory is then accepted or rejected with a Metropolis-Hastings <lb/>criterion. For the simplest case of drawing the shooting point <lb/>uniformly from the current trajectory, assigning a new veloc-<lb/>ity from the Maxwell-Boltzmann distribution, and imposing <lb/>the trajectory of fixed length to begin in state A and end in <lb/>B, this acceptance criteria amounts to accepting the new <lb/>trajectory when it satisfies the defined ensemble of interest <lb/>by terminating in regions A and B; the old path is otherwise <lb/>retained if the proposed trajectory is rejected. Depending <lb/>on the details of the shooting move, the exact acceptance <lb/>criteria will take on di erent forms [ , -, ]. <lb/>Transition path sampling is immensely powerful, as the dif-<lb/>ficult problem of describing reaction mechanisms is reduced <lb/>to the much easier problem of defining stable states A and <lb/>B. Reactive trajectories are e iciently harvested because <lb/>the trial trajectory quickly decorrelates from the original tra-<lb/>jectory, yet is still likely to meet the same path ensemble <lb/>constraints, such as connecting the reactant and product <lb/>regions of configuration space A and B. <lb/>In order for the reactive trajectories connecting metastable <lb/>sets A and B to be useful for computing transition rates and <lb/>physical interpretation of mechanisms, the system must com-<lb/>mit to and remain in the metastable states for a long time af-<lb/>ter encountering them, i.e., transitions between A and B are <lb/>rare events on the molecular time scale. The states A and B <lb/>are generally defined as configurational space regions within <lb/>the basin of attraction of the distinct metastable states. Tra-<lb/>jectories initiated from configurations in these regions, called <lb/>core sets, should have a high probability (close to unity) to <lb/>remain in or quickly return to the core set rather than escape <lb/>to other states, even at the boundary of these sets [ , ]. <lb/>TPS can also be used with flexible-length trajectories that <lb/>are constrained to terminate when they encounter the bound-<lb/>ary of core sets A and B. This can be encoded in the path en-<lb/>semble definition by demanding that frames to L−1 are nei-<lb/>ther in A nor in B. This approach is more e icient at sampling <lb/>reactive trajectories by avoiding sampling long dwell times <lb/>in each state at either end of the trajectory [ ]. To maintain <lb/>detailed balance, the acceptance criterion then contains the <lb/>ratio of the previous and trial path length, i.e., the number <lb/>of frames from which the shooting point is randomly chosen. <lb/>TPS can also easily be extended to multiple states by allowing <lb/>more states in the path ensemble definition [ ]. A variety of <lb/>other path proposal moves have been described to attempt <lb/>to increase acceptance probabilities in certain regimes, in-<lb/>cluding shi ing moves [ ], small velocity perturbations [ ], <lb/>precision shooting [ ], permutation shooting [ ], aimless <lb/>shooting [ ], and spring shooting [ ]. <lb/>C. Transition interface sampling (TIS) <lb/>While TPS yields information about the mechanism of the <lb/>rare events, important quantities such as the kinetic rate <lb/>constant requires an additional scaling factor that quantifies <lb/>how frequent transition paths are relative to non-transition <lb/>paths. Therefore, one has to relate the constrained TPS en-<lb/>semble with the unconstrained path ensemble, as given by <lb/>an infinitely long ergodic unbiased MD trajectory [ ]. This <lb/>unconstrained total (or complete) path ensemble comprises <lb/>the set of path ensembles starting from each stable state, <lb/>consisting of all (properly weighted) paths that leave that <lb/>state and either return to it, or go on to any other stable state. <lb/>Even when restricting the path ensemble to start in a partic-<lb/>ular state A, straightforward path sampling of an otherwise <lb/>unconstrained ensemble is naturally very ine icient, as the <lb/>important transitions to other states are exceedingly rare. <lb/>However one can construct the total path ensemble (for each <lb/>state) by a staging procedure. In such a procedure one can <lb/>constrain the paths to reach further and further out of the <lb/>state (while of course still starting in the stable state). This <lb/>constraining can be done using the transition interface sam-<lb/>pling method (TIS) [ ], an extension of TPS that is explained <lb/>below. Reweighting of the resulting paths yield then (an esti-<lb/>mate of) the total path ensemble [ ]. <lb/>Transition interface sampling (TIS) [ ] provides a more <lb/>e icient evaluation of the rates compared to the original <lb/>TPS rate constant calculation [ ] by sampling each con-<lb/>strained interface ensemble. TIS defines a set of N non-<lb/>intersecting hypersurfaces (the &apos;interfaces&apos;) around the stable <lb/>state, parametrized by a collective variable λ, and foliating, <lb/>in principle, the entire configuration space (or even phase <lb/>phase[ ]). The rate constant from A to B is expressed as <lb/>k AB = φ 0A P A (λ B |λ 0 ) = φ 0A <lb/>N −1 <lb/>i=0 <lb/>P A (λ i+1 |λ i ), ( ) <lb/>where φ 0A denotes the flux out of A through λ 0 , and <lb/>P A (λ B |λ 0 ) is the crossing probability, the probability that <lb/>a trajectory originating from A reaches interface λ B before <lb/>returning to A, provided that the path already crosses λ 0 at <lb/>least once. This probability is generally low, as the transition <lb/>is a rare event, but can be computed through the product of <lb/>all crossing probabilities for the individual interfaces, as indi-<lb/>cated in Eq. , with λ N ≡ λ B [ ]. Interfaces should be opti-<lb/>mally placed such that each crossing probability in the prod-<lb/>uct is roughly P A (λ i+1 |λ i ) ≈ 0.2 [ ]. The total number of <lb/>required interfaces is thus of the order N ≈ | log 5 P (λ B |λ A )|. <lb/>
			As an example, for a barrier of k B T , this roughly translates <lb/>into N = 30/ ln(5) ≈ 18 interfaces. The staging approach <lb/>thus avoids the problem of the exponentially low rate in a <lb/>way analogous to umbrella sampling [ ]. <lb/>Note that the product is not simply a product of Markovian <lb/>transition probabilities, as for each interface the entire trajec-<lb/>tory starting from A is taken into account. Evaluation of the <lb/>crossing probabilities requires sampling the path ensemble <lb/>for each interface with the constraint that the path needs to <lb/>cross that interface. While trajectories could in principle be <lb/>stopped when they reach the next interface, it turns out to be <lb/>beneficial to continue the trajectory integration until a stable <lb/>state (A or B) has been reached. This also allows the appli-<lb/>cation of the so-called reversal move of A-to-A trajectories, <lb/>where the time direction of the path is reversed, which can <lb/>be done with no additional cost, but assists in decorrelating <lb/>paths. The flux φ 0A can be easily obtained using straightfor-<lb/>ward MD inside state A [ , ]. <lb/>The reverse rate can be computed by repeating the TIS <lb/>simulation from state B: define a set of interfaces, sample the <lb/>interface ensembles, and compute the crossing probability <lb/>P B (λ B |λ A ). <lb/>Similar to TPS, the TIS algorithm can be extended to mul-<lb/>tiple states [ ]. To estimate kinetic rates between multiple <lb/>states, each state I gets its own set of interfaces λ iI , and the <lb/>rate constant from state I to state J is given by <lb/>k IJ = φ 0I P I (λ mI |λ 0I )P I (λ 0J |λ mI ), <lb/>( ) <lb/>where φ 0I is again the flux from I through λ 0I . The sec-<lb/>ond factor is the crossing probability to an outermost in-<lb/>terface m, which is typically very small and expressed as <lb/>P (λ mI |λ 0I ) = <lb/>m−1 <lb/>i=0 P I (λ (i+1)I |λ iI ). The last factor in <lb/>Eq. is the conditional probability that a trajectory crossing <lb/>the outermost interface also reaches state J. The location <lb/>of the outermost interfaces should be chosen such that the <lb/>probability to escape from A is su iciently large. Note that <lb/>while interfaces belonging to state I constitute a foliation of <lb/>non-overlapping hypersurfaces, they are completely inde-<lb/>pendent from the interfaces of state J, and in fact are allowed <lb/>to overlap [ , ]. <lb/>We introduce the concept of a transition network [ ] that, <lb/>in its simplest form, represents the ensembles of paths con-<lb/>necting pairs of defined states. For each state in the transition <lb/>network (multiple state) TIS results in a set of interface path <lb/>ensembles and a straightforward MD ensemble of that stable <lb/>state, which can be combined to yield the total path ensem-<lb/>ble by reweighting. Repeating this for all states, and (again) <lb/>properly reweighting [ , , ], leads to an accurate de-<lb/>scription of the kinetic rate matrix, the free energy landscape, <lb/>the mechanisms and reaction coordinates of all transitions <lb/>between the metastable states. This data can be further an-<lb/>alyzed using theory of Markovian stochastic processes, e.g., <lb/>the Chapman-Kolgomorov equation [ ] or transition path <lb/>theory [ ]. <lb/>D. Considerations in transition path sampling <lb/>The reader should be aware of a number of challenges they <lb/>may encounter in setting up transition path sampling based <lb/>simulations. While an exhaustive list is beyond the scope of <lb/>this paper, we list some important issues below. (See also <lb/>Ref. [ ]). <lb/>. Definition of the states <lb/>Transition path sampling requires knowledge of the stable <lb/>states. Usually the stable states are easier to characterize and <lb/>identify than the transition region. Analyzing straightforward <lb/>MD can provide information on how to describe the states <lb/>in terms of (several) collective variables. Such heuristic ap-<lb/>proaches has been used in previous applications [ , , ]. <lb/>In addition, tools such as clustering can be used to define <lb/>the states [ ]. Ideally, one would like to use automatic state <lb/>recognition, and recently attempts have been made in that <lb/>direction [ ]. In OPS we assume that the reader has an idea <lb/>about how to capture stable states by defining a range in (sev-<lb/>eral) collective variables. OPS provides the user with tools to <lb/>facilitate identification of these ranges, and hence definition <lb/>of the states. The choice of the stable state definitions still re-<lb/>quires careful attention, as an erroneous definition can easily <lb/>lead to improper or failed path sampling. For a detailed dis-<lb/>cussion on the stable state definitions, see Refs [ , , ]. <lb/>. Intermediate metastable states <lb/>Even if the process of interest exhibits two-state kinetics, <lb/>suggesting only two highly stable states are involved, it is pos-<lb/>sible that the presence of one or more intermediate states <lb/>with lifetimes short on the overall time scale but long on <lb/>the molecular timescale will cause reactive trajectories con-<lb/>necting the stable states to be quite long. A solution to this <lb/>problem is to identify the intermediate state(s), define their <lb/>core sets, and to use multistate transition interface sampling <lb/>(MSTIS) [ , ]. Alternatively, one can choose to simply sam-<lb/>ple long pathways [ ], which can still be quite fast given <lb/>the speed of modern GPU-accelerated molecular simulation <lb/>engines like OpenMM [ , ]. <lb/>. Ergodicity of path space <lb/>While the TPS and TIS algorithms are &quot;exact&quot; in the sense <lb/>that they should lead to the asymptotically unbiased esti-<lb/>mates of path averages in the limit of infinite sampling, they <lb/>su er from the same problems that all Monte Carlo meth-<lb/>ods encounter, the problem of slowly mixing Markov chains, <lb/>which in severe cases may result in broken ergodicity for prac-<lb/>tical computer times. As TIS samples path space by perturb-<lb/>ing an existing path to generate new proposals, decorrela-<lb/>tion from the initial path to generate many e ectively un-<lb/>correlated paths is essential for producing useful unbiased <lb/>estimates. However, since there might be (possibly high) <lb/>barriers in path space orthogonal to the interfaces between <lb/>di erent allowed reaction channels, this is far from guaran-<lb/>teed. One way of solving this problem is by using replica <lb/>exchange among path ensembles in transition interface sam-<lb/>pling (RETIS) [ , ]. <lb/>E. Replica exchange transition interface sampling (RETIS) <lb/>The RETIS algorithm simultaneously samples all TIS en-<lb/>sembles while allowing for swapping of paths between inter-<lb/>face ensembles when possible [ , ]. A transition path that <lb/>follows one particular mechanism can then slowly morph <lb/>into a completely di erent transition path by exchanging it <lb/>back and forth among all interfaces to state B. Including an <lb/>exchange between pathways belonging to di erent states <lb/>further enhances sampling convergence [ ]. <lb/>Further sampling improvement can be achieved by includ-<lb/>ing van Erp&apos;s minus interface ensemble [ , ]. The minus <lb/>interface move exchanges a trajectory in the first interface en-<lb/>semble with a trajectory exploring the stable state (the minus <lb/>interface ensemble). This serves two aims: ( ) to decorrelate <lb/>pathways in the first interface which tend to be short; and <lb/>( ) to provide a direct estimate for the flux out of the stable <lb/>state [ -]. OPS includes an implementation of multiple <lb/>state RETIS, which we will refer to as MSTIS. <lb/>The default MSTIS approach employs a single set of inter-<lb/>faces for each state, based on one order parameter. Multiple <lb/>interface set TIS (MISTIS), also implemented in OPS, general-<lb/>izes this approach to include multiple interface sets for states <lb/>or transitions [ ]. Although TIS is much less sensitive to the <lb/>choice of order parameter than other enhanced sampling <lb/>methods [ ], in practice, the e iciency is a ected by this <lb/>choice. Using di erent order parameters to describe (sets of) <lb/>interfaces for di erent transitions and/or states, with the help <lb/>of replica exchange, might alleviate such e iciency problems. <lb/>A drawback of the (multiple state) RETIS approach is that <lb/>it requires one replica to be simulated for each interface; for <lb/>systems with multiple stable cores and associated interface <lb/>sets defined, this can quickly get out of hand quickly, as each <lb/>core might possess O(10) interfaces. This large number of <lb/>interface ensembles prevent e icient implementation of the <lb/>method for systems more complex than toy models. A par-<lb/>allel implementation of all interfaces might seem a simple <lb/>solution, but will be complicated by the fact that the duration <lb/>of the paths in the di erent interface ensembles varies wildly. <lb/>Single replica TIS (SRTIS), based on the method of expanded <lb/>ensembles [ ], can alleviate this problem [ ]. Instead of <lb/>exchanging paths between interface ensembles, only one <lb/>replica is sampled, and transitions between ensembles are <lb/>proposed. To avoid the replica remaining close to the stable <lb/>state interface ensemble, one needs a biasing function that <lb/>pushes the replica to higher interfaces. Selecting the (un-<lb/>known) crossing probability as the biasing function would <lb/>ensure equal sampling of all interfaces, which is close to op-<lb/>timal. While the crossing probabilities are initially unknown, <lb/>an iterative procedure can be used to adapt the bias during <lb/>the simulation, as each interface ensemble naturally gives <lb/>an estimate for the crossing probability [ , ]. SRTIS can <lb/>easily be extended to include multiple states [ ] or utilize <lb/>multiple independent walkers [ , ]. <lb/>III. NOVEL CONCEPTS IN OPS <lb/>OpenPathSampling contains many new approaches to im-<lb/>plementing transition path sampling simulations, but there <lb/>are two points that we would particularly like to draw atten-<lb/>tion to: ( ) the use of volume-based interface definitions in <lb/>TIS and ( ) the general treatment of path ensembles. <lb/>A. Volume-based interface definitions <lb/>In the original TIS algorithm and most path sampling algo-<lb/>rithms based on TIS, interfaces are defined as hypersurfaces <lb/>in configuration space. To belong to the interface ensemble, <lb/>a path needs to cross this interface, meaning that at a certain <lb/>time it is at one side of the interface, while a timestep later <lb/>it is on the other side. We consider a novel interface defini-<lb/>tion in OPS which relies on hypervolumes in configuration or <lb/>phase space rather than hypersurfaces. We use the conven-<lb/>tion that the initial state is inside the hypervolume. In this <lb/>definition, a path belongs to an interface ensemble defined <lb/>by a hypervolume if it starts in the initial state, leaves the <lb/>hypervolume at some point along the path, and terminates <lb/>in any stable state. The advantage of using volumes instead <lb/>of surfaces is that set logic (e.g., a union or intersection) can <lb/>be applied to generate new volume definitions from existing <lb/>volumes. For a more extensive discussion see the companion <lb/>paper [ ]. <lb/>Flexible-length TPS <lb/>Fixed-length TPS <lb/>TIS <lb/>Minus interface <lb/>(a) <lb/>(b) <lb/>(c) <lb/>(d) <lb/>FIG. 1. Common path ensembles in TPS and TIS with repre-<lb/>sentative trajectories. Shaded areas represent states, and dashed <lb/>lines represent interface boundaries. <lb/>B. General treatment of ensembles <lb/>One of the novel approaches in OPS is the generalization <lb/>of path ensembles. Previously, each path ensemble had to <lb/>be treated with specialized code. However, as the number <lb/>of path ensembles types has grown, the need to treat them <lb/>in a general fashion arose. In this paper, we make use of a <lb/>range of path ensembles, including the following, which are <lb/>illustrated in Fig. : <lb/>• Flexible length TPS ensemble (Fig. a): The standard <lb/>TPS ensemble is a path ensemble between two states. <lb/>Only the initial and final frames are inside the states. <lb/>• Fixed length TPS ensemble (Fig. b): As with the flexi-<lb/>ble length TPS ensemble, the initial and final frames <lb/>must be in the initial and final states. However, the <lb/>fixed length ensemble has a predefined length, and <lb/>also allows frames other than the first and final to be <lb/>in the state. <lb/>• TIS ensemble (Fig. c): The elementary path ensembles <lb/>in TIS have an interface associated with them. They <lb/>must begin in a given state, exit the interface hypervol-<lb/>ume, and end in any stable state. <lb/>• Minus (interface) ensemble (Fig. d): Paths in the minus <lb/>ensemble can be described in terms of three segments: <lb/>the first and last segments are similar to TIS ensemble <lb/>paths. They start in the state, exit the interface hyper-<lb/>volume, and return to state (where TIS ensemble paths <lb/>can go to another state, these segments cannot). These <lb/>two segments are connected by another segment that <lb/>never exits the interface. Note that this implementa-<lb/>tion of the minus interface ensemble is based on Ref. , <lb/>as opposed to the original minus interface ensemble <lb/>introduced in Ref. . The two versions di er slightly <lb/>(with the original being subtrajectories of the version <lb/>used here), however both versions serve the same pur-<lb/>pose. <lb/>All of these common ensembles can be generalized for <lb/>more complicated reaction networks. The TPS ensembles <lb/>become multiple state TPS ensembles if they allow any state <lb/>to be the initial or final state, as long as the initial and final <lb/>states are di erent. The TIS ensemble becomes a multiple <lb/>
			state TIS ensemble by allowing any state as the final state. <lb/>The minus ensemble becomes the multiple interface set mi-<lb/>nus ensemble by taking its interface as the union of inner-<lb/>most interfaces. <lb/>OPS allows complicated ensembles to be built from sim-<lb/>pler ones. It generalizes both the procedure for testing <lb/>whether a given trajectory satisfies the ensemble and the <lb/>procedure for generating new trajectories. Details of this im-<lb/>plementation, as well as novel approaches to analysis that <lb/>this implementation enables, will be discussed in the com-<lb/>panion paper [ ]. <lb/>IV. THE INGREDIENTS OF OPS <lb/>Before explaining the OpenPathSampling framework and <lb/>workflow in more detail, we first explain the frequently used <lb/>basic objects of OPS that are related to path sampling con-<lb/>cepts described in the previous sections. The objects in OPS <lb/>are divided in two main categories: ( ) Data objects that con-<lb/>tain the sampled paths and information about the sampling <lb/>process; and ( ) Simulation objects that perform the sam-<lb/>pling. All objects generated in OPS, both data and simulation <lb/>objects, are stored in a single Storage file, and can be ac-<lb/>cessed from it. For example, the MCStep objects saved during <lb/>the simulation can be accessed with storage.steps once a <lb/>file is loaded into storage. <lb/>A. Data objects <lb/>The main data objects of OPS fit into a hierarchy as shown <lb/>in Fig. . The data structure can be divided into what is being <lb/>(MCStep) <lb/>active (SampleSet; collection of Sample) <lb/>trajectory (Trajectory [list of Snapshot]) <lb/>ensemble (Ensemble) <lb/>replica (int) <lb/>change (MoveChange) <lb/>subchanges (list of MoveChange) <lb/>mover (PathMover) <lb/>trials (list of Sample) <lb/>accepted (bool) <lb/>details (Details) <lb/>FIG. 2. Hierarchical data structure of the MCStep data object. <lb/>The attribute names are shown, and the type is provided in paren-<lb/>theses. <lb/>sampled (i.e., which trajectories from which ensembles), and <lb/>how it is being sampled (i.e., the nature of the path moves <lb/>performed.) All of this is unified in the MCStep object, which <lb/>describes a step of the path sampling simulation, and which <lb/>has two important attributes: a SampleSet object called <lb/>active, which records the state of all replicas in the simula-<lb/>tion at the end of a given simulation step (the &quot;what&quot;); and <lb/>a MoveChange object called change, which describes what <lb/>happened during the simulation step (the &quot;how&quot;). Below we <lb/>describe these attributes in more detail. <lb/>. Data structures for what is being sampled <lb/>• Snapshots, sometimes called &quot;frames&quot; or &quot;time slices,&quot; <lb/>are at the core of any simulation technique. They de-<lb/>scribe the state of the physical system at a point in <lb/>time, and in molecular dynamics, typically consist of <lb/>coordinates, velocities, and periodic cell vectors. The <lb/>Snapshot object in OPS can be easily extended to carry <lb/>additional data, such as wavefunction information or <lb/>variables from an extended phase space. <lb/>• A Trajectory, also called a &quot;path,&quot; is essentially a list <lb/>of Snapshots in temporal order. In addition, it pro-<lb/>vides several convenience methods, for example, to <lb/>identify which Snapshots are shared by two trajecto-<lb/>ries. <lb/>• The Sample object is a data structure that links a <lb/>Trajectory with the Ensemble object (described in <lb/>section IV B) from which it was sampled, and an inte-<lb/>ger replica ID. The Sample is needed because meth-<lb/>ods such as TIS, and especially RETIS, sample multiple <lb/>ensembles simultaneously. Correct analysis requires <lb/>knowing the ensemble from which the Trajectory <lb/>was sampled. <lb/>• Since methods like TIS have several active Samples dur-<lb/>ing a path simulation step, OPS collects them into one <lb/>SampleSet. The SampleSet contains a list of Samples, <lb/>and also has convenience methods to access a sample <lb/>either by replica ID or by ensemble, using the same <lb/>syntax as a Python dict. <lb/>. Data structures for how the sampling occurs <lb/>• The MoveChange contains a record of what happened <lb/>during the simulation step. Because the simulation <lb/>move itself generally consists of several nested de-<lb/>cisions (type of move, which ensemble to sample, <lb/>etc.), the MoveChange object can contain subchanges, <lb/>which record this entire sequence of decisions. In addi-<lb/>tion, it includes a pointer to its PathMover (described <lb/>in section IV B), a list of the trial Samples generated <lb/>during the step, and a boolean as to whether the trial <lb/>move was accepted. <lb/>CVs &amp; Order <lb/>Parameters <lb/>Dynamics <lb/>States &amp; <lb/>Interfaces <lb/>Reactions <lb/>Monte Carlo <lb/>Move Types <lb/>Output file <lb/>Initial <lb/>Conditions <lb/>Collective <lb/>Variable <lb/>Dynamics <lb/>Engine <lb/>Volume <lb/>Transition <lb/>Network <lb/>Move <lb/>Scheme <lb/>Storage <lb/>Sample <lb/>Set <lb/>Transition <lb/>Ensemble <lb/>Move <lb/>Strategy <lb/>Path <lb/>Mover <lb/>Runnable <lb/>Simulation <lb/>Path <lb/>Simulator <lb/>Concepts <lb/>user-created <lb/>automatically-created <lb/>OPS Objects <lb/>FIG. 3. Schematic representation of the connection between <lb/>the path sampling concepts and their related OPS objects. The <lb/>concepts are listed in the le most column, shaded green. The next <lb/>column shows the objects which must be created by a user to run a <lb/>simulation. The filled arrows indicate when one object is the input <lb/>to create another object. The objects in the right two columns are <lb/>automatically created. The open arrows point from an object to the <lb/>objects it automatically creates. In this way a TransitionNetwork <lb/>creates Transition object that creates in turn Ensemble objects. <lb/>• The MoveChange also contains a Details object, <lb/>which is essentially a dictionary to store additional <lb/>metadata about a move. This metadata will vary de-<lb/>pending on the type of move. For example, with a <lb/>shooting move, it would include the shooting point. In <lb/>principle, all the additional information that might be <lb/>of interest for analysis should be stored in the Details. <lb/>B. Simulation objects <lb/>The simulation objects actually perform the simulation, <lb/>and can be assembled in di erent ways to perform many <lb/>types of simulations. In addition, simulation objects in OPS <lb/>can be stored. This facilitates restarts to continue a simula-<lb/>tion and enables re-use for other types of simulations, e.g., <lb/>using the same state definitions for committor analysis as <lb/>well as path sampling. The PathSimulator class contains <lb/>all the information to run the simulation. The PathSampling <lb/>subclass of PathSimulator is used for path sampling sim-<lb/>ulations. Fig. shows the relation between path sampling <lb/>concepts and the associated objects in OPS. Each of the com-<lb/>ponents is described in more detail below. <lb/>• A DynamicsEngine performs the actual molecular dy-<lb/>namics: that is, it generates a trajectory from an initial <lb/>frame. OPS has built-in support for an internal toy dy-<lb/>namics engine (primarily intended for D models) and <lb/>for OpenMM [ ]. Support for Gromacs [ , ] and <lb/>LAMMPS [ ] will be added in future releases. <lb/>• A CollectiveVariable is a function of a Snapshot, <lb/>and in many cases is just a function of the coordi-<lb/>nates. It is also sometimes called the &quot;order pa-<lb/>rameter,&quot; &quot;progress variable,&quot; &quot;reaction coordinate,&quot; <lb/>or &quot;feature.&quot; In line with the rare event terminol-<lb/>ogy (e.g., [ , ]) the neutral term CV (for Collec-<lb/>tive Variable) can both be used to define interfaces <lb/>and states (via Volumes), as well as to construct or-<lb/>der parameters. The CollectiveVariable in OPS <lb/>is a wrapper class around an arbitrary function. For <lb/>example, the CoordinateFunctionCV will wrap any <lb/>user-defined function that only depends on the snap-<lb/>shot&apos;s coordinates. In addition, specific classes en-<lb/>able the use of functions from other packages, e.g, the <lb/>MDTrajFunctionCV provides a wrapper class for func-<lb/>tion from the MDTraj [ ] analysis package. Other wrap-<lb/>pers exist for MSMBuilder [ , ] and PyEMMA [ ]. <lb/>• The Volume class in OPS represents a hypervolume in <lb/>phase space. This can be used to define a state, also <lb/>called a &quot;core set.&quot; In addition, interfaces are also de-<lb/>fined by volumes, rather than by hypersurfaces as in <lb/>the traditional TIS literature (see section III A). A vol-<lb/>ume is typically defined based on allowed ranges of <lb/>CVs; in OPS the CVDefinedVolume object creates such <lb/>a volume based on a minimum and maximum value of <lb/>the CV. <lb/>• The Ensemble class in OPS defines the paths that are <lb/>allowed within a given path ensemble. It is more ac-<lb/>curately thought of as the indicator function for a re-<lb/>stricted path ensemble (c.f. Eq. ). The indicator func-<lb/>tion alone reduces the set of all possible paths to the <lb/>trajectories with non-zero probablity in the path en-<lb/>semble, but with no distinction in their relative statisti-<lb/>cal probabilities. Sampling according to the correct sta-<lb/>tistical weights is the role of the PathMover, described <lb/>below. <lb/>In addition to the indicator function, Ensemble objects <lb/>contain two methods, can_append and can_prepend, <lb/>which check whether a given trajectory could be ap-<lb/>pended or prepended into a trajectory in the ensemble. <lb/>This allows us to create a rich toolkit to create custom <lb/>ensembles. For instance, a path that connects states <lb/>A and B is defined as a trajectory that follows the se-<lb/>quence of events that it is first in A, then not in (A∪B), <lb/>and finally in B. In OPS, this sequence is described with <lb/>a SequentialEnsemble object, which provides a flex-<lb/>ible way to implement arbitrarily complex path ensem-<lb/>bles (see Ref. [ ]). <lb/>Despite this powerful toolkit and the fundamental <lb/>role of the Ensemble, under most circumstances <lb/>the user does not need to instantiate Ensemble ob-<lb/>jects. Instead, they are automatically created by the <lb/>Transition and Network objects, described below. <lb/>• A Transition object contains all information for <lb/>studying a single-direction reaction connecting a spe-<lb/>cific initial state and a specific final state, such as <lb/>A → B, and serves as an organizational structure for <lb/>systems with many states, where the number of possi-<lb/>ble transitions grows as N (N −1) for N states. For TPS, <lb/>this object consists just of one ensemble, while for TIS <lb/>it usually consists of several interface path ensembles, <lb/>as well as the minus ensemble (used in RETIS). Note <lb/>that A → B and B → A are two di erent transitions, <lb/>each with their own sets of ensembles, thus requiring <lb/>two Transition objects. A single rate k would be as-<lb/>sociated with each Transition and k A→B = k B→A . <lb/>• A TransitionNetwork object (which we will fre-<lb/>quently refer to as simply the &quot;network&quot;) consists <lb/>of a set of Transitions. Since OPS is designed <lb/>to handle the systems with many states, the net-<lb/>work gathers all the transitions into one object. It <lb/>is a network in the graph theory sense: states are <lb/>nodes; reactions (transitions) are directed edges. Sub-<lb/>classes of TransitionNetwork, such as TPSNetwork <lb/>or MSTISNetwork, deal with specific approaches to <lb/>sample the network. All the ensembles to be sampled <lb/>are contained in the TransitionNetwork. Section V D <lb/>provides more details. <lb/>• PathMovers, or &quot;movers,&quot; perform Monte Carlo moves <lb/>in path space, such as shooting, reversal, minus, or <lb/>replica exchange. They are organized into a move deci-<lb/>sion tree, which selects the specific move to use (the <lb/>move type and the ensemble). An example of a move <lb/>decision tree is given in Fig. . The Ensemble associ-<lb/>ated with a given mover determines whether a trajec-<lb/>tory is in the path harvest for that mover, but the mover <lb/>itself can reject paths such that the correct statistics <lb/>for the path ensemble are obeyed (i.e., to preserve de-<lb/>tailed balance.) PathMovers are discussed in more <lb/>detail in section V E . <lb/>• The MoveScheme contains and builds the move <lb/>decision tree, which in turn contains all the <lb/>PathMovers available to a simulation. <lb/>The <lb/>MoveScheme is created by associating several <lb/>MoveStrategy objects with it. Each MoveStrategy <lb/>builds several related PathMovers. For example, a <lb/>NearestNeighborReplicaExchangeStrategy will <lb/>create a ReplicaExchangeMover for each pair of <lb/>nearest-neighbor ensembles in each Transition <lb/>from the TransitionNetwork. Options for creating <lb/>the strategy can control which ensembles are used, <lb/>and whether this adds to or replaces existing strate-<lb/>gies. This provides the user a great deal of flexibility <lb/>when customizing the move decision tree using the <lb/>numpy, scipy, pandas, netcdf <lb/>CVs <lb/>Engines <lb/>NetCDF+ <lb/>Volumes &amp; <lb/>Ensembles <lb/>Path Movers <lb/>Networks <lb/>Schemes &amp; <lb/>Strategies <lb/>generic <lb/>specific <lb/>Storage <lb/>FIG. 4. The modules of OPS can be separated into di erent <lb/>layers of abstraction. The layers can be considered as both increas-<lb/>ing specificity of purpose (from bottom to top) as well as increasing <lb/>ease of use or ease of implementation of new subclasses. Under-<lb/>neath the OPS modules the are external packages upon which OPS <lb/>is built. Above that are OPS modules which have potential for use <lb/>outside the context of reaction dynamics and path sampling. Above <lb/>that the code becomes more specific to path sampling, and to the <lb/>OpenPathSampling project. At the top layer, some of the more pow-<lb/>erful OPS libraries are abstracted into a more simple user interface. <lb/>The level of user that is likely to spend significant time working at <lb/>each level is indicated on the le . <lb/>MoveScheme and MoveStrategy objects. For simplic-<lb/>ity, OPS provides a DefaultScheme with reasonable <lb/>defaults for TIS (one-way shooting, nearest-neighbor <lb/>replica exchange, path reversal, and minus move), and <lb/>a OneWayShootingMoveScheme with a reasonable <lb/>default for TPS. The MoveScheme and MoveStrategy <lb/>objects will be discussed in more detail in section V E . <lb/>C. Layers of abstraction in OPS <lb/>OPS is structured as a set of Python modules, organized <lb/>according to major classes. As a library, users can interact <lb/>with di erent levels of abstraction. Fig. and the previous <lb/>section have already indicated how TransitionNetwork ob-<lb/>jects act as a more user-friendly layer for Ensembles, and <lb/>how MoveScheme and MoveStrategy objects create a sim-<lb/>pler layer for working with PathMovers. But these lower-<lb/>level objects can also be accessed by users, as will be dis-<lb/>cussed in the companion paper [ ]. <lb/>Objects like Ensembles and PathMovers are specific to <lb/>path sampling and related topics. These are built on even <lb/>more generic objects, which might be useful beyond the <lb/>scope of path sampling. Many PathMovers use the generic <lb/>DynamicsEngine wrapper to run the molecular dynamics. <lb/>
			Volumes are defined in terms of CollectiveVariables, <lb/>which have many uses beyond path sampling. The specific <lb/>OPS Storage class is based on more generic NetCDFPlus <lb/>subpackage, built for OPS. This is shown in Fig. , where <lb/>lower levels are more generic, while higher levels are more <lb/>specific to path sampling. Higher levels also tend to be more <lb/>user friendly. <lb/>V. OPS WORKFLOW <lb/>In this section we give an overview of the process for set-<lb/>ting up and running a path sampling simulation with Open-<lb/>PathSampling, including some general discussion on prac-<lb/>tical aspects of path sampling simulations. In general, ev-<lb/>ery path sampling simulation can be split into the following <lb/>steps: <lb/>. Setting up the molecular dynamics engine <lb/>. Defining states and interfaces <lb/>. Setting up the transition network and move scheme <lb/>. Obtaining initial pathways <lb/>. Equilibration and running the simulation <lb/>. Analyzing the results <lb/>In practice, the human e ort in path sampling using OPS <lb/>will focus on defining the states and interfaces, obtaining <lb/>trajectories for initial conditions, and analyzing the simula-<lb/>tion results. OPS aims to facilitate those steps and automate <lb/>what it can, such as setting up the TransitionNetworks and <lb/>MoveSchemes, and running the simulation. In addition, OPS <lb/>provides many tools for the analysis of the simulation results. <lb/>In the first setup steps ( -), the user chooses the dynam-<lb/>ics of interest and decides on the DynamicsEngine, the <lb/>CollectiveVariables, defines the Volumes for the states <lb/>and interfaces, as well as the topology of the reaction net-<lb/>work, and decides on the sampling MoveScheme. Fig ren-<lb/>ders these steps from the top down. Selecting relevant col-<lb/>lective variables and using them to define state volumes is of <lb/>critical importance, but is also dependent on the system be-<lb/>ing studied. We assume that a user is already familiar enough <lb/>with the system to make reasonable choices for these. <lb/>The specific definition of the transition network is handled <lb/>in OPS by a TransitionNetwork object, which automates <lb/>the creation of Transitions and Ensembles for common <lb/>variants of TPS (including multiple state) and TIS (including <lb/>multiple state and multiple interface set variants). These <lb/>objects take as input the Volume based states and interfaces <lb/>definitions. <lb/>The MoveScheme is created based on the <lb/>TransitionNetwork and a DynamicsEngine. It can <lb/>be customized by adding additional MoveStrategy objects, <lb/>but OPS provides default schemes for convenience. The <lb/>MoveScheme and its accompanying MoveStrategy objects <lb/>create all the PathMovers. Each PathMover knows on which <lb/>ensemble(s) it acts, and are organized into a total move <lb/>decision tree. <lb/>The final initialization step is to create an initial SampleSet <lb/>by loading valid preexisting initial trajectories into each of <lb/>the ensembles. See Appendix A for several approaches to <lb/>obtain initial conditions. <lb/>The simulation is performed by a PathSimulator ob-<lb/>ject. Path sampling simulations use a subclass called <lb/>PathSampling. Other subclasses of the PathSimulator <lb/>include CommittorSimulation for calculating committors <lb/>and DirectSimulation for calculating rates and fluxes via <lb/>direct MD. All PathSimulator objects take a Storage ob-<lb/>ject as input, to determine where to save data. In addi-<lb/>tion, PathSampling takes the MoveScheme and the initial <lb/>SampleSet as input. <lb/>Analysis is done independently from the sampling and re-<lb/>quires only the Storage and TransitionNetwork for the <lb/>computing observables, and additionally the MoveScheme <lb/>for the sampling statistics. Everything that is needed <lb/>for analysis is stored in the output file, including the <lb/>TransitionNetwork and MoveScheme. <lb/>In the next subsections we discuss these six steps in more <lb/>detail. <lb/>A. Step : Setting up the molecular dynamics <lb/>Of course, before embarking on a path sampling simula-<lb/>tion, one must decide on the system to simulate, and the <lb/>nature of the underlying dynamics (i.e., the thermodynamic <lb/>ensemble represented, the integrator used for the dynamics, <lb/>the force field to define interactions, etc.) OPS is designed to <lb/>wrap around other engines to take advantage of the flexibility <lb/>already built into other so ware. Currently, OPS supports <lb/>OpenMM [ ] as well as its own internal dynamics engine <lb/>intended mostly for D toy models. <lb/>The basic Engine takes general OPS specific options defin-<lb/>ing, e.g., handling of failing simulations, maximal trajectory <lb/>length, etc, as well as dimensions used in snapshots that <lb/>the engine generates (e.g., number of atoms). Each specific <lb/>engine also carries information necessary for it to setup a <lb/>simulation. In case of OpenMM this includes a description <lb/>of the Integrator, the System object (force field, etc.), the <lb/>systems Topology and some OpenMM specific options (e.g., <lb/>hardware platform and numerical precision). <lb/>B. Step : Defining states and interfaces <lb/>The ensembles used in path sampling methods require <lb/>definitions of (meta)stable states and, in the case of transition <lb/>interface sampling, interfaces connecting these states. OPS <lb/>implements both states and interfaces in terms of Volume <lb/>objects. <lb/>The main types of volume objects are the <lb/>CVDefinedVolume, <lb/>and <lb/>its <lb/>periodic <lb/>version, <lb/>PeriodicCVDefinedVolume. Each of these defines a vol-<lb/>ume in phase space based on some CollectiveVariable. <lb/>This could include such quantities as atom-atom dis-<lb/>tances, dihedral angles, RMSD from a given reference <lb/>frame, number of contacts, etc. The user must first de-<lb/>fine a CollectiveVariable object, either as a wrapper <lb/>around functions from other so ware packages (some <lb/>examples below use MDTrajFunctionCV, which wraps <lb/>MDTraj analysis function), or around a user-written function <lb/>(other examples will show the use of the more general <lb/>CoordinateFunctionCV). <lb/>Using the CollectiveVariable we have a clear sepera-<lb/>tion between the full simulation data and what we consider <lb/>relevant for state definitions and later analysis. This sepera-<lb/>tion allows us to later run analysis without the need to load <lb/>a single frame, and to store a reduced set without the actual <lb/>coordinates. <lb/>To define a volume, the user must also specify minimum <lb/>and maximum values for the CV. The volumes can then <lb/>be created with, e.g., CVDefinedVolume(cv, minimum, <lb/>maximum), which defines a frame as being inside the vol-<lb/>ume if minimum ≤ cv(frame) &lt; maximum. Volumes can <lb/>be combined using the same set operation as Python sets: <lb/>&amp;(intersection), | (union), -(relative complement), ˆ(sym-<lb/>metric di erence), and ˜(complement). Volume combina-<lb/>tions of the same collective variable are automatically sim-<lb/>plified when they can be recognized [e.g., (0 ≤ x &lt; 5)&amp;(3 ≤ <lb/>x &lt; 8) becomes 3 ≤ x &lt; 5]. The ability to arbitrarily com-<lb/>bine volumes allows one to define arbitrary states, e.g., &quot;this <lb/>hydrogen bond is formed and this dihedral is near a certain <lb/>value.&quot; This provides OPS with powerful flexibility. <lb/>C. Step : Setting up the transition network and move <lb/>scheme <lb/>The transition network (path ensembles) and the move <lb/>scheme (Monte Carlo moves) can be thought of as what to <lb/>sample, and how to sample, respectively. <lb/>For complex TIS simulations, the number of path en-<lb/>sembles to be sampled can grow into the hundreds. <lb/>TransitionNetwork objects e iciently create those ensem-<lb/>bles according to standard ways of organizing, and facilitate <lb/>later analysis. The examples in Sec. VI will demonstrate the <lb/>four main kinds of network objects: TPSNetwork for flexible-<lb/>length TPS, FixedLengthTPSNetwork for fixed-length TPS, <lb/>MSTISNetwork for multiple-state TIS, and MISTISNetwork <lb/>for TIS and multiple interface set TIS. <lb/>The MoveScheme creates and organizes the possible Monte <lb/>Carlo moves, as appropriate for a given transition net-<lb/>work. As with the transition networks, the MoveScheme <lb/>object also facilitates later analysis. The examples in sec-<lb/>tion VI will go over the simplest default move schemes <lb/>(OneWayShootingMoveScheme for TPS; DefaultScheme for <lb/>TIS). However, the move scheme is very customizable, as will <lb/>be elaborated on in the companion paper [ ]. <lb/>As both the TransitionNetwork and MoveScheme are <lb/>crucial in OPS, we devote extra attention to these objects <lb/>below. <lb/>D. Step a: Transition networks <lb/>The TransitionNetwork object contains all the path <lb/>ensembles to be sampled for the reaction network of in-<lb/>terest. To simplify analysis, most ensembles are grouped <lb/>into Transition objects, which describe a single transi-<lb/>tion within the network. There are also special ensembles <lb/>(e.g., ensembles associated with multiple state interfaces <lb/>Network and Initialization <lb/>Transitions <lb/>Sampling <lb/>Transitions <lb/>Sampling <lb/>Ensembles <lb/>TPSNetwork: <lb/>A, B <lb/>1 <lb/>1 <lb/>1 <lb/>[A, B], [B, C] <lb/>3 <lb/>1 <lb/>1 <lb/>[A, B, ..., N], [A, B, ..., N] <lb/>N (N − 1) <lb/>1 <lb/>1 <lb/>MSTISNetwork: <lb/>[(A, mA), (B, mB)] <lb/>2 <lb/>2 <lb/>mA + mB <lb/>[(A, mA), (B, mB), ..., (N, mN)] <lb/>N (N − 1) <lb/>N <lb/>I mI <lb/>MISTISNetwork: <lb/>[(A, mAB, B)] <lb/>1 <lb/>1 <lb/>mAB <lb/>[(A, mAB, B) (A, mAC, C), ..., (A, mAN, N)] N − 1 <lb/>N − 1 <lb/>J =A mAJ <lb/>[(A, mAB, B), ..., (A, mAN, N), ... <lb/>..., (N, mNA, A)] <lb/>N (N − 1) N (N − 1) <lb/>I <lb/>J =I mIJ <lb/>TABLE I. Predefined network types and the number of (physical) transitions, sampling transitions, and sampling ensembles aris-<lb/>ing from di erent initialization parameters. Volumes are represented with capital letters (e.g., A or B) and interface sets are represented <lb/>as mA for the interfaces leaving A in MSTIS, or mAB for interfaces leaving A toward B in MISTIS. The number of interfaces in an interface set is <lb/>given by mA or mAB, respectively. The total number of states is assumed to be N (with the final state represented by N). <lb/>or with minus interfaces) which may not be specific to a <lb/>single transition, and are only associated with the network <lb/>as a whole. In general, the user only needs to create the <lb/>TransitionNetwork object, which will automatically cre-<lb/>ate the relevant Transitions and Ensembles. The simplest <lb/>transition network contains a single transition, the one-way <lb/>A → B. A bidirectional network A ↔ B is thus character-<lb/>ized by two transitions, each associated with its own set of <lb/>ensembles. <lb/>Each network involves two groupings of transitions: the <lb/>sampling transitions and the physical transitions. MSTIS <lb/>shows a clear example of the distinction between these: <lb/>while sampling, the transitions studied are A → (B ∪ <lb/>C), B → (A ∪ C), and C → (A ∪ B). However, in <lb/>analysis we obtain the rates for all the individual physi-<lb/>cal transitions A → B, A → C, B → A, B → C, <lb/>C → A, and C → B. For a network with N states, <lb/>up to N (N − 1) unique physical transitions are possible. <lb/>The sampling transitions are found in a list, accessed as <lb/>network.sampling_transitions, and the physical transi-<lb/>tions are in a dict, with state pairs (initial, final) as <lb/>keys, and the associated Transition object as value. <lb/>The Transition and the TransitionNetwork objects <lb/>depend on the type of simulation that is intended, just as the <lb/>Ensemble does. Table I shows how di erent input parame-<lb/>ters create di erent numbers of physical and sampling tran-<lb/>sitions for the built-in network objects in OPS. The network <lb/>for a TPS simulation is made with either the TPSNetwork or <lb/>FixedLengthTPSNetwork objects. The TPSNetwork is ini-<lb/>tialized with a list of initial states and a list of final states; <lb/>all pairs of (non-self) transitions are generated internally. A <lb/>TPSNetwork has only one sampling TPSTransition, which <lb/>has only one ensemble. However, for analysis the network <lb/>includes ensembles for every possible physical transition. If <lb/>A is the only initial state and B is the only final state, then <lb/>A → B is the only physical transition. When multiple initial <lb/>and final states are given, then all the non-self physical transi-<lb/>tions are allowed: in the second line of Table I, that would be <lb/>A → B, A → C, and B → C. When all N states are given as <lb/>both initial and final states, all N (N − 1) non-self transitions <lb/>are included. The FixedLengthTPSNetwork is exactly like <lb/>the TPSNetwork, except that its initialization also requires <lb/>the length of the path (in snapshots). <lb/>Within standard TPS approaches, there is a one-to-one <lb/>correspondence of (sampling) ensemble to network. That <lb/>makes these networks relatively simple. The situation be-<lb/>comes more complicated with TIS. In TIS, each transition <lb/>involves a set of interface ensembles. In addition, there are <lb/>the minus ensembles, which (in MISTIS) can be associated <lb/>with more than one transition, and there are the multiple <lb/>state outer ensembles (in MSTIS and MISTIS), which are also <lb/>associated with more than one transition. <lb/>The MSTISNetwork and MISTISNetwork are initialized <lb/>with specific data about the transitions. In MSTIS, this in-<lb/>cludes the initial states and the interface sets associated with <lb/>them, provided as a list of tuples. The MSTISNetwork cre-<lb/>ates sampling ensembles that allow paths that end in any <lb/>state, and always samples all transitions between all states. <lb/>As shown in Table I, it therefore always has N (N − 1) physi-<lb/>cal transitions and N sampling transitions for N input states. <lb/>The number of ensembles depends on the number of ensem-<lb/>bles per interface set, but scales linearly with the number of <lb/>states. <lb/>In addition to the initial states and the interface sets, <lb/>
			MISTISNetwork also requires the ending state for each tran-<lb/>sition, provided as a third item in each tuple. The number of <lb/>physical transitions for the MISTISNetwork is always equal <lb/>to the number of sampling transitions, and the number of <lb/>ensembles grows with the number of sampling transitions. <lb/>This means that, in the worst case of sampling all possible <lb/>transitions, the number of ensembles scales quadratically <lb/>with the number of states. However, MISTIS has the advan-<lb/>tage that it allows one to select only specific transitions of <lb/>interest, or to use di erent interface sets for transitions be-<lb/>ginning in the same initial state, allowing each transition to <lb/>be sampled more e iciently. <lb/>Both of these TIS networks automatically create appro-<lb/>priate minus interface ensembles, and they can optionally <lb/>take an MSOuterTISInterface for the multiple state (MS) <lb/>outer interface ensemble. The MS-outer ensemble is the <lb/>union of several TIS ensembles starting from di erent initial <lb/>states [ , ]. Whereas a TIS ensemble only allows trajec-<lb/>tories that begin in a single given initial state, the MS-outer <lb/>ensemble allows trajectories that begin in any of multiple ini-<lb/>tial states. This ensemble, combined with replica exchange, <lb/>facilitates decorrelation of trajectories. <lb/>MSTIS and MISTIS are two di erent ways to create ensem-<lb/>bles to study a reaction network. The MSTIS approach is <lb/>more e icient when all transitions from the same state are de-<lb/>scribed by the same order parameter. The MISTIS approach <lb/>allows more flexibility in sampling, by allowing di erent tran-<lb/>sitions from an initial state to use di erent order parameters <lb/>or selection of specific transitions of interest. <lb/>The simplest network, A → B, can be studied using <lb/>the MISTISNetwork object. The bidirectional A ↔ B net-<lb/>work can be studied using either a MISTISNetwork or a <lb/>MSTISNetwork: the ensembles which are created would be <lb/>indistinguishable. <lb/>These networks are not exhaustive, and other possibilities <lb/>might be implemented by users. For example, it might be <lb/>interesting to sample transitions from one state to all other <lb/>states in an MSTIS simulation. This cannot be done with the <lb/>built-in MSTISNetwork, but it would be relatively straight-<lb/>forward to create another subclass of TransitionNetwork <lb/>that allows this. <lb/>E. Step b: The Monte Carlo Move Scheme <lb/>. Path movers <lb/>In OPS, each PathMover instance is connected to specific <lb/>ensembles. For example, there is a separate shooting mover <lb/>for each ensemble, and a separate replica exchange mover <lb/>for each pair of ensembles that are allowed to swap in replica <lb/>exchange. The move method of the PathMover object actu-<lb/>ally performs the Monte Carlo move. It takes a SampleSet as <lb/>input, and returns a MoveChange, which the PathSimulator <lb/>applies to the original SampleSet in order to create the up-<lb/>dated SampleSet. <lb/>OPS includes a rich toolkit so that developers of new meth-<lb/>ods can create custom methods. Those toolkits are discussed <lb/>in detail in the companion paper [ ]. Here, we will introduce <lb/>some of the built-in path movers. <lb/>• Shooting movers: OPS has support for both one-<lb/>way (stochastic) shooting [ , ] as well as the two-<lb/>way shooting algorithm. These are implemented as <lb/>OneWayShootingMover and TwoWayShootingMover. <lb/>In addition to a specific ensemble, the shooting movers <lb/>require a ShootingPointSelector to choose the <lb/>shooting point. The most commonly used selector is <lb/>FIG. 5. Example of a transition network used in the MSTIS ala-<lb/>nine dipeptide examples (See Section VI) Multiple states A-D are <lb/>defined according to the dihedral angles ψ and φ. THe core sets for <lb/>A-D are defined as being within degrees of the core center (indi-<lb/>cated by black dot). Each state has its own set of interfaces using <lb/>the geometric distance in ψ − φ space to the core center, indicated <lb/>by shadede circles. The MSTISNetwork object creates for each state <lb/>the collection of path ensembles for each interface, plus the minus <lb/>interface. In addition there is a multiple state union interface for <lb/>the outermost interfaces. The plus marks the location of the initial <lb/>conformation used in the example. <lb/>the UniformSelector, which selects any point except <lb/>the endpoints of the trajectory (which are in the de-<lb/>fined states) with equal probability. Other possibilities <lb/>could also be implemented, such as using a Gaussian <lb/>distribution [ ] or a distribution constrained to the in-<lb/>terface [ ]. The TwoWayShootingMover also requires <lb/>a SnapshotModifier to change the snapshot in some <lb/>way (e.g., modifying the velocities). Several possibili-<lb/>ties exist, including either changing the direction of the <lb/>velocity for some atoms, or completely randomizing <lb/>velocities according to the Boltzmann distribution. <lb/>• Path reversal mover: Another standard mover is the <lb/>PathReversal mover, which takes the current path in <lb/>the ensemble and tries to reverse its time direction. For <lb/>a path that leaves and returns to the same stable state <lb/>this move is always accepted. As stated in Sec. II C, this <lb/>move helps to decorrelate the sampled trajectories. <lb/>• Replica Exchange mover: A ReplicaExchangeMover <lb/>involves two ensembles (see Fig. ). When a move is <lb/>attempted, the mover takes the paths associated with <lb/>these ensembles in the current sample set, and tries to <lb/>exchange them. This trial move will be accepted if both <lb/>paths are valid paths in their respective ensembles. <lb/>• Minus mover: The MinusMover is a more complicated <lb/>PathMover. In essence, it combines replica exchange <lb/>with extension of the trajectory. OPS has a toolkit to <lb/>simplify the creation of more complicated moves from <lb/>simpler ones, which is be discussed in more detail in <lb/>the companion paper. The MinusMover uses both the <lb/>minus interface ensemble and the innermost normal <lb/>TIS ensemble. It extends the trajectory from the inner-<lb/>most ensemble until it again recrosses the interface <lb/>and returns to the stable state, resulting in a trajectory <lb/>with two subtrajectories that satisfy the innermost TIS <lb/>ensemble. This trajectory satisfies the minus ensem-<lb/>ble. The trajectory that had previously been associated <lb/>with the minus ensemble also has two subtrajectories <lb/>that satisfy the innermost TIS ensemble, and one of <lb/>them is selected. A er the move, the newly extended <lb/>trajectory is associated with the minus ensemble, and <lb/>the selected subtrajectory is associated with the inner-<lb/>most TIS ensemble. <lb/>. The MoveScheme and MoveStrategy <lb/>The MoveScheme creates and contains the move decision <lb/>tree, which is essentially the protocol for the simulation. <lb/>Fig. shows a graphical representation of the decision tree <lb/>created by a simple MoveScheme. The decision tree contains <lb/>the di erent choices of move type (e.g. shooting, reversal, <lb/>replica exchange) and assigns specified weights to them. At <lb/>the leaves of the tree are path movers. Each path mover acts <lb/>on a certain ensemble (shown on the right of Fig. ). <lb/>The MoveScheme object organizes the path movers in sev-<lb/>eral mover groups, held in a dictionary called movers, with <lb/>strings as keys and a list of PathMovers are values. Each <lb/>group corresponds to a related set of movers (which are used <lb/>on di erent ensembles). For example, the default shooting <lb/>movers are in the group &apos;shooting&apos; and the default replica <lb/>exchange movers are in the group &apos;repex&apos;. <lb/>The <lb/>most <lb/>common <lb/>MoveScheme <lb/>objects <lb/>are the DefaultScheme (for TIS) and the <lb/>OneWayShootingMoveScheme (for TPS). All move <lb/>schemes require a network; DefaultScheme and <lb/>OneWayShootingMoveScheme also require an engine. <lb/>The move decision tree can also be generated by hand, and <lb/>then given as input to a LockedMoveScheme, although some <lb/>additional information (such as the choice_probability, <lb/>a dictionary mapping each path mover to its relative <lb/>probability of being selected) must be manually added <lb/>to a LockedMoveScheme for some analysis to work. Fur-<lb/>thermore, a LockedMoveScheme cannot by modified using <lb/>MoveStrategy objects. <lb/>In general, the easiest way to customize the <lb/>move scheme is to start with a DefaultScheme or a <lb/>OneWayShootingMoveScheme, and then append strategies <lb/>that give the desired behavior. The whole scheme is built <lb/>by applying the MoveStrategy objects in sequence. Each <lb/>subclass of MoveStrategy has a priority level associated <lb/>with it, and the strategies are built in an order sorted first <lb/>by that priority level, and second by the order in which <lb/>RootMover <lb/>RepexChooser <lb/>ReplicaExchange <lb/>ReplicaExchange <lb/>ShootingChooser <lb/>OneWayShootingMover A-&gt;B 0 <lb/>ForwardShoot <lb/>BackwardShoot <lb/>OneWayShootingMover A-&gt;B 2 <lb/>ForwardShoot <lb/>BackwardShoot <lb/>OneWayShootingMover A-&gt;B 1 <lb/>ForwardShoot <lb/>BackwardShoot <lb/>MinusChooser <lb/>Minus <lb/>PathreversalChooser <lb/>PathReversal <lb/>PathReversal <lb/>PathReversal <lb/>[A] A-&gt;B 0 <lb/>[B] A-&gt;B 1 <lb/>[C] A-&gt;B 2 <lb/>[D] A MIS minus <lb/>A <lb/>B <lb/>C <lb/>D <lb/>A <lb/>B <lb/>C <lb/>A <lb/>B <lb/>B <lb/>C <lb/>A <lb/>B <lb/>C <lb/>A <lb/>A <lb/>A <lb/>C <lb/>C <lb/>C <lb/>B <lb/>B <lb/>B <lb/>A <lb/>D <lb/>A <lb/>D <lb/>A <lb/>B <lb/>C <lb/>B <lb/>C <lb/>A <lb/>FIG. 6. Schematic representation of the decision tree as con-<lb/>structed by the MoveScheme object. Shown is an example for <lb/>RETIS. The MoveScheme points to the root of this tree (le ). The <lb/>branches are the di erent move levels. First level is the decision <lb/>about what type of move: shooting, replica, reversal. Next level <lb/>is the decision about what ensemble needs to be moved. For <lb/>the shooting, the next level is about which direction the shot is. <lb/>For other moves the choice is slightly di erent. The right part <lb/>of the picture show which ensembles are a ected. Each vertical <lb/>line denotes an ensemble. At the root of the tree each ensemble <lb/>can be chosen. Going down the tree, the ensembles a ected re-<lb/>duce in number. The letters are arbitrary labels for each ensem-<lb/>ble. The grey box around each letter show the input (red) and the <lb/>output (blue). This sort of schematic can be generated using the <lb/>paths.visualize.MoveTreeBuilder object. <lb/>they were appended to the scheme (so later additions can <lb/>override earlier versions). Several aspects of the way a <lb/>MoveStrategy contributes to the move decision tree can be <lb/>set in its initialization: which ensembles the strategy applies <lb/>to, which mover group the strategy is for, and whether <lb/>to replace the e ects of previous strategies. Additionally, <lb/>mover-specific parameters (such as shooting point selector <lb/>for shooting moves) are passed along to the movers that are <lb/>constructed by the strategy. <lb/>This allows one to, for example, add a shooting move of <lb/>a di erent type (e.g., two-way instead of one-way, or using <lb/>a di erent shooting point selection algorithm) for a specific <lb/>ensemble -either overriding the original mover or adding a <lb/>second &quot;group&quot; of shooting movers (with a di erent name, <lb/>e.g., &apos;shooting2&apos; so as not to conflict with the existing <lb/>&apos;shooting&apos;). One might do this so that there are two kinds <lb/>of shooting moves: one which causes large decorrelations in <lb/>path space (but might have lower acceptance) and one that <lb/>has a better acceptance probability. <lb/>F. Step : Obtaining initial conditions <lb/>
			The initial conditions for a path sampling simulation con-<lb/>sist of a SampleSet with at least one Sample for any possible <lb/>initial move. As discussed above, each Sample consists of a <lb/>trajectory, the ensemble for that trajectory, and a replica ID. <lb/>Preparing the initial sample set thus breaks down into two <lb/>parts: ( ) creating the initial trajectories; ( ) assigning them <lb/>to appropriate ensembles and giving them individual replica <lb/>IDs. <lb/>The first part, obtaining initial trajectory from the path <lb/>ensemble, is in general non-trivial since the events we are <lb/>interested in are rare, and the best approach is likely to be <lb/>system specific. We discuss several possible approaches in <lb/>detail in Appendix A. <lb/>The second part is much easier. Once we have trajectories, <lb/>scheme.initial_conditions_from_trajectories will <lb/>take those trajectories and create appropriate initial condi-<lb/>tions for the move scheme called scheme. This method at-<lb/>tempts to create a sample for every ensemble required by the <lb/>move scheme by checking if the given trajectories (or subtra-<lb/>jectories of them) or their time-reversed versions satisfy the <lb/>ensemble. Internally, this uses the ability of the Ensemble <lb/>object to test whether a trajectory (or subtrajectory thereof) <lb/>satisfies the ensemble. <lb/>For <lb/>some <lb/>ensembles, <lb/>such <lb/>as <lb/>the <lb/>mi-<lb/>nus <lb/>interface <lb/>ensemble, <lb/>the <lb/>method <lb/>extend_sample_from_trajectories has been im-<lb/>plemented, which runs dynamics to create a trajectory that <lb/>satisfies the ensemble, starting from input subtrajectories. <lb/>Last, the move scheme method MoveScheme. <lb/>assert_initial_conditions can be used to check if a <lb/>given set of initial conditions contains all Samples needed <lb/>to run the simulation, and raises an AssertionError if not. <lb/>G. Step : Equilibration and running the simulation <lb/>As with other simulation techniques, such as molecular <lb/>dynamics and configurational Monte Carlo, the equilibra-<lb/>tion process for path sampling is o en just a shorter ver-<lb/>sion of the production run. Both equilibration and produc-<lb/>tion require creating a PathSimulator object, which cre-<lb/>ate the runnable simulation. The examples here focus on <lb/>PathSampling, but other subclasses of PathSimulator in-<lb/>clude CommittorSimulation and DirectSimulation (for <lb/>rates and fluxes). The PathSampling simulator is initialized <lb/>with a storage file, a move scheme, and initial conditions. It <lb/>has a run method which takes the number of MC trial steps <lb/>to run. All the simulation and storage to disk is done auto-<lb/>matically. <lb/>H. Step : Analyzing the results <lb/>OPS has many built-in analysis tools, and users could cre-<lb/>ate a wide variety of custom analyses: the companion paper <lb/>includes several examples [ ]. However, nearly all analysis <lb/>of path sampling falls into two categories: either the analysis <lb/>provides information about the ensemble that is sampled <lb/>(o en tied to observables such as the rate) or the analysis <lb/>provides information about the sampling process itself. Both <lb/>analysis types are extremely important -poor behavior of <lb/>the sampling process would indicate low confidence in the <lb/>calculated observable. And, of course, combining insights <lb/>from both can yield understanding of the physical process <lb/>under study. The basic use of OPS analysis tools to calculate <lb/>rates from MSTIS and MISTIS simulations and mechanistic <lb/>information (path densities) from TPS simulations, as well as <lb/>properties of the sampling process such as the replica history <lb/>tree (a generalization of the &quot;TPS move tree&quot; in existing liter-<lb/>ature), measures of mover acceptance ratios, and measures <lb/>of the replica exchange network and its e iciency, will be <lb/>illustrated in the following examples. <lb/>VI. ILLUSTRATIVE EXAMPLES <lb/>In this section, we give and discuss several examples. <lb/>These examples are meant to show the user how to set up, <lb/>run, and analyze several basic applications of TPS, MSTIS, and <lb/>MISTIS. In the examples, the following set of initial imports is <lb/>assumed: <lb/>import openpathsampling as paths <lb/>import openpathsampling.engines.openmm as omm <lb/>import openpathsampling.engines.toys as toys <lb/>import openpathsampling.visualization as vis <lb/>import numpy as np <lb/>import matplotlib.pyplot as plt <lb/>import mdtraj as md <lb/>These imports load the required modules, notably the OPS <lb/>modules, but also modules such as MDTraj [ ], OpenMM [ ], <lb/>the toy dynamics, and the Python plotting modules. We note <lb/>that the explicit code given in this section is for illustrative pur-<lb/>poses only, and refers to the . release. Up-to-date versions <lb/>of the examples are available as interactive Jupyter note-<lb/>books on the website http://openpathsampling.org. <lb/>A. TPS on alanine dipeptide <lb/>This example illustrates details about setting up transition <lb/>path sampling calculations, both with fixed and flexible path <lb/>length ensembles. This example and the next consider ala-<lb/>nine dipeptide (AD) in explicit TIP P [ ] water, using the <lb/>AMBER [ ] force field to enable comparison to some pre-<lb/>vious work [ , ]. This model has been widely used as a <lb/>biomolecular test system for rare events methods. We use a <lb/>VVVR-Langevin integrator at 300K[ ], with a fs timestep <lb/>and a collision rate of ps −1 . The long ranged interactions <lb/>were treated with PME with a cuto of nm. The AD molecule <lb/>was solvated with <lb/>water molecular in a cubic box, and <lb/>equilibrated at constant pressure of atm using a Monte Carlo <lb/>barostat. A erwards the box size was set to the average value <lb/>of . Å as obtained in the NPT run. All subsequent simu-<lb/>lations were done in the NVT ensemble. <lb/>While the example is based on the explicit solvent calcu-<lb/>lations by Bolhuis, Dellago, and Chandler [ ], we di er in <lb/>several details, including our choice of force field and the <lb/>details of our ensembles: Ref. used a shorter fixed-length <lb/>TPS ensemble, whereas we use both a flexible-length TPS <lb/>ensemble and an ps fixed-length TPS ensemble. <lb/>. Setting up the molecular dynamics <lb/>We use OpenMM to set up an MD engine for the AD <lb/>system. The OpenMM-based OPS engine is essentially a <lb/>wrapper for the OpenMM Simulation object. As with the <lb/>OpenMM Simulation, it requires an OpenMM System, and <lb/>an OpenMM Integrator. The interactive OpenMM simula-<lb/>tion builder tool [http://builder.openmm.org/] allows <lb/>us construct an appropriate System and Integrator. In ad-<lb/>dition, the OpenMM Simulation takes a properties dictio-<lb/>nary, which we must define. <lb/>To build the OPS engine, we also need to fill an options <lb/>dictionary with some OPS-specific and OpenMM-specific en-<lb/>tries. All OPS engines should define nsteps_per_frame, <lb/>
			the number of time steps per saved trajectory frame, and <lb/>n_frames_max, an absolute maximum trajectory length. For <lb/>the alanine dipeptide examples, we save every fs ( steps) <lb/>and abort the trajectory if it reaches ps: <lb/>options = {&apos;n_steps_per_frame&apos;: 10, <lb/>&apos;n_frames_max&apos;: 2000} <lb/>A er creating the the OpenMM system, the OpenMM in-<lb/>tegrator, the OpenMM properties dictionary, and the OPS <lb/>options dictionary, all of these can be combined to create on <lb/>OpenMM-based OPS engine: <lb/>engine = omm.Engine(snapshot.topology, system, integrator, <lb/>properties, options).named(&quot;AD_engine&quot;) <lb/>where the snapshot is loaded from the PDB with <lb/>omm.snapshot_from_pdb(&quot;file.pdb&quot;). <lb/>This com-<lb/>mand also associates a name with the engine, which make it <lb/>easier to reload from storage for re-use. <lb/>. Defining states and interfaces <lb/>The collective variables of interest for alanine dipeptide <lb/>are the backbone φ and ψ dihedrals. To create a collective <lb/>variable for these angles, we use our wrapper around MD-<lb/>Traj&apos;s compute_dihedrals function: <lb/>psi = paths.MDTrajFunctionCV(&quot;psi&quot;, md.compute_dihedrals, <lb/>snapshot.topology, indices=[[6, 8, 14, 16]]) <lb/>The φ angle is defined similarly, consisting of the atoms with <lb/>indices 4, 6, 8, and 14. <lb/>MDTraj reports dihedral angles in radians. <lb/>The <lb/>MDTrajFunctionCV wrapper can wrap any function <lb/>that uses MDTraj; we use the simplest example here for <lb/>illustrative purposes. It would be straightforward to write <lb/>a Python function that converts this to degrees, and to use <lb/>that in place of md.compute_dihedrals; the AD MSTIS <lb/>example in section VI B uses a more complicated approach <lb/>to wrapping CVs. <lb/>In this example, we define two states, C 7eq and α R , simi-<lb/>larly to Ref. [ ]. Since we are using a di erent force field, we <lb/>use slightly di erent values for the ψ angles. Our state C 7eq <lb/>is defined (in degrees) by 180 ≤ φ &lt; 0 and 100 ≤ ψ &lt; 200 <lb/>(wrapped periodically), whereas α R is given by 180 ≤ φ &lt; 0 <lb/>and −100 ≤ ψ &lt; 0. To convert between degrees and radi-<lb/>ans, we define deg = np.pi/180. The code to define C 7eq <lb/>is, <lb/>C_7eq = (paths.PeriodicCVDefinedVolume(phi, <lb/>lambda_min=-180*deg, lambda_max=0*deg, <lb/>period_min=-180*deg, period_max=180*deg <lb/>) &amp; paths.PeriodicCVDefinedVolume(psi, <lb/>lambda_min=100*deg, lambda_max=200*deg, <lb/>period_min=-180*deg, period_max=180*deg <lb/>)).named(&quot;C_7eq&quot;) <lb/>and state α R can be coded accordingly. <lb/>For nonperiodic CVs, the equivalent form is <lb/>CVDefinedVolume, and it does not include the period_min <lb/>and period_max arguments. The periodic version allows <lb/>the C 7eq state to wrap across the periodic boundary in the <lb/>ψ variable: We define the state from 100 degrees to 200 <lb/>degrees, even though the function reports values between <lb/>−180 degrees and 180 degrees. We would get the exact <lb/>same behavior by setting lambda_max to −160 degrees. For <lb/>a TPS simulation, we only need to define the states -there <lb/>are no interfaces to define. <lb/>. Setting up the transition network and move scheme <lb/>The transition network creates and contains all the ensem-<lb/>bles to be sampled. In this case, there is only one ensemble. <lb/>Later examples will deal with sets of ensembles. The fixed <lb/>and flexible path length examples diverge here: the fixed <lb/>path length TPS simulation uses a fixed path length network <lb/>with path length <lb/>frames ( ps), created with <lb/>network = paths.FixedLengthTPSNetwork(C_7eq, <lb/>alpha_R, length=400) <lb/>For the flexible path length, which is better in practice, we <lb/>use: <lb/>network = paths.TPSNetwork(C_7eq, alpha_R) <lb/>This one line of code selects between the two approaches. <lb/>Multiple state TPS can be set up similarly. For instance, a mul-<lb/>tiple state TPS with states A, B, and C (allowing all transitions) <lb/>can be created by <lb/>paths.TPSNetwork.from_states_all_to_all([A, B, C]) <lb/>Next, we set up the move scheme. For the TPS simulations, <lb/>we only need a shooting move. This move scheme is created <lb/>with <lb/>scheme = paths.OneWayShootingMoveScheme(network, <lb/>selector=paths.UniformSelector(), engine=engine) <lb/>The selector defines how to choose the shooting <lb/>points, e.g., UniformSelector selects the points <lb/>uniformly. <lb/>Another option would be to use the <lb/>GaussianBiasSelector(lambda, alpha, l_0), which <lb/>takes the collective variable lambda and biases the shooting <lb/>point selection according to e −α(λ−l0) 2 , where l 0 is the <lb/>position of the maximum, and α determines the width of the <lb/>distribution [? ]. <lb/>. Obtaining initial conditions <lb/>We obtained an initial trajectory by running at high tem-<lb/>perature (T = 500 K) until both states had been visited. Ap-<lb/>pendix A provides details on this and other possible methods <lb/>to obtain initial trajectories. <lb/>We generate the trajectory for fixed length TPS by taking <lb/>the appropriate trajectory for flexible length TPS, adding <lb/>frames to either side, and using the fixed-length ensemble&apos;s <lb/>ensemble.split to select a segment of the appropriate <lb/>length and satisfying the requirements. <lb/>To assign this first trajectory to the ensemble <lb/>we will be sampling, we use the move scheme&apos;s <lb/>scheme.initial_conditions_from_trajectories <lb/>method. <lb/>. Equilibration and running the simulation <lb/>All OPS simulation details and simulation results are stored <lb/>in a single NetCDF storage file. The storage requires a <lb/>template snapshot to determine sizes of arrays to save per <lb/>snapshot. Before running the simulations, we need to create <lb/>a file to store our results in. A new file named tps_AD.nc can <lb/>be created with <lb/>storage = Storage(&quot;tps_AD.nc&quot;, mode=&quot;w&quot;, <lb/>template=template) <lb/>The PathSampling simulator object is created with <lb/>sim = paths.PathSampling( <lb/>storage=storage, <lb/>move_scheme=scheme, <lb/>sample_set=initial_conditions) <lb/>We can run the OPS simulation using <lb/>sim.run(n_steps) <lb/>with n_steps trial moves. We use , <lb/>steps for the TPS <lb/>examples. <lb/>In all molecular simulation approaches initial conditions <lb/>are unlikely to be representative for the equilibrium distri-<lb/>bution (e.g., one could start with the solvent molecules on a <lb/>grid, or with a high temperature snapshot), and equilibration <lb/>is usually required before one can take averages of observ-<lb/>ables. Likewise, we need to equilibrate the path sampling <lb/>before we can take statistics, when the initial trajectories <lb/>are not from the real dynamics (e.g., generated with meta-<lb/>dynamics or high-temperature simulation). As with MD and <lb/>MC approaches, the equilibration phase can be just a short <lb/>version of the production run. <lb/>. Analyzing the results <lb/>Analysis of a simulation is usually done separately from <lb/>running the simulation. The first step is to open the storage <lb/>file with the simulation results. <lb/>storage = paths.Storage(&quot;tps_AD.nc&quot;, mode=&quot;r&quot;) <lb/>will open a file for reading. <lb/>The tables of stored data objects are attributes of the <lb/>storage. To see the number of items stored, the stan-<lb/>dard Python len function can be used. For example, <lb/>len(storage.steps) gives the number of Monte Carlo <lb/>steps run (plus for the initial conditions). <lb/>The move scheme serves as the starting point for <lb/>much of the analysis. Since there is only one in stor-<lb/>age, we obtain the correct move scheme with scheme = <lb/>storage.schemes[0]. The command <lb/>scheme.move_summary(storage.steps) <lb/>returns a quick overview of the moves performed and infor-<lb/>mation on the acceptance ratios. Since our TPS move scheme <lb/>contained only one PathMover, all performed moves were <lb/>shooting moves. In this example, we find a % acceptance <lb/>ratio for flexible length TPS, and a % acceptance rate for <lb/>fixed length TPS. <lb/>As discussed in Sec. IV, every Monte Carlo step in the stor-<lb/>age consists of two main parts: the SampleSet of active sam-<lb/>ples, given by step.active, and the PathMoveChange with <lb/>details about the move, given by step.change. Typically, <lb/>analysis begins with a loop over steps, and then extracts <lb/>the relevant information. The first step (step ) corresponds <lb/>to the initial conditions. For example, a list of all the path <lb/>lengths (in frames) can be obtained with <lb/>path_lengths = [ <lb/>len(s.active[0].trajectory) for s in storage.steps] <lb/>which loops over each MC step in storage.steps, and <lb/>takes the length of the trajectory associated with replica <lb/>ID 0 in the active sample set. For TPS, this is the only <lb/>replica, so this gives us the length of every accepted tra-<lb/>jectory, weighted correctly for the ensemble. From here, <lb/>we can use standard Python libraries to analyze the list, ob-<lb/>taining, for example, the maximum (max(path_lengths)), <lb/>the mean (np.mean(path_lengths)), the standard devi-<lb/>ation (np.std(path_lengths)), or to plot a histogram <lb/>(plt.hist(path_lengths)). In this specific example, we <lb/>are o en interested not in the exact number of frames, <lb/>but in the time associated with that number of frames. <lb/>This can be accessed by multiplying the path length by <lb/>engine.snapshot_timestep, which gives the time be-<lb/>tween saved snapshots. In the case of the OpenMM engine, <lb/>this result even includes correct units, and we find that the <lb/>average path length for the flexible path length simulation is <lb/>. ps, with a maximum path length of . ps. <lb/>One of the tools for checking the behavior of path sampling <lb/>simulations, particularly of one-way flexible length path sam-<lb/>pling, is the visualization known as the &quot;path tree.&quot; This has <lb/>several uses, including checking for path decorrelation and <lb/>that there is su icient alternation between accepted forward <lb/>shots and accepted backward shots [ ]. In OPS, we generate <lb/>this object with <lb/>replica_history = vis.ReplicaEvolution(replica=0) <lb/>
			path_tree = vis.PathTree(steps, replica_history) <lb/>which works with any list of steps, although the visualiza-<lb/>tions get unwieldy for large numbers of steps. The generator <lb/>describes how to generate the list of samples to be displayed <lb/>from steps. In TPS, there is only one replica (replica=0), <lb/>but trees can also be used to track the move history of a <lb/>specific replica in TIS, where there are multiple replicas. <lb/>This PathTree object only consists of the data and <lb/>data structures to create and analyze the visualization. <lb/>The actual image can be generated (in SVG format) using <lb/>or written to file. The resulting image, shown in Fig. , shows <lb/>the original trajectory in grey, the forward shots in red, and <lb/>the backward shots in blue. However, these colors are cus-<lb/>tomizable using CSS options that can be modified by the user. <lb/>The top uses an additional CSS-based customization to show <lb/>the individual snapshots. Additional information is shown to <lb/>the le of the tree. At the far le , a number indicates the MC <lb/>trial step index. Next to that, a vertical bar contains horizon-<lb/>tal lines to indicate groups of correlated paths (paths which <lb/>share at least on configuration in common). <lb/>The list of first-decorrelated paths (the first mem-<lb/>ber of each such group) can be obtained with <lb/>replica_history.decorrelated_trajectories. This <lb/>number is a good estimate of the number of uncorrelated <lb/>samples drawn from an ensemble. For the flexible path <lb/>length simulation, we have <lb/>decorrelated trajectories, <lb/>decorrelating on average every 11.2 MC steps. For the fixed <lb/>path length simulation, there are only <lb/>decorrelated <lb/>trajectories, decorrelating every 24.4 MC steps. Note that <lb/>this set itself has no special relevance, but rather gives an <lb/>indication of the sampling e iciency. <lb/>Besides analyzing the sampling statistics, we can, of <lb/>course, perform normal MD trajectory analysis on trajecto-<lb/>ries generated by OPS. For example, suppose we wanted the <lb/>+ <lb/>B <lb/>F <lb/>F <lb/>B <lb/>B <lb/>B <lb/>B <lb/>F <lb/>F <lb/>B <lb/>B <lb/>cor <lb/>step <lb/>0 <lb/>2 <lb/>4 <lb/>5 <lb/>7 <lb/>8 <lb/>13 <lb/>14 <lb/>15 <lb/>18 <lb/>23 <lb/>24 <lb/>+ <lb/>B <lb/>F <lb/>B <lb/>F <lb/>B <lb/>F <lb/>F <lb/>B <lb/>B <lb/>F <lb/>B <lb/>F <lb/>F <lb/>F <lb/>F <lb/>F <lb/>cor <lb/>step <lb/>0 <lb/>1 <lb/>2 <lb/>5 <lb/>8 <lb/>9 <lb/>11 <lb/>12 <lb/>13 <lb/>14 <lb/>16 <lb/>18 <lb/>19 <lb/>20 <lb/>21 <lb/>22 <lb/>24 <lb/>
			FIG. 7. Path sampling history tree for alanine dipeptide TPS <lb/>simulations from Sec. VI A Top: The path tree for first trial MC <lb/>moves using flexible path length TPS. Here the initial path is repre-<lb/>sented by a grey horizontal line of a length equal to the path length. <lb/>Going downward, the sequential MC shooting moves are indicated. <lb/>The dashed vertical line indicates the shooting point. Red and blue <lb/>horizontal lines indicate forward and backward shots, respectively. <lb/>Note that these are partial paths, replacing the old path from the <lb/>shooting point forward (or backwards). The remainder of the path <lb/>is retained from the previous paths. To the le is indicated the MC <lb/>step (trial) index. Only accepted paths are shown. The bar to the le <lb/>indicate complete decorrelation of the previous decorrelated path. <lb/>Bottom, the path tree for fixed path length TPS. Note that the width <lb/>is scaled di erently; paths in the bottom tree are much longer than <lb/>the top tree. <lb/>active trajectory a er the th MC step. We can obtain this <lb/>with <lb/>trajectory = storage.steps[10].active[0].trajectory <lb/>where, again, TPS only has one replica, with replica ID 0. We <lb/>can directly analyze this trajectory with the tools in OPS. For <lb/>example, taking phi(trajectory) will give us the list of <lb/>values of φ for each frame in the trajectory. Any other OPS <lb/>collective variable will work similarly, whether it was used in <lb/>sampling or not. <lb/>The path density gives the number of paths in the ensem-<lb/>ble that visit a particular region in the projected collective <lb/>variable space. The appropriate histogram requires defining <lb/>the (inclusive) lower bound of a bin, and the width of the bin <lb/>in each collective variable. In OPS, we can calculate the path <lb/>density with <lb/>path_density = paths.PathDensityHistogram(cvs=[phi,psi], <lb/>left_bin_edges=[-180.0*deg,-180.0*deg], <lb/>bin_widths=(2.0*deg,2.0*deg)) <lb/>utilizing a bin width of degrees. <lb/>In principle, an OPS path density can be in any number of <lb/>collective variables. However, in practice, path densities are <lb/>-180 <lb/>-135 <lb/>-90 <lb/>-45 <lb/>0 <lb/>-90 <lb/>-45 <lb/>0 <lb/>45 <lb/>90 <lb/>135 <lb/>180 <lb/>R <lb/>C 7eq <lb/>0.00 <lb/>0.05 <lb/>0.10 <lb/>0.15 <lb/>0.20 <lb/>0.25 <lb/>0.30 <lb/>FIG. 8. Path density histogram for flexible path TPS of the <lb/>C7eq → αR transition in alanine dipeptide from Sec. VI A The <lb/>path density is a D histogram of the number of paths that traverse <lb/>a (discrete) ψ − φ value [ ]. On top of the path density we plot two <lb/>individual trajectories, one for each of the two observed channels. <lb/>Note that the le channel between C7eq and αR around φ ≈ 135 is <lb/>much more frequently sampled. <lb/>almost always shown as D projections. Fig. gives the path <lb/>density for the flexible path length ensemble in the (φ, ψ) <lb/>plane, along with two representative trajectories. <lb/>If one would rather use other tools, it is possible to convert <lb/>an OPS trajectory generated by OpenMM to an MDTraj [ ] <lb/>trajectory with <lb/>mdtraj_trajectory = trajectory.to_mdtraj() <lb/>From there, we can analyze the trajectory with MDTraj or <lb/>export it to any of the file formats supported by MDTraj, to be <lb/>read in by other analysis programs. In addition, MDTraj can <lb/>be used as a gateway to other libraries, such as NGLView [ ]. <lb/>The step.change starts from the root of the move deci-<lb/>sion tree, and therefore also contains information about what <lb/>kind of move was decided. This is very simple in TPS, but <lb/>can be much more complicated for the move schemes used <lb/>in TIS. The details that are probably of greatest interest can <lb/>be accessed with step.change.canonical. The nature of <lb/>a given step.change.canonical depends on the type of <lb/>Monte Carlo move. However, as discussed in Sec. IV and <lb/>shown in Fig. , all changes have a few properties: a Boolean <lb/>as to whether the trial was accepted, a link to the actual <lb/>mover that created the change, and a list of attempted sam-<lb/>ples in trials. <lb/>Sometimes we might want to study the rejected trajecto-<lb/>ries, for example, to determine whether they continued to <lb/>the maximum possible time in flexible length TPS. This could <lb/>indicate a metastable state that was not considered. The list <lb/>of rejected samples (which contain the trajectories, as well <lb/>as the associated ensembles) can be created with <lb/>rejected_samples = sum([ <lb/>step.change.canonical.trials <lb/>for step in storage.steps <lb/>if not step.change.accepted], []) <lb/>Since each step.change.canonical.trials is a list, we <lb/>use Python&apos;s sum function to add (extend) the lists with <lb/>each other. For more complicated move schemes, we might <lb/>want to add a restriction such as step.change.mover == <lb/>desired_mover with an and in the if statement. The code <lb/>above results in a list of Sample objects. The trajectories can <lb/>be extracted with <lb/>rejected_trajectories = [ <lb/>sample.trajectory for sample in rejected_samples] <lb/>These rejected trajectories can be analyzed in the same way <lb/>as above. <lb/>B. Multiple state replica exchange TIS on alanine dipeptide <lb/>. Setting up the molecular dynamics <lb/>In this example we use the same system as in the previous <lb/>example, with the same MD engine. In the online Jupyter <lb/>notebook -which contains additional detail not presented <lb/>here -we set up the engines from scratch. However, as OPS <lb/>saves all the details of the engine, we can reload a usable <lb/>engine from the output file of the previous example. In fact, <lb/>we can even use that file to reload the collective variables <lb/>that we defined: <lb/>previous_file = paths.Storage(&quot;tps_AD.nc&quot;, &apos;r&apos;) <lb/>engine = previous_file.engines[&apos;AD_engine&apos;] <lb/>psi = previous_file.cvs[&apos;psi&apos;] <lb/>phi = previous_file.cvs[&apos;phi&apos;] <lb/>. Defining states and interfaces <lb/>In contrast to the above example we take the MSTIS state <lb/>definitions for alanine dipeptide from [ ] to make the results <lb/>comparable with that work. The states are defined by a cir-<lb/>cular region around a center in φ − ψ space, while interfaces <lb/>are defined by circular regions with increasing diameter λ. <lb/>For instance, for state A we can define: <lb/>state_centers_A = [-150, 150] <lb/>interface_lambda_levels_A = [20, 45, 65, 80] <lb/>For convenience, Python dict objects can be used to con-<lb/>tain the centers and interface levels for all states (e.g., <lb/>state_centers[&quot;A&quot;]), although in this example we will use <lb/>separate objects for each. <lb/>In MSTIS, each state is associated with an order param-<lb/>eter (CV). In simple cases like this one, a single functional <lb/>can be used for all the order parameters. In OPS, this <lb/>can be accomplished by creating a single Python function <lb/>which takes a Snapshot as its first argument, and param-<lb/>eters for the functional as the remaining arguments. This <lb/>was also done implicitly in the previous example, where <lb/>the md.compute_dihedrals Python function is actually a <lb/>functional with indices as parameters. In this case, we <lb/>need to explicitly create a Python function with the signa-<lb/>ture circle_degree(snapshot, center, cv_1, cv_2), <lb/>where snapshot is an OPS Snapshot, center is a two-<lb/>member list like state_centers_A, and cv_1 and cv_2, are <lb/>OPS collective variable objects (in all cases, we will use our <lb/>phi and psi variables). <lb/>In this example, we could redefine the phi and psi vari-<lb/>ables inside the function, but using them as parameters has <lb/>an additional advantage: they will only be calculated once, <lb/>and then the values will be cached in memory (and optionally <lb/>saved to disk). This is extremely useful for expensive CVs that <lb/>are likely to be reused as part of other CVs. <lb/>Once the functional has been defined, we can wrap it in an <lb/>OPS FunctionCV for each state. For state A: <lb/>cv_A = paths.FunctionCV( <lb/>name=&apos;opA&apos;, f=circle_degree, <lb/>center=state_centers_A, cv_1=psi, cv_2=phi) <lb/>We can now use this CV to define the volume associated with <lb/>the state: <lb/>state_A = paths.CVDefinedVolume(cv_A, <lb/>lambda_min=0, lambda_max=10).named(&quot;A&quot;) <lb/>All of this is analogous to the TPS example; however, TIS also <lb/>requires defining interfaces. These can be created with: <lb/>iface_A = paths.VolumeInterfaceSet(cv_A, <lb/>minvals=0.0, maxvals=interface_lambda_levels_A) <lb/>In many cases, the innermost interface volume is identical <lb/>to the state. For those examples, one could first create the <lb/>interfaces, and then select the innermost using <lb/>state_A = iface_A[0] <lb/>The state definition used here are illustrated in Fig. . In <lb/>this example we restrict the states to {A, B, C, D}. The tran-<lb/>sitions to the E and F states are extremely rare, and requires <lb/>additional restricted path sampling [ ]. <lb/>. Setting up the transition network <lb/>MSTIS can make use of the optional multistate outer in-<lb/>terface, in which all state-to-state paths are allowed, as long <lb/>as they cross the outer interface MSOuterInterface. This <lb/>special interface allows switching paths from one associated <lb/>state to another when reversing a transtion path. Note that <lb/>in all other interface ensembles/replicas such reversal trials <lb/>are rejected by construction. We create this multi-state outer <lb/>interface with <lb/>ms_outers = paths.MSOuterTISInterface.from_lambdas({ <lb/>iface_A: max(iface_A.lambdas), ... }) <lb/>where the lambdas are the interface levels as defined above, <lb/>and the dots indicate a short hand for all other state volumes <lb/>and interfaces. <lb/>We now construct the Network that contains the structure <lb/>of states and interfaces <lb/>mstis = paths.MSTISNetwork([ <lb/>(state_A, iface_A), ..., ms_outers=ms_outers)]) <lb/>We finally construct the DefaultScheme with <lb/>scheme = paths.DefaultScheme(mstis,engine) <lb/>This scheme includes minus moves, moves for the multi-state <lb/>outer interface ensemble, as well as the standard shooting, <lb/>path reversal and nearest neighbor replica exchange moves. <lb/>FIG. 9. Comparison between initial sample a er generation at <lb/>high temperature and room temperature equilibration for ala-<lb/>nine dipeptide in the psi-phi plane from Sec. VI B. The trajecto-<lb/>ries are plotted as connect dots, where each dot represents a snap-<lb/>shot. The stable state and interface definitions for A,B,C,D are plot-<lb/>ted in the background. Note that a er cooling to room temperature <lb/>the trajectories are sampling a more narrow path samples, as ex-<lb/>pected. <lb/>. Obtaining initial conditions <lb/>Initial conditions for the MSTIS simulation can be obtained <lb/>with an approach similar to the one used in the TPS example <lb/>in Sec. VI A. The initial conditions must include a trajectory <lb/>that satisfies each (interface) ensemble. However, the same <lb/>trajectory can be reused for multiple ensembles, and an in-<lb/>terface that transitions from a given state to another must <lb/>exit all interfaces associated with the initial state. A trajectory <lb/>that visits all states has (when considering both the trajectory <lb/>and its time-reversed version) at least one subtrajectory that <lb/>represents a transition out of every state. <lb/>As the with TPS example, we therefore use <lb/>the approach described in Appendix A, using <lb/>a temperature of T <lb/>= <lb/>1000 K. Again, the <lb/>scheme.initial_conditions_from_trajectories <lb/>method is used to identify the specific subtrajectories and <lb/>associate them with the correct ensembles. <lb/>When the initial paths for the minus ensembles are <lb/>not directly found we use the innermost TIS ensem-<lb/>ble trajectories and extend them until they match the <lb/>required (minus) ensemble (or fail in doing so) using <lb/>the <lb/>.extend_sample_from_trajectories <lb/>method <lb/>and associating them with the correct ensembles using <lb/>scheme.initial_conditions_from_trajectories. <lb/>. Equilibrating and running the simulation <lb/>As in the TPS examples, the path replicas first need to be <lb/>equilibrated since the initial trajectories are not from the real <lb/>dynamics (e.g., generated with metadynamics, high tempera-<lb/>ture, etc.) and/or because the initial trajectories are not likely <lb/>representatives of the path ensemble (e.g., if state-to-state <lb/>transition trajectories are used for all interfaces). <lb/>As with straightforward MD simulations, running equili-<lb/>bration can be the same process as running the total simula-<lb/>tion. However, in path sampling we could equilibrate without <lb/> 20 30 40 50 60 70 80 90 100 <lb/> 
			λ <lb/>0.0 <lb/>0.2 <lb/>0.4 <lb/>0.6 <lb/>0.8 <lb/>1.0 <lb/>P(λ) <lb/>A <lb/>B <lb/>C <lb/>D <lb/>20 30 40 50 60 70 80 90 100 <lb/>λ <lb/>5 <lb/>4 <lb/>3 <lb/>2 <lb/>1 <lb/>0 <lb/>lnP(λ) <lb/>A <lb/>B <lb/>C <lb/>D <lb/>0 <lb/>20 <lb/>40 <lb/>60 <lb/>80 <lb/>100 <lb/>120 <lb/>λ <lb/>5 <lb/>4 <lb/>3 <lb/>2 <lb/>1 <lb/>0 <lb/>lnP(λ) <lb/>FIG. 10. TIS Crossing probabilities for alanine dipeptide, from section VI B. Le : Total crossing probability as function of the order <lb/>parameter (CV) λ for each individual state (A-D). Center: Natural logarithm of the total crossing probability per state. Right: Per interface <lb/>crossing probabilities for state A. The master curve (black) is obtained by reweighting [ , ]. <lb/>replica exchange moves or path reversal moves, for instance. <lb/>In the example below, we create a new &apos;MoveScheme&apos; that <lb/>only includes shooting movers, to achieve equilibration of <lb/>the interface ensemble replicas, <lb/>equil_scheme = paths.OneWayShootingMoveScheme( <lb/>mstis, engine=engine) <lb/>and run this scheme for <lb/>steps the way we run any other <lb/>scheme, using the PathSampling object. <lb/>equilibration = paths.PathSampling( <lb/>storage=storage, <lb/>sample_set=total_sample_set, <lb/>move_scheme=equil_scheme) <lb/>equilibration.run(500) <lb/>equilibrated_sset = equilibration.sample_set <lb/>Figure shows the set of initial and final samples. Note <lb/>that the large coverage of phase space at high temperature <lb/>narrows a er cooling down, as expected. <lb/>Fianlly, we run the simulation for <lb/>, <lb/>steps using the <lb/>PathSampling object as in previous example, with the default <lb/>scheme as defined above, a Storage object, and the initial <lb/>conditions from the equilibration. <lb/>mstis_calc = PathSampling( <lb/>storage=Storage(&quot;ala_mstis_production.nc&quot;, &quot;w&quot;), <lb/>sample_set=equilibrated_sset, <lb/>move_scheme=scheme) <lb/>mstis_cals.run(100000) <lb/>. Analyzing the results <lb/>To do analysis on the path simulation results we first have <lb/>to load the production file for analysis: <lb/>storage = paths.AnalysisStorage( <lb/>&quot;ala_mstis_production.nc&quot;) <lb/>Then we can run analysis on this storage. One of the main <lb/>objectives for doing multiple state replica exchange TIS is to <lb/>compute the rate constant matrix. To obtain the rate constant <lb/>matrix, we run <lb/>mstis.rate_matrix(storage.steps, force=True) <lb/>which gives as an output the full rate constant matrix k IJ , <lb/>obtained from a computation of the fluxes φ 0I , the cross-<lb/>ing probabilities P I (λ mI |λ 0I ) and the conditional transition <lb/>matrix P I (λ 0J |λ mI ) (see Eq. ). <lb/>A <lb/>B <lb/>C <lb/>D <lb/>A <lb/>0.06512 0.003514 0.0009725 <lb/>B 0.07606 <lb/>0.001202 0.001107 <lb/>C 0.05311 0.01103 <lb/>0.1202 <lb/>D 0.01102 0.005624 0.06909 <lb/>TABLE II. Rate constant matrix for alanine dipeptide. The av-<lb/>erage rate constant matrix for the four-state Markov model based on <lb/>several independent runs. Rows denote leaving, columns arriving <lb/>states. Subscript denotes error in the last digits. <lb/>φ0I [ps −1 ] PI (λmI |λ0I ) φmI [ps −1 ] <lb/>A 1.56 <lb/>0.06609 <lb/>0.10313 <lb/>B 1.85 <lb/>0.05909 <lb/>0.11017 <lb/>C 1.67 <lb/>0.19313 <lb/>0.32321 <lb/>D 2.29 <lb/>0.07109 <lb/>0.16220 <lb/>TABLE III. Fluxes and outer interface crossing probabilities <lb/>for TIS simulation of alanine dipeptide. Flux at the first interface <lb/>(second column), the crossing probability from the first to the outer-<lb/>most interface (third column) and the flux at the outermost interface <lb/>(last column). <lb/>A <lb/>B <lb/>C <lb/>D <lb/>A 0.3506 0.6106 0.03208 0.009012 <lb/>B 0.7203 0.2603 0.01102 0.01108 <lb/>C 0.1702 0.03307 0.4003 0.4001 <lb/>D 0.06605 0.03413 0.4203 0.4804 <lb/>TABLE IV. Conditional transition probability matrix be-<lb/>tween alanine dipeptide states. These probabilities follow di-<lb/>rectly from the path sampling in the multistate outer ensemble. <lb/>Rows denote leaving, columns arriving states. <lb/>An example of such a rate constant matrix computation <lb/>is shown in Table II which agrees well with the results in <lb/>Ref. [ ]. For comparison, the computed fluxes φ 0I and cross-<lb/>ing probabilities P I (λ mI |λ 0I ) are presented in Table III, while <lb/>Table IV reports the conditional state-to-state transition ma-<lb/>trix P I (λ 0J |λ mI ), which represents the probabilities to reach <lb/>a state provided that the trajectories have passed the outer-<lb/>most interface of a state. <lb/>OPS also includes other analysis tools such as the crossing <lb/>probabilities and the sampling statistics. Both are important <lb/>for purposes of check the validity of the simulations results. <lb/>The crossing probability graphs in Fig. can be helpful in <lb/>interpreting the rate matrix. The sampling statistics provides <lb/>the Monte Carlo acceptance ratio for the di erent movers. Of <lb/>course, each trajectory in the ensemble can accessed and <lb/>scrutinized individually, as in previous sections. <lb/>C. Example: MISTIS on a three-state D model system <lb/>This example deals with a three-state D model system, <lb/>which we also refer to as a toy model. OPS includes simple <lb/>code to simulate the dynamics of small toy models like the <lb/>one considered here. This is intended for use for either edu-<lb/>cational purposes or for rapid prototyping of new method-<lb/>ologies. Since the overall path sampling code is independent <lb/>of the underlying engine, many types of new methods could <lb/>be developed and tested on the toy models and would be <lb/>
			immediately usable for more complicated systems, simply <lb/>by changing the engine. <lb/>. Setting up the molecular dynamics <lb/>We create a simple D model with a potential consisting <lb/>of a sum of Gaussian wells: <lb/>V (x, y) = x 6 + y 6 − <lb/>2 <lb/>i=0 <lb/>e −12((x−xi) 2 +(y−yi) 2 ) <lb/>( ) <lb/>with (x 0 , y 0 ) = (−0.5, 0.5), (x 1 , y 1 ) = (−0.5, −0.5), and <lb/>(x 2 , y 2 ) = (0.5, −0.5) using <lb/>pes = (toys.OuterWalls([1.0,1.0], [0.0,0.0]) + <lb/>toys.Gaussian(-1.0, [12.0,12.0], [-0.5, 0.5]) + <lb/>toys.Gaussian(-1.0, [12.0,12.0], [-0.5,-0.5]) + <lb/>toys.Gaussian(-1.0, [12.0,12.0], [ 0.5,-0.5])) <lb/>This results in a potential energy surface with three sta-<lb/>ble states, caused by the Gaussian wells at (−0.5, −0.5), <lb/>(0.5, −0.5), and (−0.5, 0.5). We call those states A, B, and <lb/>C, respectively. This potential interface surface, along with <lb/>the state and interface definitions described below, is illus-<lb/>trated in Fig. . <lb/>To integrate the equations of motion, we use the BAOAB <lb/>Langevin integrator of Leimkuhler and Matthews [ ], which <lb/>we initialize with <lb/>integrator = toys.LangevinBAOABIntegrator( <lb/>dt=0.02, temperature=0.1, gamma=2.5) <lb/>1.00 <lb/>0.75 <lb/>0.50 <lb/>0.25 <lb/>0.00 <lb/>0.25 <lb/>0.50 <lb/>0.75 <lb/>1.00 <lb/>1.00 <lb/>0.75 <lb/>0.50 <lb/>0.25 <lb/>0.00 <lb/>0.25 <lb/>0.50 <lb/>0.75 <lb/>1.00 <lb/>FIG. 11. Potential energy surface, states, and interfaces for <lb/>the D toy model. States are light blue, boundaries of normal inter-<lb/>faces are red, and the boundary of the multiple state outer interface <lb/>is dark blue. For clarity when showing multiple interface sets, the <lb/>interface bondaries are only drawn part of the way. They continue <lb/>in an infinite straight line. <lb/>The toy engine employs units where k B = 1. The &quot;topol-<lb/>ogy&quot; for the toy engine stores the number of spatial degrees <lb/>of freedom, as well as a mass for each degree of freedom <lb/>and the potential energy surface. We also create an options <lb/>dictionary for the engine. <lb/>topology = toys.Topology( <lb/>n_spatial=2, masses=[1.0,1.0], pes=pes) <lb/>options = {&apos;integ&apos;: integ, &apos;n_frames_max&apos;: 5000, <lb/>&apos;n_steps_per_frame&apos;: 1} <lb/>We then instantiate an engine with toy_engine = <lb/>toys.Engine(options, topology). <lb/>. Defining states and interfaces <lb/>In this calculation, we will set up multiple interface set tran-<lb/>sition interface sampling (MISTIS)[ ]. This involves defining <lb/>di erent interface sets for each transition. To simplify, and to <lb/>highlight some of the flexibility of MISTIS, we will only focus <lb/>on the A → B, B → A, and A → C transitions. <lb/>First, we define simple collective variables. We use the <lb/>Cartesian x and y directions for both our state definitions <lb/>and for our interfaces. We define these as standard Python <lb/>functions, for example <lb/>def yval(snapshot): <lb/>return snapshot.xyz[0][1] <lb/>and xval is similar, but returns the [0][0] element, <lb/>where the first index refers to the atom number and the <lb/>second to the spatial dimension. We wrap functions <lb/>these in OPS collective variables with, for example, cvX <lb/>= FunctionCV(&quot;x&quot;, xval). We&apos;ll define a volume called <lb/>x_lower for x &lt; −0.35 with CVDefinedVolume(cvX, <lb/>float(&quot;-inf&quot;), -0.35). Similarly we define x_upper for <lb/>x ≥ 0.35, and use the same bounds for y with y_lower and <lb/>y_upper. With these, we define our states as <lb/>stateA = (x_lower &amp; y_lower).named(&quot;A&quot;) <lb/>stateB = (x_upper &amp; y_lower).named(&quot;B&quot;) <lb/>stateC = (x_lower &amp; y_upper).named(&quot;C&quot;) <lb/>For our TIS analysis, the order parameter must increase with <lb/>the interface. So for the B → A transition we create another <lb/>collective variable, cvNegX, based on a function that returns <lb/>-snapshot[0][0]. For all of these, we will set interfaces at <lb/>−0.35, −0.3, −0.27, −0.24, −0.2, and −0.1. The A → C <lb/>transition has an additional interface at 0.0 The A → B and <lb/>B → A transitions will share a multiple state outer interface <lb/>at 0.0. Note that, for the B → A transition, the interface <lb/>associated with cvNegX = −0.35 is actually at x = 0.35, <lb/>since cvNegX returns −x. These interfaces are created by, for <lb/>example: <lb/>interfacesAB = paths.VolumeInterfaceSet( <lb/>cvX, float(&apos;-inf&apos;), <lb/>[-0.35, -0.3, -0.27, -0.24, -0.2, -0.1]) <lb/>with similar lines for interfacesAC and interfacesBA. The <lb/>multiple state outer interface, which connects the A → B <lb/>and B → A transitions, can be created at x = 0.0 with <lb/>ms_outer = paths.MSOuterTISInterface.from_lambdas( <lb/>{iface: 0.0 for iface in <lb/>[interfacesAB, interfacesBA]}) <lb/>. Setting up the transition network and move scheme <lb/>Like the MSTISNetwork, the syntax for setting up a <lb/>MISTISNetwork requires a list of tuples. However, since <lb/>MISTIS requires a final state as well an initial state, it also <lb/>requires that the final state be included as an extra piece of <lb/>information in that tuple. So we set up our desired MISTIS <lb/>network with <lb/>network = paths.MISTISNetwork([ <lb/>(stateA, interfacesAB, stateB), <lb/>(stateA, interfacesAC, stateC), <lb/>(stateB, interfacesBA, stateA)], <lb/>ms_outers=ms_outer, <lb/>strict_sampling=True) <lb/>The strict_sampling argument means that an A → C <lb/>path will be rejected if sampling the A → B transition. Note <lb/>that A is the initial state for transitions to two states, whereas <lb/>B is the initial state for transitions to one state, and C is not <lb/>an initial state at all. The flexibility to define arbitrary reaction <lb/>networks is an important aspect of the MISTIS approach. <lb/>The move scheme is set up in exactly the same way as for <lb/>MSTIS: scheme = DefaultScheme(network, engine). <lb/>One could also use a single replica move scheme with a <lb/>MISTIS network, just as was done in the MSTIS example. <lb/>. Obtaining initial conditions <lb/>Here, we will use the bootstrapping approach to obtain ini-<lb/>tial trajectories. This approach is most e ective with simple <lb/>systems like this, where the collective variables we have cho-<lb/>sen as order parameters are good representations of the ac-<lb/>tual reaction coordinate. The bootstrapping runs separately <lb/>on each transition A → B, A → C, and B → A. Given an <lb/>initial snapshot snapA in state A, the initial samples for the <lb/>A → B transition can be obtained with <lb/>init_AB = paths.FullBootstrapping( <lb/>transition=network.transitions[(stateA, stateB)], <lb/>snapshot=snapA, <lb/>engine=toy_engine, <lb/>forbidden_states=[stateC], <lb/>extra_ensembles=network.ms_outers).run() <lb/>This will create a trajectory for each of the normal inter-<lb/>face ensembles, as well as the multiple state outer inter-<lb/>face ensembles. The other transitions can be prepared simi-<lb/>larly, although they can omit the extra_ensembles option, <lb/>since there is only one multiple state outer ensemble to fill. <lb/>Whereas snapshots for the OpenMM engine used in the pre-<lb/>vious examples came from PDBs or other files, for the toy <lb/>engine, the initial snapshot can be manually created: <lb/>snapA = toys.Snapshot( <lb/>coordinates=np.array([[-0.5, -0.5]]), <lb/>velocities=np.array([[0.0, 0.0]]), <lb/>engine=engine) <lb/>The individual sample sets created by the <lb/>FullBootstrapping approach can be combined into <lb/>one using <lb/>all_trajectories = [ <lb/>s.trajectory for s in <lb/>list(init_AB) + list(init_AC) + list(init_BC)] <lb/>From here, the setup follows that of the MSTIS example: <lb/>the trajectories can be assigned to ensembles using <lb/>scheme.initial_conditions_from_trajectories, <lb/>and the minus ensembles, <lb/>of which there <lb/>is one for each state, can be filled using <lb/>minus.extend_sample_from_trajectories. <lb/>. Running the simulation and analyzing the results <lb/>The path sampling follows exactly as with the previous ex-<lb/>amples. The PathSampling object is created with a storage <lb/>file, the move scheme, and the initial conditions. We use the <lb/>.run(n_steps) method to run the simulation. <lb/>One di erence with the MSTIS approach is that trajecto-<lb/>ries from the multiple set minus interface cannot be used <lb/>to calculate the flux. To obtain the flux, we do a separate <lb/>calculation, which we call DirectSimulation, and which <lb/>runs a molecular dynamics trajectory and calculates the flux <lb/>and the rates from the direct MD. <lb/>Setting up the DirectSimulation requires the same <lb/>toy_engine object. The set of all states if given by <lb/>states = set(network.initial_states + network.final_states) <lb/>To determine the flux out of a given state and through a given <lb/>interface, it needs the pairs of (state, interface) for each tran-<lb/>sition. We can create this with <lb/>A <lb/>B <lb/>C <lb/>A -<lb/>1.9814 1.9517 <lb/>B 2.0016 -<lb/>-<lb/>A <lb/>B <lb/>C <lb/>A -<lb/>1.9443 2.2065 <lb/>B 2.1037 -<lb/>-<lb/>TABLE V. Rates constants for the the toy model, multiplied <lb/>by 10 4 . Subscripts indicate error in the last two digits. Le : Rate <lb/>constant calculated from a very long direct molecular dynamics sim-<lb/>ulation. Right: Rate constant calculated using MISTIS. By symmetry, <lb/>all three rate constants in each table should be nearly the same. <lb/>flux_pairs = [ <lb/>(t.stateA, t.interfaces[0]) <lb/>for t in network.transitions.values()] <lb/>The simulation is then created with <lb/>sim = paths.DirectSimulation( <lb/>storage=None, engine=engine, states=states, <lb/>flux_pairs=flux_pairs, initial_snapshot=snap) <lb/>where we choose not to store the output, and where we <lb/>can use any snapshot as our initial snapshot. The method <lb/>sim.run(n_steps) runs the simulation for the given num-<lb/>ber of MD steps. Note that, although the direct simulation <lb/>here is for the MISTIS network, it would work equally well for <lb/>any other network. However, the flux calculation based on <lb/>the minus interface is more convenient for the MSTIS case. <lb/>Once the direct simulation has been run, we can obtain <lb/>the flux from it using sim.fluxes. This returns a Python <lb/>dictionary with the (state, interface) pairs as keys and <lb/>the calculated flux as value. Prior to the rate matrix cal-<lb/>culation, we can set the fluxes for the network by using <lb/>network.set_fluxes(sim.fluxes). <lb/>Aside from setting the flux, the analysis for the MISTIS net-<lb/>work is exactly as it is for other path sampling methods. The <lb/>rate matrix for this model is presented in Table V. Note that <lb/>the rate matrix only includes the specific transitions we se-<lb/>lected for study by MISTIS; others are not listed. The MISTIS <lb/>rates represent the average of runs of 10 5 MC steps each, <lb/>with the standard deviation as the reported error. To demon-<lb/>strate correctness, we compare these rates to those from <lb/>a direct MD simulation (also performed using OPS), with a <lb/>length of 8 × 10 8 frames. The cumulative MD time for the <lb/>MISTIS simulations was less than 1.8 × 10 7 frames. Errors <lb/>for the direct MD rate were determined by splitting the total <lb/>simulation into sequential blocks and calculating the stan-<lb/>dard deviation of the rate in each block. Rates and error bars <lb/>from the two methods compare favorably, even though the <lb/>MD simulation took more than times more CPU time. <lb/>VII. CONCLUSION <lb/>In this paper we have presented a new easy-to-use Python <lb/>framework for performing transition path sampling simu-<lb/>lations of (bio)molecular systems. The OpenPathSampling <lb/>framework is extensible and allows for the exploration of <lb/>new path sampling algorithms by building on a variety of <lb/>basic operations. As the framework provides a simple ab-<lb/>straction layer to isolate path sampling from the underly-<lb/>ing molecular simulation engine, new molecular simulation <lb/>packages can easily be added. Besides being able to exe-<lb/>cute existing complex path sampling simulations schemes, <lb/>tools are provided to facilitate the implementation of new <lb/>path sampling schemes built on basic path sampling com-<lb/>ponents. In addtion, tools for analaysis of e.g., rate con-<lb/>stants, are also provided. Modules that provide additional <lb/>functionality are continuously added to be used by the com-<lb/>munity (see, e.g., the repositories at https://gitlab.e-<lb/>cam2020.eu/Classical-MD_openpathsampling). <lb/>In summary, the OpenPathSampling package can assist in <lb/>making the tranistion path sampling approach easier to use <lb/>for the (bio)molecular simulation community. <lb/></body>

			<div type="acknowledgement">ACKNOWLEDGMENTS <lb/>DWHS and PGB acknowledge support from the European <lb/>Union&apos;s Horizon <lb/>research and innovation program, un-<lb/>der grant agreement No <lb/>(project E-CAM). JDC ac-<lb/>knowledges support from Cycle for Survival, NIH grant P <lb/>CA <lb/>, and NIH grant R GM <lb/>. JDC, JHP, and DWHS <lb/>gratefully acknowledge support from the Sloan Kettering <lb/>Institute. FN acknowledges ERC consolidator grant <lb/>&quot;ScaleCell&quot;, DFG NO <lb/>/ -, and SFB <lb/>, project A . <lb/>The authors are grateful for feedback from many peo-<lb/>ple who helped beta-test the so ware, whose names <lb/>are listed at http://openpathsampling.org/latest/ <lb/>acknowledgments.html. The authors are particularly grate-<lb/>ful to Sander Roet (University of Amsterdam) for his feedback, <lb/>and to Jocelyne Vreede (University of Amsterdam) for the <lb/>feedback obtained by using OPS as a teaching tool in courses <lb/>on biomolecular simulation. <lb/></div>

			<div type="annex">CONFLICT OF INTEREST STATEMENT <lb/>JDC is a member of the Scientific Advisory Board for <lb/>Schrödinger, LLC. <lb/></div>

			<div type="annex">Appendix A: Obtaining an initial trajectory <lb/>Just as configurational Monte Carlo requires a valid initial <lb/>configuration for input, path sampling Monte Carlo requires <lb/>a valid initial trajectory for input. And just as with configura-<lb/>tional Monte Carlo, an unrealistic initial state can equilibrate <lb/>into a realistic state, but more realistic starting conditions <lb/>are preferred. Unrealistic starting conditions can take longer <lb/>to equilibrate, and can get trapped in unrealistic metastable <lb/>basins. In the case of path sampling, this can mean sam-<lb/>pling a transition with a much higher energy barrier than is <lb/>realistic. <lb/>Obtaining a good first trajectory is thus of paramount <lb/>importance. However, there is no single best method <lb/>to do so. Here we review a few options, and explain <lb/>how OPS can facilitate first trajectory generation. In <lb/>all of these, the key OPS functions that simplify the <lb/>process are the Ensemble.split function, which can iden-<lb/>tify subtrajectories that satisfy the desired ensemble, and the <lb/>MoveScheme.initial_conditions_from_trajectories <lb/>function, which attempts to create initial conditions for <lb/>the desired move scheme bsaed on given trajectories. The <lb/>fundamental trade-o for these approaches is between how <lb/>&quot;realistic&quot; the initial trajectory is, and how computationally <lb/>expensive it is to obtain the first trajectory. <lb/>. Long-time MD <lb/>While a transition from an unbiased MD trajectory will pro-<lb/>vide a realistic initial trajectory, these are di icult to obtain <lb/>for rare events. Nevertheless, distributed computing projects <lb/>like Folding@Home [ ] and special-purpose computers for <lb/>MD such as Anton [ ], might yield trajectories that include <lb/>a transition. The Ensemble.split function can then select <lb/>subtrajectories that satisfy a desired ensemble. <lb/>In these trajectories frames are o en saved very infre-<lb/>quently, leading to transitions with only one or two (or even <lb/>zero) frames in the &quot;no-man&apos;s land&quot; between the states. Path <lb/>sampling requires at least a few to a few tens of frames. <lb/>A CommittorSimulation using the desired states as end-<lb/>points and any frames between the two states as input could <lb/>generate an initial trajectoriy by joining two path segments <lb/>ending in di erent states, provided the committor for at least <lb/>one of the intermediate frames is reasonable. <lb/>. High temperature MD <lb/>In the alanine dipeptide example, we use MD at high tem-<lb/>perature to increase the probability of getting a transition. <lb/>This method could cause problems in larger systems, by al-<lb/>lowing transitions that are not accessible at the relevant low <lb/>temperature. However, it works well on simple systems such <lb/>as AD, and is very easy to set up. <lb/>First, we create an engine with a higher temperature. For <lb/>the AD example, we use OPS&apos;s OpenMM engine. For the -<lb/>state system, we used a high temperature of 500K. For the <lb/>-state system, we used a high temperature of 1000K in order <lb/>to easily reach the higher-lying states. <lb/>To ensure that we visit all states, we generate a trajectory <lb/>using the ensemble <lb/>ensemble = paths.join_ensembles( <lb/>[paths.AllOutXEnsemble(state) for state in states]) <lb/>which creates the union of AllOutXEnsembles for each state. <lb/>Running with this ensemble as the continue condition means <lb/>that the trajectory will stop with the first trajectory that does <lb/>not satisfy it, i.e. the first trajectory with at least one frame in <lb/>each state. For MSTIS, this guarantees that a subtrajectory <lb/>(or its reversed version) will exist for every path ensemble. <lb/>We obtain the relevant trajectories by using the <lb/>ensemble.split method with the outermost ensemble for <lb/>each sampling transition (See also Ref. [ ]). <lb/>trajectories = [t.ensembles[-1].split(long_trajectory) <lb/>for t in network.sampling_transitions] <lb/>These trajectories can then be given to the <lb/>MoveScheme.initial_conditions_from_trajectories <lb/>method. <lb/>Relaxing the high temperature initial trajectories down to <lb/>ambient conditions might be di icult, requiring many shoot-<lb/>ing attempts before a valid room temperature path is created. <lb/>Again, a CommittorSimulation can alleviate this problem, <lb/>by joining a forward and backward committor segments from <lb/>a snapshot with a finite committor value. <lb/>. Bootstrapping/Ratcheting <lb/>In the toy model example in Sec. VI C , we use a &quot;bootstrap-<lb/>ping&quot; approach, which is specifically useful for TIS. In this ap-<lb/>proach, we initialize a trajectory in a stable state, e.g. A, and <lb/>perform MD until the first interface is crossed, which allows <lb/>the first interface ensemble to be populated,. Subsequently, <lb/>TIS is performed until the second interface is crossed, allow-<lb/>ing the second interface to be populated, etc etc. In this way <lb/>one can ratchet one self up the barrier and populate each TIS <lb/>interface. All this is taken care of by the FullBootstrapping <lb/>method. Note that this path ensemble needs to be equili-<lb/>brated subsequently. <lb/>. Using biased trajectories <lb/>The use of unbiased dynamics is not necessary, as the goal <lb/>is to obtain an initial trajectory that is just &quot;reasonably close&quot; <lb/>to the unbiased dynamics. Subsequent path sampling will <lb/>then equilibrate the trajectories with the unbiased dynamics. <lb/>Recent work [ ] has employed metadynamics [ ] to ob-<lb/>tain an initial trajectory. Although metadynamics biases the <lb/>underlying dynamics, the first transition in a metadynam-<lb/>ics simulation will not have added much bias to the barrier <lb/>region. Therefore, further path sampling can equilibrate a <lb/>first metadynamics trajectories into the unbiased dynamics <lb/>path ensemble. This initial metadynamics trajectory could <lb/>be generated with PLUMED [ ], and then read into OPS. <lb/>The same basic approach could be employed for other <lb/>approaches to generate a non-physical initial transition tra-<lb/>jectory, including steered MD [ ], nudged elastic band [ ], <lb/>or the string method[ ]. <lb/></div>

			<listBibl>[ ] I. Buch, T. Giorgino, and G. De Fabritiis, Proc. Nat. Acad. Sci. <lb/>USA <lb/>, <lb/>( <lb/>). <lb/>[ ] N. Plattner, S. Doerr, G. D. Fabritiis, and F. Noé, Nature Chem-<lb/>istry , <lb/>( <lb/>). <lb/>[ ] D.-A. Silva, G. R. Bowman, A. Sosa-Peinado, and X. Huang, PLoS <lb/>Computational Biology , e <lb/>( <lb/>). <lb/>[ ] C. Schütte, A. Fischer, W. Huisinga, and P. Deuflhard, Journal <lb/>of Computational Physics <lb/>, <lb/>( <lb/>). <lb/>[ ] C. Schütte and W. Huisinga, in Handbook of Numerical Analysis, <lb/>edited by P. G. Ciaret and J.-L. Lions (Elsevier, ADDRESS, <lb/>), <lb/>Vol. X, pp. <lb/>-. <lb/>[ ] F. Noé, I. Horenko, C. Schütte, and J. C. Smith, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] J. D. Chodera, N. Singhal, V. S. Pande, K. A. Dill, and W. C. Swope, <lb/>J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] D. Chandler, in Classical and Quantum Dynamics in Condensed <lb/>Phase Simulations, edited by B. J. Berne, G. Ciccotti, and D. F. <lb/>Coker (World Scientific, ADDRESS, <lb/>), Chap. Barrier cross-<lb/>ings: classical theory of rare but important events, pp. -. <lb/>[ ] P. G. Bolhuis, D. Chandler, C. Dellago, and P. Geissler, Ann. Rev. <lb/>Phys. Chem. , <lb/>( <lb/>). <lb/>[ ] G. M. Torrie and J. P. Valleau, Chem. Phys. Lett. , <lb/>( <lb/>). <lb/>[ ] E. Carter, G. Ciccotti, J. T. Hynes, and R. Kapral, Chem. Phys. <lb/>Lett. <lb/>, <lb/>( <lb/>). <lb/>[ ] T. Huber, A. Torda, W. van Gunsteren, J. Comput. Aided Mol. <lb/>Des. , <lb/>( <lb/>). <lb/>[ ] H. Grubmüller, Phys. Rev. E , <lb/>( <lb/>). <lb/>[ ] A. F. Voter, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] A. Laio and M. Parrinello, Proc. Nat. Acad. Sci. USA , <lb/>( <lb/>). <lb/>[ ] E. Darve and A. Pohorille, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] Y. Sugita, , and Y. Okamoto, Chem. Phys. Lett. <lb/>, <lb/>( <lb/>). <lb/>[ ] E. Marinari and G. Parisi, Europhys. Lett. , <lb/>( <lb/>). <lb/>[ ] L. Zheng, M. Chen, and W. Yang, Proceedings of the National <lb/>Academy of Sciences <lb/>, <lb/>( <lb/>). <lb/>[ ] Y. Q. Gao, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] C. Dellago, P. G. Bolhuis, F. S. Csajka, and D. Chandler, J. Chem. <lb/>Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] C. Dellago, P. G. Bolhuis, and P. L. Geissler, Adv. Chem. Phys. <lb/>, ( <lb/>). <lb/>[ ] C. Dellago and P. G. Bolhuis, Adv Polym Sci <lb/>, <lb/>( <lb/>). <lb/>[ ] R. Allen, D. Frenkel, and P. ten Wolde, J. Chem. Phys. <lb/>, xxx <lb/>( <lb/>). <lb/>[ ] F. Cerou, A. Guyader, T. Lelievre, and D. Pommier, J. Chem. Phys. <lb/>, xx ( <lb/>). <lb/>[ ] A. K. Faradjian and R. Elber, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] M. Villen-Altamirano and J. Villen-Altamirano, Eur. Trans. Tele-<lb/>com. , <lb/>( <lb/>). <lb/>[ ] J. T. Berryman and T. Schilling, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] A. Dickson, A. Warmflash, and A. R. Dinner, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] G. Huber and S. Kim, Biophysical Journal , ( <lb/>). <lb/>[ ] B. W. Zhang, D. Jasnow, and D. M. Zuckerman, The Journal of <lb/>Chemical Physics <lb/>, <lb/>( <lb/>). <lb/>[ ] J.-H. Prinz, H. Wu, M. Sarich, B. Keller, M. Senne, M. Held, J. D. <lb/>Chodera, C. Schütte, and F. Noé, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] N. Singhal, C. D. Snow, and V. S. Pande, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] J. Rogal and P. G. Bolhuis, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] S. Pronk, G. R. Bowman, B. Hess, P. Larsson, I. S. Haque, V. S. <lb/>Pande, I. Pouya, K. Beauchamp, P. M. Kasson, and E. Lindahl, in <lb/>International Conference for High Performance Computing, <lb/>Networking, Storage and Analysis (SC) (PUBLISHER, ADDRESS, <lb/>), pp. -. <lb/>[ ] J. Preto and C. Clementi, Phys. Chem. Chem. Phys. , <lb/>( <lb/>). <lb/>[ ] V. Balasubramanian, I. Bethune, A. Shkurti, E. Breitmoser, E. <lb/>Hruska, C. Clementi, C. Laughton, and S. Jha, in <lb/>IEEE th <lb/>International Conference on e-Science (e-Science) (PUBLISHER, <lb/>ADDRESS, <lb/>), pp. <lb/>-. <lb/>[ ] H. Wu, A. S. J. S. Mey, E. Rosta, and F. Noé, The Journal of <lb/>Chemical Physics <lb/>, <lb/>( <lb/>). <lb/>[ ] H. Wu, F. Paul, C. Wehmeyer, and F. Noé, Proceedings of the <lb/>National Academy of Sciences <lb/>, E <lb/>( <lb/>). <lb/>[ ] A. S. J. S. Mey, H. Wu, and F. Noe, Phys. Rev. X , <lb/>( <lb/>). <lb/>[ ] E. Rosta and G. Hummer, J. Chem. Theory Comput , <lb/>( <lb/>). <lb/>[ ] P. Eastman and V. S. Pande, Computing in Science and Engi-<lb/>neering , ( <lb/>). <lb/>[ ] P. Eastman, M. Friedrichs, J. D. Chodera, R. Radmer, C. Bruns, <lb/>J. Ku, K. Beauchamp, T. J. Lane, L.-P. Wang, D. Shukla, T. Tye, <lb/>M. Houston, T. Stitch, and C. Klein, J. Chem. Theor. Comput. , <lb/>( <lb/>). <lb/>[ ] A. Lervik, E. Riccardi, and T. S. van Erp, Journal of Computa-<lb/>tional Chemistry , <lb/>( <lb/>). <lb/>[ ] D. W. H. Swenson, J.-H. Prinz, J. Chodera, and P. G. Bolhuis, to <lb/>be published ( <lb/>). <lb/>[ ] P. G. Bolhuis and C. Dellago, Reviews of Computational Chem-<lb/>istry (Wiley-VCH, Hoboken, <lb/>). <lb/>[ ] E. Guarnera and E. Vanden-Eijnden, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] J. Juraszek and P. G. Bolhuis, Proc. Nat. Acad. Sci. USA <lb/>, <lb/>( <lb/>). <lb/>[ ] M. Grünwald, C. Dellago, and P. L. Geissler, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] R. G. Mullen, J.-E. Shea, and B. Peters, J. Comput. Theory Chem. <lb/>, <lb/>( <lb/>). <lb/>[ ] Z. F. Brotzakis and P. G. Bolhuis, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] T. S. van Erp, D. Moroni, and P. G. Bolhuis, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] J. Rogal, W. Lechner, J. Juraszek, B. Ensing, and P. G. Bolhuis, <lb/>J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] C. Dellago, P. G. Bolhuis, and D. Chandler, The Journal of Chem-<lb/>ical Physics <lb/>, <lb/>( <lb/>). <lb/>[ ] G. M. Torrie and J. P. Valleau, Chem. Phys. Lett. , <lb/>( <lb/>). <lb/>[ ] T. S. van Erp and P. G. Bolhuis, J. Comput. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] W.-N. Du, K. A. Marino, and P. G. Bolhuis, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] W. Du and P. G. Bolhuis, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] F. Noe, D. Krachtus, J. Smith, and S. Fischer, J. Chem. Theor. <lb/>Comput. , <lb/>( <lb/>). <lb/>[ ] D. Minh and J. Chodera, JCP <lb/>, <lb/>( <lb/>). <lb/>[ ] W.-N. Du and P. G. Bolhuis, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] N. G. van Kampen, Stochastic processes in physics and chem-<lb/>istry, nd ed. (Elsevier, ADDRESS, <lb/>). <lb/>[ ] F. Noé, C. Schütte, E. Vanden-Eijnden, L. Reich, and T. R. Weikl, <lb/>Proceedings of the National Academy of Sciences <lb/>, <lb/>( <lb/>). <lb/>[ ] P. G. Bolhuis and C. Dellago, Eur. Phys. J. ST <lb/>, <lb/>( <lb/>). <lb/>[ ] P. Bolhuis, Proc. Nat. Acad. Sci. USA <lb/>, <lb/>( <lb/>). <lb/>[ ] J. Vreede, J. Juraszek, and P. G. Bolhuis, Proc. Nat. Acad. Sci. <lb/>USA <lb/>, <lb/>( <lb/>). <lb/>[ ] Z. F. Brotzakis and P. G. Bolhuis, to be published ( <lb/>). <lb/>[ ] T. van Erp, Phys. Rev. Lett. , <lb/>( <lb/>). <lb/>[ ] P. G. Bolhuis, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] T. S. van Erp, Adv. Chem. Phys. <lb/>, ( <lb/>). <lb/>[ ] D. W. H. Swenson and P. G. Bolhuis, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] R. Cabriolu, K. M. S. Refsnes, P. G. Bolhuis, and T. S. van Erp, J. <lb/>Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] A. P. Lyubartsev, A. A. Martsinovski, S. V. Shevkunov, and P. N. <lb/>Vorontsov-Velyaminov, J. Chem. Phys. , <lb/>( <lb/>). <lb/>[ ] Z. Tan, J. Comput. Graph. Stat. , ( <lb/>). <lb/>[ ] A. C. Newton, J. Groenewold, W. K. Kegel, and P. G. Bolhuis, <lb/>Proc. Nat. Acad. Sci. USA <lb/>, <lb/>( <lb/>). <lb/>[ ] P. Eastman, M. S. Friedrichs, J. D. Chodera, R. J. Radmer, C. M. <lb/>Bruns, J. P. Ku, K. A. Beauchamp, T. J. Lane, L.-P. Wang, D. <lb/>Shukla, T. Tye, M. Houston, T. Stich, C. Klein, M. R. Shirts, and <lb/>V. S. Pande, J. Chem. Theory Comput. , <lb/>( <lb/>). <lb/>[ ] D. van der Spoel, E. Lindahl, B. Hess, G. Groenhof, A. E. Mark, <lb/>and H. J. C. Berendsen, J. Comput. Chem. , <lb/>( <lb/>). <lb/>[ ] B. Hess, C. Kutzner, D. van der Spoel, and E. Lindahl, J. Comput. <lb/>Theory Chem. , <lb/>( <lb/>). <lb/>[ ] S. Plimpton, Journal of Computational Physics <lb/>, ( <lb/>). <lb/>[ ] G. A. Tribello, M. Bonomi, D. Branduardi, C. Camilloni, and G. <lb/>Bussi, Computer Physics Communications <lb/>, <lb/>( <lb/>). <lb/>[ ] F. Noé and C. Clementi, Current Opinion in Structural Biology <lb/>, <lb/>( <lb/>). <lb/>[ ] R. T. McGibbon, K. A. Beauchamp, M. P. Harrigan, C. Klein, J. M. <lb/>Swails, C. X. Hernández, C. R. Schwantes, L.-P. Wang, T. J. Lane, <lb/>and V. S. Pande, Biophysical Journal <lb/>, <lb/>( <lb/>). <lb/>[ ] K. A. Beauchamp, G. R. Bowman, T. J. Lane, L. Maibaum, I. S. <lb/>Haque, and V. S. Pande, J. Chem. Theory Comput. , <lb/>( <lb/>). <lb/>[ ] M. P. Harrigan, M. M. Sultan, C. X. Hernández, B. E. Husic, P. <lb/>Eastman, C. R. Schwantes, K. A. Beauchamp, R. T. McGibbon, <lb/>and V. S. Pande, Biophysical Journal <lb/>, ( <lb/>). <lb/>[ ] M. K. Scherer, B. Trendelkamp-Schroer, F. Paul, G. Pérez-<lb/>Hernández, M. Ho mann, N. Plattner, C. Wehmeyer, J.-H. Prinz, <lb/>and F. Noé, J. Chem. Theory Comput. , <lb/>( <lb/>). <lb/>[ ] W. L. Jorgensen, J. Chandrasekhar, J. D. Madura, R. W. Impey, <lb/>and M. L. Klein, The Journal of Chemical Physics , <lb/>( <lb/>). <lb/>[ ] P. A. Kollman, Accounts of Chemical Research , <lb/>( <lb/>). <lb/>[ ] J. D. Chodera, W. C. Swope, J. W. Pitera, and K. A. Dill, Multiscale <lb/>Modeling &amp; Simulation , <lb/>( <lb/>). <lb/>[ ] J.-H. Prinz, J. D. Chodera, V. S. Pande, W. C. Swope, J. C. Smith, <lb/>and F. Noé, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] D. A. Sivak, J. D. Chodera, and G. E. Crooks, J. Phys. Chem. B <lb/>, <lb/>( <lb/>). <lb/>[ ] P. G. Bolhuis, C. Dellago, and D. Chandler, Proc. Natl. Acad. Sci. <lb/>, <lb/>( <lb/>). <lb/>[ ] P. G. Bolhuis and C. Dellago, The European Physical Journal <lb/>Special Topics <lb/>, <lb/>( <lb/>). <lb/>[ ] H. Nguyen, D. A. Case, and A. S. Rose, Bioinformatics btx <lb/>( <lb/>). <lb/>[ ] B. Leimkuhler and C. Matthews, J. Chem. Phys. <lb/>, <lb/>( <lb/>). <lb/>[ ] M. Shirts, Science <lb/>, <lb/>( <lb/>). <lb/>[ ] K. Lindor -Larsen, S. Piana, R. O. Dror, and D. E. Shaw, Science <lb/>, <lb/>( <lb/>). <lb/>[ ] B. Isralewitz, M. Gao, and K. Schulten, Current Opinion in Struc-<lb/>tural Biology , <lb/>( <lb/>). <lb/>[ ] G. Henkelman and H. Jónsson, The Journal of Chemical <lb/>Physics <lb/>, <lb/>( <lb/>). <lb/>[ ] W. E, W. Ren, and E. Vanden-Eijnden, The Journal of Physical <lb/>Chemistry B <lb/>, <lb/>( <lb/>). </listBibl>


	</text>
</tei>
