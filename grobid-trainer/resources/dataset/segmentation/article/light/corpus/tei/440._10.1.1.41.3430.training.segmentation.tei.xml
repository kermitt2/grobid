<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="_0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Planning and Proof Planning <lb/>Erica Melis 1 and Alan Bundy 2 <lb/>Abstract. The paper adresses proof planning as a specific AI plan-<lb/>ning. It describes some peculiarities of proof planning and discusses <lb/>some possible cross-fertilization of planning and proof planning. <lb/></front>

			<body>1 Introduction <lb/>Planning is an established area of Artificial Intelligence (AI) whereas <lb/>proof planning introduced by Bundy in [2] still lives in its childhood. <lb/>This means that the development of proof planning needs maturing <lb/>impulses and the natural questions arise `What can proof planning <lb/>learn from its Big Brother planning?&apos; and `What are the specific char-<lb/>acteristics of the proof planning domain that determine the answer?&apos; . <lb/>In turn for planning, the analysis of approaches points to a need of <lb/>mature techniques for practical planning. Drummond [8], e.g., an-<lb/>alyzed approaches with the conclusion that the success of Nonlin, <lb/>SIPE, and O-Plan in practical planning can be attributed to hierar-<lb/>chical action expansion, the explicit representation of a plan&apos;s causal <lb/>structure, and a very simple form of propositional resource allocation <lb/>rather than to &quot;precondition achievement&quot; which is the predominant <lb/>formulation of planning in the AI community. Therefore the tech-<lb/>niques of proof planning that succeeded so far might be of interest <lb/>for other application areas and problem classes. <lb/>To provide a feeling, under which conditions approaches or tech-<lb/>niques from proof planning can be adopted for planning in realistic <lb/>environments, we discuss some important features of the proof plan-<lb/>ning domain. In order to contribute to a cross-fertilization of AI <lb/>planning and proof planning, we briefly describe lessons that can <lb/>be learned from planning or proof planning.. This paper extends a <lb/>description given in [3]. <lb/>2 Proof Planning <lb/>While humans can cope with long and complex proofs and have <lb/>strategies to avoid less promising proof paths, automated theorem <lb/>proving suffers from exhaustive search in super-exponential search <lb/>spaces. Some empirical sources [19, 9] provide evidence that math-<lb/>ematicians use specific methods (e.g. diagonalization), intelligently <lb/>guide the search for proofs, and plan a proof during the proof discov-<lb/>ery process. E.g., the German mathematician Faltings, who proved <lb/>Mordell&apos;s Conjecture, described in [9] that &quot;We know from experience <lb/>that certain inferences are usually successful under certain prerequi-<lb/>sites. So first we ponder about a reasonable way to proceed to prove <lb/>the theorem. In other words, we roughly plan: If we get a certain <lb/>result the next result will follow and then the next etc. Afterwards we <lb/>have to fill in the details, and to check whether the plan really works.&quot; <lb/></body>

			<front>1 Universität des Saarlandes, Fachbereich Informatik, D-66041 Saarbrücken, <lb/>Germany. email: melis@cs.uni-sb.de <lb/>2 University of Edinburgh, Dept. of AI 80 South Bridge, Edinburgh EH1 1HN, <lb/>UK. email: bundy@aisb.ed.ac.uk <lb/></front>

			<body>These insights make proof planning intriguing for interactive as well <lb/>as for automated theorem proving. <lb/>Bundy [2] and his group in Edinburgh pioneered proof planning as <lb/>a technique that can be considered AI-planning and that employs <lb/>an intelligent guidance of proofs. This work resulted in the proof <lb/>planner C L A M [22] that plans proofs by mathematical induction and <lb/>that performs little average search. <lb/>Proof planning contrast with the more local heuristics which have pre-<lb/>viously been used for search control (in automated theorem proving). <lb/>That is, instead of making separate decisions at each choice point of <lb/>proving at the (low) level of logical inferences, based on local clues, <lb/>proof planning has some sense of the overall direction of the proof. <lb/>The global search control is achieved by joining two roads, (1) the <lb/>use of tactics and (2) meta-level control: <lb/>1. As opposed to traditional automated theorem that applies calculus-<lb/>level inference rules, i.e. low level inferences, proof planning relies <lb/>on tactics [10]. Tactics are procedures that produce a (not neces-<lb/>sarily fixed) sequence of lower level inferences when executed, for <lb/>instance a sequence of logical inferences at the calculus-level. Pre-<lb/>viously, tactics have already been employed in several interactive <lb/>theorem provers, e.g. Nuprl [6]. <lb/>In order to enable a combination of tactical theorem proving with <lb/>meta-level control, Bundy [2] introduced methods as (partial) spec-<lb/>ifications of tactics that specify in a meta-language the precondi-<lb/>tions and effects of its application 3 . In Figure 1 the structure of <lb/>C L A M &apos;s methods is depicted. The methods serve as planning op-<lb/>erators whose application yields the sequents from the output slot <lb/>as subgoals. These preconditions contain control knowledge. They <lb/>name: <lb/>Prolog term <lb/>input: <lb/>sequent H==&gt;G, H set of hypotheses, G goal <lb/>precondition: list of conjuncts in meta-level language <lb/>postcondition: list of conjuncts in meta-level language <lb/>output: <lb/>list of sequents <lb/>tactic: <lb/>Prolog term <lb/>Figure 1. The method data structure in CL A M. <lb/>describe in a meta-language (1) syntactic properties of object-level <lb/>expressions (sequents and formulas) E that are subgoals or ele-<lb/>ments of the initial state (definitions or axioms) or (2) abstract <lb/>properties of these expressions that emerge from annotations to <lb/></body>

			<note place="footnote">3 Note that these preconditions and effects of the methods in CL A Mdenote <lb/>things different from input and output which consist of sequents. Sequents <lb/>are of the form ∆ `F , where ∆ is a set of formulas and F is a formula. <lb/></note>

			<body>E. An example of the first kind of preconditions is &quot;E has a <lb/>free variable&quot;. An example of the second kind of preconditions is <lb/>&quot;There is a recorded definition R of the form (lhs -&gt; rhs) such <lb/>that the annotated lhs matches a subexpression of the annotated <lb/>E while preserving the annotations.&quot; <lb/>2. The meta-level control came into play by (a) recognizing common <lb/>proof plan patterns in families of proofs, for instance in proofs by <lb/>mathematical induction or in diagonalization proofs, and by (b) <lb/>discovering abstract goals and abstract heuristics that can guide <lb/>the search for proofs. <lb/>(a) Proofs by mathematical induction 4 reveal a common general <lb/>structure displayed in Figure 2. This pattern is roughly to first <lb/>Base case <lb/>Symbolic evaluation <lb/>Simplification <lb/>Tautology checking <lb/>Step case <lb/>Induction <lb/>Fertilization <lb/>Rippling <lb/>Figure 2. Structure of proofs by mathematical induction <lb/>find an appropriate induction schema and then to prove the con-<lb/>jecture for the base case, e.g., for n = 0, and for the step case, <lb/>where the conjecture for a &quot;successor&quot; of the induction variable, <lb/>e.g. of n, (called the induction conclusion) is proved provided <lb/>the conjecture for the induction variable itself (which is called <lb/>the induction hypothesis) holds. The step case pattern includes <lb/>some kind of &quot;fertilization&quot;, i.e., of applying the induction hy-<lb/>pothesis to a rewritten induction conclusion such that a true <lb/>formula results. <lb/>The rewriting is subject to the abstract heuristic rippling de-<lb/>scribed next. <lb/>(b) A meta-level goal in the step case is to reduce the differences <lb/>between induction conclusion and induction hypothesis in order <lb/>to enable a final fertilization. These differences are represented <lb/>by annotations, e.g., colours, to the induction conclusion. Ax-<lb/>ioms and definitions that belong to the initial state and which <lb/>can be used to reduce the differences are annotated similarly. <lb/>The abstract search heuristic for proofs by mathematical induc-<lb/>tion, rippling, was introduced by Bundy [2] and Hutter [12]. <lb/>It describes a systematic way to remove the differences, for <lb/>example by moving the differences outward until the induc-<lb/>tion hypothesis can be applied to an inner part of the rewritten <lb/>induction conclusion. For example, in proving the conjecture <lb/>8x; y; z: x + (y + z) = (x + y) + z <lb/>(1) <lb/></body>

			<note place="footnote">4 Mathematical induction is a generalization of the well known pattern <lb/>of Peano induction over natural numbers that has the induction schema <lb/>P(0);8k(P(k)!P(k+1)) <lb/>8n(P(n)) <lb/>. <lb/></note>

			<body>the induction hypothesis is <lb/>x + (y + z) = (x + y) + z <lb/>(2) <lb/>and the conclusion is <lb/>s(x) + (y + z) = ( s(x) + y) + z <lb/>(3) <lb/>The boxes, excluding the underlined terms, denote the differ-<lb/>ences. The non-differences are called the skeleton. Rippling <lb/>works by successively applying skeleton preserving definitions <lb/>and axioms to the induction conclusion. A definition of the <lb/>function + is <lb/>s(U ) + V ) s(U + V ) <lb/>(4) <lb/>where the skeleton on each side of the implication is U + V . <lb/>In this example, rippling involves the repeated application of <lb/>(4) which moves the differences outwards until the following <lb/>expression is obtained <lb/>s(x + (y + z)) = s((x + y) + z) <lb/>(5) <lb/>to which the induction hypothesis can be applied. <lb/>C L M &apos;s preconditions and effects of methods allow to plan (to <lb/>reason about) the application of tactics not just by &quot;precondition <lb/>achievement&quot; but supported by the meta-level control provided by <lb/>rippling. In C L A M a proof plan is then built as a tree of methods <lb/>by searching the plan-space. <lb/>Due to the urgently needed search control in theorem proving, proof <lb/>planning became more popular recently. Apart from the system C L A M , <lb/>other experiments explore different ways to realize proof planning. <lb/>For instance, the proof planner of Omega [11] performs state-space <lb/>search. As opposed to C L A M , it prefers more declaratively repre-<lb/>sented methods the output of which is determined by the input. Those <lb/>methods can be subject to reformulations. The method representation <lb/>in Omega allows for different level of goals which naturally leads to <lb/>hierarchical planning. <lb/>The fact that proof plans are an abstract and structured representa-<lb/>tion of proofs makes proof planning and, in particular, proof plans <lb/>attractive for other activities in theorem proving: <lb/>The abstract and structured representation is well-suited for theo-<lb/>rem proving by analogy, as shown in [17]. The structure of a proof <lb/>plan can be exploited when analogically transferring methods and <lb/>subplans. As opposed to analogy at an abstract level, the analogical <lb/>transfer often fails if drawn at the low level of logical inference <lb/>rules. <lb/>For derivational analogy [5, 24, 17], proof plans that store control <lb/>information are needed. <lb/>Proof plans that store control information are also well-suited for <lb/>the explanation of proofs and for user interaction as, e.g., pursued <lb/>in Barnacle [16], an interactive version of C L A M . There, explana-<lb/>tions are extracted from the preconditions of C L A M &apos;s methods. <lb/>As demonstrated in [15], a structured presentation of a proof has <lb/>proved very important for the human understanding of proofs and <lb/>is, therefore, needed for proof presentation and interactive theorem <lb/>proving. <lb/>3 Properties of Proof Planning <lb/>Proof planning is a specific plan formation in the &quot;precondition <lb/>achievement&quot; sense of AI-planning, and as an experiment the au-<lb/>thor has implemented a simple theorem proving domain in Prodigy. <lb/>Specific characteristics of this &quot;domain&quot; are: <lb/>The objects are (mathematical) objects such as numbers, lists, or <lb/>trees and actions are manipulations of formulas describing objects <lb/>and their relations and functions. <lb/>Formal mathematical proofs which theorem proving aims at, are <lb/>often long and very complex and even proof plans can be very deep. <lb/>Therefore the need to represent bigger chunks by a planning op-<lb/>erator and to understand a proof plan as an abstract representation <lb/>of a proof. <lb/>Goal interaction which is a major issue for plan formation in <lb/>general and led to the development of partial order planning [21, <lb/>20]. In proof planning there is no goal interaction in the original <lb/>object-level sense because the application of a sequence of logical <lb/>inference rules does not destroy object-level preconditions. <lb/>The acquisition of methods and of control knowledge for mathe-<lb/>matical domains is difficult. It took, for instance, quite some time <lb/>to polish C L A M &apos;s methods that at first simulated procedures from <lb/>the Nqthm theorem prover. Now C L A M gets a long way with few <lb/>methods for planning inductive proofs. We expect the acquisition <lb/>of control knowledge and methods to be a major research problem <lb/>for mathematical domains. <lb/>In proof planning, the knowledge about the mathematical world <lb/>is complete and certain rather than incomplete and uncertain as in <lb/>many real world applications of planning. <lb/>4 Lessons from Planning and Proof Planning <lb/>As Weld [25] summarizes, in planning, knowledge-based search via <lb/>a miniature production system turned out to be a good idea. Usually, <lb/>these rules refer to local decisions. They can, however, also express <lb/>control knowledge referring to the global development of a plan. <lb/>First, in SOAR [14] such a control was explored and in the Prodigy <lb/>system [18] the ideas were refined. Such a control is also described in <lb/>[1]. Meta-level control-rules can be found in Press [4]. In Prodigy the <lb/>control-rules contain meta-predicates that refer to the current state, <lb/>the sequence of operators, etc. The experiences with a separate body <lb/>of control-rules in Prodigy are summarized in [23]: The advantage of <lb/>the factual-control knowledge distinction are modularity, reification <lb/>of the control knowledge, selectivity in building learning modules, <lb/>and compositionality of the acquired control knowledge. In SOAR <lb/>and Prodigy matching algorithms and data structures have been de-<lb/>veloped to cope efficiently with many control-rules (see [7]). These <lb/>experiences can help to design proof planning systems that make use <lb/>of the advantages mentioned. <lb/>Currently, the most interesting feature of proof planning that could <lb/>fertilize planning seems to be that abstract goals are pursued by heuris-<lb/>tics expressed in a meta-language. In particular, the abstract control <lb/>knowledge might be of interest for planning in real environments. <lb/>The design of meta-predicates that capture proof-relevant abstrac-<lb/>tions, e.g., those involved in rippling, gives an additional means of <lb/>control and thus, adds to the power of the proof planner. Thereby <lb/>proof planning becomes more than pure precondition achievement. <lb/>Macro-operators as investigated in [13] are a first step towards plan <lb/>patterns and therefore of interest for proof planning. They correspond <lb/>to fixed patterns of (sub)plans. For proof planning, however, we need <lb/>to find even more flexible patterns in order to structure a proof as the <lb/>experience with proofs by mathematical induction shows. In C L A M , <lb/>an iteration over several submethods can provide a flexible pattern <lb/>represented by a supermethod. This idea might help in planning to <lb/>obtain plan patterns/macros that can be expanded flexibly. <lb/>Some clever hierarchical planning is needed in proof planning. So far, <lb/>two different techniques for hierarchical planning are used. C L A M <lb/>realizes hierarchical planning by flexibly expanding (super)methods <lb/>to a sequence of (sub)methods from a subset of methods. The output <lb/>of a super-method is determined by applying the submethods. In <lb/>Omega hierarchical planning is realized by explicitly marking less <lb/>relevant proof obligations (subgoals) that can be planned for in the <lb/>next lower hierarchical level. This will be amended by meta-level <lb/>criteria for distingishing the hierarchy levels. <lb/></body>

			<listBibl>REFERENCES <lb/>[1] A. Barrett, K. Golden, J.S. Penberthy, and D. Weld, USPOP User&apos;s <lb/>Manual, Version 2.0, Dept.of Computer Science and Engineering, Uni-<lb/>versity of Washington, 1993. Technical Report 93-09-06. <lb/>[2] A. Bundy, `The use of explicit plans to guide inductive proofs&apos; , in Proc. <lb/>9th International Conference on Automated Deduction (CADE), eds., <lb/>E. Lusk and R. Overbeek, volume 310 of Lecture Notes in Computer <lb/>Science, pp. 111-120, Argonne, (1988). Springer. <lb/>[3] A. Bundy, `Proof planning&apos; , in Proceedings of the International Con-<lb/>ference on Planning 1996 (AIPS-96, (1996). <lb/>[4] A. Bundy and B. Welham, `Using meta-level inference for selective ap-<lb/>plication of multiple rewrite rules in algebraic manipulation&apos; , Artificial <lb/>Intelligence, 16(2), 189-212, (1981). Also available from Edinburgh as <lb/>DAI Research Paper 121. <lb/>[5] J.G. Carbonell, `Derivational analogy: A theory of reconstructive prob-<lb/>lem solving and expertise acquisition&apos; , in Machine Learning: An Arti-<lb/>ficial Intelligence Approach, eds., R.S. Michalsky, J.G. Carbonell, and <lb/>T.M. Mitchell, 371-392, Morgan Kaufmann Publ., Los Altos, (1986). <lb/>[6] R.L. Constable, S.F. Allen, H.M. Bromley, W.R. Cleaveland, J.F. Cre-<lb/>mer, R.W. Harper, D.J. Howe, T.B. Knoblock, N.P. Mendler, P. Pana-<lb/>gaden, J.T. Sasaki, and S.F. Smith, Implementing Mathematics with the <lb/>Nuprl Proof Development System, Prentice Hall, Englewood Cliffs, New <lb/>Jersey, 1986. <lb/>[7] R.B. Doorenbos, Production Matching for Large Learning Systems, <lb/>Ph.D. dissertation, Computer Science Department, Carnegie Mellon <lb/>University, January 1995. <lb/>[8] M. Drummond, `On precondition achievement and the computational <lb/>economics of automatic planning&apos; , in Current Trends in AI Planning, <lb/>6-13, IOS Press, (1994). <lb/>[9] G. Faltings and U. Deker, `Interview: Die Neugier, etwas ganz genau <lb/>wissen zu wollen&apos; , bild der wissenschaft, (10), 169-182, (1983). <lb/>[10] M. Gordon, R. Milner, and C.P. Wadsworth, Edinburgh LCF: A Mech-<lb/>anized Logic of Computation, Lecture Notes in Computer Science 78, <lb/>Springer, Berlin, 1979. <lb/>[11] X. Huang, M. Kerber, M. Kohlhase, E. Melis, D. Nesmith, J. Richts, and <lb/>J. Siekmann, `Omega-MKRP: A Proof Development Environment&apos; , in <lb/>Proc. 12th International Conference on Automated Deduction (CADE), <lb/>Nancy, (1994). <lb/>[12] D. Hutter, `Guiding inductive proofs&apos; , in Proc. of 10th International <lb/>Conference on Automated Deduction (CADE), ed., M.E. Stickel, volume <lb/>Lecture Notes in Artificial Intelligence 449. Springer, (1990). <lb/>[13] R.E. Korf, `Macro-operators: A weak method for learning&apos; , Artificial <lb/>Intelligence, 26, 35-77, (1985). <lb/>[14] J Laird, A. Newell, and P. Rosenbloom, `SOAR:an architecture for <lb/>general intelligence&apos; , Artificial Intelligence, 33(1), 1-64, (1987). <lb/>[15] U. Leron, `Structuring mathematical proofs&apos; , The American Mathemat-<lb/>ical Monthly, 90, 174-185, (1983). <lb/>[16] H. Lowe, A. Bundy, and D. McLean, `The use of proof planning for co-<lb/>operative theorem proving&apos; , Research Paper 745, (1995). Submitted to <lb/>the special issue of the Journal of Symbolic Computation on graphical <lb/>user interfaces and protocols. <lb/>[17] E. Melis, `A model of analogy-driven proof-plan construction&apos; , in Pro-<lb/>ceedings of the 14th International Joint Conference on Artificial Intel-<lb/>ligence, pp. 182-189, Montreal, (1995). <lb/>[18] S. Minton, C. Knoblock, D. Koukka, Y. Gil, R. Joseph, and J. Carbonell, <lb/>PRODIGY 2.0: The Manual and Tutorial, School of Computer Science, <lb/>Carnegie Mellon University, Pittsburgh, 1989. CMU-CS-89-146. <lb/>[19] G. Polya, How to Solve it, 2nd ed. Doubleday, New York, 1957. <lb/>[20] E.D. Sacerdoti, `The nonlinear nature of plans&apos; , in Proceedings of the <lb/>Fourth International Joint Conference on Artificial Intelligence (IJCAI-<lb/>75), pp. 206-214, (1975). <lb/>[21] A. Tate, `Generating project networks&apos; , in Proceedings of the Fifth <lb/>International Joint Conference on Artificial Intelligence, pp. 888-893. <lb/>Morgan Kaufmann, (1977). <lb/>[22] F. van Harmelen, A. Ireland, S.Negrete, A. Stevens, and A. Smaill, `The <lb/>CLAM proof planner, user manual and programmers manual&apos; , Technical <lb/>Report version 2.0, University of Edinburgh, Edinburgh, (1993). <lb/>[23] Manuela Veloso, Jaime Carbonell, M. Alicia Pérez, Daniel Borrajo, <lb/>Eugene Fink, and Jim Blythe, `Integrating planning and learning: The <lb/>PRODIGY architecture&apos; , Journal of Experimental and Theoretical Ar-<lb/>tificial Intelligence, 81-120, (1995). <lb/>[24] M.M. Veloso, Planning and Learning by Analogical Reasoning, <lb/>Springer, Berlin, New York, 1994. <lb/>[25] D.S. Weld, `An introduction to least commitment planning&apos; , AI maga-<lb/>zine, 15(4), 27-61, (1994). </listBibl>


	</text>
</tei>
