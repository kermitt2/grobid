<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="_0"/>
	</teiHeader>
	<text xml:lang="en">
			<titlePage>Finite State Machines and Recurrent Neural Networks { <lb/>Automata and Dynamical Systems Approaches <lb/>Peter Ti no a;c , Bill G. Horne c , C. Lee Giles c;d , Pete C. Collingwood b <lb/>a Department of Computer Science and <lb/>Engineering <lb/>Slovak Technical University <lb/>Ilkovicova 3, 812 19 Bratislava, Slovakia <lb/>Email: tino@decef.elf.stuba.sk <lb/>b School of Computing &amp; Man. Sci. <lb/>She eld Hallam University <lb/>Hallam Business Park <lb/>100 Napier St., She eld, S11 8HD, UK <lb/>Email: p.c.collingwood@shu.ac.uk <lb/>c NEC Research Institute <lb/>4 Independence Way <lb/>Princeton, NJ 08540 <lb/>Email: <lb/>ftino,horne,gilesg@research.nj.nec.com <lb/>d Institute for Advanced Computer Studies <lb/>University of Maryland <lb/>College Park, MD 20742 <lb/>Technical Report <lb/>UMIACS-TR-95-1 and CS-TR-3396 <lb/>Institute for Advanced Computer Studies <lb/>University of Maryland <lb/>College Park, MD 20742 <lb/></titlePage>

			<page>1 <lb/></page>

			<front>Finite State Machines and Recurrent Neural Networks { <lb/>Automata and Dynamical Systems Approaches <lb/>Peter Ti no a;c , Bill G. Horne c , C. Lee Giles c;d , Pete C. Collingwood b <lb/>a Department of Computer Science and Engineering <lb/>Slovak Technical University <lb/>Ilkovicova 3, 812 19 Bratislava, Slovakia <lb/>Email: tino@decef.elf.stuba.sk <lb/>b School of Computing &amp; Man. Sci. <lb/>She eld Hallam University <lb/>Hallam Business Park <lb/>100 Napier St., She eld, S11 8HD, UK <lb/>Email: p.c.collingwood@shu.ac.uk <lb/>c NEC Research Institute <lb/>4 Independence Way <lb/>Princeton, NJ 08540 <lb/>Email: <lb/>ftino,horne,gilesg@research.nj.nec.com <lb/>d Institute for Advanced Computer Studies <lb/>University of Maryland <lb/>College Park, MD 20742 <lb/>Abstract <lb/>We present two approaches to the analysis of the relationship between a recurrent neural <lb/>network (RNN) and the nite state machine M the network is able to exactly mimic. First, <lb/>the network is treated as a state machine and the relationship between the RNN and M is <lb/>established in the context of algebraic theory of automata. In the second approach, the RNN <lb/>is viewed as a set of discrete-time dynamical systems associated with input symbols of M. In <lb/>particular, issues concerning network representation of loops and cycles in the state transition <lb/>diagram of M are shown to provide a basis for the interpretation of learning process from the <lb/>point of view of bifurcation analysis. The circumstances under which a loop corresponding <lb/>to an input symbol x is represented by an attractive xed point of the underlying dynamical <lb/>system associated with x are investigated. For the case of two recurrent neurons, under some <lb/>assumptions on weight values, bifurcations can be understood in the geometrical context of <lb/>intersection of increasing and decreasing parts of curves de ning xed points. The most typical <lb/>bifurcation responsible for the creation of a new xed point is the saddle node bifurcation. <lb/></front>

			<body>1 Introduction <lb/>The relationship between recurrent neural networks (RNN) and automata has been treated by <lb/>many 29], 26], 8], 10], 15], 17], 5], 38], 39], 28], 11], 23]. State units&apos; activations represent <lb/>past histories and clusters of these activations can represent the states of the generating automaton <lb/>18]. <lb/>In this contribution, the relationship between a RNN and a nite state machine it exactly mimics <lb/>is investigated from two points of view. First (section 5), the network is treated as a state machine. <lb/>The concept of state equivalence is used to reduce the in nite, non-countable set of network states <lb/>(activations of RNN state neurons) to a nite factor state set corresponding to the set of states of <lb/>M. Second (section 6), the RNN is viewed as a set of discrete-time dynamical systems associated <lb/>with input symbols of M. The dynamical systems operate on (0; 1) L , where L is the number <lb/>of recurrent neurons of the RNN. In our experiments, loops and cycles corresponding to an input <lb/>symbol x of M have stable representation as attractive xed points and periodic orbits respectively <lb/>of the dynamical system associated with the input x. Suppose there is a loop associated with an <lb/>input x in a state q of M. Denote the set of network states equivalent to q by (q) N . Then, if there <lb/>is a vertex v 2 f0; 1g L such that v is in the closure of (q) N , the loop is likely to be represented by <lb/>an attractive xed point 1 \near&quot; v. <lb/>A related work was independently done by Casey 5], 6]. In his setting, RNN is assumed to <lb/>operate in a noisy environment (representing for example a noise corresponding to round-o errors <lb/>in computations performed on a digital computer). RNNs are trained to perform grammatical <lb/>inference. It is proved that a presence of a loop in the state transition diagram of the automaton <lb/>2 necessarily implies the presence of an attractive set inside RNN state space (see the discussion <lb/>in section 6). It is also shown that the method for extraction of an automaton from a trained <lb/>RNN introduced in 17] is consistent: the method is based on dividing RNN state space into equal <lb/>hypercubes and there is always a nite number of hypercubes one needs to unambiguously cover <lb/>regions of equivalent network states. <lb/>In section 7 a more detailed analysis of the case when RNN has two state neurons is presented. <lb/></body>

			<note place="footnote">1 of the corresponding dynamical system <lb/></note>

			<note place="footnote">2 recognizing the same language as the RNN <lb/></note>

			<page>1 <lb/></page>

			<body>Under some conditions on weight values, the number, position and stability types of xed points of <lb/>the underlying dynamical systems are analyzed and bifurcation mechanism is clari ed. The most <lb/>typical bifurcation responsible for the creation of a new xed point as the saddle node bifurcation. A <lb/>mechanism of correct behaviour of RNN for short input strings, when for long strings, the network <lb/>is known to generalize poorly is investigated in section 8. In such cases, a correct state transition <lb/>diagram of a FSM the network was trained with can still be extracted 17]. A tool called the <lb/>state degradation diagram is developed to illustrate how regions of network state space, initially <lb/>acting as if they assumed the role of states of the FSM in which there is a loop associated with an <lb/>input symbol x, gradually degradate upon repeated presentation of x. Sections 2 and 3 bring brief <lb/>introductions to state machines and dynamical systems respectively. Section 4 is devoted to the <lb/>model of RNN 31] used for learning FSMs. <lb/>2 State Machines <lb/>This section introduces the concept of state machine, which is a generalized nite state machine <lb/>with possibly uncountable number of states. When viewed as automata, RNNs can be described <lb/>in terms of state machines. <lb/>A state machine (SM) is a 6-tuple M=(X; Y; S; f s ; f o ; s 0 ), where <lb/>X is a nonempty nite set called the input set <lb/>Y is a nonempty nite set called the output set <lb/>S is a nonempty set called the set of internal states <lb/>f s is a map f s : S X ! S called the next-state function <lb/>f o is a map f o : S X ! Y called the output function <lb/>s 0 2S is called the initial state <lb/>SMs with a nite internal state set are called nite state machines (FSMs). <lb/>We assume that the reader is familiar with the notion of monoid of words over a nite set. <lb/>Following the standard notation, ; X ; X + and uv denote the empty word, the set of all words <lb/>over X, the set of all nonempty words over X, and concatenation of words u and v respectively. <lb/></body>

			<page>2 <lb/></page>

			<body>In every moment M is in exactly one state s 2 S. When an element x 2 X is read in, the <lb/>machine changes its state to f s (s; x) and yields the output f o (s; x). The processing of any input <lb/>word w2X + by M always starts with M being in the initial state. <lb/>If for some x 2 X and s 2 S, it holds f s (s; x) = s, then it is said that there is an x-loop in the <lb/>state s. If there exist m (m 2) distinct states s 1 ; :::; s m 2 S and an input x 2 X, such that <lb/>f s (s i ; x) = s i+1 ; for all i = 1; :::; m ? 1 and f s (s m ; x) = s 1 ; then the set fs 1 ; :::; s m g is said to be <lb/>an x-cycle of length m passing through the states s 1 ; :::; s m . <lb/>It is convenient to extend the domain of f s and f o from S X to S X and S X + respectively: <lb/>8s2S; f s (s; )=s; <lb/>8s2S; 8w2X ; 8x2X; f s (s; wx)=f s (f s (s; w); x) and f o (s; wx)=f o (f s (s; w); x): <lb/>Yet further generalization of f o is useful: <lb/>8s2S; 8w=x 1 x 2 :::x n 2X + ; f + <lb/>o (s; w)=f o (s; x 1 )f o (s; x 1 x 2 ):::f o (s; x 1 x 2 :::x n ): <lb/>A distinguishing sequence of M is a word w 2 X + such that there are no two states s 1 ; s 2 of M <lb/>for which f + <lb/>o (s 1 ; w) = f + <lb/>o (s 2 ; w). <lb/>The behaviour of M is a map B M :X + !Y : 8w2X + ; B M (w)=f o (s 0 ; w): <lb/>A state s 2 2S is said to be accessible and x-accessible from the state s 1 2S if there exists some <lb/>w 2 X and w 2 fxg respectively, such that s 2 = f s (s 1 ; w). M is said to be connected if every <lb/>state s 2 S is accessible from s 0 . The set of all states that are x-accessible from a state s 2 S is <lb/>denoted by Acc(x; s). An x-cycle = fs 1 ; :::; s m g is said to be x-accessible from a state p 2 S, if <lb/>Acc(x; p). <lb/>An input word w 2 X is leading to a state q if f s (s 0 ; w) = q. An input word leading to q is <lb/>minimal if there is no input word leading to q of shorter length. <lb/>We shall also need some concepts concerning state and machine equivalence. Let M i = <lb/>(X; Y; S i ; f i <lb/>s ; f i <lb/>o ; s 0i ); i = 1; 2 be two SMs. States s 1 2 S 1 and s 2 2 S 2 are said to be equivalent <lb/>if there is no non-empty word over X which would cause M 1 to give di erent output from that <lb/>given by M 2 , provided M 1 and M 2 started from s 1 and s 2 respectively. This is formally represented <lb/>by the equivalence relation E(M 1 ; M 2 ) S 1 S 2 : <lb/>(s 1 ; s 2 )2E(M 1 ; M 2 ) i 8w2X + ; f 1 <lb/>o (s 1 ; w)=f 2 <lb/>o (s 2 ; w): <lb/></body>

			<page>3 <lb/></page>

			<body>The set fp 2 S 2 j(q; p) 2 E(M 1 ; M 2 )g of all states of M 2 that are equivalent to a state q 2 S 1 of <lb/>M 1 is denoted by q] E(M 1 ;M 2 ) . When M 1 =M 2 =M, the equivalence relation E(M; M) partitions <lb/>the state set S of M into the set of disjoint equivalence classes S=E(M; M). <lb/>M 1 and M 2 are said to be equivalent if for every state s 1 2S 1 there exists a state s 2 2S 2 such <lb/>that (s 1 ; s 2 )2E(M 1 ; M 2 ), and vice-versa. If there exists a bijection b S : S 1 ! S 2 satisfying: <lb/>8s2S 1 ; 8x2X; b S (f 1 <lb/>s (s; x))=f 2 <lb/>s (b S (s); x) and f 1 <lb/>o (s; x)=f 2 <lb/>o (b S (s); x) <lb/>b S (s 1 0 )=s 2 0 ; <lb/>then M 1 and M 2 are said to be isomorphic. Isomorphic SMs can be considered identical since <lb/>they di er only in names of states. <lb/>An SM is said to be reduced if no two of its states are equivalent to each other. Reduced SM <lb/>equivalent to M=(X; Y; S; f s ; f o ; s 0 ) is (X; Y; S=E(M; M); f 0 <lb/>s ; f 0 <lb/>o ; s 0 ] E(M;M) ), with f 0 <lb/>s : S=E(M; M) <lb/>X !S=E(M; M) and f 0 <lb/>o : S=E(M; M) X + !S=E(M; M) de ned as follows: <lb/>8s2S; 8w2X ; f 0 <lb/>s ( s] E(M;M) ; w)= f s (s; w)] E(M;M) ; <lb/>(1) <lb/>8s2S; 8w2X + ; f 0 <lb/>o ( s] E(M;M) ; w)=f o (s; w): <lb/>(2) <lb/>3 Dynamical Systems <lb/>Analysis of dynamical systems (DSs) via state space structures plays an important role in ex-<lb/>perimenting and interpreting complex systems. Most of the important qualitative behaviors of a <lb/>nonlinear system can be made explicit in the state space with a state space analysis. In this paper <lb/>only discrete-time DSs (i.e. DSs evolving in discrete time) will be considered. Our theoretical <lb/>knowledge about nonlinear DSs is far from complete. The state space of a nonlinear DS often con-<lb/>sists of qualitatively di erent regions. It is useful to take into account the geometric information <lb/>about the structures and spatial arrangements of these regions. <lb/>Among the most important characteristics of a DS are the xed points, periodic orbits, their <lb/>stability types, and the spatial arrangement of the corresponding stability regions. We review some <lb/>of the basic concepts in DS theory. <lb/></body>

			<page>4 <lb/></page>

			<body>A discrete-time DS can be represented as the iteration of a (di erentiable, invertible) function <lb/>f : A ! A (A &lt; n ), i.e. <lb/>x t+1 = f(x t ); t 2 Z; <lb/>(3) <lb/>where Z denotes the set of all integers. For each x 2 A, the iteration (3) generates a sequence <lb/>of distinct points de ning the orbit, or trajectory of x under f. Hence, the (forward) orbit of x <lb/>under f is the set ff m (x)j m 0g. For m 1, f m is the composition of f with itself m times. <lb/>f 0 is de ned to be the identity map on A. <lb/>A point x 2 A is called a xed point of f, if f m (x ) = x , for all m 2 Z. A point x 2 A is a <lb/>periodic point of f, if f q (x ) = x for some q 1. The least such a value of q is called the period <lb/>of the point x and the orbit of x . The set fx ; f(x ); :::; f q?1 (x )g is said to be a periodic orbit <lb/>of x of period q. Notice that a xed point is a periodic point of period one, and a periodic point <lb/>of f with period q is a xed point of f q . If x is a periodic point of period q for f, then so are <lb/>all of the other points in the orbit of x . <lb/>Fixed and periodic points can be classi ed according to the behaviour of the orbits of points in <lb/>their vicinity. A xed point x is said to be asymptotically stable (or an attractive point of f), if <lb/>there exists a neighborhood O(x ) of x , such that lim m!1 f m (x)=x , for all x 2 O(x ). As m <lb/>increases, trajectories of points near to an asymptotically stable xed point tend to it. The basin <lb/>of attraction of an attractive xed point x is the set fx 2 Aj lim m!1 f m (x)=x g: <lb/>A xed point x of f is asymptotically stable only if for each eigenvalue of Df(x ), the <lb/>Jacobian of f at x , j j &lt; 1 holds. The eigenvalues of Df(x ) govern whether or not the map f <lb/>in a vicinity of x has contracting or expanding directions. Eigenvalues larger in absolute value <lb/>than one lead to expansion, whereas eigenvalues smaller than one lead to contraction. If all the <lb/>eigenvalues of Df(x ) are outside the unit circle, x is a repulsive point, or repellor. All points from <lb/>a neighborhood of a repellor move away from it as m increases, or equivalently, move towards it as <lb/>?m decreases 3 . If some eigenvalues of Df(x ) are inside and some are outside the unit circle, x <lb/>is said to be a saddle point. There is a set W s of points x such that the trajectory of x tends to <lb/>x for m ! 1. W s is called the stable invariant manifold of x . Similarly, the unstable invariant <lb/>manifold of x , W u , is the set of points x such that the trajectory of x tends to x for m ! ?1. <lb/></body>

			<note place="footnote">3 f ?m = (f ?1 ) m <lb/></note>

			<page>5 <lb/></page>

			<body>Since any periodic point of period q can be thought of as a xed point of f q , these remarks <lb/>apply to periodic points as well. <lb/>An absorbing set of a set B A under the map f is a set P such that for all x 2 B, there <lb/>exists m 0 0, for which f m (x) 2 P, for all m m 0 . For a given x 2 B, the least such a value of <lb/>m 0 is called the absorption level of x in P under the map f. An absorption region of P under the <lb/>map f is de ned as follows: <lb/>A f (P ) = fx 2 Aj there exists m 0 0; such that f m (x)2P; for all m m 0 g: <lb/>When A &lt;, or A &lt; 2 , it is useful to code with colors (or di erent gray levels) the absorption <lb/>levels of points from A f (P ) in P. We will refer to such a diagram as an absorption diagram of P <lb/>under the map f. <lb/>B A is said to be positively invariant set of f if f(B) B, i.e. trajectories of points from B <lb/>stay in B. Trivially, A is positively invariant set of f, but in an e ort to understand the dynamics of <lb/>(3), we are usually interested in nding as minimal positively invariant set 4 as possible. If B is open <lb/>and 5 f(B) B then the setB = T <lb/>m 0 f m (B) is not only positively invariant, but also attracting, <lb/>meaning that there is a neighborhood ofB such that all orbits starting in that neighborhood <lb/>converge toB. Attractive xed points and periodic orbits are trivial examples of attractive sets. <lb/>Much more complicated attractive sets can be found in dynamical systems literature under the <lb/>name strange attractors 6 12]. As in the case of an attractive xed point, the basin of attraction of <lb/>an attractive setB is the set of all points whose orbits converge toB. <lb/>If B A is positively invariant set of f then it is certainly an absorbing set of itself under f. B <lb/>may be an attracting set of f, or it may contain an attractive set of f 7 , or none of the two 8 . <lb/>To learn more about the theory of DSs, see for example 19]. <lb/></body>

			<note place="footnote">4 in sense of inclusion <lb/></note>

			<note place="footnote">5 B denotes the closure of B <lb/></note>

			<note place="footnote">6 Loosely speaking, strange attractors are attractive sets that are topologically distinct from (i.e. cannot be <lb/>transformed by a homeomorphism to) trivial attractive sets mentioned above. <lb/></note>

			<note place="footnote">7 Note that this does not necessarily imply that B is part of basin of attraction of an attractive set contained in <lb/>B. Think of attractive periodic orbit inside B that encircles a repelling xed point. <lb/></note>

			<note place="footnote">8 Identity map constitutes a simple example <lb/></note>

			<page>6 <lb/></page>

			<body>Figure 1: RNN model used for learning FSMs. <lb/>4 Recurrent Neural Network <lb/>The RNN presented in gure 1 was shown to be able to learn mappings that can be described by <lb/>nite state machines 31]. A binary input vector I (t) = (I (t) <lb/>1 ; :::; I (t) <lb/>N ) corresponds to the activations <lb/>of N input neurons. There are two types of hidden neurons in the network. <lb/>K hidden nonrecurrent neurons H 1 ,...,H K , activations of which are denoted by H (t) <lb/>j ; j = <lb/>1; :::; K. <lb/>L hidden recurrent neurons S 1 ,...,S L , called state neurons. We refer to the activations of <lb/>state neurons by S (t) <lb/>i ; i = 1; :::; L. The vector S (t) = (S (t) <lb/>1 ; :::; S (t) <lb/>L ) is called the state of the <lb/>network. <lb/></body>

			<page>7 <lb/></page>

			<body>W iln ; Q jln and V mk are real-valued weights and g is a sigmoid function g(x) = 1=(1 + e ?x ). The <lb/>activations of hidden nonrecurrent neurons are determined by <lb/>H (t) <lb/>j = g( <lb/>X <lb/>l;n <lb/>Q jln S (t) <lb/>l I (t) <lb/>n ): <lb/>The activations of state neurons at the next time step (t + 1) are computed as follows: <lb/>S (t+1) <lb/>i <lb/>= g( <lb/>X <lb/>l;n <lb/>W iln S (t) <lb/>l I (t) <lb/>n ) = S i (S (t) ; I (t) ): <lb/>(4) <lb/>The output of the network at time t is the vector (O (t) <lb/>1 ; :::; O (t) <lb/>M ) of activations of M output neurons <lb/>O 1 ,...,O M . The network output is determined by <lb/>O (t) <lb/>m = g( <lb/>X <lb/>k <lb/>V mk H (t) <lb/>k ) = O m (S (t) ; I (t) ): <lb/>(5) <lb/>Network states are elements of the L-dimensional open interval (0; 1) L , the internal region of <lb/>the L-dimensional hypercube. <lb/>A unary encoding of symbols of both the input and output alphabets is used with one input <lb/>and one output neuron for each input and output symbol respectively. <lb/>The bijection de ning the encoding of N input symbols into N-dimensional binary vectors with <lb/>just one active bit is denoted by c I . Similarly, the bijection that de nes the encoding of M output <lb/>symbols into M-dimensional one-active-bit binary vectors is denoted by c O . <lb/>The vector I(t) = (I (t) <lb/>1 ; :::; I (t) <lb/>N ) 2 f0; 1g N of activations of input neurons corresponds to the <lb/>input symbol c ?1 I (I (t) <lb/>1 ; :::; I (t) <lb/>N ). <lb/>Activation of each output neuron is from the open interval (0; 1). A threshold 2 (0; 1 <lb/>2 ) is <lb/>introduced, such that any value from (0; ) is assumed to be an approximation of 0, and any value <lb/>from (1 ? ; 1) represents the value 1. A mapping r : (0; 1) ! f0; 1; ?1g is de ned as follows 9 : <lb/>r(x) = <lb/>8 <lb/>&gt; &gt; &gt; &lt; <lb/>&gt; &gt; &gt; : <lb/>0 <lb/>if x 2 (0; ) <lb/>1 if x 2 (1 ? ; 1) <lb/>?1 <lb/>otherwise: <lb/></body>

			<note place="footnote">9 ?1 represents don&apos;t know output of an output neuron <lb/></note>

			<page>8 <lb/></page>

			<body>Interpretation of network output in terms of output symbols of the FSM it models is performed <lb/>via mapping D 10 : <lb/>D(y 1 ; :::; y M ) = <lb/>( c ?1 O (y 1 ; :::; y M ) if y i 2 f0; 1g; i = 1; :::; M <lb/>otherwise: <lb/>If the output of the network, O(t) = (O (t) <lb/>1 ; :::; O (t) <lb/>M ), falls into ((0; ) (1 ? ; 1)) M , then it <lb/>corresponds to the output symbol <lb/>D(r(O (t) <lb/>1 ); :::; r(O (t) <lb/>M )) = c ?1 O (r(O (t) <lb/>1 ); :::; r(O (t) <lb/>M )) = c ?1 O (R(O (t) <lb/>1 ; :::; O (t) <lb/>M )) = c ?1 O (R(O (t) )); <lb/>where the map R is the component-wise application of the map r. <lb/>Each input word (a word over the input alphabet of the FSM used for training) is encoded into <lb/>the input neurons one symbol per discrete time step t, yielding the corresponding output, as well <lb/>as the network new state. <lb/>Training is performed via optimization with respect to the error function <lb/>E = 1 <lb/>2 <lb/>X <lb/>m <lb/>(T (t) <lb/>m ? O (t) <lb/>m ) 2 ; <lb/>where T (t) <lb/>m 2f0; 1g is the desired response value for the m{th output neuron at the time step t. For <lb/>a more detailed explanation of the training procedure see 31]. <lb/>5 RNN as a State Machine <lb/>In this section we assume that a RNN N of the type described above has learned to exactly mimic <lb/>the behaviour of a reduced, connected FSM M = (X; Y; Q; ; ; s o ) it was trained with. It follows <lb/>that there exists a network state S 0 , for which network output will always be in ((0; ) (1? ; 1)) M <lb/>upon presentation of any input word, and such that the following correspondence holds (time is set <lb/>to t = 1 ): 11 <lb/>8w = x 1 :::x n 2X + ; (q i ; x i )=D(R(O (i) )); for all i = 1; :::; n; <lb/>(6) <lb/></body>

			<note place="footnote">10 It is assumed that * does not belong to the set of output symbols of the FSM modeled by the RNN. * stands for <lb/>don&apos;t know output of the net. <lb/></note>

			<note place="footnote">11 In practical terms, during learning phase, the network is trained to respond to a special &quot;reset&quot; input symbol <lb/># (# = <lb/>2 X) by changing its state to a state equivalent to s0, the initial state of M (more details in 31]). S 0 is the <lb/>\next-state&quot; computed in the layer of recurrent state neurons when the symbol # is presented to the network input <lb/>after training process has been completed. <lb/></note>

			<page>9 <lb/></page>

			<body>where <lb/>q 1 = s 0 , <lb/>S (1) = S 0 , <lb/>q i+1 = (q i ; x i ); i = 1; :::; n ? 1, and <lb/>the network input I (i) at the time step i is the code c I (x i ) of the i-th input symbol x i of the <lb/>input word w. <lb/>Automata theory provides us with the ability to connect structural and behavioural equivalence <lb/>of automata 32]. In particular, it can be shown, that for any couple (M 1 ; M 2 ) of connected FSMs <lb/>with equal input, as well as output sets it holds: if B M 1 =B M 2 , then M 1 and M 2 are equivalent <lb/>and their reduced forms are isomorphic. To investigate the correspondence between N and M in <lb/>this context, we represent the network N as a SM N =(X; Y f g; S; ; ; S 0 ), where the maps <lb/>and are de ned as follows: <lb/>for any S =(S 1 ; :::; S L )2 S; and any x2X; <lb/>(S; x)=D(R(O 1 (S; c I (x)); :::; O M (S; c I (x)))); <lb/>and <lb/>(S; x)=(S 1 (S; c I (x)); :::; S L (S; c I (x))); <lb/>with O i and S j de ned by (5) and (4) respectively. <lb/>From (6) it follows that <lb/>8w2X + ; + (s 0 ; w)= + (S 0 ; w): <lb/>(7) <lb/>The set S = (0; 1) L of states of N can be partitioned into the set of equivalence classes corre-<lb/>sponding to the equivalence relation E( N; N). By presenting inputs to the network and considering <lb/>only the de-coded network outputs, it is impossible to distinguish between equivalent network states. <lb/>S 0 ] E( N; N) is the set of all network states equivalent to S 0 . Denote the set of network states <lb/>accessible from states from S 0 ] E( N; N) by S acc . Note that for every state S 2 S acc and for each <lb/>input word w 2 X + , + (S; w) does not contain the don&apos;t know symbol . From N, a reduced, <lb/>connected SM N 1 = (X; Y; S acc =E( N; N); 1 ; 1 ; S 0 ] E( N; N) ) is constructed, where 1 and 1 are <lb/></body>

			<page>10 <lb/></page>

			<body>de ned according to (1) and (2) respectively, and respectively restricted to S acc =E( N; N) X and <lb/>S acc =E( N; N) X + . N 1 has the same behaviour as M. It is easy to see that the number of states <lb/>of N 1 is nite and hence N 1 is a FSM. It follows that N 1 and M are isomorphic. <lb/>The set q] E(M; N) of all network states equivalent to the state q of M is denoted by (q) N . <lb/>States of a SM code the information about \what has happened so far in the course of input word <lb/>processing&quot;. From that point of view, all network states from (q) N code the same information, the <lb/>information that is coded by the state q of M. <lb/>So far we have dealt with the existence issues concerning nonempty regions of network states <lb/>equivalent to states of the FSM the network is capable to exactly mimic. For a \constructive&quot; <lb/>approach to determination of (q) N , the regions N y <lb/>x of network state space are identi ed, for which <lb/>the network N gives the (decoded) output y provided the code of the input symbol x is presented <lb/>at network input. In particular, N y <lb/>x = fS 2 Sj (S; x) = yg. Note that for each x 2 X and y 2 Y , <lb/>N y <lb/>x is an open set. For a given input word w = x 1 x 2 :::x n 2 X + , the set of all network states <lb/>N + (q;w) <lb/>w <lb/>originating the output equal to + (q; w) is <lb/>N + (q;w) <lb/>w <lb/>= N (q;x 1 ) <lb/>x 1 <lb/>\ <lb/>&quot; n <lb/>\ <lb/>i=2 <lb/>( x i?1 ::: x 2 x 1 ) ?1 (N (q;x 1 x 2 :::x i ) <lb/>x i <lb/>) <lb/># <lb/>; <lb/>(8) <lb/>where <lb/>x (S)= (S; x); for each x2X: <lb/>(9) <lb/>By f ?1 (A), where f is a map and A is a set, we denote the set of all points whose images under <lb/>f are in A. For any x 2 X; x is continuous, and so is the composition xm ::: x 2 x 1 for any <lb/>word x 1 x 2 :::x m 2 X + . It follows that the sets N + (q;w) <lb/>w <lb/>are open. However, the set <lb/>(q) N = <lb/>\ <lb/>w2X + <lb/>N + (q;w) <lb/>w <lb/>(10) <lb/>of network states equivalent to the state q of M is not necessarily open, since an in nite, countable <lb/>intersection of open sets is not guaranteed to be open 12 . If (q) N is open, (q) N 6 = ; implies there <lb/>exists a ( nite) length L of input words such that 13 (q) N = T <lb/>jwj L N + (q;w) <lb/>w <lb/>. <lb/></body>

			<note place="footnote">12 The case when trajectories in the RNN state space may be corrupted by a noise is not discussed in this paper. <lb/>However, we note that if (q)N is not open, arbitrarily close to a state S 2(q)N there is a network state not equivalent <lb/>to the state q of M and an arbitrarily small perturbation of S may cause failure in the RNN modeling of M. <lb/></note>

			<note place="footnote">13 jwj denotes length of the word w, i.e. the number of symbols contained in w <lb/></note>

			<page>11 <lb/></page>

			<body>From (8) and (10) it follows that if there is an x-loop in a state q of M producing an output <lb/>symbol y, then <lb/>x ((q) N ) (q) N <lb/>\ <lb/>i 0 <lb/>( i <lb/>x ) ?1 (N y <lb/>x ): <lb/>(11) <lb/>As in section 3, i <lb/>x is the composition of x with itself i times. 0 <lb/>x is de ned to be the identity map. <lb/>Analogically, if there is an x-cycle of length m passing through states q 1 ; :::; q m with outputs <lb/>y i = (q i ; x); i = 1; :::; m, then <lb/>(q 1 ) N <lb/>m <lb/>\ <lb/>j=1 <lb/>( j?1 <lb/>x ) ?1 <lb/>0 <lb/>@ \ <lb/>i 0 <lb/>( im <lb/>x ) ?1 (N y j <lb/>x ) <lb/>1 <lb/>A : <lb/>(12) <lb/>Similar bounds can be found for (q 2 ) N ; :::; (q m ) N , in particular <lb/>m <lb/>x ((q j ) N ) (q j ) N <lb/>\ <lb/>i 0 <lb/>( im <lb/>x ) ?1 (N y j <lb/>x ); j = 1; :::; m: <lb/>(13) <lb/>Some researchers attempted to extract learned automaton from a trained recurrent network <lb/>17], 8], 37], 31]. Extraction procedures rely on the assumption that equivalent network states <lb/>are grouped together in well-separated regions in the recurrent neurons&apos; activation space. After <lb/>training, the network state space is partitioned into clusters using some clustering tool and for each <lb/>q 2 Q, the region (q) N is approximated by (possibly) several of such obtained clusters. For example, <lb/>in 17] the network state neurons&apos; activation space is divided into several equal hypercubes. When <lb/>the number of hypercubes is su ciently high, each hypercube is believed to contain only mutually <lb/>equal states. After training, Ti no and Sajda 31] present a large number of input words to the <lb/>network input. All states the network passes through during the presentation are saved. Then <lb/>the clustering of those states is performed using Kohonen map with &quot;star&quot; topology of neural eld <lb/>consisting of several \branches&quot; of neurons connected to one \central&quot; neuron. Such a topology <lb/>helped to reduce great sensitivity to initial conditions found in vector-coding algorithms using <lb/>independent cluster centers, while avoiding time consuming approximation of input space topology <lb/>typical of classical regular-grid topologies of Kohonen Map 30]. Other approaches to RNN state <lb/>space clustering are discussed in 31]. <lb/>Having approximated the regions (q) N , the automaton N 1 is constructed via determining arcs in <lb/>the corresponding transition diagram, followed by non-determinism eliminating and minimization <lb/>procedures. <lb/></body>

			<page>12 <lb/></page>

			<body>All ideas presented in this section stem from the assumption, that the network N exactly mimics <lb/>the FSM M it was trained with. However, it is possible that a correct automaton is extracted from <lb/>trained RNN even though the network is known to generalize poorly on long, unseen input words <lb/>17]. This is discussed in section 8. <lb/>5.1 Experiments <lb/>Number of experiments were performed in which RNNs with two or three state neurons were trained <lb/>simple FSMs. To show how the network learned to organize its state space in order to mimic a given <lb/>FSM, the regions corresponding to (q) N were detected. The network state space was \covered&quot; <lb/>with a regular grid G of R R points (R is of order of hundreds) and a nite vocabulary ? of <lb/>distinguishing sequences of M was created. Regions (q) N were approximated by grouping together <lb/>those network states from the grid that, for each input word from the vocabulary, lead to equal <lb/>output strings. In other words, (q) N = T <lb/>w2X + N + (q;w) <lb/>w <lb/>were approximated by T <lb/>w2? N + (q;w) <lb/>w <lb/>\G. <lb/>For example, in gure 3 approximations of regions of equivalent network states corresponding to <lb/>states of a FSM shown in gure 2 can be seen. Figure 3 should be compared with gure 4 showing <lb/>activations of state neurons during presentation of training set to the RNN after training. <lb/>Generally, in our experiments, regions approximating (q) N were observed to be connected and <lb/>of \simple shape&quot;. Further study needs to be devoted to that matter. However, at least empirically <lb/>and for simple tasks, our use of the Kohonen Map as a clustering tool 31], as well as the use of <lb/>simple clustering technique introduced in 17] are supported. <lb/>6 RNN as a Collection of Dynamical Systems <lb/>RNNs can be viewed as discrete-time DSs. Literature dealing with the relationship between RNNs <lb/>and DSs is quite rich: 20], 3], 16], 6], 7] 24], 26], 35], 36], 34], 2], 21], for example. However, <lb/>as it has been already mentioned, the task of complete understanding of the global dynamical <lb/>behaviour of a given DS is not at all an easy one. In 36] it is shown that networks with just two <lb/>recurrent neurons can exhibit chaos and hence the asymptotic network dynamical behaviour (on a <lb/>chaotic attractor) can be very complex. <lb/>In order to describe the behaviour of the RNN N by an iterative map, we con ne ourselves <lb/></body>

			<page>13 <lb/></page>

			<body>Figure 2: FSM M used for training RNN. M=(X; Y; S; f s ; f o ; s 0 ) is represented as a directed graph <lb/>called the state transition diagram. The graph has node for each state, and every node has jXj <lb/>(jXj denotes the number of elements of a nite set X ) outgoing arcs labeled with xjy (x2X; y2Y ) <lb/>according to the rule: The arc from the node labeled with s 1 2S to the node labeled with s 2 2S is <lb/>labeled with xjy if s 2 = f s (s 1 ; x); and y = f o (s 1 ; x). The node corresponding to the initial state <lb/>is indicated by an arrow labeled with START. <lb/>Figure 3: Regions of equivalent network states. Capital letter inside each region indicates to which <lb/>state of M the network states from that region are equivalent. = 0:1. Two lines stemming from <lb/>the origin are the lines a (s) 1 = 1=2 and a (s) 2 = 1=2, between them is the region P a;(1;1) (see <lb/>section 6). <lb/></body>

			<page>14 <lb/></page>

			<body>Figure 4: Activations of state neurons when training set is presented to the network after training <lb/>process has nished (weights are frozen). <lb/>to only one input symbol x from the input alphabet of the FSM used for training N, the code of <lb/>which is repeatedly presented to the network input. The evolution of the network is described in <lb/>terms of trajectories fS; x (S); 2 <lb/>x (S); :::g in (0; 1) L . The iterative map x : (0; 1) L ! (0; 1) L is <lb/>de ned in (9). <lb/>As in the previous section, here we also assume that a RNN N exactly mimics the behaviour of <lb/>a reduced, connected FSM M=(X; Y; Q; ; ; s o ). In this section we deal with the problem of how <lb/>certain features of M found in its STD (such as loops and cycles) induce some speci c features <lb/>(such as attractive points and periodic orbits) of network global dynamical behaviour. <lb/>Assume that there is an x-loop in a state q of M and (q; x) = y. Then according to (11), (q) N <lb/>is a positively invariant set of x and hence an absorbing set of itself under x . From (8) it follows <lb/>that, under x , (q) N is an absorbing set of all sets (p) N such that q is x-accessible from p. If there <lb/>is an open set B such that B (q) N and x (B) B, or (q) N B and x (B) (q) N , then there <lb/>is an attractive set T <lb/>m 0 f m (B) of x in (q) N that constitutes a stable network representation of <lb/>the x-loop in a state q of M. <lb/>Similarly, assume that there is an x-cycle of length m passing through states q 1 ; :::; q m with <lb/>outputs y j = (q j ; x); j = 1; :::; m. Then according to (13), (q j ) N are positively invariant sets of m <lb/>x <lb/>and S m j=1 (q j ) N is positively invariant set of x . A statement concerning the existence of attractive <lb/>sets of m <lb/>x inside (q j ) N (or an attractive set of x inside S m j=1 (q j ) N ) can be made analogically to <lb/></body>

			<page>15 <lb/></page>

			<body>the statement above. Considering (8) it can be seen that under x , S <lb/>q2 (q) N is an absorbing set <lb/>of itself and all sets (p) N such that is x-accessible from p. <lb/>Observation 1 formulates these ideas in a more compact form. <lb/>Observation 1: Assume that a RNN N exactly mimics the behaviour of a reduced, connected FSM <lb/>M=(X; Y; Q; ; ; s o ). Then <lb/>if there is an x-loop in a state q of M, then (q) N N (q;x) <lb/>x <lb/>is positively invariant set of x <lb/>and 14 S <lb/>q2Acc(x;p) (p) N A x ((q) N ). <lb/>if there is an x-cycle of length m passing through states q 1 ; :::; q m of M, then (q j ) N ; j = <lb/>1; :::; m are positively invariant sets of m <lb/>x and S m j=1 (q j ) N is positively invariant set of x . <lb/>(q 1 ) N ; :::; (q m ) N are periodically visited in the process of iteration of x , and S <lb/>Acc(x;p) (p) N <lb/>A x <lb/>S <lb/>q2 (q) N . <lb/>When there was an x-loop in a state q of M in all our experiments an attractive xed point S of <lb/>x \near&quot; a vertex v 2 f0; 1g L was detected (see subsection Experiments bellow). If S 2 (q) N , S <lb/>constitutes a plausible network representation of the x-loop. If furthermore S is the only attractive <lb/>set of x inside (q) N , then S <lb/>q2Acc(x;p) (p) N is a subset of its basin of attraction. <lb/>For each input symbol x of M and each vertex v = (v 1 ; :::; v L ) 2 f0; 1g L de ne the set 15 <lb/>P x;v = s 2 &lt; L j x (s) i &lt; 1 <lb/>2 if v i = 0; x (s) i &gt; 1 <lb/>2 if v i = 1; i = 1; :::; L : <lb/>Hyperplanes x (s) i = 1=2 separate &lt; L into 2 L partitions P x;v . The map x is transformed to <lb/>the map x by multiplying weights W iln by a scalar &gt; 0, i.e. x (s) = x ( s). is also called <lb/>the neuron gain. The following Lemma was proved by Li 27]. It is stated for maps x and <lb/>accommodated with our notation. It tells us under what conditions one may expect an attractive <lb/>xed point of x to exist \near&quot; a vertex v 2 f0; 1g L . <lb/>Lemma 1: (Li, 1992) Suppose that for some input symbol x of M there exists a vertex v 2 <lb/>P x;v \ x (P x;v ). Then there exists a neuron gain 0 such that for all &gt; 0 there is an attractive <lb/>xed point of x in P x;v \ x (P x;v ). <lb/></body>

			<note place="footnote">14 recall that A x ((q)N ) is the absorbing region of (q)N under map x <lb/></note>

			<note place="footnote">15 x(s)i denotes the i-th component of x(s). When viewed as an iterative map, x operates on (0; 1) L , but here <lb/>we allow s 2 &lt; L . <lb/></note>

			<page>16 <lb/></page>

			<body>It was also shown that as tends to in nity, the attractive xed point tends to the vertex v. For <lb/>two recurrent neurons, under certain conditions on weights W iln , this is made more speci c in the <lb/>next section (Corollary 1). <lb/>Theorem 1: In addition to the assumptions in Observation 1, assume there is an x-loop in a <lb/>state q of M. Suppose there is a vertex v 2 f0; 1g L such that (q) N P x;v and v 2 x ((q) N ). <lb/>Then there exists a neuron gain 0 such that for all &gt; 0 there exists an attractive xed point <lb/>S 2 P x;v \ x (P x;v ) of x . <lb/>Proof: From <lb/>x ((q) N ) (q) N P x;v and x ((q) N ) x (P x;v ) <lb/>it follows that x ((q) N ) P x;v \ x (P x;v ). Hence <lb/>v 2 x ((q) N ) P x;v \ x (P x;v ): <lb/>Employing Lemma 1, the result follows immediately. <lb/>2 <lb/>Loosely speaking, Theorem 1 says that if arbitrarily close to a vertex v 2 f0; 1g L there is a network <lb/>state from x ((q) N ) (q) N P x;v , i.e. if network states that are equivalent to the state q of M <lb/>in which there is an x-loop are \accumulated&quot; around the vertex v within P x;v , then if the weights <lb/>are \large enough&quot;, so that 0 &lt; 1, an attractive xed point of x exists in a neighborhood of v <lb/>( gures 3 and 5). <lb/>As mentioned in the introduction, the approach presented in 6] addresses representational issues <lb/>concerning recurrent neural networks trained to act as regular language recognizers. Recurrent <lb/>neural networks are assumed to operate in a noisy environment. Such an assumption can be <lb/>supported by an argument that in any system implemented on a digital computer there is a nite <lb/>amount of noise due to round-o errors and \we are only interested in solutions wich work in spite <lb/>of round-o errors&quot; 6]. Orbits of points under a map f and attractive sets of f are substituted <lb/>for by the notions of -pseudo-orbit of points under f and -pseudo-attractor of f. These concepts <lb/>correspond to the idea that instead of the precise trajectory of a point under a map we should <lb/>consider each sequence of points (pseudotrajectory) having the distance from the precise trajectory <lb/>less than &gt; 0. It is proved that when there is a loop in the reduced acceptor of a regular language <lb/></body>

			<page>17 <lb/></page>

			<body>also recognized by the network, then there must be an -pseudo-attractor (and hence an attractor) <lb/>of the corresponding map in the network state space. The network accepts and rejects a string <lb/>of symbols if -pseudo-orbits driven by the string end in subregions denoted by accept and reject <lb/>regions respectively. It is assumed that the accept and reject regions are closed in the network state <lb/>space. <lb/>6.1 Experiments <lb/>To see how loops and cycles of a FSM M are transformed into global dynamical properties of a <lb/>RNN N that is able to exactly mimic M, the following experiments were performed: <lb/>Consider again the FSM M presented in gure 2. In gure 3 it can be seen how the RNN <lb/>N with two state neurons organizes its state space, (0; 1) 2 , into three distinct, connected regions <lb/>(A) N , (B) N , and (C) N , corresponding to states A, B, and C respectively. It was observed 16 that <lb/>trajectories starting in (A) N converged to a single attractive point placed inside (A) N . The same <lb/>applies to the state C, and its corresponding region (C) N . So the a-loops in the states A and C <lb/>induce attractive points of a placed inside the corresponding regions of equivalent RNN states. <lb/>Actually, this represents the only RNN stable representation of loops in M we have observed during <lb/>our simulations. <lb/>(A) N and (C) N are absorbing sets of themselves under the map a . Since the state C is a-<lb/>accessible from B, (C) N is an absorbing set of (B) N under a . Absorption diagrams of (A) N and <lb/>(C) N under a together with the attractive points are presented in gure 5. <lb/>If we presented M only with input symbol b, we would end up either in a b-cycle of length <lb/>two involving states A and B, or in a b-loop in the state C. When, during the experiments, we <lb/>started in a state from (C) N , and presented to the network input only the code of the symbol b, <lb/>the trajectory converged to an attractive point inside (C) N . An absorption diagram of (C) N under <lb/>b together with the attractive point can be seen in gure 6. <lb/>On the other hand, when started in a state from (A) N , the trajectory jumped between the sets <lb/>(A) N and (B) N converging to a periodic orbit of length two. Again, this was observed to be the <lb/>typical stable RNN representation of a cycle corresponding to an input symbol of M. The states <lb/></body>

			<note place="footnote">16 As before, during the simulations, the network state space was \covered&quot; with a regular grid of points and only <lb/>the orbits starting from these points were taken into account. <lb/></note>

			<page>18 <lb/></page>

			<body>Figure 5: Absorption diagrams of (A) N and (C) N under the map a . Network states lying in the <lb/>lightest region need one or no iteration step under the map G a to get to their absorption set. The <lb/>more iteration steps are needed, the darker the region is, with the exception of the region &quot;close <lb/>to&quot; the &quot;border line&quot; between the two absorption diagrams. The region is light so that the border <lb/>contours are clearly visible. The gure should be compared with the gure in the previous section <lb/>showing (A) N and (C) N . Note the two attractive points of a placed inside (A) N and (C) N induced <lb/>by a-loops in states A and C respectively. <lb/></body>

			<page>19 <lb/></page>

			<body>Figure 6: Absorption diagram of (C) N under the map b . Network states from the two white <lb/>regions do not belong to the absorption region of (C) N . The gure should be compared with the <lb/>gure in the previous section showing (C) N . Note the attractive point of b placed inside (C) N <lb/>induced by the b-loop in the state C, as well as, two periodic points of b placed inside (A) N and <lb/>(B) N constituting an attractive periodic orbit of period two. The orbit is induced by the b-cycle <lb/>fA; Bg. <lb/>constituting the orbit can be seen in gure 6. <lb/>In the second experiment, a FSM M shown in gure 7 was used to generate the training set for a <lb/>RNN N with three state neurons. The a-cycle fA; B; C; D; Eg of length ve induced an attractive <lb/>periodic orbit of a of period ve. Projections of the orbit to a two{dimensional subspace (0; 1) 2 <lb/>of the network state space can be seen in gures 8, 9, 10. To illustrate the convergence of orbits, <lb/>the orbits were plotted after 60, 100, and 300 pre-iterations ( gures 8, 9, and 10 respectively). No <lb/>plotting occurred during the pre-iterations. <lb/>7 RNN with Two State Neurons <lb/>Usually, studies of the asymptotic behaviour of recurrent neural networks assume some form of <lb/>structure in the weight matrix describing connectivity pattern among recurrent neurons. For ex-<lb/>ample, symmetric connectivity and absence of self-interactions enabled Hop eld 22] to interpret <lb/>the network as a physical system having energy minima in attractive xed points of the network. <lb/>These rather strict conditions were weakened in 7], where a more easily satis ed conditions are <lb/></body>

			<page>20 <lb/></page>

			<body>Figure 7: FSM M whose state transition diagram contains cycle of length ve. <lb/>Figure 8: <lb/>Figure 9: <lb/></body>

			<page>21 <lb/></page>

			<body>Figure 10: <lb/>formulated. Blum and Wang 3] globally analyze networks with nonsymmetrical connectivity pat-<lb/>terns of special types. In case of two recurrent neurons with sigmoidal activation function g, they <lb/>give results for weight matrices with diagonal elements equal to zero 17 . Recently, Jin, Niki ruk <lb/>and Gupta 25] reported new results on the absolute stability for a rather general class of recur-<lb/>rent neural networks. Conditions under which all xed points of the network are attractive were <lb/>determined by the weight matrix of the network. <lb/>The purpose of this section is to investigate the position and stability types of xed points of <lb/>maps x under certain assumptions concerning the signs and magnitudes of weights W iln . The <lb/>iterative map under consideration can be written as follows: <lb/>(u n+1 ; v n+1 ) = (g( u n + v n ); g( u n + v n )); <lb/>(14) <lb/>where (u n ; v n )2(0; 1) 2 is the state of recurrent network with two state neurons at the time step n; <lb/>and ; and ; are positive and negative real coe cients respectively. Thus we investigate the <lb/>case when the two recurrent neurons are self-exciting ( ; &gt; 0), with the tendency to inhibit each <lb/>other ( ; &lt; 0). <lb/>For c &gt; 4, de ne <lb/>(c) = 1 <lb/>2 <lb/>r <lb/>1 ? 4 <lb/>c <lb/>In the following it will be shown how the network state space (0; 1) 2 can be partitioned into regions <lb/></body>

			<note place="footnote">17 In such a case the recurrent network is shown to have only one xed point and no \genuine&quot; periodic orbits (of <lb/>period greater than one) <lb/></note>

			<page>22 <lb/></page>

			<body>A <lb/>R <lb/>R <lb/>R <lb/>R <lb/>R <lb/>R <lb/>R <lb/>R <lb/>R <lb/>R <lb/>R <lb/>R <lb/>R <lb/>R <lb/>R <lb/>R <lb/>A <lb/>A <lb/>A <lb/>00 <lb/>00 <lb/>00 <lb/>00 <lb/>01 <lb/>01 <lb/>0.5+∆(δ) <lb/>01 <lb/>01 <lb/>11 <lb/>11 <lb/>11 <lb/>11 <lb/>10 <lb/>10 <lb/>10 <lb/>10 <lb/>S <lb/>S <lb/>S <lb/>S <lb/>S <lb/>S <lb/>S <lb/>S <lb/>R <lb/>R <lb/>R <lb/>R <lb/>0 <lb/>1 <lb/>1 <lb/>0.5 <lb/>0.5 <lb/>0.5−∆(α) <lb/>0.5+∆(α) <lb/>0.5−∆(δ) <lb/>Figure 11: Partitioning of RNN state space according to stability types of xed points of maps x . <lb/>according to the stability types of xed points of (14) found in the regions. <lb/>Regions <lb/>0; 1 <lb/>2 ? ( ) <lb/>0; 1 <lb/>2 ? ( ) ; <lb/>1 <lb/>2 ? ( ); 1 <lb/>2 <lb/>0; 1 <lb/>2 ? ( ) <lb/>0; 1 <lb/>2 ? ( ) <lb/>1 <lb/>2 ? ( ); 1 <lb/>2 <lb/>and <lb/>1 <lb/>2 ? ( ); 1 <lb/>2 <lb/>1 <lb/>2 ? ( ); 1 <lb/>2 <lb/>are denoted by R A <lb/>00 ; R S <lb/>00 and R R <lb/>00 respectively. Regions symmetrical to R A <lb/>00 ; R S <lb/>00 and R R <lb/>00 with respect <lb/>to the line u = 1=2 are denoted by R A <lb/>10 ; R S <lb/>10 and R R <lb/>10 respectively: <lb/>R A <lb/>10 = 1 <lb/>2 + ( ); 1 <lb/>0; 1 <lb/>2 ? ( ) ; <lb/>R S <lb/>10 = 1 <lb/>2 ; 1 <lb/>2 + ( ) <lb/>0; 1 <lb/>2 ? ( ) <lb/>1 <lb/>2 + ( ); 1 <lb/>1 <lb/>2 ? ( ); 1 <lb/>2 ; <lb/>R R <lb/>10 = 1 <lb/>2 ; 1 <lb/>2 + ( ) <lb/>1 <lb/>2 ? ( ); 1 <lb/>2 : <lb/>Similarly, let R A <lb/>01 ; R S <lb/>01 and R R <lb/>01 denote the regions symmetrical to R A <lb/>00 ; R S <lb/>00 and R R <lb/>00 with respect to <lb/>the line v = 1=2. Finally, R A <lb/>11 ; R S <lb/>11 and R R <lb/>11 denote regions that are symmetrical to R A <lb/>01 ; R S <lb/>01 and <lb/>R R <lb/>01 with respect to the line u = 1=2 ( gure 11). <lb/></body>

			<page>23 <lb/></page>

			<body>Theorem 2: Suppose &gt; 4; &lt; 0; &lt; 0; &gt; 4; &gt; j j; &gt; j j. Then the following can be said <lb/>about the xed points of (14): <lb/>attractive and repulsive points can lie only in S <lb/>i2I R A <lb/>i and S <lb/>i2I R R <lb/>i respectively. I is the <lb/>index set I = f00; 10; 01; 11g. If maxf ( ? 4); ( ? 4)g &lt; , there are no repellors. <lb/>all xed points in S <lb/>i2I R S <lb/>i are saddle points 18 . <lb/>Proof: Any xed point (u; v) of (14) satis es <lb/>(u; v) = (g( u + v); g( u + v)): <lb/>(15) <lb/>Jacobian J(u; v) of (14) in (u; v) is given by <lb/>0 <lb/>B @ <lb/>G 1 (u; v) G 1 (u; v) <lb/>G 2 (u; v) G 2 (u; v) <lb/>1 <lb/>C A; <lb/>where G 1 (u; v) = g 0 ( u + v) and G 2 (u; v) = g 0 ( u + v). Since g 0 (p) = g(p)(1 ? g(p)), considering <lb/>(15) we have <lb/>(G 1 (u; v); G 2 (u; v)) = (u(1 ? u); v(1 ? v)) = (u; v): <lb/>(16) <lb/>The eigenvalues of J are 19 <lb/>1;2 = G 1 + G 2 <lb/>p <lb/>D <lb/>2 <lb/>; <lb/>where D = ( G 1 ? G 2 ) 2 + 4G 1 G 2 . <lb/>D is always positive and so is G 1 + G 2 . It follows that to identify possible values of G 1 and <lb/>G 2 so that j 1;2 j &lt; 1, it is su cient to solve the inequality G 1 + G 2 + <lb/>p <lb/>D &lt; 2, or equivalently <lb/>2 ? G 1 ? G 2 &gt; <lb/>p D: <lb/>(17) <lb/>Consider only G 1 ; G 2 such that G 1 + G 2 &lt; 2, that is, (G 1 ; G 2 ) lies under the line : G 1 + G 2 = 2. <lb/>All (G 1 ; G 2 ) above lead to at least one eigenvalue of J greater than 1. Squaring both sides of <lb/>(17) we arrive at <lb/>( ? )G 1 G 2 ? G 1 ? G 2 &gt; ?1: <lb/>(18) <lb/></body>

			<note place="footnote">18 Note that this does not exclude the existence of saddle xed points in other regions. <lb/></note>

			<note place="footnote">19 to simplify the notation, the identi cation (u; v) of a xed point in which (14) is linearized is omitted <lb/></note>

			<page>24 <lb/></page>

			<body>P <lb/>1/δ <lb/>1/α <lb/>A <lb/>C <lb/>(0,0) <lb/>ρ <lb/>κ <lb/>κ <lb/>G 1 <lb/>2 <lb/>G <lb/>1/4 <lb/>1/4 <lb/>Figure 12: <lb/>The \border&quot; curve : ( ? )G 1 G 2 ? G 1 ? G 2 = ?1 in (G 1 ; G 2 )-space is a hyperbola <lb/>G 2 = (G 1 ) = A 1 + B=(G 1 ? C)], where <lb/>A = 1 <lb/>? <lb/>; C = 1 <lb/>? <lb/>; and B = C ? 1 : <lb/>Since 0 &lt; ? = &lt; and 0 &lt; ? = &lt; , it follows that A &gt; 1= ; C &gt; 1= and B &gt; 0. <lb/>(1= ) = 0; (0) = 1= and (G 1 ; G 2 ) satisfying (18) lie under the \left branch&quot; and above the \right <lb/>branch&quot; of (see gure 12). It is easy to see that since we are con ned to the space below the line <lb/>, only (G 1 ; G 2 ) under the left branch of will be considered. Indeed, is a decreasing line going <lb/>through (C; P) and A ? P = 2(A ? 1= ) &gt; 0, so it never intersects the right branch of . <lb/>A necessary (not su cient) condition for a xed point (u; v) of (14) to be attractive is that the <lb/>corresponding (G 1 ; G 2 ) = (u; v) 2 (0; 1=4] 2 lies in (0; 1= ) (0; 1= ), where the map is de ned <lb/>by (16). For each (G 1 ; G 2 ) 2 (0; 1=4] 2 , under , there are four preimages <lb/>(u; v) = ?1 (G 1 ; G 2 ) = 1 <lb/>2 <lb/>1 <lb/>G 1 <lb/>; 1 <lb/>2 <lb/>1 <lb/>G 2 <lb/>: <lb/>(19) <lb/></body>

			<page>25 <lb/></page>

			<body>The set of preimages of (0; 1= ) (0; 1= ) is the set S <lb/>i2I R A <lb/>i ; I = f00; 10; 01; 11g. <lb/>A xed point (u; v) of (14) is a saddle if j 2 j &lt; 1 and j 1 j = 1 &gt; 1. Since &gt; , <lb/>0 &lt; <lb/>q <lb/>( G 1 + G 2 ) 2 ? 4G 1 G 2 ( ? ) = <lb/>p D &lt; G 1 + G 2 : <lb/>It follows that if G 1 + G 2 &lt; 2, i.e. (G 1 ; G 2 ) lies under the line , 0 &lt; G 1 + G 2 ? <lb/>p D &lt; 2 <lb/>holds and 0 &lt; 2 &lt; 1. For (G 1 ; G 2 ) above the line , i.e. G 1 + G 2 &gt; 2, we solve the inequality <lb/>G 1 + G 2 ? 2 &lt; <lb/>p <lb/>D, that leads to the \border&quot; curve G 2 = (G 1 ) we have already described. <lb/>This time, only (G 1 ; G 2 ) \between&quot; the two branches of hyperbola are considered. <lb/>It can be seen that in all xed points (u; v) of (14) with <lb/>(u; v) 2 0; 1 <lb/>4 <lb/>0; min A; 1 <lb/>4 <lb/>0; min C; 1 <lb/>4 <lb/>0; 1 <lb/>4 ; <lb/>the eigenvalue 2 &gt; 0 is less than 1. This is certainly true for all (u; v) such that (u; v) 2 <lb/>(0; 1=4] (0; 1= ) (0; 1= ) (0; 1=4]. In particular, the preimages of (G 1 ; G 2 ) 2 (1= ; 1=4] <lb/>(0; 1= ) (0; 1= ) (1= ; 1=4] under de ne the region S <lb/>i2I R S <lb/>i where only saddle xed points of <lb/>(14) can lie. <lb/>Fixed points (u; v) whose images under lie above the right branch of are repellors. No <lb/>(G 1 ; G 2 ) can lie in that region, if C; A &gt; 1=4, that is, if ( ? 4) &lt; and ( ? 4) &lt; , which is <lb/>equivalent to maxf ( ? 4); ( ? 4)g &lt; . <lb/>2 <lb/>The condition maxf ( ?4); ( ?4)g &lt; implies that when self-excitations of recurrent neurons <lb/>are not signi cantly higher than their mutual inhibition, there are no repulsive xed points of (14). <lb/>As self-excitations and grow, stable xed points of (14) move closer towards f0; 1g 2 . More <lb/>precisely: <lb/>Corollary 1: Same assumptions as in Theorem 2. All attractive xed points of (14) lie in the <lb/>&quot;-neighborhood of vertices of unit square, where <lb/>&quot; = <lb/>q <lb/>(0:5 ? ( )) 2 + (0:5 ? ( )) 2 : <lb/>. <lb/>The tendency of attractive xed points in discrete-time RNNs with exclusively self-exciting recur-<lb/>rent neurons to move towards saturation values as neural gain grows is also discussed in 21]. <lb/></body>

			<page>26 <lb/></page>

			<body>So far, we have con ned the areas of the network state space (0; 1) 2 where (under some assump-<lb/>tions on weights) xed points of (14) of particular stability types can lie. In the following, it will <lb/>be shown that those regions correspond to monotonicity intervals of functions de ning xed points <lb/>of (14). The reasoning about the stability type of a xed point can be based on the knowledge of <lb/>where the functions intersect. <lb/>Recall that any xed point (u ; v ) of (14) satis es <lb/>(u ; v ) = (g( u + v ); g( u + v )); <lb/>or equivalently, (v ; v ) lies on the intersection of two curves v = f ; (u); u = f ; (v), where <lb/>f c 1 ;c 2 : (0; 1) ! &lt;; <lb/>f c 1 ;c 2 (`) = ? c 1 <lb/>c 2`+ <lb/>1 <lb/>c 2 <lb/>ln1 ?`: <lb/>(20) <lb/>lim`! 0 + f c 1 ;c 2 (`) = 1, lim`! 1 ? f c 1 ;c 2 (`) = ?1 20 . f c 1 ;c 2 is convex and concave on (0; 0:5) and (0:5; 1) <lb/>respectively. If c 1 4, f c 1 ;c 2 is nonincreasing, otherwise it is decreasing on (0; 0:5 ? (c 1 )) (0:5 + <lb/>(c 1 ); 1) and increasing on (0:5 ? (c 1 ); 0:5 + (c 1 )): Graph of f c 1 ;c 2 (`) is presented in gure 13. <lb/>The \bended&quot; graph of f c 1 ;c 2 for c 1 &gt; 4 gives rise to a potentially complicated intersection <lb/>pattern of f ; (u) and f ; (v). In the following, we shall consider only the case c 1 &gt; jc 2 j, since it <lb/>is su cient to explain some interesting features of training process observed in our experiments. <lb/>Note that c 1 &gt; jc 2 j means that for both neurons, the self-excitation is higher than the inhibition <lb/>from the other neuron. <lb/>Lemma 2: Assume &gt; 0; &lt; 0; &lt; 0; &gt; 0: If j j and j j, then f ; (u) and f ; (v) do <lb/>not intersect in (0; 0:5) 2 . <lb/>Proof: Assume that both f ; (u) and f ; (v) lie in (0; 0:5) 2 , otherwise the result follows trivially. <lb/>For u 2 (0; 0:5); both (ln(u=(1 ? u))= and ? u= are positive. It follows that in (0; 0:5) 2 , <lb/>f ; (u) lies above the line v = u=j j. Similarly, in (0; 0:5) 2 , f ; (v) lies above the line u= v=j j. <lb/>In terms of the co-ordinate system (u; v), this can be restated as follows: in (0; 0:5) 2 , the graph <lb/>of f ; lies above the line v = u=j j while the graph of f ; lies bellow the line v = j ju= . Since <lb/>j j= 1 =j j, f ; (u) and f ; (v) do not intersect in (0; 0:5) 2 . <lb/>2 <lb/></body>

			<note place="footnote">20 note that since ; and ; are assumed to be positive and negative respectively, we have c1 &gt; 0 and c2 &lt; 0 <lb/></note>

			<page>27 <lb/></page>

			<body>1 c 2 <lb/>( ) <lb/>l <lb/>f c <lb/>l <lb/>c <lb/>) <lb/>0.5−∆( <lb/>c <lb/>1 &gt; 4 <lb/>1 &lt; 4 <lb/>1 <lb/>c <lb/>0.5+∆( 1 ) <lb/>c <lb/>1 <lb/>0 <lb/>0.5 <lb/>Figure 13: <lb/></body>

			<page>28 <lb/></page>

			<body>The correspondence between regions R Q <lb/>i;j ; i; j = 0; 1; Q = A; S; R, and the regions of monotonicity <lb/>of f ; (u) and f ; (v) enables us to interpret training process as a process of \shaping&quot; f ; and <lb/>f ; so that the desired behaviour of (14), as prescribed by the training set, is achieved. <lb/>Denote the set f(u; f ; (u))j u2(0; 0:5? ( ))g of points lying on the \ rst decreasing branch&quot; <lb/>of f ; (u) by f 0? <lb/>; . Analogically, the set of points f(u; f ; (u))j u 2 (0:5 + ( ); 1)g in the \sec-<lb/>ond decreasing branch&quot; of f ; (u) is denoted by f 1? ; . Finally, let f + ; denote the set of points <lb/>f(u; f ; (u))j u 2 (0:5 ? ( ); 0:5 + ( ))g on the increasing part of f ; (u). Similarly, f 0? ; ; f 1? ; <lb/>and f + ; are used to denote the sets f(f ; (v); v)j v2(0; 0:5? ( ))g, f(f ; (v); v)j v2(0:5+ ( ); 1)g <lb/>and f(f ; (v); v)j v2(0:5 ? ( ); 0:5 + ( ))g respectively. Using the Theorem 2 and Lemma 2 we <lb/>state the following corollary: <lb/>Corollary 2: Same assumptions as in Theorem 2. Attractive xed points of (14) can lie only on <lb/>the intersection of decreasing parts of f ; and f ; . Whenever the increasing part of f ; intersects <lb/>with a decreasing part of f ; (or vice-versa), it corresponds to a saddle point of (14). In particular, <lb/>all attractive xed points of (14) are from f 0? ; \ f 1? ; , f 1? ; \ f 1? ; or f 1? ; \ f 0? ; . Every point from <lb/>f + <lb/>; \ f 1? ; or f 1? ; \ f + ; is a saddle point of (14). <lb/>The usual scenario of creation of a new attractive xed point of (14) is that typical of saddle-<lb/>node bifurcation in which a pair attractive + saddle xed point is created. Attractive xed points <lb/>disappear in a reverse manner: an attractive point coalesces with with a saddle and they are <lb/>annihilated. This is illustrated in gure 14. f ; (v) shown as dashed curve intersects f ; (u) in <lb/>three points. By increasing , f ; bends further (solid curve) and intersects with f ; in ve <lb/>points 21 . Saddle and attractive points are marked with squares and circles respectively. Note that <lb/>as increases attractive xed points move closer to vertices f0; 1g 2 . <lb/>A similar approach to determining the number and stability types of xed points of the under-<lb/>lying dynamical systems in continuous{time recurrent neural networks can be found in 2]. <lb/></body>

			<note place="footnote">21 At the same time, j j has to be also appropriately increased so as to compensate for the increase in so that the <lb/>\bended&quot; part of f ; does not move radically to higher values of u. <lb/></note>

			<page>29 <lb/></page>

			<body>v <lb/>1 <lb/>1 <lb/>0 <lb/>f <lb/>f δ,γ <lb/>α,β (u) <lb/>(v) <lb/>u <lb/>Figure 14: Geometrical illustration of saddle-node bifurcation in RNN with two state neurons. <lb/>D <lb/>START <lb/>a | 1 <lb/>a | 2 <lb/>a | 3 <lb/>a | 4 <lb/>b | 1 <lb/>b | 4 <lb/>b | 3 <lb/>b | 2 <lb/>A <lb/>B <lb/>C <lb/>Figure 15: FSM M with four a-loops and \transition&quot; input symbol b. <lb/>8 Experiments { Learning loops of FSM <lb/>A RNN with two state neurons was trained with the FSM M presented in gure 15. In each of <lb/>its four states there is an a-loop. Input symbol b causes subsequent transitions between states up <lb/>to the \trap&quot; state D. Training set representing M was constructed as follows: Transitions to <lb/>states B; C and D from the initial state A are represented by one, two and three consecutive b&apos;s <lb/>respectively. Apart from transition, each a-loop is represented by strings of consecutive a&apos;s up to <lb/>length 5. b-loop in the state D is represented by a string of 5 consecutive b&apos;s. To each input string <lb/>w, its corresponding output string + (A; w) is determined. <lb/>During the training, after each epoch, attractive sets of a were numerically detected. The <lb/>evolution of position and number of attractive xed point(s) of a in (0; 1) 2 can be seen in gure 16. <lb/></body>

			<page>30 <lb/></page>

			<body>1 <lb/>137 <lb/>139 <lb/>139 <lb/>321 <lb/>59 <lb/>59 <lb/>225 <lb/>225 <lb/>225 <lb/>512 <lb/>511 <lb/>s2 <lb/>0.0 <lb/>0.2 <lb/>0.4 <lb/>0.6 <lb/>0.8 <lb/>1.0 <lb/>s1 <lb/>0.0 <lb/>0.2 <lb/>0.4 <lb/>0.6 <lb/>0.8 <lb/>1.0 <lb/>Figure 16: Evolution of position of attractive sets of a during RNN training on FSM M (two state <lb/>neurons). <lb/>Near the points the corresponding epoch numbers are shown. At the beginning, there is only one <lb/>xed point of a . A bifurcation during the 59th epoch produces two attractive xed points. Since <lb/>the 138th epoch till the 321st epoch there are three attractive xed points and two saddle points <lb/>of a . These are determined by the intersection of the corresponding lines f a; a and f a; a , where <lb/>a ; a ; a and a are coe cients of the map a as in (14). The episode of existence of the attractive <lb/>xed point f 1? <lb/>a; a \f 1? <lb/>a; a begins when f a; a is \bended&quot; enough so that f 1? <lb/>a; a intersects with both <lb/>increasing and decreasing parts f + <lb/>a; a and f 1? <lb/>a; a respectively. At the same time, in order for the <lb/>intersection f 1? <lb/>a; a \ f + <lb/>a; a to exist, f a; a needs also to be su ciently \bended&quot; ( gure 17). The <lb/>degree to which f a; a and f a; a are \bended&quot; is primarily controlled by a and a respectively, <lb/>while the vertical positions of bended parts are mainly determined by respectively a and a . During <lb/>the 322nd epoch, the attractive xed point f 1? <lb/>a; a \ f 1? <lb/>a; a together with saddle point f 1? <lb/>a; a \ f + <lb/>a; a <lb/>disappear because the increase in j a j pushes the &quot;bended&quot; part of f a; a inside the state space <lb/>(0; 1) 2 ( gure 18). <lb/>The training error was 0:08, yet the only attractive sets of a that were detected were two <lb/>attractive xed points S A and S D near vertices (0; 1) and (1; 0) corresponding to a-loops in states <lb/></body>

			<page>31 <lb/></page>

			<body>0 <lb/>0.2 <lb/>0.4 <lb/>0.6 <lb/>0.8 <lb/>1 <lb/>1.2 <lb/>1.4 <lb/>1.6 <lb/>1.8 <lb/>2 <lb/>0 <lb/>0.2 <lb/>0.4 <lb/>0.6 <lb/>0.8 <lb/>1 <lb/>1.2 <lb/>1.4 <lb/>1.6 <lb/>1.8 <lb/>2 <lb/>Figure 17: f a; a (u) and f a; a (v) after 150th training epoch. Coe cients of the map a are <lb/>a = 5:21; a = ?2:58; a = ?2:63; a = 5:23. <lb/>0 <lb/>0.2 <lb/>0.4 <lb/>0.6 <lb/>0.8 <lb/>1 <lb/>1.2 <lb/>1.4 <lb/>1.6 <lb/>1.8 <lb/>2 <lb/>0 <lb/>0.2 <lb/>0.4 <lb/>0.6 <lb/>0.8 <lb/>1 <lb/>1.2 <lb/>1.4 <lb/>1.6 <lb/>1.8 <lb/>2 <lb/>Figure 18: f a; a (u) and f a; a (v) after 1000th training epoch. Coe cients of the map a are <lb/>a = 8:61; a = ?3:96; a = ?3:08; a = 5:17. <lb/></body>

			<page>32 <lb/></page>

			<body>A and D respectively. Starting in a small neighborhood of S A and S D , upon repeated presentation <lb/>of input a, the decoded network outputs are 1 and 4 with trajectories of a approaching S A and <lb/>S D respectively. There is no stable representation of the a-loops in states B and C, i.e. there are <lb/>no positively invariant sets of a leading to the network output 2 and 3 respectively when input a <lb/>is presented to the network. <lb/>However, the net is able to simulate the training set perfectly. It follows that after it is reset 22 <lb/>and presented with b, when ve consecutive a&apos;s arrive, the decoded output will be ve consecutive <lb/>2&apos;s. Hence, the network must have developed a mechanism for acting as if the a-loops in B and C <lb/>were represented in a stable manner, at least for strings having no more than ve consecutive a&apos;s. <lb/>It turns out that the underlying mechanism for pretending that there are stable representations <lb/>of a-loops for short input strings involves a behaviour of trajectories starting \near&quot; the stable <lb/>manifold W s of the saddle xed point S S lying \between&quot; attractive points S A and S D , with W s <lb/>constituting the border of regions of attraction of S A and S D . <lb/>Consider a point S \near&quot; W s . Due to the continuity of a , the orbit of S under a rst moves <lb/>towards S S along W s and then away from S S along a branch of the unstable manifold W u of <lb/>S S gradually approaching one of the attractive points S A , S D . To which of the two points the <lb/>trajectory actually converges is determined by the \side&quot; of W s on which the initial point S lies. <lb/>Assume that the trajectory of S converges to S A . If we slightly displace S into S 0 on \the other <lb/>side&quot; of the curve W s , trajectories trajectories of S and S 0 move towards S S close to each other, but <lb/>as they approach S S , the trajectory of S 0 follows the other branch of W u towards S D (see gure 19). <lb/>As we move starting point S towards S A and S D , the trajectories less and less follow the pattern <lb/>described above, move towards S A and S D in a straightforward manner 23 and approach a vicinity <lb/>of S A and S D respectively much faster than trajectories starting \near&quot; W s . Hence, the network is <lb/>able to \cheat&quot; by pretending stable behaviour as described by the a-loop in the state B because <lb/>it takes advantage of di erent convergence rates of orbits starting near W s and S D . The decoded <lb/>output of the net with input a and a state near S D is 4 (region D ), while for states involving rst <lb/>several steps in trajectories starting near W s , the output is 2 (region B ). Analogical statement can <lb/></body>

			<note place="footnote">22 with (possibly repeated) presentation of \reset&quot; input # <lb/></note>

			<note place="footnote">23 Due to the coe cients of a, eigenvalues of its Jacobian in every point from (0; 1) 2 are real thus implying an <lb/>absence of rotation in neighborhoods of xed points. <lb/></note>

			<page>33 <lb/></page>

			<body>b <lb/>1 <lb/>0 <lb/>1 <lb/>B <lb/>D <lb/>W <lb/>s <lb/>W <lb/>u <lb/>W <lb/>u <lb/>A <lb/>S <lb/>S <lb/>S <lb/>S <lb/>D <lb/>S <lb/>S&apos; <lb/>C <lb/>A <lb/>τ <lb/>Figure 19: Illustration of a mechanism that enables RNN to \pretend&quot; stable representation of <lb/>loops in M for short input strings. <lb/>be made about trajectories starting near S A and W s , and regions A and C respectively. Most of the <lb/>time towards the end of learning session was spent on learning the output function a (S) = (S; a) <lb/>in closely neighboring regions of B and C so that the outputs for states from B and C are 2 and 3 <lb/>respectively (see gures 20, 21). The map # associated with the \reset&quot; input symbol # has one <lb/>attractive xed point in the region A. Under the \reset&quot; map # , trajectories of network states <lb/>S 2(0; 1) 2 quickly approach region A thus preparing ground for processing of a new input word. <lb/>The key role, however, is played by the transfer function b . It simulates transition between <lb/>states with a-loops in M. Starting in S 2 A, b (S) 2 B and 2 <lb/>b (S) 2 C lie near W s and the <lb/>behaviour of a in B and C appears to be stable for several iterations. Upon repeated presentation <lb/></body>

			<page>34 <lb/></page>

			<body>0 <lb/>0.5 <lb/>1 <lb/>0.2 <lb/>0.4 <lb/>0.6 <lb/>0.8 <lb/>0 <lb/>0.2 <lb/>0.4 <lb/>0.6 <lb/>0.8 <lb/>1 <lb/>Figure 20: The map ( a ) 2 representing the output of the second output neuron that corresponds <lb/>to the output symbol 2. Note the sharp activity change along border of regions of attraction of S A <lb/>and S D . <lb/>0 <lb/>0.5 <lb/>1 <lb/>0.2 <lb/>0.4 <lb/>0.6 <lb/>0.8 <lb/>0 <lb/>0.2 <lb/>0.4 <lb/>0.6 <lb/>0.8 <lb/>1 <lb/>Figure 21: The map ( a ) 3 representing the output of the third output neuron that corresponds to <lb/>the output symbol 3. A sharp activity change along border of regions of attraction of S A and S D <lb/>is clearly visible. <lb/></body>

			<page>35 <lb/></page>

			<body>of a, 3 <lb/>b (S) 2 D converges to S D with network output 4. <lb/>The delicate role of b responsible for transitions A ! B ! C ! D with jumping on the <lb/>\appropriate&quot; sides of W s while staying close to W s , together with di erent convergence rates of <lb/>orbits under a starting close to W s and near S A , S D are principal tools enabling the net to behave <lb/>nicely for testing strings of smaller length, although it generalizes poorly on strings with many <lb/>consecutive a&apos;s after b or bb. In particular, the outputs of the net for input strings ba n and bba m <lb/>are consistent with training set for n = 8 and m = 10. As further a&apos;s keep coming, trajectories of <lb/>a move away from B and C towards S D and S A respectively. <lb/>To visualize the process of state degradation upon repeated presentation of input a a state <lb/>degradation diagram for input a is constructed as follows (M a denotes the set of states of M in <lb/>which there is an a-loop): <lb/>Construct a nite vocabulary ? of short distinguishing words for M a , such that ? does not <lb/>contain a word ua i v; i 2, where u is leading to a state of M in which there is an a-loop. <lb/>With each state q of M a associate a minimal input word m q leading to q. <lb/>For each i 2 f1; 2; :::; N max g <lb/>{ For each w 2 ? <lb/>For each state q2M a <lb/>present the reset network with m q a i and then <lb/>present the network with w and check whether the net output equals + (q; w). <lb/>If not, check whether there is a state p of M such that the network output equals <lb/>+ (p; w) { if so, draw an arrow in a diagram from q to p. <lb/>State degradation diagram for input a is presented in gure 22. Note that when only short input <lb/>strings are presented to the network, and quantization of network state space individually captures <lb/>regions A; B; C; D a correct state transition diagram can be obtained, even though, on longer input <lb/>strings the net generalizes poorly. <lb/>When the network with three state neurons was trained with the FSM M, it generalized cor-<lb/>rectly over the training set by forming four attractive xed points of a corresponding to loops <lb/>in states A; B; C; D of M. The training process looked at from the point of view of asymptotic <lb/></body>

			<page>36 <lb/></page>

			<body>D <lb/>A <lb/>C <lb/>B <lb/>Figure 22: State degradation diagram for input a. N max = 100. <lb/>behaviour of a is illustrated in gure 23. Horizontal axis correspond to time (in epochs), network <lb/>state space (0; 1) 3 is orthogonally projected into 2-dimensional space of activations of a couple of <lb/>state neurons. Bifurcations leading to formation of new attractive xed points appeared during <lb/>the 53rd,115th and the 121st epoch. If the network is able to exactly mimic the FSM M the state <lb/>degradation diagram for each input symbol has no arrows. <lb/>As another example, Consider a FSM M in gure 24. It is a FSM taken from the database <lb/>of the International Symposium on Circuits and Systems (Portland, Oregon, 1989) 4]. In each of <lb/>its 7 states there is an a-loop with output 0 except for a-loops in states 4 and 7. The training <lb/>set consists of 3500 training strings 24 of input string length 3{35 and is ordered according to their <lb/>length starting with the shortest ones. The machine M is hard to learn because the training set <lb/>is very sparse in output symbols other than 0. Training process is disrupted by a tendency to nd <lb/>trivial solution represented by the automaton with only one state and loops for every input symbol <lb/>with the output 0. An example of a part of the training set is given in table 1. <lb/>After 53 training epochs RNN with 6 state neurons is able to perform well on short test strings <lb/>(training error was 0.06). Generalization on long test strings was found to be poor. Part of the <lb/>problem was unstable network representation of a-loops in M. The state degradation diagram for <lb/>input a can be seen in gure 25. a-loops in states 4,6 and 7 are \well represented&quot; by xed points <lb/>S 4 ; S 6 and S 7 respectively in that when starting in a small neighborhood of S q ; q = 4; 6; 7 , the <lb/>resulting output sequences of RNN for input words a i w; w 2 ?; i 0 equal + (q; a i w). This is not <lb/>true of a-loops in states 1,2,3 and 5. When the net is reset and presented with m q ; q = 1; 2; 3; 5 , <lb/>for i &gt; N q it does not emulate + (q; a i w); w 2 ?. Sates 5 and 3 degradate to states 1 and 2 <lb/>respectively. In particular, N 5 = 8 and N 3 = 5. Both states 1 and 2 degradate to attractive <lb/>xed point S 0 with N 1 = 27 and N 2 = 40. The network state S 0 does not represent any state <lb/>of M even for short input strings. S j ; j = 0; 4; 6; 7; are the only attractive sets of a that were <lb/>detected. There are trajectories of a starting near border of regions of attraction of S 0 and some <lb/></body>

			<note place="footnote">24 input word w ! corresponding output word + (q0; w) <lb/></note>

			<page>37 <lb/></page>

			<body>426 <lb/>426 <lb/>415 <lb/>435 <lb/>53 <lb/>53 <lb/>57 <lb/>57 <lb/>71 <lb/>71 <lb/>115 <lb/>115 <lb/>115 <lb/>1 <lb/>121 <lb/>121 <lb/>121 <lb/>114 <lb/>30 <lb/>126 <lb/>200 <lb/>s1 <lb/>s3 <lb/>t <lb/>Figure 23: Evolution of position of attractive sets of a during RNN training on FSM M (three <lb/>state neurons). <lb/></body>

			<page>38 <lb/></page>

			<body>. <lb/>. <lb/>. <lb/>dddeadfdaeaafaaadddaddadfeeedeaeee# --&gt; 0000000000000000000000000000000002x <lb/>affedfeefaedeededfdefddaafeeeeeadd# --&gt; 0000000000000000000000000000022200x <lb/>dffdadedfadaddffeeafeafdffdffefaad# --&gt; 0000000000000000000000000000000000x <lb/>fdaadaafddafafdadfdffdeaffaaefeade# --&gt; 0000000000000000000000000000000000x <lb/>ddfaddadfaaddddeafdafdfaeedaedeeda# --&gt; 0000000000000000000000000000000000x <lb/>defadedefdeffdefdafdaaadeaeddaaefd# --&gt; 0000000000000000000000000000000000x <lb/>ddfedaaffdedeaeadeefdfefaadadeaaff# --&gt; 0000000000000000000000000000000000x <lb/>aafaaeefafeaffeeefeafaefeeadaefafa# --&gt; 0000000000000000000000000000000000x <lb/>dddeeafffafeaadaddfdffadfeafdddefd# --&gt; 0000000001100000000000000000000000x <lb/>fdaaddaadadffefaeadddfeddeafdddaea# --&gt; 0000000000000000000000000000000000x <lb/>dedaddadaafeaaddaafaaefaefdeeffafe# --&gt; 0000000000000000000000000000000000x <lb/>ddaeeafddfaaffffaeeefeadaefdfedfee# --&gt; 0000000000000011100000000000000000x <lb/>dddedeeafdfddfaeeaddafdfafadedfaaf# --&gt; 0000000000000000000000000000000000x <lb/>. <lb/>. <lb/>. <lb/>Table 1: A part of the training set characterizing the FSM M. Output strings are sparse in output <lb/>symbols other than 0. <lb/></body>

			<page>39 <lb/></page>

			<body>other attractive xed point of a that pass through the region assuming the role of state 5 of M <lb/>for short input strings. Then, further towards S 0 , they pass through the region of network states <lb/>that for short input strings seem to be equivalent to the state 1 of M, nally making their way to <lb/>a close neighborhood of S 0 and converge to it. A similar statement can be made about states 3 <lb/>and 2 of M. <lb/>9 Discussion <lb/>Two views on the relationship between a RNN and a FSM M such that the RNN exactly mimics <lb/>M were presented. First, the network was treated as a state machine. The notion of regions of <lb/>equivalent network states that are also equivalent to a state of M link the rst approach with the <lb/>second, dynamical systems&apos; approach to the RNN. <lb/>Our experiments suggest that the most usual stable RNN N representations of loops and cycles <lb/>in M can be described as follows: An x-loop in a state q of M induces an attractive xed point of <lb/>x inside (q) N , and an x-cycle fq 1 ; :::; q m g of M induces an attractive periodic orbit of period m of <lb/>x periodically visiting (q 1 ) N ; :::; (q m ) N : <lb/>The present paper provides us with the opportunity to look at the learning process from the <lb/>point of view of bifurcation analysis. If the network is supposed to operate as a FSM, its state space <lb/>must have multiple attractor basins to store distinct internal states. The network solves the task <lb/>of FSM simulation by location of point and periodic attractors and the shaping of their respective <lb/>basins of attraction 9]. Before training, the connection weights are set to small random values and <lb/>as a consequence, the network has only one attractor basin. This implies that the network must <lb/>undergo several bifurcations 13]. This can have an undesirable e ect on the training process, since <lb/>the gradient descent learning may get into trouble. At bifurcations points, the output of a network <lb/>can change discontinuously with the change of parameters and therefore convergence of gradient <lb/>descent algorithms is not guaranteed 14]. <lb/>In the following a possible application of these ideas to the problem of determination of the <lb/>complexity of language recognition by neural networks will be discussed brie y. <lb/>Any FSM with binary output alphabet f0; 1g can function as a recognizer of a regular language. <lb/>A word over the input alphabet belongs to the language only if the output symbol after presentation <lb/></body>

			<page>40 <lb/></page>

			<body>3 <lb/>a|0 <lb/>a|0 <lb/>a|2 <lb/>e|2 <lb/>a|0 <lb/>a|0 <lb/>a|1 <lb/>f|1 <lb/>f|0 <lb/>f|0 <lb/>f|0 <lb/>e|0 <lb/>f|0 <lb/>d|0 <lb/>d|0 <lb/>d|0 <lb/>d|0 <lb/>d|0 <lb/>d|0 <lb/>e|0 <lb/>e|0 <lb/>e|0 <lb/>e|0 <lb/>e|0 <lb/>f|0 <lb/>f|0 <lb/>6 <lb/>S <lb/>a|0 <lb/>d|0 <lb/>4 <lb/>7 <lb/>5 <lb/>2 <lb/>1 <lb/>Figure 24: FSM M taken from the database of the International Symposium on Circuits and Sys-<lb/>tems (Portland, Oregon, 1989). M is the reduced form of a machine de ned in the le bbara.kiss2. <lb/>Inputs ??01; ??10 and ??00 are represented as the input symbol a since, in every state, they <lb/>initiate the same transition with the same output. Inputs 0011; ?111 and 1011 are represented <lb/>as input symbols d; e and f respectively. Outputs 00; 01 and 10 are coded as output symbols <lb/>0; 1 and 2 respectively. <lb/></body>

			<page>41 <lb/></page>

			<body>0 <lb/>4 <lb/>5 <lb/>3 <lb/>6 <lb/>7 <lb/>1 <lb/>2 <lb/>S <lb/>S <lb/>S <lb/>S <lb/>4 <lb/>6 <lb/>7 <lb/>Figure 25: State degradation diagram for input a extended with network state S 0 not representing <lb/>any state of M. S 0 = (0:89; 0:01; 0:55; 0:95; 0:99; 0:92); S 4 = (0:16; 0:98; 0:02; 0:87; 0:04; 0:92); S 6 = <lb/>(0:98; 0:03; 0:97; 0:09; 0:99; 0:87); S 7 = (0:94; 0:98; 0:95; 0:01; 0:05; 0:15). N max = 100. <lb/>of word&apos;s last symbol is 1. Hence, the network output is used to decide whether a word does belong <lb/>to the language, or not. One of the most promising neural acceptors of regular languages 32] is the <lb/>second-order RNN introduced by Giles et al. 17]. However, the practical aspects of the acceptance <lb/>issue are still unclear 33]. The di culty of acceptance of a given language by a neural network (the <lb/>neural complexity of the language) can be quanti ed by the minimal number of neurons needed <lb/>to recognize the language. In the context of mealy machines and threshold networks a similar <lb/>problem was attacked by Alon et al. 1] and Horne and Hush 23]. An attempt to predict the <lb/>minimal second-order RNN size so that the network can learn to accept a given regular language <lb/>is presented in 33]. The predicted numbers of neurons were shown to correlate well with the <lb/>experimental ndings. <lb/>Essentially, a good starting point for the estimation of neural complexity of a given regular <lb/>language is the representation of the language with the reduced recognizer. The most usual, very <lb/>rough, approach to the neural complexity estimation takes into account only the number of states <lb/>of such a recognizer 33]. What plays a principal role in making the internal structure of a regular <lb/>language rich is <lb/></body>

			<page>42 <lb/></page>

			<body>the number of input symbols of the recognizer <lb/>the number of loops associated with each input symbol <lb/>the number and corresponding lengths of cycles associated with each input symbol <lb/>the relationship among loops and/or cycles (i.e. a x 1 -cycle is passing through a state q in <lb/>which there exists a x 2 -loop, etc... ). <lb/>In every recognizer of a regular language, for each input symbol there exists at least one loop or a <lb/>cycle. During the training process, the weights of a network are modi ed so that the corresponding <lb/>attractive sets evolve in dynamical systems de ned by the iterative maps x . A hint for a lower <lb/>bound on the minimal number of neurons can be obtained by exploring the possibilities of the <lb/>existence of attractive points and/or periodic orbits that are to be induced during the training <lb/>process. The expected relationship among their basins of attraction has to be taken into account <lb/>at the same time 5]. <lb/>As an example consider the FSMs M 1 and M 2 presented in gures 26, and 27 respectively. <lb/>Apparently, the the internal structure of a regular language accepted by M 2 is \more complex&quot; <lb/>than that of accepted by M 1 . In the latter case, only one attractive xed point of a is su cient <lb/>to represent the a-loop in the state E. The same applies to the b-loop in E, and the map b . In the <lb/>former case, an attractive periodic orbit of period four of the map a , and four attractive points of <lb/>the map b have to be induced. Even though the FSM M 2 has only four states, the RNN needed <lb/>four state neurons to accomplish a successful learning. On the other hand, two state neurons were <lb/>su cient for the RNN to learn the FSM M 1 . <lb/>A mechanism underlying generalization loss on longer input strings due to unstable represen-<lb/>tation of loops in a FSM to be learned was investigated. It was shown that even in such cases a <lb/>correct state transition diagram of the FSM can potentially be extracted even though the network <lb/>performs badly on longer input strings (as reported by Giles et al. 17]). The state degradation <lb/>diagram for an input symbol x illustrates how regions of network state space, initially acting as if <lb/>they assumed the role of states of the FSM in which there is an x-loop, gradually degradate upon <lb/>repeated presentation of x. The degradation may lead to a network state not representing any state <lb/>of the FSM even for short input strings. <lb/></body>

			<page>43 <lb/></page>

			<body>Figure 26: Acceptor of the language L = L 1 L 2 ; L 1 = fa; bg n b; n 2 f0; 2; 4; 5; 6; :::g; L 2 = <lb/>fa; bg m a; m 2 f1; 3g. <lb/>Figure 27: Acceptor of the language L = L + 3 , where L 3 = b ab (b a) 3 b + (b a) 4 . <lb/></body>

			<page>44 <lb/></page>

			<body>Zeng et al. 39] and Das and Mozer 11] view the RNN state space quantization as an integral <lb/>part of the learning process in which the network is trained to mimic a nite state machine. In <lb/>particular, in 39] state units&apos; activation pattern is mapped at each time step to the nearest corner <lb/>of a hypercube as if state neurons had a hard threshold activation function. Das and Mozer 11] <lb/>used a \soft&quot; version of the gaussian mixture model 25 in a supervised mode as a clustering tool. <lb/>The mixture model parameters were adjusted so as to minimize the overall performance error of <lb/>the whole system (recurrent network + clustering tool). Both Zeng et al., and Das and Mozer <lb/>report better assymptotical behaviour for long, unseen test input strings. It would be interesting <lb/>to investigate such approaches to training RNN on nite state problems as a form of \dynamical <lb/>self-reinforcement&quot; learning encouraging bifurcations to attractive xed points and periodic orbits <lb/>of the underlying dynamical systems. <lb/></body>

			<div type="acknowledgement">Acknowledgments <lb/>Thanks to M aria Marko sov a, Pavol Brunovsk y and Phil Holmes for useful discussions on dynamical <lb/>systems. Work of Mike Casey and Randall Beer was of great contribution in preparing this report. <lb/></div>

			<listBibl>References <lb/>1] N. Alon, A.K. Dewdney, and T.J. Ott. E cient simulation of nite automata by neural nets. <lb/>Journal of the Association of Computing Machinery, 38(2):495{514, 1991. <lb/>2] R.D. Beer. On the dynamics of small continuous{time recurrent networks. Technical Report <lb/>CES{94{18, Case Western Reserve University, Cleveland, OH, 1994. <lb/>3] E.K. Blum and X. Wang. Stability of xed points and periodic orbits and bifurcations in <lb/>analog neural networks. Neural Networks, (5):577{587, 1992. <lb/>4] F. Brglez, D. Bryan, and K. Kozminski. Combinational Pro les of Sequential Benchmark <lb/>Circuits. In Proceedings of the International Symposium on Circuits and Systems, Portland, <lb/>Oregon, May 1989. <lb/></listBibl>

			<note place="footnote">25 Instead of the center with greatest posterior probability given a pattern of state units&apos; activation, a linear <lb/>combination of centers is used, where each center is weighted by its posterior probability given current network state. <lb/></note>

			<page>45 <lb/></page>

			<listBibl>5] M.P. Casey. Computation dynamics in discrete-time recurrent neural networks. In Proceed-<lb/>ings of the Annual Research Symposium, volume 3, pages 78{95, UCSD, La Jolla, CA, 1993. <lb/>Institute for Neural Computation. <lb/>6] M.P. Casey. Computation in Discrete-Time Dynamical Systems. PhD thesis, University of <lb/>California, San Diego, Department of Mathematics, March 1995. <lb/>7] M.P. Casey. Relaxing the symmetric weight condition for convergent dynamics in discrete-time <lb/>recurrent networks. Technical Report INC-9504, Institute for Neural Computation, University <lb/>of California, San Diego, 9500 Gilman Drive, La Jolla, CA 92093-0112, 1995. <lb/>8] A. Cleeremans, D. Servan-Schreiber, and J.L. McClelland. Finite state automata and simple <lb/>recurrent networks. Neural Computation, 1(3):372{381, 1989. <lb/>9] F. Cummins. Representation of temporal patterns in recurrent networks. Submitted to the <lb/>15th Annual Conference of the Cognitive Science Society, 1993. <lb/>10] S. Das, C.L. Giles, and G.Z. Sun. Learning context-free grammars: Capabilities and limitations <lb/>of a recurrent neural network with an external stack memory. In Proceedings of The Fourteenth <lb/>Annual Conference of Cognitive Science Society. Indiana University, 1992. <lb/>11] S. Das and M.C. Mozer. A uni ed gradient{descent/clustering architecture for nite state <lb/>machine induction. In J.D. Cowen, G. Tesauro, and J. Alspector, editors, Advances in Neural <lb/>Information Processing Systems 6, pages 19{26. Morgan Kaufmann, 1994. <lb/>12] R.L. Devaney. An Introduction to Chaotic Dynamical Systems. Benjamin/Cummings Publish-<lb/>ing Company, Inc., Menlo Park, California, 1986. <lb/>13] K. Doya. Bifurcations in the learning of recurrent neural networks. In Proc. of 1992 IEEE <lb/>Int. Symposium on Circuits and Systems, pages 2777{2780, 1992. <lb/>14] K. Doya. Bifurcations of recurrent neural networks in gradient descent learning. Submitted to <lb/>IEEE Transactions on Neural Networks, 1993. <lb/>15] J.L. Elman. Finding structure in time. Cognitive Science, 14:179{211, 1990. <lb/></listBibl>

			<page>46 <lb/></page>

			<listBibl>16] M. Garzon and S. Franklin. Global dynamics in neural networks. Complex Systems, (3):29{36, <lb/>1989. <lb/>17] C.L. Giles, C.B. Miller, D. Chen, H.H. Chen, G.Z. Sun, and Y.C. Lee. Learning and extract-<lb/>ing nite state automata with second{order recurrent neural networks. Neural Computation, <lb/>4(3):393{405, 1992. <lb/>18] C.L. Giles, C.B. Miller, D. Chen, G.Z. Sun, H.H. Chen, and Y.C. Lee. Extracting and learning <lb/>an unknown grammar with recurrent neural networks. In J.E. Moody, S.J. Hanson, and R.P. <lb/>Lippmann, editors, Advances in Neural Information Processing Systems 4, pages 317{324, <lb/>1992. <lb/>19] J. Guckenheimer and P. Holmes. Nonlinear Oscilations, Dynamical Systems, and Bifurcations <lb/>of Vector Fields. Springer-Verlag, 1982. <lb/>20] M.W. Hirsch. Convergent activation dynamics in continuous time networks. Neural Networks, <lb/>2(5):331{349, 1989. <lb/>21] M.W. Hirsch. Saturation at high gain in discrete time recurrent networks. Neural Networks, <lb/>7(3):449{453, 1994. <lb/>22] J.J. Hop eld. Neurons with a graded response have collective computational properties like <lb/>those of two{state neurons. Proceedings of the National Academy of Science USA, 81:3088{ <lb/>3092, May 1984. <lb/>23] B.G. Horne and D.R. Hush. Bounds on the complexity of recurrent neural network implemen-<lb/>tations of nite state machines. In J.D. Cowen, G. Tesauro, and J. Alspector, editors, Advances <lb/>in Neural Information Processing Systems 6, pages 359{366. Morgan Kaufmann, 1994. Also <lb/>submitted to Neural Networks. <lb/>24] S. Hui and S.H. Zak. Dynamical analysis of the brain-state-in-a-box neural models. IEEE <lb/>Transactions on Neural Networks, (1):86{94, 1992. <lb/>25] L. Jin, P.N. Nikiforuk, and M.M. Gupta. Absolute stability conditions for discrete-time recur-<lb/>rent neural networks. IEEE Transactions on Neural Networks, (6):954{963, 1994. <lb/></listBibl>

			<page>47 <lb/></page>

			<listBibl>26] M.I. Jordan. Attractor dynamics and parallelism in a connectionist sequential machine. In <lb/>Proceedings of the Eighth Conference of the Cognitive Science Society, pages 531{546. Erlbaum, <lb/>1986. <lb/>27] L.K. Li. Fixed point analysis for discrete-time recurrent neural networks. In Proceedings of <lb/>IJCNN, volume 4, pages 134{139, Baltimore, USA, 1992. <lb/>28] P. Manolios and R. Fanelli. First order recurrent neural networks and deterministic nite state <lb/>automata. Neural Computation, 6(6):1155{1173, 1994. <lb/>29] R.C. Minnick. Linear{input logic. IRE Transactions on Electronic Computers, EC{13:6{16, <lb/>1961. <lb/>30] P. Ti no, I.E. Jelly, and V. Vojtek. Non-standard topologies of neuron eld in self-organizing <lb/>feature maps. In Proceedings of the AIICSR&apos;94 conference, Slovakia, pages 391{396. World <lb/>Scienti c Publishing Company, 1994. <lb/>31] P. Ti no and J. Sajda. Learning and extracting initial mealy machines with a modular neural <lb/>network model. Neural Computation, 7(4), 1995. <lb/>32] M.W. Shields. An Introduction to Automata Theory. Blackwell Scienti c Publications, London, <lb/>UK, 1987. <lb/>33] H.T. Siegelmann, E.D. Sontag, and C.L. Giles. The complexity of language recognition by <lb/>neural networks. In J. van Leeuwen, editor, Algorithms, Software, Architecture (Proceedings <lb/>of IFIP 12 th World Computer Congress), pages 329{335, Amsterdam, 1992. North{Holland. <lb/>34] M. Vidyasagar. Location and stability of the high{gain equilibria of nonlinear neural networks. <lb/>IEEE Transactions on Neural Networks, 4(4):660{672, July 1993. <lb/>35] X. Wang. Period-doublings to chaos in a simple neural network: An analytical proof. Complex <lb/>Systems, (5):425{441, 1991. <lb/>36] X. Wang and E.K. Blum. Discrete-time versus continuous-time models of neural networks. <lb/>Journal of Computer and Systems Sciences, 45:1{19, 1990. <lb/></listBibl>

			<page>48 <lb/></page>

			<listBibl>37] R.L. Watrous and G.M. Kuhn. Induction of nite{state automata using second{order recurrent <lb/>networks. In J.E. Moody, S.J. Hanson, and R.P. Lippmann, editors, Advances in Neural <lb/>Information Processing Systems 4, pages 309{316, 1992. <lb/>38] R.L. Watrous and G.M. Kuhn. Induction of nite{state languages using second{order recurrent <lb/>networks. Neural Computation, 4(3):406{414, 1992. <lb/>39] Z. Zeng, R.M. Goodman, and P. Smyth. Learning nite state machines with self{clustering <lb/>recurrent networks. Neural Computation, 5(6):976{990, 1993. <lb/></listBibl>

			<page>49 </page>


	</text>
</tei>
