<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="_0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Integrality and Separability of Input Devices <lb/>ROBERT J. K. JACOB, LINDA E. SIBERT, DANIEL C. MCFARLANE, and <lb/>M. PRESTON MULLEN, JR. <lb/>Naval Research Laboratory, Washington, D.C. <lb/>Current <lb/>input device taxonomies <lb/>and other frameworks <lb/>typically <lb/>emphasize the mechanical <lb/>structure <lb/>of input devices. We suggest that selecting an appropriate <lb/>input device for an <lb/>interactive <lb/>task requires looking beyond the physical structure of devices to the deeper percep-<lb/>tual structure of the task, the device, and the interrelationship <lb/>between the perceptual structure <lb/>of the task and the control properties <lb/>of the device. We atllrm <lb/>that perception <lb/>is key to <lb/>understanding <lb/>performance <lb/>of multidimensional <lb/>input devices on multidimensional <lb/>tasks. We <lb/>have therefore extended the theory of processing of perceptual structure to graphical interactive <lb/>tasks and to the control structure of input devices. This allows us to predict task and device <lb/>combinations <lb/>that lead to better performance <lb/>and hypothesize that performance <lb/>is improved <lb/>when the perceptual <lb/>structure <lb/>of the task matches the control structure <lb/>of the device. We <lb/>conducted an experiment <lb/>in which subjects performed <lb/>two tasks with different <lb/>perceptual <lb/>structures, using two input devices with correspondingly <lb/>different control structures, a three-di-<lb/>mensional tracker and a mouse. We analyzed both speed and accuracy, as well as the trajectories <lb/>generated by subjects as they used the unconstrained <lb/>three-dimensional <lb/>tracker to perform each <lb/>task. The results support our hypothesis and confirm the importance of matching the perceptual <lb/>structure of the task and the control structure of the input device. <lb/>Categories <lb/>and Subject <lb/>Descriptors: <lb/>H.1.2 <lb/>[Models <lb/>and <lb/>Principles]: <lb/>User/Machine <lb/>Systems-human <lb/>factors; <lb/>H.5.2 [Information <lb/>Interfaces <lb/>and Presentation]: <lb/>User Interfaces <lb/>-input devices and strategies, <lb/>interaction <lb/>styles; 1.3.6 [Computer <lb/>Graphics]: <lb/>Methodology and <lb/>Techniques-interaction <lb/>techniques <lb/>General Terms: Design, Experimentation, <lb/>Human Factors, Measurement, <lb/>Theory <lb/>Additional <lb/>Key Words and Phrases: Gesture input, input devices, integrality, <lb/>interaction <lb/>tech-<lb/>niques, perceptual space, Polhemus tracker, separability <lb/></front>

			<body>INTRODUCTION <lb/>A mechanical <lb/>input <lb/>device encodes motion <lb/>into a signal that can be read by <lb/>the computer. <lb/>Designing <lb/>workable <lb/>input <lb/>devices requires <lb/>that the motion <lb/>clearly <lb/>convey the intent <lb/>of the user and complement <lb/>his or her physical <lb/>capabilities. <lb/>The design of current <lb/>input <lb/>devices and their interaction <lb/>tech-<lb/>niques have been driven <lb/>more by what is technologically <lb/>feasible <lb/>than from <lb/>an understanding <lb/>of human <lb/>performance. <lb/>Their success relies, in part, on the <lb/>well-documented <lb/>human <lb/>ability <lb/>to adapt. To design and select more effective <lb/></body>

			<front>This work was sponsored by the office of Naval Research. Authors&apos; address: Human-Computer <lb/>Interaction <lb/>Laboratory, <lb/>Naval Research Laboratory, <lb/>Washington, <lb/>D.C. 20375. <lb/>Permission to copy without fee all or part of this material is granted provided that the copies are <lb/>not made or distributed <lb/>for direct commercial advantage, the ACM copyright notice and the title <lb/>of the publication <lb/>and its date appear, and notice is given that copying is by permission of the <lb/>Association <lb/>for Computing <lb/>Machinery. <lb/>To copy otherwise, <lb/>or to republish, <lb/>requires <lb/>a fee smd/or <lb/>specific permission. <lb/>Q 1994 ACM 1073-0516/94/0300-0003 <lb/>$03.50 <lb/>ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994, Pages 3-26. <lb/></front>

			<page>4. <lb/></page>

			<note place="headnote">Roberl J. K. Jacob et al. <lb/></note>

			<body>input <lb/>devices and interaction <lb/>techniques, <lb/>we need to use a deeper under-<lb/>standing <lb/>of task, device, and the interrelationship <lb/>between <lb/>task and device <lb/>from the perspective <lb/>of the user. <lb/>Such understanding <lb/>may come from the intuition <lb/>and judgment <lb/>of design-<lb/>ers and, perhaps, <lb/>from empirical <lb/>studies <lb/>of specific <lb/>new devices. However, <lb/>greater <lb/>leverage <lb/>is available <lb/>by reasoning <lb/>from a more general <lb/>predictive <lb/>theoretical <lb/>framework, <lb/>rather <lb/>than finding <lb/>an ad hoc answer <lb/>to each such <lb/>question. <lb/>The present study provides <lb/>one example of the development <lb/>and use <lb/>of such a theoretical <lb/>framework <lb/>to the problem <lb/>of three-dimensional <lb/>input <lb/>devices (as, for example, <lb/>Card et al. [1983] have done for two-dimensional <lb/>pointing <lb/>devices). <lb/>To do this, we extend <lb/>the theory <lb/>of processing <lb/>of perceptual <lb/>structure <lb/>[Garner <lb/>197&apos;4; Garner <lb/>and Felfoldy <lb/>19701, first developed with fixed images, <lb/>to interactive <lb/>graphical <lb/>manipulation <lb/>tasks. According <lb/>to this theory, <lb/>the <lb/>attributes <lb/>of objects in multidimensional <lb/>spaces can have different <lb/>dominant <lb/>perceptual <lb/>structures, <lb/>integral <lb/>or separable, <lb/>as described <lb/>in more detail <lb/>below. The nature <lb/>of that structure, <lb/>that is, the way in which the dimensions <lb/>of the space combine <lb/>perceptually, <lb/>affects <lb/>how an observer <lb/>perceives <lb/>an <lb/>object. We posit that this distinction <lb/>between perceptual <lb/>structures <lb/>is a key to <lb/>performance <lb/>of multidimensional <lb/>input <lb/>devices on multidimensional <lb/>tasks. <lb/>Hence, two three-dimensional <lb/>tasks, such as those in our experiment, <lb/>may <lb/>seem equivalent, <lb/>but if they involve <lb/>different <lb/>types of perceptual <lb/>spaces, they <lb/>should be assigned to correspondingly <lb/>different <lb/>input <lb/>devices. <lb/>Three-Dimensional <lb/>Tracker <lb/>A three-dimensional <lb/>tracker, <lb/>such as the Polhemus <lb/>3SPACE <lb/>or Ascension <lb/>Bird, is a three-dimensional <lb/>absolute-position <lb/>locator. In contrast, <lb/>a mouse is <lb/>a two-dimensional <lb/>relative-position <lb/>locator. <lb/>The three-dimensional <lb/>tracker <lb/>reports <lb/>its position <lb/>in three-space <lb/>relative <lb/>to a user-defined <lb/>origin. <lb/>(In fact, <lb/>the Polhemus <lb/>and Ascension <lb/>devices also report their rotational <lb/>orientation, <lb/>but we have focused on position <lb/>only.) The device allows a user to input three <lb/>coordinates <lb/>or data values <lb/>simultaneously <lb/>and to input <lb/>changes <lb/>that <lb/>cut <lb/>across all three <lb/>coordinate <lb/>axes in a single <lb/>operation. <lb/>Such a device is <lb/>obviously <lb/>useful for pointing <lb/>in three-space, <lb/>but it is also applicable <lb/>in any <lb/>other situation <lb/>that involves <lb/>changing <lb/>three values simultaneously. <lb/>A mouse, <lb/>in comparison, <lb/>requires <lb/>two operations <lb/>to manipulate <lb/>three variables. <lb/>One <lb/>commonly <lb/>used design for mapping <lb/>three variables <lb/>(such as x, y, and z for <lb/>zooming <lb/>and panning) <lb/>onto a mouse <lb/>allows <lb/>two of the variables <lb/>( z and y) to <lb/>be input <lb/>simultaneously <lb/>in normal <lb/>operational <lb/>mode and the third <lb/>(z) to be <lb/>controlled <lb/>through <lb/>a mode change button <lb/>that temporarily <lb/>turns the mouse <lb/>into a one-dimensional <lb/>slider. A technological <lb/>view of these two alternatives <lb/>suggests <lb/>that the three-dimensional <lb/>tracker <lb/>is logically <lb/>a superset <lb/>of the <lb/>two-dimensional <lb/>mouse (provided <lb/>they are both used as absolute <lb/>devices, i.e., <lb/>the mouse is not lifted from its pad), since it provides <lb/>the same two outputs <lb/>plus a third. <lb/>Thus, the three-dimensional <lb/>tracker <lb/>should <lb/>always be used in <lb/>place of a mouse since it is always at least as good-and <lb/>sometimes <lb/>better. <lb/></body>

			<note place="footnote">ACM TransactIons <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. <lb/></note>

			<note place="headnote">Integrality and Separability <lb/>. <lb/></note>

			<page>5 <lb/></page>

			<body>This also assumes ideal devices (that do not exist) with equal cost and equal <lb/>accuracy and the absence of other ergonomic <lb/>differences <lb/>in such parameters <lb/>as control-display <lb/>ratio, nonlinearities, <lb/>instabilities, <lb/>size, shape, and weight. <lb/>Nevertheless, <lb/>our intuition <lb/>tells us that this is unlikely <lb/>to be true-but <lb/>why? <lb/>Our goal is to base such judgments <lb/>on a firmer <lb/>theoretical <lb/>foundation. <lb/>History of Input Device Frameworks <lb/>From the inception <lb/>of interactive <lb/>computer <lb/>graphics, <lb/>researchers <lb/>have pro-<lb/>posed a number <lb/>of frameworks <lb/>that organize <lb/>knowledge <lb/>about input <lb/>devices <lb/>to simplify <lb/>the job of selecting <lb/>an appropriate <lb/>device for a task. The earliest <lb/>works focused on equating <lb/>the physical <lb/>properties <lb/>of different <lb/>input <lb/>devices <lb/>to minimize <lb/>the programming <lb/>effort in substituting <lb/>one device for another. <lb/>Later <lb/>systems <lb/>added knowledge <lb/>about device pragmatic <lb/>and task require-<lb/>ments to better capture <lb/>their qualities <lb/>and use. <lb/>An early abstraction <lb/>is that of the logical device found in device-indepen-<lb/>dent <lb/>graphics <lb/>packages <lb/>developed <lb/>from <lb/>standards <lb/>such as ACMS <lb/>Core <lb/>Graphics <lb/>System [GSPC 1977]. Devices were assigned to logical-device <lb/>classes <lb/>based on how they performed <lb/>fundamental <lb/>user actions. Foley et al.&apos;s [1984] <lb/>taxonomy <lb/>of interaction <lb/>techniques <lb/>improved <lb/>this concept by adding a middle <lb/>layer that made explicit <lb/>the fact that more than one interaction <lb/>technique <lb/>may perform <lb/>a given elementary <lb/>task. However, <lb/>both approaches <lb/>considered, <lb/>for example, <lb/>selecting <lb/>with a joystick <lb/>or trackball <lb/>equivalent. <lb/>They hid the <lb/>crucial pragmatic <lb/>aspects of haptic input by treating <lb/>devices that output <lb/>the <lb/>same information <lb/>as equivalent, <lb/>despite <lb/>the different <lb/>subjective <lb/>qualities <lb/>they present to the user. <lb/>Buxton <lb/>[1986] recognized <lb/>the importance <lb/>of these qualitative <lb/>differences <lb/>which he called pragmatic <lb/>attributes. <lb/>He developed <lb/>a taxonomy <lb/>that orga-<lb/>nized continuous-input <lb/>devices by property <lb/>(position, <lb/>motion, <lb/>pressure) <lb/>and <lb/>the number <lb/>of dimensions. <lb/>A tablet, <lb/>light pen, and two-dimensional <lb/>joystick <lb/>have two-dimensions <lb/>and sense position, <lb/>but they differ from a two-dimen-<lb/>sional trackball <lb/>because they sense motion. While this approach <lb/>can point out <lb/>that <lb/>substituting <lb/>a trackball <lb/>for a joystick <lb/>is not equivalent, <lb/>it does not <lb/>explain <lb/>why. <lb/>Mackinlay <lb/>et al. expanded <lb/>Buxton&apos;s <lb/>taxonomy <lb/>to include most input devices <lb/>and complex controls <lb/>[Card et al. 1991; Mackinlay <lb/>et al. 1990]. One feature <lb/>of <lb/>their approach <lb/>is an evaluation <lb/>technique <lb/>for comparing <lb/>alternative <lb/>designs <lb/>in terms of expressiveness <lb/>(e.g., is the meaning <lb/>exactly conveyed) <lb/>and effec-<lb/>tiveness <lb/>(e.g., is the meaning <lb/>conveyed <lb/>with <lb/>felicity). <lb/>Their <lb/>approach <lb/>both <lb/>furthers <lb/>our understanding <lb/>of the structure <lb/>of input <lb/>device space and recog-<lb/>nizes that human <lb/>performance <lb/>issues are important <lb/>for understanding <lb/>how a <lb/>device actually <lb/>works in a given situation. <lb/>Although <lb/>some relatively <lb/>straight-<lb/>forward <lb/>human <lb/>factors <lb/>issues are handled <lb/>formally, <lb/>such as matching <lb/>the <lb/>size of the domain <lb/>and range of a value, the more subtle pragmatic <lb/>of input <lb/>device usage and task characteristics <lb/>are still handled <lb/>by a set of specific <lb/>rules. <lb/>Bleser [1991] developed <lb/>a device taxonomy <lb/>and input model that explicitly <lb/>incorporated <lb/>the physical <lb/>attributes <lb/>of input <lb/>devices, including <lb/>the notion of <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. <lb/></note>

			<page>6. <lb/></page>

			<note place="headnote">Robert J. K. Jacob et al. <lb/></note>

			<body>the physical <lb/>separability <lb/>of input <lb/>degrees of freedom, <lb/>and knowledge <lb/>about <lb/>task requirements. <lb/>The taxonomy <lb/>and model were used in an interactive <lb/>design tool to suggest one or more natural <lb/>interaction <lb/>techniques <lb/>based on a <lb/>description <lb/>of an interaction <lb/>task [Bleser <lb/>and Sibert 1990]. The model intro-<lb/>duces a set of heuristic <lb/>rules and a pattern-matching <lb/>procedure <lb/>rather <lb/>than a <lb/>more general, <lb/>theoretical <lb/>framework, <lb/>but it highlights <lb/>the need for such <lb/>information <lb/>in the design process. <lb/>Therefore, <lb/>while <lb/>current <lb/>frameworks <lb/>include <lb/>knowledge <lb/>about <lb/>physical <lb/>structure, <lb/>pragmatic, <lb/>and some task requirements, <lb/>it is not enough <lb/>to <lb/>explain <lb/>why the three-dimensional <lb/>tracker <lb/>is not always better. We suggest <lb/>that what is also needed is to move from an ad hoc understanding <lb/>of input <lb/>devices <lb/>and task requirements <lb/>to the added leverage <lb/>of incorporating <lb/>a <lb/>predictive <lb/>theoretical <lb/>framework <lb/>that allows reasoning <lb/>about the utility <lb/>of a <lb/>device for a particular <lb/>task. To help put the study of multidimensional <lb/>input <lb/>devices on a firmer <lb/>theoretical <lb/>footing, <lb/>we extend the theory of processing <lb/>of <lb/>perceptual <lb/>structure <lb/>to interactive <lb/>graphical <lb/>manipulation <lb/>[Garner <lb/>1974; <lb/>Garner <lb/>and Felfody <lb/>1970]. Our research <lb/>hypothesis <lb/>is that <lb/>performance <lb/>improves <lb/>when the perceptual <lb/>structure <lb/>of the task matches <lb/>the control <lb/>structure <lb/>of the device. To test our hypothesis, <lb/>we conducted <lb/>an experiment <lb/>in which subjects <lb/>performed <lb/>two tasks that have different <lb/>perceptual <lb/>struc-<lb/>tures, using two input <lb/>devices with correspondingly <lb/>different <lb/>control <lb/>struc-<lb/>tures, a three-dimensional <lb/>tracker <lb/>and a mouse. The data analysis <lb/>examined <lb/>several <lb/>aspects <lb/>of performance: <lb/>task completion <lb/>time, <lb/>time <lb/>to reach <lb/>an <lb/>absolute <lb/>accuracy criterion, <lb/>and differences <lb/>among the trajectories <lb/>generated <lb/>by subjects using the three-dimensional <lb/>tracker <lb/>as they completed <lb/>each task. <lb/>The results <lb/>converge to confirm <lb/>the utility <lb/>of matching <lb/>the perceptual <lb/>struc-<lb/>ture of the task and the control <lb/>structure <lb/>of the input <lb/>device. <lb/>BACKGROUND <lb/>This work merges two separate <lb/>threads <lb/>of research. <lb/>One, described <lb/>above, is <lb/>the understanding <lb/>of input devices in human-computer <lb/>interaction, <lb/>from the <lb/>logical-device <lb/>concept through <lb/>more recent taxonomies <lb/>and tools. The other <lb/>gives insight <lb/>into task and performance <lb/>issues; this is the theory <lb/>of the <lb/>processing <lb/>of perceptual <lb/>structure <lb/>of a multidimensional <lb/>space formed by the <lb/>attributes <lb/>of an object. <lb/>A multidimensional <lb/>object is characterized <lb/>by its attributes. <lb/>A small red <lb/>circle has size, color, shape, and location. <lb/>Investigations <lb/>into spatial <lb/>struc-<lb/>tures that describe the perception <lb/>of such attributes <lb/>[Attneave <lb/>1950; Shepard <lb/>1964] led Garner <lb/>[ 1974] <lb/>to observe <lb/>the <lb/>attributes <lb/>of some <lb/>visual <lb/>objects <lb/>combine <lb/>perceptually <lb/>to form a unitary <lb/>whole, while <lb/>those of other objects <lb/>remain <lb/>more distinct <lb/>and identifiable. <lb/>Attributes <lb/>that combine <lb/>perceptually <lb/>are said to be integral; <lb/>those that remain <lb/>distinct <lb/>are separable. <lb/>For example, <lb/>value (lightness) <lb/>and chroma (saturation) <lb/>of a color are perceived <lb/>integrally, <lb/>while <lb/>size and lightness <lb/>of an object are perceived <lb/>separably <lb/>[Handel <lb/>and <lb/>Imai 1972]. The horizontal <lb/>and vertical <lb/>positions <lb/>of a single dot in the middle <lb/>of an outline <lb/>square <lb/>are integral <lb/>[Garner <lb/>1974], but color and shape are <lb/>separable <lb/>[ Imai and Garner <lb/>1968]. <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. <lb/></note>

			<note place="headnote">Integrality and Separability <lb/>. <lb/></note>

			<page>7 <lb/></page>

			<body>Integral <lb/>and separable <lb/>define two classes of perceptual <lb/>structure <lb/>that mark <lb/>the endpoints <lb/>of a continuum <lb/>rather <lb/>than forming <lb/>a sharp dichotomy. <lb/>Where <lb/>an object falls can be determined <lb/>by two operational <lb/>methods. <lb/>First, integral <lb/>and separable <lb/>objects can be distinguished <lb/>by direct <lb/>similarity <lb/>scaling, <lb/>a <lb/>technique <lb/>that <lb/>measures <lb/>the perceived <lb/>similarity <lb/>among <lb/>objects. <lb/>In this <lb/>procedure, <lb/>subjects are asked to compare <lb/>pairs of objects and derive a value <lb/>that indicates <lb/>how alike they are overall. These measures <lb/>are then compared <lb/>to the actual <lb/>Euclidean <lb/>and city-block <lb/>distances <lb/>in the attribute <lb/>space. <lb/>Integral <lb/>objects <lb/>are those related <lb/>by the Euclidean <lb/>metric <lb/>(distance <lb/>in <lb/>Euclidean <lb/>space); subjects&apos; judgments <lb/>are based on the overall <lb/>sameness <lb/>of <lb/>the objects. Separable <lb/>objects are related by the city-block <lb/>metric which is the <lb/>sum of the distances <lb/>measured <lb/>parallel <lb/>to the coordinate <lb/>axes (the distance <lb/>one would <lb/>have to travel <lb/>in a city in which <lb/>all streets <lb/>run in an x or y <lb/>direction). <lb/>Their <lb/>distance <lb/>is the sum of distance <lb/>in each atttibute. <lb/>Second, <lb/>when asked to form classes of objects that have the same set of attributes <lb/>(for <lb/>example, <lb/>that vary in shape and color), observers <lb/>will partition <lb/>an integral <lb/>set into clusters <lb/>based on their overall <lb/>similarity, <lb/>but a separable <lb/>set will be <lb/>partitioned <lb/>by attribute. <lb/>Integral <lb/>objects are said to possess similarity <lb/>struc-<lb/>ture, and separable <lb/>objects dimensional <lb/>structure. <lb/>With similarity <lb/>structure, <lb/>individual <lb/>attributes <lb/>do not dominate; <lb/>with <lb/>dimensional <lb/>structure, <lb/>the at-<lb/>tributes <lb/>cannot be ignored. <lb/>Perceptual Structure Extended to Interaction <lb/>The notion of integral <lb/>and separable <lb/>can be extended <lb/>to interactive <lb/>tasks by <lb/>observing <lb/>that <lb/>manipulating <lb/>a graphical <lb/>interaction <lb/>object is simply <lb/>the <lb/>changing <lb/>of values of its attributes. <lb/>Since the attributes <lb/>of an object define a <lb/>perceptual <lb/>space, changing <lb/>these values is the same as moving <lb/>in real time <lb/>within <lb/>the perceptual <lb/>space of the object. Because integral <lb/>objects have a <lb/>similarity <lb/>structure <lb/>and follow the Euclidean <lb/>metric, <lb/>and separable <lb/>objects <lb/>have a dimensional <lb/>structure <lb/>and obey the city-block <lb/>metric, the nature of the <lb/>interaction <lb/>path can be predicted: <lb/>movement <lb/>in an integral <lb/>space should be <lb/>Euclidean, <lb/>straight-line <lb/>distance <lb/>between <lb/>two points; movement <lb/>in a separa-<lb/>ble space should be city-block <lb/>and run parallel <lb/>to the axes. In other words, <lb/>graphical <lb/>interactive <lb/>tasks have a perceptual <lb/>structure <lb/>that influences <lb/>how <lb/>they are completed. <lb/>Moreover, <lb/>the type of perceptual <lb/>structure <lb/>is the same as <lb/>the type of perceptual <lb/>structure <lb/>of the underlying <lb/>object. <lb/>Control Structure of Input Devices <lb/>The control <lb/>spaces of input <lb/>devices have similar <lb/>characteristics. <lb/>An input <lb/>device with more than one degree of freedom <lb/>can be characterized <lb/>as integral <lb/>or separable <lb/>based on whether <lb/>it is natural <lb/>(or possible) <lb/>to move diagonally <lb/>across dimensions. <lb/>With an integral <lb/>device, movement <lb/>is in Euclidean <lb/>space <lb/>and cuts across all the dimensions <lb/>of control. <lb/>A separable <lb/>device constrains <lb/>movement <lb/>to a stair-step, <lb/>city-block <lb/>pattern; <lb/>movement <lb/>occurs along one <lb/>dimension <lb/>at a time. <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. <lb/></note>

			<page>8. <lb/></page>

			<note place="headnote">Robert J. K. Jacob et al. <lb/></note>

			<body>METHOD <lb/>Our research <lb/>hypothesis <lb/>states that performance <lb/>improves <lb/>when the struc-<lb/>ture of the perceptual <lb/>space of an interaction <lb/>task mirrors <lb/>that of the control <lb/>space of the input <lb/>device. To test its validity, <lb/>we examined <lb/>two interactive <lb/>tasks, one set within <lb/>an integral <lb/>space and one in a separable <lb/>one, and two <lb/>devices, one with integral <lb/>control and one, separable. <lb/>This yields a two-by-two <lb/>experiment <lb/>with four conditions. <lb/>We predict performance <lb/>on each task will be <lb/>superior <lb/>in the condition <lb/>where the device matches <lb/>the task in integrality/ <lb/>separability. <lb/>That is, the interaction <lb/>effect between <lb/>task and device should <lb/>far exceed the main effects of task or device alone. We also predict <lb/>that the <lb/>perceptual <lb/>structure <lb/>of the task determines <lb/>how the subject manipulates <lb/>the <lb/>three-dimensional <lb/>tracker; <lb/>the path to target <lb/>should <lb/>be more nearly <lb/>Eu-<lb/>clidean with the integral <lb/>task than the separable <lb/>one. <lb/>We chose two tasks that require <lb/>adjusting <lb/>three variables <lb/>but concentrated <lb/>on task spaces that do not directly <lb/>map to three-dimensional <lb/>physical <lb/>space <lb/>and on manipulation <lb/>rather <lb/>than pointing <lb/>tasks, in order to frame a balanced <lb/>comparison. <lb/>The integral <lb/>three-attribute <lb/>task required <lb/>changing <lb/>the x-y <lb/>location <lb/>and the size of an object to match <lb/>a target. <lb/>The separable <lb/>task <lb/>required <lb/>changing <lb/>x-y location <lb/>and the color (lightness <lb/>or darkness <lb/>of <lb/>greyscale). <lb/>Studies of noninteractive <lb/>stimuli <lb/>suggested <lb/>that position <lb/>and size <lb/>are perceived <lb/>as integral <lb/>attributes,while <lb/>position <lb/>and color are perceived <lb/>as <lb/>separable <lb/>[Garner <lb/>1974]. For the integral <lb/>device, we used the Polhemus <lb/>tracker <lb/>which <lb/>permits <lb/>input <lb/>of three <lb/>integral <lb/>values. <lb/>For the separable <lb/>device, we used a conventional <lb/>mouse which permits <lb/>two integral <lb/>values, to <lb/>which we added a mode change to enable input <lb/>of a third, <lb/>separable, <lb/>value. <lb/>Our research <lb/>hypothesis <lb/>asserts that the three-degree-of-freedom <lb/>input <lb/>de-<lb/>vice (Polhemus) <lb/>will <lb/>be superior <lb/>to the two-degree-of-freedom <lb/>plus mode <lb/>change <lb/>device <lb/>(mouse) <lb/>when <lb/>the task involves <lb/>three <lb/>integral <lb/>attributes <lb/>(location/size) <lb/>rather <lb/>than two integral <lb/>plus one separable <lb/>attribute <lb/>(loca-<lb/>tion/greyscale). <lb/>Conversely, <lb/>the separable <lb/>mouse plus mode change device <lb/>will be superior <lb/>for the separable <lb/>(location/greyscale) <lb/>task. <lb/>Design <lb/>Each subject <lb/>performed <lb/>both tasks using <lb/>both devices, <lb/>constituting <lb/>a re-<lb/>peated-measures <lb/>design. Forty <lb/>subjects <lb/>(26 men and 14 women) <lb/>were ran-<lb/>domly <lb/>assigned <lb/>to four presentation <lb/>orders. <lb/>In each order, <lb/>one task was <lb/>completed <lb/>with <lb/>both <lb/>devices <lb/>before <lb/>the second <lb/>task <lb/>was presented <lb/>to control <lb/>for practice <lb/>and fatigue <lb/>with a device. Each order had a unique <lb/>sequencing, <lb/>and together <lb/>the four orders formed a latin square design so that each device <lb/>and task combination <lb/>appeared <lb/>only once at each position <lb/>in the sequence. <lb/>Subjects <lb/>were clerical, <lb/>administrative, <lb/>and technical <lb/>personnel <lb/>from <lb/>the <lb/>Information <lb/>Technology <lb/>Division <lb/>of the Naval <lb/>Research <lb/>Laboratory <lb/>who <lb/>volunteered <lb/>to participate <lb/>without <lb/>compensation. <lb/>All but two were right-<lb/>handed. <lb/>Only two had tried <lb/>a Polhemus <lb/>previously. <lb/>Thirty-seven <lb/>reported <lb/>using a mouse daily, two weekly, <lb/>and one monthly. <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. <lb/></note>

			<note place="headnote">Integrality and Separability <lb/>. <lb/></note>

			<page>9 <lb/></page>

			<body>Stimulus and Apparatus <lb/>On each trial, the subject adjusted a user-controllable <lb/>object until it matched <lb/>the location <lb/>and either <lb/>size or greyscale <lb/>level of a target. <lb/>For the size task, <lb/>the user-controllable <lb/>object was a square whose greyscale <lb/>level was 50?6 of <lb/>the total greyscale <lb/>range and whose location <lb/>and size could be adjusted <lb/>(see <lb/>Figure <lb/>1). The target <lb/>position <lb/>and size were represented <lb/>by a black outline <lb/>square. The range of sizes was 0.7 to 6.2 inches on a side. For the greyscale <lb/>task, the user-controllable <lb/>object was a square of size 2.8 inches (the midpoint <lb/>of the size range) that contained <lb/>an embedded <lb/>circle 1.5 inches in diameter <lb/>(see Figure <lb/>2). The greyscale <lb/>level of the circle was under user control, <lb/>and <lb/>the target <lb/>greyscale <lb/>level was displayed <lb/>in the outer region of the user-con-<lb/>trollable <lb/>object to facilitate <lb/>matching. <lb/>The target position <lb/>was a black outline <lb/>square. In both tasks, the user-controllable <lb/>object was translucent, <lb/>so it never <lb/>obscured <lb/>the position <lb/>target; <lb/>the background <lb/>was white <lb/>to maximize <lb/>the <lb/>range of remaining <lb/>available <lb/>intensities <lb/>that the human <lb/>vision <lb/>system can <lb/>distinguish; <lb/>and the monitor <lb/>gamma <lb/>correction <lb/>was set at a level that <lb/>enhanced <lb/>the greyscale <lb/>range of the monitor. <lb/>The maximum <lb/>size of the space of possible three-variable <lb/>targets <lb/>is a cube <lb/>13.75 inches on a side, the width of the monitor. <lb/>The restrictions <lb/>we imposed <lb/>on size and greyscale <lb/>cut down this space differently <lb/>for each task. We <lb/>required <lb/>that the entire target <lb/>square fit within <lb/>the 13.75 -by-l 1 inch screen <lb/>display area and that a target not be closer than 570 of the screen height from <lb/>the edge of the screen to allow for overshooting <lb/>the target <lb/>and to eliminate <lb/>any conflict between the edge of the target and the edge of the screen, and we <lb/>reserved <lb/>the greyscale <lb/>levels near black and white <lb/>for the target <lb/>position <lb/>outline <lb/>and screen background, <lb/>cutting <lb/>the range of allowable <lb/>intensities <lb/>by <lb/>2070. After <lb/>taking <lb/>these restrictions <lb/>into <lb/>account, <lb/>the size target <lb/>space <lb/>became a rectangular <lb/>frustrum <lb/>with more small than large targets, <lb/>and the <lb/>greyscale <lb/>space, a balanced <lb/>rectangular <lb/>prism. We made further <lb/>adjustments <lb/>to the two spaces so that they had equal volumes <lb/>with <lb/>equal number <lb/>of <lb/>targets (giving <lb/>each target the same probability <lb/>of being selected) and so that <lb/>each had a reasonable <lb/>central <lb/>value (the greyscale <lb/>midpoint <lb/>is the middle <lb/>of <lb/>the intensity <lb/>range; <lb/>the size midpoint <lb/>is the centroid <lb/>of the unbalanced <lb/>fi-ustrum), <lb/>stimulus <lb/>range, and equal range of hand movement. <lb/>A different <lb/>stimulus <lb/>set was randomly <lb/>generated <lb/>for each of the four <lb/>conditions <lb/>but constrained <lb/>by a script <lb/>so that the total three-dimensional <lb/>distance <lb/>between <lb/>one stimulus <lb/>and the next was the same across conditions. <lb/>Corresponding <lb/>trials <lb/>thus had equal distances <lb/>but different <lb/>absolute <lb/>loca-<lb/>tions. We also required <lb/>each stimulus <lb/>to differ from the preceding <lb/>one by at <lb/>least 0.5 inches in each dimension <lb/>to avoid degenerate <lb/>trials <lb/>that could be <lb/>completed <lb/>without <lb/>exercising <lb/>all three dimensions <lb/>of motion. <lb/>Each stimulus <lb/>trial was represented <lb/>in the computer <lb/>program <lb/>as a three-dimensional <lb/>point <lb/>(x, y, z), and the software <lb/>driving <lb/>the experiment <lb/>was identical <lb/>except for <lb/>how the z dimension <lb/>was displayed <lb/>on the monitor. <lb/>The x and y dimensions <lb/>of both tasks were mapped <lb/>as position, <lb/>but the z was mapped <lb/>as either size <lb/>or greyscale <lb/>level. <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994 <lb/></note>

			<page>10 <lb/>. <lb/></page>

			<note place="headnote">Robert J. K. Jacob et al. <lb/></note>

			<body>El <lb/>Fig. 1. Stimulus for the integral (size) task. The outline square is the target. The user adjusts <lb/>the location and size of the solid grey square to match the target. <lb/>u <lb/>Fig. 2. Stimulus for then~eparable (greyscale) task. The outline square gives the target location, <lb/>and the outer area of the solid square gives the target color. The user adjusts the location of the <lb/>solid grey square to match the target outline and the color of the inner circle on the grey square <lb/>to match that of the outer area. <lb/>The three-dimensional <lb/>tracker <lb/>used in the experiment <lb/>was the Polhemus <lb/>3SPACE magnetic <lb/>tracker. <lb/>It consists of a transmitter <lb/>that generates <lb/>electro-<lb/>magnetic <lb/>fields <lb/>and a wand housing <lb/>three orthogonal <lb/>coils that sense the <lb/>fields. The position <lb/>and orientation <lb/>of the wand are transmitted <lb/>to the host <lb/>computer. <lb/>In this experiment, <lb/>only the three position <lb/>values were used. The <lb/>Polhemus <lb/>was configured <lb/>as an absolute <lb/>device with the origin at what would <lb/>be the forward <lb/>end of the arm of the chair. The source was permanently <lb/>fixed <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No, 1, March 1994 <lb/></note>

			<note place="headnote">Integrality and Separability <lb/>. <lb/></note>

			<page>11 <lb/></page>

			<body>under the subject&apos;s <lb/>chair. The control-display <lb/>ratio was one inch of device <lb/>movement <lb/>to one inch of screen movement. <lb/>To improve <lb/>the performance <lb/>of <lb/>the Polhemus, <lb/>the raw position <lb/>data was smoothed <lb/>with <lb/>a small <lb/>moving <lb/>average <lb/>filter, <lb/>and we eliminated <lb/>as much metal <lb/>as possible <lb/>from the sur-<lb/>rounding <lb/>area to reduce interference <lb/>with <lb/>the electromagnetic <lb/>fields. <lb/>The <lb/>experiment <lb/>was located <lb/>away from electrical <lb/>wiring <lb/>and metal <lb/>poles; the <lb/>furniture <lb/>was wooden; <lb/>and the metal mouse pad was removed <lb/>when not in <lb/>use. The Polhemus <lb/>was initialized <lb/>from one of two precalibrated <lb/>files (one for <lb/>left-handed <lb/>use, one for right) <lb/>so that (1) the operating <lb/>area was consistent <lb/>across subjects and (2) its axes were orthogonal. <lb/>Movement <lb/>of the wand in a <lb/>plane parallel <lb/>to the screen moved the user-controllable <lb/>object in x and y. <lb/>Moving <lb/>the wand toward <lb/>the screen made the object either bigger or darker; <lb/>away made it smaller <lb/>or lighter. <lb/>The <lb/>mouse <lb/>was a standard <lb/>relative-position <lb/>optical <lb/>mouse <lb/>with <lb/>its <lb/>control-display <lb/>ratio set to minimize <lb/>the need for stroking <lb/>(picking <lb/>up and <lb/>repositioning <lb/>the mouse while moving the cursor over long distances) <lb/>in order <lb/>to make its behavior <lb/>close to that of an absolute-position <lb/>device like the <lb/>Polhemus, <lb/>Two of the three input values needed were the standard <lb/>x and y <lb/>mouse coordinates. <lb/>The third <lb/>was a mode change into a one-dimensional <lb/>slider, in which the mouse was moved along the vertical <lb/>axis of the pad while <lb/>any of the three <lb/>mouse-buttons <lb/>was depressed. <lb/>We chose this <lb/>strategy <lb/>because it is similar <lb/>to those currently <lb/>used in applications <lb/>that require <lb/>mouse input <lb/>of more than two variables. <lb/>Movement <lb/>over the optical <lb/>pad <lb/>corresponded <lb/>to moving <lb/>the user-controllable <lb/>object in x and y. Movement <lb/>while holding <lb/>the mouse button <lb/>corresponded <lb/>to changing <lb/>the size or light-<lb/>ness of the user-controllable <lb/>object; movement <lb/>toward <lb/>the top of the optical <lb/>pad (toward <lb/>the display <lb/>screen) made the object either <lb/>bigger <lb/>or darker; <lb/>toward <lb/>the bottom made it smaller <lb/>or lighter. <lb/>The computer <lb/>was a two-processor <lb/>(16 MHz) Silicon Graphics <lb/>Iris Worksta-<lb/>tion, model 4D/120G. <lb/>The program <lb/>was divided <lb/>into two processes, <lb/>which <lb/>ran concurrently <lb/>on the two processors. <lb/>Most other system processes and all <lb/>network <lb/>daemons <lb/>were eliminated. <lb/>One of our two processes <lb/>continuously <lb/>monitored <lb/>the Polhemus <lb/>over a serial port and fed data into an event queue <lb/>in shared <lb/>memory, <lb/>while <lb/>the other <lb/>drew the images <lb/>and supervised <lb/>the <lb/>experiment. <lb/>This architecture <lb/>was effective <lb/>in greatly <lb/>reducing <lb/>the often-ob-<lb/>served lag in response to movements <lb/>of the Polhemus <lb/>because handling <lb/>of the <lb/>heavy <lb/>serial <lb/>port data transfer <lb/>from the Polhemus <lb/>was performed <lb/>by a <lb/>separate <lb/>processor, <lb/>communicating <lb/>via shared memory. <lb/>Position <lb/>data from <lb/>the mouse or Polhemus <lb/>were recorded <lb/>continuously <lb/>throughout <lb/>the experi-<lb/>ment, <lb/>approximately <lb/>every <lb/>20 milliseconds. <lb/>The monitor <lb/>was a 19-inch <lb/>Hitachi, <lb/>and the gamma correction <lb/>was set at 2.7. <lb/>Procedure <lb/>The arrangement <lb/>of the apparatus <lb/>is shown to scale in Figure <lb/>3. The subject <lb/>was seated on a straight-backed <lb/>chair in front of a monitor <lb/>that was placed <lb/>on a standard <lb/>office desk. The subject was approximately <lb/>56 inches from the <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. <lb/></note>

			<page>12 <lb/>. <lb/></page>

			<note place="headnote">Robert J. K. Jacob et al <lb/></note>

			<body>B, x&apos; 19&quot; Monitor <lb/>Wooden 1 <lb/>Wooden Table <lb/>n <lb/>n-<lb/>Indlca <lb/>Mouse <lb/>Wood <lb/>Fig. 3. Room layout, precisely to scale; note how the subject sits 56 inches from the monitor. <lb/>This illustration <lb/>shows the mouse condition. For the Polhemus condition, the wooden table and <lb/>mouse were removed, and the subjects held the Polhemus wand in their right hand. The <lb/>indicator button and input device were reversed for left-handed <lb/>subjects. <lb/>monitor, <lb/>a distance <lb/>that <lb/>gave the subject <lb/>ample <lb/>room to manipulate <lb/>the <lb/>Polhemus <lb/>and reduced the interference <lb/>between <lb/>the electromagnetic <lb/>fields of <lb/>the monitor <lb/>and the Polhemus. <lb/>The mouse pad was placed on a 27.5-inch <lb/>high <lb/>table located <lb/>under <lb/>the subject&apos;s <lb/>preferred <lb/>hand. The indicator <lb/>button <lb/>was <lb/>located on another <lb/>27.75-inch <lb/>high table under the subject&apos;s other hand. The <lb/>tables <lb/>and chair were located <lb/>in the same position <lb/>for each subject. <lb/>The <lb/>subject, however, <lb/>was allowed to adjust the position <lb/>of the mouse pad and the <lb/>button <lb/>upon the table tops for comfort. <lb/>The experimenter <lb/>sat at a terminal <lb/>to <lb/>the left rear of the subject. The experiment <lb/>was conducted <lb/>in a special-pur-<lb/>pose laboratory <lb/>designed <lb/>for such work [Achille <lb/>1990]. <lb/>Subjects were required <lb/>to designate <lb/>a preferred <lb/>hand and use it to manipu-<lb/>late both devices. Information <lb/>about handedness <lb/>and choice of preferred <lb/>hand <lb/>was recorded, <lb/>as was gender <lb/>of the subject. <lb/>The information <lb/>was used to <lb/>balance the assignment <lb/>of subjects to experimental <lb/>conditions <lb/>to control <lb/>for <lb/>variation <lb/>caused by gender differences <lb/>and handedness. <lb/>The experiment <lb/>was divided <lb/>into four presentation <lb/>orders, <lb/>one for each <lb/>device and task combination. <lb/>Within <lb/>each order, the subject was first given <lb/>33 practice trials to stabilize <lb/>performance <lb/>before beginning <lb/>88 data trials. The <lb/>data trials <lb/>were subdivided <lb/>into sets of 11, with <lb/>the first in each set not <lb/>scored because it measured <lb/>the time to home the user-controllable <lb/>object from <lb/>an unknown <lb/>starting <lb/>position. <lb/>The home position <lb/>was located in the middle of <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>InteractIon, <lb/>Vol. 1, No, 1, March 1994. <lb/></note>

			<note place="headnote">Integrality and Separability <lb/>. <lb/></note>

			<page>13 <lb/></page>

			<body>the screen with the object being either <lb/>midsized <lb/>or midcolored. <lb/>Each trial <lb/>required <lb/>that the subject <lb/>change the location <lb/>and either <lb/>size or greyscale <lb/>color of the user-controllable <lb/>object using <lb/>one of the two devices until <lb/>it <lb/>matched <lb/>the position <lb/>and size or color of the target. <lb/>The subject indicated <lb/>that a match was complete <lb/>by pushing <lb/>the indicator <lb/>button. <lb/>It would have <lb/>been easy to have the computer <lb/>terminate <lb/>each trial automatically, <lb/>as soon as <lb/>a match of sufllcient <lb/>accuracy was achieved. However, <lb/>as discussed below, we <lb/>wanted <lb/>to collect data that would <lb/>allow us to investigate <lb/>a wide range of <lb/>different <lb/>accuracy <lb/>criteria <lb/>through <lb/>a retrospective <lb/>analysis <lb/>procedure, <lb/>and <lb/>thus we did not want the experimental <lb/>procedure <lb/>to constrain <lb/>the choice of <lb/>the criterion <lb/>in advance. <lb/>Within <lb/>a set of trials, <lb/>as soon as a subject pushed the indicator <lb/>button, <lb/>that <lb/>trial was ended and another <lb/>target <lb/>presented <lb/>for the next trial. An instruc-<lb/>tion screen separated <lb/>the sets of trials, <lb/>and the subject determined <lb/>when to <lb/>start <lb/>a new set. Subjects <lb/>were instructed <lb/>to rest as long as they needed <lb/>between <lb/>sets of trials. <lb/>Subjects <lb/>were encouraged <lb/>to ask questions <lb/>during <lb/>practice <lb/>but not during <lb/>the data trials. <lb/>They were instructed <lb/>that accuracy <lb/>and speed were of equal importance. <lb/>Subjects were asked to complete <lb/>a short <lb/>questionnaire <lb/>at the conclusion <lb/>of the experiment <lb/>to learn <lb/>their <lb/>opinions <lb/>about the devices and tasks and about their prior experience <lb/>with selected <lb/>input devices. Each subject took approximately <lb/>1.5 hours to finish the experi-<lb/>ment. <lb/>RESULTS AND DISCUSSION <lb/>The data analysis <lb/>is in three parts. The first looks at the time and accuracy, <lb/>when the subject <lb/>ended the trial <lb/>by pressing <lb/>the indicator <lb/>button, <lb/>that is, <lb/>when the subject thought <lb/>he or she was satisfied <lb/>with the match. The second <lb/>examines <lb/>time to reach a fixed absolute <lb/>criterion <lb/>(before the very end of the <lb/>trial); <lb/>this combines <lb/>time <lb/>and accuracy <lb/>into <lb/>a single <lb/>measure. <lb/>The last <lb/>analyzes <lb/>the difference <lb/>between <lb/>the trajectories <lb/>that subjects followed <lb/>with <lb/>the Polhemus <lb/>as they completed <lb/>each task. To facilitate <lb/>the latter <lb/>two <lb/>analyses, <lb/>we recorded <lb/>the position <lb/>of the mouse or Polhemus <lb/>approximately <lb/>every 20 ms. during <lb/>each trial. All processing <lb/>and aggregation <lb/>was conducted <lb/>after the data collection <lb/>part of the experiment <lb/>was completed. <lb/>The analysis <lb/>of questionnaire <lb/>data can be found in Jacob and Sibert [1992]. <lb/>Time to End of Trial <lb/>The first analysis <lb/>looked at time and accuracy when a subject ended a trial. <lb/>Time was measured <lb/>from the appearance <lb/>of the target <lb/>until <lb/>the subject <lb/>pressed the indicator <lb/>button. Accuracy <lb/>was total Euclidean <lb/>distance <lb/>across all <lb/>three dimensions <lb/>of the stimulus <lb/>space (x, y, and size or lightness) <lb/>from the <lb/>center of the user-controllable <lb/>object to the center of the target. The research <lb/>hypothesis <lb/>predicts <lb/>a strong interaction <lb/>effect between <lb/>task and device; the <lb/>two task and device combinations <lb/>in which <lb/>both are integral <lb/>or separable <lb/>should give superior <lb/>performance. <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. <lb/></note>

			<page>14 <lb/>. <lb/></page>

			<note place="headnote">Robert J. K. Jacob et al. <lb/></note>

			<body>Average <lb/>(mean) time to button <lb/>press, shown in Figure <lb/>4 and graphed <lb/>in <lb/>Figure <lb/>5, suggests that, as predicted, <lb/>neither <lb/>task nor device alone produced <lb/>as large an effect as the interaction <lb/>of the two. These observations <lb/>were <lb/>evaluated <lb/>with a repeated-measures <lb/>analysis <lb/>of variance. <lb/>Order of presenta-<lb/>tion was not significant <lb/>(F(3, 39) = 1.09, p &gt; 0.30), allowing <lb/>aggregation <lb/>of <lb/>the four orders. There were significant <lb/>effects for both task (l&apos;(l, <lb/>39) = 7.40, <lb/>p &lt; 0.01) and device (F(l, <lb/>39) = 7.80, p &lt; 0,01) and a highly <lb/>significant <lb/>effect for interaction <lb/>between <lb/>task and device (3&apos;(1, 39) = 69.34, p &lt; 0.0001). <lb/>An omega-squared <lb/>analysis <lb/>indicated <lb/>that 20% of the total <lb/>variance <lb/>was <lb/>accounted <lb/>for by this interaction; <lb/>this is high given the large variation <lb/>from <lb/>individual <lb/>differences. <lb/>The accuracy results, <lb/>shown in Figure <lb/>6, exhibit <lb/>a strong task difference, <lb/>with subjects less accurate <lb/>on the greyscale <lb/>task. (The small device effect is <lb/>confounded <lb/>by a task and device interaction <lb/>and so was not considered.) <lb/>These observations <lb/>were also evaluated <lb/>with a repeated-measures <lb/>analysis <lb/>of <lb/>variance. <lb/>Order <lb/>of presentation <lb/>was again not significant <lb/>(F(3, 36) = 2.29, <lb/>p &gt; 0.09), allowing <lb/>aggregation. <lb/>The task difference <lb/>was highly <lb/>significant <lb/>(F(l, 39) = 117.11, p &lt; 0.0001). Both device (F(l, 39) = 11.32, p &lt; 0.01) and <lb/>a task and device interaction <lb/>(Ill, <lb/>39) = 6.52, p &lt; 0.05) were present. <lb/>Al-<lb/>though the mean scores differed <lb/>by task, the variances <lb/>of their accuracies <lb/>are <lb/>approximately <lb/>the same, indicating <lb/>a stability <lb/>in a subject&apos;s <lb/>underlying <lb/>judgment <lb/>process. <lb/>Since the button <lb/>press indicates <lb/>when a subject thinks <lb/>the match is good <lb/>enough, <lb/>performance <lb/>time is linked <lb/>to the subject&apos;s <lb/>own maximum <lb/>accuracy <lb/>criterion. <lb/>The data showed that although <lb/>the subjects selected a wide range of <lb/>criteria, <lb/>they used a consistent <lb/>stopping <lb/>criterion <lb/>across tasks, as indicated <lb/>by the standard <lb/>deviations <lb/>of the accuracy <lb/>results. <lb/>The strong <lb/>interaction <lb/>effect in performance <lb/>times <lb/>and the high <lb/>percentage <lb/>of the variance <lb/>ac-<lb/>counted for by the interaction <lb/>strongly <lb/>support <lb/>the conclusion <lb/>that matching <lb/>integrality <lb/>or separability <lb/>of the device to that <lb/>of the task provides <lb/>an <lb/>advantage. <lb/>A common <lb/>denominator <lb/>to improving <lb/>performance <lb/>is matching <lb/>the structure <lb/>of the device and task. <lb/>Time to Absolute Criterion <lb/>The second analysis <lb/>measured <lb/>the time required <lb/>by subjects to reach a fixed <lb/>accuracy criterion <lb/>on each trial. This can be viewed as simulating <lb/>an experi-<lb/>ment in which the subject was required <lb/>to reach a certain <lb/>accuracy, <lb/>at which <lb/>point the trial was terminated <lb/>automatically. <lb/>This approach <lb/>combines <lb/>speed <lb/>and accuracy <lb/>into a single measure <lb/>and removes <lb/>the effect of an individual <lb/>subject&apos;s <lb/>personal <lb/>accuracy <lb/>criterion <lb/>for terminating <lb/>trials. <lb/>It also allows <lb/>removing <lb/>the effect of a speed-accuracy <lb/>tradeoff, <lb/>since performance <lb/>to a fixed <lb/>accuracy <lb/>criterion <lb/>is required. <lb/>Accuracy <lb/>was, again, <lb/>the overall <lb/>Euclidean <lb/>distance <lb/>to the target in the three-dimensional <lb/>space of stimuli. <lb/>The raw position <lb/>data, recorded <lb/>approximately <lb/>every 20 ms, during <lb/>each <lb/>trial, <lb/>were transformed <lb/>using linear <lb/>interpolation <lb/>into a time series with a <lb/>10-ms. period. A retroactive <lb/>data analysis <lb/>algorithm <lb/>then calculated <lb/>the last <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994 <lb/></note>

			<note place="headnote">Integrality and Separability <lb/></note>

			<body>. <lb/>Device <lb/>Integral (F&apos;olhemus) <lb/>Seoarable (Mouse) <lb/>Task <lb/>Mean (ins.) <lb/>Std. dev. <lb/>Mean . <lb/>, I <lb/>Integral (Size) <lb/>4981 <lb/>2065 <lb/>6274 <lb/>2518 <lb/>L <lb/>I (ins.) <lb/>Std. dev. <lb/>I Separable (Grey) II <lb/>5357 <lb/>I <lb/>1613 <lb/>I <lb/>483~1269 <lb/>I <lb/>Fig. 4. Time per trial in msec. <lb/>6000 <lb/>5000 <lb/>4000 <lb/>3000 <lb/>2000 <lb/>1000 <lb/>Time <lb/>per trial <lb/>In msec. <lb/>G <lb/>s <lb/>15 <lb/>-<lb/>I <lb/>I <lb/>Polhemus <lb/>Mouse <lb/>Condition <lb/>Fig. 5. Graph of mean time per trial in msec., illustrating <lb/>interaction <lb/>effect. Line marked S <lb/>shows performance on the integral (size) task, G, the separable (grey) task. <lb/>time a subject <lb/>reached <lb/>a given criterion <lb/>on each trial. <lb/>Simply <lb/>setting <lb/>an <lb/>accuracy <lb/>cutoff would underestimate <lb/>trial completion <lb/>time by terminating <lb/>a <lb/>trial when a subject just nicks a target <lb/>distance <lb/>unintentionally <lb/>while over-<lb/>shooting <lb/>the desired accuracy. With our retroactive <lb/>analysis, <lb/>however, <lb/>time is <lb/>measured <lb/>until <lb/>the subject reached <lb/>our criterion <lb/>for the last time during <lb/>a <lb/>trial, a better approximation <lb/>of performance <lb/>to that distance <lb/>from the target. <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. <lb/></note>

			<page>16 <lb/>. <lb/></page>

			<note place="headnote">Robert J. K. Jacob et al. <lb/></note>

			<body>Device <lb/>Integral (Polhemus) <lb/>Separable (Mouse) <lb/>Task <lb/>Mean (ins.) <lb/>Std. dev. <lb/>Mean (ins.) <lb/>Std. dev. <lb/>Integral (Size) <lb/>0.0805 <lb/>0.0308 <lb/>0.0630 <lb/>0.0334 <lb/>Separable (Grey) <lb/>0.1088 <lb/>0.0303 <lb/>0.1034 <lb/>0.0422 <lb/>Fig. 6. Accuracy in inches. <lb/>Retroactive <lb/>analysis <lb/>also allowed <lb/>us to produce <lb/>a series of simulated <lb/>experiments, <lb/>each having <lb/>a different <lb/>accuracy criterion. <lb/>Each such simulated <lb/>experiment <lb/>is a snapshot <lb/>of performance <lb/>to a selected <lb/>distance <lb/>from the <lb/>target. The results <lb/>from each experiment <lb/>are the average performance <lb/>times <lb/>for the four conditions. <lb/>Two hundred <lb/>evenly spaced distances <lb/>from the target <lb/>were chosen in order to investigate <lb/>how performance <lb/>changed as the distance <lb/>to the target <lb/>decreased <lb/>(i.e., as accuracy <lb/>increased). <lb/>These 200 experiments <lb/>cover the full range of behavior, <lb/>from distances <lb/>that were too far from the <lb/>target <lb/>to be considered <lb/>even a crude match, <lb/>to distances <lb/>that required <lb/>the <lb/>match <lb/>to be very good. As noted, <lb/>we could have run any one of these <lb/>experiments <lb/>by terminating <lb/>trials automatically <lb/>at a fixed accuracy criterion. <lb/>The retrospective <lb/>analysis, <lb/>however, <lb/>allows <lb/>us to simulate <lb/>many different <lb/>experiments <lb/>from the same data. (The simulation <lb/>is not entirely <lb/>precise, since <lb/>subjects&apos; behavior <lb/>would have been somewhat <lb/>different <lb/>under different <lb/>stop-<lb/>ping criteria.) <lb/>The analysis <lb/>involves <lb/>two stages. First, <lb/>the average <lb/>performance <lb/>of all <lb/>subjects was computed <lb/>for each task and device combination <lb/>at each criterion <lb/>distance <lb/>from target. A plot of these for criteria <lb/>near the target <lb/>is shown in <lb/>Figure <lb/>7. <lb/>Next, the four averages were ranked <lb/>according <lb/>to completion <lb/>time. The bar <lb/>drawn <lb/>in Figure <lb/>7 highlights <lb/>the region <lb/>in which <lb/>the rankings <lb/>follow <lb/>our <lb/>predictions, <lb/>that is, for the size task, where Polhemus <lb/>always beats mouse, <lb/>and for the greyscale <lb/>task, where mouse always beats Polhemus. <lb/>This region <lb/>contains <lb/>all the accuracies <lb/>that one would consider <lb/>to be successful <lb/>comple-<lb/>tions of the task, from very inaccurate <lb/>task performance <lb/>at the distance <lb/>0.24 <lb/>inches (Figure <lb/>8 illustrates <lb/>a 0.24-inch <lb/>match) <lb/>down to an almost <lb/>perfect <lb/>match. <lb/>The results <lb/>from several <lb/>criteria <lb/>were analyzed <lb/>further <lb/>to evaluate <lb/>the significance <lb/>of these findings, <lb/>and the results were all similar. <lb/>We present <lb/>results <lb/>for 0.099 inches, <lb/>an accuracy <lb/>reached <lb/>on 70% of all trials. <lb/>These <lb/>results <lb/>are shown in Figure <lb/>9 and graphed <lb/>in Figure <lb/>10. These observations <lb/>were evaluated <lb/>with a repeated-measures <lb/>analysis <lb/>of variance. <lb/>Neither <lb/>task <lb/>(3&apos;(1, 39) = 2.48, p &gt; 0.12) nor device (F(l, 39) = 3.18, p &gt; 0.08) was signifi-<lb/>cant, but the interaction <lb/>of task and device (#&apos;(l, 39) = 52.46, p &lt; 0.0001) <lb/>was highly significant <lb/>as predicted. <lb/>Omega squared indicated <lb/>that 22&apos;%o of the <lb/>variance <lb/>was accounted <lb/>for by this interaction. <lb/>In contrast, <lb/>task (lYo) and <lb/>device (2%) accounted <lb/>for very little. <lb/>The highly <lb/>significant <lb/>interaction <lb/>sup-<lb/>ported by the high percentage <lb/>of variance <lb/>accounted <lb/>for by the interaction <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994 <lb/></note>

			<body>&apos;&quot;&quot;&quot;&quot;&apos;&quot;r <lb/>6000 <lb/>4000 <lb/>Mean time <lb/>(in msec.) <lb/>2&quot;&quot;&quot;&quot;4------<lb/>(see text) <lb/></body>

			<note place="headnote">integrality and Separability <lb/></note>

			<body>. <lb/>-------<lb/>*&quot; <lb/>;?, <lb/></body>

			<page>17 <lb/></page>

			<body>i&quot; <lb/>Stopping criterion (in inches) <lb/>Fig. 7. Average performance <lb/>by condition over a range of stopping criteria covering 0.579 to <lb/>0.034 inches (Euclidean distance to target). The line markeds / p gives the data for th~size task <lb/>using the Polhemus; s/rnis <lb/>size task using mouse; g/pisthe <lb/>greyscale task using Polhemus; <lb/>and g/m <lb/>is greyscale task using mouse. The striped bar at the bottom indicates the criteria <lb/>where performance time rankings followed our predictions. <lb/>The value 0.24 inches at the right <lb/>endofthe <lb/>barcorresponds <lb/>to the criterion at which g/m <lb/>and g/p <lb/>cross. <lb/>again supports <lb/>the hypothesis <lb/>that matching <lb/>task and device in integrality <lb/>or <lb/>separability <lb/>leads to better performance. <lb/>The rankings <lb/>also contain <lb/>a second region <lb/>of interest, <lb/>further <lb/>from the <lb/>target. <lb/>Although <lb/>the distance <lb/>to target <lb/>in this region <lb/>is too great <lb/>to be <lb/>considered <lb/>a match, <lb/>the results <lb/>shed light <lb/>on the process of completing <lb/>a <lb/>match. This region begins at approximately <lb/>3.65 inches from target and ends <lb/>at the 0.24-inch <lb/>mark (the distance <lb/>at the right end of the bar in Figure 8). In <lb/>this early behavior, <lb/>for each task, the Polhemus <lb/>always <lb/>performed <lb/>better <lb/>than <lb/>the mouse (although <lb/>still better <lb/>on the integral <lb/>size task than <lb/>the <lb/>separable <lb/>greyscale <lb/>one). That is, for very crude, quick-and-dirty <lb/>matches, <lb/>the Polhemus <lb/>was always <lb/>faster. <lb/>Again, <lb/>several <lb/>points <lb/>in the range were <lb/>examined, <lb/>and the data for 0.987 inches are presented <lb/>here. The results <lb/>are <lb/>shown in Figure <lb/>11 and graphed <lb/>in Figure <lb/>12. A repeated-measures <lb/>analysis <lb/>of variance <lb/>was again conducted. <lb/>Both task (F(l, 39) = 143.23, p &lt; 0.0001) <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. <lb/></note>

			<page>18 <lb/>. <lb/></page>

			<note place="headnote">Robert J. K. Jacob et al <lb/></note>

			<body>Fi~. 8. Illustration <lb/>of the accuracv imdied <lb/>bv the 0.24-inch criterion <lb/>referenced in Fimme 7, <lb/>shown to scale for a 1.2-inch-wide-tar~et and&quot; user-controllable <lb/>object. Shaded square is 0.24 <lb/>inches in Euclidean distance from the outline square in x and y only, in the stimulus space. This <lb/>criterion distance is too large to be considered a match for most purposes. <lb/>Device <lb/>Integral (Polhemus) <lb/>Separable (Mouse) <lb/>Task <lb/>Mean (ins.) <lb/>Std. dev. <lb/>Mean (ins.) <lb/>Std. dev. <lb/>Integral (Size) <lb/>4062 <lb/>1523 <lb/>4501 <lb/>1424 <lb/>Separable (Grey) <lb/>4902 <lb/>1427 <lb/>4035 <lb/>938 <lb/>Fig. 9. Time in msec. to reach 0.099-inch criterion accuracy <lb/>and device (F(l, 39) = 97.60, p &lt; 0.0001) were highly <lb/>significant, <lb/>and there <lb/>was no interaction <lb/>(F(l, 39) = 0.83, p &gt; 0.37). An omega-squared <lb/>analysis <lb/>showed that 35$Z0 of the variance <lb/>was accounted <lb/>for by task and 3290 by <lb/>device in this region. <lb/>Trajectory Analysis <lb/>Our research <lb/>hypothesis <lb/>implies <lb/>that the nature <lb/>of the task influences <lb/>how it <lb/>is perceived <lb/>which, in turn, alters how the task is performed. <lb/>To examine <lb/>this <lb/>notion, <lb/>we investigated <lb/>whether <lb/>a plot of the trajectory <lb/>taken by the subject <lb/>performing <lb/>a match reflects <lb/>the perceptual <lb/>structure <lb/>of the task. The theory <lb/>of perceptual <lb/>structure <lb/>suggests <lb/>the shape of the trajectory <lb/>for each task <lb/>type; that is, integral <lb/>stimuli <lb/>exhibit <lb/>an Euclidean <lb/>pattern <lb/>(subjects&apos; <lb/>move-<lb/>ment cuts diagonally <lb/>across the dimensions) <lb/>and separable <lb/>stimuli, <lb/>a city-<lb/>block pattern <lb/>(movement <lb/>occurs along one dimension <lb/>at a time). Specifically, <lb/>in our tasks, if z (size or greyscale) <lb/>is traversed <lb/>along with <lb/>x and/or <lb/>y <lb/>(position), <lb/>then the trajectory <lb/>follows <lb/>a Euclidean <lb/>pattern. <lb/>If z is manipu-<lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No, 1, March 1994. <lb/></note>

			<note place="headnote">Integrality and Separability <lb/>. <lb/></note>

			<page>19 <lb/></page>

			<body>6000 <lb/>5000 <lb/>4000 <lb/>3000 <lb/>2000 <lb/>1000 <lb/>Time <lb/>to criteri <lb/>m msec. <lb/>G <lb/>s <lb/>I <lb/>I <lb/>Polhemus <lb/>Mouse <lb/>Condition <lb/>Fig. 10. Graph of mean time to 0.099-inch criterion in msec., illustrating <lb/>interaction <lb/>effect. Line <lb/>marked S shows performance on the integral (size) task, G, the separable (grey) task. <lb/>Device <lb/>Integral (Polhemus) <lb/>Separable (Mouse) <lb/>Task <lb/>Mean (ins.) <lb/>Std. dev. <lb/>Mean (ins.) <lb/>Std. dev. <lb/>Integral (Size) <lb/>1442 <lb/>438 <lb/>2113 <lb/>558 <lb/>Separable (Grey) <lb/>2147 <lb/>416 <lb/>2929 <lb/>688 <lb/>Fig. 11. Time in msec. to reach 0.987-inch criterion accuracy. <lb/>lated <lb/>separately <lb/>from <lb/>x and y in a stair-step <lb/>manner, <lb/>then it follows <lb/>a <lb/>city-block <lb/>pattern. <lb/>To demonstrate <lb/>this requires <lb/>two conditions, <lb/>both of which were present in <lb/>the two Polhemus <lb/>conditions <lb/>of this experiment. <lb/>First, the subject&apos;s range of <lb/>motion <lb/>must not be constrained; <lb/>both tasks must be performed <lb/>with a device <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. <lb/></note>

			<page>20 <lb/>. <lb/></page>

			<note place="headnote">Robert J. K. Jacob et al. <lb/></note>

			<body>6000 <lb/>5000 <lb/>4000 <lb/>3000 <lb/>2000 <lb/>1000 <lb/>Time <lb/>fo criten <lb/>m msec. <lb/>Polhemus <lb/>Mouse <lb/>Condition <lb/>Fig. 12. Graph of mean time to 0.987-inch criterion <lb/>in msec., illustrating <lb/>lack of interaction <lb/>effect. Line marked S shows performance on the integral (size) task, G, the separable (grey) task. <lb/>that <lb/>allows <lb/>freedom <lb/>to move in any direction. <lb/>The Polhemus <lb/>meets this <lb/>requirement. <lb/>In contrast, <lb/>the combination <lb/>of two-dimensional <lb/>mouse move-<lb/>ments and one-dimensional <lb/>slider does not because it constrains <lb/>the subject <lb/>to city-block <lb/>movement <lb/>by not allowing <lb/>all dimensions <lb/>to be manipulated <lb/>concurrently. <lb/>Second, the tasks should <lb/>differ <lb/>only minimally <lb/>to isolate <lb/>key <lb/>differences. <lb/>In this <lb/>experiment, <lb/>the software <lb/>driving <lb/>the two tasks was <lb/>identical <lb/>except for how one parameter <lb/>was visually <lb/>presented. <lb/>In both tasks, <lb/>the x and y dimensions <lb/>were displayed <lb/>as position <lb/>coordinates. <lb/>The differ-<lb/>ence lay solely in how the z dimension <lb/>was displayed, <lb/>as either <lb/>size or <lb/>greyscale. <lb/>The pictures <lb/>in Figures <lb/>13 and 14 show the average <lb/>performance <lb/>of all <lb/>subjects on one selected trial out of the 80 total scored trials. <lb/>Like-numbered <lb/>trials in each condition <lb/>had the same distance <lb/>and so could be compared. <lb/>The <lb/>trial presented <lb/>is one of the longer ones (5.885 inches out of the range 2.946 <lb/>inches to 6.875 inches) and one of the last completed <lb/>in a session (number <lb/>74 <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994 <lb/></note>

			<note place="headnote">Integrality and Separability <lb/>. <lb/></note>

			<page>21 <lb/></page>

			<body>Towi+rd <lb/>CRT <lb/>screen <lb/>Subject <lb/>Fig. 13. Picture of average Polhemus trajectory for all subjects on one trial in the integral (size) <lb/>condition. Trajectory <lb/>shows that subjects cut across all three axes in an integral fashion. The <lb/>trial begins at the upper right corner. Fine tuning is the small knot seen at the end of the trial <lb/>(to the left). <lb/>out of 80). This trial was selected because it clearly illustrates <lb/>the observed <lb/>difference <lb/>in subject performance <lb/>between <lb/>tasks. The Polhemus <lb/>trajectory <lb/>for <lb/>the size task on this trial (Figure <lb/>13) suggests that the subject was cutting <lb/>across all three axes. In contrast, <lb/>the greyscale <lb/>task (Figure <lb/>14) was com-<lb/>pleted first by resolving <lb/>the discrepancy <lb/>in x and y followed <lb/>by the discrep-<lb/>ancy in z. In other words, we do not see simultaneous <lb/>motion in the x-y plane <lb/>and along the z axis. These tasks differed <lb/>only in how z was displayed. <lb/>The <lb/>perceptual <lb/>structures <lb/>of the tasks were thus strong <lb/>enough <lb/>to alter <lb/>how <lb/>subjects performed <lb/>them physically. <lb/>Other trials that were sampled exhibited <lb/>a similar <lb/>but less pronounced <lb/>effect, <lb/>that <lb/>is, smooth, <lb/>free-form, <lb/>integral <lb/>characteristics <lb/>with <lb/>the size task and stair-step, <lb/>separable <lb/>characteristics <lb/>with the greyscale <lb/>task. <lb/>While Figures <lb/>13 and 14 visually <lb/>suggest the effect of perceptual <lb/>space on <lb/>trajectory <lb/>for a selected trial, we wish to measure <lb/>it in a more objective <lb/>way, <lb/></body>

			<note place="footnote">ACM Transactions on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. <lb/></note>

			<page>22 <lb/>. <lb/></page>

			<note place="headnote">Roberl J. K. Jacob et al, <lb/></note>

			<body>/&apos;-&apos;&apos;&quot; <lb/>Toward CRI screen <lb/>/ <lb/>Fig. 14. Picture of average trajectory <lb/>for all subjects on one trial in the separable (greyscale) <lb/>condition. Traiectorv shows that subiects did not move simultaneously <lb/>in the x-y plane and along <lb/>. <lb/>. <lb/>the z axes, consistent with separable performance. The trial begins from the top right and moves <lb/>down to the left. <lb/>over all trials. We therefore <lb/>developed <lb/>a technique <lb/>to quantify <lb/>how a subject <lb/>manipulated <lb/>the Polhemus <lb/>during <lb/>a trial. <lb/>The idea is to divide a trajectory <lb/>into small segments, <lb/>ask if the movement <lb/>in each segment <lb/>is Euclidean <lb/>or <lb/>city-block, <lb/>and then tally the proportion <lb/>of Euclidean-vers,us-city-block <lb/>seg-<lb/>ments. The procedure <lb/>involves <lb/>four steps: <lb/>-First, <lb/>the raw event data series was transformed <lb/>into a time series with a <lb/>10-ms. period. <lb/>It was then smoothed <lb/>using a 15-point <lb/>low-pass <lb/>filter <lb/>to <lb/>remove high-frequency <lb/>equipment <lb/>noise and hand tremor. <lb/>-Second, <lb/>the data were truncated <lb/>to isolate the area of interest. <lb/>A subject&apos;s <lb/>behavior <lb/>on a trial <lb/>typically <lb/>divides <lb/>into two parts: <lb/>strong, <lb/>quick move-<lb/>ments toward <lb/>the target <lb/>followed <lb/>by back-and-forth <lb/>fine-tuning <lb/>behavior. <lb/>The latter <lb/>can be seen in the small knot at the left in Figure <lb/>13; the view <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. <lb/></note>

			<note place="headnote">Integrality and Separability <lb/>. <lb/></note>

			<page>23 <lb/></page>

			<body>angle in Figure <lb/>14 obscures this behavior. <lb/>We truncated <lb/>each trial at 0.3 <lb/>inches from the target <lb/>to remove <lb/>this highly <lb/>variable <lb/>end part. (As dis-<lb/>cussed below, the sensitivity <lb/>of our results <lb/>to this specific choice of cutoff <lb/>value was very small; other choices yielded <lb/>similar <lb/>results.) <lb/>-Third, <lb/>the data for a trajectory <lb/>were segmented, <lb/>and each trajectory <lb/>was <lb/>passed through <lb/>a classification <lb/>algorithm <lb/>that labeled <lb/>the dimensions <lb/>as <lb/>having <lb/>changed <lb/>location <lb/>(movement) <lb/>or not (no movement). <lb/>A position <lb/>change of more than 0.0008 inches in one 10-ms. time step was considered <lb/>movement. <lb/>(Again, <lb/>as discussed below, the sensitivity <lb/>of the results <lb/>to the <lb/>choice of this threshold <lb/>value was small.) <lb/>-Fourth, <lb/>a recognition <lb/>algorithm <lb/>computed <lb/>the amount <lb/>of Euclidean <lb/>and <lb/>city-block <lb/>movement <lb/>used to complete <lb/>that trial. A segment <lb/>was classified <lb/>as Euclidean <lb/>if its trajectory <lb/>showed movement <lb/>in more than one dimen-<lb/>sion (except for movement <lb/>in the x-y plane, since the two tasks are both <lb/>integral <lb/>in this respect); <lb/>it was classified <lb/>as city-block <lb/>if it showed move-<lb/>ment in any single <lb/>axis or in the x-y plane. The ratio <lb/>of Euclidean <lb/>to <lb/>city-block <lb/>segments <lb/>was then <lb/>calculated <lb/>for each of the experimental <lb/>conditions. <lb/>For the selected criterion <lb/>of 0.3 inches and threshold <lb/>of 0.008 inches, the <lb/>average ratio of Euclidean <lb/>to city-block <lb/>behavior <lb/>was 1.408 for the size task <lb/>versus <lb/>1.234 for the greyscale <lb/>task. A one-tailed <lb/>pair <lb/>comparison <lb/>t-test <lb/>showed a highly <lb/>significant <lb/>difference <lb/>(t(39) = 4.297, p &lt; 0.0001), supporting <lb/>our hypothesis <lb/>that the size task is completed <lb/>in a more integral <lb/>manner <lb/>than the greyscale <lb/>task. We performed <lb/>a sensitivity <lb/>analysis <lb/>to give confi-<lb/>dence in our choice of the two parameters, <lb/>criterion <lb/>from the truncation <lb/>step <lb/>and threshold <lb/>from <lb/>classification <lb/>by computing <lb/>a t-value <lb/>for a range <lb/>of <lb/>criterion <lb/>and threshold <lb/>pairs. A series of one-tailed <lb/>paired comparison <lb/>t-tests <lb/>of these pairs was significant <lb/>throughout <lb/>the range 0.217 to 0.38 (criteria) <lb/>and 0.003 to 0.015 (threshold). <lb/>The results <lb/>confirm <lb/>that the way in which a user physically <lb/>manipulates <lb/>the Polhemus <lb/>to complete <lb/>a task depends on the perceptual <lb/>structure <lb/>of the <lb/>task. The integral <lb/>task induces <lb/>more motion <lb/>that <lb/>cuts across all three <lb/>dimensions. <lb/>The separable <lb/>task alternates <lb/>more between <lb/>changes to location <lb/>and changes to greyscale. <lb/>APPLICATION <lb/>An example <lb/>application <lb/>of this work <lb/>would <lb/>be in designing <lb/>controls <lb/>for <lb/>zooming <lb/>and panning <lb/>of a geographic <lb/>display. <lb/>Zooming <lb/>and panning, <lb/>taken <lb/>together, <lb/>involve <lb/>three degrees of freedom. <lb/>The most common <lb/>design uses a <lb/>mouse or trackball <lb/>for two-dimensional <lb/>panning <lb/>and a separate <lb/>control <lb/>for <lb/>zooming. <lb/>We claim that a user typically <lb/>does not really think <lb/>of zooming <lb/>or <lb/>panning <lb/>operations <lb/>separably, <lb/>but thinks <lb/>rather <lb/>of integral <lb/>operations <lb/>like <lb/>&quot;focus in on that area over there.&quot; <lb/>The space is thus Euclidean, <lb/>like that of <lb/>the size task in the experiment, <lb/>and, therefore, <lb/>making <lb/>the user do the two <lb/></body>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No, 1, March 1994. <lb/></note>

			<page>24 <lb/>. <lb/></page>

			<note place="headnote">Robeti J. K. Jacob et al. <lb/></note>

			<body>separately <lb/>violates <lb/>perceptual <lb/>compatibility. <lb/>It would <lb/>be more natural <lb/>to <lb/>permit <lb/>a user to make a gesture that performs <lb/>the overall operation <lb/>he or she <lb/>had in mind, <lb/>using <lb/>an integral <lb/>three-dimensional <lb/>input <lb/>device. The user <lb/>moves the puck around <lb/>in a volume <lb/>directly <lb/>in front of the display <lb/>screen. <lb/>Moving <lb/>it in the x or y direction <lb/>parallel <lb/>to the display <lb/>surface <lb/>causes <lb/>panning; <lb/>moving <lb/>it perpendicular <lb/>to the display <lb/>(directly <lb/>toward <lb/>or away <lb/>from it) causes zooming. <lb/>The user typically <lb/>moves the puck in all three <lb/>dimensions <lb/>simultaneously, <lb/>resulting <lb/>in some combination <lb/>of zooming <lb/>and <lb/>panning <lb/>and directly <lb/>reaches the view of interest. <lb/>We have demonstrated <lb/>a <lb/>mockup <lb/>of this application. <lb/>CONCLUSIONS <lb/>Our research <lb/>hypothesis <lb/>is that performance <lb/>improves <lb/>when the structure <lb/>of <lb/>the perceptual <lb/>space of a graphical <lb/>interaction <lb/>task mirrors <lb/>that <lb/>of the <lb/>control <lb/>space of the input <lb/>device. We have presented <lb/>an experiment <lb/>to test <lb/>this hypothesis <lb/>and three different <lb/>analyses <lb/>in support. <lb/>The first looked at <lb/>time and accuracy at button <lb/>press. Button <lb/>press captures <lb/>a subject&apos;s behavior <lb/>when he or she is satisfied <lb/>with the match. These outcome measures <lb/>describe <lb/>terminal <lb/>actions and give insight <lb/>into performance <lb/>at a subject&apos;s <lb/>maximum <lb/>accuracy <lb/>criterion. <lb/>The results <lb/>support <lb/>our hypothesis <lb/>that completing <lb/>the <lb/>integral <lb/>size task with <lb/>the integral <lb/>Polhemus <lb/>and the separable <lb/>greyscale <lb/>task with the separable <lb/>mouse plus mode change lead to faster performance. <lb/>The second approach <lb/>removes the variation <lb/>caused by individual <lb/>differences <lb/>in accuracy <lb/>as well as speed-accuracy <lb/>tradeoff <lb/>and allows us to simulate <lb/>a <lb/>range of different <lb/>experiments <lb/>retroactively. <lb/>We studied <lb/>performance <lb/>of a <lb/>series of fixed criteria <lb/>that combine time and accuracy into one measure. <lb/>This <lb/>approach <lb/>allowed <lb/>us to investigate <lb/>performance <lb/>at a number <lb/>of criteria <lb/>to <lb/>determine <lb/>the stability <lb/>of performance <lb/>over time. We found that within <lb/>the <lb/>range of plausible <lb/>matches, <lb/>completion <lb/>times are faster when the structure <lb/>of <lb/>the device and task match rather <lb/>than for one device or one task uniformly. <lb/>The third <lb/>analysis <lb/>examined <lb/>the trajectory <lb/>of the Polhemus <lb/>on both tasks. <lb/>The research <lb/>hypothesis <lb/>suggests that if the device used by the subject is not <lb/>restrictive, <lb/>the path taken will be influenced <lb/>by the structure <lb/>of the percep-<lb/>tual space of the task. Our analysis <lb/>confirms <lb/>that the perceptual <lb/>structure <lb/>of <lb/>the task determines <lb/>how an input device is used. <lb/>The overall <lb/>conclusion <lb/>confirms <lb/>our prediction <lb/>that <lb/>choosing <lb/>an input <lb/>device for a task requires <lb/>looking <lb/>at the deeper perceptual <lb/>structure <lb/>of the <lb/>task, the device, and the interrelationship <lb/>between <lb/>task and device. We have <lb/>shown <lb/>that <lb/>perceptual <lb/>structure <lb/>determines <lb/>how a user approaches <lb/>an <lb/>interactive <lb/>manipulation <lb/>task. Tasks in which <lb/>the perceptual <lb/>structure <lb/>is <lb/>integral <lb/>operate by similarity <lb/>and follow the Euclidean <lb/>metric. The attributes <lb/>of an integral <lb/>object do not dominate <lb/>and are viewed as a unitary <lb/>whole. They <lb/>are manipulated <lb/>as a unit. <lb/>Tasks <lb/>set in a separable <lb/>space operate <lb/>by <lb/>dimensional <lb/>structure <lb/>and obey the city-block <lb/>metric. <lb/>The attributes <lb/>of a <lb/>separable <lb/>object cannot be ignored <lb/>and are manipulated <lb/>along each attribute <lb/></body>

			<note place="footnote">ACM TransactIons <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No 1, March 1994, <lb/></note>

			<note place="headnote">Integrality and Separability <lb/>. <lb/></note>

			<page>25 <lb/></page>

			<body>in turn. If the input device supports <lb/>the type of motion <lb/>required <lb/>by the task, <lb/>then the task can be performed <lb/>in an effkient <lb/>manner. <lb/>If the device limits <lb/>necessary <lb/>motion <lb/>or does not restrict <lb/>motion <lb/>appropriately, <lb/>efficiency <lb/>can <lb/>decrease. <lb/>The interplay <lb/>between <lb/>task and device was more important <lb/>in <lb/>determining <lb/>performance <lb/>than either task or device alone. <lb/>Current <lb/>input <lb/>device taxonomies <lb/>and other frameworks <lb/>developed <lb/>to aid <lb/>device selection <lb/>have typically <lb/>started <lb/>from the point of view of input <lb/>device <lb/>structure. <lb/>They recognize the need for what Buxton <lb/>calls pragmatic, <lb/>Mackin-<lb/>lay, Card, and Robertson <lb/>term expressiveness <lb/>and effectiveness <lb/>ratings, <lb/>and <lb/>Bleser includes <lb/>in her input model, but they relegate <lb/>these crucial pragmatic <lb/>aspects of haptic <lb/>input <lb/>to rules based primarily <lb/>on ad hoc testing <lb/>or expert <lb/>judgment. <lb/>We suggest <lb/>incorporating <lb/>a predictive <lb/>theoretical <lb/>framework <lb/>to <lb/>allow formal reasoning <lb/>about selecting <lb/>an input device. We offer the approach <lb/>of extending <lb/>a perceptual <lb/>theory and provide <lb/>as an example <lb/>our extension <lb/>of <lb/>the processing <lb/>of perceptual <lb/>structure <lb/>to interactive <lb/>stimuli. <lb/></body>

			<div type="acknowledgement">ACKNOWLEDGMENTS <lb/>We thank Jim Ballas, <lb/>Susan Kirschenbaum, <lb/>and Astrid <lb/>Schmidt-Nielsen <lb/>for <lb/>help and advice, particularly <lb/>in experimental <lb/>design and data analysis; <lb/>Lisa <lb/>Achille, <lb/>Jeff Brown, <lb/>Robert <lb/>Carter, <lb/>Dave Heide, <lb/>Connie <lb/>Heitmeyer, <lb/>John <lb/>Sibert, <lb/>and Stan Wilson <lb/>for all kinds <lb/>of help with this research; <lb/>our NRL <lb/>colleagues <lb/>who took time from their <lb/>own work to serve as experimental <lb/>subjects; <lb/>and Stuart <lb/>Card and the anonymous <lb/>referees <lb/>for their thoughtful <lb/>reading <lb/>and helpful <lb/>comments. <lb/></div>

			<listBibl>REFERENCES <lb/>ACHILLE, L. B. <lb/>1990. <lb/>Considerations <lb/>in the design <lb/>and development <lb/>of a human <lb/>computer <lb/>interaction <lb/>laboratory. <lb/>NRL Rep. 9279, Naval Research <lb/>Laboratory, <lb/>Washington, <lb/>D.C. <lb/>ATTNEAVE, F. 1950. Dimensions of similarity. <lb/>Am. J. Psychol. <lb/>63, 516-556. <lb/>BLESER, T. W. <lb/>1991. <lb/>An input <lb/>device model of interactive <lb/>systems <lb/>design. Doctoral <lb/>Disserta-<lb/>tion, The George Washington <lb/>Univ., Washington, <lb/>D.C. <lb/>BLESER,T. W. AND SIBERT,J. L. 1990. Toto: A tool for selecting interaction <lb/>techniques. In <lb/>Proceedings <lb/>of the ACM <lb/>UIST <lb/>&apos;90 Symposium <lb/>on User Interface <lb/>Software <lb/>and Technology. <lb/>ACM Press, New York, 135-142. <lb/>BUXTON, W. <lb/>1986. <lb/>There&apos;s <lb/>more to interaction <lb/>than meets the eye: Some issues in manual <lb/>input. <lb/>In User Centered <lb/>System Design: <lb/>New Perspectives <lb/>on Human-Computer <lb/>Interaction. <lb/>Lawrence Erlbaum, Hillsdale, N.J., 319-337. <lb/>CARD, S. K., MACKINLAY, J. D., AND ROBERTSON, G. G. <lb/>1991. <lb/>A morphological <lb/>analysis <lb/>of the <lb/>design space of input <lb/>devices. ACM Trans. <lb/>Znf. Sys. 9, 2, 99-122. <lb/>CARD, S. K., MORAN, T. P., ANDNEWELL,A. 1983. The Psychology of Human-Computer <lb/>Interac-<lb/>tion. Lawrence Erlbaum, Hillsdale, <lb/>N.J. <lb/>FOLEY, J. D., WALLACE, V. L. AND CHAN, P. 1984. The human factors of computer graphics <lb/>interaction <lb/>techniques. IEEE Comput. <lb/>Graph. <lb/>Appl. 4, 11, 13-48. <lb/>GARNER, W. R. 1974. The Processing <lb/>of Information <lb/>and Structure. <lb/>Lawrence Erlbaum, <lb/>Po-<lb/>tomac, Md. <lb/>GARNER, W. R. AND FELFOLDY, G. L. <lb/>1970. <lb/>Integrality <lb/>of stimulus <lb/>dimensions <lb/>in various <lb/>types <lb/>of information <lb/>processing. <lb/>Cog. Psychol. <lb/>1, 225-241. <lb/>GSPC. <lb/>1977. Status report of the Graphics Standards Planning Committee. Comput. <lb/>Graph. <lb/>11. <lb/></listBibl>

			<note place="footnote">ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. <lb/></note>

			<page>26 <lb/>. <lb/></page>

			<note place="headnote">Robert J. K. Jacob et al. <lb/></note>

			<listBibl>HANDEL, S. AND IMAI, S. <lb/>1972. <lb/>The free classification <lb/>of analyzable <lb/>and unanalyzable <lb/>stimuli. <lb/>Percep. Psychophy. <lb/>12, 108-116. <lb/>IMAI, S. AND GARNER, W. R. 1968. <lb/>Structure <lb/>in perceptual <lb/>classification. <lb/>Psychonom. <lb/>Mono-<lb/>graph <lb/>Suppl. <lb/>2, 9, Whole No. 25. <lb/>JACOB, R. J. K. AND SIBERT, L. E. <lb/>1992. <lb/>The perceptual <lb/>structure <lb/>of multidimensional <lb/>input <lb/>device selection. <lb/>In Proceedings <lb/>of the ACM <lb/>CHI &apos;92 Human <lb/>Factors in Computing <lb/>Systems <lb/>Conference. <lb/>ACM Press, New York, 211-218. <lb/>MACKINLAY, J. D., CARD, S. K., AND ROBERTSON, G. G. <lb/>1990. <lb/>A semantic <lb/>analysis <lb/>of the design <lb/>space of input <lb/>devices. Hum. Comput. <lb/>Interact. <lb/>5, 145-190. <lb/>SHEPARD, R. N. <lb/>1964. <lb/>Attention <lb/>and the metric <lb/>structure <lb/>of the stimulus <lb/>space. J. Math. <lb/>Psychol. <lb/>1, 54-87. <lb/></listBibl>

			<front>Received March 1993; revised December 1993; accepted January 1994 <lb/>ACM Transactions <lb/>on Computer-Human <lb/>Interaction, <lb/>Vol. 1, No. 1, March 1994. </front>


	</text>
</tei>
