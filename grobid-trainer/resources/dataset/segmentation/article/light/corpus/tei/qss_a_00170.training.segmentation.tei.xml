<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>Towards Establishing a Research Lineage via Identification of <lb/>Significant Citations <lb/>Tirthankar Ghosal § * , Piyush Tiwary † * , Robert Patton ‡ and Christopher Stahl ‡ <lb/> §Institute of Formal and Applied Linguistics, Charles University, CZ <lb/> †Indian Institute of Science, India <lb/> ‡Oak Ridge National Laboratories, US <lb/> §ghosal@ufal.mff.cuni.cz <lb/> †piyushtiwary@iisc.ac.in <lb/> ‡(pattonrm, stahlcg)@ornl.gov <lb/>October 26, 2021 <lb/>Abstract <lb/>Finding the lineage of a research topic is crucial for understanding the prior state of <lb/>the art and advancing scientific displacement. The deluge of scholarly articles makes <lb/>it difficult to locate the most relevant previous work. It causes researchers to spend a <lb/>considerable amount of time building up their literature list. Citations play a crucial <lb/>role in discovering relevant literature. However, not all citations are created equal. The <lb/>majority of the citations that a paper receives provide contextual and background in-<lb/>formation to the citing papers. In those cases, the cited paper is not central to the theme <lb/>of citing papers. However, some papers build upon a given paper, further the research <lb/>frontier. In those cases, the concerned cited paper plays a pivotal role in the citing <lb/>paper. Hence, the nature of citation the former receives from the latter is significant. <lb/>In this work, we discuss our investigations towards discovering significant citations of <lb/>a given paper. We further show how we can leverage significant citations to build a <lb/>research lineage via a significant citation graph. We demonstrate the efficacy of our idea <lb/>with two real-life case studies. Our experiments yield promising results with respect <lb/>to the current state-of-the-art in classifying significant citations, outperforming the ear-<lb/>lier ones by a relative margin of 20 points in terms of precision. We hypothesize that <lb/>such an automated system can facilitate relevant literature discovery and help identify <lb/>knowledge flow for a particular category of papers. <lb/>Keywords-citation classification, citation significance detection, machine learning, research <lb/>lineage, citation graph, academic influence <lb/></front>

			<body>1 Introduction <lb/>Literature searches are crucial to discover relevant publications. The knowledge discovery that <lb/>ensues forms the basis of understanding a research problem, finding the previously explored fron-<lb/>tiers, identifying research gaps, which eventually leads to the development of new ideas. However, <lb/>with the exponential growth of scientific literature (including published papers and pre-prints) <lb/>(Ghosal, Sonam, Ekbal, Saha, &amp; Bhattacharyya, 2019), it is almost impossible for a researcher to <lb/>go through the entire body of the scholarly works even in a very narrow domain. Citations play <lb/>an important role here in finding the relevant articles that further topical knowledge. However, <lb/>not all citations are equally (Zhu, Turney, Lemire, &amp; Vellino, 2015) effective in finding relevant re-<lb/>search. A majority of the papers cite a work contextually (Pride &amp; Knoth, 2017a) for providing <lb/>additional background context. Such background contextual citations help in the broader under-<lb/>standing; however, they are not central to the citing paper&apos;s theme. Some papers use the ideas in <lb/>a given paper, build upon those ideas, and displace the body of relevant research. Such papers are <lb/>expected to acknowledge the prior work (via citing them) duly. However, the nature of citation, <lb/>in this case, is different from that of contextual citations. These citations, which heavily rely on a <lb/></body>

			<front>* equal contribution <lb/>1 <lb/>Ghosal, T., Tiwary, P., Patton, R., and Stahl, C. (2021) Towards Establishing a Research Lineage via Identification of <lb/>Significant Citations. Quantitative Science Studies. Advance Publication. https://doi.org/10.1162/qss_a_00170 <lb/>Copyright: © 2021 Tirthankar Ghosal, Piyush Tiwary, Robert Patton and Christopher Stahl. Published under a Creative <lb/>Commons Attribution 4.0 International (CC BY 4.0) license. <lb/>Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></front>

			<body>given work or build upon that work, are significant citations. However, the current citation count <lb/>metric puts equal weights on all the citations. Therefore, it is inadequate to identify the papers that <lb/>have significantly cited a given work and may have taken the relevant research forward. Identify-<lb/>ing such significant citations are hence crucial to the literature study. <lb/>It is not uncommon that authors sometimes fail to acknowledge relevant papers&apos; role in stemming <lb/>up their ideas (Rousseau, 2007; Van Noorden, 2017). As a result, researchers spend a lot of their <lb/>time searching for the most relevant papers to their research topic, thereby locating the subsequent <lb/>papers that carried forward a given scientific idea. It is usually desirable for a researcher to un-<lb/>derstand the story behind a prior work and trace the concept&apos;s emergence and gradual evolution <lb/>through publications, thereby identifying the knowledge flow. Researchers ideally curate their lit-<lb/>erature base by identifying significant references to a given paper and then hierarchically locating <lb/>meaningful prior work. <lb/>The idea of recognizing significant citations is also important to understand the true impact of given <lb/>research or facility. To understand how pervasive particular research was in the community, it is <lb/>essential to understand its influence beyond the direct citations it received. To this end, tracking <lb/>transitive influence of research via identifying significant citations could be one possible solution. <lb/>In this work, we develop automatic approaches to trace the lineage of given research via transi-<lb/>tively identifying the significant citations to a given article. The overall objective of our work is <lb/>two-fold: <lb/>• Accelerate relevant literature discovery via establishing a research lineage <lb/>• Find the true influence of a given work and its pervasiveness in the community beyond <lb/>citation counts <lb/>There are two aspects to the problem: identifying the relevant prior work and identifying the follow-up <lb/>works that stemmed or are influenced by the current work. The first aspect would facilitate relevant <lb/>prior literature discovery for a paper. In contrast, the second aspect would facilitate discovering <lb/>knowledge flow in subsequent relevant papers. Obviously, our approach would not be a one shoe <lb/>fits for all. Still, we believe it is effective to find investigations that build upon relevant priors, <lb/>facilitate relevant literature discovery, and thereby steer towards identifying the pervasiveness of <lb/>a given piece of research in the community. We base our work to classify citations as contextual or <lb/>significant and trace the lineage of research in a citation graph via identifying significant edges. <lb/>The major contributions of the current work are: <lb/>1. We use a set of novel and rich features to classify citations as significant or contextual. <lb/>2. A graph-based approach to trace the lineage of a given research work leveraging on citation <lb/>classification. <lb/>2 Research Lineage <lb/>The mechanism of citations in academia is not always transparent (Van Noorden &amp; Singh Chawla, <lb/>2019; Vîiu, 2016; West, Stenius, &amp; Kettunen, 2017). Problems like coercive citations (Wilhite &amp; Fong, <lb/>2012), anomalous citations (Bai, Xia, Lee, Zhang, &amp; Ning, 2016), citation manipulation (Bartneck <lb/>&amp; Kokkelmans, 2011), rich gets richer effects (Ronda-Pupo &amp; Pham, 2018), discriminatory citation <lb/>practices (Camacho-Mi ñano &amp; N ú ñez-Nickel, 2009), etc. has infested the academic community. <lb/>However, in spite of all these known issues, citation counts and h-indices still remain the measures <lb/>of research impact and tools for academic incentives, though long-debated by many (Cerdá, Nieto, <lb/>&amp; Campos, 2009; Laloë &amp; Mosseri, 2009). Usually, we measure the impact of a given paper by the <lb/>direct citations it receives. However, a given research may have induced a transitive effect on other <lb/>papers, which is not apparent with the current citation count measures. Figure 1 shows a sample <lb/>citation network where A could be a paper or a research facility. We want to know how pervasive <lb/>was the research or facility A in the community. At d=1 are the direct citations to A. We see article <lb/>B cites A significantly, or B is inspired by A. Other citations to A are background. At citation depth <lb/>d=2, we see that article C and article D significantly cites B (direct citation). We see that C also cites <lb/></body>

			<page>2 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<body>Figure 1: Research Lineage <lb/>A significantly. Finally, at citation depth d=3, E significantly cites C. We intend to understand if <lb/>there is a lineage of research from A to E (A→B→C→E). Although E does not cite A directly, can <lb/>we identify A&apos;s influence on E? If E is a seminal work receiving hundreds of citations, can we infer <lb/>that A was the prior work that indirectly inspired E? We are interested in discovering such hidden <lb/>inspirations to honestly assess the contributions of a research article or a facility. <lb/>3 Related Work <lb/>Measuring academic influence has been a research topic since publications associate with academic <lb/>prestige and incentives. Several metrics (Impact Factor, Eigen Factor, h-index, citation counts, alt <lb/>metrics, etc.) came up to comprehend research impact efficiently. Still, each one is motivated on <lb/>a different aspect and has found varied importance across disciplines. Zhu et al. (2015) did pio-<lb/>neering work on academic influence prediction leveraging on citation context. Shi, Wang, Chen, <lb/>Liu, and Zhou (2019) presented a visual analysis of citation context-based article influence rank-<lb/>ing. Xie, Sun, and Shen (2016) predicted paper influence in an academic network by taking into <lb/>account the contents and venue of a paper, as well as the reputation of its authors. Shen et al. (2016) <lb/>used topic modeling to measure academic influence in scientific literature. Manju, Kavitha, and <lb/>Geetha (2017) identified influential researchers in an academic network using a rough-set based <lb/>selection of time-weighted academic and social network features. Pileggi (2018) did a citation net-<lb/>work analysis to measure academic influence. F. Zhang and Wu (2020) used a dynamic academic <lb/>network to predict the future influence of papers. Ji, Tang, and Chen (2019) analyzed the impact of <lb/>academic papers based on improved PageRank. F. Wang, Jia, Liu, and Liu (2019) assessed the aca-<lb/>demic influence of scientific literature via alt metrics. F. Zhao, Zhang, Lu, and Shai (2019) measured <lb/>academic influence using heterogeneous author-citation networks. Recently, many deep learning-<lb/>based methods are being explored for citation classification. Perier-Camby, Bertin, Atanassova, and <lb/>Armetta (2019) attempt to compare deep learning-based methods with rule-based methods. They <lb/>use deep learning-based feature extractors such as BCN (McCann, Bradbury, Xiong, &amp; Socher, 2017) <lb/>and ELMo (Peters et al., 2018) to extract semantic information and feed it to various classifiers for <lb/>classification. They conclude that neural networks could be a potential dimension for citation clas-<lb/>sification when a large number of samples are available. However, for a small dataset like the one <lb/>we use, rule-based methods clearly hold an advantage. Apart from this, the features used in rule-<lb/>based methods are more comprehensible than features extracted from deep learning methods, thus <lb/>providing deeper insights into analyzing factors that make a citation significant or contextual. <lb/>The closest literature for our task are the ones on citation classification. Citation classification <lb/>has been explored in the works of Alvarez, Soriano, and Martínez-Barco (2017); Dong and Schäfer <lb/>(2011); Qayyum and Afzal (2019); Teufel, Siddharthan, and Tidhar (2006). These works use features <lb/>from the perspective of citation motivation. On the other hand there are works which emphasize on <lb/></body>

			<page>3 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<body>features from semantic perspective. M. Wang et al. (2020) use syntactic and contextual information <lb/>of citations for classification. Aljuaid, Iftikhar, Ahmad, Asif, and Afzal (2021); Amjad and Ihsan <lb/>(n.d.) perform classification based on sentiment analysis of in-text citations. Athar (2011); Ihsan, <lb/>Imran, Ahmed, and Qadir (2019) propose sentiment analysis of citations using linguistic studies <lb/>of the citance. More recently, several open-source datasets for citation classification came up in <lb/>the works of Cohan, Ammar, van Zuylen, and Cady (2019); Pride and Knoth (2020). Valenzuela, <lb/>Ha, and Etzioni (2015) explored citation classification into influential and incidental using machine <lb/>learning techniques which we adapt as significant and contextual respectively in this work. <lb/>In this work, we propose a rich set of features informed from both citation and context (semantics) <lb/>perspectives, leveraging advantages of both types, thus performing better than all of the methods <lb/>mentioned above. However, our problem is motivated beyond citation classification. We restrict <lb/>our classification labels to significant and contextual unlike Valenzuela et al. (2015) as these labels are <lb/>enough to trace the lineage of a work. Furthermore, to the best of our knowledge, we did not find <lb/>any work leveraging citation classification for finding a research lineage. Hence, we only compare <lb/>our performance for the citation significance detection sub-task with other approaches. <lb/>4 Dataset Description <lb/>We experiment with the Valenzuela dataset (Valenzuela et al., 2015) for our task. The dataset con-<lb/>sists of incidental/influential human judgments on 630 citing-cited paper pairs for articles drawn <lb/>from the 2013 ACL anthology, the full texts of which are publicly available. Two expert human <lb/>annotators determined the judgment for each citation, and each citation was assigned a label. Us-<lb/>ing the author&apos;s binary classification, 396 citation pairs were ranked as incidental citations, and 69 <lb/>(14.3%) were ranked as influential (important) citations. For demonstrating our research lineage <lb/>idea, we explore knowledge flow on certain papers of Document-Level Novelty Detection (Ghosal, <lb/>Salam, Tiwari, Ekbal, &amp; Bhattacharyya, 2018) and the High Performance Computing (HPC) algo-<lb/>rithm MENNDL (Young, Rose, Karnowski, Lim, &amp; Patton, 2015). Actual authors of these two topics <lb/>helped us with manual annotation of their paper&apos;s lineage. <lb/>5 Methodology <lb/>To identify significant citations, we pursue a feature-engineering approach to curate several fea-<lb/>tures from cited-citing paper pairs. The objective is to classify the citations received by a given <lb/>paper into SIGNIFICANT and CONTEXTUAL. The original cited citing papers in the Valenzuela <lb/>dataset are in PDF. We convert the PDFs to corresponding XMLs using GROBID (Lopez, 2009). We <lb/>use GROBID to parse our PDFs into XMLs as well as manually correct a few inconsistent files so <lb/>that there is no discrepancy. <lb/>1. Citation frequency inside the body of citing paper (F1): We measure the number of times <lb/>the cited paper is referenced from within the citing paper&apos;s body. The intuition is that if a <lb/>paper is cited multiple times, the cited paper may be significant to the citing paper. <lb/>2. Are the authors of citing &amp; cited paper the same? (Boolean) (F2): We check if the authors <lb/>of the citing and cited paper are the same. This might be the case of self-citation or can also <lb/>signal the extension of the work. <lb/>3. Author overlap ratio (F3): This measures number of common authors in citing and cited <lb/>paper normalized to the total number of authors in citing paper. Intuition is similar to F2. <lb/>4. Is the citation occurring in a table or figure captions? (Boolean) (F4): The intuition is <lb/>that most of the citations in tables &amp; figures appear for comparison/significantly referencing <lb/>existing work. Hence, the citing paper might be an extension of the cited article or may have <lb/>compared it with earlier significant work. <lb/>5. Is the citation occurring in groups? (Boolean) (F5): We check if the citation is occurring <lb/>along with other citations in a group. Intuition is that such citations generally appear in <lb/>related works to highlight a background detail; hence, they might not be a significant citation. <lb/></body>

			<page>4 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<body>6. Number of citations to the cited paper normalized by the total number of citations made <lb/>by the citing paper (F6): This measures number of citations to the cited paper by the citing <lb/>paper normalized by the total number of citation instances in the citing paper. This measures <lb/>how frequently the cited paper is mentioned compared to other cited papers in the citing <lb/>paper. <lb/>7. Number of citations to the cited paper normalized by the total number of bibliography <lb/>items in the citing paper (F7): This measures number of citations to the cited paper nor-<lb/>malized to the total number of bibliography items in the citing paper. Intuition is similar to <lb/>F6. <lb/>8. tf-idf similarity between abstracts of the cited and citing paper (F8): We take cosine simi-<lb/>larity between the tf-idf representations of the abstracts of cited and citing papers. Intuition <lb/>is that if the similarity is higher, the citing paper may be inspired/extended from the cited <lb/>paper. <lb/>9. tf-idf similarity between titles of the cited and citing paper (F9): We take cosine similarity <lb/>between the tf-idf representations of the titles of cited and citing papers. <lb/>10. Average tf-idf similarity between citance and abstract of the cited paper (F10): We calcu-<lb/>late the similarity of each citance with the abstract of the cited article and take the average <lb/>of it. Citances are sentences containing the citations in the citing paper. Citances reveal the <lb/>purpose of the cited paper in the citing paper. Abstracts contain the contribution/purpose <lb/>statements of a given paper. Hence similarity with citances may construe that the cited paper <lb/>may have been used significantly in the current paper. <lb/>11. Maximum tf-idf similarity between citance and abstract of the cited paper (F11): We take <lb/>the maximum of similarity of the citances (there could be multiple citation instances of the <lb/>same paper in a given paper) with the abstract of the cited paper. <lb/>12. Average tf-idf similarity between citance and title of the cited paper (F12): We calculate <lb/>the similarity of each citance with the title of the cited paper and take an average of it. <lb/>13. Maximum tf-idf similarity between citance and title of the cited paper (F13): We take the <lb/>maximum of similarity of the citances with the title of the cited paper. <lb/>14. Average Length of the Citance (F14): Average length of the citances (in words) for multiple <lb/>citances. Intuition is that if the citing paper has spent many words on the cited article, it may <lb/>have significantly cited the corresponding article. <lb/>15. Maximum Length of the Citance (F15): Maximum length of the citances (in words). <lb/>16. No. of words between citances (F16): We take the average of the number of words between <lb/>each pair of consecutive citance of the cited paper. This is set to 0 in the case of a single <lb/>citance. <lb/>17. In how many different sections does the citation appear in the citing paper? (F17): We take <lb/>the number of different sections in which the citation to cited paper occurs and normalize it <lb/>with the total number of sections present in the citing paper. Intuition is that if a citation <lb/>occurs in most sections, it might be a significant citation. <lb/>18. Number of common references in citing &amp; cited paper normalized by the total number <lb/>of references in citing article (F18): We count the number of common bibliographic items <lb/>present in the citing &amp; cited paper and normalize it with total bibliographic items present in <lb/>the citing paper. <lb/>19. Number of common keywords between abstracts of the cited and citing paper extracted by <lb/>YAKE (Campos et al., 2018) (F19): We compare the number of common keywords between <lb/>abstract of citing &amp; cited paper extracted using YAKE. Our instinct is that more number of <lb/>common keywords would denote more similarity between abstracts. <lb/>20. Number of common keywords between titles of the cited and citing paper extracted by <lb/>YAKE (F20): We compare the number of common keywords between the title of citing &amp; <lb/>cited paper extracted using YAKE. <lb/></body>

			<page>5 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<body>21. Number of common keywords between the body of the cited and citing paper extracted <lb/>by YAKE (F21): We compare the number of common keyword between the body of citing &amp; <lb/>cited paper extracted using YAKE. <lb/>22. Word Mover&apos;s Distance (WMD) (Huang et al., 2016) between abstracts of the cited and <lb/>citing paper (F22): We measure the WMD between abstracts of citing &amp; cited paper. The <lb/>essence of this feature is to calculate semantic distance/similarity between abstracts of the <lb/>two papers. <lb/>23. WMD between titles of the cited and citing paper (F23): We measure the WMD between <lb/>title of citing &amp; cited paper. <lb/>24. WMD between the body of the cited and citing paper (F24): We measure the WMD be-<lb/>tween the body of citing &amp; cited paper. <lb/>25. Average WMD between citance and abstract of the cited and citing paper (F25): We take <lb/>the average of WMDs between citance and abstract of the cited paper. <lb/>26. Maximum WMD between citance and abstract of the cited and citing paper (F26): We take <lb/>the maximum of WMDs between citance and abstract of the cited paper. <lb/>27. Average VADER (Gilbert &amp; Hutto, 2014) Polarity Index -Positive (F27), Negative (F28), <lb/>Neutral (F29), Compound (F30): We measure VADER polarity index of all the citance of <lb/>cited paper, and take their average for each sentiment (positive, negative, neutral &amp; com-<lb/>pound). <lb/>28. Maximum VADER Polarity Index -Positive (F31), Negative (F32), Neutral (F33), Com-<lb/>pound (F34) of Citances: We measure VADER polarity index of all the citance of cited <lb/>paper, and take maximum among them for each sentiment (positive, negative, neutral &amp; <lb/>compound). The intuition to use sentiment information is to understand how the citing pa-<lb/>per cites the cited paper. <lb/>29. Number of common venues in Bibliography of citing and cited paper (F35): We count <lb/>the number of common venues mentioned in the bibliography of citing &amp; cited paper and <lb/>normalize it with the number of unique venues in citing paper. Higher venue overlap would <lb/>signify that the papers are in the same domain (Ghosal, Sonam, et al., 2019). <lb/>30. Number of common Authors in Bibliography of citing and cited paper (F36): We count <lb/>the number of common authors mentioned in the bibliography of citing &amp; cited paper and <lb/>normalize it with the number of unique authors in citing paper (Ghosal, Sonam, et al., 2019). <lb/>As mentioned earlier, only 14.3% of total citations are labeled as significant, which poses a Class <lb/>Imbalance problem. To address this issue, we use SMOTE (Chawla, Bowyer, Hall, &amp; Kegelmeyer, <lb/>2002) along with random under-sampling of majority (contextual citation) class. We first split the <lb/>dataset into 60% training &amp; 40% testing data. Then we under-sample the majority class by 50%, <lb/>and then we over-sample the minority class by 40%, on the training partition of the dataset. <lb/>6 Evaluation <lb/>Our evaluation consists of two stages: first, we evaluate our approach on the citation significance <lb/>task. Next, we try to see if we can identify the research lineage via tracing significant citations <lb/>across the two research topics (Document-level Novelty and MENNDL). We ask the original authors <lb/>to annotate the lineage and verify it with our automatic method. We train our model on the Valen-<lb/>zuela dataset and use that trained model to predict significant citations of Document-level Novelty <lb/>and MENNDL papers, thereby try to visualize the research lineage across the citing papers. We cu-<lb/>rate a small citation graph to demonstrate our idea. Please note that our task in concern is Citation <lb/>Significance Detection, which is different from Citation Classification in literature. Whereas Cita-<lb/>tion Classification focuses on identifying the citation&apos;s intent, Citation Significance aims to identify <lb/>the value associated with the citation. Obviously, the two tasks are related to each other, but the <lb/>objectives are different. <lb/></body>

			<page>6 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<body>6.1 Citation Significance Detection <lb/>The goal of this task is to identify whether a citation was SIGNIFICANT or CONTEXTUAL. We <lb/>experiment with several classifiers for the binary classification task such as kNN (k = 3), Support <lb/>Vector Machines (kernel = RBF), Decision Trees (max depth = 10) and Random Forest (n estimators <lb/>= 15, max depth = 10). We found Random Forest to be the best performing one with our feature set. <lb/>Table 1 shows our current results against the earlier reported results on the Valenzuela dataset. We <lb/>attain promising results compared to earlier approaches with a relative improvement of 20 points <lb/>in precision. Since the dataset is small, none of the earlier approaches or we attempted a deep <lb/>neural approach on this dataset. Like us, Qayyum and Afzal (2019) also used Random Forest as the <lb/>classifier; however, they relied on meta data features rather than content-based features for their <lb/>work. Their experiments tried to answer: to what extent can the similarities and dissimilarities <lb/>between metadata parameters serve as useful indicators for important citation tracking? which <lb/>metadata parameters or their combinations are helpful in achieving good results? We specifically <lb/>work with paper full-text content-based features, hence our approach leverages richer information <lb/>since it takes into consideration the full-text of the works, whereas Qayyum and Afzal (2019) is <lb/>solely based on metadata which helps us to achieve better performance. <lb/>Table 2 shows classification results of the various classifiers we experimented with. Clearly, <lb/>our features are highly inter-dependent (Section 5), and hence it explains the better performance of <lb/>Random Forests. <lb/>Methods <lb/>Precision <lb/>Valenzuela et al. (2015) <lb/>0.65 <lb/>Qayyum and Afzal (2019) <lb/>0.72 <lb/>Nazir, Asif, and Ahmad (2020) <lb/>0.75 <lb/>Nazir, Asif, Ahmad, Bukhari, et al. (2020) <lb/>0.85 <lb/>Current Approach <lb/>0.92 <lb/>Table 1: Results on Citation Significance Detection on Valenzuela dataset <lb/>Methods <lb/>Precision Recall F1-Score Accuracy <lb/>kNN <lb/>0.80 <lb/>0.87 <lb/>0.83 <lb/>0.81 <lb/>SVM <lb/>0.79 <lb/>0.67 <lb/>0.73 <lb/>0.81 <lb/>Decision Tree <lb/>0.80 <lb/>0.82 <lb/>0.81 <lb/>0.86 <lb/>Random Forest <lb/>0.92 <lb/>0.82 <lb/>0.87 <lb/>0.90 <lb/>Table 2: Classification Result of various Classifiers for Citation Significance <lb/>Figure 2 shows the importance of the top 10 features ranked as per their information gain. How-<lb/>ever, our experimental dataset is small, our features co-related, and hence it seems that some fea-<lb/>tures have marginal contributions. We deem that in a real-life bigger dataset, the feature signifi-<lb/>cance would be more visible. Here, we can see that features like distance between citances, the number <lb/>of concerned citation normalized by the total number of citations, similarity between cited-citing abstracts, <lb/>in-text citation frequency, the similarity between citance &amp; cited abstract, play an important role in the <lb/>classification. The other features featuring in the top 10 are: distance between citance, number of cita-<lb/>tions from citing to cited normalized by the total citations made by the citing paper, the similarity between <lb/>cited-citing abstracts, in-text citation frequency, the average similarity between citance &amp; cited abstract, <lb/>number of citations from citing to cited normalized by the total references made by the citing paper, number <lb/>of common YAKE keywords between the body of citing and cited paper, the average similarity between ci-<lb/>tance and title of cited paper, the max similarity between citance and abstract of cited paper, neutral sentiment <lb/>polarity of citance. We explain the possible reasons behind the performance of these features in the <lb/>subsequent sections. The precision with only using the top 10 features is 0.73. Hence, other features <lb/>play a significant role, as well. A complete list of features and the corresponding information gain <lb/></body>

			<page>7 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<body>Information Gain <lb/>0.025 <lb/>0.1 <lb/>0.15 <lb/>Features <lb/>F16 F7 F8 F1 F10 F6 F21 F12 F13 F33 <lb/>Figure 2: Feature importance ranked via Information Gain. <lb/>Feature <lb/>IG <lb/>Feature <lb/>IG <lb/>Feature <lb/>IG <lb/>F16 <lb/>0.147 <lb/>F24 <lb/>0.024 <lb/>F30 <lb/>0.015 <lb/>F7 <lb/>0.070 <lb/>F13 <lb/>0.022 <lb/>F27 <lb/>0.015 <lb/>F8 <lb/>0.070 <lb/>F33 <lb/>0.021 <lb/>F31 <lb/>0.015 <lb/>F1 <lb/>0.065 <lb/>F18 <lb/>0.020 <lb/>F32 <lb/>0.014 <lb/>F10 <lb/>0.061 <lb/>F3 <lb/>0.020 <lb/>F15 <lb/>0.014 <lb/>F6 <lb/>0.041 <lb/>F23 <lb/>0.019 <lb/>F9 <lb/>0.013 <lb/>F21 <lb/>0.033 <lb/>F35 <lb/>0.019 <lb/>F17 <lb/>0.011 <lb/>F12 <lb/>0.031 <lb/>F34 <lb/>0.017 <lb/>F36 <lb/>0.011 <lb/>F13 <lb/>0.030 <lb/>F19 <lb/>0.017 <lb/>F4 <lb/>0.006 <lb/>F33 <lb/>0.030 <lb/>F22 <lb/>0.016 <lb/>F5 <lb/>0.006 <lb/>F35 <lb/>0.025 <lb/>F28 <lb/>0.016 <lb/>F2 <lb/>0.004 <lb/>F26 <lb/>0.024 <lb/>F25 <lb/>0.016 <lb/>F20 <lb/>0.003 <lb/>Table 3: Information Gain (IG) due to each feature. Features are ranked in decreasing order <lb/>of Information Gain. <lb/>is given in Table 3 <lb/>To analyze the contribution of each feature, we evaluate our model using single feature at a time <lb/>similar to Valenzuela et al. (2015). The precision after considering each feature individually is <lb/>shown in Table 4. It is seen that the first 28 features in the table contribute significantly in classifi-<lb/>cation, and the overall precision after considering all the features is even better (an improvement <lb/>of 14 points). F1, F4 (suggesting that significant citations do occur in tables or figures) and F21 <lb/>followed by F7, F19, and F3 are the best performing features. This indicates that features obtained <lb/>from citation perspective are more useful. On the other hand the least performing features are F20 <lb/>(perhaps due to small size of dataset), F13, F5 (suggesting significant citations also occur in groups), <lb/>F17, F2, F22 and F33. Most of our observations are in line with Valenzuela et al. (2015). <lb/>To mention here, authors in Pride and Knoth (2017b) found Number of Direct Citations, Author <lb/>Overlap, and Abstract Similarity to be the most important features. Our approach performs good <lb/>enough to proceed with the next stage. <lb/>It is important to note that despite so many features, it is possible that some features might be <lb/>correlated. Hence, we find the Pearson&apos;s correlation coefficient between each pair of feature to see <lb/></body>

			<page>8 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<body>Feature Precision Feature Precision Feature Precision <lb/>F1 <lb/>0.78 <lb/>F15 <lb/>0.28 <lb/>F25 <lb/>0.15 <lb/>F4 <lb/>0.76 <lb/>F8 <lb/>0.27 <lb/>F11 <lb/>0.14 <lb/>F21 <lb/>0.71 <lb/>F10 <lb/>0.27 <lb/>F24 <lb/>0.13 <lb/>F7 <lb/>0.68 <lb/>F9 <lb/>0.25 <lb/>F31 <lb/>0.11 <lb/>F19 <lb/>0.61 <lb/>F27 <lb/>0.23 <lb/>F26 <lb/>0.10 <lb/>F3 <lb/>0.50 <lb/>F23 <lb/>0.20 <lb/>F33 <lb/>0.08 <lb/>F16 <lb/>0.47 <lb/>F36 <lb/>0.20 <lb/>F22 <lb/>0.07 <lb/>F28 <lb/>0.43 <lb/>F35 <lb/>0.20 <lb/>F2 <lb/>0.04 <lb/>F35 <lb/>0.37 <lb/>F12 <lb/>0.19 <lb/>F17 <lb/>0.04 <lb/>F6 <lb/>0.33 <lb/>F34 <lb/>0.19 <lb/>F5 <lb/>0.03 <lb/>F32 <lb/>0.33 <lb/>F30 <lb/>0.17 <lb/>F13 <lb/>0.03 <lb/>F33 <lb/>0.29 <lb/>F18 <lb/>0.15 <lb/>F20 <lb/>0.01 <lb/>Total <lb/>0.92 <lb/>Table 4: Performance of Random Forest Model by using individual feature at a time. The <lb/>features are listed in decreasing order of the precision. <lb/>how they are dependent on each other. The heatmap of correlation matrix is shown in Fig. 3. <lb/>Figure 3: Heatmap of correlation between various pair of features. <lb/>We find that the average correlation coefficient between all the features is 0.074. However, <lb/>there are few pairs of features which have high correlation coefficients. We have listed such pairs <lb/>in Table 5. <lb/>From Table 5 we can see that feature pairs like F10 &amp; F11, F30 &amp; F34, F28 &amp; F32, F27 &amp; F31, <lb/>F12 &amp; F13, F25 &amp; F26, F29 &amp; F33 have high correlation, which is understandable as these pairs <lb/>are nothing but maximum and average of same quantity measured throughout the corresponding <lb/></body>

			<page>9 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<body>Feature Pair Correlation Coefficient Feature Pair Correlation Coefficient <lb/>F10 &amp; F11 <lb/>0.937 <lb/>F25 &amp; F26 <lb/>0.910 <lb/>F30 &amp; F34 <lb/>0.919 <lb/>F9 &amp; F20 <lb/>0.907 <lb/>F28 &amp; F32 <lb/>0.917 <lb/>F29 &amp; F33 <lb/>0.905 <lb/>F27 &amp; F31 <lb/>0.914 <lb/>F1 &amp; F15 <lb/>0.835 <lb/>F12 &amp; F13 <lb/>0.910 <lb/>F27 &amp; F29 <lb/>0.832 <lb/>Table 5: Feature pairs with high correlation coefficient. <lb/>literature. Hence, in order to reduce the complexity of the classifier, one may use just one of the <lb/>features from each pair. The results after combining these features is shown in Table 6. It can be <lb/>seen that even after clubbing these features there is no significant degradation in performance of <lb/>our model. <lb/>Precision Recall F1 Score Accuracy <lb/>0.91 <lb/>0.80 <lb/>0.85 <lb/>0.89 <lb/>Table 6: Citation significance results after combining features on the Valenzuela dataset <lb/>6.2 The 3C Dataset <lb/>As we mention earlier, the dataset used is small due to which the significance of each feature might <lb/>not be visible explicitly. Hence, we also test our method on the 3C dataset which is relatively a <lb/>bigger one. The 3C Citation Context Classification 1 Shared Task organized as part of the Second <lb/>Workshop on Scholarly Document Processing @ NAACL 2021 is a classification challenge, where <lb/>each citation context is categorized based on its purpose and influence. It consists of 2 subtasks: <lb/>• Task A: Multiclass classification of citation contexts based on purpose with categories -BACK-<lb/>GROUND, USES, COMPARES CONTRASTS, MOTIVATION, EXTENSION, and FUTURE. <lb/>• Task B: Binary classification of citations into INCIDENTAL or INFLUENTIAL classes, i.e. a <lb/>task for identifying the importance of a citation <lb/>The training and test dataset used for Task A and Task B are the same. The training data and <lb/>test data consist of 3000 and 1000 instances, respectively. We use the data for Task B in for our <lb/>experiments. However, the 3C dataset doesn&apos;t provide us with full text due to which we are only <lb/>able to test only 19 of our features. We achieved an F1 score of 0.5358 with these 19 features on the <lb/>privately-held 3C test set. Our relevant features in use here are: F1, F2, F9, F10, F11, F12, F13, F14, <lb/>F15, F20, F23, F27, F28, F29, F30, F31, F32, F33, F34. We provide the results on the validation set <lb/>using a random forest classifier in Table 7. The best performing system in 3C achieved an F1 score <lb/>of 0.60 while the baseline F1 scores was 0.30. <lb/>Precision Recall F1 Score Accuracy <lb/>0.569 <lb/>0.575 <lb/>0.572 <lb/>0.606 <lb/>Table 7: Citation Influence Classification Results on 3C Validation Set using a Random <lb/>Forest Classifier <lb/>6.3 Research Lineage: Case Studies <lb/>Our end goal is not just citation classification but to make use of a highly accurate citation signifi-<lb/>cance detection approach to trace significant citations and thereafter, try and establish a lineage of <lb/></body>

			<note place="footnote">1 https://sdproc.org/2021/sharedtasks.html#3c <lb/></note>

			<page>10 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<body>the given research. As explained in Section 2, by research lineage we aim to identify the idea prop-<lb/>agation via tracking the significant citations. To achieve this, we create a Significant Citation Graph. <lb/>A Significant Citation Graph (SCG) is a graph-like structure, where each node represents a research <lb/>paper. There is a directed edge between each cited-citing pair, whose direction is from cited pa-<lb/>per node to citing paper node, indicating the flow of knowledge from cited paper to citing paper. <lb/>In a usual case, all citations have equal weights in a citation graph. However, in our case, each <lb/>edge is labeled as either significant or contextual, using the approach we discussed in the previous <lb/>section. Our idea is similar to that of existing scholarly graph databases; however, we go one step <lb/>further and depict how a particular concept or knowledge has propagated with consecutive citations. <lb/>Algorithm 1: Algorithm to Create Significance Citation Graph <lb/>Input: Trained Model &amp; concerned research document, P <lb/>Output: Adjacency List for Citation Graph <lb/>1 Initialize adjacency list, A <lb/>2 Initialize an empty queue, Q <lb/>3 Q.add(P ) <lb/>4 while Q is not empty do <lb/>5 <lb/>for Each citation, C in Q[0] do <lb/>6 <lb/>Extract features (F1-F36) for C <lb/>7 <lb/>if C is Significant and C is not in Q then <lb/>8 <lb/>Q.add(C) <lb/>9 <lb/>A[Q[0]].add(C) <lb/>10 <lb/>Q.pop() <lb/>11 return A <lb/>Algorithm 1 shows the method to create the adjacency list for the SCG. The Citation Signifi-<lb/>cance Detection ML model is trained on a given dataset (Valenzuela in our case). To demonstrate <lb/>the effectiveness of our method, we present a SCG for a set of papers on Document-Level Novelty <lb/>Detection and MENNDL. Being the authors of the papers on these topics, we have identified the <lb/>significant citations of each paper and used it to test the effectiveness of our proposed method to <lb/>create an SCG. <lb/>6.3.1 Case Study I: Document-Level Novelty Detection <lb/>Figure 4 denotes an excerpt of a SCG from our Document-Level Novelty Detection papers. The red <lb/>edges denote significant citations whereas black edges denote contextual citations. Our approach <lb/>determined if a citation edge is significant or contextual. In the citation graph, we are interested <lb/>in the lineage among four textual novelty detection papers (P1, P2, P3, P4), which the original <lb/>authors annotate. We annotated that P1 is the pivot paper which introduced their document-level <lb/>novelty detection dataset, and their other papers P2, P3, P4 are based on P1. While P2 and P4 <lb/>address novelty classification, P3 aims to quantify textual novelty. Our approach conforms to the <lb/>annotation by the original authors. With P1 as the pivot we can see that there are significant edges <lb/>from P1 to each of P2, P3, and P4. There is also a significant edge between P2 and P4. However, <lb/>there is no edge between P2 and P3, as they were contemporaneous submissions and their objective <lb/>was different (P2 was about novelty classification and P3 was about novelty scoring). P1 → P2 → P4 <lb/>forms a research lineage as P2 extends on P1 and P4 extends on P2. Furthermore, we see that P12, <lb/>P25, P24, P22 (transitively) are some influential papers for P1. We verified from the authors that P25 <lb/>was the paper to introduce the first document-level novelty detection dataset but from an information <lb/>retrieval perspective. P25 inspired the authors to create the dataset in P1 for ML experiments. We <lb/>construe that P12, P22, P24 had a significant influence on their investigations with P1. Hence, our <lb/>approach (trained on a different set of papers in Valenzuela dataset) proved successful to identify <lb/>the significant citations and thereby also identify the corresponding lineage. <lb/></body>

			<page>11 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<body>Figure 4: Significant Citation graph for a set of papers on Document-Level Novelty Detec-<lb/>tion. Please refer to the bibliography for the paper details. P1→Ghosal, Salam, et al. <lb/>(2018), P2→Ghosal, Edithal, et al. (2018), P3→Ghosal, Shukla, et al. (2019), P4→Ghosal <lb/>et al. (2020), P6→Soboroff and Harman (2003), P7→P. Zhao and Lee (2016), P8→Colomo-<lb/>Palacios et al. (2010), P9→Tang et al. (2010), P11→Kusner et al. (2015), P12→Li and Croft <lb/>(2005), P17→Schiffman and McKeown (2005), P22→Allan et al. (2003), P23→Soboroff and <lb/>Harman (2005), P24→Karkali et al. (2013), P25→Y. Zhang et al. (2002), P28→F. Zhang et al. <lb/>(2015) <lb/>6.3.2 Case Study II: MENNDL HPC Algorithm <lb/>We went ahead to test our approach&apos;s efficacy to predict the lineage of a high-performance comput-<lb/>ing algorithm MENNDL. We show the research lineage of MENNDL Young et al. (2015) in Figure <lb/>5. We ask the original authors to annotate their research progression with MENNDL. As per the <lb/>authors, the first paper to describe the MENNDL algorithm came in 2015, which is deemed as the <lb/>pivot (P9). The follow-up paper that carried forward the work in P9 was P4 in 2017. Then P1 came <lb/>in 2018 that built upon P4. P7, P12 came as extensions over P4. Next, P6 came in 2019 that took <lb/>forward the work from P1. With P9 as the source, our approach correctly predicted the lineage <lb/>as P 9 → P 4 → P 1 → P 6. Also, the lineage P 9 → P 4 → P 12 and P 9 → P 4 → P 7 via tracing <lb/>significant citations could be visible in the SCG at Figure 4. We annotate P8 as an application of P9; <lb/>hence no significant link exists between P9 and P8. <lb/>From the above experiments and case studies, it is clear that our proposed method works reason-<lb/>ably well when a paper cites the influencing paper meaningfully. However, there are cases where <lb/>some papers do not cite the papers from whom they are inspired. In such cases, our method would <lb/>not work. <lb/>7 Conclusion and Future Work <lb/>Here, in this work, we present our novel idea towards finding a research lineage to accelerate liter-<lb/>ature review. We achieve state-of-the-art performance on citation significance detection, which is a <lb/>crucial component to form the lineage. We leverage on that and show the efficacy of our approach <lb/>on two completely different research topics. Our approach is simple and could be easily imple-<lb/>mented on a large-scale citation graph (given the paper full-text). The training dataset is built from <lb/>NLP papers. However, we demonstrate our approach&apos;s efficacy by testing on two topics: one from <lb/>NLP and the other from HPC, hence establishing that our approach is domain-agnostic. Identifying <lb/>significant citations to form a research lineage would also help the community to understand the <lb/>real impact of a research beyond simple citation counts. We would look forward to experimenting <lb/></body>

			<page>12 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<body>Figure 5: Significant Citation graph for a set of papers on MENNDL HPC algorithm. <lb/>Please refer to the bibliography for the corresponding paper details. P1→Patton et al. <lb/>(2018), P4→Young et al. (2017), P6→Patton et al. (2019), P7→J. T. Johnston et al. (2019), <lb/>P8→T. Johnston et al. (2017), P9→Young et al. (2015), P12→Chae et al. (2019), P13→Jia et al. <lb/>(2014), P14→Saltz et al. (2018), P15→Thorsson et al. (2018), P16→Bottou (2010), P17→Noh <lb/>et al. (2015), P18→Lucchi et al. (2014), P19→Baldi et al. (2014), P20→Ciregan et al. (2012), <lb/>P25→Y. Zhang et al. (2002), P28→F. Zhang et al. (2015) <lb/>with deep neural architectures to identify meaningful features for the current task automatically. <lb/>Our next foray would be to identify the missing citations for papers which may have played instru-<lb/>mental role in certain papers but unfortunately are not cited. We release all the codes related to our <lb/>experiment at https://figshare.com/s/2388c54ba01d2df25f38 <lb/></body>

			<div type="annex">8 Author&apos;s Contribution <lb/>The first author conceptualized the work along with carrying out the investigation, formal analysis, <lb/>data curation, methodology, baselines codes, and writing the original draft. The second author led <lb/>the implementation, contributed in the formal analysis, and writing the paper draft. The third <lb/>author was engaged in the overall supervision, funding acquisition, and providing resources for <lb/>the investigation. The fourth author contributed towards the problem statement, data curation, <lb/>writing-review and editing, and project administration. <lb/></div>

			<div type="acknowledgement">9 Acknowledgement <lb/>This manuscript has been authored by UT-Battelle, LLC under Contract No. DE-AC05-00OR22725 <lb/>with the U.S. Department of Energy (DOE). The views expressed in the article do not necessarily <lb/>represent the views of the DOE or the U.S. Government. The United States Government retains and <lb/>the publisher, by accepting the article for publication, acknowledges that the United States Gov-<lb/>ernment retains a non-exclusive, paid-up, irrevocable, world-wide license to publish or reproduce <lb/>the published form of this manuscript, or allow others to do so, for United States Government pur-<lb/>poses. The Department of Energy will provide public access to these results of federally sponsored <lb/>research in accordance with the DOE Public Access Plan (http://energy.gov/downloads/ <lb/>doe-public-access-plan). <lb/>The first author also thanks the Oak Ridge Institute for Science and Education (ORISE) to spon-<lb/>sor the first author for the Advanced Short-Term Research Opportunity (ASTRO) program at the <lb/>Oak Ridge National Laboratory (ORNL). The ASTRO program is administered by the Oak Ridge <lb/></div>

			<page>13 <lb/></page>

			<note place="headnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<div type="acknowledgement">Institute for Science and Education (ORISE) for the U.S. Department of Energy. The first author <lb/>also acknowledges the Visvesvaraya PhD fellowship award VISPHD-MEITY-2518 from Digital In-<lb/>dia Corporation under Ministry of Electronics and Information Technology, Government of India. <lb/></div>

			<listBibl>References <lb/>Aljuaid, H., Iftikhar, R., Ahmad, S., Asif, M., &amp; Afzal, M. T. (2021). Important citation <lb/>identification using sentiment analysis of in-text citations. Telematics and Informatics, <lb/>56, 101492. <lb/>Allan, J., Wade, C., &amp; Bolivar, A. (2003). Retrieval and novelty detection at the sentence <lb/>level. In Proceedings of the 26th annual international acm sigir conference on research and <lb/>development in informaion retrieval (pp. 314-321). <lb/>Alvarez, M. H., Soriano, J. M. G., &amp; Martínez-Barco, P. (2017). Citation func-<lb/>tion, polarity and influence classification. Nat. Lang. Eng., 23(4), 561-588. Re-<lb/>trieved from https://doi.org/10.1017/S1351324916000346 doi: 10.1017/ <lb/>S1351324916000346 <lb/>Amjad, Z., &amp; Ihsan, I. (n.d.). Verbnet based citation sentiment class assignment using <lb/>machine learning. <lb/>Athar, A. (2011). Sentiment analysis of citations using sentence structure-based features. <lb/>In Proceedings of the acl 2011 student session (pp. 81-87). <lb/>Bai, X., Xia, F., Lee, I., Zhang, J., &amp; Ning, Z. (2016). Identifying anomalous citations for <lb/>objective evaluation of scholarly article impact. PloS one, 11(9), e0162364. <lb/>Baldi, P., Sadowski, P., &amp; Whiteson, D. (2014). Searching for exotic particles in high-energy <lb/>physics with deep learning. Nature communications, 5(1), 1-9. <lb/>Bartneck, C., &amp; Kokkelmans, S. (2011). Detecting h-index manipulation through self-<lb/>citation analysis. Scientometrics, 87(1), 85-98. <lb/>Bottou, L. (2010). Large-scale machine learning with stochastic gradient descent. In Pro-<lb/>ceedings of compstat&apos;2010 (pp. 177-186). Springer. <lb/>Camacho-Mi ñano, M., &amp; N ú ñez-Nickel, M. (2009). The multilayered nature of reference <lb/>selection. J. Assoc. Inf. Sci. Technol., 60(4), 754-777. Retrieved from https://doi <lb/>.org/10.1002/asi.21018 doi: 10.1002/asi.21018 <lb/>Campos, R., Mangaravite, V., Pasquali, A., Jorge, A. M., Nunes, C., &amp; Jatowt, A. (2018). <lb/>Yake! collection-independent automatic keyword extractor. In European conference on <lb/>information retrieval (pp. 806-810). <lb/>Cerdá, J. H. C., Nieto, E. M., &amp; Campos, M. L. (2009). What&apos;s wrong with citation counts? <lb/>D-Lib Magazine, 15(3/4), 1082-9873. <lb/>Chae, J., Schuman, C. D., Young, S. R., Johnston, J. T., Rose, D. C., Patton, R. M., &amp; Potok, <lb/>T. E. (2019). Visualization system for evolutionary neural networks for deep learning. <lb/>In 2019 ieee international conference on big data (big data) (pp. 4498-4502). <lb/>Chawla, N. V., Bowyer, K. W., Hall, L. O., &amp; Kegelmeyer, W. P. (2002). Smote: synthetic <lb/>minority over-sampling technique. Journal of artificial intelligence research, 16, 321-<lb/>357. <lb/>Ciregan, D., Meier, U., &amp; Schmidhuber, J. (2012). Multi-column deep neural networks for <lb/>image classification. In 2012 ieee conference on computer vision and pattern recognition <lb/>(pp. 3642-3649). <lb/>Cohan, A., Ammar, W., van Zuylen, M., &amp; Cady, F. (2019). Structural scaffolds for citation <lb/>intent classification in scientific publications. In J. Burstein, C. Doran, &amp; T. Solorio <lb/>(Eds.), Proceedings of the 2019 conference of the north american chapter of the association for <lb/>computational linguistics: Human language technologies, NAACL-HLT 2019, minneapolis, <lb/>mn, usa, june 2-7, 2019, volume 1 (long and short papers) (pp. 3586-3596). Association for <lb/></listBibl>

			<page>14 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<listBibl>Computational Linguistics. Retrieved from https://doi.org/10.18653/v1/ <lb/>n19-1361 doi: 10.18653/v1/n19-1361 <lb/>Colomo-Palacios, R., Tsai, F. S., &amp; Chan, K. L. (2010). Redundancy and novelty mining in <lb/>the business blogosphere. The Learning Organization. <lb/>Dong, C., &amp; Schäfer, U. (2011). Ensemble-style self-training on citation classification. In <lb/>Fifth international joint conference on natural language processing, IJCNLP 2011, chiang <lb/>mai, thailand, november 8-13, 2011 (pp. 623-631). The Association for Computer Lin-<lb/>guistics. Retrieved from https://www.aclweb.org/anthology/I11-1070/ <lb/>Ghosal, T., Edithal, V., Ekbal, A., Bhattacharyya, P., Chivukula, S. S. S. K., &amp; Tsatsaronis, <lb/>G. (2020). Is your document novel? let attention guide you. an attention-based <lb/>model for document-level novelty detection. Natural Language Engineering, 1-28. doi: <lb/>10.1017/S1351324920000194 <lb/>Ghosal, T., Edithal, V., Ekbal, A., Bhattacharyya, P., Tsatsaronis, G., &amp; Chivukula, S. S. S. K. <lb/>(2018). Novelty goes deep. a deep neural solution to document level novelty detec-<lb/>tion. In Proceedings of the 27th international conference on computational linguistics (pp. <lb/>2802-2813). <lb/>Ghosal, T., Salam, A., Tiwari, S., Ekbal, A., &amp; Bhattacharyya, P. (2018). Tap-dlnd 1.0: A <lb/>corpus for document level novelty detection. arXiv preprint arXiv:1802.06950. <lb/>Ghosal, T., Shukla, A., Ekbal, A., &amp; Bhattacharyya, P. (2019). To comprehend the new: On <lb/>measuring the freshness of a document. In 2019 international joint conference on neural <lb/>networks (ijcnn) (pp. 1-8). <lb/>Ghosal, T., Sonam, R., Ekbal, A., Saha, S., &amp; Bhattacharyya, P. (2019). Is the paper within <lb/>scope? are you fishing in the right pond? In M. Bonn, D. Wu, J. S. Downie, &amp; <lb/>A. Martaus (Eds.), 19th ACM/IEEE joint conference on digital libraries, JCDL 2019, cham-<lb/>paign, il, usa, june 2-6, 2019 (pp. 237-240). IEEE. Retrieved from https://doi.org/ <lb/>10.1109/JCDL.2019.00040 doi: 10.1109/JCDL.2019.00040 <lb/>Gilbert, C., &amp; Hutto, E. (2014). Vader: A parsimonious rule-based model for sentiment <lb/>analysis of social media text. In Eighth international conference on weblogs and social <lb/>media (icwsm-14). available at (20/04/16) http://comp. social. gatech. edu/papers/icwsm14. <lb/>vader. hutto. pdf (Vol. 81, p. 82). <lb/>Huang, G., Guo, C., Kusner, M. J., Sun, Y., Sha, F., &amp; Weinberger, K. Q. (2016). Supervised <lb/>word mover&apos;s distance. In Advances in neural information processing systems (pp. 4862-<lb/>4870). <lb/>Ihsan, I., Imran, S., Ahmed, O., &amp; Qadir, M. A. (2019). A corpus-based study of reporting <lb/>verbs in citation texts using natural language processing: Study of reporting verbs <lb/>in citation texts using natural language processing. CORPORUM: Journal of Corpus <lb/>Linguistics, 2(1), 25-36. <lb/>Ji, C., Tang, Y., &amp; Chen, G. (2019). Analyzing the influence of academic papers based on <lb/>improved pagerank. In E. Popescu, T. Hao, T. Hsu, H. Xie, M. Temperini, &amp; W. Chen <lb/>(Eds.), Emerging technologies for education -4th international symposium, sete@icwl 2019, <lb/>magdeburg, germany, september 23-25, 2019, revised selected papers (Vol. 11984, pp. 214-<lb/>225). Springer. Retrieved from https://doi.org/10.1007/978-3-030-38778 <lb/>-5 24 doi: 10.1007/978-3-030-38778-5\ 24 <lb/>Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., . . . Darrell, T. (2014). <lb/>Caffe: Convolutional architecture for fast feature embedding. In Proceedings of the <lb/>22nd acm international conference on multimedia (pp. 675-678). <lb/>Johnston, J. T., Young, S. R., Schuman, C. D., Chae, J., March, D. D., Patton, R. M., &amp; Potok, <lb/>T. E. (2019). Fine-grained exploitation of mixed precision for faster cnn training. In <lb/>2019 ieee/acm workshop on machine learning in high performance computing environments <lb/>(mlhpc) (pp. 9-18). <lb/></listBibl>

			<page>15 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<listBibl>Johnston, T., Young, S. R., Hughes, D., Patton, R. M., &amp; White, D. (2017). Optimizing con-<lb/>volutional neural networks for cloud detection. In Proceedings of the machine learning <lb/>on hpc environments (pp. 1-9). <lb/>Karkali, M., Rousseau, F., Ntoulas, A., &amp; Vazirgiannis, M. (2013). Efficient online nov-<lb/>elty detection in news streams. In International conference on web information systems <lb/>engineering (pp. 57-71). <lb/>Kusner, M., Sun, Y., Kolkin, N., &amp; Weinberger, K. (2015). From word embeddings to <lb/>document distances. In International conference on machine learning (pp. 957-966). <lb/>Laloë, F., &amp; Mosseri, R. (2009). Bibliometric evaluation of individual researchers: not even <lb/>right... not even wrong! Europhysics News, 40(5), 26-29. <lb/>Li, X., &amp; Croft, W. B. (2005). Novelty detection based on sentence level patterns. In Pro-<lb/>ceedings of the 14th acm international conference on information and knowledge management <lb/>(pp. 744-751). <lb/>Lopez, P. (2009). Grobid: Combining automatic bibliographic data recognition and term <lb/>extraction for scholarship publications. In International conference on theory and practice <lb/>of digital libraries (pp. 473-474). <lb/>Lucchi, A., Márquez-Neila, P., Becker, C., Li, Y., Smith, K., Knott, G., &amp; Fua, P. (2014). <lb/>Learning structured models for segmentation of 2-d and 3-d imagery. IEEE transac-<lb/>tions on medical imaging, 34(5), 1096-1110. <lb/>Manju, G., Kavitha, V., &amp; Geetha, T. V. (2017). Influential researcher identification in aca-<lb/>demic network using rough set based selection of time-weighted academic and so-<lb/>cial network features. Int. J. Intell. Inf. Technol., 13(1), 1-25. Retrieved from https:// <lb/>doi.org/10.4018/IJIIT.2017010101 doi: 10.4018/IJIIT.2017010101 <lb/>McCann, B., Bradbury, J., Xiong, C., &amp; Socher, R. (2017). Learned in translation: Contextu-<lb/>alized word vectors. arXiv preprint arXiv:1708.00107. <lb/>Nazir, S., Asif, M., &amp; Ahmad, S. (2020). Important citation identification by exploiting the <lb/>optimal in-text citation frequency. In 2020 international conference on engineering and <lb/>emerging technologies (iceet) (pp. 1-6). <lb/>Nazir, S., Asif, M., Ahmad, S., Bukhari, F., Afzal, M. T., &amp; Aljuaid, H. (2020). Important <lb/>citation identification by exploiting content and section-wise in-text citation count. <lb/>PloS one, 15(3), e0228885. <lb/>Noh, H., Hong, S., &amp; Han, B. (2015). Learning deconvolution network for semantic seg-<lb/>mentation. In Proceedings of the ieee international conference on computer vision (pp. <lb/>1520-1528). <lb/>Patton, R. M., Johnston, J. T., Young, S. R., Schuman, C. D., March, D. D., Potok, T. E., <lb/>. . . others (2018). 167-pflops deep learning for electron microscopy: from learning <lb/>physics to atomic manipulation. In Sc18: International conference for high performance <lb/>computing, networking, storage and analysis (pp. 638-648). <lb/>Patton, R. M., Johnston, J. T., Young, S. R., Schuman, C. D., Potok, T. E., Rose, D. C., . . . <lb/>others (2019). Exascale deep learning to accelerate cancer research. In 2019 ieee <lb/>international conference on big data (big data) (pp. 1488-1496). <lb/>Perier-Camby, J., Bertin, M., Atanassova, I., &amp; Armetta, F. (2019). A preliminary study to <lb/>compare deep learning with rule-based approaches for citation classification. In 8th <lb/>international workshop on bibliometric-enhanced information retrieval (bir) co-located with <lb/>the 41st european conference on information retrieval (ecir 2019) (Vol. 2345, pp. 125-131). <lb/>Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., &amp; Zettlemoyer, L. <lb/>(2018). Deep contextualized word representations. arXiv preprint arXiv:1802.05365. <lb/>Pileggi, S. F. (2018). Looking deeper into academic citations through network analysis: <lb/>popularity, influence and impact. Univers. Access Inf. Soc., 17(3), 541-548. Retrieved <lb/>from https://doi.org/10.1007/s10209-017-0565-5 doi: 10.1007/s10209 <lb/></listBibl>

			<page>16 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<listBibl>-017-0565-5 <lb/>Pride, D., &amp; Knoth, P. (2017a). Incidental or influential? -A decade of using text-mining <lb/>for citation function classification. In J. Qiu, R. Rousseau, C. R. Sugimoto, &amp; F. Xin <lb/>(Eds.), Proceedings of the 16th international conference on scientometrics and informetrics, <lb/>ISSI 2017, wuhan, china, october 16-20, 2017 (pp. 1357-1367). ISSI Society. <lb/>Pride, D., &amp; Knoth, P. (2017b). Incidental or influential? -challenges in automatically <lb/>detecting citation importance using publication full texts. In J. Kamps, G. Tsakonas, <lb/>Y. Manolopoulos, L. S. Iliadis, &amp; I. Karydis (Eds.), Research and advanced technology <lb/>for digital libraries -21st international conference on theory and practice of digital libraries, <lb/>TPDL 2017, thessaloniki, greece, september 18-21, 2017, proceedings (Vol. 10450, pp. 572-<lb/>578). Springer. Retrieved from https://doi.org/10.1007/978-3-319-67008 <lb/>-9 48 doi: 10.1007/978-3-319-67008-9\ 48 <lb/>Pride, D., &amp; Knoth, P. (2020). An authoritative approach to citation classification. In <lb/>R. Huang, D. Wu, G. Marchionini, D. He, S. J. Cunningham, &amp; P. Hansen (Eds.), JCDL <lb/>&apos;20: Proceedings of the ACM/IEEE joint conference on digital libraries in 2020, virtual event, <lb/>china, august 1-5, 2020 (pp. 337-340). ACM. Retrieved from https://doi.org/ <lb/>10.1145/3383583.3398617 doi: 10.1145/3383583.3398617 <lb/>Qayyum, F., &amp; Afzal, M. T. (2019). Identification of important citations by exploiting <lb/>research articles&apos; metadata and cue-terms from content. Scientometrics, 118(1), 21-<lb/>43. Retrieved from https://doi.org/10.1007/s11192-018-2961-x doi: 10 <lb/>.1007/s11192-018-2961-x <lb/>Ronda-Pupo, G. A., &amp; Pham, T. (2018). The evolutions of the rich get richer and the fit <lb/>get richer phenomena in scholarly networks: the case of the strategic management <lb/>journal. Scientometrics, 116(1), 363-383. <lb/>Rousseau, R. (2007). The influence of missing publications on the hirsch index. Journal of <lb/>Informetrics, 1(1), 2-7. <lb/>Saltz, J., Gupta, R., Hou, L., Kurc, T., Singh, P., Nguyen, V., . . . others (2018). Spatial <lb/>organization and molecular correlation of tumor-infiltrating lymphocytes using deep <lb/>learning on pathology images. Cell reports, 23(1), 181-193. <lb/>Schiffman, B., &amp; McKeown, K. (2005). Context and learning in novelty detection. In <lb/>Proceedings of human language technology conference and conference on empirical methods <lb/>in natural language processing (pp. 716-723). <lb/>Shen, J., Song, Z., Li, S., Tan, Z., Mao, Y., Fu, L., . . . Wang, X. (2016). Modeling <lb/>topic-level academic influence in scientific literatures. In M. Khabsa, C. L. Giles, <lb/>&amp; A. D. Wade (Eds.), Scholarly big data: AI perspectives, challenges, and ideas, papers from <lb/>the 2016 AAAI workshop, phoenix, arizona, usa, february 13, 2016 (Vol. WS-16-13). AAAI <lb/>Press. Retrieved from http://www.aaai.org/ocs/index.php/WS/AAAIW16/ <lb/>paper/view/12598 <lb/>Shi, C., Wang, H., Chen, B., Liu, Y., &amp; Zhou, Z. (2019). Visual analysis of citation context-<lb/>based article influence ranking. IEEE Access, 7, 113853-113866. Retrieved from <lb/>https://doi.org/10.1109/ACCESS.2019.2932051 doi: 10.1109/ACCESS <lb/>.2019.2932051 <lb/>Soboroff, I., &amp; Harman, D. (2003). Overview of the trec 2003 novelty track. In Trec (pp. <lb/>38-53). <lb/>Soboroff, I., &amp; Harman, D. (2005). Novelty detection: the trec experience. In Proceedings <lb/>of human language technology conference and conference on empirical methods in natural <lb/>language processing (pp. 105-112). <lb/>Tang, W., Tsai, F. S., &amp; Chen, L. (2010). Blended metrics for novel sentence mining. Expert <lb/>Systems with Applications, 37(7), 5172-5177. <lb/>Teufel, S., Siddharthan, A., &amp; Tidhar, D. (2006). Automatic classification of citation func-<lb/></listBibl>

			<page>17 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<listBibl>tion. In D. Jurafsky &amp; É. Gaussier (Eds.), EMNLP 2006, proceedings of the 2006 confer-<lb/>ence on empirical methods in natural language processing, 22-23 july 2006, sydney, australia <lb/>(pp. 103-110). ACL. Retrieved from https://www.aclweb.org/anthology/ <lb/>W06-1613/ <lb/>Thorsson, V., Gibbs, D. L., Brown, S. D., Wolf, D., Bortone, D. S., Yang, T.-H. O., . . . others <lb/>(2018). The immune landscape of cancer. Immunity, 48(4), 812-830. <lb/>Valenzuela, M., Ha, V., &amp; Etzioni, O. (2015). Identifying meaningful citations. In C. Caragea <lb/>et al. (Eds.), Scholarly big data: AI perspectives, challenges, and ideas, papers from the 2015 <lb/>AAAI workshop, austin, texas, usa, january, 2015 (Vol. WS-15-13). AAAI Press. Re-<lb/>trieved from http://aaai.org/ocs/index.php/WS/AAAIW15/paper/view/ <lb/>10185 <lb/>Van Noorden, R. (2017). The science that&apos;s never been cited. Nature, 552. <lb/>Van Noorden, R., &amp; Singh Chawla, D. (2019). Hundreds of extreme self-citing scientists <lb/>revealed in new database. Natur, 572(7771), 578-579. <lb/>Vîiu, G.-A. (2016). A theoretical evaluation of hirsch-type bibliometric indicators con-<lb/>fronted with extreme self-citation. Journal of Informetrics, 10(2), 552-566. <lb/>Wang, F., Jia, C., Liu, J., &amp; Liu, J. (2019). Dynamic assessment of the academic influence <lb/>of scientific literature from the perspective of altmetrics. In G. Catalano, C. Daraio, <lb/>M. Gregori, H. F. Moed, &amp; G. Ruocco (Eds.), Proceedings of the 17th international con-<lb/>ference on scientometrics and informetrics, ISSI 2019, rome, italy, september 2-5, 2019 (pp. <lb/>2528-2529). ISSI Society. <lb/>Wang, M., Zhang, J., Jiao, S., Zhang, X., Zhu, N., &amp; Chen, G. (2020). Important citation <lb/>identification by exploiting the syntactic and contextual information of citations. Sci-<lb/>entometrics, 125(3), 2109-2129. <lb/>West, R., Stenius, K., &amp; Kettunen, T. (2017). Use and abuse of citations. Addiction Science: <lb/>A Guide for the Perplexed, 191. <lb/>Wilhite, A. W., &amp; Fong, E. A. (2012). Coercive citation in academic publishing. Science, <lb/>335(6068), 542-543. <lb/>Xie, Y., Sun, Y., &amp; Shen, L. (2016). Predicating paper influence in academic network. In 20th <lb/>IEEE international conference on computer supported cooperative work in design, CSCWD <lb/>2016, nanchang, china, may 4-6, 2016 (pp. 539-544). IEEE. Retrieved from https:// <lb/>doi.org/10.1109/CSCWD.2016.7566047 doi: 10.1109/CSCWD.2016.7566047 <lb/>Young, S. R., Rose, D. C., Johnston, T., Heller, W. T., Karnowski, T. P., Potok, T. E., . . . <lb/>Miller, J. (2017). Evolving deep networks using hpc. In Proceedings of the machine <lb/>learning on hpc environments (pp. 1-7). <lb/>Young, S. R., Rose, D. C., Karnowski, T. P., Lim, S.-H., &amp; Patton, R. M. (2015). Optimizing <lb/>deep learning hyper-parameters through an evolutionary algorithm. In Proceedings of <lb/>the workshop on machine learning in high-performance computing environments (pp. 1-5). <lb/>Zhang, F., &amp; Wu, S. (2020). Predicting future influence of papers, researchers, and <lb/>venues in a dynamic academic network. J. Informetrics, 14(2), 101035. Retrieved <lb/>from https://doi.org/10.1016/j.joi.2020.101035 doi: 10.1016/j.joi.2020 <lb/>.101035 <lb/>Zhang, F., Zheng, K., Yuan, N. J., Xie, X., Chen, E., &amp; Zhou, X. (2015). A novelty-seeking <lb/>based dining recommender system. In Proceedings of the 24th international conference <lb/>on world wide web (pp. 1362-1372). <lb/>Zhang, Y., Callan, J., &amp; Minka, T. (2002). Novelty and redundancy detection in adaptive <lb/>filtering. In Proceedings of the 25th annual international acm sigir conference on research <lb/>and development in information retrieval (pp. 81-88). <lb/>Zhao, F., Zhang, Y., Lu, J., &amp; Shai, O. (2019). Measuring academic influence using hetero-<lb/>geneous author-citation networks. Scientometrics, 118(3), 1119-1140. Retrieved from <lb/></listBibl>

			<page>18 <lb/></page>

			<note place="footnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 <lb/></note>

			<listBibl>https://doi.org/10.1007/s11192-019-03010-5 doi: 10.1007/s11192-019 <lb/>-03010-5 <lb/>Zhao, P., &amp; Lee, D. L. (2016). How much novelty is relevant? it depends on your curiosity. <lb/>In Proceedings of the 39th international acm sigir conference on research and development in <lb/>information retrieval (pp. 315-324). <lb/>Zhu, X., Turney, P. D., Lemire, D., &amp; Vellino, A. (2015). Measuring academic influence: <lb/>Not all citations are equal. J. Assoc. Inf. Sci. Technol., 66(2), 408-427. Retrieved from <lb/>https://doi.org/10.1002/asi.23179 doi: 10.1002/asi.23179 <lb/></listBibl>

			<page>19 <lb/></page>

			<note place="headnote">Downloaded from http://direct.mit.edu/qss/article-pdf/doi/10.1162/qss_a_00170/1971219/qss_a_00170.pdf by guest on 27 November 2021 </note>


	</text>
</tei>
