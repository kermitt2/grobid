<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>server date 20190709; downloaded by EPO on 20190710 <lb/>Benchmarking Working Group <lb/>M. Konstantynowicz, Ed. <lb/>Internet-Draft <lb/>V. Polak, Ed. <lb/>Intended status: Informational <lb/>Cisco Systems <lb/>Expires: January 9, 2020 <lb/>July 08, 2019 <lb/>Probabilistic Loss Ratio Search for Packet Throughput (PLRsearch) <lb/>draft-vpolak-bmwg-plrsearch-02 <lb/>Abstract <lb/>This document addresses challenges while applying methodologies <lb/>described in [RFC2544] to benchmarking software based NFV (Network <lb/>Function Virtualization) data planes over an extended period of time, <lb/>sometimes referred to as &quot;soak testing&quot;. Packet throughput search <lb/>approach proposed by this document assumes that system under test is <lb/>probabilistic in nature, and not deterministic. <lb/>Status of This Memo <lb/>This Internet-Draft is submitted in full conformance with the <lb/>provisions of BCP 78 and BCP 79. <lb/>Internet-Drafts are working documents of the Internet Engineering <lb/>Task Force (IETF). Note that other groups may also distribute <lb/>working documents as Internet-Drafts. The list of current Internet-<lb/>Drafts is at https://datatracker.ietf.org/drafts/current/. <lb/>Internet-Drafts are draft documents valid for a maximum of six months <lb/>and may be updated, replaced, or obsoleted by other documents at any <lb/>time. It is inappropriate to use Internet-Drafts as reference <lb/>material or to cite them other than as &quot;work in progress.&quot; <lb/>This Internet-Draft will expire on January 9, 2020. <lb/>Copyright Notice <lb/>Copyright (c) 2019 IETF Trust and the persons identified as the <lb/>document authors. All rights reserved. <lb/>This document is subject to BCP 78 and the IETF Trust&apos;s Legal <lb/>Provisions Relating to IETF Documents <lb/>(https://trustee.ietf.org/license-info) in effect on the date of <lb/>publication of this document. Please review these documents <lb/>carefully, as they describe your rights and restrictions with respect <lb/>to this document. Code Components extracted from this document must <lb/>include Simplified BSD License text as described in Section 4.e of <lb/>Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/>[Page 1] <lb/>Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/>the Trust Legal Provisions and are provided without warranty as <lb/>described in the Simplified BSD License. <lb/></front>

			<div type="toc">Table of Contents <lb/>1. Motivation . . . . . . . . . . . . . . . . . . . . . . . . . <lb/>3 <lb/>2. Relation To RFC2544 . . . . . . . . . . . . . . . . . . . . . <lb/>4 <lb/>3. Terms And Assumptions . . . . . . . . . . . . . . . . . . . . <lb/>4 <lb/>3.1. Device Under Test . . . . . . . . . . . . . . . . . . . . <lb/>4 <lb/>3.2. System Under Test . . . . . . . . . . . . . . . . . . . . <lb/>4 <lb/>3.3. SUT Configuration . . . . . . . . . . . . . . . . . . . . <lb/>4 <lb/>3.4. SUT Setup . . . . . . . . . . . . . . . . . . . . . . . . <lb/>4 <lb/>3.5. Network Traffic . . . . . . . . . . . . . . . . . . . . . <lb/>5 <lb/>3.6. Packet . . . . . . . . . . . . . . . . . . . . . . . . . <lb/>5 <lb/>3.6.1. Packet Offered . . . . . . . . . . . . . . . . . . . <lb/>5 <lb/>3.6.2. Packet Received . . . . . . . . . . . . . . . . . . . <lb/>5 <lb/>3.6.3. Packet Lost . . . . . . . . . . . . . . . . . . . . . <lb/>5 <lb/>3.6.4. Other Packets . . . . . . . . . . . . . . . . . . . . <lb/>5 <lb/>3.7. Traffic Profile . . . . . . . . . . . . . . . . . . . . . <lb/>6 <lb/>3.8. Traffic Generator . . . . . . . . . . . . . . . . . . . . <lb/>6 <lb/>3.9. Offered Load . . . . . . . . . . . . . . . . . . . . . . <lb/>6 <lb/>3.10. Trial Measurement . . . . . . . . . . . . . . . . . . . . <lb/>6 <lb/>3.11. Trial Duration . . . . . . . . . . . . . . . . . . . . . <lb/>7 <lb/>3.12. Packet Loss . . . . . . . . . . . . . . . . . . . . . . . <lb/>7 <lb/>3.12.1. Loss Count . . . . . . . . . . . . . . . . . . . . . <lb/>7 <lb/>3.12.2. Loss Rate . . . . . . . . . . . . . . . . . . . . . <lb/>7 <lb/>3.12.3. Loss Ratio . . . . . . . . . . . . . . . . . . . . . <lb/>7 <lb/>3.13. Trial Order Independent System . . . . . . . . . . . . . <lb/>7 <lb/>3.14. Trial Measurement Result Distribution . . . . . . . . . . <lb/>8 <lb/>3.15. Average Loss Ratio . . . . . . . . . . . . . . . . . . . <lb/>8 <lb/>3.16. Duration Independent System . . . . . . . . . . . . . . . <lb/>8 <lb/>3.17. Load Regions . . . . . . . . . . . . . . . . . . . . . . <lb/>9 <lb/>3.17.1. Zero Loss Region . . . . . . . . . . . . . . . . . . <lb/>9 <lb/>3.17.2. Guaranteed Loss Region . . . . . . . . . . . . . . . <lb/>9 <lb/>3.17.3. Non-Deterministic Region . . . . . . . . . . . . . . <lb/>9 <lb/>3.17.4. Normal Region Ordering . . . . . . . . . . . . . . . <lb/>9 <lb/>3.18. Deterministic System . . . . . . . . . . . . . . . . . . 10 <lb/>3.19. Througphput . . . . . . . . . . . . . . . . . . . . . . . 10 <lb/>3.20. Deterministic Search . . . . . . . . . . . . . . . . . . 10 <lb/>3.21. Probabilistic Search . . . . . . . . . . . . . . . . . . 10 <lb/>3.22. Loss Ratio Function . . . . . . . . . . . . . . . . . . . 11 <lb/>3.23. Target Loss Ratio . . . . . . . . . . . . . . . . . . . . 11 <lb/>3.24. Critical Load . . . . . . . . . . . . . . . . . . . . . . 11 <lb/>3.25. Critical Load Estimate . . . . . . . . . . . . . . . . . 11 <lb/>3.26. Fitting Function . . . . . . . . . . . . . . . . . . . . 11 <lb/>3.27. Shape of Fitting Function . . . . . . . . . . . . . . . . 11 <lb/>3.28. Parameter Space . . . . . . . . . . . . . . . . . . . . . 12 <lb/>4. Abstract Algorithm . . . . . . . . . . . . . . . . . . . . . 12 <lb/></div>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 2] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <div type="toc">4.1. High level description . . . . . . . . . . . . . . . . . 12 <lb/>4.2. Main Ideas . . . . . . . . . . . . . . . . . . . . . . . 12 <lb/>4.2.1. Trial Durations . . . . . . . . . . . . . . . . . . . 13 <lb/>4.2.2. Target Loss Ratio . . . . . . . . . . . . . . . . . . 13 <lb/>4.3. PLRsearch Building Blocks . . . . . . . . . . . . . . . . 13 <lb/>4.3.1. Bayesian Inference . . . . . . . . . . . . . . . . . 13 <lb/>4.3.2. Iterative Search . . . . . . . . . . . . . . . . . . 14 <lb/>4.3.3. Fitting Functions . . . . . . . . . . . . . . . . . . 14 <lb/>4.3.4. Measurement Impact . . . . . . . . . . . . . . . . . 14 <lb/>4.3.5. Fitting Function Coefficients Distribution . . . . . 15 <lb/>4.3.6. Exit Condition . . . . . . . . . . . . . . . . . . . 15 <lb/>4.3.7. Integration . . . . . . . . . . . . . . . . . . . . . 15 <lb/>4.3.8. Optimizations . . . . . . . . . . . . . . . . . . . . 15 <lb/>4.3.9. Offered Load Selection . . . . . . . . . . . . . . . 16 <lb/>4.3.10. Trend Analysis . . . . . . . . . . . . . . . . . . . 16 <lb/>5. Sample Implementation Specifics: FD.io CSIT . . . . . . . . . 16 <lb/>5.1. Measurement Delay . . . . . . . . . . . . . . . . . . . . 16 <lb/>5.2. Rounding Errors and Underflows . . . . . . . . . . . . . 17 <lb/>5.3. Fitting Functions . . . . . . . . . . . . . . . . . . . . 17 <lb/>5.3.1. Stretch Function . . . . . . . . . . . . . . . . . . 18 <lb/>5.3.2. Erf Function . . . . . . . . . . . . . . . . . . . . 18 <lb/>5.4. Prior Distributions . . . . . . . . . . . . . . . . . . . 19 <lb/>5.5. Integrator . . . . . . . . . . . . . . . . . . . . . . . 19 <lb/>5.6. Offered Load Selection . . . . . . . . . . . . . . . . . 20 <lb/>6. IANA Considerations . . . . . . . . . . . . . . . . . . . . . 20 <lb/>7. Security Considerations . . . . . . . . . . . . . . . . . . . 20 <lb/>8. Acknowledgements . . . . . . . . . . . . . . . . . . . . . . 21 <lb/>9. References . . . . . . . . . . . . . . . . . . . . . . . . . 21 <lb/>9.1. Normative References . . . . . . . . . . . . . . . . . . 21 <lb/>9.2. Informative References . . . . . . . . . . . . . . . . . 21 <lb/>Authors&apos; Addresses . . . . . . . . . . . . . . . . . . . . . . . 21 <lb/></div>

			<body>1. Motivation <lb/>Network providers are interested in throughput a system can sustain. <lb/>[RFC2544] assumes loss ratio is given by a deterministic function of <lb/>offered load. But NFV software systems are not deterministic enough. <lb/>This makes deterministic algorithms (such as Binary Search per <lb/>[RFC2544] and [draft-vpolak-mkonstan-bmwg-mlrsearch] with single <lb/>trial) to return results, which when repeated show relatively high <lb/>standard deviation, thus making it harder to tell what &quot;the <lb/>throughput&quot; actually is. <lb/>We need another algorithm, which takes this indeterminism into <lb/>account. <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 3] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>2. Relation To RFC2544 <lb/>The aim of this document is to become an extension of [RFC2544] <lb/>suitable for benchmarking networking setups such as software based <lb/>NFV systems. <lb/>3. Terms And Assumptions <lb/>3.1. Device Under Test <lb/>In software networking, &quot;device&quot; denotes a specific piece of software <lb/>tasked with packet processing. Such device is surrounded with other <lb/>software components (such as operating system kernel). It is not <lb/>possible to run devices without also running the other components, <lb/>and hardware resources are shared between both. <lb/>For purposes of testing, the whole set of hardware and software <lb/>components is called &quot;system under test&quot; (SUT). As SUT is the part <lb/>of the whole test setup performance of which can be measured by <lb/>[RFC2544] methods, this document uses SUT instead of [RFC2544] DUT. <lb/>Device under test (DUT) can be re-introduced when analysing test <lb/>results using whitebox techniques, but that is outside the scope of <lb/>this document. <lb/>3.2. System Under Test <lb/>System under test (SUT) is a part of the whole test setup whose <lb/>performance is to be benchmarked. The complete methodology contains <lb/>other parts, whose performance is either already established, or not <lb/>affecting the benchmarking result. <lb/>3.3. SUT Configuration <lb/>Usually, system under test allows different configurations, affecting <lb/>its performance. The rest of this document assumes a single <lb/>configuration has been chosen. <lb/>3.4. SUT Setup <lb/>Similarly to [RFC2544], it is assumed that the system under test has <lb/>been updated with all the packet forwarding information it needs, <lb/>before the trial measurements (see below) start. <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 4] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>3.5. Network Traffic <lb/>Network traffic is a type of interaction between system under test <lb/>and the rest of the system (traffic generator), used to gather <lb/>information about the system under test performance. PLRsearch is <lb/>applicable only to areas where network traffic consists of packets. <lb/>3.6. Packet <lb/>Unit of interaction between traffic generator and the system under <lb/>test. Term &quot;packet&quot; is used also as an abstraction of Ethernet <lb/>frames. <lb/>3.6.1. Packet Offered <lb/>Packet can be offered, which means it is sent from traffic generator <lb/>to the system under test. <lb/>Each offered packet is assumed to become received or lost in a short <lb/>time. <lb/>3.6.2. Packet Received <lb/>Packet can be received, which means the traffic generator verifies it <lb/>has been processed. Typically, when it is succesfully sent from the <lb/>system under test to traffic generator. <lb/>It is assumed that each received packet has been caused by an offered <lb/>packet, so the number of packets received cannot be larger than the <lb/>number of packets offered. <lb/>3.6.3. Packet Lost <lb/>Packet can be lost, which means sent but not received in a timely <lb/>manner. <lb/>It is assumed that each lost packet has been caused by an offered <lb/>packet, so the number of packets lost cannot be larger than the <lb/>number of packets offered. <lb/>Usually, the number of packets lost is computed as the number of <lb/>packets offered, minus the number of packets received. <lb/>3.6.4. Other Packets <lb/>PLRsearch is not considering other packet behaviors known from <lb/>networking (duplicated, reordered, greatly delayed), assuming the <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 5] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>test specification reclassifies those behaviors to fit into the first <lb/>three categories. <lb/>3.7. Traffic Profile <lb/>Usually, the performance of the system under test depends on a &quot;type&quot; <lb/>of a particular packet (for example size), and &quot;composition&quot; if the <lb/>network traffic consists of a mixture of different packet types. <lb/>Also, some systems under test contain multiple &quot;ports&quot; packets can be <lb/>offered to and received from. <lb/>All such qualities together (but not including properties of trial <lb/>measurements) are called traffic profile. <lb/>Similarly to system under test configuration, this document assumes <lb/>only one traffic profile has been chosen for a particular test. <lb/>3.8. Traffic Generator <lb/>Traffic generator is the part of the whole test setup, distinct from <lb/>the system under test, responsible both for offering packets in a <lb/>highly predictable manner (so the number of packets offered is <lb/>known), and for counting received packets in a precise enough way (to <lb/>distinguish lost packets from tolerably delayed packets). <lb/>Traffic generator must offer only packets compatible with the traffic <lb/>profile, and only count similarly compatible packets as received. <lb/>Criteria defining which received packets are compatible are left for <lb/>test specification to decide. <lb/>3.9. Offered Load <lb/>Offered load is an aggregate rate (measured in packets per second) of <lb/>network traffic offered to the system under test, the rate is kept <lb/>constant for the duration of trial measurement. <lb/>3.10. Trial Measurement <lb/>Trial measurement is a process of stressing (previously setup) system <lb/>under test by offering traffic of a particular offered load, for a <lb/>particular duration. <lb/>After that, the system has a short time to become idle, while the <lb/>traffic generator decides how many packets were lost. <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 6] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>After that, another trial measurement (possibly with different <lb/>offered load and duration) can be immediately performed. Traffic <lb/>generator should ignore received packets caused by packets offered in <lb/>previous trial measurements. <lb/>3.11. Trial Duration <lb/>Duration for which the traffic generator was offering packets at <lb/>constant offered load. <lb/>In theory, care has to be taken to ensure the offered load and trial <lb/>duration predict integer number of packets to offer, and that the <lb/>traffic generator really sends appropriate number of packets within <lb/>precisely enough timed duration. In practice, such consideration do <lb/>not change PLRsearch result in any significant way. <lb/>3.12. Packet Loss <lb/>Packet loss is any quantity describing a result of trial measurement. <lb/>It can be loss count, loss rate or loss ratio. Packet loss is zero <lb/>(or non-zero) if either of the three quantities are zero (or non-<lb/>zero, respecively). <lb/>3.12.1. Loss Count <lb/>Number of packets lost (or delayed too much) at a trial measurement <lb/>by the system under test as determined by packet generator. Measured <lb/>in packets. <lb/>3.12.2. Loss Rate <lb/>Loss rate is computed as loss count divided by trial duration. <lb/>Measured in packets per second. <lb/>3.12.3. Loss Ratio <lb/>Loss ratio is computed as loss count divided by number of packets <lb/>offered. Measured as a real (in practice rational) number between <lb/>zero or one (including). <lb/>3.13. Trial Order Independent System <lb/>Trial order independent system is a system under test, proven (or <lb/>just assumed) to produce trial measurement results that display trial <lb/>order independence. <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 7] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>That means when a pair of consequent trial measurements are <lb/>performed, the probability to observe a pair of specific results is <lb/>the same, as the probability to observe the reversed pair of results <lb/>whe performing the reversed pair of consequent measurements. <lb/>PLRsearch assumes the system under test is trial order independent. <lb/>In practice, most system under test are not entirely trial order <lb/>independent, but it is not easy to devise an algorithm taking that <lb/>into account. <lb/>3.14. Trial Measurement Result Distribution <lb/>When a trial order independent system is subjected to repeated trial <lb/>measurements of constant duration and offered load, Law of Large <lb/>Numbers implies the observed loss count frequencies will converge to <lb/>a specific probability distribution over possible loss counts. <lb/>This probability distribution is called trial measurement result <lb/>distribution, and it depends on all properties fixed when defining <lb/>it. That includes the system under test, its chosen configuration, <lb/>the chosen traffic profile, the offered load and the trial duration. <lb/>As the system is trial order independent, trial measurement result <lb/>distribution does not depend on results of few initial trial <lb/>measurements, of any offered load or (finite) duration. <lb/>3.15. Average Loss Ratio <lb/>Probability distribution over some (finite) set of states enables <lb/>computation of probability-weighted average of any quantity evaluated <lb/>on the states (called the expected value of the quantity). <lb/>Average loss ratio is simply the expected value of loss ratio for a <lb/>given trial measurement result distribution. <lb/>3.16. Duration Independent System <lb/>Duration independent system is a trial order independent system, <lb/>whose trial measurement result distribution is proven (or just <lb/>assumed) to display practical independence from trial duration. See <lb/>definition of trial duration for discussion on practical versus <lb/>theoretical. <lb/>The only requirement is for average loss ratio to be independent of <lb/>trial duration. <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 8] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>In theory, that would necessitate each trial measurement result <lb/>distribution to be a binomial distribution. In practice, more <lb/>distributions are allowed. <lb/>PLRsearch assumes the system under test is duration independent, at <lb/>least for trial durations typically chosen for trial measurements <lb/>initiated by PLRsearch. <lb/>3.17. Load Regions <lb/>For a duration independent system, trial measurement result <lb/>distribution depends only on offered load. <lb/>It is convenient to name some areas of offered load space by possible <lb/>trial results. <lb/>3.17.1. Zero Loss Region <lb/>A particular offered load value is said to belong to zero loss <lb/>region, if the probability of seeing non-zero loss trial measurement <lb/>result is exactly zero, or at least practically indistinguishable <lb/>from zero. <lb/>3.17.2. Guaranteed Loss Region <lb/>A particular offered load value is said to belong to guaranteed loss <lb/>region, if the probability of seeing zero loss trial measurement <lb/>result (for non-negligible count of packets offered) is exactly zero, <lb/>or at least practically indistinguishable from zero. <lb/>3.17.3. Non-Deterministic Region <lb/>A particular offered load value is said to belong to non-<lb/>deterministic region, if the probability of seeing zero loss trial <lb/>measurement result (for non-negligible count of packets offered) is <lb/>practically distinguishable from both zero and one. <lb/>3.17.4. Normal Region Ordering <lb/>Although theoretically the three regions can be arbitrary sets, this <lb/>document assumes they are intervals, where zero loss region contains <lb/>values smaller than non-deterministic region, which in turn contains <lb/>values smaller than guaranteed loss region. <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 9] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>3.18. Deterministic System <lb/>A hypothetical duration independent system with normal region <lb/>ordering, whose non-deterministic region is extremely narrow (only <lb/>present due to &quot;practical distinguishibility&quot; and cases when the <lb/>expected number of packets offered is not and integer). <lb/>A duration independent system which is not deterministic is called <lb/>non-deterministic system. <lb/>3.19. Througphput <lb/>Throughput is the highest offered load provably causing zero packet <lb/>loss for trial measurements of duration at least 60 seconds. <lb/>For duration independent systems with normal region ordering, the <lb/>throughput is the highest value within the zero loss region. <lb/>3.20. Deterministic Search <lb/>Any algorithm that assumes each measurement is a proof of the offered <lb/>load belonging to zero loss region (or not) is called deterministic <lb/>search. <lb/>This definition includes algorithms based on &quot;composite measurements&quot; <lb/>which perform multiple trial measurements, somehow re-classifying <lb/>results pointing at non-deterministic region. <lb/>Binary Search is an example of deterministic search. <lb/>Single run of a deterministic search launched against a deterministic <lb/>system is guaranteed to find the throughput with any prescribed <lb/>precision (not better than non-deterministic region width). <lb/>Multiple runs of a deterministic search launched against a non-<lb/>deterministic system can return varied results within non-<lb/>deterministic region. The exact distribution of deterministic search <lb/>results depends on the algorithm used. <lb/>3.21. Probabilistic Search <lb/>Any algorithm which performs probabilistic computations based on <lb/>observed results of trial measurements, and which does not assume <lb/>that non-deterministic region is practically absent, is called <lb/>probabilistic search. <lb/>A probabilistic search algorithm, which would assume that non-<lb/>deterministic region is practically absent, does not really need to <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 10] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>perform probabilistic computations, so it would become a <lb/>deterministic search. <lb/>While probabilistic search for estimating throughput is possible, it <lb/>would need a careful model for boundary between zero loss region and <lb/>non-deterministic region, and it would need a lot of measurements of <lb/>almost surely zero loss to reach good precision. <lb/>3.22. Loss Ratio Function <lb/>For any duration independent system, the average loss ratio depends <lb/>only on offered load (for a particular test setup). <lb/>Loss ratio function is the name used for the function mapping offered <lb/>load to average loss ratio. <lb/>This function is initially unknown. <lb/>3.23. Target Loss Ratio <lb/>Input parameter of PLRsearch. The average loss ratio the output of <lb/>PLRsearch aims to achieve. <lb/>3.24. Critical Load <lb/>Aggregate rate of network traffic, which would lead to average loss <lb/>ratio exactly matching target loss ratio, if used as the offered load <lb/>for infinite many trial measurement. <lb/>3.25. Critical Load Estimate <lb/>Any quantitative description of the possible critical load PLRsearch <lb/>is able to give after observing finite amount of trial measurements. <lb/>3.26. Fitting Function <lb/>Any function PLRsearch uses internally instead of the unknown loss <lb/>ratio function. Typically chosen from small set of formulas (shapes) <lb/>with few parameters to tweak. <lb/>3.27. Shape of Fitting Function <lb/>Any formula with few undetermined parameters. <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 11] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>3.28. Parameter Space <lb/>A subset of Real Coordinate Space. A point of parameter space is a <lb/>vector of real numbers. Fitting function is defined by shape (a <lb/>formula with parameters) and point of parameter space (specifying <lb/>values for the parameters). <lb/>4. Abstract Algorithm <lb/>4.1. High level description <lb/>PLRsearch accepts some input arguments, then iteratively performs <lb/>trial measurements at varying offered loads (and durations), and <lb/>returns some estimates of critical load. <lb/>PLRsearch input arguments form three groups. <lb/>First group has a single argument: measurer. This is a callback <lb/>(function) accepting offered load and duration, and returning the <lb/>measured loss count. <lb/>Second group consists of load related arguments required for measurer <lb/>to work correctly, typically minimal and maximal load to offer. <lb/>Also, target loss ratio (if not hardcoded) is a required argument. <lb/>Third group consists of time related arguments. Typically the <lb/>duration for the first trial measurement, duration increment per <lb/>subsequent trial measurement, and total time for search. Some <lb/>PLRsearch implementation may use estimation accuracy parameters as an <lb/>exit condition instead of total search time. <lb/>The returned quantities should describe the final (or best) estimate <lb/>of critical load. Implementers can chose any description that suits <lb/>their users, typically it is average and standard deviation, or lower <lb/>and upper boundary. <lb/>4.2. Main Ideas <lb/>The search tries to perform measurements at offered load close to the <lb/>critical load, because measurement results at offered loads far from <lb/>the critical load give less information on precise location of the <lb/>critical load. As virtually every trial measurement result alters <lb/>the estimate of the critical load, offered loads vary as they <lb/>approach the critical load. <lb/>The only quantity of trial measurement result affecting the <lb/>computation is loss count. No latency (or other information) is <lb/>taken into account. <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 12] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>PLRsearch uses Bayesian Inference, computed using numerical <lb/>integration, which takes long time to get reliable enough results. <lb/>Therefore it takes some time before the most recent measurement <lb/>result starts affecting subsequent offered loads and critical rate <lb/>estimates. <lb/>During the search, PLRsearch spawns few processes that perform <lb/>numerical computations, the main process is calling the measurer to <lb/>perform trial measurements, without any significant delays between <lb/>them. The durations of the trial measurements are increasing <lb/>linearly, as higher number of trial measurement results take longer <lb/>to process. <lb/>4.2.1. Trial Durations <lb/>[RFC2544] motivates the usage of at least 60 second duration by the <lb/>idea of the system under test slowly running out of resources (such <lb/>as memory buffers). <lb/>Practical results when measuring NFV software systems show that <lb/>relative change of trial duration has negligible effects on average <lb/>loss ratio, compared to relative change in offered load. <lb/>While the standard deviation of loss ratio usually shows some effects <lb/>of trial duration, they are hard to model. So PLRsearch assumes SUT <lb/>is duration independent, and chooses trial durations only based on <lb/>numeric integration requirements. <lb/>4.2.2. Target Loss Ratio <lb/>(TODO: Link to why we think 1e-7 is acceptable loss ratio.) <lb/>4.3. PLRsearch Building Blocks <lb/>Here we define notions used by PLRsearch which are not applicable to <lb/>other search methods, nor probabilistic systems under test in <lb/>general. <lb/>4.3.1. Bayesian Inference <lb/>PLRsearch uses a fixed set of fitting function shapes, and uses <lb/>Bayesian inference to track posterior distribution on each fitting <lb/>function parameter space. <lb/>Specifically, the few parameters describing a fitting function become <lb/>the model space. Given a prior over the model space, and trial <lb/>duration results, a posterior distribution is computed, together with <lb/>quantities describing the critical load estimate. <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 13] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>Likelihood of a particular loss count is computed using Poisson <lb/>distribution of average loss rate given by the fitting function (at <lb/>specific point of parameter space). <lb/>Side note: Binomial Distribution is a better fit compared to Poisson <lb/>distribution (acknowledging that the number of packets lost cannot be <lb/>higher than the number of packets offered), but the difference tends <lb/>to be relevant only in high loss region. Using Poisson distribution <lb/>lowers the impact of measurements in high loss region, thus helping <lb/>the algorithm to converge towards critical load faster. <lb/>4.3.2. Iterative Search <lb/>The idea PLRsearch is to iterate trial measurements, using Bayesian <lb/>inference to compute both the current estimate of the critical load <lb/>and the next offered load to measure at. <lb/>The required numerical computations are done in parallel with the <lb/>trial measurements. <lb/>This means the result of measurement &quot;n&quot; comes as an (additional) <lb/>input to the computation running in parallel with measurement &quot;n+1&quot;, <lb/>and the outputs of the computation are used for determining the <lb/>offered load for measurement &quot;n+2&quot;. <lb/>Other schemes are possible, aimed to increase the number of <lb/>measurements (by decreasing their duration), which would have even <lb/>higher number of measurements run before a result of a measurement <lb/>affects offered load. <lb/>4.3.3. Fitting Functions <lb/>To make the space of possible loss ratio functions more tractable the <lb/>algorithm uses only few fitting function shapes for its predicitons. <lb/>As the search algorithm needs to evaluate the function also far away <lb/>from the critical load, the fitting function have to be reasonably <lb/>behaved for every positive offered load, specifically cannot cannot <lb/>predict non-positive packet loss ratio. <lb/>4.3.4. Measurement Impact <lb/>Results from trials far from the critical load are likely to affect <lb/>the critical load estimate negatively, as the fitting functions do <lb/>not need to be good approximations there. This is true mainly for <lb/>guaranteed loss region, as in zero loss region even badly behaved <lb/>fitting function predicts loss count to be &quot;almost zero&quot;, so seeing a <lb/>measurement confirming the loss has been zero indeed has small <lb/>impact. <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 14] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>Discarding some results, or &quot;suppressing&quot; their impact with ad-hoc <lb/>methods (other than using Poisson distribution instead of binomial) <lb/>is not used, as such methods tend to make the overall search <lb/>unstable. We rely on most of measurements being done (eventually) <lb/>near the critical load, and overweighting far-off measurements <lb/>(eventually) for well-behaved fitting functions. <lb/>4.3.5. Fitting Function Coefficients Distribution <lb/>To accomodate systems with different behaviours, a fitting function <lb/>is expected to have few numeric parameters affecting its shape <lb/>(mainly affecting the linear approximation in the critical region). <lb/>The general search algorithm can use whatever increasing fitting <lb/>function, some specific functions are described later. <lb/>It is up to implementer to chose a fitting function and prior <lb/>distribution of its parameters. The rest of this document assumes <lb/>each parameter is independently and uniformly distributed over a <lb/>common interval. Implementers are to add non-linear transformations <lb/>into their fitting functions if their prior is different. <lb/>4.3.6. Exit Condition <lb/>Exit condition for the search is either the standard deviation of the <lb/>critical load estimate becoming small enough (or similar), or overal <lb/>search time becoming long enough. <lb/>The algorithm should report both average and standard deviation for <lb/>its critical load posterior. <lb/>4.3.7. Integration <lb/>The posterior distributions for fitting function parameters are not <lb/>be integrable in general. <lb/>The search algorithm utilises the fact that trial measurement takes <lb/>some time, so this time can be used for numeric integration (using <lb/>suitable method, such as Monte Carlo) to achieve sufficient <lb/>precision. <lb/>4.3.8. Optimizations <lb/>After enough trials, the posterior distribution will be concentrated <lb/>in a narrow area of the parameter space. The integration method <lb/>should take advantage of that. <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 15] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>Even in the concentrated area, the likelihood can be quite small, so <lb/>the integration algorithm should avoid underflow errors by some <lb/>means, for example by tracking the logarithm of the likelihood. <lb/>4.3.9. Offered Load Selection <lb/>The simplest rule is to set offered load for next trial measurememnt <lb/>equal to the current average (both over posterio and over fitting <lb/>function shapes) of the critical load estimate. <lb/>Contrary to critical load estimate computation, heuristic algorithms <lb/>affecting offered load selection do not introduce instability, and <lb/>can help with convergence speed. <lb/>4.3.10. Trend Analysis <lb/>If the reported averages follow a trend (maybe without reaching <lb/>equilibrium), average and standard deviation COULD refer to the <lb/>equilibrium estimates based on the trend, not to immediate posterior <lb/>values. <lb/>But such post-processing is discouraged, unless a clear reason for <lb/>the trend is known. Frequently, presence of such a trend is a sign <lb/>of some of PLRsearch assumption being violated (usually trial order <lb/>independence or duration independence). <lb/>It is RECOMMENDED to report any trend quantification together with <lb/>direct critical load estimate, so users can draw their own <lb/>conclusion. Alternatively, trend analysis may be a part of exit <lb/>conditions, requiring longer searches for systems displaying trends. <lb/>5. Sample Implementation Specifics: FD.io CSIT <lb/>The search receives min_rate and max_rate values, to avoid <lb/>measurements at offered loads not supporeted by the traffic <lb/>generator. <lb/>The implemented tests cases use bidirectional traffic. The algorithm <lb/>stores each rate as bidirectional rate (internally, the algorithm is <lb/>agnostic to flows and directions, it only cares about overall counts <lb/>of packets sent and packets lost), but debug output from traffic <lb/>generator lists unidirectional values. <lb/>5.1. Measurement Delay <lb/>In a sample implemenation in FD.io CSIT project, there is roughly 0.5 <lb/>second delay between trials due to restrictons imposed by packet <lb/>traffic generator in use (T-Rex). <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 16] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>As measurements results come in, posterior distribution computation <lb/>takes more time (per sample), although there is a considerable <lb/>constant part (mostly for inverting the fitting functions). <lb/>Also, the integrator needs a fair amount of samples to reach the <lb/>region the posterior distribution is concentrated at. <lb/>And of course, speed of the integrator depends on computing power of <lb/>the CPUs the algorithm is able to use. <lb/>All those timing related effects are addressed by arithmetically <lb/>increasing trial durations with configurable coefficients (currently <lb/>5.1 seconds for the first trial, each subsequent trial being 0.1 <lb/>second longer). <lb/>5.2. Rounding Errors and Underflows <lb/>In order to avoid them, the current implementation tracks natural <lb/>logarithm (instead of the original quantity) for any quantity which <lb/>is never negative. Logarithm of zero is minus infinity (not <lb/>supported by Python), so special value &quot;None&quot; is used instead. <lb/>Specific functions for frequent operations (such as &quot;logarithm of sum <lb/>of exponentials&quot;) are defined to handle None correctly. <lb/>5.3. Fitting Functions <lb/>Current implementation uses two fitting functions. In general, their <lb/>estimates for critical rate differ, which adds a simple source of <lb/>systematic error, on top of posterior dispersion reported by <lb/>integrator. Otherwise the reported stdev of critical rate estimate <lb/>is unrealistically low. <lb/>Both functions are not only increasing, but also convex (meaning the <lb/>rate of increase is also increasing). <lb/>As Primitive Function to any positive function is an increasing <lb/>function, and Primitive Function to any increasing function is convex <lb/>function; both fitting functions were constructed as double Primitive <lb/>Function to a positive function (even though the intermediate <lb/>increasing function is easier to describe). <lb/>As not any function is integrable, some more realistic functions <lb/>(especially with respect to behavior at very small offered loads) are <lb/>not easily available. <lb/>Both fitting functions have a &quot;central point&quot; and a &quot;spread&quot;, varied <lb/>by simply shifting and scaling (in x-axis, the offered load <lb/>direction) the function to be doubly integrated. Scaling in y-axis <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

            <page>[Page 17] <lb/></page>

            <note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <body>(the loss rate direction) is fixed by the requirement of transfer <lb/>rate staying nearly constant in very high offered loads. <lb/>In both fitting functions (as they are a double Primitive Function to <lb/>a symmetric function), the &quot;central point&quot; turns out to be equal to <lb/>the aforementioned limiting transfer rate, so the fitting function <lb/>parameter is named &quot;mrr&quot;, the same quantity CSIT Maximum Receive Rate <lb/>tests are designed to measure. <lb/>Both fitting functions return logarithm of loss rate, to avoid <lb/>rounding errors and underflows. Parameters and offered load are not <lb/>given as logarithms, as they are not expected to be extreme, and the <lb/>formulas are simpler that way. <lb/>Both fitting functions have several mathematically equivalent <lb/>formulas, each can lead to an overflow or underflow in different <lb/>places. Overflows can be eliminated by using different exact <lb/>formulas for different argument ranges. Underflows can be avoided by <lb/>using approximate formulas in affected argument ranges, such ranges <lb/>have their own formulas to compute. At the end, both fitting <lb/>function implementations contain multiple &quot;if&quot; branches, <lb/>discontinuities are a possibility at range boundaries. <lb/>5.3.1. Stretch Function <lb/>The original function (before applying logarithm) is Primitive <lb/>Function to Logistic Function. The name &quot;stretch&quot; is used for <lb/>related a function in context of neural networks with sigmoid <lb/>activation function. <lb/>Formula for stretch fitting function: average loss rate (r) computed <lb/>from offered load (b), mrr parameter (m) and spread parameter (a), <lb/>given as InputForm of Wolfram language: <lb/>r = (a*(1 + E^(m/a))*Log[(E^(b/a) + E^(m/a))/(1 + E^(m/a))])/E^(m/a) <lb/>5.3.2. Erf Function <lb/>The original function is double Primitive Function to Gaussian <lb/>Function. The name &quot;erf&quot; comes from error function, the first <lb/>primitive to Gaussian. <lb/>Formula for erf fitting function: average loss rate (r) computed from <lb/>offered load (b), mrr parameter (m) and spread parameter (a), given <lb/>as InputForm of Wolfram language: <lb/>r = ((a*(E^(-((b -m)^2/a^2)) -E^(-(m^2/a^2))))/Sqrt[Pi] + m*Erfc[m/a] <lb/>+ (b -m)*Erfc[(-b + m)/a])/(1 + Erf[m/a]) <lb/></body>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

			<page>[Page 18] <lb/></page>

			<note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

			<body>>5.4. Prior Distributions <lb/>The numeric integrator expects all the parameters to be distributed <lb/>(independently and) uniformly on an interval (-1, 1). <lb/>As both &quot;mrr&quot; and &quot;spread&quot; parameters are positive and not <lb/>dimensionless, a transformation is needed. Dimentionality is <lb/>inherited from max_rate value. <lb/>The &quot;mrr&quot; parameter follows a Lomax Distribution with alpha equal to <lb/>one, but shifted so that mrr is always greater than 1 packet per <lb/>second. <lb/>The &quot;stretch&quot; parameter is generated simply as the &quot;mrr&quot; value raised <lb/>to a random power between zero and one; thus it follows a Reciprocal <lb/>Distribution. <lb/>5.5. Integrator <lb/>After few measurements, the posterior distribution of fitting <lb/>function arguments gets quite concentrated into a small area. The <lb/>integrator is using Monte Carlo with Importance Sampling where the <lb/>biased distribution is Bivariate Gaussian distribution, with <lb/>deliberately larger variance. If the generated sample falls outside <lb/>(-1, 1) interval, another sample is generated. <lb/>The the center and the covariance matrix for the biased distribution <lb/>is based on the first and second moments of samples seen so far <lb/>(within the computation), with the following additional features <lb/>designed to avoid hyper-focused distributions. <lb/>Each computation starts with the biased distribution inherited from <lb/>the previous computation (zero point and unit covariance matrix is <lb/>used in the first computation), but the overal weight of the data is <lb/>set to the weight of the first sample of the computation. Also, the <lb/>center is set to the first sample point. When additional samples <lb/>come, their weight (including the importance correction) is compared <lb/>to the weight of data seen so far (within the computation). If the <lb/>new sample is more than one e-fold more impactful, both weight values <lb/>(for data so far and for the new sample) are set to (geometric) <lb/>average if the two weights. Finally, the actual sample generator <lb/>uses covariance matrix scaled up by a configurable factor (8.0 by <lb/>default). <lb/>This combination showed the best behavior, as the integrator usually <lb/>follows two phases. First phase (where inherited biased distribution <lb/>or single big sasmples are dominating) is mainly important for <lb/>locating the new area the posterior distribution is concentrated at. <lb/></body>

			<note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

			<page>[Page 19] <lb/></page>

			<note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

			<body>The second phase (dominated by whole sample population) is actually <lb/>relevant for the critical rate estimation. <lb/>5.6. Offered Load Selection <lb/>First two measurements are hardcoded to happen at the middle of rate <lb/>interval and at max_rate. Next two measurements follow MRR-like <lb/>logic, offered load is decreased so that it would reach target loss <lb/>ratio if offered load decrease lead to equal decrease of loss rate. <lb/>Basis for offered load for next trial measurements is the integrated <lb/>average of current critical rate estimate, averaged over fitting <lb/>function. <lb/>There is one workaround implemented, aimed at reducing the number of <lb/>consequent zero loss measurements. The workaround first stores every <lb/>measurement result which loss ratio was the targed loss ratio or <lb/>higher. Sorted list (called lossy loads) of such results is <lb/>maintained. <lb/>When a sequence of one or more zero loss measurement results is <lb/>encountered, a smallest of lossy loads is drained from the list. If <lb/>the estimate average is smaller than the drained value, a weighted <lb/>average of this estimate and the drained value is used as the next <lb/>offered load. The weight of the drained value doubles with each <lb/>additional consecutive zero loss results. <lb/>This behavior helps the algorithm with convergence speed, as it does <lb/>not need so many zero loss result to get near critical load. Using <lb/>the smallest (not drained yet) of lossy loads makes it sure the new <lb/>offered load is unlikely to result in big loss region. Draining even <lb/>if the estimate is large enough helps to discard early measurements <lb/>when loss hapened at too low offered load. Current implementation <lb/>adds 4 copies of lossy loads and drains 3 of them, which leads to <lb/>fairly stable behavior even for somewhat inconsistent SUTs. <lb/>6. IANA Considerations <lb/>No requests of IANA. <lb/>7. Security Considerations <lb/>Benchmarking activities as described in this memo are limited to <lb/>technology characterization of a DUT/SUT using controlled stimuli in <lb/>a laboratory environment, with dedicated address space and the <lb/>constraints specified in the sections above. <lb/></body>

			<note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

			<page>[Page 20] <lb/></page>

			<note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

			<body>The benchmarking network topology will be an independent test setup <lb/> and MUST NOT be connected to devices that may forward the test <lb/>traffic into a production network or misroute traffic to the test <lb/>management network. <lb/>Further, benchmarking is performed on a &quot;black-box&quot; basis, relying <lb/>solely on measurements observable external to the DUT/SUT. <lb/>Special capabilities SHOULD NOT exist in the DUT/SUT specifically for <lb/>benchmarking purposes. Any implications for network security arising <lb/>from the DUT/SUT SHOULD be identical in the lab and in production <lb/>networks. <lb/></body>

            <div type="acknowledgement">8. Acknowledgements <lb/>.. <lb/></div>

			<listBibl>9. References <lb/>9.1. Normative References <lb/>[RFC2544] Bradner, S. and J. McQuaid, &quot;Benchmarking Methodology for <lb/>Network Interconnect Devices&quot;, RFC 2544, <lb/>DOI 10.17487/RFC2544, March 1999, <lb/>&lt;https://www.rfc-editor.org/info/rfc2544&gt;. <lb/>[RFC8174] Leiba, B., &quot;Ambiguity of Uppercase vs Lowercase in RFC <lb/>2119 Key Words&quot;, BCP 14, RFC 8174, DOI 10.17487/RFC8174, <lb/>May 2017, &lt;https://www.rfc-editor.org/info/rfc8174&gt;. <lb/>9.2. Informative References <lb/>[draft-vpolak-mkonstan-bmwg-mlrsearch] <lb/>&quot;Multiple Loss Ratio Search for Packet Throughput <lb/>(MLRsearch)&quot;, July 2019, &lt;https://tools.ietf.org/html/ <lb/>draft-vpolak-mkonstan-bmwg-mlrsearch&gt;. <lb/></listBibl>

            Authors&apos; Addresses <lb/>

            <front>Maciek Konstantynowicz (editor) <lb/>Cisco Systems <lb/>Email: mkonstan@cisco.com <lb/></front>

			<note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

			<page>[Page 21] <lb/></page>

			<note place="headnote">Internet-DraProbabilistic Loss Ratio Search for Packet Throug July 2019 <lb/></note>

            <front>Vratko Polak (editor) <lb/>Cisco Systems <lb/> Email: vrpolak@cisco.com <lb/></front>

            <note place="footnote">Konstantynowicz &amp; Polak Expires January 9, 2020 <lb/></note>

			<page>[Page 22] </page>


	</text>
</tei>
