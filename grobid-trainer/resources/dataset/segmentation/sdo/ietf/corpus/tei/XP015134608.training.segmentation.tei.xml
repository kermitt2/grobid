<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>server date 20190804; downloaded by EPO on 20190805 <lb/>NFSv4 <lb/>D. Noveck, Ed. <lb/>Internet-Draft <lb/>NetApp <lb/>Obsoletes: 5661 (if approved) <lb/>C. Lever <lb/>Intended status: Standards Track <lb/>ORACLE <lb/>Expires: February 5, 2020 <lb/>August 4, 2019 <lb/>Network File System (NFS) Version 4 Minor Version 1 Protocol <lb/>draft-ietf-nfsv4-rfc5661sesqui-msns-01 <lb/>Abstract <lb/>This document describes the Network File System (NFS) version 4 minor <lb/>version 1, including features retained from the base protocol (NFS <lb/>version 4 minor version 0, which is specified in RFC 7530) and <lb/>protocol extensions made subsequently. The later minor version has <lb/>no dependencies on NFS version 4 minor version 0, and is considered a <lb/>separate protocol. <lb/>This document obsoletes RFC5661. It substantialy revises the <lb/>treatment of features relating to multi-server namesapce superseding <lb/>the description of those features appearing in RFC5661. <lb/>Status of This Memo <lb/>This Internet-Draft is submitted in full conformance with the <lb/>provisions of BCP 78 and BCP 79. <lb/>Internet-Drafts are working documents of the Internet Engineering <lb/>Task Force (IETF). Note that other groups may also distribute <lb/>working documents as Internet-Drafts. The list of current Internet-<lb/>Drafts is at https://datatracker.ietf.org/drafts/current/. <lb/>Internet-Drafts are draft documents valid for a maximum of six months <lb/>and may be updated, replaced, or obsoleted by other documents at any <lb/>time. It is inappropriate to use Internet-Drafts as reference <lb/>material or to cite them other than as &quot;work in progress.&quot; <lb/>This Internet-Draft will expire on February 5, 2020. <lb/>Copyright Notice <lb/>Copyright (c) 2019 IETF Trust and the persons identified as the <lb/>document authors. All rights reserved. <lb/>This document is subject to BCP 78 and the IETF Trust&apos;s Legal <lb/>Provisions Relating to IETF Documents <lb/>(https://trustee.ietf.org/license-info) in effect on the date of <lb/>Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/>[Page 1] <lb/>Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/>publication of this document. Please review these documents <lb/>carefully, as they describe your rights and restrictions with respect <lb/>to this document. Code Components extracted from this document must <lb/>include Simplified BSD License text as described in Section 4.e of <lb/>the Trust Legal Provisions and are provided without warranty as <lb/>described in the Simplified BSD License. <lb/>This document may contain material from IETF Documents or IETF <lb/>Contributions published or made publicly available before November <lb/>10, 2008. The person(s) controlling the copyright in some of this <lb/>material may not have granted the IETF Trust the right to allow <lb/>modifications of such material outside the IETF Standards Process. <lb/>Without obtaining an adequate license from the person(s) controlling <lb/>the copyright in such materials, this document may not be modified <lb/>outside the IETF Standards Process, and derivative works of it may <lb/>not be created outside the IETF Standards Process, except to format <lb/>it for publication as an RFC or to translate it into languages other <lb/>than English. <lb/></front>

			<div type="toc">Table of Contents <lb/>1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . <lb/>7 <lb/>1.1. Introduction to this Update . . . . . . . . . . . . . . . <lb/>7 <lb/>1.2. The NFS Version 4 Minor Version 1 Protocol . . . . . . . <lb/>8 <lb/>1.3. Requirements Language . . . . . . . . . . . . . . . . . . <lb/>9 <lb/>1.4. Scope of This Document . . . . . . . . . . . . . . . . . <lb/>9 <lb/>1.5. NFSv4 Goals . . . . . . . . . . . . . . . . . . . . . . . <lb/>9 <lb/>1.6. NFSv4.1 Goals . . . . . . . . . . . . . . . . . . . . . . 10 <lb/>1.7. General Definitions . . . . . . . . . . . . . . . . . . . 10 <lb/>1.8. Overview of NFSv4.1 Features . . . . . . . . . . . . . . 13 <lb/>1.9. Differences from NFSv4.0 . . . . . . . . . . . . . . . . 17 <lb/>2. Core Infrastructure . . . . . . . . . . . . . . . . . . . . . 18 <lb/>2.1. Introduction . . . . . . . . . . . . . . . . . . . . . . 18 <lb/>2.2. RPC and XDR . . . . . . . . . . . . . . . . . . . . . . . 18 <lb/>2.3. COMPOUND and CB_COMPOUND . . . . . . . . . . . . . . . . 22 <lb/>2.4. Client Identifiers and Client Owners . . . . . . . . . . 22 <lb/>2.5. Server Owners . . . . . . . . . . . . . . . . . . . . . . 28 <lb/>2.6. Security Service Negotiation . . . . . . . . . . . . . . 29 <lb/>2.7. Minor Versioning . . . . . . . . . . . . . . . . . . . . 34 <lb/>2.8. Non-RPC-Based Security Services . . . . . . . . . . . . . 36 <lb/>2.9. Transport Layers . . . . . . . . . . . . . . . . . . . . 37 <lb/>2.10. Session . . . . . . . . . . . . . . . . . . . . . . . . . 40 <lb/>3. Protocol Constants and Data Types . . . . . . . . . . . . . . 86 <lb/>3.1. Basic Constants . . . . . . . . . . . . . . . . . . . . . 86 <lb/>3.2. Basic Data Types . . . . . . . . . . . . . . . . . . . . 87 <lb/>3.3. Structured Data Types . . . . . . . . . . . . . . . . . . 89 <lb/>4. Filehandles . . . . . . . . . . . . . . . . . . . . . . . . . 97 <lb/>4.1. Obtaining the First Filehandle . . . . . . . . . . . . . 98 <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 2] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="toc">4.2. Filehandle Types . . . . . . . . . . . . . . . . . . . . 99 <lb/>4.3. One Method of Constructing a Volatile Filehandle . . . . 101 <lb/>4.4. Client Recovery from Filehandle Expiration . . . . . . . 102 <lb/>5. File Attributes . . . . . . . . . . . . . . . . . . . . . . . 103 <lb/>5.1. REQUIRED Attributes . . . . . . . . . . . . . . . . . . . 104 <lb/>5.2. RECOMMENDED Attributes . . . . . . . . . . . . . . . . . 104 <lb/>5.3. Named Attributes . . . . . . . . . . . . . . . . . . . . 105 <lb/>5.4. Classification of Attributes . . . . . . . . . . . . . . 106 <lb/>5.5. Set-Only and Get-Only Attributes . . . . . . . . . . . . 107 <lb/>5.6. REQUIRED Attributes -List and Definition References . . 107 <lb/>5.7. RECOMMENDED Attributes -List and Definition References . 108 <lb/>5.8. Attribute <lb/>Definitions . . . . . . . . . . . . . . 110 <lb/>5.9. Interpreting owner and owner_group . . . . . . . . . . . 119 <lb/>5.10. Character Case Attributes . . . . . . . . . . . . . . . . 121 <lb/>5.11. Directory Notification Attributes . . . . . . . . . . . . 121 <lb/>5.12. pNFS Attribute Definitions . . . . . . . . . . . . . . . 122 <lb/>5.13. Retention Attributes . . . . . . . . . . . . . . . . . . 123 <lb/>6. Access Control Attributes . . . . . . . . . . . . . . . . . . 126 <lb/>6.1. Goals . . . . . . . . . . . . . . . . . . . . . . . . . . 126 <lb/>6.2. File Attributes Discussion . . . . . . . . . . . . . . . 127 <lb/>6.3. Common Methods . . . . . . . . . . . . . . . . . . . . . 144 <lb/>6.4. Requirements . . . . . . . . . . . . . . . . . . . . . . 146 <lb/>7. Single-Server Namespace . . . . . . . . . . . . . . . . . . . 153 <lb/>7.1. Server Exports . . . . . . . . . . . . . . . . . . . . . 153 <lb/>7.2. Browsing Exports . . . . . . . . . . . . . . . . . . . . 153 <lb/>7.3. Server Pseudo File System . . . . . . . . . . . . . . . . 154 <lb/>7.4. Multiple Roots . . . . . . . . . . . . . . . . . . . . . 154 <lb/>7.5. Filehandle Volatility . . . . . . . . . . . . . . . . . . 155 <lb/>7.6. Exported Root . . . . . . . . . . . . . . . . . . . . . . 155 <lb/>7.7. Mount Point Crossing . . . . . . . . . . . . . . . . . . 155 <lb/>7.8. Security Policy and Namespace Presentation . . . . . . . 156 <lb/>8. State Management . . . . . . . . . . . . . . . . . . . . . . 157 <lb/>8.1. Client and Session ID . . . . . . . . . . . . . . . . . . 158 <lb/>8.2. Stateid Definition . . . . . . . . . . . . . . . . . . . 158 <lb/>8.3. Lease Renewal . . . . . . . . . . . . . . . . . . . . . . 167 <lb/>8.4. Crash Recovery . . . . . . . . . . . . . . . . . . . . . 169 <lb/>8.5. Server Revocation of Locks . . . . . . . . . . . . . . . 180 <lb/>8.6. Short and Long Leases . . . . . . . . . . . . . . . . . . 181 <lb/>8.7. Clocks, Propagation Delay, and Calculating Lease <lb/>Expiration . . . . . . . . . . . . . . . . . . . . . . . 182 <lb/>8.8. Obsolete Locking Infrastructure from NFSv4.0 . . . . . . 182 <lb/>9. File Locking and Share Reservations . . . . . . . . . . . . . 183 <lb/>9.1. Opens and Byte-Range Locks . . . . . . . . . . . . . . . 183 <lb/>9.2. Lock Ranges . . . . . . . . . . . . . . . . . . . . . . . 187 <lb/>9.3. Upgrading and Downgrading Locks . . . . . . . . . . . . . 188 <lb/>9.4. Stateid Seqid Values and Byte-Range Locks . . . . . . . . 188 <lb/>9.5. Issues with Multiple Open-Owners . . . . . . . . . . . . 188 <lb/>9.6. Blocking Locks . . . . . . . . . . . . . . . . . . . . . 189 <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 3] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="toc">9.7. Share Reservations . . . . . . . . . . . . . . . . . . . 190 <lb/>9.8. OPEN/CLOSE Operations . . . . . . . . . . . . . . . . . . 191 <lb/>9.9. Open Upgrade and Downgrade . . . . . . . . . . . . . . . 192 <lb/>9.10. Parallel OPENs . . . . . . . . . . . . . . . . . . . . . 193 <lb/>9.11. Reclaim of Open and Byte-Range Locks . . . . . . . . . . 193 <lb/>10. Client-Side Caching . . . . . . . . . . . . . . . . . . . . . 194 <lb/>10.1. Performance Challenges for Client-Side Caching . . . . . 194 <lb/>10.2. Delegation and Callbacks . . . . . . . . . . . . . . . . 195 <lb/>10.3. Data Caching . . . . . . . . . . . . . . . . . . . . . . 200 <lb/>10.4. Open Delegation . . . . . . . . . . . . . . . . . . . . 204 <lb/>10.5. Data Caching and Revocation . . . . . . . . . . . . . . 215 <lb/>10.6. Attribute Caching . . . . . . . . . . . . . . . . . . . 217 <lb/>10.7. Data and Metadata Caching and Memory Mapped Files . . . 219 <lb/>10.8. Name and Directory Caching without Directory Delegations 221 <lb/>10.9. Directory Delegations . . . . . . . . . . . . . . . . . 223 <lb/>11. Multi-Server Namespace . . . . . . . . . . . . . . . . . . . 227 <lb/>11.1. Terminology . . . . . . . . . . . . . . . . . . . . . . 227 <lb/>11.2. File System Location Attributes . . . . . . . . . . . . 230 <lb/>11.3. File System Presence or Absence . . . . . . . . . . . . 231 <lb/>11.4. Getting Attributes for an Absent File System . . . . . . 232 <lb/>11.5. Uses of File System Location Information . . . . . . . . 234 <lb/>11.6. Users and Groups in a Multi-server Namespace . . . . . . 242 <lb/>11.7. Additional Client-Side Considerations . . . . . . . . . 243 <lb/>11.8. Overview of File Access Transitions . . . . . . . . . . 244 <lb/>11.9. Effecting Network Endpoint Transitions . . . . . . . . . 244 <lb/>11.10. Effecting File System Transitions . . . . . . . . . . . 245 <lb/>11.11. Transferring State upon Migration . . . . . . . . . . . 253 <lb/>11.12. Client Responsibilities when Access is Transitioned . . 255 <lb/>11.13. Server Responsibilities Upon Migration . . . . . . . . . 264 <lb/>11.14. Effecting File System Referrals . . . . . . . . . . . . 270 <lb/>11.15. The Attribute fs_locations . . . . . . . . . . . . . . . 277 <lb/>11.16. The Attribute fs_locations_info . . . . . . . . . . . . 280 <lb/>11.17. The Attribute fs_status . . . . . . . . . . . . . . . . 293 <lb/>12. Parallel NFS (pNFS) . . . . . . . . . . . . . . . . . . . . . 297 <lb/>12.1. Introduction . . . . . . . . . . . . . . . . . . . . . . 297 <lb/>12.2. pNFS Definitions . . . . . . . . . . . . . . . . . . . . 298 <lb/>12.3. pNFS Operations . . . . . . . . . . . . . . . . . . . . 304 <lb/>12.4. pNFS Attributes . . . . . . . . . . . . . . . . . . . . 305 <lb/>12.5. Layout Semantics . . . . . . . . . . . . . . . . . . . . 305 <lb/>12.6. pNFS Mechanics . . . . . . . . . . . . . . . . . . . . . 320 <lb/>12.7. Recovery . . . . . . . . . . . . . . . . . . . . . . . . 322 <lb/>12.8. Metadata and Storage Device Roles . . . . . . . . . . . 327 <lb/>12.9. Security Considerations for pNFS . . . . . . . . . . . . 327 <lb/>13. NFSv4.1 as a Storage Protocol in pNFS: the File Layout Type . 329 <lb/>13.1. Client ID and Session Considerations . . . . . . . . . . 329 <lb/>13.2. File Layout Definitions . . . . . . . . . . . . . . . . 332 <lb/>13.3. File Layout Data Types . . . . . . . . . . . . . . . . . 332 <lb/>13.4. Interpreting the File Layout . . . . . . . . . . . . . . 336 <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 4] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="toc">13.5. Data Server Multipathing . . . . . . . . . . . . . . . . 344 <lb/>13.6. Operations Sent to NFSv4.1 Data Servers . . . . . . . . 345 <lb/>13.7. COMMIT through Metadata Server . . . . . . . . . . . . . 347 <lb/>13.8. The Layout Iomode . . . . . . . . . . . . . . . . . . . 348 <lb/>13.9. Metadata and Data Server State Coordination . . . . . . 349 <lb/>13.10. Data Server Component File Size . . . . . . . . . . . . 352 <lb/>13.11. Layout Revocation and Fencing . . . . . . . . . . . . . 352 <lb/>13.12. Security Considerations for the File Layout Type . . . . 353 <lb/>14. Internationalization . . . . . . . . . . . . . . . . . . . . 354 <lb/>14.1. Stringprep Profile for the utf8str_cs Type . . . . . . . 355 <lb/>14.2. Stringprep Profile for the utf8str_cis Type . . . . . . 357 <lb/>14.3. Stringprep Profile for the utf8str_mixed Type . . . . . 358 <lb/>14.4. UTF-8 Capabilities . . . . . . . . . . . . . . . . . . . 360 <lb/>14.5. UTF-8 Related Errors . . . . . . . . . . . . . . . . . . 360 <lb/>15. Error Values . . . . . . . . . . . . . . . . . . . . . . . . 361 <lb/>15.1. Error Definitions . . . . . . . . . . . . . . . . . . . 361 <lb/>15.2. Operations and Their Valid Errors . . . . . . . . . . . 380 <lb/>15.3. Callback Operations and Their Valid Errors . . . . . . . 396 <lb/>15.4. Errors and the Operations That Use Them . . . . . . . . 399 <lb/>16. NFSv4.1 Procedures . . . . . . . . . . . . . . . . . . . . . 414 <lb/>16.1. Procedure 0: NULL -No Operation . . . . . . . . . . . . 414 <lb/>16.2. Procedure 1: COMPOUND -Compound Operations . . . . . . 414 <lb/>17. Operations: REQUIRED, RECOMMENDED, or OPTIONAL . . . . . . . 426 <lb/>18. NFSv4.1 Operations . . . . . . . . . . . . . . . . . . . . . 429 <lb/>18.1. Operation 3: ACCESS -Check Access Rights . . . . . . . 429 <lb/>18.2. Operation 4: CLOSE -Close File . . . . . . . . . . . . 435 <lb/>18.3. Operation 5: COMMIT -Commit Cached Data . . . . . . . . 436 <lb/>18.4. Operation 6: CREATE -Create a Non-Regular File Object . 439 <lb/>18.5. Operation 7: DELEGPURGE -Purge Delegations Awaiting <lb/>Recovery . . . . . . . . . . . . . . . . . . . . . . . . 442 <lb/>18.6. Operation 8: DELEGRETURN -Return Delegation . . . . . . 443 <lb/>18.7. Operation 9: GETATTR -Get Attributes . . . . . . . . . 443 <lb/>18.8. Operation 10: GETFH -Get Current Filehandle . . . . . . 445 <lb/>18.9. Operation 11: LINK -Create Link to a File . . . . . . . 446 <lb/>18.10. Operation 12: LOCK -Create Lock . . . . . . . . . . . . 449 <lb/>18.11. Operation 13: LOCKT -Test for Lock . . . . . . . . . . 454 <lb/>18.12. Operation 14: LOCKU -Unlock File . . . . . . . . . . . 455 <lb/>18.13. Operation 15: LOOKUP -Lookup Filename . . . . . . . . . 457 <lb/>18.14. Operation 16: LOOKUPP -Lookup Parent Directory . . . . 459 <lb/>18.15. Operation 17: NVERIFY -Verify Difference in Attributes 460 <lb/>18.16. Operation 18: OPEN -Open a Regular File . . . . . . . . 461 <lb/>18.17. Operation 19: OPENATTR -Open Named Attribute Directory 481 <lb/>18.18. Operation 21: OPEN_DOWNGRADE -Reduce Open File Access . 483 <lb/>18.19. Operation 22: PUTFH -Set Current Filehandle . . . . . . 484 <lb/>18.20. Operation 23: PUTPUBFH -Set <lb/>Public Filehandle . . . . 485 <lb/>18.21. Operation 24: PUTROOTFH -Set Root Filehandle . . . . . 487 <lb/>18.22. Operation 25: READ -Read from File . . . . . . . . . . 488 <lb/>18.23. Operation 26: READDIR -Read Directory . . . . . . . . . 490 <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 5] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="toc">18.24. Operation 27: READLINK -Read Symbolic Link . . . . . . 494 <lb/>18.25. Operation 28: REMOVE -Remove File System Object . . . . 495 <lb/>18.26. Operation 29: RENAME -Rename Directory Entry . . . . . 498 <lb/>18.27. Operation 31: RESTOREFH -Restore Saved Filehandle . . . 501 <lb/>18.28. Operation 32: SAVEFH -Save Current Filehandle . . . . . 502 <lb/>18.29. Operation 33: SECINFO -Obtain Available Security . . . 503 <lb/>18.30. Operation 34: SETATTR -Set Attributes . . . . . . . . . 507 <lb/>18.31. Operation 37: VERIFY -Verify Same Attributes . . . . . 510 <lb/>18.32. Operation 38: WRITE -Write to File . . . . . . . . . . 511 <lb/>18.33. Operation 40: BACKCHANNEL_CTL -Backchannel Control . . 516 <lb/>18.34. Operation 41: BIND_CONN_TO_SESSION -Associate <lb/>Connection with Session . . . . . . . . . . . . . . . . 517 <lb/>18.35. Operation 42: EXCHANGE_ID -Instantiate Client ID . . . 520 <lb/>18.36. Operation 43: CREATE_SESSION -Create New Session and <lb/>Confirm Client ID . . . . . . . . . . . . . . . . . . . 538 <lb/>18.37. Operation 44: DESTROY_SESSION -Destroy a Session . . . 549 <lb/>18.38. Operation 45: FREE_STATEID -Free Stateid with No Locks 550 <lb/>18.39. Operation 46: GET_DIR_DELEGATION -Get a Directory <lb/>Delegation . . . . . . . . . . . . . . . . . . . . . . . 551 <lb/>18.40. Operation 47: GETDEVICEINFO -Get Device Information . . 555 <lb/>18.41. Operation 48: GETDEVICELIST -Get All Device Mappings <lb/>for a File System . . . . . . . . . . . . . . . . . . . 558 <lb/>18.42. Operation 49: LAYOUTCOMMIT -Commit Writes Made Using a <lb/>Layout . . . . . . . . . . . . . . . . . . . . . . . . . 560 <lb/>18.43. Operation 50: LAYOUTGET -Get Layout Information . . . . 564 <lb/>18.44. Operation 51: LAYOUTRETURN -Release Layout Information 573 <lb/>18.45. Operation 52: SECINFO_NO_NAME -Get Security on Unnamed <lb/>Object . . . . . . . . . . . . . . . . . . . . . . . . . 578 <lb/>18.46. Operation 53: SEQUENCE -Supply Per-Procedure Sequencing <lb/>and Control . . . . . . . . . . . . . . . . . . . . . . 579 <lb/>18.47. Operation 54: SET_SSV -Update SSV for a Client ID . . . 585 <lb/>18.48. Operation 55: TEST_STATEID -Test Stateids for Validity 587 <lb/>18.49. Operation 56: WANT_DELEGATION -Request Delegation . . . 589 <lb/>18.50. Operation 57: DESTROY_CLIENTID -Destroy a Client ID . . 593 <lb/>18.51. Operation 58: RECLAIM_COMPLETE -Indicates Reclaims <lb/>Finished . . . . . . . . . . . . . . . . . . . . . . . . 594 <lb/>18.52. Operation 10044: ILLEGAL -Illegal Operation . . . . . . 597 <lb/>19. NFSv4.1 Callback Procedures . . . . . . . . . . . . . . . . . 598 <lb/>19.1. Procedure 0: CB_NULL -No Operation . . . . . . . . . . 598 <lb/>19.2. Procedure 1: CB_COMPOUND -Compound Operations . . . . . 598 <lb/>20. NFSv4.1 Callback Operations . . . . . . . . . . . . . . . . . 603 <lb/>20.1. Operation 3: CB_GETATTR -Get Attributes . . . . . . . . 603 <lb/>20.2. Operation 4: CB_RECALL -Recall a Delegation . . . . . . 604 <lb/>20.3. Operation 5: CB_LAYOUTRECALL -Recall Layout from Client 605 <lb/>20.4. Operation 6: CB_NOTIFY -Notify Client of Directory <lb/>Changes . . . . . . . . . . . . . . . . . . . . . . . . 608 <lb/>20.5. Operation 7: CB_PUSH_DELEG -Offer Previously Requested <lb/>Delegation to Client . . . . . . . . . . . . . . . . . . 612 <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 6] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="toc">20.6. Operation 8: CB_RECALL_ANY -Keep Any N Recallable <lb/>Objects . . . . . . . . . . . . . . . . . . . . . . . . 613 <lb/>20.7. Operation 9: CB_RECALLABLE_OBJ_AVAIL -Signal Resources <lb/>for Recallable Objects . . . . . . . . . . . . . . . . . 616 <lb/>20.8. Operation 10: CB_RECALL_SLOT -Change Flow Control <lb/>Limits . . . . . . . . . . . . . . . . . . . . . . . . . 617 <lb/>20.9. Operation 11: CB_SEQUENCE -Supply Backchannel <lb/>Sequencing and Control . . . . . . . . . . . . . . . . . 618 <lb/>20.10. Operation 12: CB_WANTS_CANCELLED -Cancel Pending <lb/>Delegation Wants . . . . . . . . . . . . . . . . . . . . 621 <lb/>20.11. Operation 13: CB_NOTIFY_LOCK -Notify Client of Possible <lb/>Lock Availability . . . . . . . . . . . . . . . . . . . 622 <lb/>20.12. Operation 14: CB_NOTIFY_DEVICEID -Notify Client of <lb/>Device ID Changes . . . . . . . . . . . . . . . . . . . 623 <lb/>20.13. Operation 10044: CB_ILLEGAL -Illegal Callback Operation 625 <lb/>21. Security Considerations . . . . . . . . . . . . . . . . . . . 626 <lb/>22. IANA Considerations . . . . . . . . . . . . . . . . . . . . . 630 <lb/>22.1. IANA Actions Neeeded . . . . . . . . . . . . . . . . . . 630 <lb/>22.2. Named Attribute Definitions . . . . . . . . . . . . . . 630 <lb/>22.3. Device ID Notifications . . . . . . . . . . . . . . . . 631 <lb/>22.4. Object Recall Types . . . . . . . . . . . . . . . . . . 633 <lb/>22.5. Layout Types . . . . . . . . . . . . . . . . . . . . . . 635 <lb/>22.6. Path Variable Definitions . . . . . . . . . . . . . . . 637 <lb/>23. References . . . . . . . . . . . . . . . . . . . . . . . . . 641 <lb/>23.1. Normative References . . . . . . . . . . . . . . . . . . 641 <lb/>23.2. Informative References . . . . . . . . . . . . . . . . . 644 <lb/>Appendix A. Need for this Update . . . . . . . . . . . . . . . . 647 <lb/>Appendix B. Changes in this Update . . . . . . . . . . . . . . . 649 <lb/>B.1. Revisions Made to Section 11 of [RFC5661] . . . . . . . . 649 <lb/>B.2. Revisions Made to Operations in [RFC5661] . . . . . . . . 652 <lb/>B.3. Revisions Made to Error Definitions in [RFC5661] . . . . 655 <lb/>B.4. Other Revisions Made to [RFC5661] . . . . . . . . . . . . 655 <lb/>Appendix C. Security Issues that Need to be Addressed . . . . . 656 <lb/>Appendix D. Acknowledgments . . . . . . . . . . . . . . . . . . 658 <lb/>Authors&apos; Addresses . . . . . . . . . . . . . . . . . . . . . . . 661 <lb/></div>

			<body>1. Introduction <lb/>1.1. Introduction to this Update <lb/>The revised description of the NFS version 4 minor version 1 <lb/>(NFSv4.1) protocol presented in this update is necessary to enable <lb/>full use of trunking in connection with multi-server namespace <lb/>features and to enable the use of transparent state migration in <lb/>connection with NFSv4.1. See Appendix A for a discussion of the need <lb/>for this modified treatment and Appendix B for a description of the <lb/>specific changes made to arrive at the current text. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 7] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>This document is in the form of a complete updated description of the <lb/>protocol, rather than a series of updated sections. However, it is <lb/>not, as the term has generally been used with regard to NFSv4 minor <lb/>versions, a &quot;bis document&quot;, which contains a full description of the <lb/>protocol, with no documents updating it. Production of such a <lb/>document would require completion of the work items listed below. <lb/>This would include work with regard to documents which curently <lb/>update RFC5661 [60], which will also update this document. In <lb/>addition, it is believed that there are areas for which the <lb/>description in RFC5661 [60] is either incorrect or inadequate. <lb/>o Work would have to be done with regard to RFC8178 [61] with which <lb/>RFC5661 [60] is curretly inconsistent, in order to arrive at a <lb/>situation in which there would be no need for RFC8178 to update <lb/>the NFSv4.1 specfication. <lb/>o Work would have to be done with regard to RFC8434 [64] which <lb/>curently updates RFC5661 [60]. When that work is done and the <lb/>resulting document approved, the new NFSv4.1 specfication will <lb/>obsolete RFC8434 as well as RFC5661. <lb/>o There is a need for a new approach to the description of <lb/>internationalization since the current internationalization <lb/>section (Section 14) has never been implemented and does not meet <lb/>the needs of the NFSv4 protocol. Possible solutions are to create <lb/>a new internationalization section modeled on that in [62] or to <lb/>create a new document describing internationalization for all <lb/>NFSv4 minor versions and reference that document in the RFCs <lb/>defining both NFSv4.0 and NFSv4.1. <lb/>o There is a need for a revised treatment of security of in NFSv4.1. <lb/>The issues with the existing treatment are discussed in <lb/>Appendix C. <lb/>Until the above work is done, there will not be a full, correct <lb/>description of the NFSv41 protocol in a single document and any full <lb/>description would involves documents updating the specification, just <lb/>as RFC8434 [64] and RFC8178 [61] do today. <lb/>1.2. The NFS Version 4 Minor Version 1 Protocol <lb/>The NFS version 4 minor version 1 (NFSv4.1) protocol is the second <lb/>minor version of the NFS version 4 (NFSv4) protocol. The first minor <lb/>version, NFSv4.0, is now described in RFC7530 [62]. It generally <lb/>follows the guidelines for minor versioning that are listed in <lb/>Section 10 of RFC 3530. However, it diverges from guidelines 11 (&quot;a <lb/>client and server that support minor version X must support minor <lb/>versions 0 through X-1&quot;) and 12 (&quot;no new features may be introduced <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 8] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>as mandatory in a minor version&quot;). These divergences are due to the <lb/>introduction of the sessions model for managing non-idempotent <lb/>operations and the RECLAIM_COMPLETE operation. These two new <lb/>features are infrastructural in nature and simplify implementation of <lb/>existing and other new features. Making them anything but REQUIRED <lb/>would add undue complexity to protocol definition and implementation. <lb/>NFSv4.1 accordingly updates the minor versioning guidelines <lb/>(Section 2.7). <lb/>As a minor version, NFSv4.1 is consistent with the overall goals for <lb/>NFSv4, but extends the protocol so as to better meet those goals, <lb/>based on experiences with NFSv4.0. In addition, NFSv4.1 has adopted <lb/>some additional goals, which motivate some of the major extensions in <lb/>NFSv4.1. <lb/>1.3. Requirements Language <lb/>The key words &quot;MUST&quot;, &quot;MUST NOT&quot;, &quot;REQUIRED&quot;, &quot;SHALL&quot;, &quot;SHALL NOT&quot;, <lb/>&quot;SHOULD&quot;, &quot;SHOULD NOT&quot;, &quot;RECOMMENDED&quot;, &quot;MAY&quot;, and &quot;OPTIONAL&quot; in this <lb/>document are to be interpreted as described in RFC 2119 [1]. <lb/>1.4. Scope of This Document <lb/>This document describes the NFSv4.1 protocol. With respect to <lb/>NFSv4.0, this document does not: <lb/>o describe the NFSv4.0 protocol, except where needed to contrast <lb/>with NFSv4.1. <lb/>o modify the specification of the NFSv4.0 protocol. <lb/>o clarify the NFSv4.0 protocol. <lb/>1.5. NFSv4 Goals <lb/>The NFSv4 protocol is a further revision of the NFS protocol defined <lb/>already by NFSv3 [34]. It retains the essential characteristics of <lb/>previous versions: easy recovery; independence of transport <lb/>protocols, operating systems, and file systems; simplicity; and good <lb/>performance. NFSv4 has the following goals: <lb/>o Improved access and good performance on the Internet <lb/>The protocol is designed to transit firewalls easily, perform well <lb/>where latency is high and bandwidth is low, and scale to very <lb/>large numbers of clients per server. <lb/>o Strong security with negotiation built into the protocol <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 9] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The protocol builds on the work of the ONCRPC working group in <lb/>supporting the RPCSEC_GSS protocol. Additionally, the NFSv4.1 <lb/>protocol provides a mechanism to allow clients and servers the <lb/>ability to negotiate security and require clients and servers to <lb/>support a minimal set of security schemes. <lb/>o Good cross-platform interoperability <lb/>The protocol features a file system model that provides a useful, <lb/>common set of features that does not unduly favor one file system <lb/>or operating system over another. <lb/>o Designed for protocol extensions <lb/>The protocol is designed to accept standard extensions within a <lb/>framework that enables and encourages backward compatibility. <lb/>1.6. NFSv4.1 Goals <lb/>NFSv4.1 has the following goals, within the framework established by <lb/>the overall NFSv4 goals. <lb/>o To correct significant structural weaknesses and oversights <lb/>discovered in the base protocol. <lb/>o To add clarity and specificity to areas left unaddressed or not <lb/>addressed in sufficient detail in the base protocol. However, as <lb/>stated in Section 1.4, it is not a goal to clarify the NFSv4.0 <lb/>protocol in the NFSv4.1 specification. <lb/>o To add specific features based on experience with the existing <lb/>protocol and recent industry developments. <lb/>o To provide protocol support to take advantage of clustered server <lb/>deployments including the ability to provide scalable parallel <lb/>access to files distributed among multiple servers. <lb/>1.7. General Definitions <lb/>The following definitions provide an appropriate context for the <lb/>reader. <lb/>Byte: In this document, a byte is an octet, i.e., a datum exactly 8 <lb/>bits in length. <lb/>Client: The client is the entity that accesses the NFS server&apos;s <lb/>resources. The client may be an application that contains the <lb/>logic to access the NFS server directly. The client may also be <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 10] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the traditional operating system client that provides remote file <lb/>system services for a set of applications. <lb/>A client is uniquely identified by a client owner. <lb/>With reference to byte-range locking, the client is also the <lb/>entity that maintains a set of locks on behalf of one or more <lb/>applications. This client is responsible for crash or failure <lb/>recovery for those locks it manages. <lb/>Note that multiple clients may share the same transport and <lb/>connection and multiple clients may exist on the same network <lb/>node. <lb/>Client ID: The client ID is a 64-bit quantity used as a unique, <lb/>short-hand reference to a client-supplied verifier and client <lb/>owner. The server is responsible for supplying the client ID. <lb/>Client Owner: The client owner is a unique string, opaque to the <lb/>server, that identifies a client. Multiple network connections <lb/>and source network addresses originating from those connections <lb/>may share a client owner. The server is expected to treat <lb/>requests from connections with the same client owner as coming <lb/>from the same client. <lb/>File System: The file system is the collection of objects on a <lb/>server (as identified by the major identifier of a server owner, <lb/>which is defined later in this section) that share the same fsid <lb/>attribute (see Section 5.8.1.9). <lb/>Lease: A lease is an interval of time defined by the server for <lb/>which the client is irrevocably granted locks. At the end of a <lb/>lease period, locks may be revoked if the lease has not been <lb/>extended. A lock must be revoked if a conflicting lock has been <lb/>granted after the lease interval. <lb/>A server grants a client a single lease for all state. <lb/>Lock: The term &quot;lock&quot; is used to refer to byte-range (in UNIX <lb/>environments, also known as record) locks, share reservations, <lb/>delegations, or layouts unless specifically stated otherwise. <lb/>Secret State Verifier (SSV): The SSV is a unique secret key shared <lb/>between a client and server. The SSV serves as the secret key for <lb/>an internal (that is, internal to NFSv4.1) Generic Security <lb/>Services (GSS) mechanism (the SSV GSS mechanism; see <lb/>Section 2.10.9). The SSV GSS mechanism uses the SSV to compute <lb/>message integrity code (MIC) and Wrap tokens. See <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 11] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Section 2.10.8.3 for more details on how NFSv4.1 uses the SSV and <lb/>the SSV GSS mechanism. <lb/>Server: The Server is the entity responsible for coordinating client <lb/>access to a set of file systems and is identified by a server <lb/>owner. A server can span multiple network addresses. <lb/>Server Owner: The server owner identifies the server to the client. <lb/>The server owner consists of a major identifier and a minor <lb/>identifier. When the client has two connections each to a peer <lb/>with the same major identifier, the client assumes that both peers <lb/>are the same server (the server namespace is the same via each <lb/>connection) and that lock state is sharable across both <lb/>connections. When each peer has both the same major and minor <lb/>identifiers, the client assumes that each connection might be <lb/>associable with the same session. <lb/>Stable Storage: Stable storage is storage from which data stored by <lb/>an NFSv4.1 server can be recovered without data loss from multiple <lb/>power failures (including cascading power failures, that is, <lb/>several power failures in quick succession), operating system <lb/>failures, and/or hardware failure of components other than the <lb/>storage medium itself (such as disk, nonvolatile RAM, flash <lb/>memory, etc.). <lb/>Some examples of stable storage that are allowable for an NFS <lb/>server include: <lb/>1. Media commit of data; that is, the modified data has been <lb/>successfully written to the disk media, for example, the disk <lb/>platter. <lb/>2. An immediate reply disk drive with battery-backed, on-drive <lb/>intermediate storage or uninterruptible power system (UPS). <lb/>3. Server commit of data with battery-backed intermediate storage <lb/>and recovery software. <lb/>4. Cache commit with uninterruptible power system (UPS) and <lb/>recovery software. <lb/>Stateid: A stateid is a 128-bit quantity returned by a server that <lb/>uniquely defines the open and locking states provided by the <lb/>server for a specific open-owner or lock-owner/open-owner pair for <lb/>a specific file and type of lock. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 12] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Verifier: A verifier is a 64-bit quantity generated by the client <lb/>that the server can use to determine if the client has restarted <lb/>and lost all previous lock state. <lb/>1.8. Overview of NFSv4.1 Features <lb/>The major features of the NFSv4.1 protocol will be reviewed in brief. <lb/>This will be done to provide an appropriate context for both the <lb/>reader who is familiar with the previous versions of the NFS protocol <lb/>and the reader who is new to the NFS protocols. For the reader new <lb/>to the NFS protocols, there is still a set of fundamental knowledge <lb/>that is expected. The reader should be familiar with the External <lb/>Data Representation (XDR) and Remote Procedure Call (RPC) protocols <lb/>as described in [2] and [3]. A basic knowledge of file systems and <lb/>distributed file systems is expected as well. <lb/>In general, this specification of NFSv4.1 will not distinguish those <lb/>features added in minor version 1 from those present in the base <lb/>protocol but will treat NFSv4.1 as a unified whole. See Section 1.9 <lb/>for a summary of the differences between NFSv4.0 and NFSv4.1. <lb/>1.8.1. RPC and Security <lb/>As with previous versions of NFS, the External Data Representation <lb/>(XDR) and Remote Procedure Call (RPC) mechanisms used for the NFSv4.1 <lb/>protocol are those defined in [2] and [3]. To meet end-to-end <lb/>security requirements, the RPCSEC_GSS framework [4] is used to extend <lb/>the basic RPC security. With the use of RPCSEC_GSS, various <lb/>mechanisms can be provided to offer authentication, integrity, and <lb/>privacy to the NFSv4 protocol. Kerberos V5 is used as described in <lb/>[5] to provide one security framework. With the use of RPCSEC_GSS, <lb/>other mechanisms may also be specified and used for NFSv4.1 security. <lb/>To enable in-band security negotiation, the NFSv4.1 protocol has <lb/>operations that provide the client a method of querying the server <lb/>about its policies regarding which security mechanisms must be used <lb/>for access to the server&apos;s file system resources. With this, the <lb/>client can securely match the security mechanism that meets the <lb/>policies specified at both the client and server. <lb/>NFSv4.1 introduces parallel access (see Section 1.8.2.2), which is <lb/>called pNFS. The security framework described in this section is <lb/>significantly modified by the introduction of pNFS (see <lb/>Section 12.9), because data access is sometimes not over RPC. The <lb/>level of significance varies with the storage protocol (see <lb/>Section 12.2.5) and can be as low as zero impact (see Section 13.12). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 13] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>1.8.2. Protocol Structure <lb/>1.8.2.1. Core Protocol <lb/>Unlike NFSv3, which used a series of ancillary protocols (e.g., NLM, <lb/>NSM (Network Status Monitor), MOUNT), within all minor versions of <lb/>NFSv4 a single RPC protocol is used to make requests to the server. <lb/>Facilities that had been separate protocols, such as locking, are now <lb/>integrated within a single unified protocol. <lb/>1.8.2.2. Parallel Access <lb/>Minor version 1 supports high-performance data access to a clustered <lb/>server implementation by enabling a separation of metadata access and <lb/>data access, with the latter done to multiple servers in parallel. <lb/>Such parallel data access is controlled by recallable objects known <lb/>as &quot;layouts&quot;, which are integrated into the protocol locking model. <lb/>Clients direct requests for data access to a set of data servers <lb/>specified by the layout via a data storage protocol which may be <lb/>NFSv4.1 or may be another protocol. <lb/>Because the protocols used for parallel data access are not <lb/>necessarily RPC-based, the RPC-based security model (Section 1.8.1) <lb/>is obviously impacted (see Section 12.9). The degree of impact <lb/>varies with the storage protocol (see Section 12.2.5) used for data <lb/>access, and can be as low as zero (see Section 13.12). <lb/>1.8.3. File System Model <lb/>The general file system model used for the NFSv4.1 protocol is the <lb/>same as previous versions. The server file system is hierarchical <lb/>with the regular files contained within being treated as opaque byte <lb/>streams. In a slight departure, file and directory names are encoded <lb/>with UTF-8 to deal with the basics of internationalization. <lb/>The NFSv4.1 protocol does not require a separate protocol to provide <lb/>for the initial mapping between path name and filehandle. All file <lb/>systems exported by a server are presented as a tree so that all file <lb/>systems are reachable from a special per-server global root <lb/>filehandle. This allows LOOKUP operations to be used to perform <lb/>functions previously provided by the MOUNT protocol. The server <lb/>provides any necessary pseudo file systems to bridge any gaps that <lb/>arise due to unexported gaps between exported file systems. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 14] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>1.8.3.1. Filehandles <lb/>As in previous versions of the NFS protocol, opaque filehandles are <lb/>used to identify individual files and directories. Lookup-type and <lb/>create operations translate file and directory names to filehandles, <lb/>which are then used to identify objects in subsequent operations. <lb/>The NFSv4.1 protocol provides support for persistent filehandles, <lb/>guaranteed to be valid for the lifetime of the file system object <lb/>designated. In addition, it provides support to servers to provide <lb/>filehandles with more limited validity guarantees, called volatile <lb/>filehandles. <lb/>1.8.3.2. File Attributes <lb/>The NFSv4.1 protocol has a rich and extensible file object attribute <lb/>structure, which is divided into REQUIRED, RECOMMENDED, and named <lb/>attributes (see Section 5). <lb/>Several (but not all) of the REQUIRED attributes are derived from the <lb/>attributes of NFSv3 (see the definition of the fattr3 data type in <lb/>[34]). An example of a REQUIRED attribute is the file object&apos;s type <lb/>(Section 5.8.1.2) so that regular files can be distinguished from <lb/>directories (also known as folders in some operating environments) <lb/>and other types of objects. REQUIRED attributes are discussed in <lb/>Section 5.1. <lb/>An example of three RECOMMENDED attributes are acl, sacl, and dacl. <lb/>These attributes define an Access Control List (ACL) on a file object <lb/>(Section 6). An ACL provides directory and file access control <lb/>beyond the model used in NFSv3. The ACL definition allows for <lb/>specification of specific sets of permissions for individual users <lb/>and groups. In addition, ACL inheritance allows propagation of <lb/>access permissions and restrictions down a directory tree as file <lb/>system objects are created. RECOMMENDED attributes are discussed in <lb/>Section 5.2. <lb/>A named attribute is an opaque byte stream that is associated with a <lb/>directory or file and referred to by a string name. Named attributes <lb/>are meant to be used by client applications as a method to associate <lb/>application-specific data with a regular file or directory. NFSv4.1 <lb/>modifies named attributes relative to NFSv4.0 by tightening the <lb/>allowed operations in order to prevent the development of non-<lb/>interoperable implementations. Named attributes are discussed in <lb/>Section 5.3. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 15] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>1.8.3.3. Multi-Server Namespace <lb/>NFSv4.1 contains a number of features to allow implementation of <lb/>namespaces that cross server boundaries and that allow and facilitate <lb/>a non-disruptive transfer of support for individual file systems <lb/>between servers. They are all based upon attributes that allow one <lb/>file system to specify alternate, additional, and new location <lb/>information that specifies how the client may access that file <lb/>system. <lb/>These attributes can be used to provide for individual active file <lb/>systems: <lb/>o Alternate network addresses to access the current file system <lb/>instance. <lb/>o The locations of alternate file system instances or replicas to be <lb/>used in the event that the current file system instance becomes <lb/>unavailable. <lb/>These file system location attributes may be used together with the <lb/>concept of absent file systems, in which a position in the server <lb/>namespace is associated with locations on other servers without there <lb/>being any corresponding file system instance on the current server. <lb/>For example, <lb/>o These attributes may be used with absent file systems to implement <lb/>referrals whereby one server may direct the client to a file <lb/>system provided by another server. This allows extensive multi-<lb/>server namespaces to be constructed. <lb/>o These attributes may be provided when a previously present file <lb/>system becomes absent. This allows non-disruptive migration of <lb/>file systems to alternate servers. <lb/>1.8.4. Locking Facilities <lb/>As mentioned previously, NFSv4.1 is a single protocol that includes <lb/>locking facilities. These locking facilities include support for <lb/>many types of locks including a number of sorts of recallable locks. <lb/>Recallable locks such as delegations allow the client to be assured <lb/>that certain events will not occur so long as that lock is held. <lb/>When circumstances change, the lock is recalled via a callback <lb/>request. The assurances provided by delegations allow more extensive <lb/>caching to be done safely when circumstances allow it. <lb/>The types of locks are: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 16] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o Share reservations as established by OPEN operations. <lb/>o Byte-range locks. <lb/>o File delegations, which are recallable locks that assure the <lb/>holder that inconsistent opens and file changes cannot occur so <lb/>long as the delegation is held. <lb/>o Directory delegations, which are recallable locks that assure the <lb/>holder that inconsistent directory modifications cannot occur so <lb/>long as the delegation is held. <lb/>o Layouts, which are recallable objects that assure the holder that <lb/>direct access to the file data may be performed directly by the <lb/>client and that no change to the data&apos;s location that is <lb/>inconsistent with that access may be made so long as the layout is <lb/>held. <lb/>All locks for a given client are tied together under a single client-<lb/>wide lease. All requests made on sessions associated with the client <lb/>renew that lease. When the client&apos;s lease is not promptly renewed, <lb/>the client&apos;s locks are subject to revocation. In the event of server <lb/>restart, clients have the opportunity to safely reclaim their locks <lb/>within a special grace period. <lb/>1.9. Differences from NFSv4.0 <lb/>The following summarizes the major differences between minor version <lb/>1 and the base protocol: <lb/>o Implementation of the sessions model (Section 2.10). <lb/>o Parallel access to data (Section 12). <lb/>o Addition of the RECLAIM_COMPLETE operation to better structure the <lb/>lock reclamation process (Section 18.51). <lb/>o Enhanced delegation support as follows. <lb/>* Delegations on directories and other file types in addition to <lb/>regular files (Section 18.39, Section 18.49). <lb/>* Operations to optimize acquisition of recalled or denied <lb/>delegations (Section 18.49, Section 20.5, Section 20.7). <lb/>* Notifications of changes to files and directories <lb/>(Section 18.39, Section 20.4). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 17] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>* A method to allow a server to indicate that it is recalling one <lb/>or more delegations for resource management reasons, and thus a <lb/>method to allow the client to pick which delegations to return <lb/>(Section 20.6). <lb/>o Attributes can be set atomically during exclusive file create via <lb/>the OPEN operation (see the new EXCLUSIVE4_1 creation method in <lb/>Section 18.16). <lb/>o Open files can be preserved if removed and the hard link count <lb/>(&quot;hard link&quot; is defined in an Open Group [6] standard) goes to <lb/>zero, thus obviating the need for clients to rename deleted files <lb/>to partially hidden names --colloquially called &quot;silly rename&quot; <lb/>(see the new OPEN4_RESULT_PRESERVE_UNLINKED reply flag in <lb/>Section 18.16). <lb/>o Improved compatibility with Microsoft Windows for Access Control <lb/>Lists (Section 6.2.3, Section 6.2.2, Section 6.4.3.2). <lb/>o Data retention (Section 5.13). <lb/>o Identification of the implementation of the NFS client and server <lb/>(Section 18.35). <lb/>o Support for notification of the availability of byte-range locks <lb/>(see the new OPEN4_RESULT_MAY_NOTIFY_LOCK reply flag in <lb/>Section 18.16 and see Section 20.11). <lb/>o In NFSv4.1, LIPKEY and SPKM-3 are not required security mechanisms <lb/>[35]. <lb/>2. Core Infrastructure <lb/>2.1. Introduction <lb/>NFSv4.1 relies on core infrastructure common to nearly every <lb/>operation. This core infrastructure is described in the remainder of <lb/>this section. <lb/>2.2. RPC and XDR <lb/>The NFSv4.1 protocol is a Remote Procedure Call (RPC) application <lb/>that uses RPC version 2 and the corresponding eXternal Data <lb/>Representation (XDR) as defined in [3] and [2]. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 18] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.2.1. RPC-Based Security <lb/>Previous NFS versions have been thought of as having a host-based <lb/>authentication model, where the NFS server authenticates the NFS <lb/>client, and trusts the client to authenticate all users. Actually, <lb/>NFS has always depended on RPC for authentication. One of the first <lb/>forms of RPC authentication, AUTH_SYS, had no strong authentication <lb/>and required a host-based authentication approach. NFSv4.1 also <lb/>depends on RPC for basic security services and mandates RPC support <lb/>for a user-based authentication model. The user-based authentication <lb/>model has user principals authenticated by a server, and in turn the <lb/>server authenticated by user principals. RPC provides some basic <lb/>security services that are used by NFSv4.1. <lb/>2.2.1.1. RPC Security Flavors <lb/>As described in Section 7.2 (&quot;Authentication&quot;) of [3], RPC security <lb/>is encapsulated in the RPC header, via a security or authentication <lb/>flavor, and information specific to the specified security flavor. <lb/>Every RPC header conveys information used to identify and <lb/>authenticate a client and server. As discussed in Section 2.2.1.1.1, <lb/>some security flavors provide additional security services. <lb/>NFSv4.1 clients and servers MUST implement RPCSEC_GSS. (This <lb/>requirement to implement is not a requirement to use.) Other <lb/>flavors, such as AUTH_NONE and AUTH_SYS, MAY be implemented as well. <lb/>2.2.1.1.1. RPCSEC_GSS and Security Services <lb/>RPCSEC_GSS [4] uses the functionality of GSS-API [7]. This allows <lb/>for the use of various security mechanisms by the RPC layer without <lb/>the additional implementation overhead of adding RPC security <lb/>flavors. <lb/>2.2.1.1.1.1. Identification, Authentication, Integrity, Privacy <lb/>Via the GSS-API, RPCSEC_GSS can be used to identify and authenticate <lb/>users on clients to servers, and servers to users. It can also <lb/>perform integrity checking on the entire RPC message, including the <lb/>RPC header, and on the arguments or results. Finally, privacy, <lb/>usually via encryption, is a service available with RPCSEC_GSS. <lb/>Privacy is performed on the arguments and results. Note that if <lb/>privacy is selected, integrity, authentication, and identification <lb/>are enabled. If privacy is not selected, but integrity is selected, <lb/>authentication and identification are enabled. If integrity and <lb/>privacy are not selected, but authentication is enabled, <lb/>identification is enabled. RPCSEC_GSS does not provide <lb/>identification as a separate service. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 19] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Although GSS-API has an authentication service distinct from its <lb/>privacy and integrity services, GSS-API&apos;s authentication service is <lb/>not used for RPCSEC_GSS&apos;s authentication service. Instead, each RPC <lb/>request and response header is integrity protected with the GSS-API <lb/>integrity service, and this allows RPCSEC_GSS to offer per-RPC <lb/>authentication and identity. See [4] for more information. <lb/>NFSv4.1 client and servers MUST support RPCSEC_GSS&apos;s integrity and <lb/>authentication service. NFSv4.1 servers MUST support RPCSEC_GSS&apos;s <lb/>privacy service. NFSv4.1 clients SHOULD support RPCSEC_GSS&apos;s privacy <lb/>service. <lb/>2.2.1.1.1.2. Security Mechanisms for NFSv4.1 <lb/>RPCSEC_GSS, via GSS-API, normalizes access to mechanisms that provide <lb/>security services. Therefore, NFSv4.1 clients and servers MUST <lb/>support the Kerberos V5 security mechanism. <lb/>The use of RPCSEC_GSS requires selection of mechanism, quality of <lb/>protection (QOP), and service (authentication, integrity, privacy). <lb/>For the mandated security mechanisms, NFSv4.1 specifies that a QOP of <lb/>zero is used, leaving it up to the mechanism or the mechanism&apos;s <lb/>configuration to map QOP zero to an appropriate level of protection. <lb/>Each mandated mechanism specifies a minimum set of cryptographic <lb/>algorithms for implementing integrity and privacy. NFSv4.1 clients <lb/>and servers MUST be implemented on operating environments that comply <lb/>with the REQUIRED cryptographic algorithms of each REQUIRED <lb/>mechanism. <lb/>2.2.1.1.1.2.1. Kerberos V5 <lb/>The Kerberos V5 GSS-API mechanism as described in [5] MUST be <lb/>implemented with the RPCSEC_GSS services as specified in the <lb/>following table: <lb/>column descriptions: <lb/>1 == number of pseudo flavor <lb/>2 == name of pseudo flavor <lb/>3 == mechanism&apos;s OID <lb/>4 == RPCSEC_GSS service <lb/>5 == NFSv4.1 clients MUST support <lb/>6 == NFSv4.1 servers MUST support <lb/>1 <lb/>2 <lb/>3 <lb/>4 <lb/>5 <lb/>6 <lb/>------------------------------------------------------------------<lb/>390003 krb5 <lb/>1.2.840.113554.1.2.2 rpc_gss_svc_none <lb/>yes yes <lb/>390004 krb5i <lb/>1.2.840.113554.1.2.2 rpc_gss_svc_integrity yes yes <lb/>390005 krb5p <lb/>1.2.840.113554.1.2.2 rpc_gss_svc_privacy <lb/>no yes <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 20] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Note that the number and name of the pseudo flavor are presented here <lb/>as a mapping aid to the implementor. Because the NFSv4.1 protocol <lb/>includes a method to negotiate security and it understands the GSS-<lb/>API mechanism, the pseudo flavor is not needed. The pseudo flavor is <lb/>needed for the NFSv3 since the security negotiation is done via the <lb/>MOUNT protocol as described in [36]. <lb/>At the time NFSv4.1 was specified, the Advanced Encryption Standard <lb/>(AES) with HMAC-SHA1 was a REQUIRED algorithm set for Kerberos V5. <lb/>In contrast, when NFSv4.0 was specified, weaker algorithm sets were <lb/>REQUIRED for Kerberos V5, and were REQUIRED in the NFSv4.0 <lb/>specification, because the Kerberos V5 specification at the time did <lb/>not specify stronger algorithms. The NFSv4.1 specification does not <lb/>specify REQUIRED algorithms for Kerberos V5, and instead, the <lb/>implementor is expected to track the evolution of the Kerberos V5 <lb/>standard if and when stronger algorithms are specified. <lb/>2.2.1.1.1.2.1.1. Security Considerations for Cryptographic Algorithms <lb/>in Kerberos V5 <lb/>When deploying NFSv4.1, the strength of the security achieved depends <lb/>on the existing Kerberos V5 infrastructure. The algorithms of <lb/>Kerberos V5 are not directly exposed to or selectable by the client <lb/>or server, so there is some due diligence required by the user of <lb/>NFSv4.1 to ensure that security is acceptable where needed. <lb/>2.2.1.1.1.3. GSS Server Principal <lb/>Regardless of what security mechanism under RPCSEC_GSS is being used, <lb/>the NFS server MUST identify itself in GSS-API via a <lb/>GSS_C_NT_HOSTBASED_SERVICE name type. GSS_C_NT_HOSTBASED_SERVICE <lb/>names are of the form: <lb/>service@hostname <lb/>For NFS, the &quot;service&quot; element is <lb/>nfs <lb/>Implementations of security mechanisms will convert nfs@hostname to <lb/>various different forms. For Kerberos V5, the following form is <lb/>RECOMMENDED: <lb/>nfs/hostname <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 21] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.3. COMPOUND and CB_COMPOUND <lb/>A significant departure from the versions of the NFS protocol before <lb/>NFSv4 is the introduction of the COMPOUND procedure. For the NFSv4 <lb/>protocol, in all minor versions, there are exactly two RPC <lb/>procedures, NULL and COMPOUND. The COMPOUND procedure is defined as <lb/>a series of individual operations and these operations perform the <lb/>sorts of functions performed by traditional NFS procedures. <lb/>The operations combined within a COMPOUND request are evaluated in <lb/>order by the server, without any atomicity guarantees. A limited set <lb/>of facilities exist to pass results from one operation to another. <lb/>Once an operation returns a failing result, the evaluation ends and <lb/>the results of all evaluated operations are returned to the client. <lb/>With the use of the COMPOUND procedure, the client is able to build <lb/>simple or complex requests. These COMPOUND requests allow for a <lb/>reduction in the number of RPCs needed for logical file system <lb/>operations. For example, multi-component look up requests can be <lb/>constructed by combining multiple LOOKUP operations. Those can be <lb/>further combined with operations such as GETATTR, READDIR, or OPEN <lb/>plus READ to do more complicated sets of operation without incurring <lb/>additional latency. <lb/>NFSv4.1 also contains a considerable set of callback operations in <lb/>which the server makes an RPC directed at the client. Callback RPCs <lb/>have a similar structure to that of the normal server requests. In <lb/>all minor versions of the NFSv4 protocol, there are two callback RPC <lb/>procedures: CB_NULL and CB_COMPOUND. The CB_COMPOUND procedure is <lb/>defined in an analogous fashion to that of COMPOUND with its own set <lb/>of callback operations. <lb/>The addition of new server and callback operations within the <lb/>COMPOUND and CB_COMPOUND request framework provides a means of <lb/>extending the protocol in subsequent minor versions. <lb/>Except for a small number of operations needed for session creation, <lb/>server requests and callback requests are performed within the <lb/>context of a session. Sessions provide a client context for every <lb/>request and support robust reply protection for non-idempotent <lb/>requests. <lb/>2.4. Client Identifiers and Client Owners <lb/>For each operation that obtains or depends on locking state, the <lb/>specific client needs to be identifiable by the server. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 22] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Each distinct client instance is represented by a client ID. A <lb/>client ID is a 64-bit identifier representing a specific client at a <lb/>given time. The client ID is changed whenever the client re-<lb/>initializes, and may change when the server re-initializes. Client <lb/>IDs are used to support lock identification and crash recovery. <lb/>During steady state operation, the client ID associated with each <lb/>operation is derived from the session (see Section 2.10) on which the <lb/>operation is sent. A session is associated with a client ID when the <lb/>session is created. <lb/>Unlike NFSv4.0, the only NFSv4.1 operations possible before a client <lb/>ID is established are those needed to establish the client ID. <lb/>A sequence of an EXCHANGE_ID operation followed by a CREATE_SESSION <lb/>operation using that client ID (eir_clientid as returned from <lb/>EXCHANGE_ID) is required to establish and confirm the client ID on <lb/>the server. Establishment of identification by a new incarnation of <lb/>the client also has the effect of immediately releasing any locking <lb/>state that a previous incarnation of that same client might have had <lb/>on the server. Such released state would include all byte-range <lb/>lock, share reservation, layout state, and --where the server <lb/>supports neither the CLAIM_DELEGATE_PREV nor CLAIM_DELEG_CUR_FH claim <lb/>types --all delegation state associated with the same client with <lb/>the same identity. For discussion of delegation state recovery, see <lb/>Section 10.2.1. For discussion of layout state recovery, see <lb/>Section 12.7.1. <lb/>Releasing such state requires that the server be able to determine <lb/>that one client instance is the successor of another. Where this <lb/>cannot be done, for any of a number of reasons, the locking state <lb/>will remain for a time subject to lease expiration (see Section 8.3) <lb/>and the new client will need to wait for such state to be removed, if <lb/>it makes conflicting lock requests. <lb/>Client identification is encapsulated in the following client owner <lb/>data type: <lb/>struct client_owner4 { <lb/>verifier4 <lb/>co_verifier; <lb/>opaque <lb/>co_ownerid&lt;NFS4_OPAQUE_LIMIT&gt;; <lb/>}; <lb/>The first field, co_verifier, is a client incarnation verifier. The <lb/>server will start the process of canceling the client&apos;s leased state <lb/>if co_verifier is different than what the server has previously <lb/>recorded for the identified client (as specified in the co_ownerid <lb/>field). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 23] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The second field, co_ownerid, is a variable length string that <lb/>uniquely defines the client so that subsequent instances of the same <lb/>client bear the same co_ownerid with a different verifier. <lb/>There are several considerations for how the client generates the <lb/>co_ownerid string: <lb/>o The string should be unique so that multiple clients do not <lb/>present the same string. The consequences of two clients <lb/>presenting the same string range from one client getting an error <lb/>to one client having its leased state abruptly and unexpectedly <lb/>cancelled. <lb/>o The string should be selected so that subsequent incarnations <lb/>(e.g., restarts) of the same client cause the client to present <lb/>the same string. The implementor is cautioned from an approach <lb/>that requires the string to be recorded in a local file because <lb/>this precludes the use of the implementation in an environment <lb/>where there is no local disk and all file access is from an <lb/>NFSv4.1 server. <lb/>o The string should be the same for each server network address that <lb/>the client accesses. This way, if a server has multiple <lb/>interfaces, the client can trunk traffic over multiple network <lb/>paths as described in Section 2.10.5. (Note: the precise opposite <lb/>was advised in the NFSv4.0 specification [33].) <lb/>o The algorithm for generating the string should not assume that the <lb/>client&apos;s network address will not change, unless the client <lb/>implementation knows it is using statically assigned network <lb/>addresses. This includes changes between client incarnations and <lb/>even changes while the client is still running in its current <lb/>incarnation. Thus, with dynamic address assignment, if the client <lb/>includes just the client&apos;s network address in the co_ownerid <lb/>string, there is a real risk that after the client gives up the <lb/>network address, another client, using a similar algorithm for <lb/>generating the co_ownerid string, would generate a conflicting <lb/>co_ownerid string. <lb/>Given the above considerations, an example of a well-generated <lb/>co_ownerid string is one that includes: <lb/>o If applicable, the client&apos;s statically assigned network address. <lb/>o Additional information that tends to be unique, such as one or <lb/>more of: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 24] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>* The client machine&apos;s serial number (for privacy reasons, it is <lb/>best to perform some one-way function on the serial number). <lb/>* A Media Access Control (MAC) address (again, a one-way function <lb/>should be performed). <lb/>* The timestamp of when the NFSv4.1 software was first installed <lb/>on the client (though this is subject to the previously <lb/>mentioned caution about using information that is stored in a <lb/>file, because the file might only be accessible over NFSv4.1). <lb/>* A true random number. However, since this number ought to be <lb/>the same between client incarnations, this shares the same <lb/>problem as that of using the timestamp of the software <lb/>installation. <lb/>o For a user-level NFSv4.1 client, it should contain additional <lb/>information to distinguish the client from other user-level <lb/>clients running on the same host, such as a process identifier or <lb/>other unique sequence. <lb/>The client ID is assigned by the server (the eir_clientid result from <lb/>EXCHANGE_ID) and should be chosen so that it will not conflict with a <lb/>client ID previously assigned by the server. This applies across <lb/>server restarts. <lb/>In the event of a server restart, a client may find out that its <lb/>current client ID is no longer valid when it receives an <lb/>NFS4ERR_STALE_CLIENTID error. The precise circumstances depend on <lb/>the characteristics of the sessions involved, specifically whether <lb/>the session is persistent (see Section 2.10.6.5), but in each case <lb/>the client will receive this error when it attempts to establish a <lb/>new session with the existing client ID and receives the error <lb/>NFS4ERR_STALE_CLIENTID, indicating that a new client ID needs to be <lb/>obtained via EXCHANGE_ID and the new session established with that <lb/>client ID. <lb/>When a session is not persistent, the client will find out that it <lb/>needs to create a new session as a result of getting an <lb/>NFS4ERR_BADSESSION, since the session in question was lost as part of <lb/>a server restart. When the existing client ID is presented to a <lb/>server as part of creating a session and that client ID is not <lb/>recognized, as would happen after a server restart, the server will <lb/>reject the request with the error NFS4ERR_STALE_CLIENTID. <lb/>In the case of the session being persistent, the client will re-<lb/>establish communication using the existing session after the restart. <lb/>This session will be associated with the existing client ID but may <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 25] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>only be used to retransmit operations that the client previously <lb/>transmitted and did not see replies to. Replies to operations that <lb/>the server previously performed will come from the reply cache; <lb/>otherwise, NFS4ERR_DEADSESSION will be returned. Hence, such a <lb/>session is referred to as &quot;dead&quot;. In this situation, in order to <lb/>perform new operations, the client needs to establish a new session. <lb/>If an attempt is made to establish this new session with the existing <lb/>client ID, the server will reject the request with <lb/>NFS4ERR_STALE_CLIENTID. <lb/>When NFS4ERR_STALE_CLIENTID is received in either of these <lb/>situations, the client needs to obtain a new client ID by use of the <lb/>EXCHANGE_ID operation, then use that client ID as the basis of a new <lb/>session, and then proceed to any other necessary recovery for the <lb/>server restart case (see Section 8.4.2). <lb/>See the descriptions of EXCHANGE_ID (Section 18.35) and <lb/>CREATE_SESSION (Section 18.36) for a complete specification of these <lb/>operations. <lb/>2.4.1. Upgrade from NFSv4.0 to NFSv4.1 <lb/>To facilitate upgrade from NFSv4.0 to NFSv4.1, a server may compare a <lb/>value of data type client_owner4 in an EXCHANGE_ID with a value of <lb/>data type nfs_client_id4 that was established using the SETCLIENTID <lb/>operation of NFSv4.0. A server that does so will allow an upgraded <lb/>client to avoid waiting until the lease (i.e., the lease established <lb/>by the NFSv4.0 instance client) expires. This requires that the <lb/>value of data type client_owner4 be constructed the same way as the <lb/>value of data type nfs_client_id4. If the latter&apos;s contents included <lb/>the server&apos;s network address (per the recommendations of the NFSv4.0 <lb/>specification [33]), and the NFSv4.1 client does not wish to use a <lb/>client ID that prevents trunking, it should send two EXCHANGE_ID <lb/>operations. The first EXCHANGE_ID will have a client_owner4 equal to <lb/>the nfs_client_id4. This will clear the state created by the NFSv4.0 <lb/>client. The second EXCHANGE_ID will not have the server&apos;s network <lb/>address. The state created for the second EXCHANGE_ID will not have <lb/>to wait for lease expiration, because there will be no state to <lb/>expire. <lb/>2.4.2. Server Release of Client ID <lb/>NFSv4.1 introduces a new operation called DESTROY_CLIENTID <lb/>(Section 18.50), which the client SHOULD use to destroy a client ID <lb/>it no longer needs. This permits graceful, bilateral release of a <lb/>client ID. The operation cannot be used if there are sessions <lb/>associated with the client ID, or state with an unexpired lease. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 26] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If the server determines that the client holds no associated state <lb/>for its client ID (associated state includes unrevoked sessions, <lb/>opens, locks, delegations, layouts, and wants), the server MAY choose <lb/>to unilaterally release the client ID in order to conserve resources. <lb/>If the client contacts the server after this release, the server MUST <lb/>ensure that the client receives the appropriate error so that it will <lb/>use the EXCHANGE_ID/CREATE_SESSION sequence to establish a new client <lb/>ID. The server ought to be very hesitant to release a client ID <lb/>since the resulting work on the client to recover from such an event <lb/>will be the same burden as if the server had failed and restarted. <lb/>Typically, a server would not release a client ID unless there had <lb/>been no activity from that client for many minutes. As long as there <lb/>are sessions, opens, locks, delegations, layouts, or wants, the <lb/>server MUST NOT release the client ID. See Section 2.10.13.1.4 for <lb/>discussion on releasing inactive sessions. <lb/>2.4.3. Resolving Client Owner Conflicts <lb/>When the server gets an EXCHANGE_ID for a client owner that currently <lb/>has no state, or that has state but the lease has expired, the server <lb/>MUST allow the EXCHANGE_ID and confirm the new client ID if followed <lb/>by the appropriate CREATE_SESSION. <lb/>When the server gets an EXCHANGE_ID for a new incarnation of a client <lb/>owner that currently has an old incarnation with state and an <lb/>unexpired lease, the server is allowed to dispose of the state of the <lb/>previous incarnation of the client owner if one of the following is <lb/>true: <lb/>o The principal that created the client ID for the client owner is <lb/>the same as the principal that is sending the EXCHANGE_ID <lb/>operation. Note that if the client ID was created with <lb/>SP4_MACH_CRED state protection (Section 18.35), the principal MUST <lb/>be based on RPCSEC_GSS authentication, the RPCSEC_GSS service used <lb/>MUST be integrity or privacy, and the same GSS mechanism and <lb/>principal MUST be used as that used when the client ID was <lb/>created. <lb/>o The client ID was established with SP4_SSV protection <lb/>(Section 18.35, Section 2.10.8.3) and the client sends the <lb/>EXCHANGE_ID with the security flavor set to RPCSEC_GSS using the <lb/>GSS SSV mechanism (Section 2.10.9). <lb/>o The client ID was established with SP4_SSV protection, and under <lb/>the conditions described herein, the EXCHANGE_ID was sent with <lb/>SP4_MACH_CRED state protection. Because the SSV might not persist <lb/>across client and server restart, and because the first time a <lb/>client sends EXCHANGE_ID to a server it does not have an SSV, the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 27] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>client MAY send the subsequent EXCHANGE_ID without an SSV <lb/>RPCSEC_GSS handle. Instead, as with SP4_MACH_CRED protection, the <lb/>principal MUST be based on RPCSEC_GSS authentication, the <lb/>RPCSEC_GSS service used MUST be integrity or privacy, and the same <lb/>GSS mechanism and principal MUST be used as that used when the <lb/>client ID was created. <lb/>If none of the above situations apply, the server MUST return <lb/>NFS4ERR_CLID_INUSE. <lb/>If the server accepts the principal and co_ownerid as matching that <lb/>which created the client ID, and the co_verifier in the EXCHANGE_ID <lb/>differs from the co_verifier used when the client ID was created, <lb/>then after the server receives a CREATE_SESSION that confirms the <lb/>client ID, the server deletes state. If the co_verifier values are <lb/>the same (e.g., the client either is updating properties of the <lb/>client ID (Section 18.35) or is attempting trunking (Section 2.10.5), <lb/>the server MUST NOT delete state. <lb/>2.5. Server Owners <lb/>The server owner is similar to a client owner (Section 2.4), but <lb/>unlike the client owner, there is no shorthand server ID. The server <lb/>owner is defined in the following data type: <lb/>struct server_owner4 { <lb/>uint64_t <lb/>so_minor_id; <lb/>opaque <lb/>so_major_id&lt;NFS4_OPAQUE_LIMIT&gt;; <lb/>}; <lb/>The server owner is returned from EXCHANGE_ID. When the so_major_id <lb/>fields are the same in two EXCHANGE_ID results, the connections that <lb/>each EXCHANGE_ID were sent over can be assumed to address the same <lb/>server (as defined in Section 1.7). If the so_minor_id fields are <lb/>also the same, then not only do both connections connect to the same <lb/>server, but the session can be shared across both connections. The <lb/>reader is cautioned that multiple servers may deliberately or <lb/>accidentally claim to have the same so_major_id or so_major_id/ <lb/>so_minor_id; the reader should examine Sections 2.10.5 and 18.35 in <lb/>order to avoid acting on falsely matching server owner values. <lb/>The considerations for generating a so_major_id are similar to that <lb/>for generating a co_ownerid string (see Section 2.4). The <lb/>consequences of two servers generating conflicting so_major_id values <lb/>are less dire than they are for co_ownerid conflicts because the <lb/>client can use RPCSEC_GSS to compare the authenticity of each server <lb/>(see Section 2.10.5). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 28] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.6. Security Service Negotiation <lb/>With the NFSv4.1 server potentially offering multiple security <lb/>mechanisms, the client needs a method to determine or negotiate which <lb/>mechanism is to be used for its communication with the server. The <lb/>NFS server may have multiple points within its file system namespace <lb/>that are available for use by NFS clients. These points can be <lb/>considered security policy boundaries, and, in some NFS <lb/>implementations, are tied to NFS export points. In turn, the NFS <lb/>server may be configured such that each of these security policy <lb/>boundaries may have different or multiple security mechanisms in use. <lb/>The security negotiation between client and server SHOULD be done <lb/>with a secure channel to eliminate the possibility of a third party <lb/>intercepting the negotiation sequence and forcing the client and <lb/>server to choose a lower level of security than required or desired. <lb/>See Section 21 for further discussion. <lb/>2.6.1. NFSv4.1 Security Tuples <lb/>An NFS server can assign one or more &quot;security tuples&quot; to each <lb/>security policy boundary in its namespace. Each security tuple <lb/>consists of a security flavor (see Section 2.2.1.1) and, if the <lb/>flavor is RPCSEC_GSS, a GSS-API mechanism Object Identifier (OID), a <lb/>GSS-API quality of protection, and an RPCSEC_GSS service. <lb/>2.6.2. SECINFO and SECINFO_NO_NAME <lb/>The SECINFO and SECINFO_NO_NAME operations allow the client to <lb/>determine, on a per-filehandle basis, what security tuple is to be <lb/>used for server access. In general, the client will not have to use <lb/>either operation except during initial communication with the server <lb/>or when the client crosses security policy boundaries at the server. <lb/>However, the server&apos;s policies may also change at any time and force <lb/>the client to negotiate a new security tuple. <lb/>Where the use of different security tuples would affect the type of <lb/>access that would be allowed if a request was sent over the same <lb/>connection used for the SECINFO or SECINFO_NO_NAME operation (e.g., <lb/>read-only vs. read-write) access, security tuples that allow greater <lb/>access should be presented first. Where the general level of access <lb/>is the same and different security flavors limit the range of <lb/>principals whose privileges are recognized (e.g., allowing or <lb/>disallowing root access), flavors supporting the greatest range of <lb/>principals should be listed first. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 29] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.6.3. Security Error <lb/>Based on the assumption that each NFSv4.1 client and server MUST <lb/>support a minimum set of security (i.e., Kerberos V5 under <lb/>RPCSEC_GSS), the NFS client will initiate file access to the server <lb/>with one of the minimal security tuples. During communication with <lb/>the server, the client may receive an NFS error of NFS4ERR_WRONGSEC. <lb/>This error allows the server to notify the client that the security <lb/>tuple currently being used contravenes the server&apos;s security policy. <lb/>The client is then responsible for determining (see Section 2.6.3.1) <lb/>what security tuples are available at the server and choosing one <lb/>that is appropriate for the client. <lb/>2.6.3.1. Using NFS4ERR_WRONGSEC, SECINFO, and SECINFO_NO_NAME <lb/>This section explains the mechanics of NFSv4.1 security negotiation. <lb/>2.6.3.1.1. Put Filehandle Operations <lb/>The term &quot;put filehandle operation&quot; refers to PUTROOTFH, PUTPUBFH, <lb/>PUTFH, and RESTOREFH. Each of the subsections herein describes how <lb/>the server handles a subseries of operations that starts with a put <lb/>filehandle operation. <lb/>2.6.3.1.1.1. Put Filehandle Operation + SAVEFH <lb/>The client is saving a filehandle for a future RESTOREFH, LINK, or <lb/>RENAME. SAVEFH MUST NOT return NFS4ERR_WRONGSEC. To determine <lb/>whether or not the put filehandle operation returns NFS4ERR_WRONGSEC, <lb/>the server implementation pretends SAVEFH is not in the series of <lb/>operations and examines which of the situations described in the <lb/>other subsections of Section 2.6.3.1.1 apply. <lb/>2.6.3.1.1.2. Two or More Put Filehandle Operations <lb/>For a series of N put filehandle operations, the server MUST NOT <lb/>return NFS4ERR_WRONGSEC to the first N-1 put filehandle operations. <lb/>The Nth put filehandle operation is handled as if it is the first in <lb/>a subseries of operations. For example, if the server received a <lb/>COMPOUND request with this series of operations --PUTFH, PUTROOTFH, <lb/>LOOKUP --then the PUTFH operation is ignored for NFS4ERR_WRONGSEC <lb/>purposes, and the PUTROOTFH, LOOKUP subseries is processed as <lb/>according to Section 2.6.3.1.1.3. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 30] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.6.3.1.1.3. Put Filehandle Operation + LOOKUP (or OPEN of an Existing <lb/>Name) <lb/>This situation also applies to a put filehandle operation followed by <lb/>a LOOKUP or an OPEN operation that specifies an existing component <lb/>name. <lb/>In this situation, the client is potentially crossing a security <lb/>policy boundary, and the set of security tuples the parent directory <lb/>supports may differ from those of the child. The server <lb/>implementation may decide whether to impose any restrictions on <lb/>security policy administration. There are at least three approaches <lb/>(sec_policy_child is the tuple set of the child export, <lb/>sec_policy_parent is that of the parent). <lb/>(a) sec_policy_child &lt;= sec_policy_parent (&lt;= for subset). This <lb/>means that the set of security tuples specified on the security <lb/>policy of a child directory is always a subset of its parent <lb/>directory. <lb/>(b) sec_policy_child ^ sec_policy_parent != {} (^ for intersection, <lb/>{} for the empty set). This means that the set of security <lb/>tuples specified on the security policy of a child directory <lb/>always has a non-empty intersection with that of the parent. <lb/>(c) sec_policy_child ^ sec_policy_parent == {}. This means that the <lb/>set of security tuples specified on the security policy of a <lb/>child directory may not intersect with that of the parent. In <lb/>other words, there are no restrictions on how the system <lb/>administrator may set up these tuples. <lb/>In order for a server to support approaches (b) (for the case when a <lb/>client chooses a flavor that is not a member of sec_policy_parent) <lb/>and (c), the put filehandle operation cannot return NFS4ERR_WRONGSEC <lb/>when there is a security tuple mismatch. Instead, it should be <lb/>returned from the LOOKUP (or OPEN by existing component name) that <lb/>follows. <lb/>Since the above guideline does not contradict approach (a), it should <lb/>be followed in general. Even if approach (a) is implemented, it is <lb/>possible for the security tuple used to be acceptable for the target <lb/>of LOOKUP but not for the filehandles used in the put filehandle <lb/>operation. The put filehandle operation could be a PUTROOTFH or <lb/>PUTPUBFH, where the client cannot know the security tuples for the <lb/>root or public filehandle. Or the security policy for the filehandle <lb/>used by the put filehandle operation could have changed since the <lb/>time the filehandle was obtained. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 31] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Therefore, an NFSv4.1 server MUST NOT return NFS4ERR_WRONGSEC in <lb/>response to the put filehandle operation if the operation is <lb/>immediately followed by a LOOKUP or an OPEN by component name. <lb/>2.6.3.1.1.4. Put Filehandle Operation + LOOKUPP <lb/>Since SECINFO only works its way down, there is no way LOOKUPP can <lb/>return NFS4ERR_WRONGSEC without SECINFO_NO_NAME. SECINFO_NO_NAME <lb/>solves this issue via style SECINFO_STYLE4_PARENT, which works in the <lb/>opposite direction as SECINFO. As with Section 2.6.3.1.1.3, a put <lb/>filehandle operation that is followed by a LOOKUPP MUST NOT return <lb/>NFS4ERR_WRONGSEC. If the server does not support SECINFO_NO_NAME, <lb/>the client&apos;s only recourse is to send the put filehandle operation, <lb/>LOOKUPP, GETFH sequence of operations with every security tuple it <lb/>supports. <lb/>Regardless of whether SECINFO_NO_NAME is supported, an NFSv4.1 server <lb/>MUST NOT return NFS4ERR_WRONGSEC in response to a put filehandle <lb/>operation if the operation is immediately followed by a LOOKUPP. <lb/>2.6.3.1.1.5. Put Filehandle Operation + SECINFO/SECINFO_NO_NAME <lb/>A security-sensitive client is allowed to choose a strong security <lb/>tuple when querying a server to determine a file object&apos;s permitted <lb/>security tuples. The security tuple chosen by the client does not <lb/>have to be included in the tuple list of the security policy of <lb/>either the parent directory indicated in the put filehandle operation <lb/>or the child file object indicated in SECINFO (or any parent <lb/>directory indicated in SECINFO_NO_NAME). Of course, the server has <lb/>to be configured for whatever security tuple the client selects; <lb/>otherwise, the request will fail at the RPC layer with an appropriate <lb/>authentication error. <lb/>In theory, there is no connection between the security flavor used by <lb/>SECINFO or SECINFO_NO_NAME and those supported by the security <lb/>policy. But in practice, the client may start looking for strong <lb/>flavors from those supported by the security policy, followed by <lb/>those in the REQUIRED set. <lb/>The NFSv4.1 server MUST NOT return NFS4ERR_WRONGSEC to a put <lb/>filehandle operation that is immediately followed by SECINFO or <lb/>SECINFO_NO_NAME. The NFSv4.1 server MUST NOT return NFS4ERR_WRONGSEC <lb/>from SECINFO or SECINFO_NO_NAME. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 32] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.6.3.1.1.6. Put Filehandle Operation + Nothing <lb/>The NFSv4.1 server MUST NOT return NFS4ERR_WRONGSEC. <lb/>2.6.3.1.1.7. Put Filehandle Operation + Anything Else <lb/>&quot;Anything Else&quot; includes OPEN by filehandle. <lb/>The security policy enforcement applies to the filehandle specified <lb/>in the put filehandle operation. Therefore, the put filehandle <lb/>operation MUST return NFS4ERR_WRONGSEC when there is a security tuple <lb/>mismatch. This avoids the complexity of adding NFS4ERR_WRONGSEC as <lb/>an allowable error to every other operation. <lb/>A COMPOUND containing the series put filehandle operation + <lb/>SECINFO_NO_NAME (style SECINFO_STYLE4_CURRENT_FH) is an efficient way <lb/>for the client to recover from NFS4ERR_WRONGSEC. <lb/>The NFSv4.1 server MUST NOT return NFS4ERR_WRONGSEC to any operation <lb/>other than a put filehandle operation, LOOKUP, LOOKUPP, and OPEN (by <lb/>component name). <lb/>2.6.3.1.1.8. Operations after SECINFO and SECINFO_NO_NAME <lb/>Suppose a client sends a COMPOUND procedure containing the series <lb/>SEQUENCE, PUTFH, SECINFO_NONAME, READ, and suppose the security tuple <lb/>used does not match that required for the target file. By rule (see <lb/>Section 2.6.3.1.1.5), neither PUTFH nor SECINFO_NO_NAME can return <lb/>NFS4ERR_WRONGSEC. By rule (see Section 2.6.3.1.1.7), READ cannot <lb/>return NFS4ERR_WRONGSEC. The issue is resolved by the fact that <lb/>SECINFO and SECINFO_NO_NAME consume the current filehandle (note that <lb/>this is a change from NFSv4.0). This leaves no current filehandle <lb/>for READ to use, and READ returns NFS4ERR_NOFILEHANDLE. <lb/>2.6.3.1.2. LINK and RENAME <lb/>The LINK and RENAME operations use both the current and saved <lb/>filehandles. Technically, the server MAY return NFS4ERR_WRONGSEC <lb/>from LINK or RENAME if the security policy of the saved filehandle <lb/>rejects the security flavor used in the COMPOUND request&apos;s <lb/>credentials. If the server does so, then if there is no intersection <lb/>between the security policies of saved and current filehandles, this <lb/>means that it will be impossible for the client to perform the <lb/>intended LINK or RENAME operation. <lb/>For example, suppose the client sends this COMPOUND request: <lb/>SEQUENCE, PUTFH bFH, SAVEFH, PUTFH aFH, RENAME &quot;c&quot; &quot;d&quot;, where <lb/>filehandles bFH and aFH refer to different directories. Suppose no <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 33] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>common security tuple exists between the security policies of aFH and <lb/>bFH. If the client sends the request using credentials acceptable to <lb/>bFH&apos;s security policy but not aFH&apos;s policy, then the PUTFH aFH <lb/>operation will fail with NFS4ERR_WRONGSEC. After a SECINFO_NO_NAME <lb/>request, the client sends SEQUENCE, PUTFH bFH, SAVEFH, PUTFH aFH, <lb/>RENAME &quot;c&quot; &quot;d&quot;, using credentials acceptable to aFH&apos;s security policy <lb/>but not bFH&apos;s policy. The server returns NFS4ERR_WRONGSEC on the <lb/>RENAME operation. <lb/>To prevent a client from an endless sequence of a request containing <lb/>LINK or RENAME, followed by a request containing SECINFO_NO_NAME or <lb/>SECINFO, the server MUST detect when the security policies of the <lb/>current and saved filehandles have no mutually acceptable security <lb/>tuple, and MUST NOT return NFS4ERR_WRONGSEC from LINK or RENAME in <lb/>that situation. Instead the server MUST do one of two things: <lb/>o The server can return NFS4ERR_XDEV. <lb/>o The server can allow the security policy of the current filehandle <lb/>to override that of the saved filehandle, and so return NFS4_OK. <lb/>2.7. Minor Versioning <lb/>To address the requirement of an NFS protocol that can evolve as the <lb/>need arises, the NFSv4.1 protocol contains the rules and framework to <lb/>allow for future minor changes or versioning. <lb/></body>

			<body>The base assumption with respect to minor versioning is that any <lb/>future accepted minor version will be documented in one or more <lb/>Standards Track RFCs. Minor version 0 of the NFSv4 protocol is <lb/>represented by [33], and minor version 1 is represented by this RFC. <lb/>The COMPOUND and CB_COMPOUND procedures support the encoding of the <lb/>minor version being requested by the client. <lb/>The following items represent the basic rules for the development of <lb/>minor versions. Note that a future minor version may modify or add <lb/>to the following rules as part of the minor version definition. <lb/>1. <lb/>Procedures are not added or deleted. <lb/>To maintain the general RPC model, NFSv4 minor versions will not <lb/>add to or delete procedures from the NFS program. <lb/>2. <lb/>Minor versions may add operations to the COMPOUND and <lb/>CB_COMPOUND procedures. <lb/>The addition of operations to the COMPOUND and CB_COMPOUND <lb/>procedures does not affect the RPC model. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 34] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>* Minor versions may append attributes to the bitmap4 that <lb/>represents sets of attributes and to the fattr4 that <lb/>represents sets of attribute values. <lb/>This allows for the expansion of the attribute model to allow <lb/>for future growth or adaptation. <lb/>* Minor version X must append any new attributes after the last <lb/>documented attribute. <lb/>Since attribute results are specified as an opaque array of <lb/>per-attribute, XDR-encoded results, the complexity of adding <lb/>new attributes in the midst of the current definitions would <lb/>be too burdensome. <lb/>3. <lb/>Minor versions must not modify the structure of an existing <lb/>operation&apos;s arguments or results. <lb/>Again, the complexity of handling multiple structure definitions <lb/>for a single operation is too burdensome. New operations should <lb/>be added instead of modifying existing structures for a minor <lb/>version. <lb/>This rule does not preclude the following adaptations in a minor <lb/>version: <lb/>* adding bits to flag fields, such as new attributes to <lb/>GETATTR&apos;s bitmap4 data type, and providing corresponding <lb/>variants of opaque arrays, such as a notify4 used together <lb/>with such bitmaps <lb/>* adding bits to existing attributes like ACLs that have flag <lb/>words <lb/>* extending enumerated types (including NFS4ERR_*) with new <lb/>values <lb/>* adding cases to a switched union <lb/>4. <lb/>Minor versions must not modify the structure of existing <lb/>attributes. <lb/>5. <lb/>Minor versions must not delete operations. <lb/>This prevents the potential reuse of a particular operation <lb/>&quot;slot&quot; in a future minor version. <lb/>6. <lb/>Minor versions must not delete attributes. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 35] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>7. <lb/>Minor versions must not delete flag bits or enumeration values. <lb/>8. <lb/>Minor versions may declare an operation MUST NOT be implemented. <lb/>Specifying that an operation MUST NOT be implemented is <lb/>equivalent to obsoleting an operation. For the client, it means <lb/>that the operation MUST NOT be sent to the server. For the <lb/>server, an NFS error can be returned as opposed to &quot;dropping&quot; <lb/>the request as an XDR decode error. This approach allows for <lb/>the obsolescence of an operation while maintaining its structure <lb/>so that a future minor version can reintroduce the operation. <lb/>1. Minor versions may declare that an attribute MUST NOT be <lb/>implemented. <lb/>2. Minor versions may declare that a flag bit or enumeration <lb/>value MUST NOT be implemented. <lb/>9. <lb/>Minor versions may downgrade features from REQUIRED to <lb/>RECOMMENDED, or RECOMMENDED to OPTIONAL. <lb/>10. Minor versions may upgrade features from OPTIONAL to <lb/>RECOMMENDED, or RECOMMENDED to REQUIRED. <lb/>11. A client and server that support minor version X SHOULD support <lb/>minor versions zero through X-1 as well. <lb/>12. Except for infrastructural changes, a minor version must not <lb/>introduce REQUIRED new features. <lb/>This rule allows for the introduction of new functionality and <lb/>forces the use of implementation experience before designating a <lb/>feature as REQUIRED. On the other hand, some classes of <lb/>features are infrastructural and have broad effects. Allowing <lb/>infrastructural features to be RECOMMENDED or OPTIONAL <lb/>complicates implementation of the minor version. <lb/>13. A client MUST NOT attempt to use a stateid, filehandle, or <lb/>similar returned object from the COMPOUND procedure with minor <lb/>version X for another COMPOUND procedure with minor version Y, <lb/>where X != Y. <lb/>2.8. Non-RPC-Based Security Services <lb/>As described in Section 2.2.1.1.1.1, NFSv4.1 relies on RPC for <lb/>identification, authentication, integrity, and privacy. NFSv4.1 <lb/>itself provides or enables additional security services as described <lb/>in the next several subsections. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 36] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.8.1. Authorization <lb/>Authorization to access a file object via an NFSv4.1 operation is <lb/>ultimately determined by the NFSv4.1 server. A client can <lb/>predetermine its access to a file object via the OPEN (Section 18.16) <lb/>and the ACCESS (Section 18.1) operations. <lb/>Principals with appropriate access rights can modify the <lb/>authorization on a file object via the SETATTR (Section 18.30) <lb/>operation. Attributes that affect access rights include mode, owner, <lb/>owner_group, acl, dacl, and sacl. See Section 5. <lb/>2.8.2. Auditing <lb/>NFSv4.1 provides auditing on a per-file object basis, via the acl and <lb/>sacl attributes as described in Section 6. It is outside the scope <lb/>of this specification to specify audit log formats or management <lb/>policies. <lb/>2.8.3. Intrusion Detection <lb/>NFSv4.1 provides alarm control on a per-file object basis, via the <lb/>acl and sacl attributes as described in Section 6. Alarms may serve <lb/>as the basis for intrusion detection. It is outside the scope of <lb/>this specification to specify heuristics for detecting intrusion via <lb/>alarms. <lb/>2.9. Transport Layers <lb/>2.9.1. REQUIRED and RECOMMENDED Properties of Transports <lb/>NFSv4.1 works over Remote Direct Memory Access (RDMA) and non-RDMA-<lb/>based transports with the following attributes: <lb/>o The transport supports reliable delivery of data, which NFSv4.1 <lb/>requires but neither NFSv4.1 nor RPC has facilities for ensuring <lb/>[37]. <lb/>o The transport delivers data in the order it was sent. Ordered <lb/>delivery simplifies detection of transmit errors, and simplifies <lb/>the sending of arbitrary sized requests and responses via the <lb/>record marking protocol [3]. <lb/>Where an NFSv4.1 implementation supports operation over the IP <lb/>network protocol, any transport used between NFS and IP MUST be among <lb/>the IETF-approved congestion control transport protocols. At the <lb/>time this document was written, the only two transports that had the <lb/>above attributes were TCP and the Stream Control Transmission <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 37] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Protocol (SCTP). To enhance the possibilities for interoperability, <lb/>an NFSv4.1 implementation MUST support operation over the TCP <lb/>transport protocol. <lb/>Even if NFSv4.1 is used over a non-IP network protocol, it is <lb/>RECOMMENDED that the transport support congestion control. <lb/>It is permissible for a connectionless transport to be used under <lb/>NFSv4.1; however, reliable and in-order delivery of data combined <lb/>with congestion control by the connectionless transport is REQUIRED. <lb/>As a consequence, UDP by itself MUST NOT be used as an NFSv4.1 <lb/>transport. NFSv4.1 assumes that a client transport address and <lb/>server transport address used to send data over a transport together <lb/>constitute a connection, even if the underlying transport eschews the <lb/>concept of a connection. <lb/>2.9.2. Client and Server Transport Behavior <lb/>If a connection-oriented transport (e.g., TCP) is used, the client <lb/>and server SHOULD use long-lived connections for at least three <lb/>reasons: <lb/>1. This will prevent the weakening of the transport&apos;s congestion <lb/>control mechanisms via short-lived connections. <lb/>2. This will improve performance for the WAN environment by <lb/>eliminating the need for connection setup handshakes. <lb/>3. The NFSv4.1 callback model differs from NFSv4.0, and requires the <lb/>client and server to maintain a client-created backchannel (see <lb/>Section 2.10.3.1) for the server to use. <lb/>In order to reduce congestion, if a connection-oriented transport is <lb/>used, and the request is not the NULL procedure: <lb/>o A requester MUST NOT retry a request unless the connection the <lb/>request was sent over was lost before the reply was received. <lb/>o A replier MUST NOT silently drop a request, even if the request is <lb/>a retry. (The silent drop behavior of RPCSEC_GSS [4] does not <lb/>apply because this behavior happens at the RPCSEC_GSS layer, a <lb/>lower layer in the request processing.) Instead, the replier <lb/>SHOULD return an appropriate error (see Section 2.10.6.1), or it <lb/>MAY disconnect the connection. <lb/>When sending a reply, the replier MUST send the reply to the same <lb/>full network address (e.g., if using an IP-based transport, the <lb/>source port of the requester is part of the full network address) <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 38] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>from which the requester sent the request. If using a connection-<lb/>oriented transport, replies MUST be sent on the same connection from <lb/>which the request was received. <lb/>If a connection is dropped after the replier receives the request but <lb/>before the replier sends the reply, the replier might have a pending <lb/>reply. If a connection is established with the same source and <lb/>destination full network address as the dropped connection, then the <lb/>replier MUST NOT send the reply until the requester retries the <lb/>request. The reason for this prohibition is that the requester MAY <lb/>retry a request over a different connection (provided that connection <lb/>is associated with the original request&apos;s session). <lb/>When using RDMA transports, there are other reasons for not <lb/>tolerating retries over the same connection: <lb/>o RDMA transports use &quot;credits&quot; to enforce flow control, where a <lb/>credit is a right to a peer to transmit a message. If one peer <lb/>were to retransmit a request (or reply), it would consume an <lb/>additional credit. If the replier retransmitted a reply, it would <lb/>certainly result in an RDMA connection loss, since the requester <lb/>would typically only post a single receive buffer for each <lb/>request. If the requester retransmitted a request, the additional <lb/>credit consumed on the server might lead to RDMA connection <lb/>failure unless the client accounted for it and decreased its <lb/>available credit, leading to wasted resources. <lb/>o RDMA credits present a new issue to the reply cache in NFSv4.1. <lb/>The reply cache may be used when a connection within a session is <lb/>lost, such as after the client reconnects. Credit information is <lb/>a dynamic property of the RDMA connection, and stale values must <lb/>not be replayed from the cache. This implies that the reply cache <lb/>contents must not be blindly used when replies are sent from it, <lb/>and credit information appropriate to the channel must be <lb/>refreshed by the RPC layer. <lb/>In addition, as described in Section 2.10.6.2, while a session is <lb/>active, the NFSv4.1 requester MUST NOT stop waiting for a reply. <lb/>2.9.3. Ports <lb/>Historically, NFSv3 servers have listened over TCP port 2049. The <lb/>registered port 2049 [38] for the NFS protocol should be the default <lb/>configuration. NFSv4.1 clients SHOULD NOT use the RPC binding <lb/>protocols as described in [39]. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 39] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.10. Session <lb/>NFSv4.1 clients and servers MUST support and MUST use the session <lb/>feature as described in this section. <lb/>2.10.1. Motivation and Overview <lb/>Previous versions and minor versions of NFS have suffered from the <lb/>following: <lb/>o Lack of support for Exactly Once Semantics (EOS). This includes <lb/>lack of support for EOS through server failure and recovery. <lb/>o Limited callback support, including no support for sending <lb/>callbacks through firewalls, and races between replies to normal <lb/>requests and callbacks. <lb/>o Limited trunking over multiple network paths. <lb/>o Requiring machine credentials for fully secure operation. <lb/>Through the introduction of a session, NFSv4.1 addresses the above <lb/>shortfalls with practical solutions: <lb/>o EOS is enabled by a reply cache with a bounded size, making it <lb/>feasible to keep the cache in persistent storage and enable EOS <lb/>through server failure and recovery. One reason that previous <lb/>revisions of NFS did not support EOS was because some EOS <lb/>approaches often limited parallelism. As will be explained in <lb/>Section 2.10.6, NFSv4.1 supports both EOS and unlimited <lb/>parallelism. <lb/>o The NFSv4.1 client (defined in Section 1.7, Paragraph 2) creates <lb/>transport connections and provides them to the server to use for <lb/>sending callback requests, thus solving the firewall issue <lb/>(Section 18.34). Races between responses from client requests and <lb/>callbacks caused by the requests are detected via the session&apos;s <lb/>sequencing properties that are a consequence of EOS <lb/>(Section 2.10.6.3). <lb/>o The NFSv4.1 client can associate an arbitrary number of <lb/>connections with the session, and thus provide trunking <lb/>(Section 2.10.5). <lb/>o The NFSv4.1 client and server produces a session key independent <lb/>of client and server machine credentials which can be used to <lb/>compute a digest for protecting critical session management <lb/>operations (Section 2.10.8.3). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 40] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o The NFSv4.1 client can also create secure RPCSEC_GSS contexts for <lb/>use by the session&apos;s backchannel that do not require the server to <lb/>authenticate to a client machine principal (Section 2.10.8.2). <lb/>A session is a dynamically created, long-lived server object created <lb/>by a client and used over time from one or more transport <lb/>connections. Its function is to maintain the server&apos;s state relative <lb/>to the connection(s) belonging to a client instance. This state is <lb/>entirely independent of the connection itself, and indeed the state <lb/>exists whether or not the connection exists. A client may have one <lb/>or more sessions associated with it so that client-associated state <lb/>may be accessed using any of the sessions associated with that <lb/>client&apos;s client ID, when connections are associated with those <lb/>sessions. When no connections are associated with any of a client <lb/>ID&apos;s sessions for an extended time, such objects as locks, opens, <lb/>delegations, layouts, etc. are subject to expiration. The session <lb/>serves as an object representing a means of access by a client to the <lb/>associated client state on the server, independent of the physical <lb/>means of access to that state. <lb/>A single client may create multiple sessions. A single session MUST <lb/>NOT serve multiple clients. <lb/>2.10.2. NFSv4 Integration <lb/>Sessions are part of NFSv4.1 and not NFSv4.0. Normally, a major <lb/>infrastructure change such as sessions would require a new major <lb/>version number to an Open Network Computing (ONC) RPC program like <lb/>NFS. However, because NFSv4 encapsulates its functionality in a <lb/>single procedure, COMPOUND, and because COMPOUND can support an <lb/>arbitrary number of operations, sessions have been added to NFSv4.1 <lb/>with little difficulty. COMPOUND includes a minor version number <lb/>field, and for NFSv4.1 this minor version is set to 1. When the <lb/>NFSv4 server processes a COMPOUND with the minor version set to 1, it <lb/>expects a different set of operations than it does for NFSv4.0. <lb/>NFSv4.1 defines the SEQUENCE operation, which is required for every <lb/>COMPOUND that operates over an established session, with the <lb/>exception of some session administration operations, such as <lb/>DESTROY_SESSION (Section 18.37). <lb/>2.10.2.1. SEQUENCE and CB_SEQUENCE <lb/>In NFSv4.1, when the SEQUENCE operation is present, it MUST be the <lb/>first operation in the COMPOUND procedure. The primary purpose of <lb/>SEQUENCE is to carry the session identifier. The session identifier <lb/>associates all other operations in the COMPOUND procedure with a <lb/>particular session. SEQUENCE also contains required information for <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 41] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>maintaining EOS (see Section 2.10.6). Session-enabled NFSv4.1 <lb/>COMPOUND requests thus have the form: <lb/>+-----+--------------+-----------+------------+-----------+----<lb/>| tag | minorversion | numops <lb/>|SEQUENCE op | op + args | ... <lb/>| <lb/>| <lb/>(== 1) <lb/>| (limited) | + args <lb/>| <lb/>| <lb/>+-----+--------------+-----------+------------+-----------+----<lb/>and the replies have the form: <lb/>+------------+-----+--------+-------------------------------+--// <lb/>|last status | tag | numres |status + SEQUENCE op + results | // <lb/>+------------+-----+--------+-------------------------------+--// <lb/>//-----------------------+----<lb/>// status + op + results | ... <lb/>//-----------------------+----<lb/>A CB_COMPOUND procedure request and reply has a similar form to <lb/>COMPOUND, but instead of a SEQUENCE operation, there is a CB_SEQUENCE <lb/>operation. CB_COMPOUND also has an additional field called <lb/>&quot;callback_ident&quot;, which is superfluous in NFSv4.1 and MUST be ignored <lb/>by the client. CB_SEQUENCE has the same information as SEQUENCE, and <lb/>also includes other information needed to resolve callback races <lb/>(Section 2.10.6.3). <lb/>2.10.2.2. Client ID and Session Association <lb/>Each client ID (Section 2.4) can have zero or more active sessions. <lb/>A client ID and associated session are required to perform file <lb/>access in NFSv4.1. Each time a session is used (whether by a client <lb/>sending a request to the server or the client replying to a callback <lb/>request from the server), the state leased to its associated client <lb/>ID is automatically renewed. <lb/>State (which can consist of share reservations, locks, delegations, <lb/>and layouts (Section 1.8.4)) is tied to the client ID. Client state <lb/>is not tied to any individual session. Successive state changing <lb/>operations from a given state owner MAY go over different sessions, <lb/>provided the session is associated with the same client ID. A <lb/>callback MAY arrive over a different session than that of the request <lb/>that originally acquired the state pertaining to the callback. For <lb/>example, if session A is used to acquire a delegation, a request to <lb/>recall the delegation MAY arrive over session B if both sessions are <lb/>associated with the same client ID. Sections 2.10.8.1 and 2.10.8.2 <lb/>discuss the security considerations around callbacks. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 42] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.10.3. Channels <lb/>A channel is not a connection. A channel represents the direction <lb/>ONC RPC requests are sent. <lb/>Each session has one or two channels: the fore channel and the <lb/>backchannel. Because there are at most two channels per session, and <lb/>because each channel has a distinct purpose, channels are not <lb/>assigned identifiers. <lb/>The fore channel is used for ordinary requests from the client to the <lb/>server, and carries COMPOUND requests and responses. A session <lb/>always has a fore channel. <lb/>The backchannel is used for callback requests from server to client, <lb/>and carries CB_COMPOUND requests and responses. Whether or not there <lb/>is a backchannel is a decision made by the client; however, many <lb/>features of NFSv4.1 require a backchannel. NFSv4.1 servers MUST <lb/>support backchannels. <lb/>Each session has resources for each channel, including separate reply <lb/>caches (see Section 2.10.6.1). Note that even the backchannel <lb/>requires a reply cache (or, at least, a slot table in order to detect <lb/>retries) because some callback operations are nonidempotent. <lb/>2.10.3.1. Association of Connections, Channels, and Sessions <lb/>Each channel is associated with zero or more transport connections <lb/>(whether of the same transport protocol or different transport <lb/>protocols). A connection can be associated with one channel or both <lb/>channels of a session; the client and server negotiate whether a <lb/>connection will carry traffic for one channel or both channels via <lb/>the CREATE_SESSION (Section 18.36) and the BIND_CONN_TO_SESSION <lb/>(Section 18.34) operations. When a session is created via <lb/>CREATE_SESSION, the connection that transported the CREATE_SESSION <lb/>request is automatically associated with the fore channel, and <lb/>optionally the backchannel. If the client specifies no state <lb/>protection (Section 18.35) when the session is created, then when <lb/>SEQUENCE is transmitted on a different connection, the connection is <lb/>automatically associated with the fore channel of the session <lb/>specified in the SEQUENCE operation. <lb/>A connection&apos;s association with a session is not exclusive. A <lb/>connection associated with the channel(s) of one session may be <lb/>simultaneously associated with the channel(s) of other sessions <lb/>including sessions associated with other client IDs. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 43] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>It is permissible for connections of multiple transport types to be <lb/>associated with the same channel. For example, both TCP and RDMA <lb/>connections can be associated with the fore channel. In the event an <lb/>RDMA and non-RDMA connection are associated with the same channel, <lb/>the maximum number of slots SHOULD be at least one more than the <lb/>total number of RDMA credits (Section 2.10.6.1). This way, if all <lb/>RDMA credits are used, the non-RDMA connection can have at least one <lb/>outstanding request. If a server supports multiple transport types, <lb/>it MUST allow a client to associate connections from each transport <lb/>to a channel. <lb/>It is permissible for a connection of one type of transport to be <lb/>associated with the fore channel, and a connection of a different <lb/>type to be associated with the backchannel. <lb/>2.10.4. Server Scope <lb/>Servers each specify a server scope value in the form of an opaque <lb/>string eir_server_scope returned as part of the results of an <lb/>EXCHANGE_ID operation. The purpose of the server scope is to allow a <lb/>group of servers to indicate to clients that a set of servers sharing <lb/>the same server scope value has arranged to use compatible values of <lb/>otherwise opaque identifiers. Thus, the identifiers generated by two <lb/>servers within that set can be assumed compatible so that, in some <lb/>cases, identifiers generated by one server in that set may be <lb/>presented to another server of the same scope. <lb/>The use of such compatible values does not imply that a value <lb/>generated by one server will always be accepted by another. In most <lb/>cases, it will not. However, a server will not accept a value <lb/>generated by another inadvertently. When it does accept it, it will <lb/>be because it is recognized as valid and carrying the same meaning as <lb/>on another server of the same scope. <lb/>When servers are of the same server scope, this compatibility of <lb/>values applies to the following identifiers: <lb/>o Filehandle values. A filehandle value accepted by two servers of <lb/>the same server scope denotes the same object. A WRITE operation <lb/>sent to one server is reflected immediately in a READ sent to the <lb/>other. <lb/>o Server owner values. When the server scope values are the same, <lb/>server owner value may be validly compared. In cases where the <lb/>server scope values are different, server owner values are treated <lb/>as different even if they contain identical strings of bytes. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 44] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The coordination among servers required to provide such compatibility <lb/>can be quite minimal, and limited to a simple partition of the ID <lb/>space. The recognition of common values requires additional <lb/>implementation, but this can be tailored to the specific situations <lb/>in which that recognition is desired. <lb/>Clients will have occasion to compare the server scope values of <lb/>multiple servers under a number of circumstances, each of which will <lb/>be discussed under the appropriate functional section: <lb/>o When server owner values received in response to EXCHANGE_ID <lb/>operations sent to multiple network addresses are compared for the <lb/>purpose of determining the validity of various forms of trunking, <lb/>as described in Section 11.5.2. . <lb/>o When network or server reconfiguration causes the same network <lb/>address to possibly be directed to different servers, with the <lb/>necessity for the client to determine when lock reclaim should be <lb/>attempted, as described in Section 8.4.2.1. <lb/>When two replies from EXCHANGE_ID, each from two different server <lb/>network addresses, have the same server scope, there are a number of <lb/>ways a client can validate that the common server scope is due to two <lb/>servers cooperating in a group. <lb/>o If both EXCHANGE_ID requests were sent with RPCSEC_GSS ([4], [9], <lb/>[27]) authentication and the server principal is the same for both <lb/>targets, the equality of server scope is validated. It is <lb/>RECOMMENDED that two servers intending to share the same server <lb/>scope and server_owner major_id also share the same principal <lb/>name. In some cases, this simplifies the client&apos;s task of <lb/>validating server scope. <lb/>o The client may accept the appearance of the second server in the <lb/>fs_locations or fs_locations_info attribute for a relevant file <lb/>system. For example, if there is a migration event for a <lb/>particular file system or there are locks to be reclaimed on a <lb/>particular file system, the attributes for that particular file <lb/>system may be used. The client sends the GETATTR request to the <lb/>first server for the fs_locations or fs_locations_info attribute <lb/>with RPCSEC_GSS authentication. It may need to do this in advance <lb/>of the need to verify the common server scope. If the client <lb/>successfully authenticates the reply to GETATTR, and the GETATTR <lb/>request and reply containing the fs_locations or fs_locations_info <lb/>attribute refers to the second server, then the equality of server <lb/>scope is supported. A client may choose to limit the use of this <lb/>form of support to information relevant to the specific file <lb/>system involved (e.g. a file system being migrated). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 45] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.10.5. Trunking <lb/>Trunking is the use of multiple connections between a client and <lb/>server in order to increase the speed of data transfer. NFSv4.1 <lb/>supports two types of trunking: session trunking and client ID <lb/>trunking. <lb/>In the context of a single server network address, it can be assumed <lb/>that all connections are accessing the same server and NFSv4.1 <lb/>servers MUST support both forms of trunking. When multiple <lb/>connections use a set of network addresses accessing the same server, <lb/>the server MUST support both forms of trunking. NFSv4.1 servers in a <lb/>clustered configuration MAY allow network addresses for different <lb/>servers to use client ID trunking. <lb/>Clients may use either form of trunking as long as they do not, when <lb/>trunking between different server network addresses, violate the <lb/>servers&apos; mandates as to the kinds of trunking to be allowed (see <lb/>below). With regard to callback channels, the client MUST allow the <lb/>server to choose among all callback channels valid for a given client <lb/>ID and MUST support trunking when the connections supporting the <lb/>backchannel allow session or client ID trunking to be used for <lb/>callbacks. <lb/>Session trunking is essentially the association of multiple <lb/>connections, each with potentially different target and/or source <lb/>network addresses, to the same session. When the target network <lb/>addresses (server addresses) of the two connections are the same, the <lb/>server MUST support such session trunking. When the target network <lb/>addresses are different, the server MAY indicate such support using <lb/>the data returned by the EXCHANGE_ID operation (see below). <lb/>Client ID trunking is the association of multiple sessions to the <lb/>same client ID. Servers MUST support client ID trunking for two <lb/>target network addresses whenever they allow session trunking for <lb/>those same two network addresses. In addition, a server MAY, by <lb/>presenting the same major server owner ID (Section 2.5) and server <lb/>scope (Section 2.10.4), allow an additional case of client ID <lb/>trunking. When two servers return the same major server owner and <lb/>server scope, it means that the two servers are cooperating on <lb/>locking state management, which is a prerequisite for client ID <lb/>trunking. <lb/>Distinguishing when the client is allowed to use session and client <lb/>ID trunking requires understanding how the results of the EXCHANGE_ID <lb/>(Section 18.35) operation identify a server. Suppose a client sends <lb/>EXCHANGE_IDs over two different connections, each with a possibly <lb/>different target network address, but each EXCHANGE_ID operation has <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 46] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the same value in the eia_clientowner field. If the same NFSv4.1 <lb/>server is listening over each connection, then each EXCHANGE_ID <lb/>result MUST return the same values of eir_clientid, <lb/>eir_server_owner.so_major_id, and eir_server_scope. The client can <lb/>then treat each connection as referring to the same server (subject <lb/>to verification; see Section 2.10.5.1 below), and it can use each <lb/>connection to trunk requests and replies. The client&apos;s choice is <lb/>whether session trunking or client ID trunking applies. <lb/>Session Trunking. If the eia_clientowner argument is the same in two <lb/>different EXCHANGE_ID requests, and the eir_clientid, <lb/>eir_server_owner.so_major_id, eir_server_owner.so_minor_id, and <lb/>eir_server_scope results match in both EXCHANGE_ID results, then <lb/>the client is permitted to perform session trunking. If the <lb/>client has no session mapping to the tuple of eir_clientid, <lb/>eir_server_owner.so_major_id, eir_server_scope, and <lb/>eir_server_owner.so_minor_id, then it creates the session via a <lb/>CREATE_SESSION operation over one of the connections, which <lb/>associates the connection to the session. If there is a session <lb/>for the tuple, the client can send BIND_CONN_TO_SESSION to <lb/>associate the connection to the session. <lb/>Of course, if the client does not desire to use session trunking, <lb/>it is not required to do so. It can invoke CREATE_SESSION on the <lb/>connection. This will result in client ID trunking as described <lb/>below. It can also decide to drop the connection if it does not <lb/>choose to use trunking. <lb/>Client ID Trunking. If the eia_clientowner argument is the same in <lb/>two different EXCHANGE_ID requests, and the eir_clientid, <lb/>eir_server_owner.so_major_id, and eir_server_scope results match <lb/>in both EXCHANGE_ID results, then the client is permitted to <lb/>perform client ID trunking (regardless of whether the <lb/>eir_server_owner.so_minor_id results match). The client can <lb/>associate each connection with different sessions, where each <lb/>session is associated with the same server. <lb/>The client completes the act of client ID trunking by invoking <lb/>CREATE_SESSION on each connection, using the same client ID that <lb/>was returned in eir_clientid. These invocations create two <lb/>sessions and also associate each connection with its respective <lb/>session. The client is free to decline to use client ID trunking <lb/>by simply dropping the connection at this point. <lb/>When doing client ID trunking, locking state is shared across <lb/>sessions associated with that same client ID. This requires the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 47] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>server to coordinate state across sessions and the client to be <lb/>able to associate the same locking state with multiple sessions. <lb/>It is always possible that, as a result of various sorts of <lb/>reconfiguration events, eir_server_scope and eir_server_owner values <lb/>may be different on subsequent EXCHANGE_ID requests made to the same <lb/>network address. <lb/>In most cases such reconfiguration events will be disruptive and <lb/>indicate that an IP address formerly connected to one server is now <lb/>connected to an entirely different one. <lb/>Some guidelines on client handling of such situations follow: <lb/>o When eir_server_scope changes, the client has no assurance that <lb/>any id&apos;s it obtained previously (e.g. file handles, state ids, <lb/>client ids) can be validly used on the new server, and, even if <lb/>the new server accepts them, there is no assurance that this is <lb/>not due to accident. Thus, it is best to treat all such state as <lb/>lost/stale although a client may assume that the probability of <lb/>inadvertent acceptance is low and treat this situation as within <lb/>the next case. <lb/>o When eir_server_scope remains the same and <lb/>eir_server_owner.so_major_id changes, the client can use the <lb/>filehandles it has, consider its locking state lost, and attempt <lb/>to reclaim or otherwise re-obtain its locks. It may find that its <lb/>file handle IS now stale but if NFS4ERR_STALE is not received, it <lb/>can proceed to reclaim or otherwise re-obtain its open locking <lb/>state. <lb/>o When eir_server_scope and eir_server_owner.so_major_id remain the <lb/>same, the client has to use the now-current values of <lb/>eir_server_owner.so_minor_id in deciding on appropriate forms of <lb/>trunking. This may result in connections being dropped or new <lb/>sessions being created. <lb/>2.10.5.1. Verifying Claims of Matching Server Identity <lb/>When the server responds using two different connections claim <lb/>matching or partially matching eir_server_owner, eir_server_scope, <lb/>and eir_clientid values, the client does not have to trust the <lb/>servers&apos; claims. The client may verify these claims before trunking <lb/>traffic in the following ways: <lb/>o For session trunking, clients SHOULD reliably verify if <lb/>connections between different network paths are in fact associated <lb/>with the same NFSv4.1 server and usable on the same session, and <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 48] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>servers MUST allow clients to perform reliable verification. When <lb/>a client ID is created, the client SHOULD specify that <lb/>BIND_CONN_TO_SESSION is to be verified according to the SP4_SSV or <lb/>SP4_MACH_CRED (Section 18.35) state protection options. For <lb/>SP4_SSV, reliable verification depends on a shared secret (the <lb/>SSV) that is established via the SET_SSV (see Section 18.47) <lb/>operation. <lb/>When a new connection is associated with the session (via the <lb/>BIND_CONN_TO_SESSION operation, see Section 18.34), if the client <lb/>specified SP4_SSV state protection for the BIND_CONN_TO_SESSION <lb/>operation, the client MUST send the BIND_CONN_TO_SESSION with <lb/>RPCSEC_GSS protection, using integrity or privacy, and an <lb/>RPCSEC_GSS handle created with the GSS SSV mechanism (see <lb/>Section 2.10.9). <lb/>If the client mistakenly tries to associate a connection to a <lb/>session of a wrong server, the server will either reject the <lb/>attempt because it is not aware of the session identifier of the <lb/>BIND_CONN_TO_SESSION arguments, or it will reject the attempt <lb/>because the RPCSEC_GSS authentication fails. Even if the server <lb/>mistakenly or maliciously accepts the connection association <lb/>attempt, the RPCSEC_GSS verifier it computes in the response will <lb/>not be verified by the client, so the client will know it cannot <lb/>use the connection for trunking the specified session. <lb/>If the client specified SP4_MACH_CRED state protection, the <lb/>BIND_CONN_TO_SESSION operation will use RPCSEC_GSS integrity or <lb/>privacy, using the same credential that was used when the client <lb/>ID was created. Mutual authentication via RPCSEC_GSS assures the <lb/>client that the connection is associated with the correct session <lb/>of the correct server. <lb/>o For client ID trunking, the client has at least two options for <lb/>verifying that the same client ID obtained from two different <lb/>EXCHANGE_ID operations came from the same server. The first <lb/>option is to use RPCSEC_GSS authentication when sending each <lb/>EXCHANGE_ID operation. Each time an EXCHANGE_ID is sent with <lb/>RPCSEC_GSS authentication, the client notes the principal name of <lb/>the GSS target. If the EXCHANGE_ID results indicate that client <lb/>ID trunking is possible, and the GSS targets&apos; principal names are <lb/>the same, the servers are the same and client ID trunking is <lb/>allowed. <lb/>The second option for verification is to use SP4_SSV protection. <lb/>When the client sends EXCHANGE_ID, it specifies SP4_SSV <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 49] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>protection. The first EXCHANGE_ID the client sends always has to <lb/>be confirmed by a CREATE_SESSION call. The client then sends <lb/>SET_SSV. Later, the client sends EXCHANGE_ID to a second <lb/>destination network address different from the one the first <lb/>EXCHANGE_ID was sent to. The client checks that each EXCHANGE_ID <lb/>reply has the same eir_clientid, eir_server_owner.so_major_id, and <lb/>eir_server_scope. If so, the client verifies the claim by sending <lb/>a CREATE_SESSION operation to the second destination address, <lb/>protected with RPCSEC_GSS integrity using an RPCSEC_GSS handle <lb/>returned by the second EXCHANGE_ID. If the server accepts the <lb/>CREATE_SESSION request, and if the client verifies the RPCSEC_GSS <lb/>verifier and integrity codes, then the client has proof the second <lb/>server knows the SSV, and thus the two servers are cooperating for <lb/>the purposes of specifying server scope and client ID trunking. <lb/>2.10.6. Exactly Once Semantics <lb/>Via the session, NFSv4.1 offers exactly once semantics (EOS) for <lb/>requests sent over a channel. EOS is supported on both the fore <lb/>channel and backchannel. <lb/>Each COMPOUND or CB_COMPOUND request that is sent with a leading <lb/>SEQUENCE or CB_SEQUENCE operation MUST be executed by the receiver <lb/>exactly once. This requirement holds regardless of whether the <lb/>request is sent with reply caching specified (see <lb/>Section 2.10.6.1.3). The requirement holds even if the requester is <lb/>sending the request over a session created between a pNFS data client <lb/>and pNFS data server. To understand the rationale for this <lb/>requirement, divide the requests into three classifications: <lb/>o Non-idempotent requests. <lb/>o Idempotent modifying requests. <lb/>o Idempotent non-modifying requests. <lb/>An example of a non-idempotent request is RENAME. Obviously, if a <lb/>replier executes the same RENAME request twice, and the first <lb/>execution succeeds, the re-execution will fail. If the replier <lb/>returns the result from the re-execution, this result is incorrect. <lb/>Therefore, EOS is required for non-idempotent requests. <lb/>An example of an idempotent modifying request is a COMPOUND request <lb/>containing a WRITE operation. Repeated execution of the same WRITE <lb/>has the same effect as execution of that WRITE a single time. <lb/>Nevertheless, enforcing EOS for WRITEs and other idempotent modifying <lb/>requests is necessary to avoid data corruption. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 50] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Suppose a client sends WRITE A to a noncompliant server that does not <lb/>enforce EOS, and receives no response, perhaps due to a network <lb/>partition. The client reconnects to the server and re-sends WRITE A. <lb/>Now, the server has outstanding two instances of A. The server can <lb/>be in a situation in which it executes and replies to the retry of A, <lb/>while the first A is still waiting in the server&apos;s internal I/O <lb/>system for some resource. Upon receiving the reply to the second <lb/>attempt of WRITE A, the client believes its WRITE is done so it is <lb/>free to send WRITE B, which overlaps the byte-range of A. When the <lb/>original A is dispatched from the server&apos;s I/O system and executed <lb/>(thus the second time A will have been written), then what has been <lb/>written by B can be overwritten and thus corrupted. <lb/>An example of an idempotent non-modifying request is a COMPOUND <lb/>containing SEQUENCE, PUTFH, READLINK, and nothing else. The re-<lb/>execution of such a request will not cause data corruption or produce <lb/>an incorrect result. Nonetheless, to keep the implementation simple, <lb/>the replier MUST enforce EOS for all requests, whether or not <lb/>idempotent and non-modifying. <lb/>Note that true and complete EOS is not possible unless the server <lb/>persists the reply cache in stable storage, and unless the server is <lb/>somehow implemented to never require a restart (indeed, if such a <lb/>server exists, the distinction between a reply cache kept in stable <lb/>storage versus one that is not is one without meaning). See <lb/>Section 2.10.6.5 for a discussion of persistence in the reply cache. <lb/>Regardless, even if the server does not persist the reply cache, EOS <lb/>improves robustness and correctness over previous versions of NFS <lb/>because the legacy duplicate request/reply caches were based on the <lb/>ONC RPC transaction identifier (XID). Section 2.10.6.1 explains the <lb/>shortcomings of the XID as a basis for a reply cache and describes <lb/>how NFSv4.1 sessions improve upon the XID. <lb/>2.10.6.1. Slot Identifiers and Reply Cache <lb/>The RPC layer provides a transaction ID (XID), which, while required <lb/>to be unique, is not convenient for tracking requests for two <lb/>reasons. First, the XID is only meaningful to the requester; it <lb/>cannot be interpreted by the replier except to test for equality with <lb/>previously sent requests. When consulting an RPC-based duplicate <lb/>request cache, the opaqueness of the XID requires a computationally <lb/>expensive look up (often via a hash that includes XID and source <lb/>address). NFSv4.1 requests use a non-opaque slot ID, which is an <lb/>index into a slot table, which is far more efficient. Second, <lb/>because RPC requests can be executed by the replier in any order, <lb/>there is no bound on the number of requests that may be outstanding <lb/>at any time. To achieve perfect EOS, using ONC RPC would require <lb/>storing all replies in the reply cache. XIDs are 32 bits; storing <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 51] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>over four billion (2^32) replies in the reply cache is not practical. <lb/>In practice, previous versions of NFS have chosen to store a fixed <lb/>number of replies in the cache, and to use a least recently used <lb/>(LRU) approach to replacing cache entries with new entries when the <lb/>cache is full. In NFSv4.1, the number of outstanding requests is <lb/>bounded by the size of the slot table, and a sequence ID per slot is <lb/>used to tell the replier when it is safe to delete a cached reply. <lb/>In the NFSv4.1 reply cache, when the requester sends a new request, <lb/>it selects a slot ID in the range 0..N, where N is the replier&apos;s <lb/>current maximum slot ID granted to the requester on the session over <lb/>which the request is to be sent. The value of N starts out as equal <lb/>to ca_maxrequests -1 (Section 18.36), but can be adjusted by the <lb/>response to SEQUENCE or CB_SEQUENCE as described later in this <lb/>section. The slot ID must be unused by any of the requests that the <lb/>requester has already active on the session. &quot;Unused&quot; here means the <lb/>requester has no outstanding request for that slot ID. <lb/>A slot contains a sequence ID and the cached reply corresponding to <lb/>the request sent with that sequence ID. The sequence ID is a 32-bit <lb/>unsigned value, and is therefore in the range 0..0xFFFFFFFF (2^32 -<lb/>1). The first time a slot is used, the requester MUST specify a <lb/>sequence ID of one (Section 18.36). Each time a slot is reused, the <lb/>request MUST specify a sequence ID that is one greater than that of <lb/>the previous request on the slot. If the previous sequence ID was <lb/>0xFFFFFFFF, then the next request for the slot MUST have the sequence <lb/>ID set to zero (i.e., (2^32 -1) + 1 mod 2^32). <lb/>The sequence ID accompanies the slot ID in each request. It is for <lb/>the critical check at the replier: it used to efficiently determine <lb/>whether a request using a certain slot ID is a retransmit or a new, <lb/>never-before-seen request. It is not feasible for the requester to <lb/>assert that it is retransmitting to implement this, because for any <lb/>given request the requester cannot know whether the replier has seen <lb/>it unless the replier actually replies. Of course, if the requester <lb/>has seen the reply, the requester would not retransmit. <lb/>The replier compares each received request&apos;s sequence ID with the <lb/>last one previously received for that slot ID, to see if the new <lb/>request is: <lb/>o A new request, in which the sequence ID is one greater than that <lb/>previously seen in the slot (accounting for sequence wraparound). <lb/>The replier proceeds to execute the new request, and the replier <lb/>MUST increase the slot&apos;s sequence ID by one. <lb/>o A retransmitted request, in which the sequence ID is equal to that <lb/>currently recorded in the slot. If the original request has <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 52] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>executed to completion, the replier returns the cached reply. See <lb/>Section 2.10.6.2 for direction on how the replier deals with <lb/>retries of requests that are still in progress. <lb/>o A misordered retry, in which the sequence ID is less than <lb/>(accounting for sequence wraparound) that previously seen in the <lb/>slot. The replier MUST return NFS4ERR_SEQ_MISORDERED (as the <lb/>result from SEQUENCE or CB_SEQUENCE). <lb/>o A misordered new request, in which the sequence ID is two or more <lb/>than (accounting for sequence wraparound) that previously seen in <lb/>the slot. Note that because the sequence ID MUST wrap around to <lb/>zero once it reaches 0xFFFFFFFF, a misordered new request and a <lb/>misordered retry cannot be distinguished. Thus, the replier MUST <lb/>return NFS4ERR_SEQ_MISORDERED (as the result from SEQUENCE or <lb/>CB_SEQUENCE). <lb/>Unlike the XID, the slot ID is always within a specific range; this <lb/>has two implications. The first implication is that for a given <lb/>session, the replier need only cache the results of a limited number <lb/>of COMPOUND requests. The second implication derives from the first, <lb/>which is that unlike XID-indexed reply caches (also known as <lb/>duplicate request caches -DRCs), the slot ID-based reply cache <lb/>cannot be overflowed. Through use of the sequence ID to identify <lb/>retransmitted requests, the replier does not need to actually cache <lb/>the request itself, reducing the storage requirements of the reply <lb/>cache further. These facilities make it practical to maintain all <lb/>the required entries for an effective reply cache. <lb/>The slot ID, sequence ID, and session ID therefore take over the <lb/>traditional role of the XID and source network address in the <lb/>replier&apos;s reply cache implementation. This approach is considerably <lb/>more portable and completely robust --it is not subject to the <lb/>reassignment of ports as clients reconnect over IP networks. In <lb/>addition, the RPC XID is not used in the reply cache, enhancing <lb/>robustness of the cache in the face of any rapid reuse of XIDs by the <lb/>requester. While the replier does not care about the XID for the <lb/>purposes of reply cache management (but the replier MUST return the <lb/>same XID that was in the request), nonetheless there are <lb/>considerations for the XID in NFSv4.1 that are the same as all other <lb/>previous versions of NFS. The RPC XID remains in each message and <lb/>needs to be formulated in NFSv4.1 requests as in any other ONC RPC <lb/>request. The reasons include: <lb/>o The RPC layer retains its existing semantics and implementation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 53] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o The requester and replier must be able to interoperate at the RPC <lb/>layer, prior to the NFSv4.1 decoding of the SEQUENCE or <lb/>CB_SEQUENCE operation. <lb/>o If an operation is being used that does not start with SEQUENCE or <lb/>CB_SEQUENCE (e.g., BIND_CONN_TO_SESSION), then the RPC XID is <lb/>needed for correct operation to match the reply to the request. <lb/>o The SEQUENCE or CB_SEQUENCE operation may generate an error. If <lb/>so, the embedded slot ID, sequence ID, and session ID (if present) <lb/>in the request will not be in the reply, and the requester has <lb/>only the XID to match the reply to the request. <lb/>Given that well-formulated XIDs continue to be required, this begs <lb/>the question: why do SEQUENCE and CB_SEQUENCE replies have a session <lb/>ID, slot ID, and sequence ID? Having the session ID in the reply <lb/>means that the requester does not have to use the XID to look up the <lb/>session ID, which would be necessary if the connection were <lb/>associated with multiple sessions. Having the slot ID and sequence <lb/>ID in the reply means that the requester does not have to use the XID <lb/>to look up the slot ID and sequence ID. Furthermore, since the XID <lb/>is only 32 bits, it is too small to guarantee the re-association of a <lb/>reply with its request [40]; having session ID, slot ID, and sequence <lb/>ID in the reply allows the client to validate that the reply in fact <lb/>belongs to the matched request. <lb/>The SEQUENCE (and CB_SEQUENCE) operation also carries a <lb/>&quot;highest_slotid&quot; value, which carries additional requester slot usage <lb/>information. The requester MUST always indicate the slot ID <lb/>representing the outstanding request with the highest-numbered slot <lb/>value. The requester should in all cases provide the most <lb/>conservative value possible, although it can be increased somewhat <lb/>above the actual instantaneous usage to maintain some minimum or <lb/>optimal level. This provides a way for the requester to yield unused <lb/>request slots back to the replier, which in turn can use the <lb/>information to reallocate resources. <lb/>The replier responds with both a new target highest_slotid and an <lb/>enforced highest_slotid, described as follows: <lb/>o The target highest_slotid is an indication to the requester of the <lb/>highest_slotid the replier wishes the requester to be using. This <lb/>permits the replier to withdraw (or add) resources from a <lb/>requester that has been found to not be using them, in order to <lb/>more fairly share resources among a varying level of demand from <lb/>other requesters. The requester must always comply with the <lb/>replier&apos;s value updates, since they indicate newly established <lb/>hard limits on the requester&apos;s access to session resources. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 54] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>However, because of request pipelining, the requester may have <lb/>active requests in flight reflecting prior values; therefore, the <lb/>replier must not immediately require the requester to comply. <lb/>o The enforced highest_slotid indicates the highest slot ID the <lb/>requester is permitted to use on a subsequent SEQUENCE or <lb/>CB_SEQUENCE operation. The replier&apos;s enforced highest_slotid <lb/>SHOULD be no less than the highest_slotid the requester indicated <lb/>in the SEQUENCE or CB_SEQUENCE arguments. <lb/>A requester can be intransigent with respect to lowering its <lb/>highest_slotid argument to a Sequence operation, i.e. the <lb/>requester continues to ignore the target highest_slotid in the <lb/>response to a Sequence operation, and continues to set its <lb/>highest_slotid argument to be higher than the target <lb/>highest_slotid. This can be considered particularly egregious <lb/>behavior when the replier knows there are no outstanding requests <lb/>with slot IDs higher than its target highest_slotid. When faced <lb/>with such intransigence, the replier is free to take more forceful <lb/>action, and MAY reply with a new enforced highest_slotid that is <lb/>less than its previous enforced highest_slotid. Thereafter, if <lb/>the requester continues to send requests with a highest_slotid <lb/>that is greater than the replier&apos;s new enforced highest_slotid, <lb/>the server MAY return NFS4ERR_BAD_HIGH_SLOT, unless the slot ID in <lb/>the request is greater than the new enforced highest_slotid and <lb/>the request is a retry. <lb/>The replier SHOULD retain the slots it wants to retire until the <lb/>requester sends a request with a highest_slotid less than or equal <lb/>to the replier&apos;s new enforced highest_slotid. <lb/>The requester can also be intransigent with respect to sending <lb/>non-retry requests that have a slot ID that exceeds the replier&apos;s <lb/>highest_slotid. Once the replier has forcibly lowered the <lb/>enforced highest_slotid, the requester is only allowed to send <lb/>retries on slots that exceed the replier&apos;s highest_slotid. If a <lb/>request is received with a slot ID that is higher than the new <lb/>enforced highest_slotid, and the sequence ID is one higher than <lb/>what is in the slot&apos;s reply cache, then the server can both retire <lb/>the slot and return NFS4ERR_BADSLOT (however, the server MUST NOT <lb/>do one and not the other). The reason it is safe to retire the <lb/>slot is because by using the next sequence ID, the requester is <lb/>indicating it has received the previous reply for the slot. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 55] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o The requester SHOULD use the lowest available slot when sending a <lb/>new request. This way, the replier may be able to retire slot <lb/>entries faster. However, where the replier is actively adjusting <lb/>its granted highest_slotid, it will not be able to use only the <lb/>receipt of the slot ID and highest_slotid in the request. Neither <lb/>the slot ID nor the highest_slotid used in a request may reflect <lb/>the replier&apos;s current idea of the requester&apos;s session limit, <lb/>because the request may have been sent from the requester before <lb/>the update was received. Therefore, in the downward adjustment <lb/>case, the replier may have to retain a number of reply cache <lb/>entries at least as large as the old value of maximum requests <lb/>outstanding, until it can infer that the requester has seen a <lb/>reply containing the new granted highest_slotid. The replier can <lb/>infer that the requester has seen such a reply when it receives a <lb/>new request with the same slot ID as the request replied to and <lb/>the next higher sequence ID. <lb/>2.10.6.1.1. Caching of SEQUENCE and CB_SEQUENCE Replies <lb/>When a SEQUENCE or CB_SEQUENCE operation is successfully executed, <lb/>its reply MUST always be cached. Specifically, session ID, sequence <lb/>ID, and slot ID MUST be cached in the reply cache. The reply from <lb/>SEQUENCE also includes the highest slot ID, target highest slot ID, <lb/>and status flags. Instead of caching these values, the server MAY <lb/>re-compute the values from the current state of the fore channel, <lb/>session, and/or client ID as appropriate. Similarly, the reply from <lb/>CB_SEQUENCE includes a highest slot ID and target highest slot ID. <lb/>The client MAY re-compute the values from the current state of the <lb/>session as appropriate. <lb/>Regardless of whether or not a replier is re-computing highest slot <lb/>ID, target slot ID, and status on replies to retries, the requester <lb/>MUST NOT assume that the values are being re-computed whenever it <lb/>receives a reply after a retry is sent, since it has no way of <lb/>knowing whether the reply it has received was sent by the replier in <lb/>response to the retry or is a delayed response to the original <lb/>request. Therefore, it may be the case that highest slot ID, target <lb/>slot ID, or status bits may reflect the state of affairs when the <lb/>request was first executed. Although acting based on such delayed <lb/>information is valid, it may cause the receiver of the reply to do <lb/>unneeded work. Requesters MAY choose to send additional requests to <lb/>get the current state of affairs or use the state of affairs reported <lb/>by subsequent requests, in preference to acting immediately on data <lb/>that might be out of date. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 56] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.10.6.1.2. Errors from SEQUENCE and CB_SEQUENCE <lb/>Any time SEQUENCE or CB_SEQUENCE returns an error, the sequence ID of <lb/>the slot MUST NOT change. The replier MUST NOT modify the reply <lb/>cache entry for the slot whenever an error is returned from SEQUENCE <lb/>or CB_SEQUENCE. <lb/>2.10.6.1.3. Optional Reply Caching <lb/>On a per-request basis, the requester can choose to direct the <lb/>replier to cache the reply to all operations after the first <lb/>operation (SEQUENCE or CB_SEQUENCE) via the sa_cachethis or <lb/>csa_cachethis fields of the arguments to SEQUENCE or CB_SEQUENCE. <lb/>The reason it would not direct the replier to cache the entire reply <lb/>is that the request is composed of all idempotent operations [37]. <lb/>Caching the reply may offer little benefit. If the reply is too <lb/>large (see Section 2.10.6.4), it may not be cacheable anyway. Even <lb/>if the reply to idempotent request is small enough to cache, <lb/>unnecessarily caching the reply slows down the server and increases <lb/>RPC latency. <lb/>Whether or not the requester requests the reply to be cached has no <lb/>effect on the slot processing. If the results of SEQUENCE or <lb/>CB_SEQUENCE are NFS4_OK, then the slot&apos;s sequence ID MUST be <lb/>incremented by one. If a requester does not direct the replier to <lb/>cache the reply, the replier MUST do one of following: <lb/>o The replier can cache the entire original reply. Even though <lb/>sa_cachethis or csa_cachethis is FALSE, the replier is always free <lb/>to cache. It may choose this approach in order to simplify <lb/>implementation. <lb/>o The replier enters into its reply cache a reply consisting of the <lb/>original results to the SEQUENCE or CB_SEQUENCE operation, and <lb/>with the next operation in COMPOUND or CB_COMPOUND having the <lb/>error NFS4ERR_RETRY_UNCACHED_REP. Thus, if the requester later <lb/>retries the request, it will get NFS4ERR_RETRY_UNCACHED_REP. If a <lb/>replier receives a retried Sequence operation where the reply to <lb/>the COMPOUND or CB_COMPOUND was not cached, then the replier, <lb/>* MAY return NFS4ERR_RETRY_UNCACHED_REP in reply to a Sequence <lb/>operation if the Sequence operation is not the first operation <lb/>(granted, a requester that does so is in violation of the <lb/>NFSv4.1 protocol). <lb/>* MUST NOT return NFS4ERR_RETRY_UNCACHED_REP in reply to a <lb/>Sequence operation if the Sequence operation is the first <lb/>operation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 57] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o If the second operation is an illegal operation, or an operation <lb/>that was legal in a previous minor version of NFSv4 and MUST NOT <lb/>be supported in the current minor version (e.g., SETCLIENTID), the <lb/>replier MUST NOT ever return NFS4ERR_RETRY_UNCACHED_REP. Instead <lb/>the replier MUST return NFS4ERR_OP_ILLEGAL or NFS4ERR_BADXDR or <lb/>NFS4ERR_NOTSUPP as appropriate. <lb/>o If the second operation can result in another error status, the <lb/>replier MAY return a status other than NFS4ERR_RETRY_UNCACHED_REP, <lb/>provided the operation is not executed in such a way that the <lb/>state of the replier is changed. Examples of such an error status <lb/>include: NFS4ERR_NOTSUPP returned for an operation that is legal <lb/>but not REQUIRED in the current minor versions, and thus not <lb/>supported by the replier; NFS4ERR_SEQUENCE_POS; and <lb/>NFS4ERR_REQ_TOO_BIG. <lb/>The discussion above assumes that the retried request matches the <lb/>original one. Section 2.10.6.1.3.1 discusses what the replier might <lb/>do, and MUST do when original and retried requests do not match. <lb/>Since the replier may only cache a small amount of the information <lb/>that would be required to determine whether this is a case of a false <lb/>retry, the replier may send to the client any of the following <lb/>responses: <lb/>o The cached reply to the original request (if the replier has <lb/>cached it in its entirety and the users of the original request <lb/>and retry match). <lb/>o A reply that consists only of the Sequence operation with the <lb/>error NFS4ERR_FALSE_RETRY. <lb/>o A reply consisting of the response to Sequence with the status <lb/>NFS4_OK, together with the second operation as it appeared in the <lb/>retried request with an error of NFS4ERR_RETRY_UNCACHED_REP or <lb/>other error as described above. <lb/>o A reply that consists of the response to Sequence with the status <lb/>NFS4_OK, together with the second operation as it appeared in the <lb/>original request with an error of NFS4ERR_RETRY_UNCACHED_REP or <lb/>other error as described above. <lb/>2.10.6.1.3.1. False Retry <lb/>If a requester sent a Sequence operation with a slot ID and sequence <lb/>ID that are in the reply cache but the replier detected that the <lb/>retried request is not the same as the original request, including a <lb/>retry that has different operations or different arguments in the <lb/>operations from the original and a retry that uses a different <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 58] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>principal in the RPC request&apos;s credential field that translates to a <lb/>different user, then this is a false retry. When the replier detects <lb/>a false retry, it is permitted (but not always obligated) to return <lb/>NFS4ERR_FALSE_RETRY in response to the Sequence operation when it <lb/>detects a false retry. <lb/>Translations of particularly privileged user values to other users <lb/>due to the lack of appropriately secure credentials, as configured on <lb/>the replier, should be applied before determining whether the users <lb/>are the same or different. If the replier determines the users are <lb/>different between the original request and a retry, then the replier <lb/>MUST return NFS4ERR_FALSE_RETRY. <lb/>If an operation of the retry is an illegal operation, or an operation <lb/>that was legal in a previous minor version of NFSv4 and MUST NOT be <lb/>supported in the current minor version (e.g., SETCLIENTID), the <lb/>replier MAY return NFS4ERR_FALSE_RETRY (and MUST do so if the users <lb/>of the original request and retry differ). Otherwise, the replier <lb/>MAY return NFS4ERR_OP_ILLEGAL or NFS4ERR_BADXDR or NFS4ERR_NOTSUPP as <lb/>appropriate. Note that the handling is in contrast for how the <lb/>replier deals with retries requests with no cached reply. The <lb/>difference is due to NFS4ERR_FALSE_RETRY being a valid error for only <lb/>Sequence operations, whereas NFS4ERR_RETRY_UNCACHED_REP is a valid <lb/>error for all operations except illegal operations and operations <lb/>that MUST NOT be supported in the current minor version of NFSv4. <lb/>2.10.6.2. Retry and Replay of Reply <lb/>A requester MUST NOT retry a request, unless the connection it used <lb/>to send the request disconnects. The requester can then reconnect <lb/>and re-send the request, or it can re-send the request over a <lb/>different connection that is associated with the same session. <lb/>If the requester is a server wanting to re-send a callback operation <lb/>over the backchannel of a session, the requester of course cannot <lb/>reconnect because only the client can associate connections with the <lb/>backchannel. The server can re-send the request over another <lb/>connection that is bound to the same session&apos;s backchannel. If there <lb/>is no such connection, the server MUST indicate that the session has <lb/>no backchannel by setting the SEQ4_STATUS_CB_PATH_DOWN_SESSION flag <lb/>bit in the response to the next SEQUENCE operation from the client. <lb/>The client MUST then associate a connection with the session (or <lb/>destroy the session). <lb/>Note that it is not fatal for a requester to retry without a <lb/>disconnect between the request and retry. However, the retry does <lb/>consume resources, especially with RDMA, where each request, retry or <lb/>not, consumes a credit. Retries for no reason, especially retries <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 59] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>sent shortly after the previous attempt, are a poor use of network <lb/>bandwidth and defeat the purpose of a transport&apos;s inherent congestion <lb/>control system. <lb/>A requester MUST wait for a reply to a request before using the slot <lb/>for another request. If it does not wait for a reply, then the <lb/>requester does not know what sequence ID to use for the slot on its <lb/>next request. For example, suppose a requester sends a request with <lb/>sequence ID 1, and does not wait for the response. The next time it <lb/>uses the slot, it sends the new request with sequence ID 2. If the <lb/>replier has not seen the request with sequence ID 1, then the replier <lb/>is not expecting sequence ID 2, and rejects the requester&apos;s new <lb/>request with NFS4ERR_SEQ_MISORDERED (as the result from SEQUENCE or <lb/>CB_SEQUENCE). <lb/>RDMA fabrics do not guarantee that the memory handles (Steering Tags) <lb/>within each RPC/RDMA &quot;chunk&quot; [31] are valid on a scope outside that <lb/>of a single connection. Therefore, handles used by the direct <lb/>operations become invalid after connection loss. The server must <lb/>ensure that any RDMA operations that must be replayed from the reply <lb/>cache use the newly provided handle(s) from the most recent request. <lb/>A retry might be sent while the original request is still in progress <lb/>on the replier. The replier SHOULD deal with the issue by returning <lb/>NFS4ERR_DELAY as the reply to SEQUENCE or CB_SEQUENCE operation, but <lb/>implementations MAY return NFS4ERR_MISORDERED. Since errors from <lb/>SEQUENCE and CB_SEQUENCE are never recorded in the reply cache, this <lb/>approach allows the results of the execution of the original request <lb/>to be properly recorded in the reply cache (assuming that the <lb/>requester specified the reply to be cached). <lb/>2.10.6.3. Resolving Server Callback Races <lb/>It is possible for server callbacks to arrive at the client before <lb/>the reply from related fore channel operations. For example, a <lb/>client may have been granted a delegation to a file it has opened, <lb/>but the reply to the OPEN (informing the client of the granting of <lb/>the delegation) may be delayed in the network. If a conflicting <lb/>operation arrives at the server, it will recall the delegation using <lb/>the backchannel, which may be on a different transport connection, <lb/>perhaps even a different network, or even a different session <lb/>associated with the same client ID. <lb/>The presence of a session between the client and server alleviates <lb/>this issue. When a session is in place, each client request is <lb/>uniquely identified by its { session ID, slot ID, sequence ID } <lb/>triple. By the rules under which slot entries (reply cache entries) <lb/>are retired, the server has knowledge whether the client has &quot;seen&quot; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 60] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>each of the server&apos;s replies. The server can therefore provide <lb/>sufficient information to the client to allow it to disambiguate <lb/>between an erroneous or conflicting callback race condition. <lb/>For each client operation that might result in some sort of server <lb/>callback, the server SHOULD &quot;remember&quot; the { session ID, slot ID, <lb/>sequence ID } triple of the client request until the slot ID <lb/>retirement rules allow the server to determine that the client has, <lb/>in fact, seen the server&apos;s reply. Until the time the { session ID, <lb/>slot ID, sequence ID } request triple can be retired, any recalls of <lb/>the associated object MUST carry an array of these referring <lb/>identifiers (in the CB_SEQUENCE operation&apos;s arguments), for the <lb/>benefit of the client. After this time, it is not necessary for the <lb/>server to provide this information in related callbacks, since it is <lb/>certain that a race condition can no longer occur. <lb/>The CB_SEQUENCE operation that begins each server callback carries a <lb/>list of &quot;referring&quot; { session ID, slot ID, sequence ID } triples. If <lb/>the client finds the request corresponding to the referring session <lb/>ID, slot ID, and sequence ID to be currently outstanding (i.e., the <lb/>server&apos;s reply has not been seen by the client), it can determine <lb/>that the callback has raced the reply, and act accordingly. If the <lb/>client does not find the request corresponding to the referring <lb/>triple to be outstanding (including the case of a session ID <lb/>referring to a destroyed session), then there is no race with respect <lb/>to this triple. The server SHOULD limit the referring triples to <lb/>requests that refer to just those that apply to the objects referred <lb/>to in the CB_COMPOUND procedure. <lb/>The client must not simply wait forever for the expected server reply <lb/>to arrive before responding to the CB_COMPOUND that won the race, <lb/>because it is possible that it will be delayed indefinitely. The <lb/>client should assume the likely case that the reply will arrive <lb/>within the average round-trip time for COMPOUND requests to the <lb/>server, and wait that period of time. If that period of time <lb/>expires, it can respond to the CB_COMPOUND with NFS4ERR_DELAY. There <lb/>are other scenarios under which callbacks may race replies. Among <lb/>them are pNFS layout recalls as described in Section 12.5.5.2. <lb/>2.10.6.4. COMPOUND and CB_COMPOUND Construction Issues <lb/>Very large requests and replies may pose both buffer management <lb/>issues (especially with RDMA) and reply cache issues. When the <lb/>session is created (Section 18.36), for each channel (fore and back), <lb/>the client and server negotiate the maximum-sized request they will <lb/>send or process (ca_maxrequestsize), the maximum-sized reply they <lb/>will return or process (ca_maxresponsesize), and the maximum-sized <lb/>reply they will store in the reply cache (ca_maxresponsesize_cached). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 61] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If a request exceeds ca_maxrequestsize, the reply will have the <lb/>status NFS4ERR_REQ_TOO_BIG. A replier MAY return NFS4ERR_REQ_TOO_BIG <lb/>as the status for the first operation (SEQUENCE or CB_SEQUENCE) in <lb/>the request (which means that no operations in the request executed <lb/>and that the state of the slot in the reply cache is unchanged), or <lb/>it MAY opt to return it on a subsequent operation in the same <lb/>COMPOUND or CB_COMPOUND request (which means that at least one <lb/>operation did execute and that the state of the slot in the reply <lb/>cache does change). The replier SHOULD set NFS4ERR_REQ_TOO_BIG on <lb/>the operation that exceeds ca_maxrequestsize. <lb/>If a reply exceeds ca_maxresponsesize, the reply will have the status <lb/>NFS4ERR_REP_TOO_BIG. A replier MAY return NFS4ERR_REP_TOO_BIG as the <lb/>status for the first operation (SEQUENCE or CB_SEQUENCE) in the <lb/>request, or it MAY opt to return it on a subsequent operation (in the <lb/>same COMPOUND or CB_COMPOUND reply). A replier MAY return <lb/>NFS4ERR_REP_TOO_BIG in the reply to SEQUENCE or CB_SEQUENCE, even if <lb/>the response would still exceed ca_maxresponsesize. <lb/>If sa_cachethis or csa_cachethis is TRUE, then the replier MUST cache <lb/>a reply except if an error is returned by the SEQUENCE or CB_SEQUENCE <lb/>operation (see Section 2.10.6.1.2). If the reply exceeds <lb/>ca_maxresponsesize_cached (and sa_cachethis or csa_cachethis is <lb/>TRUE), then the server MUST return NFS4ERR_REP_TOO_BIG_TO_CACHE. <lb/>Even if NFS4ERR_REP_TOO_BIG_TO_CACHE (or any other error for that <lb/>matter) is returned on an operation other than the first operation <lb/>(SEQUENCE or CB_SEQUENCE), then the reply MUST be cached if <lb/>sa_cachethis or csa_cachethis is TRUE. For example, if a COMPOUND <lb/>has eleven operations, including SEQUENCE, the fifth operation is a <lb/>RENAME, and the tenth operation is a READ for one million bytes, the <lb/>server may return NFS4ERR_REP_TOO_BIG_TO_CACHE on the tenth <lb/>operation. Since the server executed several operations, especially <lb/>the non-idempotent RENAME, the client&apos;s request to cache the reply <lb/>needs to be honored in order for the correct operation of exactly <lb/>once semantics. If the client retries the request, the server will <lb/>have cached a reply that contains results for ten of the eleven <lb/>requested operations, with the tenth operation having a status of <lb/>NFS4ERR_REP_TOO_BIG_TO_CACHE. <lb/>A client needs to take care that when sending operations that change <lb/>the current filehandle (except for PUTFH, PUTPUBFH, PUTROOTFH, and <lb/>RESTOREFH), it not exceed the maximum reply buffer before the GETFH <lb/>operation. Otherwise, the client will have to retry the operation <lb/>that changed the current filehandle, in order to obtain the desired <lb/>filehandle. For the OPEN operation (see Section 18.16), retry is not <lb/>always available as an option. The following guidelines for the <lb/>handling of filehandle-changing operations are advised: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 62] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o Within the same COMPOUND procedure, a client SHOULD send GETFH <lb/>immediately after a current filehandle-changing operation. A <lb/>client MUST send GETFH after a current filehandle-changing <lb/>operation that is also non-idempotent (e.g., the OPEN operation), <lb/>unless the operation is RESTOREFH. RESTOREFH is an exception, <lb/>because even though it is non-idempotent, the filehandle RESTOREFH <lb/>produced originated from an operation that is either idempotent <lb/>(e.g., PUTFH, LOOKUP), or non-idempotent (e.g., OPEN, CREATE). If <lb/>the origin is non-idempotent, then because the client MUST send <lb/>GETFH after the origin operation, the client can recover if <lb/>RESTOREFH returns an error. <lb/>o A server MAY return NFS4ERR_REP_TOO_BIG or <lb/>NFS4ERR_REP_TOO_BIG_TO_CACHE (if sa_cachethis is TRUE) on a <lb/>filehandle-changing operation if the reply would be too large on <lb/>the next operation. <lb/>o A server SHOULD return NFS4ERR_REP_TOO_BIG or <lb/>NFS4ERR_REP_TOO_BIG_TO_CACHE (if sa_cachethis is TRUE) on a <lb/>filehandle-changing, non-idempotent operation if the reply would <lb/>be too large on the next operation, especially if the operation is <lb/>OPEN. <lb/>o A server MAY return NFS4ERR_UNSAFE_COMPOUND to a non-idempotent <lb/>current filehandle-changing operation, if it looks at the next <lb/>operation (in the same COMPOUND procedure) and finds it is not <lb/>GETFH. The server SHOULD do this if it is unable to determine in <lb/>advance whether the total response size would exceed <lb/>ca_maxresponsesize_cached or ca_maxresponsesize. <lb/>2.10.6.5. Persistence <lb/>Since the reply cache is bounded, it is practical for the reply cache <lb/>to persist across server restarts. The replier MUST persist the <lb/>following information if it agreed to persist the session (when the <lb/>session was created; see Section 18.36): <lb/>o The session ID. <lb/>o The slot table including the sequence ID and cached reply for each <lb/>slot. <lb/>The above are sufficient for a replier to provide EOS semantics for <lb/>any requests that were sent and executed before the server restarted. <lb/>If the replier is a client, then there is no need for it to persist <lb/>any more information, unless the client will be persisting all other <lb/>state across client restart, in which case, the server will never see <lb/>any NFSv4.1-level protocol manifestation of a client restart. If the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 63] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>replier is a server, with just the slot table and session ID <lb/>persisting, any requests the client retries after the server restart <lb/>will return the results that are cached in the reply cache, and any <lb/>new requests (i.e., the sequence ID is one greater than the slot&apos;s <lb/>sequence ID) MUST be rejected with NFS4ERR_DEADSESSION (returned by <lb/>SEQUENCE). Such a session is considered dead. A server MAY re-<lb/>animate a session after a server restart so that the session will <lb/>accept new requests as well as retries. To re-animate a session, the <lb/>server needs to persist additional information through server <lb/>restart: <lb/>o The client ID. This is a prerequisite to let the client create <lb/>more sessions associated with the same client ID as the re-<lb/>animated session. <lb/>o The client ID&apos;s sequence ID that is used for creating sessions <lb/>(see Sections 18.35 and 18.36). This is a prerequisite to let the <lb/>client create more sessions. <lb/>o The principal that created the client ID. This allows the server <lb/>to authenticate the client when it sends EXCHANGE_ID. <lb/>o The SSV, if SP4_SSV state protection was specified when the client <lb/>ID was created (see Section 18.35). This lets the client create <lb/>new sessions, and associate connections with the new and existing <lb/>sessions. <lb/>o The properties of the client ID as defined in Section 18.35. <lb/>A persistent reply cache places certain demands on the server. The <lb/>execution of the sequence of operations (starting with SEQUENCE) and <lb/>placement of its results in the persistent cache MUST be atomic. If <lb/>a client retries a sequence of operations that was previously <lb/>executed on the server, the only acceptable outcomes are either the <lb/>original cached reply or an indication that the client ID or session <lb/>has been lost (indicating a catastrophic loss of the reply cache or a <lb/>session that has been deleted because the client failed to use the <lb/>session for an extended period of time). <lb/>A server could fail and restart in the middle of a COMPOUND procedure <lb/>that contains one or more non-idempotent or idempotent-but-modifying <lb/>operations. This creates an even higher challenge for atomic <lb/>execution and placement of results in the reply cache. One way to <lb/>view the problem is as a single transaction consisting of each <lb/>operation in the COMPOUND followed by storing the result in <lb/>persistent storage, then finally a transaction commit. If there is a <lb/>failure before the transaction is committed, then the server rolls <lb/>back the transaction. If the server itself fails, then when it <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 64] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>restarts, its recovery logic could roll back the transaction before <lb/>starting the NFSv4.1 server. <lb/>While the description of the implementation for atomic execution of <lb/>the request and caching of the reply is beyond the scope of this <lb/>document, an example implementation for NFSv2 [41] is described in <lb/>[42]. <lb/>2.10.7. RDMA Considerations <lb/>A complete discussion of the operation of RPC-based protocols over <lb/>RDMA transports is in [31]. A discussion of the operation of NFSv4, <lb/>including NFSv4.1, over RDMA is in [32]. Where RDMA is considered, <lb/>this specification assumes the use of such a layering; it addresses <lb/>only the upper-layer issues relevant to making best use of RPC/RDMA. <lb/>2.10.7.1. RDMA Connection Resources <lb/>RDMA requires its consumers to register memory and post buffers of a <lb/>specific size and number for receive operations. <lb/>Registration of memory can be a relatively high-overhead operation, <lb/>since it requires pinning of buffers, assignment of attributes (e.g., <lb/>readable/writable), and initialization of hardware translation. <lb/>Preregistration is desirable to reduce overhead. These registrations <lb/>are specific to hardware interfaces and even to RDMA connection <lb/>endpoints; therefore, negotiation of their limits is desirable to <lb/>manage resources effectively. <lb/>Following basic registration, these buffers must be posted by the RPC <lb/>layer to handle receives. These buffers remain in use by the RPC/ <lb/>NFSv4.1 implementation; the size and number of them must be known to <lb/>the remote peer in order to avoid RDMA errors that would cause a <lb/>fatal error on the RDMA connection. <lb/>NFSv4.1 manages slots as resources on a per-session basis (see <lb/>Section 2.10), while RDMA connections manage credits on a per-<lb/>connection basis. This means that in order for a peer to send data <lb/>over RDMA to a remote buffer, it has to have both an NFSv4.1 slot and <lb/>an RDMA credit. If multiple RDMA connections are associated with a <lb/>session, then if the total number of credits across all RDMA <lb/>connections associated with the session is X, and the number of slots <lb/>in the session is Y, then the maximum number of outstanding requests <lb/>is the lesser of X and Y. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 65] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.10.7.2. Flow Control <lb/>Previous versions of NFS do not provide flow control; instead, they <lb/>rely on the windowing provided by transports like TCP to throttle <lb/>requests. This does not work with RDMA, which provides no operation <lb/>flow control and will terminate a connection in error when limits are <lb/>exceeded. Limits such as maximum number of requests outstanding are <lb/>therefore negotiated when a session is created (see the <lb/>ca_maxrequests field in Section 18.36). These limits then provide <lb/>the maxima within which each connection associated with the session&apos;s <lb/>channel(s) must remain. RDMA connections are managed within these <lb/>limits as described in Section 3.3 of [31]; if there are multiple <lb/>RDMA connections, then the maximum number of requests for a channel <lb/>will be divided among the RDMA connections. Put a different way, the <lb/>onus is on the replier to ensure that the total number of RDMA <lb/>credits across all connections associated with the replier&apos;s channel <lb/>does exceed the channel&apos;s maximum number of outstanding requests. <lb/>The limits may also be modified dynamically at the replier&apos;s choosing <lb/>by manipulating certain parameters present in each NFSv4.1 reply. In <lb/>addition, the CB_RECALL_SLOT callback operation (see Section 20.8) <lb/>can be sent by a server to a client to return RDMA credits to the <lb/>server, thereby lowering the maximum number of requests a client can <lb/>have outstanding to the server. <lb/>2.10.7.3. Padding <lb/>Header padding is requested by each peer at session initiation (see <lb/>the ca_headerpadsize argument to CREATE_SESSION in Section 18.36), <lb/>and subsequently used by the RPC RDMA layer, as described in [31]. <lb/>Zero padding is permitted. <lb/>Padding leverages the useful property that RDMA preserve alignment of <lb/>data, even when they are placed into anonymous (untagged) buffers. <lb/>If requested, client inline writes will insert appropriate pad bytes <lb/>within the request header to align the data payload on the specified <lb/>boundary. The client is encouraged to add sufficient padding (up to <lb/>the negotiated size) so that the &quot;data&quot; field of the WRITE operation <lb/>is aligned. Most servers can make good use of such padding, which <lb/>allows them to chain receive buffers in such a way that any data <lb/>carried by client requests will be placed into appropriate buffers at <lb/>the server, ready for file system processing. The receiver&apos;s RPC <lb/>layer encounters no overhead from skipping over pad bytes, and the <lb/>RDMA layer&apos;s high performance makes the insertion and transmission of <lb/>padding on the sender a significant optimization. In this way, the <lb/>need for servers to perform RDMA Read to satisfy all but the largest <lb/>client writes is obviated. An added benefit is the reduction of <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 66] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>message round trips on the network --a potentially good trade, where <lb/>latency is present. <lb/>The value to choose for padding is subject to a number of criteria. <lb/>A primary source of variable-length data in the RPC header is the <lb/>authentication information, the form of which is client-determined, <lb/>possibly in response to server specification. The contents of <lb/>COMPOUNDs, sizes of strings such as those passed to RENAME, etc. all <lb/>go into the determination of a maximal NFSv4.1 request size and <lb/>therefore minimal buffer size. The client must select its offered <lb/>value carefully, so as to avoid overburdening the server, and vice <lb/>versa. The benefit of an appropriate padding value is higher <lb/>performance. <lb/>Sender gather: <lb/>|RPC Request|Pad bytes|Length| -&gt; |User data...| <lb/>\------+----------------------/ <lb/>\ <lb/>\ <lb/>\ <lb/>\ <lb/>Receiver scatter: <lb/>\-----------+-... <lb/>/-----+----------------\ <lb/>\ <lb/>\ <lb/>|RPC Request|Pad|Length| <lb/>-&gt; |FS buffer|-&gt;|FS buffer|-&gt;... <lb/>In the above case, the server may recycle unused buffers to the next <lb/>posted receive if unused by the actual received request, or may pass <lb/>the now-complete buffers by reference for normal write processing. <lb/>For a server that can make use of it, this removes any need for data <lb/>copies of incoming data, without resorting to complicated end-to-end <lb/>buffer advertisement and management. This includes most kernel-based <lb/>and integrated server designs, among many others. The client may <lb/>perform similar optimizations, if desired. <lb/>2.10.7.4. Dual RDMA and Non-RDMA Transports <lb/>Some RDMA transports (e.g., RFC 5040 [8]) permit a &quot;streaming&quot; (non-<lb/>RDMA) phase, where ordinary traffic might flow before &quot;stepping up&quot; <lb/>to RDMA mode, commencing RDMA traffic. Some RDMA transports start <lb/>connections always in RDMA mode. NFSv4.1 allows, but does not <lb/>assume, a streaming phase before RDMA mode. When a connection is <lb/>associated with a session, the client and server negotiate whether <lb/>the connection is used in RDMA or non-RDMA mode (see Sections 18.36 <lb/>and 18.34). <lb/>2.10.8. Session Security <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 67] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.10.8.1. Session Callback Security <lb/>Via session/connection association, NFSv4.1 improves security over <lb/>that provided by NFSv4.0 for the backchannel. The connection is <lb/>client-initiated (see Section 18.34) and subject to the same firewall <lb/>and routing checks as the fore channel. At the client&apos;s option (see <lb/>Section 18.35), connection association is fully authenticated before <lb/>being activated (see Section 18.34). Traffic from the server over <lb/>the backchannel is authenticated exactly as the client specifies (see <lb/>Section 2.10.8.2). <lb/>2.10.8.2. Backchannel RPC Security <lb/>When the NFSv4.1 client establishes the backchannel, it informs the <lb/>server of the security flavors and principals to use when sending <lb/>requests. If the security flavor is RPCSEC_GSS, the client expresses <lb/>the principal in the form of an established RPCSEC_GSS context. The <lb/>server is free to use any of the flavor/principal combinations the <lb/>client offers, but it MUST NOT use unoffered combinations. This way, <lb/>the client need not provide a target GSS principal for the <lb/>backchannel as it did with NFSv4.0, nor does the server have to <lb/>implement an RPCSEC_GSS initiator as it did with NFSv4.0 [33]. <lb/>The CREATE_SESSION (Section 18.36) and BACKCHANNEL_CTL <lb/>(Section 18.33) operations allow the client to specify flavor/ <lb/>principal combinations. <lb/>Also note that the SP4_SSV state protection mode (see Sections 18.35 <lb/>and 2.10.8.3) has the side benefit of providing SSV-derived <lb/>RPCSEC_GSS contexts (Section 2.10.9). <lb/>2.10.8.3. Protection from Unauthorized State Changes <lb/>As described to this point in the specification, the state model of <lb/>NFSv4.1 is vulnerable to an attacker that sends a SEQUENCE operation <lb/>with a forged session ID and with a slot ID that it expects the <lb/>legitimate client to use next. When the legitimate client uses the <lb/>slot ID with the same sequence number, the server returns the <lb/>attacker&apos;s result from the reply cache, which disrupts the legitimate <lb/>client and thus denies service to it. Similarly, an attacker could <lb/>send a CREATE_SESSION with a forged client ID to create a new session <lb/>associated with the client ID. The attacker could send requests <lb/>using the new session that change locking state, such as LOCKU <lb/>operations to release locks the legitimate client has acquired. <lb/>Setting a security policy on the file that requires RPCSEC_GSS <lb/>credentials when manipulating the file&apos;s state is one potential work <lb/>around, but has the disadvantage of preventing a legitimate client <lb/>from releasing state when RPCSEC_GSS is required to do so, but a GSS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 68] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>context cannot be obtained (possibly because the user has logged off <lb/>the client). <lb/>NFSv4.1 provides three options to a client for state protection, <lb/>which are specified when a client creates a client ID via EXCHANGE_ID <lb/>(Section 18.35). <lb/>The first (SP4_NONE) is to simply waive state protection. <lb/>The other two options (SP4_MACH_CRED and SP4_SSV) share several <lb/>traits: <lb/>o An RPCSEC_GSS-based credential is used to authenticate client ID <lb/>and session maintenance operations, including creating and <lb/>destroying a session, associating a connection with the session, <lb/>and destroying the client ID. <lb/>o Because RPCSEC_GSS is used to authenticate client ID and session <lb/>maintenance, the attacker cannot associate a rogue connection with <lb/>a legitimate session, or associate a rogue session with a <lb/>legitimate client ID in order to maliciously alter the client ID&apos;s <lb/>lock state via CLOSE, LOCKU, DELEGRETURN, LAYOUTRETURN, etc. <lb/>o In cases where the server&apos;s security policies on a portion of its <lb/>namespace require RPCSEC_GSS authentication, a client may have to <lb/>use an RPCSEC_GSS credential to remove per-file state (e.g., <lb/>LOCKU, CLOSE, etc.). The server may require that the principal <lb/>that removes the state match certain criteria (e.g., the principal <lb/>might have to be the same as the one that acquired the state). <lb/>However, the client might not have an RPCSEC_GSS context for such <lb/>a principal, and might not be able to create such a context <lb/>(perhaps because the user has logged off). When the client <lb/>establishes SP4_MACH_CRED or SP4_SSV protection, it can specify a <lb/>list of operations that the server MUST allow using the machine <lb/>credential (if SP4_MACH_CRED is used) or the SSV credential (if <lb/>SP4_SSV is used). <lb/>The SP4_MACH_CRED state protection option uses a machine credential <lb/>where the principal that creates the client ID MUST also be the <lb/>principal that performs client ID and session maintenance operations. <lb/>The security of the machine credential state protection approach <lb/>depends entirely on safe guarding the per-machine credential. <lb/>Assuming a proper safeguard using the per-machine credential for <lb/>operations like CREATE_SESSION, BIND_CONN_TO_SESSION, <lb/>DESTROY_SESSION, and DESTROY_CLIENTID will prevent an attacker from <lb/>associating a rogue connection with a session, or associating a rogue <lb/>session with a client ID. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 69] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>There are at least three scenarios for the SP4_MACH_CRED option: <lb/>1. The system administrator configures a unique, permanent per-<lb/>machine credential for one of the mandated GSS mechanisms (e.g., <lb/>if Kerberos V5 is used, a &quot;keytab&quot; containing a principal derived <lb/>from a client host name could be used). <lb/>2. The client is used by a single user, and so the client ID and its <lb/>sessions are used by just that user. If the user&apos;s credential <lb/>expires, then session and client ID maintenance cannot occur, but <lb/>since the client has a single user, only that user is <lb/>inconvenienced. <lb/>3. The physical client has multiple users, but the client <lb/>implementation has a unique client ID for each user. This is <lb/>effectively the same as the second scenario, but a disadvantage <lb/>is that each user needs to be allocated at least one session <lb/>each, so the approach suffers from lack of economy. <lb/>The SP4_SSV protection option uses the SSV (Section 1.7), via <lb/>RPCSEC_GSS and the SSV GSS mechanism (Section 2.10.9), to protect <lb/>state from attack. The SP4_SSV protection option is intended for the <lb/>situation comprised of a client that has multiple active users and a <lb/>system administrator who wants to avoid the burden of installing a <lb/>permanent machine credential on each client. The SSV is established <lb/>and updated on the server via SET_SSV (see Section 18.47). To <lb/>prevent eavesdropping, a client SHOULD send SET_SSV via RPCSEC_GSS <lb/>with the privacy service. Several aspects of the SSV make it <lb/>intractable for an attacker to guess the SSV, and thus associate <lb/>rogue connections with a session, and rogue sessions with a client <lb/>ID: <lb/>o The arguments to and results of SET_SSV include digests of the old <lb/>and new SSV, respectively. <lb/>o Because the initial value of the SSV is zero, therefore known, the <lb/>client that opts for SP4_SSV protection and opts to apply SP4_SSV <lb/>protection to BIND_CONN_TO_SESSION and CREATE_SESSION MUST send at <lb/>least one SET_SSV operation before the first BIND_CONN_TO_SESSION <lb/>operation or before the second CREATE_SESSION operation on a <lb/>client ID. If it does not, the SSV mechanism will not generate <lb/>tokens (Section 2.10.9). A client SHOULD send SET_SSV as soon as <lb/>a session is created. <lb/>o A SET_SSV request does not replace the SSV with the argument to <lb/>SET_SSV. Instead, the current SSV on the server is logically <lb/>exclusive ORed (XORed) with the argument to SET_SSV. Each time a <lb/>new principal uses a client ID for the first time, the client <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 70] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>SHOULD send a SET_SSV with that principal&apos;s RPCSEC_GSS <lb/>credentials, with RPCSEC_GSS service set to RPC_GSS_SVC_PRIVACY. <lb/>Here are the types of attacks that can be attempted by an attacker <lb/>named Eve on a victim named Bob, and how SP4_SSV protection foils <lb/>each attack: <lb/>o Suppose Eve is the first user to log into a legitimate client. <lb/>Eve&apos;s use of an NFSv4.1 file system will cause the legitimate <lb/>client to create a client ID with SP4_SSV protection, specifying <lb/>that the BIND_CONN_TO_SESSION operation MUST use the SSV <lb/>credential. Eve&apos;s use of the file system also causes an SSV to be <lb/>created. The SET_SSV operation that creates the SSV will be <lb/>protected by the RPCSEC_GSS context created by the legitimate <lb/>client, which uses Eve&apos;s GSS principal and credentials. Eve can <lb/>eavesdrop on the network while her RPCSEC_GSS context is created <lb/>and the SET_SSV using her context is sent. Even if the legitimate <lb/>client sends the SET_SSV with RPC_GSS_SVC_PRIVACY, because Eve <lb/>knows her own credentials, she can decrypt the SSV. Eve can <lb/>compute an RPCSEC_GSS credential that BIND_CONN_TO_SESSION will <lb/>accept, and so associate a new connection with the legitimate <lb/>session. Eve can change the slot ID and sequence state of a <lb/>legitimate session, and/or the SSV state, in such a way that when <lb/>Bob accesses the server via the same legitimate client, the <lb/>legitimate client will be unable to use the session. <lb/>The client&apos;s only recourse is to create a new client ID for Bob to <lb/>use, and establish a new SSV for the client ID. The client will <lb/>be unable to delete the old client ID, and will let the lease on <lb/>the old client ID expire. <lb/>Once the legitimate client establishes an SSV over the new session <lb/>using Bob&apos;s RPCSEC_GSS context, Eve can use the new session via <lb/>the legitimate client, but she cannot disrupt Bob. Moreover, <lb/>because the client SHOULD have modified the SSV due to Eve using <lb/>the new session, Bob cannot get revenge on Eve by associating a <lb/>rogue connection with the session. <lb/>The question is how did the legitimate client detect that Eve has <lb/>hijacked the old session? When the client detects that a new <lb/>principal, Bob, wants to use the session, it SHOULD have sent a <lb/>SET_SSV, which leads to the following sub-scenarios: <lb/>* Let us suppose that from the rogue connection, Eve sent a <lb/>SET_SSV with the same slot ID and sequence ID that the <lb/>legitimate client later uses. The server will assume the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 71] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>SET_SSV sent with Bob&apos;s credentials is a retry, and return to <lb/>the legitimate client the reply it sent Eve. However, unless <lb/>Eve can correctly guess the SSV the legitimate client will use, <lb/>the digest verification checks in the SET_SSV response will <lb/>fail. That is an indication to the client that the session has <lb/>apparently been hijacked. <lb/>* Alternatively, Eve sent a SET_SSV with a different slot ID than <lb/>the legitimate client uses for its SET_SSV. Then the digest <lb/>verification of the SET_SSV sent with Bob&apos;s credentials fails <lb/>on the server, and the error returned to the client makes it <lb/>apparent that the session has been hijacked. <lb/>* Alternatively, Eve sent an operation other than SET_SSV, but <lb/>with the same slot ID and sequence that the legitimate client <lb/>uses for its SET_SSV. The server returns to the legitimate <lb/>client the response it sent Eve. The client sees that the <lb/>response is not at all what it expects. The client assumes <lb/>either session hijacking or a server bug, and either way <lb/>destroys the old session. <lb/>o Eve associates a rogue connection with the session as above, and <lb/>then destroys the session. Again, Bob goes to use the server from <lb/>the legitimate client, which sends a SET_SSV using Bob&apos;s <lb/>credentials. The client receives an error that indicates that the <lb/>session does not exist. When the client tries to create a new <lb/>session, this will fail because the SSV it has does not match that <lb/>which the server has, and now the client knows the session was <lb/>hijacked. The legitimate client establishes a new client ID. <lb/>o If Eve creates a connection before the legitimate client <lb/>establishes an SSV, because the initial value of the SSV is zero <lb/>and therefore known, Eve can send a SET_SSV that will pass the <lb/>digest verification check. However, because the new connection <lb/>has not been associated with the session, the SET_SSV is rejected <lb/>for that reason. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 72] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>In summary, an attacker&apos;s disruption of state when SP4_SSV protection <lb/>is in use is limited to the formative period of a client ID, its <lb/>first session, and the establishment of the SSV. Once a non-<lb/>malicious user uses the client ID, the client quickly detects any <lb/>hijack and rectifies the situation. Once a non-malicious user <lb/>successfully modifies the SSV, the attacker cannot use NFSv4.1 <lb/>operations to disrupt the non-malicious user. <lb/>Note that neither the SP4_MACH_CRED nor SP4_SSV protection approaches <lb/>prevent hijacking of a transport connection that has previously been <lb/>associated with a session. If the goal of a counter-threat strategy <lb/>is to prevent connection hijacking, the use of IPsec is RECOMMENDED. <lb/>If a connection hijack occurs, the hijacker could in theory change <lb/>locking state and negatively impact the service to legitimate <lb/>clients. However, if the server is configured to require the use of <lb/>RPCSEC_GSS with integrity or privacy on the affected file objects, <lb/>and if EXCHGID4_FLAG_BIND_PRINC_STATEID capability (Section 18.35) is <lb/>in force, this will thwart unauthorized attempts to change locking <lb/>state. <lb/>2.10.9. The Secret State Verifier (SSV) GSS Mechanism <lb/>The SSV provides the secret key for a GSS mechanism internal to <lb/>NFSv4.1 that NFSv4.1 uses for state protection. Contexts for this <lb/>mechanism are not established via the RPCSEC_GSS protocol. Instead, <lb/>the contexts are automatically created when EXCHANGE_ID specifies <lb/>SP4_SSV protection. The only tokens defined are the PerMsgToken <lb/>(emitted by GSS_GetMIC) and the SealedMessage token (emitted by <lb/>GSS_Wrap). <lb/>The mechanism OID for the SSV mechanism is <lb/>iso.org.dod.internet.private.enterprise.Michael Eisler.nfs.ssv_mech <lb/>(1.3.6.1.4.1.28882.1.1). While the SSV mechanism does not define any <lb/>initial context tokens, the OID can be used to let servers indicate <lb/>that the SSV mechanism is acceptable whenever the client sends a <lb/>SECINFO or SECINFO_NO_NAME operation (see Section 2.6). <lb/>The SSV mechanism defines four subkeys derived from the SSV value. <lb/>Each time SET_SSV is invoked, the subkeys are recalculated by the <lb/>client and server. The calculation of each of the four subkeys <lb/>depends on each of the four respective ssv_subkey4 enumerated values. <lb/>The calculation uses the HMAC [59] algorithm, using the current SSV <lb/>as the key, the one-way hash algorithm as negotiated by EXCHANGE_ID, <lb/>and the input text as represented by the XDR encoded enumeration <lb/>value for that subkey of data type ssv_subkey4. If the length of the <lb/>output of the HMAC algorithm exceeds the length of key of the <lb/>encryption algorithm (which is also negotiated by EXCHANGE_ID), then <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 73] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the subkey MUST be truncated from the HMAC output, i.e., if the <lb/>subkey is of N bytes long, then the first N bytes of the HMAC output <lb/>MUST be used for the subkey. The specification of EXCHANGE_ID states <lb/>that the length of the output of the HMAC algorithm MUST NOT be less <lb/>than the length of subkey needed for the encryption algorithm (see <lb/>Section 18.35). <lb/>/* Input for computing subkeys */ <lb/>enum ssv_subkey4 { <lb/>SSV4_SUBKEY_MIC_I2T <lb/>= 1, <lb/>SSV4_SUBKEY_MIC_T2I <lb/>= 2, <lb/>SSV4_SUBKEY_SEAL_I2T <lb/>= 3, <lb/>SSV4_SUBKEY_SEAL_T2I <lb/>= 4 <lb/>}; <lb/>The subkey derived from SSV4_SUBKEY_MIC_I2T is used for calculating <lb/>message integrity codes (MICs) that originate from the NFSv4.1 <lb/>client, whether as part of a request over the fore channel or a <lb/>response over the backchannel. The subkey derived from <lb/>SSV4_SUBKEY_MIC_T2I is used for MICs originating from the NFSv4.1 <lb/>server. The subkey derived from SSV4_SUBKEY_SEAL_I2T is used for <lb/>encryption text originating from the NFSv4.1 client, and the subkey <lb/>derived from SSV4_SUBKEY_SEAL_T2I is used for encryption text <lb/>originating from the NFSv4.1 server. <lb/>The PerMsgToken description is based on an XDR definition: <lb/>/* Input for computing smt_hmac */ <lb/>struct ssv_mic_plain_tkn4 { <lb/>uint32_t <lb/>smpt_ssv_seq; <lb/>opaque <lb/>smpt_orig_plain&lt;&gt;; <lb/>}; <lb/>/* SSV GSS PerMsgToken token */ <lb/>struct ssv_mic_tkn4 { <lb/>uint32_t <lb/>smt_ssv_seq; <lb/>opaque <lb/>smt_hmac&lt;&gt;; <lb/>}; <lb/>The field smt_hmac is an HMAC calculated by using the subkey derived <lb/>from SSV4_SUBKEY_MIC_I2T or SSV4_SUBKEY_MIC_T2I as the key, the one-<lb/>way hash algorithm as negotiated by EXCHANGE_ID, and the input text <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 74] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>as represented by data of type ssv_mic_plain_tkn4. The field <lb/>smpt_ssv_seq is the same as smt_ssv_seq. The field smpt_orig_plain <lb/>is the &quot;message&quot; input passed to GSS_GetMIC() (see Section 2.3.1 of <lb/>[7]). The caller of GSS_GetMIC() provides a pointer to a buffer <lb/>containing the plain text. The SSV mechanism&apos;s entry point for <lb/>GSS_GetMIC() encodes this into an opaque array, and the encoding will <lb/>include an initial four-byte length, plus any necessary padding. <lb/>Prepended to this will be the XDR encoded value of smpt_ssv_seq, thus <lb/>making up an XDR encoding of a value of data type ssv_mic_plain_tkn4, <lb/>which in turn is the input into the HMAC. <lb/>The token emitted by GSS_GetMIC() is XDR encoded and of XDR data type <lb/>ssv_mic_tkn4. The field smt_ssv_seq comes from the SSV sequence <lb/>number, which is equal to one after SET_SSV (Section 18.47) is called <lb/>the first time on a client ID. Thereafter, the SSV sequence number <lb/>is incremented on each SET_SSV. Thus, smt_ssv_seq represents the <lb/>version of the SSV at the time GSS_GetMIC() was called. As noted in <lb/>Section 18.35, the client and server can maintain multiple concurrent <lb/>versions of the SSV. This allows the SSV to be changed without <lb/>serializing all RPC calls that use the SSV mechanism with SET_SSV <lb/>operations. Once the HMAC is calculated, it is XDR encoded into <lb/>smt_hmac, which will include an initial four-byte length, and any <lb/>necessary padding. Prepended to this will be the XDR encoded value <lb/>of smt_ssv_seq. <lb/>The SealedMessage description is based on an XDR definition: <lb/>/* Input for computing ssct_encr_data and ssct_hmac */ <lb/>struct ssv_seal_plain_tkn4 { <lb/>opaque <lb/>sspt_confounder&lt;&gt;; <lb/>uint32_t <lb/>sspt_ssv_seq; <lb/>opaque <lb/>sspt_orig_plain&lt;&gt;; <lb/>opaque <lb/>sspt_pad&lt;&gt;; <lb/>}; <lb/>/* SSV GSS SealedMessage token */ <lb/>struct ssv_seal_cipher_tkn4 { <lb/>uint32_t <lb/>ssct_ssv_seq; <lb/>opaque <lb/>ssct_iv&lt;&gt;; <lb/>opaque <lb/>ssct_encr_data&lt;&gt;; <lb/>opaque <lb/>ssct_hmac&lt;&gt;; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 75] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The token emitted by GSS_Wrap() is XDR encoded and of XDR data type <lb/>ssv_seal_cipher_tkn4. <lb/>The ssct_ssv_seq field has the same meaning as smt_ssv_seq. <lb/>The ssct_encr_data field is the result of encrypting a value of the <lb/>XDR encoded data type ssv_seal_plain_tkn4. The encryption key is the <lb/>subkey derived from SSV4_SUBKEY_SEAL_I2T or SSV4_SUBKEY_SEAL_T2I, and <lb/>the encryption algorithm is that negotiated by EXCHANGE_ID. <lb/>The ssct_iv field is the initialization vector (IV) for the <lb/>encryption algorithm (if applicable) and is sent in clear text. The <lb/>content and size of the IV MUST comply with the specification of the <lb/>encryption algorithm. For example, the id-aes256-CBC algorithm MUST <lb/>use a 16-byte initialization vector (IV), which MUST be unpredictable <lb/>for each instance of a value of data type ssv_seal_plain_tkn4 that is <lb/>encrypted with a particular SSV key. <lb/>The ssct_hmac field is the result of computing an HMAC using the <lb/>value of the XDR encoded data type ssv_seal_plain_tkn4 as the input <lb/>text. The key is the subkey derived from SSV4_SUBKEY_MIC_I2T or <lb/>SSV4_SUBKEY_MIC_T2I, and the one-way hash algorithm is that <lb/>negotiated by EXCHANGE_ID. <lb/>The sspt_confounder field is a random value. <lb/>The sspt_ssv_seq field is the same as ssvt_ssv_seq. <lb/>The field sspt_orig_plain field is the original plaintext and is the <lb/>&quot;input_message&quot; input passed to GSS_Wrap() (see Section 2.3.3 of <lb/>[7]). As with the handling of the plaintext by the SSV mechanism&apos;s <lb/>GSS_GetMIC() entry point, the entry point for GSS_Wrap() expects a <lb/>pointer to the plaintext, and will XDR encode an opaque array into <lb/>sspt_orig_plain representing the plain text, along with the other <lb/>fields of an instance of data type ssv_seal_plain_tkn4. <lb/>The sspt_pad field is present to support encryption algorithms that <lb/>require inputs to be in fixed-sized blocks. The content of sspt_pad <lb/>is zero filled except for the length. Beware that the XDR encoding <lb/>of ssv_seal_plain_tkn4 contains three variable-length arrays, and so <lb/>each array consumes four bytes for an array length, and each array <lb/>that follows the length is always padded to a multiple of four bytes <lb/>per the XDR standard. <lb/>For example, suppose the encryption algorithm uses 16-byte blocks, <lb/>and the sspt_confounder is three bytes long, and the sspt_orig_plain <lb/>field is 15 bytes long. The XDR encoding of sspt_confounder uses <lb/>eight bytes (4 + 3 + 1 byte pad), the XDR encoding of sspt_ssv_seq <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 76] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>uses four bytes, the XDR encoding of sspt_orig_plain uses 20 bytes (4 <lb/>+ 15 + 1 byte pad), and the smallest XDR encoding of the sspt_pad <lb/>field is four bytes. This totals 36 bytes. The next multiple of 16 <lb/>is 48; thus, the length field of sspt_pad needs to be set to 12 <lb/>bytes, or a total encoding of 16 bytes. The total number of XDR <lb/>encoded bytes is thus 8 + 4 + 20 + 16 = 48. <lb/>GSS_Wrap() emits a token that is an XDR encoding of a value of data <lb/>type ssv_seal_cipher_tkn4. Note that regardless of whether or not <lb/>the caller of GSS_Wrap() requests confidentiality, the token always <lb/>has confidentiality. This is because the SSV mechanism is for <lb/>RPCSEC_GSS, and RPCSEC_GSS never produces GSS_wrap() tokens without <lb/>confidentiality. <lb/>There is one SSV per client ID. There is a single GSS context for a <lb/>client ID / SSV pair. All SSV mechanism RPCSEC_GSS handles of a <lb/>client ID / SSV pair share the same GSS context. SSV GSS contexts do <lb/>not expire except when the SSV is destroyed (causes would include the <lb/>client ID being destroyed or a server restart). Since one purpose of <lb/>context expiration is to replace keys that have been in use for &quot;too <lb/>long&quot;, hence vulnerable to compromise by brute force or accident, the <lb/>client can replace the SSV key by sending periodic SET_SSV <lb/>operations, which is done by cycling through different users&apos; <lb/>RPCSEC_GSS credentials. This way, the SSV is replaced without <lb/>destroying the SSV&apos;s GSS contexts. <lb/>SSV RPCSEC_GSS handles can be expired or deleted by the server at any <lb/>time, and the EXCHANGE_ID operation can be used to create more SSV <lb/>RPCSEC_GSS handles. Expiration of SSV RPCSEC_GSS handles does not <lb/>imply that the SSV or its GSS context has expired. <lb/>The client MUST establish an SSV via SET_SSV before the SSV GSS <lb/>context can be used to emit tokens from GSS_Wrap() and GSS_GetMIC(). <lb/>If SET_SSV has not been successfully called, attempts to emit tokens <lb/>MUST fail. <lb/>The SSV mechanism does not support replay detection and sequencing in <lb/>its tokens because RPCSEC_GSS does not use those features (See <lb/>Section 5.2.2, &quot;Context Creation Requests&quot;, in [4]). However, <lb/>Section 2.10.10 discusses special considerations for the SSV <lb/>mechanism when used with RPCSEC_GSS. <lb/>2.10.10. Security Considerations for RPCSEC_GSS When Using the SSV <lb/>Mechanism <lb/>When a client ID is created with SP4_SSV state protection (see <lb/>Section 18.35), the client is permitted to associate multiple <lb/>RPCSEC_GSS handles with the single SSV GSS context (see <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 77] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Section 2.10.9). Because of the way RPCSEC_GSS (both version 1 and <lb/>version 2, see [4] and [9]) calculate the verifier of the reply, <lb/>special care must be taken by the implementation of the NFSv4.1 <lb/>client to prevent attacks by a man-in-the-middle. The verifier of an <lb/>RPCSEC_GSS reply is the output of GSS_GetMIC() applied to the input <lb/>value of the seq_num field of the RPCSEC_GSS credential (data type <lb/>rpc_gss_cred_ver_1_t) (see Section 5.3.3.2 of [4]). If multiple <lb/>RPCSEC_GSS handles share the same GSS context, then if one handle is <lb/>used to send a request with the same seq_num value as another handle, <lb/>an attacker could block the reply, and replace it with the verifier <lb/>used for the other handle. <lb/>There are multiple ways to prevent the attack on the SSV RPCSEC_GSS <lb/>verifier in the reply. The simplest is believed to be as follows. <lb/>o Each time one or more new SSV RPCSEC_GSS handles are created via <lb/>EXCHANGE_ID, the client SHOULD send a SET_SSV operation to modify <lb/>the SSV. By changing the SSV, the new handles will not result in <lb/>the re-use of an SSV RPCSEC_GSS verifier in a reply. <lb/>o When a requester decides to use N SSV RPCSEC_GSS handles, it <lb/>SHOULD assign a unique and non-overlapping range of seq_nums to <lb/>each SSV RPCSEC_GSS handle. The size of each range SHOULD be <lb/>equal to MAXSEQ / N (see Section 5 of [4] for the definition of <lb/>MAXSEQ). When an SSV RPCSEC_GSS handle reaches its maximum, it <lb/>SHOULD force the replier to destroy the handle by sending a NULL <lb/>RPC request with seq_num set to MAXSEQ + 1 (see Section 5.3.3.3 of <lb/>[4]). <lb/>o When the requester wants to increase or decrease N, it SHOULD <lb/>force the replier to destroy all N handles by sending a NULL RPC <lb/>request on each handle with seq_num set to MAXSEQ + 1. If the <lb/>requester is the client, it SHOULD send a SET_SSV operation before <lb/>using new handles. If the requester is the server, then the <lb/>client SHOULD send a SET_SSV operation when it detects that the <lb/>server has forced it to destroy a backchannel&apos;s SSV RPCSEC_GSS <lb/>handle. By sending a SET_SSV operation, the SSV will change, and <lb/>so the attacker will be unavailable to successfully replay a <lb/>previous verifier in a reply to the requester. <lb/>Note that if the replier carefully creates the SSV RPCSEC_GSS <lb/>handles, the related risk of a man-in-the-middle splicing a forged <lb/>SSV RPCSEC_GSS credential with a verifier for another handle does not <lb/>exist. This is because the verifier in an RPCSEC_GSS request is <lb/>computed from input that includes both the RPCSEC_GSS handle and <lb/>seq_num (see Section 5.3.1 of [4]). Provided the replier takes care <lb/>to avoid re-using the value of an RPCSEC_GSS handle that it creates, <lb/>such as by including a generation number in the handle, the man-in-<lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 78] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the-middle will not be able to successfully replay a previous <lb/>verifier in the request to a replier. <lb/>2.10.11. Session Mechanics -Steady State <lb/>2.10.11.1. Obligations of the Server <lb/>The server has the primary obligation to monitor the state of <lb/>backchannel resources that the client has created for the server <lb/>(RPCSEC_GSS contexts and backchannel connections). If these <lb/>resources vanish, the server takes action as specified in <lb/>Section 2.10.13.2. <lb/>2.10.11.2. Obligations of the Client <lb/>The client SHOULD honor the following obligations in order to utilize <lb/>the session: <lb/>o Keep a necessary session from going idle on the server. A client <lb/>that requires a session but nonetheless is not sending operations <lb/>risks having the session be destroyed by the server. This is <lb/>because sessions consume resources, and resource limitations may <lb/>force the server to cull an inactive session. A server MAY <lb/>consider a session to be inactive if the client has not used the <lb/>session before the session inactivity timer (Section 2.10.12) has <lb/>expired. <lb/>o Destroy the session when not needed. If a client has multiple <lb/>sessions, one of which has no requests waiting for replies, and <lb/>has been idle for some period of time, it SHOULD destroy the <lb/>session. <lb/>o Maintain GSS contexts and RPCSEC_GSS handles for the backchannel. <lb/>If the client requires the server to use the RPCSEC_GSS security <lb/>flavor for callbacks, then it needs to be sure the RPCSEC_GSS <lb/>handles and/or their GSS contexts that are handed to the server <lb/>via BACKCHANNEL_CTL or CREATE_SESSION are unexpired. <lb/>o Preserve a connection for a backchannel. The server requires a <lb/>backchannel in order to gracefully recall recallable state or <lb/>notify the client of certain events. Note that if the connection <lb/>is not being used for the fore channel, there is no way for the <lb/>client to tell if the connection is still alive (e.g., the server <lb/>restarted without sending a disconnect). The onus is on the <lb/>server, not the client, to determine if the backchannel&apos;s <lb/>connection is alive, and to indicate in the response to a SEQUENCE <lb/>operation when the last connection associated with a session&apos;s <lb/>backchannel has disconnected. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 79] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.10.11.3. Steps the Client Takes to Establish a Session <lb/>If the client does not have a client ID, the client sends EXCHANGE_ID <lb/>to establish a client ID. If it opts for SP4_MACH_CRED or SP4_SSV <lb/>protection, in the spo_must_enforce list of operations, it SHOULD at <lb/>minimum specify CREATE_SESSION, DESTROY_SESSION, <lb/>BIND_CONN_TO_SESSION, BACKCHANNEL_CTL, and DESTROY_CLIENTID. If it <lb/>opts for SP4_SSV protection, the client needs to ask for SSV-based <lb/>RPCSEC_GSS handles. <lb/>The client uses the client ID to send a CREATE_SESSION on a <lb/>connection to the server. The results of CREATE_SESSION indicate <lb/>whether or not the server will persist the session reply cache <lb/>through a server that has restarted, and the client notes this for <lb/>future reference. <lb/>If the client specified SP4_SSV state protection when the client ID <lb/>was created, then it SHOULD send SET_SSV in the first COMPOUND after <lb/>the session is created. Each time a new principal goes to use the <lb/>client ID, it SHOULD send a SET_SSV again. <lb/>If the client wants to use delegations, layouts, directory <lb/>notifications, or any other state that requires a backchannel, then <lb/>it needs to add a connection to the backchannel if CREATE_SESSION did <lb/>not already do so. The client creates a connection, and calls <lb/>BIND_CONN_TO_SESSION to associate the connection with the session and <lb/>the session&apos;s backchannel. If CREATE_SESSION did not already do so, <lb/>the client MUST tell the server what security is required in order <lb/>for the client to accept callbacks. The client does this via <lb/>BACKCHANNEL_CTL. If the client selected SP4_MACH_CRED or SP4_SSV <lb/>protection when it called EXCHANGE_ID, then the client SHOULD specify <lb/>that the backchannel use RPCSEC_GSS contexts for security. <lb/>If the client wants to use additional connections for the <lb/>backchannel, then it needs to call BIND_CONN_TO_SESSION on each <lb/>connection it wants to use with the session. If the client wants to <lb/>use additional connections for the fore channel, then it needs to <lb/>call BIND_CONN_TO_SESSION if it specified SP4_SSV or SP4_MACH_CRED <lb/>state protection when the client ID was created. <lb/>At this point, the session has reached steady state. <lb/>2.10.12. Session Inactivity Timer <lb/>The server MAY maintain a session inactivity timer for each session. <lb/>If the session inactivity timer expires, then the server MAY destroy <lb/>the session. To avoid losing a session due to inactivity, the client <lb/>MUST renew the session inactivity timer. The length of session <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 80] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>inactivity timer MUST NOT be less than the lease_time attribute <lb/>(Section 5.8.1.11). As with lease renewal (Section 8.3), when the <lb/>server receives a SEQUENCE operation, it resets the session <lb/>inactivity timer, and MUST NOT allow the timer to expire while the <lb/>rest of the operations in the COMPOUND procedure&apos;s request are still <lb/>executing. Once the last operation has finished, the server MUST set <lb/>the session inactivity timer to expire no sooner than the sum of the <lb/>current time and the value of the lease_time attribute. <lb/>2.10.13. Session Mechanics -Recovery <lb/>2.10.13.1. Events Requiring Client Action <lb/>The following events require client action to recover. <lb/>2.10.13.1.1. RPCSEC_GSS Context Loss by Callback Path <lb/>If all RPCSEC_GSS handles granted by the client to the server for <lb/>callback use have expired, the client MUST establish a new handle via <lb/>BACKCHANNEL_CTL. The sr_status_flags field of the SEQUENCE results <lb/>indicates when callback handles are nearly expired, or fully expired <lb/>(see Section 18.46.3). <lb/>2.10.13.1.2. Connection Loss <lb/>If the client loses the last connection of the session and wants to <lb/>retain the session, then it needs to create a new connection, and if, <lb/>when the client ID was created, BIND_CONN_TO_SESSION was specified in <lb/>the spo_must_enforce list, the client MUST use BIND_CONN_TO_SESSION <lb/>to associate the connection with the session. <lb/>If there was a request outstanding at the time of connection loss, <lb/>then if the client wants to continue to use the session, it MUST <lb/>retry the request, as described in Section 2.10.6.2. Note that it is <lb/>not necessary to retry requests over a connection with the same <lb/>source network address or the same destination network address as the <lb/>lost connection. As long as the session ID, slot ID, and sequence ID <lb/>in the retry match that of the original request, the server will <lb/>recognize the request as a retry if it executed the request prior to <lb/>disconnect. <lb/>If the connection that was lost was the last one associated with the <lb/>backchannel, and the client wants to retain the backchannel and/or <lb/>prevent revocation of recallable state, the client needs to <lb/>reconnect, and if it does, it MUST associate the connection to the <lb/>session and backchannel via BIND_CONN_TO_SESSION. The server SHOULD <lb/>indicate when it has no callback connection via the sr_status_flags <lb/>result from SEQUENCE. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 81] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.10.13.1.3. Backchannel GSS Context Loss <lb/>Via the sr_status_flags result of the SEQUENCE operation or other <lb/>means, the client will learn if some or all of the RPCSEC_GSS <lb/>contexts it assigned to the backchannel have been lost. If the <lb/>client wants to retain the backchannel and/or not put recallable <lb/>state subject to revocation, the client needs to use BACKCHANNEL_CTL <lb/>to assign new contexts. <lb/>2.10.13.1.4. Loss of Session <lb/>The replier might lose a record of the session. Causes include: <lb/>o Replier failure and restart. <lb/>o A catastrophe that causes the reply cache to be corrupted or lost <lb/>on the media on which it was stored. This applies even if the <lb/>replier indicated in the CREATE_SESSION results that it would <lb/>persist the cache. <lb/>o The server purges the session of a client that has been inactive <lb/>for a very extended period of time. <lb/>o As a result of configuration changes among a set of clustered <lb/>servers, a network address previously connected to one server <lb/>becomes connected to a different server that has no knowledge of <lb/>the session in question. Such a configuration change will <lb/>generally only happen when the original server ceases to function <lb/>for a time. <lb/>Loss of reply cache is equivalent to loss of session. The replier <lb/>indicates loss of session to the requester by returning <lb/>NFS4ERR_BADSESSION on the next operation that uses the session ID <lb/>that refers to the lost session. <lb/>After an event like a server restart, the client may have lost its <lb/>connections. The client assumes for the moment that the session has <lb/>not been lost. It reconnects, and if it specified connection <lb/>association enforcement when the session was created, it invokes <lb/>BIND_CONN_TO_SESSION using the session ID. Otherwise, it invokes <lb/>SEQUENCE. If BIND_CONN_TO_SESSION or SEQUENCE returns <lb/>NFS4ERR_BADSESSION, the client knows the session is not available to <lb/>it when communicating with that network address. If the connection <lb/>survives session loss, then the next SEQUENCE operation the client <lb/>sends over the connection will get back NFS4ERR_BADSESSION. The <lb/>client again knows the session was lost. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 82] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Here is one suggested algorithm for the client when it gets <lb/>NFS4ERR_BADSESSION. It is not obligatory in that, if a client does <lb/>not want to take advantage of such features as trunking, it may omit <lb/>parts of it. However, it is a useful example that draws attention to <lb/>various possible recovery issues: <lb/>1. If the client has other connections to other server network <lb/>addresses associated with the same session, attempt a COMPOUND <lb/>with a single operation, SEQUENCE, on each of the other <lb/>connections. <lb/>2. If the attempts succeed, the session is still alive, and this is <lb/>a strong indicator that the server&apos;s network address has moved. <lb/>The client might send an EXCHANGE_ID on the connection that <lb/>returned NFS4ERR_BADSESSION to see if there are opportunities for <lb/>client ID trunking (i.e., the same client ID and so_major are <lb/>returned). The client might use DNS to see if the moved network <lb/>address was replaced with another, so that the performance and <lb/>availability benefits of session trunking can continue. <lb/>3. If the SEQUENCE requests fail with NFS4ERR_BADSESSION, then the <lb/>session no longer exists on any of the server network addresses <lb/>for which the client has connections associated with that session <lb/>ID. It is possible the session is still alive and available on <lb/>other network addresses. The client sends an EXCHANGE_ID on all <lb/>the connections to see if the server owner is still listening on <lb/>those network addresses. If the same server owner is returned <lb/>but a new client ID is returned, this is a strong indicator of a <lb/>server restart. If both the same server owner and same client ID <lb/>are returned, then this is a strong indication that the server <lb/>did delete the session, and the client will need to send a <lb/>CREATE_SESSION if it has no other sessions for that client ID. <lb/>If a different server owner is returned, the client can use DNS <lb/>to find other network addresses. If it does not, or if DNS does <lb/>not find any other addresses for the server, then the client will <lb/>be unable to provide NFSv4.1 service, and fatal errors should be <lb/>returned to processes that were using the server. If the client <lb/>is using a &quot;mount&quot; paradigm, unmounting the server is advised. <lb/>4. If the client knows of no other connections associated with the <lb/>session ID and server network addresses that are, or have been, <lb/>associated with the session ID, then the client can use DNS to <lb/>find other network addresses. If it does not, or if DNS does not <lb/>find any other addresses for the server, then the client will be <lb/>unable to provide NFSv4.1 service, and fatal errors should be <lb/>returned to processes that were using the server. If the client <lb/>is using a &quot;mount&quot; paradigm, unmounting the server is advised. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 83] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If there is a reconfiguration event that results in the same network <lb/>address being assigned to servers where the eir_server_scope value is <lb/>different, it cannot be guaranteed that a session ID generated by the <lb/>first will be recognized as invalid by the first. Therefore, in <lb/>managing server reconfigurations among servers with different server <lb/>scope values, it is necessary to make sure that all clients have <lb/>disconnected from the first server before effecting the <lb/>reconfiguration. Nonetheless, clients should not assume that servers <lb/>will always adhere to this requirement; clients MUST be prepared to <lb/>deal with unexpected effects of server reconfigurations. Even where <lb/>a session ID is inappropriately recognized as valid, it is likely <lb/>either that the connection will not be recognized as valid or that a <lb/>sequence value for a slot will not be correct. Therefore, when a <lb/>client receives results indicating such unexpected errors, the use of <lb/>EXCHANGE_ID to determine the current server configuration is <lb/>RECOMMENDED. <lb/>A variation on the above is that after a server&apos;s network address <lb/>moves, there is no NFSv4.1 server listening, e.g., no listener on <lb/>port 2049. In this example, one of the following occur: the NFSv4 <lb/>server returns NFS4ERR_MINOR_VERS_MISMATCH, the NFS server returns a <lb/>PROG_MISMATCH error, the RPC listener on 2049 returns PROG_UNVAIL, or <lb/>attempts to reconnect to the network address timeout. These SHOULD <lb/>be treated as equivalent to SEQUENCE returning NFS4ERR_BADSESSION for <lb/>these purposes. <lb/>When the client detects session loss, it needs to call CREATE_SESSION <lb/>to recover. Any non-idempotent operations that were in progress <lb/>might have been performed on the server at the time of session loss. <lb/>The client has no general way to recover from this. <lb/>Note that loss of session does not imply loss of byte-range lock, <lb/>open, delegation, or layout state because locks, opens, delegations, <lb/>and layouts are tied to the client ID and depend on the client ID, <lb/>not the session. Nor does loss of byte-range lock, open, delegation, <lb/>or layout state imply loss of session state, because the session <lb/>depends on the client ID; loss of client ID however does imply loss <lb/>of session, byte-range lock, open, delegation, and layout state. See <lb/>Section 8.4.2. A session can survive a server restart, but lock <lb/>recovery may still be needed. <lb/>It is possible that CREATE_SESSION will fail with <lb/>NFS4ERR_STALE_CLIENTID (e.g., the server restarts and does not <lb/>preserve client ID state). If so, the client needs to call <lb/>EXCHANGE_ID, followed by CREATE_SESSION. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 84] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.10.13.2. Events Requiring Server Action <lb/>The following events require server action to recover. <lb/>2.10.13.2.1. Client Crash and Restart <lb/>As described in Section 18.35, a restarted client sends EXCHANGE_ID <lb/>in such a way that it causes the server to delete any sessions it <lb/>had. <lb/>2.10.13.2.2. Client Crash with No Restart <lb/>If a client crashes and never comes back, it will never send <lb/>EXCHANGE_ID with its old client owner. Thus, the server has session <lb/>state that will never be used again. After an extended period of <lb/>time, and if the server has resource constraints, it MAY destroy the <lb/>old session as well as locking state. <lb/>2.10.13.2.3. Extended Network Partition <lb/>To the server, the extended network partition may be no different <lb/>from a client crash with no restart (see Section 2.10.13.2.2). <lb/>Unless the server can discern that there is a network partition, it <lb/>is free to treat the situation as if the client has crashed <lb/>permanently. <lb/>2.10.13.2.4. Backchannel Connection Loss <lb/>If there were callback requests outstanding at the time of a <lb/>connection loss, then the server MUST retry the requests, as <lb/>described in Section 2.10.6.2. Note that it is not necessary to <lb/>retry requests over a connection with the same source network address <lb/>or the same destination network address as the lost connection. As <lb/>long as the session ID, slot ID, and sequence ID in the retry match <lb/>that of the original request, the callback target will recognize the <lb/>request as a retry even if it did see the request prior to <lb/>disconnect. <lb/>If the connection lost is the last one associated with the <lb/>backchannel, then the server MUST indicate that in the <lb/>sr_status_flags field of every SEQUENCE reply until the backchannel <lb/>is re-established. There are two situations, each of which uses <lb/>different status flags: no connectivity for the session&apos;s backchannel <lb/>and no connectivity for any session backchannel of the client. See <lb/>Section 18.46 for a description of the appropriate flags in <lb/>sr_status_flags. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 85] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2.10.13.2.5. GSS Context Loss <lb/>The server SHOULD monitor when the number of RPCSEC_GSS handles <lb/>assigned to the backchannel reaches one, and when that one handle is <lb/>near expiry (i.e., between one and two periods of lease time), and <lb/>indicate so in the sr_status_flags field of all SEQUENCE replies. <lb/>The server MUST indicate when all of the backchannel&apos;s assigned <lb/>RPCSEC_GSS handles have expired via the sr_status_flags field of all <lb/>SEQUENCE replies. <lb/>2.10.14. Parallel NFS and Sessions <lb/>A client and server can potentially be a non-pNFS implementation, a <lb/>metadata server implementation, a data server implementation, or two <lb/>or three types of implementations. The EXCHGID4_FLAG_USE_NON_PNFS, <lb/>EXCHGID4_FLAG_USE_PNFS_MDS, and EXCHGID4_FLAG_USE_PNFS_DS flags (not <lb/>mutually exclusive) are passed in the EXCHANGE_ID arguments and <lb/>results to allow the client to indicate how it wants to use sessions <lb/>created under the client ID, and to allow the server to indicate how <lb/>it will allow the sessions to be used. See Section 13.1 for pNFS <lb/>sessions considerations. <lb/>3. Protocol Constants and Data Types <lb/>The syntax and semantics to describe the data types of the NFSv4.1 <lb/>protocol are defined in the XDR RFC 4506 [2] and RPC RFC 5531 [3] <lb/>documents. The next sections build upon the XDR data types to define <lb/>constants, types, and structures specific to this protocol. The full <lb/>list of XDR data types is in [10]. <lb/>3.1. Basic Constants <lb/>const NFS4_FHSIZE <lb/>= 128; <lb/>const NFS4_VERIFIER_SIZE <lb/>= 8; <lb/>const NFS4_OPAQUE_LIMIT <lb/>= 1024; <lb/>const NFS4_SESSIONID_SIZE <lb/>= 16; <lb/>const NFS4_INT64_MAX <lb/>= 0x7fffffffffffffff; <lb/>const NFS4_UINT64_MAX <lb/>= 0xffffffffffffffff; <lb/>const NFS4_INT32_MAX <lb/>= 0x7fffffff; <lb/>const NFS4_UINT32_MAX <lb/>= 0xffffffff; <lb/>const NFS4_MAXFILELEN <lb/>= 0xffffffffffffffff; <lb/>const NFS4_MAXFILEOFF <lb/>= 0xfffffffffffffffe; <lb/>Except where noted, all these constants are defined in bytes. <lb/>o NFS4_FHSIZE is the maximum size of a filehandle. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 86] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o NFS4_VERIFIER_SIZE is the fixed size of a verifier. <lb/>o NFS4_OPAQUE_LIMIT is the maximum size of certain opaque <lb/>information. <lb/>o NFS4_SESSIONID_SIZE is the fixed size of a session identifier. <lb/>o NFS4_INT64_MAX is the maximum value of a signed 64-bit integer. <lb/>o NFS4_UINT64_MAX is the maximum value of an unsigned 64-bit <lb/>integer. <lb/>o NFS4_INT32_MAX is the maximum value of a signed 32-bit integer. <lb/>o NFS4_UINT32_MAX is the maximum value of an unsigned 32-bit <lb/>integer. <lb/>o NFS4_MAXFILELEN is the maximum length of a regular file. <lb/>o NFS4_MAXFILEOFF is the maximum offset into a regular file. <lb/>3.2. Basic Data Types <lb/>These are the base NFSv4.1 data types. <lb/>+---------------+---------------------------------------------------+ <lb/>| Data Type <lb/>| Definition <lb/>| <lb/>+---------------+---------------------------------------------------+ <lb/>| int32_t <lb/>| typedef int int32_t; <lb/>| <lb/>| uint32_t <lb/>| typedef unsigned int uint32_t; <lb/>| <lb/>| int64_t <lb/>| typedef hyper int64_t; <lb/>| <lb/>| uint64_t <lb/>| typedef unsigned hyper uint64_t; <lb/>| <lb/>| attrlist4 <lb/>| typedef opaque attrlist4&lt;&gt;; <lb/>| <lb/>| <lb/>| Used for file/directory attributes. <lb/>| <lb/>| bitmap4 <lb/>| typedef uint32_t bitmap4&lt;&gt;; <lb/>| <lb/>| <lb/>| Used in attribute array encoding. <lb/>| <lb/>| changeid4 <lb/>| typedef uint64_t changeid4; <lb/>| <lb/>| <lb/>| Used in the definition of change_info4. <lb/>| <lb/>| clientid4 <lb/>| typedef uint64_t clientid4; <lb/>| <lb/>| <lb/>| Shorthand reference to client identification. <lb/>| <lb/>| count4 <lb/>| typedef uint32_t count4; <lb/>| <lb/>| <lb/>| Various count parameters (READ, WRITE, COMMIT). <lb/>| <lb/>| length4 <lb/>| typedef uint64_t length4; <lb/>| <lb/>| <lb/>| The length of a byte-range within a file. <lb/>| <lb/>| mode4 <lb/>| typedef uint32_t mode4; <lb/>| <lb/>| <lb/>| Mode attribute data type. <lb/>| <lb/>| nfs_cookie4 <lb/>| typedef uint64_t nfs_cookie4; <lb/>| <lb/>| <lb/>| Opaque cookie value for READDIR. <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 87] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| nfs_fh4 <lb/>| typedef opaque nfs_fh4&lt;NFS4_FHSIZE&gt;; <lb/>| <lb/>| <lb/>| Filehandle definition. <lb/>| <lb/>| nfs_ftype4 <lb/>| enum nfs_ftype4; <lb/>| <lb/>| <lb/>| Various defined file types. <lb/>| <lb/>| nfsstat4 <lb/>| enum nfsstat4; <lb/>| <lb/>| <lb/>| Return value for operations. <lb/>| <lb/>| offset4 <lb/>| typedef uint64_t offset4; <lb/>| <lb/>| <lb/>| Various offset designations (READ, WRITE, LOCK, <lb/>| <lb/>| <lb/>| COMMIT). <lb/>| <lb/>| qop4 <lb/>| typedef uint32_t qop4; <lb/>| <lb/>| <lb/>| Quality of protection designation in SECINFO. <lb/>| <lb/>| sec_oid4 <lb/>| typedef opaque sec_oid4&lt;&gt;; <lb/>| <lb/>| <lb/>| Security Object Identifier. The sec_oid4 data <lb/>| <lb/>| <lb/>| type is not really opaque. Instead, it contains | <lb/>| <lb/>| an ASN.1 OBJECT IDENTIFIER as used by GSS-API in | <lb/>| <lb/>| the mech_type argument to GSS_Init_sec_context. <lb/>| <lb/>| <lb/>| See [7] for details. <lb/>| <lb/>| sequenceid4 <lb/>| typedef uint32_t sequenceid4; <lb/>| <lb/>| <lb/>| Sequence number used for various session <lb/>| <lb/>| <lb/>| operations (EXCHANGE_ID, CREATE_SESSION, <lb/>| <lb/>| <lb/>| SEQUENCE, CB_SEQUENCE). <lb/>| <lb/>| seqid4 <lb/>| typedef uint32_t seqid4; <lb/>| <lb/>| <lb/>| Sequence identifier used for locking. <lb/>| <lb/>| sessionid4 <lb/>| typedef opaque sessionid4[NFS4_SESSIONID_SIZE]; <lb/>| <lb/>| <lb/>| Session identifier. <lb/>| <lb/>| slotid4 <lb/>| typedef uint32_t slotid4; <lb/>| <lb/>| <lb/>| Sequencing artifact for various session <lb/>| <lb/>| <lb/>| operations (SEQUENCE, CB_SEQUENCE). <lb/>| <lb/>| utf8string <lb/>| typedef opaque utf8string&lt;&gt;; <lb/>| <lb/>| <lb/>| UTF-8 encoding for strings. <lb/>| <lb/>| utf8str_cis <lb/>| typedef utf8string utf8str_cis; <lb/>| <lb/>| <lb/>| Case-insensitive UTF-8 string. <lb/>| <lb/>| utf8str_cs <lb/>| typedef utf8string utf8str_cs; <lb/>| <lb/>| <lb/>| Case-sensitive UTF-8 string. <lb/>| <lb/>| utf8str_mixed | typedef utf8string utf8str_mixed; <lb/>| <lb/>| <lb/>| UTF-8 strings with a case-sensitive prefix and a | <lb/>| <lb/>| case-insensitive suffix. <lb/>| <lb/>| component4 <lb/>| typedef utf8str_cs component4; <lb/>| <lb/>| <lb/>| Represents pathname components. <lb/>| <lb/>| linktext4 <lb/>| typedef utf8str_cs linktext4; <lb/>| <lb/>| <lb/>| Symbolic link contents (&quot;symbolic link&quot; is <lb/>| <lb/>| <lb/>| defined in an Open Group [11] standard). <lb/>| <lb/>| pathname4 <lb/>| typedef component4 pathname4&lt;&gt;; <lb/>| <lb/>| <lb/>| Represents pathname for fs_locations. <lb/>| <lb/>| verifier4 <lb/>| typedef opaque verifier4[NFS4_VERIFIER_SIZE]; <lb/>| <lb/>| <lb/>| Verifier used for various operations (COMMIT, <lb/>| <lb/>| <lb/>| CREATE, EXCHANGE_ID, OPEN, READDIR, WRITE) <lb/>| <lb/>| <lb/>| NFS4_VERIFIER_SIZE is defined as 8. <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 88] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>+---------------+---------------------------------------------------+ <lb/>End of Base Data Types <lb/>Table 1 <lb/>3.3. Structured Data Types <lb/>3.3.1. nfstime4 <lb/>struct nfstime4 { <lb/>int64_t <lb/>seconds; <lb/>uint32_t <lb/>nseconds; <lb/>}; <lb/>The nfstime4 data type gives the number of seconds and nanoseconds <lb/>since midnight or zero hour January 1, 1970 Coordinated Universal <lb/>Time (UTC). Values greater than zero for the seconds field denote <lb/>dates after the zero hour January 1, 1970. Values less than zero for <lb/>the seconds field denote dates before the zero hour January 1, 1970. <lb/>In both cases, the nseconds field is to be added to the seconds field <lb/>for the final time representation. For example, if the time to be <lb/>represented is one-half second before zero hour January 1, 1970, the <lb/>seconds field would have a value of negative one (-1) and the <lb/>nseconds field would have a value of one-half second (500000000). <lb/>Values greater than 999,999,999 for nseconds are invalid. <lb/>This data type is used to pass time and date information. A server <lb/>converts to and from its local representation of time when processing <lb/>time values, preserving as much accuracy as possible. If the <lb/>precision of timestamps stored for a file system object is less than <lb/>defined, loss of precision can occur. An adjunct time maintenance <lb/>protocol is RECOMMENDED to reduce client and server time skew. <lb/>3.3.2. time_how4 <lb/>enum time_how4 { <lb/>SET_TO_SERVER_TIME4 = 0, <lb/>SET_TO_CLIENT_TIME4 = 1 <lb/>}; <lb/>3.3.3. settime4 <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 89] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>union settime4 switch (time_how4 set_it) { <lb/>case SET_TO_CLIENT_TIME4: <lb/>nfstime4 <lb/>time; <lb/>default: <lb/>void; <lb/>}; <lb/>The time_how4 and settime4 data types are used for setting timestamps <lb/>in file object attributes. If set_it is SET_TO_SERVER_TIME4, then <lb/>the server uses its local representation of time for the time value. <lb/>3.3.4. specdata4 <lb/>struct specdata4 { <lb/>uint32_t specdata1; /* major device number */ <lb/>uint32_t specdata2; /* minor device number */ <lb/>}; <lb/>This data type represents the device numbers for the device file <lb/>types NF4CHR and NF4BLK. <lb/>3.3.5. fsid4 <lb/>struct fsid4 { <lb/>uint64_t <lb/>major; <lb/>uint64_t <lb/>minor; <lb/>}; <lb/>3.3.6. change_policy4 <lb/>struct change_policy4 { <lb/>uint64_t <lb/>cp_major; <lb/>uint64_t <lb/>cp_minor; <lb/>}; <lb/>The change_policy4 data type is used for the change_policy <lb/>RECOMMENDED attribute. It provides change sequencing indication <lb/>analogous to the change attribute. To enable the server to present a <lb/>value valid across server re-initialization without requiring <lb/>persistent storage, two 64-bit quantities are used, allowing one to <lb/>be a server instance ID and the second to be incremented non-<lb/>persistently, within a given server instance. <lb/>3.3.7. fattr4 <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 90] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct fattr4 { <lb/>bitmap4 <lb/>attrmask; <lb/>attrlist4 <lb/>attr_vals; <lb/>}; <lb/>The fattr4 data type is used to represent file and directory <lb/>attributes. <lb/>The bitmap is a counted array of 32-bit integers used to contain bit <lb/>values. The position of the integer in the array that contains bit n <lb/>can be computed from the expression (n / 32), and its bit within that <lb/>integer is (n mod 32). <lb/>0 <lb/>1 <lb/>+-----------+-----------+-----------+--<lb/>| count <lb/>| 31 .. 0 | 63 .. 32 | <lb/>+-----------+-----------+-----------+--<lb/>3.3.8. change_info4 <lb/>struct change_info4 { <lb/>bool <lb/>atomic; <lb/>changeid4 <lb/>before; <lb/>changeid4 <lb/>after; <lb/>}; <lb/>This data type is used with the CREATE, LINK, OPEN, REMOVE, and <lb/>RENAME operations to let the client know the value of the change <lb/>attribute for the directory in which the target file system object <lb/>resides. <lb/>3.3.9. netaddr4 <lb/>struct netaddr4 { <lb/>/* see struct rpcb in RFC 1833 */ <lb/>string na_r_netid&lt;&gt;; /* network id */ <lb/>string na_r_addr&lt;&gt;; /* universal address */ <lb/>}; <lb/>The netaddr4 data type is used to identify network transport <lb/>endpoints. The r_netid and r_addr fields respectively contain a <lb/>netid and uaddr. The netid and uaddr concepts are defined in [12]. <lb/>The netid and uaddr formats for TCP over IPv4 and TCP over IPv6 are <lb/>defined in [12], specifically Tables 2 and 3 and Sections 5.2.3.3 and <lb/>5.2.3.4. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 91] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>3.3.10. state_owner4 <lb/>struct state_owner4 { <lb/>clientid4 <lb/>clientid; <lb/>opaque <lb/>owner&lt;NFS4_OPAQUE_LIMIT&gt;; <lb/>}; <lb/>typedef state_owner4 open_owner4; <lb/>typedef state_owner4 lock_owner4; <lb/>The state_owner4 data type is the base type for the open_owner4 <lb/>(Section 3.3.10.1) and lock_owner4 (Section 3.3.10.2). <lb/>3.3.10.1. open_owner4 <lb/>This data type is used to identify the owner of OPEN state. <lb/>3.3.10.2. lock_owner4 <lb/>This structure is used to identify the owner of byte-range locking <lb/>state. <lb/>3.3.11. open_to_lock_owner4 <lb/>struct open_to_lock_owner4 { <lb/>seqid4 <lb/>open_seqid; <lb/>stateid4 <lb/>open_stateid; <lb/>seqid4 <lb/>lock_seqid; <lb/>lock_owner4 <lb/>lock_owner; <lb/>}; <lb/>This data type is used for the first LOCK operation done for an <lb/>open_owner4. It provides both the open_stateid and lock_owner, such <lb/>that the transition is made from a valid open_stateid sequence to <lb/>that of the new lock_stateid sequence. Using this mechanism avoids <lb/>the confirmation of the lock_owner/lock_seqid pair since it is tied <lb/>to established state in the form of the open_stateid/open_seqid. <lb/>3.3.12. stateid4 <lb/>struct stateid4 { <lb/>uint32_t <lb/>seqid; <lb/>opaque <lb/>other[12]; <lb/>}; <lb/>This data type is used for the various state sharing mechanisms <lb/>between the client and server. The client never modifies a value of <lb/>data type stateid. The starting value of the &quot;seqid&quot; field is <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 92] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>undefined. The server is required to increment the &quot;seqid&quot; field by <lb/>one at each transition of the stateid. This is important since the <lb/>client will inspect the seqid in OPEN stateids to determine the order <lb/>of OPEN processing done by the server. <lb/>3.3.13. layouttype4 <lb/>enum layouttype4 { <lb/>LAYOUT4_NFSV4_1_FILES <lb/>= 0x1, <lb/>LAYOUT4_OSD2_OBJECTS <lb/>= 0x2, <lb/>LAYOUT4_BLOCK_VOLUME <lb/>= 0x3 <lb/>}; <lb/>This data type indicates what type of layout is being used. The file <lb/>server advertises the layout types it supports through the <lb/>fs_layout_type file system attribute (Section 5.12.1). A client asks <lb/>for layouts of a particular type in LAYOUTGET, and processes those <lb/>layouts in its layout-type-specific logic. <lb/>The layouttype4 data type is 32 bits in length. The range <lb/>represented by the layout type is split into three parts. Type 0x0 <lb/>is reserved. Types within the range 0x00000001-0x7FFFFFFF are <lb/>globally unique and are assigned according to the description in <lb/>Section 22.5; they are maintained by IANA. Types within the range <lb/>0x80000000-0xFFFFFFFF are site specific and for private use only. <lb/>The LAYOUT4_NFSV4_1_FILES enumeration specifies that the NFSv4.1 file <lb/>layout type, as defined in Section 13, is to be used. The <lb/>LAYOUT4_OSD2_OBJECTS enumeration specifies that the object layout, as <lb/>defined in [43], is to be used. Similarly, the LAYOUT4_BLOCK_VOLUME <lb/>enumeration specifies that the block/volume layout, as defined in <lb/>[44], is to be used. <lb/>3.3.14. deviceid4 <lb/>const NFS4_DEVICEID4_SIZE = 16; <lb/>typedef opaque deviceid4[NFS4_DEVICEID4_SIZE]; <lb/>Layout information includes device IDs that specify a storage device <lb/>through a compact handle. Addressing and type information is <lb/>obtained with the GETDEVICEINFO operation. Device IDs are not <lb/>guaranteed to be valid across metadata server restarts. A device ID <lb/>is unique per client ID and layout type. See Section 12.2.10 for <lb/>more details. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 93] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>3.3.15. device_addr4 <lb/>struct device_addr4 { <lb/>layouttype4 <lb/>da_layout_type; <lb/>opaque <lb/>da_addr_body&lt;&gt;; <lb/>}; <lb/>The device address is used to set up a communication channel with the <lb/>storage device. Different layout types will require different data <lb/>types to define how they communicate with storage devices. The <lb/>opaque da_addr_body field is interpreted based on the specified <lb/>da_layout_type field. <lb/>This document defines the device address for the NFSv4.1 file layout <lb/>(see Section 13.3), which identifies a storage device by network IP <lb/>address and port number. This is sufficient for the clients to <lb/>communicate with the NFSv4.1 storage devices, and may be sufficient <lb/>for other layout types as well. Device types for object-based <lb/>storage devices and block storage devices (e.g., Small Computer <lb/>System Interface (SCSI) volume labels) are defined by their <lb/>respective layout specifications. <lb/>3.3.16. layout_content4 <lb/>struct layout_content4 { <lb/>layouttype4 loc_type; <lb/>opaque <lb/>loc_body&lt;&gt;; <lb/>}; <lb/>The loc_body field is interpreted based on the layout type <lb/>(loc_type). This document defines the loc_body for the NFSv4.1 file <lb/>layout type; see Section 13.3 for its definition. <lb/>3.3.17. layout4 <lb/>struct layout4 { <lb/>offset4 <lb/>lo_offset; <lb/>length4 <lb/>lo_length; <lb/>layoutiomode4 <lb/>lo_iomode; <lb/>layout_content4 <lb/>lo_content; <lb/>}; <lb/>The layout4 data type defines a layout for a file. The layout type <lb/>specific data is opaque within lo_content. Since layouts are sub-<lb/>dividable, the offset and length together with the file&apos;s filehandle, <lb/>the client ID, iomode, and layout type identify the layout. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 94] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>3.3.18. layoutupdate4 <lb/>struct layoutupdate4 { <lb/>layouttype4 <lb/>lou_type; <lb/>opaque <lb/>lou_body&lt;&gt;; <lb/>}; <lb/>The layoutupdate4 data type is used by the client to return updated <lb/>layout information to the metadata server via the LAYOUTCOMMIT <lb/>(Section 18.42) operation. This data type provides a channel to pass <lb/>layout type specific information (in field lou_body) back to the <lb/>metadata server. For example, for the block/volume layout type, this <lb/>could include the list of reserved blocks that were written. The <lb/>contents of the opaque lou_body argument are determined by the layout <lb/>type. The NFSv4.1 file-based layout does not use this data type; if <lb/>lou_type is LAYOUT4_NFSV4_1_FILES, the lou_body field MUST have a <lb/>zero length. <lb/>3.3.19. layouthint4 <lb/>struct layouthint4 { <lb/>layouttype4 <lb/>loh_type; <lb/>opaque <lb/>loh_body&lt;&gt;; <lb/>}; <lb/>The layouthint4 data type is used by the client to pass in a hint <lb/>about the type of layout it would like created for a particular file. <lb/>It is the data type specified by the layout_hint attribute described <lb/>in Section 5.12.4. The metadata server may ignore the hint or may <lb/>selectively ignore fields within the hint. This hint should be <lb/>provided at create time as part of the initial attributes within <lb/>OPEN. The loh_body field is specific to the type of layout <lb/>(loh_type). The NFSv4.1 file-based layout uses the <lb/>nfsv4_1_file_layouthint4 data type as defined in Section 13.3. <lb/>3.3.20. layoutiomode4 <lb/>enum layoutiomode4 { <lb/>LAYOUTIOMODE4_READ <lb/>= 1, <lb/>LAYOUTIOMODE4_RW <lb/>= 2, <lb/>LAYOUTIOMODE4_ANY <lb/>= 3 <lb/>}; <lb/>The iomode specifies whether the client intends to just read or both <lb/>read and write the data represented by the layout. While the <lb/>LAYOUTIOMODE4_ANY iomode MUST NOT be used in the arguments to the <lb/>LAYOUTGET operation, it MAY be used in the arguments to the <lb/>LAYOUTRETURN and CB_LAYOUTRECALL operations. The LAYOUTIOMODE4_ANY <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 95] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>iomode specifies that layouts pertaining to both LAYOUTIOMODE4_READ <lb/>and LAYOUTIOMODE4_RW iomodes are being returned or recalled, <lb/>respectively. The metadata server&apos;s use of the iomode may depend on <lb/>the layout type being used. The storage devices MAY validate I/O <lb/>accesses against the iomode and reject invalid accesses. <lb/>3.3.21. nfs_impl_id4 <lb/>struct nfs_impl_id4 { <lb/>utf8str_cis <lb/>nii_domain; <lb/>utf8str_cs <lb/>nii_name; <lb/>nfstime4 <lb/>nii_date; <lb/>}; <lb/>This data type is used to identify client and server implementation <lb/>details. The nii_domain field is the DNS domain name with which the <lb/>implementor is associated. The nii_name field is the product name of <lb/>the implementation and is completely free form. It is RECOMMENDED <lb/>that the nii_name be used to distinguish machine architecture, <lb/>machine platforms, revisions, versions, and patch levels. The <lb/>nii_date field is the timestamp of when the software instance was <lb/>published or built. <lb/>3.3.22. threshold_item4 <lb/>struct threshold_item4 { <lb/>layouttype4 <lb/>thi_layout_type; <lb/>bitmap4 <lb/>thi_hintset; <lb/>opaque <lb/>thi_hintlist&lt;&gt;; <lb/>}; <lb/>This data type contains a list of hints specific to a layout type for <lb/>helping the client determine when it should send I/O directly through <lb/>the metadata server versus the storage devices. The data type <lb/>consists of the layout type (thi_layout_type), a bitmap (thi_hintset) <lb/>describing the set of hints supported by the server (they may differ <lb/>based on the layout type), and a list of hints (thi_hintlist) whose <lb/>content is determined by the hintset bitmap. See the mdsthreshold <lb/>attribute for more details. <lb/>The thi_hintset field is a bitmap of the following values: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 96] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>+-------------------------+---+---------+---------------------------+ <lb/>| name <lb/>| # | Data <lb/>| Description <lb/>| <lb/>| <lb/>| <lb/>| Type <lb/>| <lb/>| <lb/>+-------------------------+---+---------+---------------------------+ <lb/>| threshold4_read_size <lb/>| 0 | length4 | If a file&apos;s length is <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| less than the value of <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| threshold4_read_size, <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| then it is RECOMMENDED <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| that the client read from | <lb/>| <lb/>| <lb/>| <lb/>| the file via the MDS and | <lb/>| <lb/>| <lb/>| <lb/>| not a storage device. <lb/>| <lb/>| threshold4_write_size <lb/>| 1 | length4 | If a file&apos;s length is <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| less than the value of <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| threshold4_write_size, <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| then it is RECOMMENDED <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| that the client write to | <lb/>| <lb/>| <lb/>| <lb/>| the file via the MDS and | <lb/>| <lb/>| <lb/>| <lb/>| not a storage device. <lb/>| <lb/>| threshold4_read_iosize | 2 | length4 | For read I/O sizes below | <lb/>| <lb/>| <lb/>| <lb/>| this threshold, it is <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| RECOMMENDED to read data | <lb/>| <lb/>| <lb/>| <lb/>| through the MDS. <lb/>| <lb/>| threshold4_write_iosize | 3 | length4 | For write I/O sizes below | <lb/>| <lb/>| <lb/>| <lb/>| this threshold, it is <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| RECOMMENDED to write data | <lb/>| <lb/>| <lb/>| <lb/>| through the MDS. <lb/>| <lb/>+-------------------------+---+---------+---------------------------+ <lb/>3.3.23. mdsthreshold4 <lb/>struct mdsthreshold4 { <lb/>threshold_item4 mth_hints&lt;&gt;; <lb/>}; <lb/>This data type holds an array of elements of data type <lb/>threshold_item4, each of which is valid for a particular layout type. <lb/>An array is necessary because a server can support multiple layout <lb/>types for a single file. <lb/>4. Filehandles <lb/>The filehandle in the NFS protocol is a per-server unique identifier <lb/>for a file system object. The contents of the filehandle are opaque <lb/>to the client. Therefore, the server is responsible for translating <lb/>the filehandle to an internal representation of the file system <lb/>object. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 97] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>4.1. Obtaining the First Filehandle <lb/>The operations of the NFS protocol are defined in terms of one or <lb/>more filehandles. Therefore, the client needs a filehandle to <lb/>initiate communication with the server. With the NFSv3 protocol (RFC <lb/>1813 [34]), there exists an ancillary protocol to obtain this first <lb/>filehandle. The MOUNT protocol, RPC program number 100005, provides <lb/>the mechanism of translating a string-based file system pathname to a <lb/>filehandle, which can then be used by the NFS protocols. <lb/>The MOUNT protocol has deficiencies in the area of security and use <lb/>via firewalls. This is one reason that the use of the public <lb/>filehandle was introduced in RFC 2054 [45] and RFC 2055 [46]. With <lb/>the use of the public filehandle in combination with the LOOKUP <lb/>operation in the NFSv3 protocol, it has been demonstrated that the <lb/>MOUNT protocol is unnecessary for viable interaction between NFS <lb/>client and server. <lb/>Therefore, the NFSv4.1 protocol will not use an ancillary protocol <lb/>for translation from string-based pathnames to a filehandle. Two <lb/>special filehandles will be used as starting points for the NFS <lb/>client. <lb/>4.1.1. Root Filehandle <lb/>The first of the special filehandles is the ROOT filehandle. The <lb/>ROOT filehandle is the &quot;conceptual&quot; root of the file system namespace <lb/>at the NFS server. The client uses or starts with the ROOT <lb/>filehandle by employing the PUTROOTFH operation. The PUTROOTFH <lb/>operation instructs the server to set the &quot;current&quot; filehandle to the <lb/>ROOT of the server&apos;s file tree. Once this PUTROOTFH operation is <lb/>used, the client can then traverse the entirety of the server&apos;s file <lb/>tree with the LOOKUP operation. A complete discussion of the server <lb/>namespace is in Section 7. <lb/>4.1.2. Public Filehandle <lb/>The second special filehandle is the PUBLIC filehandle. Unlike the <lb/>ROOT filehandle, the PUBLIC filehandle may be bound or represent an <lb/>arbitrary file system object at the server. The server is <lb/>responsible for this binding. It may be that the PUBLIC filehandle <lb/>and the ROOT filehandle refer to the same file system object. <lb/>However, it is up to the administrative software at the server and <lb/>the policies of the server administrator to define the binding of the <lb/>PUBLIC filehandle and server file system object. The client may not <lb/>make any assumptions about this binding. The client uses the PUBLIC <lb/>filehandle via the PUTPUBFH operation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 98] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>4.2. Filehandle Types <lb/>In the NFSv3 protocol, there was one type of filehandle with a single <lb/>set of semantics. This type of filehandle is termed &quot;persistent&quot; in <lb/>NFSv4.1. The semantics of a persistent filehandle remain the same as <lb/>before. A new type of filehandle introduced in NFSv4.1 is the <lb/>&quot;volatile&quot; filehandle, which attempts to accommodate certain server <lb/>environments. <lb/>The volatile filehandle type was introduced to address server <lb/>functionality or implementation issues that make correct <lb/>implementation of a persistent filehandle infeasible. Some server <lb/>environments do not provide a file-system-level invariant that can be <lb/>used to construct a persistent filehandle. The underlying server <lb/>file system may not provide the invariant or the server&apos;s file system <lb/>programming interfaces may not provide access to the needed <lb/>invariant. Volatile filehandles may ease the implementation of <lb/>server functionality such as hierarchical storage management or file <lb/>system reorganization or migration. However, the volatile filehandle <lb/>increases the implementation burden for the client. <lb/>Since the client will need to handle persistent and volatile <lb/>filehandles differently, a file attribute is defined that may be used <lb/>by the client to determine the filehandle types being returned by the <lb/>server. <lb/>4.2.1. General Properties of a Filehandle <lb/>The filehandle contains all the information the server needs to <lb/>distinguish an individual file. To the client, the filehandle is <lb/>opaque. The client stores filehandles for use in a later request and <lb/>can compare two filehandles from the same server for equality by <lb/>doing a byte-by-byte comparison. However, the client MUST NOT <lb/>otherwise interpret the contents of filehandles. If two filehandles <lb/>from the same server are equal, they MUST refer to the same file. <lb/>Servers SHOULD try to maintain a one-to-one correspondence between <lb/>filehandles and files, but this is not required. Clients MUST use <lb/>filehandle comparisons only to improve performance, not for correct <lb/>behavior. All clients need to be prepared for situations in which it <lb/>cannot be determined whether two filehandles denote the same object <lb/>and in such cases, avoid making invalid assumptions that might cause <lb/>incorrect behavior. Further discussion of filehandle and attribute <lb/>comparison in the context of data caching is presented in <lb/>Section 10.3.4. <lb/>As an example, in the case that two different pathnames when <lb/>traversed at the server terminate at the same file system object, the <lb/>server SHOULD return the same filehandle for each path. This can <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 99] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>occur if a hard link (see [6]) is used to create two file names that <lb/>refer to the same underlying file object and associated data. For <lb/>example, if paths /a/b/c and /a/d/c refer to the same file, the <lb/>server SHOULD return the same filehandle for both pathnames&apos; <lb/>traversals. <lb/>4.2.2. Persistent Filehandle <lb/>A persistent filehandle is defined as having a fixed value for the <lb/>lifetime of the file system object to which it refers. Once the <lb/>server creates the filehandle for a file system object, the server <lb/>MUST accept the same filehandle for the object for the lifetime of <lb/>the object. If the server restarts, the NFS server MUST honor the <lb/>same filehandle value as it did in the server&apos;s previous <lb/>instantiation. Similarly, if the file system is migrated, the new <lb/>NFS server MUST honor the same filehandle as the old NFS server. <lb/>The persistent filehandle will be become stale or invalid when the <lb/>file system object is removed. When the server is presented with a <lb/>persistent filehandle that refers to a deleted object, it MUST return <lb/>an error of NFS4ERR_STALE. A filehandle may become stale when the <lb/>file system containing the object is no longer available. The file <lb/>system may become unavailable if it exists on removable media and the <lb/>media is no longer available at the server or the file system in <lb/>whole has been destroyed or the file system has simply been removed <lb/>from the server&apos;s namespace (i.e., unmounted in a UNIX environment). <lb/>4.2.3. Volatile Filehandle <lb/>A volatile filehandle does not share the same longevity <lb/>characteristics of a persistent filehandle. The server may determine <lb/>that a volatile filehandle is no longer valid at many different <lb/>points in time. If the server can definitively determine that a <lb/>volatile filehandle refers to an object that has been removed, the <lb/>server should return NFS4ERR_STALE to the client (as is the case for <lb/>persistent filehandles). In all other cases where the server <lb/>determines that a volatile filehandle can no longer be used, it <lb/>should return an error of NFS4ERR_FHEXPIRED. <lb/>The REQUIRED attribute &quot;fh_expire_type&quot; is used by the client to <lb/>determine what type of filehandle the server is providing for a <lb/>particular file system. This attribute is a bitmask with the <lb/>following values: <lb/>FH4_PERSISTENT The value of FH4_PERSISTENT is used to indicate a <lb/>persistent filehandle, which is valid until the object is removed <lb/>from the file system. The server will not return <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 100] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>NFS4ERR_FHEXPIRED for this filehandle. FH4_PERSISTENT is defined <lb/>as a value in which none of the bits specified below are set. <lb/>FH4_VOLATILE_ANY The filehandle may expire at any time, except as <lb/>specifically excluded (i.e., FH4_NO_EXPIRE_WITH_OPEN). <lb/>FH4_NOEXPIRE_WITH_OPEN May only be set when FH4_VOLATILE_ANY is set. <lb/>If this bit is set, then the meaning of FH4_VOLATILE_ANY is <lb/>qualified to exclude any expiration of the filehandle when it is <lb/>open. <lb/>FH4_VOL_MIGRATION The filehandle will expire as a result of a file <lb/>system transition (migration or replication), in those cases in <lb/>which the continuity of filehandle use is not specified by handle <lb/>class information within the fs_locations_info attribute. When <lb/>this bit is set, clients without access to fs_locations_info <lb/>information should assume that filehandles will expire on file <lb/>system transitions. <lb/>FH4_VOL_RENAME The filehandle will expire during rename. This <lb/>includes a rename by the requesting client or a rename by any <lb/>other client. If FH4_VOL_ANY is set, FH4_VOL_RENAME is redundant. <lb/>Servers that provide volatile filehandles that can expire while open <lb/>require special care as regards handling of RENAMEs and REMOVEs. <lb/>This situation can arise if FH4_VOL_MIGRATION or FH4_VOL_RENAME is <lb/>set, if FH4_VOLATILE_ANY is set and FH4_NOEXPIRE_WITH_OPEN is not <lb/>set, or if a non-read-only file system has a transition target in a <lb/>different handle class. In these cases, the server should deny a <lb/>RENAME or REMOVE that would affect an OPEN file of any of the <lb/>components leading to the OPEN file. In addition, the server should <lb/>deny all RENAME or REMOVE requests during the grace period, in order <lb/>to make sure that reclaims of files where filehandles may have <lb/>expired do not do a reclaim for the wrong file. <lb/>Volatile filehandles are especially suitable for implementation of <lb/>the pseudo file systems used to bridge exports. See Section 7.5 for <lb/>a discussion of this. <lb/>4.3. One Method of Constructing a Volatile Filehandle <lb/>A volatile filehandle, while opaque to the client, could contain: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 101] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>[volatile bit = 1 | server boot time | slot | generation number] <lb/>o slot is an index in the server volatile filehandle table <lb/>o generation number is the generation number for the table entry/ <lb/>slot <lb/>When the client presents a volatile filehandle, the server makes the <lb/>following checks, which assume that the check for the volatile bit <lb/>has passed. If the server boot time is less than the current server <lb/>boot time, return NFS4ERR_FHEXPIRED. If slot is out of range, return <lb/>NFS4ERR_BADHANDLE. If the generation number does not match, return <lb/>NFS4ERR_FHEXPIRED. <lb/>When the server restarts, the table is gone (it is volatile). <lb/>If the volatile bit is 0, then it is a persistent filehandle with a <lb/>different structure following it. <lb/>4.4. Client Recovery from Filehandle Expiration <lb/>If possible, the client SHOULD recover from the receipt of an <lb/>NFS4ERR_FHEXPIRED error. The client must take on additional <lb/>responsibility so that it may prepare itself to recover from the <lb/>expiration of a volatile filehandle. If the server returns <lb/>persistent filehandles, the client does not need these additional <lb/>steps. <lb/>For volatile filehandles, most commonly the client will need to store <lb/>the component names leading up to and including the file system <lb/>object in question. With these names, the client should be able to <lb/>recover by finding a filehandle in the namespace that is still <lb/>available or by starting at the root of the server&apos;s file system <lb/>namespace. <lb/>If the expired filehandle refers to an object that has been removed <lb/>from the file system, obviously the client will not be able to <lb/>recover from the expired filehandle. <lb/>It is also possible that the expired filehandle refers to a file that <lb/>has been renamed. If the file was renamed by another client, again <lb/>it is possible that the original client will not be able to recover. <lb/>However, in the case that the client itself is renaming the file and <lb/>the file is open, it is possible that the client may be able to <lb/>recover. The client can determine the new pathname based on the <lb/>processing of the rename request. The client can then regenerate the <lb/>new filehandle based on the new pathname. The client could also use <lb/>the COMPOUND procedure to construct a series of operations like: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 102] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>RENAME A B <lb/>LOOKUP B <lb/>GETFH <lb/>Note that the COMPOUND procedure does not provide atomicity. This <lb/>example only reduces the overhead of recovering from an expired <lb/>filehandle. <lb/>5. File Attributes <lb/>To meet the requirements of extensibility and increased <lb/>interoperability with non-UNIX platforms, attributes need to be <lb/>handled in a flexible manner. The NFSv3 fattr3 structure contains a <lb/>fixed list of attributes that not all clients and servers are able to <lb/>support or care about. The fattr3 structure cannot be extended as <lb/>new needs arise and it provides no way to indicate non-support. With <lb/>the NFSv4.1 protocol, the client is able to query what attributes the <lb/>server supports and construct requests with only those supported <lb/>attributes (or a subset thereof). <lb/>To this end, attributes are divided into three groups: REQUIRED, <lb/>RECOMMENDED, and named. Both REQUIRED and RECOMMENDED attributes are <lb/>supported in the NFSv4.1 protocol by a specific and well-defined <lb/>encoding and are identified by number. They are requested by setting <lb/>a bit in the bit vector sent in the GETATTR request; the server <lb/>response includes a bit vector to list what attributes were returned <lb/>in the response. New REQUIRED or RECOMMENDED attributes may be added <lb/>to the NFSv4 protocol as part of a new minor version by publishing a <lb/>Standards Track RFC that allocates a new attribute number value and <lb/>defines the encoding for the attribute. See Section 2.7 for further <lb/>discussion. <lb/>Named attributes are accessed by the new OPENATTR operation, which <lb/>accesses a hidden directory of attributes associated with a file <lb/>system object. OPENATTR takes a filehandle for the object and <lb/>returns the filehandle for the attribute hierarchy. The filehandle <lb/>for the named attributes is a directory object accessible by LOOKUP <lb/>or READDIR and contains files whose names represent the named <lb/>attributes and whose data bytes are the value of the attribute. For <lb/>example: <lb/>+----------+-----------+---------------------------------+ <lb/>| LOOKUP <lb/>| &quot;foo&quot; <lb/>| ; look up file <lb/>| <lb/>| GETATTR | attrbits | <lb/>| <lb/>| OPENATTR | <lb/>| ; access foo&apos;s named attributes | <lb/>| LOOKUP <lb/>| &quot;x11icon&quot; | ; look up specific attribute <lb/>| <lb/>| READ <lb/>| 0,4096 <lb/>| ; read stream of bytes <lb/>| <lb/>+----------+-----------+---------------------------------+ <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 103] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Named attributes are intended for data needed by applications rather <lb/>than by an NFS client implementation. NFS implementors are strongly <lb/>encouraged to define their new attributes as RECOMMENDED attributes <lb/>by bringing them to the IETF Standards Track process. <lb/>The set of attributes that are classified as REQUIRED is deliberately <lb/>small since servers need to do whatever it takes to support them. A <lb/>server should support as many of the RECOMMENDED attributes as <lb/>possible but, by their definition, the server is not required to <lb/>support all of them. Attributes are deemed REQUIRED if the data is <lb/>both needed by a large number of clients and is not otherwise <lb/>reasonably computable by the client when support is not provided on <lb/>the server. <lb/>Note that the hidden directory returned by OPENATTR is a convenience <lb/>for protocol processing. The client should not make any assumptions <lb/>about the server&apos;s implementation of named attributes and whether or <lb/>not the underlying file system at the server has a named attribute <lb/>directory. Therefore, operations such as SETATTR and GETATTR on the <lb/>named attribute directory are undefined. <lb/>5.1. REQUIRED Attributes <lb/>These MUST be supported by every NFSv4.1 client and server in order <lb/>to ensure a minimum level of interoperability. The server MUST store <lb/>and return these attributes, and the client MUST be able to function <lb/>with an attribute set limited to these attributes. With just the <lb/>REQUIRED attributes some client functionality may be impaired or <lb/>limited in some ways. A client may ask for any of these attributes <lb/>to be returned by setting a bit in the GETATTR request, and the <lb/>server MUST return their value. <lb/>5.2. RECOMMENDED Attributes <lb/>These attributes are understood well enough to warrant support in the <lb/>NFSv4.1 protocol. However, they may not be supported on all clients <lb/>and servers. A client may ask for any of these attributes to be <lb/>returned by setting a bit in the GETATTR request but must handle the <lb/>case where the server does not return them. A client MAY ask for the <lb/>set of attributes the server supports and SHOULD NOT request <lb/>attributes the server does not support. A server should be tolerant <lb/>of requests for unsupported attributes and simply not return them <lb/>rather than considering the request an error. It is expected that <lb/>servers will support all attributes they comfortably can and only <lb/>fail to support attributes that are difficult to support in their <lb/>operating environments. A server should provide attributes whenever <lb/>they don&apos;t have to &quot;tell lies&quot; to the client. For example, a file <lb/>modification time should be either an accurate time or should not be <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 104] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>supported by the server. At times this will be difficult for <lb/>clients, but a client is better positioned to decide whether and how <lb/>to fabricate or construct an attribute or whether to do without the <lb/>attribute. <lb/>5.3. Named Attributes <lb/>These attributes are not supported by direct encoding in the NFSv4 <lb/>protocol but are accessed by string names rather than numbers and <lb/>correspond to an uninterpreted stream of bytes that are stored with <lb/>the file system object. The namespace for these attributes may be <lb/>accessed by using the OPENATTR operation. The OPENATTR operation <lb/>returns a filehandle for a virtual &quot;named attribute directory&quot;, and <lb/>further perusal and modification of the namespace may be done using <lb/>operations that work on more typical directories. In particular, <lb/>READDIR may be used to get a list of such named attributes, and <lb/>LOOKUP and OPEN may select a particular attribute. Creation of a new <lb/>named attribute may be the result of an OPEN specifying file <lb/>creation. <lb/>Once an OPEN is done, named attributes may be examined and changed by <lb/>normal READ and WRITE operations using the filehandles and stateids <lb/>returned by OPEN. <lb/>Named attributes and the named attribute directory may have their own <lb/>(non-named) attributes. Each of these objects MUST have all of the <lb/>REQUIRED attributes and may have additional RECOMMENDED attributes. <lb/>However, the set of attributes for named attributes and the named <lb/>attribute directory need not be, and typically will not be, as large <lb/>as that for other objects in that file system. <lb/>Named attributes and the named attribute directory might be the <lb/>target of delegations (in the case of the named attribute directory, <lb/>these will be directory delegations). However, since granting <lb/>delegations is at the server&apos;s discretion, a server need not support <lb/>delegations on named attributes or the named attribute directory. <lb/>It is RECOMMENDED that servers support arbitrary named attributes. A <lb/>client should not depend on the ability to store any named attributes <lb/>in the server&apos;s file system. If a server does support named <lb/>attributes, a client that is also able to handle them should be able <lb/>to copy a file&apos;s data and metadata with complete transparency from <lb/>one location to another; this would imply that names allowed for <lb/>regular directory entries are valid for named attribute names as <lb/>well. <lb/>In NFSv4.1, the structure of named attribute directories is <lb/>restricted in a number of ways, in order to prevent the development <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 105] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>of non-interoperable implementations in which some servers support a <lb/>fully general hierarchical directory structure for named attributes <lb/>while others support a limited but adequate structure for named <lb/>attributes. In such an environment, clients or applications might <lb/>come to depend on non-portable extensions. The restrictions are: <lb/>o CREATE is not allowed in a named attribute directory. Thus, such <lb/>objects as symbolic links and special files are not allowed to be <lb/>named attributes. Further, directories may not be created in a <lb/>named attribute directory, so no hierarchical structure of named <lb/>attributes for a single object is allowed. <lb/>o If OPENATTR is done on a named attribute directory or on a named <lb/>attribute, the server MUST return NFS4ERR_WRONG_TYPE. <lb/>o Doing a RENAME of a named attribute to a different named attribute <lb/>directory or to an ordinary (i.e., non-named-attribute) directory <lb/>is not allowed. <lb/>o Creating hard links between named attribute directories or between <lb/>named attribute directories and ordinary directories is not <lb/>allowed. <lb/>Names of attributes will not be controlled by this document or other <lb/>IETF Standards Track documents. See Section 22.2 for further <lb/>discussion. <lb/>5.4. Classification of Attributes <lb/>Each of the REQUIRED and RECOMMENDED attributes can be classified in <lb/>one of three categories: per server (i.e., the value of the attribute <lb/>will be the same for all file objects that share the same server <lb/>owner; see Section 2.5 for a definition of server owner), per file <lb/>system (i.e., the value of the attribute will be the same for some or <lb/>all file objects that share the same fsid attribute (Section 5.8.1.9) <lb/>and server owner), or per file system object. Note that it is <lb/>possible that some per file system attributes may vary within the <lb/>file system, depending on the value of the &quot;homogeneous&quot; <lb/>(Section 5.8.2.16) attribute. Note that the attributes <lb/>time_access_set and time_modify_set are not listed in this section <lb/>because they are write-only attributes corresponding to time_access <lb/>and time_modify, and are used in a special instance of SETATTR. <lb/>o The per-server attribute is: <lb/>lease_time <lb/>o The per-file system attributes are: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 106] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>supported_attrs, suppattr_exclcreat, fh_expire_type, <lb/>link_support, symlink_support, unique_handles, aclsupport, <lb/>cansettime, case_insensitive, case_preserving, <lb/>chown_restricted, files_avail, files_free, files_total, <lb/>fs_locations, homogeneous, maxfilesize, maxname, maxread, <lb/>maxwrite, no_trunc, space_avail, space_free, space_total, <lb/>time_delta, change_policy, fs_status, fs_layout_type, <lb/>fs_locations_info, fs_charset_cap <lb/>o The per-file system object attributes are: <lb/>type, change, size, named_attr, fsid, rdattr_error, filehandle, <lb/>acl, archive, fileid, hidden, maxlink, mimetype, mode, <lb/>numlinks, owner, owner_group, rawdev, space_used, system, <lb/>time_access, time_backup, time_create, time_metadata, <lb/>time_modify, mounted_on_fileid, dir_notif_delay, <lb/>dirent_notif_delay, dacl, sacl, layout_type, layout_hint, <lb/>layout_blksize, layout_alignment, mdsthreshold, retention_get, <lb/>retention_set, retentevt_get, retentevt_set, retention_hold, <lb/>mode_set_masked <lb/>For quota_avail_hard, quota_avail_soft, and quota_used, see their <lb/>definitions below for the appropriate classification. <lb/>5.5. Set-Only and Get-Only Attributes <lb/>Some REQUIRED and RECOMMENDED attributes are set-only; i.e., they can <lb/>be set via SETATTR but not retrieved via GETATTR. Similarly, some <lb/>REQUIRED and RECOMMENDED attributes are get-only; i.e., they can be <lb/>retrieved via GETATTR but not set via SETATTR. If a client attempts <lb/>to set a get-only attribute or get a set-only attributes, the server <lb/>MUST return NFS4ERR_INVAL. <lb/>5.6. REQUIRED Attributes -List and Definition References <lb/>The list of REQUIRED attributes appears in Table 2. The meaning of <lb/>the columns of the table are: <lb/>o Name: The name of the attribute. <lb/>o Id: The number assigned to the attribute. In the event of <lb/>conflicts between the assigned number and [10], the latter is <lb/>likely authoritative, but should be resolved with Errata to this <lb/>document and/or [10]. See [47] for the Errata process. <lb/>o Data Type: The XDR data type of the attribute. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 107] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o Acc: Access allowed to the attribute. R means read-only (GETATTR <lb/>may retrieve, SETATTR may not set). W means write-only (SETATTR <lb/>may set, GETATTR may not retrieve). R W means read/write (GETATTR <lb/>may retrieve, SETATTR may set). <lb/>o Defined in: The section of this specification that describes the <lb/>attribute. <lb/>+--------------------+----+------------+-----+-------------------+ <lb/>| Name <lb/>| Id | Data Type | Acc | Defined in: <lb/>| <lb/>+--------------------+----+------------+-----+-------------------+ <lb/>| supported_attrs <lb/>| 0 | bitmap4 <lb/>| R <lb/>| Section 5.8.1.1 <lb/>| <lb/>| type <lb/>| 1 | nfs_ftype4 | R <lb/>| Section 5.8.1.2 <lb/>| <lb/>| fh_expire_type <lb/>| 2 | uint32_t <lb/>| R <lb/>| Section 5.8.1.3 <lb/>| <lb/>| change <lb/>| 3 | uint64_t <lb/>| R <lb/>| Section 5.8.1.4 <lb/>| <lb/>| size <lb/>| 4 | uint64_t <lb/>| R W | Section 5.8.1.5 <lb/>| <lb/>| link_support <lb/>| 5 | bool <lb/>| R <lb/>| Section 5.8.1.6 <lb/>| <lb/>| symlink_support <lb/>| 6 | bool <lb/>| R <lb/>| Section 5.8.1.7 <lb/>| <lb/>| named_attr <lb/>| 7 | bool <lb/>| R <lb/>| Section 5.8.1.8 <lb/>| <lb/>| fsid <lb/>| 8 | fsid4 <lb/>| R <lb/>| Section 5.8.1.9 <lb/>| <lb/>| unique_handles <lb/>| 9 | bool <lb/>| R <lb/>| Section 5.8.1.10 | <lb/>| lease_time <lb/>| 10 | nfs_lease4 | R <lb/>| Section 5.8.1.11 | <lb/>| rdattr_error <lb/>| 11 | enum <lb/>| R <lb/>| Section 5.8.1.12 | <lb/>| filehandle <lb/>| 19 | nfs_fh4 <lb/>| R <lb/>| Section 5.8.1.13 | <lb/>| suppattr_exclcreat | 75 | bitmap4 <lb/>| R <lb/>| Section 5.8.1.14 | <lb/>+--------------------+----+------------+-----+-------------------+ <lb/>Table 2 <lb/>5.7. RECOMMENDED Attributes -List and Definition References <lb/>The RECOMMENDED attributes are defined in Table 3. The meanings of <lb/>the column headers are the same as Table 2; see Section 5.6 for the <lb/>meanings. <lb/>+--------------------+----+----------------+-----+------------------+ <lb/>| Name <lb/>| Id | Data Type <lb/>| Acc | Defined in: <lb/>| <lb/>+--------------------+----+----------------+-----+------------------+ <lb/>| acl <lb/>| 12 | nfsace4&lt;&gt; <lb/>| R W | Section 6.2.1 <lb/>| <lb/>| aclsupport <lb/>| 13 | uint32_t <lb/>| R <lb/>| Section 6.2.1.2 | <lb/>| archive <lb/>| 14 | bool <lb/>| R W | Section 5.8.2.1 | <lb/>| cansettime <lb/>| 15 | bool <lb/>| R <lb/>| Section 5.8.2.2 | <lb/>| case_insensitive <lb/>| 16 | bool <lb/>| R <lb/>| Section 5.8.2.3 | <lb/>| case_preserving <lb/>| 17 | bool <lb/>| R <lb/>| Section 5.8.2.4 | <lb/>| change_policy <lb/>| 60 | chg_policy4 <lb/>| R <lb/>| Section 5.8.2.5 | <lb/>| chown_restricted <lb/>| 18 | bool <lb/>| R <lb/>| Section 5.8.2.6 | <lb/>| dacl <lb/>| 58 | nfsacl41 <lb/>| R W | Section 6.2.2 <lb/>| <lb/>| dir_notif_delay <lb/>| 56 | nfstime4 <lb/>| R <lb/>| Section 5.11.1 <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 108] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| dirent_notif_delay | 57 | nfstime4 <lb/>| R <lb/>| Section 5.11.2 <lb/>| <lb/>| fileid <lb/>| 20 | uint64_t <lb/>| R <lb/>| Section 5.8.2.7 | <lb/>| files_avail <lb/>| 21 | uint64_t <lb/>| R <lb/>| Section 5.8.2.8 | <lb/>| files_free <lb/>| 22 | uint64_t <lb/>| R <lb/>| Section 5.8.2.9 | <lb/>| files_total <lb/>| 23 | uint64_t <lb/>| R <lb/>| Section 5.8.2.10 | <lb/>| fs_charset_cap <lb/>| 76 | uint32_t <lb/>| R <lb/>| Section 5.8.2.11 | <lb/>| fs_layout_type <lb/>| 62 | layouttype4&lt;&gt; | R <lb/>| Section 5.12.1 <lb/>| <lb/>| fs_locations <lb/>| 24 | fs_locations <lb/>| R <lb/>| Section 5.8.2.12 | <lb/>| fs_locations_info | 67 | * <lb/>| R <lb/>| Section 5.8.2.13 | <lb/>| fs_status <lb/>| 61 | fs4_status <lb/>| R <lb/>| Section 5.8.2.14 | <lb/>| hidden <lb/>| 25 | bool <lb/>| R W | Section 5.8.2.15 | <lb/>| homogeneous <lb/>| 26 | bool <lb/>| R <lb/>| Section 5.8.2.16 | <lb/>| layout_alignment <lb/>| 66 | uint32_t <lb/>| R <lb/>| Section 5.12.2 <lb/>| <lb/>| layout_blksize <lb/>| 65 | uint32_t <lb/>| R <lb/>| Section 5.12.3 <lb/>| <lb/>| layout_hint <lb/>| 63 | layouthint4 <lb/>| W <lb/>| Section 5.12.4 <lb/>| <lb/>| layout_type <lb/>| 64 | layouttype4&lt;&gt; | R <lb/>| Section 5.12.5 <lb/>| <lb/>| maxfilesize <lb/>| 27 | uint64_t <lb/>| R <lb/>| Section 5.8.2.17 | <lb/>| maxlink <lb/>| 28 | uint32_t <lb/>| R <lb/>| Section 5.8.2.18 | <lb/>| maxname <lb/>| 29 | uint32_t <lb/>| R <lb/>| Section 5.8.2.19 | <lb/>| maxread <lb/>| 30 | uint64_t <lb/>| R <lb/>| Section 5.8.2.20 | <lb/>| maxwrite <lb/>| 31 | uint64_t <lb/>| R <lb/>| Section 5.8.2.21 | <lb/>| mdsthreshold <lb/>| 68 | mdsthreshold4 | R <lb/>| Section 5.12.6 <lb/>| <lb/>| mimetype <lb/>| 32 | utf8str_cs <lb/>| R W | Section 5.8.2.22 | <lb/>| mode <lb/>| 33 | mode4 <lb/>| R W | Section 6.2.4 <lb/>| <lb/>| mode_set_masked <lb/>| 74 | mode_masked4 <lb/>| W <lb/>| Section 6.2.5 <lb/>| <lb/>| mounted_on_fileid | 55 | uint64_t <lb/>| R <lb/>| Section 5.8.2.23 | <lb/>| no_trunc <lb/>| 34 | bool <lb/>| R <lb/>| Section 5.8.2.24 | <lb/>| numlinks <lb/>| 35 | uint32_t <lb/>| R <lb/>| Section 5.8.2.25 | <lb/>| owner <lb/>| 36 | utf8str_mixed | R W | Section 5.8.2.26 | <lb/>| owner_group <lb/>| 37 | utf8str_mixed | R W | Section 5.8.2.27 | <lb/>| quota_avail_hard <lb/>| 38 | uint64_t <lb/>| R <lb/>| Section 5.8.2.28 | <lb/>| quota_avail_soft <lb/>| 39 | uint64_t <lb/>| R <lb/>| Section 5.8.2.29 | <lb/>| quota_used <lb/>| 40 | uint64_t <lb/>| R <lb/>| Section 5.8.2.30 | <lb/>| rawdev <lb/>| 41 | specdata4 <lb/>| R <lb/>| Section 5.8.2.31 | <lb/>| retentevt_get <lb/>| 71 | retention_get4 | R <lb/>| Section 5.13.3 <lb/>| <lb/>| retentevt_set <lb/>| 72 | retention_set4 | W <lb/>| Section 5.13.4 <lb/>| <lb/>| retention_get <lb/>| 69 | retention_get4 | R <lb/>| Section 5.13.1 <lb/>| <lb/>| retention_hold <lb/>| 73 | uint64_t <lb/>| R W | Section 5.13.5 <lb/>| <lb/>| retention_set <lb/>| 70 | retention_set4 | W <lb/>| Section 5.13.2 <lb/>| <lb/>| sacl <lb/>| 59 | nfsacl41 <lb/>| R W | Section 6.2.3 <lb/>| <lb/>| space_avail <lb/>| 42 | uint64_t <lb/>| R <lb/>| Section 5.8.2.32 | <lb/>| space_free <lb/>| 43 | uint64_t <lb/>| R <lb/>| Section 5.8.2.33 | <lb/>| space_total <lb/>| 44 | uint64_t <lb/>| R <lb/>| Section 5.8.2.34 | <lb/>| space_used <lb/>| 45 | uint64_t <lb/>| R <lb/>| Section 5.8.2.35 | <lb/>| system <lb/>| 46 | bool <lb/>| R W | Section 5.8.2.36 | <lb/>| time_access <lb/>| 47 | nfstime4 <lb/>| R <lb/>| Section 5.8.2.37 | <lb/>| time_access_set <lb/>| 48 | settime4 <lb/>| W <lb/>| Section 5.8.2.38 | <lb/>| time_backup <lb/>| 49 | nfstime4 <lb/>| R W | Section 5.8.2.39 | <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 109] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| time_create <lb/>| 50 | nfstime4 <lb/>| R W | Section 5.8.2.40 | <lb/>| time_delta <lb/>| 51 | nfstime4 <lb/>| R <lb/>| Section 5.8.2.41 | <lb/>| time_metadata <lb/>| 52 | nfstime4 <lb/>| R <lb/>| Section 5.8.2.42 | <lb/>| time_modify <lb/>| 53 | nfstime4 <lb/>| R <lb/>| Section 5.8.2.43 | <lb/>| time_modify_set <lb/>| 54 | settime4 <lb/>| W <lb/>| Section 5.8.2.44 | <lb/>+--------------------+----+----------------+-----+------------------+ <lb/>Table 3 <lb/>* fs_locations_info4 <lb/>5.8. Attribute Definitions <lb/>5.8.1. Definitions of REQUIRED Attributes <lb/>5.8.1.1. Attribute 0: supported_attrs <lb/>The bit vector that would retrieve all REQUIRED and RECOMMENDED <lb/>attributes that are supported for this object. The scope of this <lb/>attribute applies to all objects with a matching fsid. <lb/>5.8.1.2. Attribute 1: type <lb/>Designates the type of an object in terms of one of a number of <lb/>special constants: <lb/>o NF4REG designates a regular file. <lb/>o NF4DIR designates a directory. <lb/>o NF4BLK designates a block device special file. <lb/>o NF4CHR designates a character device special file. <lb/>o NF4LNK designates a symbolic link. <lb/>o NF4SOCK designates a named socket special file. <lb/>o NF4FIFO designates a fifo special file. <lb/>o NF4ATTRDIR designates a named attribute directory. <lb/>o NF4NAMEDATTR designates a named attribute. <lb/>Within the explanatory text and operation descriptions, the following <lb/>phrases will be used with the meanings given below: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 110] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o The phrase &quot;is a directory&quot; means that the object&apos;s type attribute <lb/>is NF4DIR or NF4ATTRDIR. <lb/>o The phrase &quot;is a special file&quot; means that the object&apos;s type <lb/>attribute is NF4BLK, NF4CHR, NF4SOCK, or NF4FIFO. <lb/>o The phrases &quot;is an ordinary file&quot; and &quot;is a regular file&quot; mean <lb/>that the object&apos;s type attribute is NF4REG or NF4NAMEDATTR. <lb/>5.8.1.3. Attribute 2: fh_expire_type <lb/>Server uses this to specify filehandle expiration behavior to the <lb/>client. See Section 4 for additional description. <lb/>5.8.1.4. Attribute 3: change <lb/>A value created by the server that the client can use to determine if <lb/>file data, directory contents, or attributes of the object have been <lb/>modified. The server may return the object&apos;s time_metadata attribute <lb/>for this attribute&apos;s value, but only if the file system object cannot <lb/>be updated more frequently than the resolution of time_metadata. <lb/>5.8.1.5. Attribute 4: size <lb/>The size of the object in bytes. <lb/>5.8.1.6. Attribute 5: link_support <lb/>TRUE, if the object&apos;s file system supports hard links. <lb/>5.8.1.7. Attribute 6: symlink_support <lb/>TRUE, if the object&apos;s file system supports symbolic links. <lb/>5.8.1.8. Attribute 7: named_attr <lb/>TRUE, if this object has named attributes. In other words, object <lb/>has a non-empty named attribute directory. <lb/>5.8.1.9. Attribute 8: fsid <lb/>Unique file system identifier for the file system holding this <lb/>object. The fsid attribute has major and minor components, each of <lb/>which are of data type uint64_t. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 111] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>5.8.1.10. Attribute 9: unique_handles <lb/>TRUE, if two distinct filehandles are guaranteed to refer to two <lb/>different file system objects. <lb/>5.8.1.11. Attribute 10: lease_time <lb/>Duration of the lease at server in seconds. <lb/>5.8.1.12. Attribute 11: rdattr_error <lb/>Error returned from an attempt to retrieve attributes during a <lb/>READDIR operation. <lb/>5.8.1.13. Attribute 19: filehandle <lb/>The filehandle of this object (primarily for READDIR requests). <lb/>5.8.1.14. Attribute 75: suppattr_exclcreat <lb/>The bit vector that would set all REQUIRED and RECOMMENDED attributes <lb/>that are supported by the EXCLUSIVE4_1 method of file creation via <lb/>the OPEN operation. The scope of this attribute applies to all <lb/>objects with a matching fsid. <lb/>5.8.2. Definitions of Uncategorized RECOMMENDED Attributes <lb/>The definitions of most of the RECOMMENDED attributes follow. <lb/>Collections that share a common category are defined in other <lb/>sections. <lb/>5.8.2.1. Attribute 14: archive <lb/>TRUE, if this file has been archived since the time of last <lb/>modification (deprecated in favor of time_backup). <lb/>5.8.2.2. Attribute 15: cansettime <lb/>TRUE, if the server is able to change the times for a file system <lb/>object as specified in a SETATTR operation. <lb/>5.8.2.3. Attribute 16: case_insensitive <lb/>TRUE, if file name comparisons on this file system are case <lb/>insensitive. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 112] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>5.8.2.4. Attribute 17: case_preserving <lb/>TRUE, if file name case on this file system is preserved. <lb/>5.8.2.5. Attribute 60: change_policy <lb/>A value created by the server that the client can use to determine if <lb/>some server policy related to the current file system has been <lb/>subject to change. If the value remains the same, then the client <lb/>can be sure that the values of the attributes related to fs location <lb/>and the fss_type field of the fs_status attribute have not changed. <lb/>On the other hand, a change in this value does necessarily imply a <lb/>change in policy. It is up to the client to interrogate the server <lb/>to determine if some policy relevant to it has changed. See <lb/>Section 3.3.6 for details. <lb/>This attribute MUST change when the value returned by the <lb/>fs_locations or fs_locations_info attribute changes, when a file <lb/>system goes from read-only to writable or vice versa, or when the <lb/>allowable set of security flavors for the file system or any part <lb/>thereof is changed. <lb/>5.8.2.6. Attribute 18: chown_restricted <lb/>If TRUE, the server will reject any request to change either the <lb/>owner or the group associated with a file if the caller is not a <lb/>privileged user (for example, &quot;root&quot; in UNIX operating environments <lb/>or, in Windows 2000, the &quot;Take Ownership&quot; privilege). <lb/>5.8.2.7. Attribute 20: fileid <lb/>A number uniquely identifying the file within the file system. <lb/>5.8.2.8. Attribute 21: files_avail <lb/>File slots available to this user on the file system containing this <lb/>object --this should be the smallest relevant limit. <lb/>5.8.2.9. Attribute 22: files_free <lb/>Free file slots on the file system containing this object --this <lb/>should be the smallest relevant limit. <lb/>5.8.2.10. Attribute 23: files_total <lb/>Total file slots on the file system containing this object. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 113] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>5.8.2.11. Attribute 76: fs_charset_cap <lb/>Character set capabilities for this file system. See Section 14.4. <lb/>5.8.2.12. Attribute 24: fs_locations <lb/>Locations where this file system may be found. If the server returns <lb/>NFS4ERR_MOVED as an error, this attribute MUST be supported. See <lb/>Section 11.15 for more details. <lb/>5.8.2.13. Attribute 67: fs_locations_info <lb/>Full function file system location. See Section 11.16.2 for more <lb/>details. <lb/>5.8.2.14. Attribute 61: fs_status <lb/>Generic file system type information. See Section 11.17 for more <lb/>details. <lb/>5.8.2.15. Attribute 25: hidden <lb/>TRUE, if the file is considered hidden with respect to the Windows <lb/>API. <lb/>5.8.2.16. Attribute 26: homogeneous <lb/>TRUE, if this object&apos;s file system is homogeneous; i.e., all objects <lb/>in the file system (all objects on the server with the same fsid) <lb/>have common values for all per-file-system attributes. <lb/>5.8.2.17. Attribute 27: maxfilesize <lb/>Maximum supported file size for the file system of this object. <lb/>5.8.2.18. Attribute 28: maxlink <lb/>Maximum number of links for this object. <lb/>5.8.2.19. Attribute 29: maxname <lb/>Maximum file name size supported for this object. <lb/>5.8.2.20. Attribute 30: maxread <lb/>Maximum amount of data the READ operation will return for this <lb/>object. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 114] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>5.8.2.21. Attribute 31: maxwrite <lb/>Maximum amount of data the WRITE operation will accept for this <lb/>object. This attribute SHOULD be supported if the file is writable. <lb/>Lack of this attribute can lead to the client either wasting <lb/>bandwidth or not receiving the best performance. <lb/>5.8.2.22. Attribute 32: mimetype <lb/>MIME body type/subtype of this object. <lb/>5.8.2.23. Attribute 55: mounted_on_fileid <lb/>Like fileid, but if the target filehandle is the root of a file <lb/>system, this attribute represents the fileid of the underlying <lb/>directory. <lb/>UNIX-based operating environments connect a file system into the <lb/>namespace by connecting (mounting) the file system onto the existing <lb/>file object (the mount point, usually a directory) of an existing <lb/>file system. When the mount point&apos;s parent directory is read via an <lb/>API like readdir(), the return results are directory entries, each <lb/>with a component name and a fileid. The fileid of the mount point&apos;s <lb/>directory entry will be different from the fileid that the stat() <lb/>system call returns. The stat() system call is returning the fileid <lb/>of the root of the mounted file system, whereas readdir() is <lb/>returning the fileid that stat() would have returned before any file <lb/>systems were mounted on the mount point. <lb/>Unlike NFSv3, NFSv4.1 allows a client&apos;s LOOKUP request to cross other <lb/>file systems. The client detects the file system crossing whenever <lb/>the filehandle argument of LOOKUP has an fsid attribute different <lb/>from that of the filehandle returned by LOOKUP. A UNIX-based client <lb/>will consider this a &quot;mount point crossing&quot;. UNIX has a legacy <lb/>scheme for allowing a process to determine its current working <lb/>directory. This relies on readdir() of a mount point&apos;s parent and <lb/>stat() of the mount point returning fileids as previously described. <lb/>The mounted_on_fileid attribute corresponds to the fileid that <lb/>readdir() would have returned as described previously. <lb/>While the NFSv4.1 client could simply fabricate a fileid <lb/>corresponding to what mounted_on_fileid provides (and if the server <lb/>does not support mounted_on_fileid, the client has no choice), there <lb/>is a risk that the client will generate a fileid that conflicts with <lb/>one that is already assigned to another object in the file system. <lb/>Instead, if the server can provide the mounted_on_fileid, the <lb/>potential for client operational problems in this area is eliminated. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 115] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If the server detects that there is no mounted point at the target <lb/>file object, then the value for mounted_on_fileid that it returns is <lb/>the same as that of the fileid attribute. <lb/>The mounted_on_fileid attribute is RECOMMENDED, so the server SHOULD <lb/>provide it if possible, and for a UNIX-based server, this is <lb/>straightforward. Usually, mounted_on_fileid will be requested during <lb/>a READDIR operation, in which case it is trivial (at least for UNIX-<lb/>based servers) to return mounted_on_fileid since it is equal to the <lb/>fileid of a directory entry returned by readdir(). If <lb/>mounted_on_fileid is requested in a GETATTR operation, the server <lb/>should obey an invariant that has it returning a value that is equal <lb/>to the file object&apos;s entry in the object&apos;s parent directory, i.e., <lb/>what readdir() would have returned. Some operating environments <lb/>allow a series of two or more file systems to be mounted onto a <lb/>single mount point. In this case, for the server to obey the <lb/>aforementioned invariant, it will need to find the base mount point, <lb/>and not the intermediate mount points. <lb/>5.8.2.24. Attribute 34: no_trunc <lb/>If this attribute is TRUE, then if the client uses a file name longer <lb/>than name_max, an error will be returned instead of the name being <lb/>truncated. <lb/>5.8.2.25. Attribute 35: numlinks <lb/>Number of hard links to this object. <lb/>5.8.2.26. Attribute 36: owner <lb/>The string name of the owner of this object. <lb/>5.8.2.27. Attribute 37: owner_group <lb/>The string name of the group ownership of this object. <lb/>5.8.2.28. Attribute 38: quota_avail_hard <lb/>The value in bytes that represents the amount of additional disk <lb/>space beyond the current allocation that can be allocated to this <lb/>file or directory before further allocations will be refused. It is <lb/>understood that this space may be consumed by allocations to other <lb/>files or directories. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 116] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>5.8.2.29. Attribute 39: quota_avail_soft <lb/>The value in bytes that represents the amount of additional disk <lb/>space that can be allocated to this file or directory before the user <lb/>may reasonably be warned. It is understood that this space may be <lb/>consumed by allocations to other files or directories though there is <lb/>a rule as to which other files or directories. <lb/>5.8.2.30. Attribute 40: quota_used <lb/>The value in bytes that represents the amount of disk space used by <lb/>this file or directory and possibly a number of other similar files <lb/>or directories, where the set of &quot;similar&quot; meets at least the <lb/>criterion that allocating space to any file or directory in the set <lb/>will reduce the &quot;quota_avail_hard&quot; of every other file or directory <lb/>in the set. <lb/>Note that there may be a number of distinct but overlapping sets of <lb/>files or directories for which a quota_used value is maintained, <lb/>e.g., &quot;all files with a given owner&quot;, &quot;all files with a given group <lb/>owner&quot;, etc. The server is at liberty to choose any of those sets <lb/>when providing the content of the quota_used attribute, but should do <lb/>so in a repeatable way. The rule may be configured per file system <lb/>or may be &quot;choose the set with the smallest quota&quot;. <lb/>5.8.2.31. Attribute 41: rawdev <lb/>Raw device number of file of type NF4BLK or NF4CHR. The device <lb/>number is split into major and minor numbers. If the file&apos;s type <lb/>attribute is not NF4BLK or NF4CHR, the value returned SHOULD NOT be <lb/>considered useful. <lb/>5.8.2.32. Attribute 42: space_avail <lb/>Disk space in bytes available to this user on the file system <lb/>containing this object --this should be the smallest relevant limit. <lb/>5.8.2.33. Attribute 43: space_free <lb/>Free disk space in bytes on the file system containing this object --<lb/>this should be the smallest relevant limit. <lb/>5.8.2.34. Attribute 44: space_total <lb/>Total disk space in bytes on the file system containing this object. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 117] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>5.8.2.35. Attribute 45: space_used <lb/>Number of file system bytes allocated to this object. <lb/>5.8.2.36. Attribute 46: system <lb/>This attribute is TRUE if this file is a &quot;system&quot; file with respect <lb/>to the Windows operating environment. <lb/>5.8.2.37. Attribute 47: time_access <lb/>The time_access attribute represents the time of last access to the <lb/>object by a READ operation sent to the server. The notion of what is <lb/>an &quot;access&quot; depends on the server&apos;s operating environment and/or the <lb/>server&apos;s file system semantics. For example, for servers obeying <lb/>Portable Operating System Interface (POSIX) semantics, time_access <lb/>would be updated only by the READ and READDIR operations and not any <lb/>of the operations that modify the content of the object [13], [14], <lb/>[15]. Of course, setting the corresponding time_access_set attribute <lb/>is another way to modify the time_access attribute. <lb/>Whenever the file object resides on a writable file system, the <lb/>server should make its best efforts to record time_access into stable <lb/>storage. However, to mitigate the performance effects of doing so, <lb/>and most especially whenever the server is satisfying the read of the <lb/>object&apos;s content from its cache, the server MAY cache access time <lb/>updates and lazily write them to stable storage. It is also <lb/>acceptable to give administrators of the server the option to disable <lb/>time_access updates. <lb/>5.8.2.38. Attribute 48: time_access_set <lb/>Sets the time of last access to the object. SETATTR use only. <lb/>5.8.2.39. Attribute 49: time_backup <lb/>The time of last backup of the object. <lb/>5.8.2.40. Attribute 50: time_create <lb/>The time of creation of the object. This attribute does not have any <lb/>relation to the traditional UNIX file attribute &quot;ctime&quot; or &quot;change <lb/>time&quot;. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 118] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>5.8.2.41. Attribute 51: time_delta <lb/>Smallest useful server time granularity. <lb/>5.8.2.42. Attribute 52: time_metadata <lb/>The time of last metadata modification of the object. <lb/>5.8.2.43. Attribute 53: time_modify <lb/>The time of last modification to the object. <lb/>5.8.2.44. Attribute 54: time_modify_set <lb/>Sets the time of last modification to the object. SETATTR use only. <lb/>5.9. Interpreting owner and owner_group <lb/>The RECOMMENDED attributes &quot;owner&quot; and &quot;owner_group&quot; (and also users <lb/>and groups within the &quot;acl&quot; attribute) are represented in terms of a <lb/>UTF-8 string. To avoid a representation that is tied to a particular <lb/>underlying implementation at the client or server, the use of the <lb/>UTF-8 string has been chosen. Note that Section 6.1 of RFC 2624 [48] <lb/>provides additional rationale. It is expected that the client and <lb/>server will have their own local representation of owner and <lb/>owner_group that is used for local storage or presentation to the end <lb/>user. Therefore, it is expected that when these attributes are <lb/>transferred between the client and server, the local representation <lb/>is translated to a syntax of the form &quot;user@dns_domain&quot;. This will <lb/>allow for a client and server that do not use the same local <lb/>representation the ability to translate to a common syntax that can <lb/>be interpreted by both. <lb/>Similarly, security principals may be represented in different ways <lb/>by different security mechanisms. Servers normally translate these <lb/>representations into a common format, generally that used by local <lb/>storage, to serve as a means of identifying the users corresponding <lb/>to these security principals. When these local identifiers are <lb/>translated to the form of the owner attribute, associated with files <lb/>created by such principals, they identify, in a common format, the <lb/>users associated with each corresponding set of security principals. <lb/>The translation used to interpret owner and group strings is not <lb/>specified as part of the protocol. This allows various solutions to <lb/>be employed. For example, a local translation table may be consulted <lb/>that maps a numeric identifier to the user@dns_domain syntax. A name <lb/>service may also be used to accomplish the translation. A server may <lb/>provide a more general service, not limited by any particular <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 119] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>translation (which would only translate a limited set of possible <lb/>strings) by storing the owner and owner_group attributes in local <lb/>storage without any translation or it may augment a translation <lb/>method by storing the entire string for attributes for which no <lb/>translation is available while using the local representation for <lb/>those cases in which a translation is available. <lb/>Servers that do not provide support for all possible values of the <lb/>owner and owner_group attributes SHOULD return an error <lb/>(NFS4ERR_BADOWNER) when a string is presented that has no <lb/>translation, as the value to be set for a SETATTR of the owner, <lb/>owner_group, or acl attributes. When a server does accept an owner <lb/>or owner_group value as valid on a SETATTR (and similarly for the <lb/>owner and group strings in an acl), it is promising to return that <lb/>same string when a corresponding GETATTR is done. Configuration <lb/>changes (including changes from the mapping of the string to the <lb/>local representation) and ill-constructed name translations (those <lb/>that contain aliasing) may make that promise impossible to honor. <lb/>Servers should make appropriate efforts to avoid a situation in which <lb/>these attributes have their values changed when no real change to <lb/>ownership has occurred. <lb/>The &quot;dns_domain&quot; portion of the owner string is meant to be a DNS <lb/>domain name, for example, user@example.org. Servers should accept as <lb/>valid a set of users for at least one domain. A server may treat <lb/>other domains as having no valid translations. A more general <lb/>service is provided when a server is capable of accepting users for <lb/>multiple domains, or for all domains, subject to security <lb/>constraints. <lb/>In the case where there is no translation available to the client or <lb/>server, the attribute value will be constructed without the &quot;@&quot;. <lb/>Therefore, the absence of the @ from the owner or owner_group <lb/>attribute signifies that no translation was available at the sender <lb/>and that the receiver of the attribute should not use that string as <lb/>a basis for translation into its own internal format. Even though <lb/>the attribute value cannot be translated, it may still be useful. In <lb/>the case of a client, the attribute string may be used for local <lb/>display of ownership. <lb/>To provide a greater degree of compatibility with NFSv3, which <lb/>identified users and groups by 32-bit unsigned user identifiers and <lb/>group identifiers, owner and group strings that consist of decimal <lb/>numeric values with no leading zeros can be given a special <lb/>interpretation by clients and servers that choose to provide such <lb/>support. The receiver may treat such a user or group string as <lb/>representing the same user as would be represented by an NFSv3 uid or <lb/>gid having the corresponding numeric value. A server is not <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 120] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>obligated to accept such a string, but may return an NFS4ERR_BADOWNER <lb/>instead. To avoid this mechanism being used to subvert user and <lb/>group translation, so that a client might pass all of the owners and <lb/>groups in numeric form, a server SHOULD return an NFS4ERR_BADOWNER <lb/>error when there is a valid translation for the user or owner <lb/>designated in this way. In that case, the client must use the <lb/>appropriate name@domain string and not the special form for <lb/>compatibility. <lb/>The owner string &quot;nobody&quot; may be used to designate an anonymous user, <lb/>which will be associated with a file created by a security principal <lb/>that cannot be mapped through normal means to the owner attribute. <lb/>Users and implementations of NFSv4.1 SHOULD NOT use &quot;nobody&quot; to <lb/>designate a real user whose access is not anonymous. <lb/>5.10. Character Case Attributes <lb/>With respect to the case_insensitive and case_preserving attributes, <lb/>each UCS-4 character (which UTF-8 encodes) can be mapped according to <lb/>Appendix B.2 of RFC 3454 [16]. For general character handling and <lb/>internationalization issues, see Section 14. <lb/>5.11. Directory Notification Attributes <lb/>As described in Section 18.39, the client can request a minimum delay <lb/>for notifications of changes to attributes, but the server is free to <lb/>ignore what the client requests. The client can determine in advance <lb/>what notification delays the server will accept by sending a GETATTR <lb/>operation for either or both of two directory notification <lb/>attributes. When the client calls the GET_DIR_DELEGATION operation <lb/>and asks for attribute change notifications, it should request <lb/>notification delays that are no less than the values in the server-<lb/>provided attributes. <lb/>5.11.1. Attribute 56: dir_notif_delay <lb/>The dir_notif_delay attribute is the minimum number of seconds the <lb/>server will delay before notifying the client of a change to the <lb/>directory&apos;s attributes. <lb/>5.11.2. Attribute 57: dirent_notif_delay <lb/>The dirent_notif_delay attribute is the minimum number of seconds the <lb/>server will delay before notifying the client of a change to a file <lb/>object that has an entry in the directory. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 121] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>5.12. pNFS Attribute Definitions <lb/>5.12.1. Attribute 62: fs_layout_type <lb/>The fs_layout_type attribute (see Section 3.3.13) applies to a file <lb/>system and indicates what layout types are supported by the file <lb/>system. When the client encounters a new fsid, the client SHOULD <lb/>obtain the value for the fs_layout_type attribute associated with the <lb/>new file system. This attribute is used by the client to determine <lb/>if the layout types supported by the server match any of the client&apos;s <lb/>supported layout types. <lb/>5.12.2. Attribute 66: layout_alignment <lb/>When a client holds layouts on files of a file system, the <lb/>layout_alignment attribute indicates the preferred alignment for I/O <lb/>to files on that file system. Where possible, the client should send <lb/>READ and WRITE operations with offsets that are whole multiples of <lb/>the layout_alignment attribute. <lb/>5.12.3. Attribute 65: layout_blksize <lb/>When a client holds layouts on files of a file system, the <lb/>layout_blksize attribute indicates the preferred block size for I/O <lb/>to files on that file system. Where possible, the client should send <lb/>READ operations with a count argument that is a whole multiple of <lb/>layout_blksize, and WRITE operations with a data argument of size <lb/>that is a whole multiple of layout_blksize. <lb/>5.12.4. Attribute 63: layout_hint <lb/>The layout_hint attribute (see Section 3.3.19) may be set on newly <lb/>created files to influence the metadata server&apos;s choice for the <lb/>file&apos;s layout. If possible, this attribute is one of those set in <lb/>the initial attributes within the OPEN operation. The metadata <lb/>server may choose to ignore this attribute. The layout_hint <lb/>attribute is a subset of the layout structure returned by LAYOUTGET. <lb/>For example, instead of specifying particular devices, this would be <lb/>used to suggest the stripe width of a file. The server <lb/>implementation determines which fields within the layout will be <lb/>used. <lb/>5.12.5. Attribute 64: layout_type <lb/>This attribute lists the layout type(s) available for a file. The <lb/>value returned by the server is for informational purposes only. The <lb/>client will use the LAYOUTGET operation to obtain the information <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 122] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>needed in order to perform I/O, for example, the specific device <lb/>information for the file and its layout. <lb/>5.12.6. Attribute 68: mdsthreshold <lb/>This attribute is a server-provided hint used to communicate to the <lb/>client when it is more efficient to send READ and WRITE operations to <lb/>the metadata server or the data server. The two types of thresholds <lb/>described are file size thresholds and I/O size thresholds. If a <lb/>file&apos;s size is smaller than the file size threshold, data accesses <lb/>SHOULD be sent to the metadata server. If an I/O request has a <lb/>length that is below the I/O size threshold, the I/O SHOULD be sent <lb/>to the metadata server. Each threshold type is specified separately <lb/>for read and write. <lb/>The server MAY provide both types of thresholds for a file. If both <lb/>file size and I/O size are provided, the client SHOULD reach or <lb/>exceed both thresholds before sending its read or write requests to <lb/>the data server. Alternatively, if only one of the specified <lb/>thresholds is reached or exceeded, the I/O requests are sent to the <lb/>metadata server. <lb/>For each threshold type, a value of zero indicates no READ or WRITE <lb/>should be sent to the metadata server, while a value of all ones <lb/>indicates that all READs or WRITEs should be sent to the metadata <lb/>server. <lb/>The attribute is available on a per-filehandle basis. If the current <lb/>filehandle refers to a non-pNFS file or directory, the metadata <lb/>server should return an attribute that is representative of the <lb/>filehandle&apos;s file system. It is suggested that this attribute is <lb/>queried as part of the OPEN operation. Due to dynamic system <lb/>changes, the client should not assume that the attribute will remain <lb/>constant for any specific time period; thus, it should be <lb/>periodically refreshed. <lb/>5.13. Retention Attributes <lb/>Retention is a concept whereby a file object can be placed in an <lb/>immutable, undeletable, unrenamable state for a fixed or infinite <lb/>duration of time. Once in this &quot;retained&quot; state, the file cannot be <lb/>moved out of the state until the duration of retention has been <lb/>reached. <lb/>When retention is enabled, retention MUST extend to the data of the <lb/>file, and the name of file. The server MAY extend retention to any <lb/>other property of the file, including any subset of REQUIRED, <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 123] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>RECOMMENDED, and named attributes, with the exceptions noted in this <lb/>section. <lb/>Servers MAY support or not support retention on any file object type. <lb/>The five retention attributes are explained in the next subsections. <lb/>5.13.1. Attribute 69: retention_get <lb/>If retention is enabled for the associated file, this attribute&apos;s <lb/>value represents the retention begin time of the file object. This <lb/>attribute&apos;s value is only readable with the GETATTR operation and <lb/>MUST NOT be modified by the SETATTR operation (Section 5.5). The <lb/>value of the attribute consists of: <lb/>const RET4_DURATION_INFINITE <lb/>= 0xffffffffffffffff; <lb/>struct retention_get4 { <lb/>uint64_t <lb/>rg_duration; <lb/>nfstime4 <lb/>rg_begin_time&lt;1&gt;; <lb/>}; <lb/>The field rg_duration is the duration in seconds indicating how long <lb/>the file will be retained once retention is enabled. The field <lb/>rg_begin_time is an array of up to one absolute time value. If the <lb/>array is zero length, no beginning retention time has been <lb/>established, and retention is not enabled. If rg_duration is equal <lb/>to RET4_DURATION_INFINITE, the file, once retention is enabled, will <lb/>be retained for an infinite duration. <lb/>If (as soon as) rg_duration is zero, then rg_begin_time will be of <lb/>zero length, and again, retention is not (no longer) enabled. <lb/>5.13.2. Attribute 70: retention_set <lb/>This attribute is used to set the retention duration and optionally <lb/>enable retention for the associated file object. This attribute is <lb/>only modifiable via the SETATTR operation and MUST NOT be retrieved <lb/>by the GETATTR operation (Section 5.5). This attribute corresponds <lb/>to retention_get. The value of the attribute consists of: <lb/>struct retention_set4 { <lb/>bool <lb/>rs_enable; <lb/>uint64_t <lb/>rs_duration&lt;1&gt;; <lb/>}; <lb/>If the client sets rs_enable to TRUE, then it is enabling retention <lb/>on the file object with the begin time of retention starting from the <lb/>server&apos;s current time and date. The duration of the retention can <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 124] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>also be provided if the rs_duration array is of length one. The <lb/>duration is the time in seconds from the begin time of retention, and <lb/>if set to RET4_DURATION_INFINITE, the file is to be retained forever. <lb/>If retention is enabled, with no duration specified in either this <lb/>SETATTR or a previous SETATTR, the duration defaults to zero seconds. <lb/>The server MAY restrict the enabling of retention or the duration of <lb/>retention on the basis of the ACE4_WRITE_RETENTION ACL permission. <lb/>The enabling of retention MUST NOT prevent the enabling of event-<lb/>based retention or the modification of the retention_hold attribute. <lb/>The following rules apply to both the retention_set and retentevt_set <lb/>attributes. <lb/>o As long as retention is not enabled, the client is permitted to <lb/>decrease the duration. <lb/>o The duration can always be set to an equal or higher value, even <lb/>if retention is enabled. Note that once retention is enabled, the <lb/>actual duration (as returned by the retention_get or retentevt_get <lb/>attributes; see Section 5.13.1 or Section 5.13.3) is constantly <lb/>counting down to zero (one unit per second), unless the duration <lb/>was set to RET4_DURATION_INFINITE. Thus, it will not be possible <lb/>for the client to precisely extend the duration on a file that has <lb/>retention enabled. <lb/>o While retention is enabled, attempts to disable retention or <lb/>decrease the retention&apos;s duration MUST fail with the error <lb/>NFS4ERR_INVAL. <lb/>o If the principal attempting to change retention_set or <lb/>retentevt_set does not have ACE4_WRITE_RETENTION permissions, the <lb/>attempt MUST fail with NFS4ERR_ACCESS. <lb/>5.13.3. Attribute 71: retentevt_get <lb/>Gets the event-based retention duration, and if enabled, the event-<lb/>based retention begin time of the file object. This attribute is <lb/>like retention_get, but refers to event-based retention. The event <lb/>that triggers event-based retention is not defined by the NFSv4.1 <lb/>specification. <lb/>5.13.4. Attribute 72: retentevt_set <lb/>Sets the event-based retention duration, and optionally enables <lb/>event-based retention on the file object. This attribute corresponds <lb/>to retentevt_get and is like retention_set, but refers to event-based <lb/>retention. When event-based retention is set, the file MUST be <lb/>retained even if non-event-based retention has been set, and the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 125] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>duration of non-event-based retention has been reached. Conversely, <lb/>when non-event-based retention has been set, the file MUST be <lb/>retained even if event-based retention has been set, and the duration <lb/>of event-based retention has been reached. The server MAY restrict <lb/>the enabling of event-based retention or the duration of event-based <lb/>retention on the basis of the ACE4_WRITE_RETENTION ACL permission. <lb/>The enabling of event-based retention MUST NOT prevent the enabling <lb/>of non-event-based retention or the modification of the <lb/>retention_hold attribute. <lb/>5.13.5. Attribute 73: retention_hold <lb/>Gets or sets administrative retention holds, one hold per bit <lb/>position. <lb/>This attribute allows one to 64 administrative holds, one hold per <lb/>bit on the attribute. If retention_hold is not zero, then the file <lb/>MUST NOT be deleted, renamed, or modified, even if the duration on <lb/>enabled event or non-event-based retention has been reached. The <lb/>server MAY restrict the modification of retention_hold on the basis <lb/>of the ACE4_WRITE_RETENTION_HOLD ACL permission. The enabling of <lb/>administration retention holds does not prevent the enabling of <lb/>event-based or non-event-based retention. <lb/>If the principal attempting to change retention_hold does not have <lb/>ACE4_WRITE_RETENTION_HOLD permissions, the attempt MUST fail with <lb/>NFS4ERR_ACCESS. <lb/>6. Access Control Attributes <lb/>Access Control Lists (ACLs) are file attributes that specify fine-<lb/>grained access control. This section covers the &quot;acl&quot;, &quot;dacl&quot;, <lb/>&quot;sacl&quot;, &quot;aclsupport&quot;, &quot;mode&quot;, and &quot;mode_set_masked&quot; file attributes <lb/>and their interactions. Note that file attributes may apply to any <lb/>file system object. <lb/>6.1. Goals <lb/>ACLs and modes represent two well-established models for specifying <lb/>permissions. This section specifies requirements that attempt to <lb/>meet the following goals: <lb/>o If a server supports the mode attribute, it should provide <lb/>reasonable semantics to clients that only set and retrieve the <lb/>mode attribute. <lb/>o If a server supports ACL attributes, it should provide reasonable <lb/>semantics to clients that only set and retrieve those attributes. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 126] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o On servers that support the mode attribute, if ACL attributes have <lb/>never been set on an object, via inheritance or explicitly, the <lb/>behavior should be traditional UNIX-like behavior. <lb/>o On servers that support the mode attribute, if the ACL attributes <lb/>have been previously set on an object, either explicitly or via <lb/>inheritance: <lb/>* Setting only the mode attribute should effectively control the <lb/>traditional UNIX-like permissions of read, write, and execute <lb/>on owner, owner_group, and other. <lb/>* Setting only the mode attribute should provide reasonable <lb/>security. For example, setting a mode of 000 should be enough <lb/>to ensure that future OPEN operations for <lb/>OPEN4_SHARE_ACCESS_READ or OPEN4_SHARE_ACCESS_WRITE by any <lb/>principal fail, regardless of a previously existing or <lb/>inherited ACL. <lb/>o NFSv4.1 may introduce different semantics relating to the mode and <lb/>ACL attributes, but it does not render invalid any previously <lb/>existing implementations. Additionally, this section provides <lb/>clarifications based on previous implementations and discussions <lb/>around them. <lb/>o On servers that support both the mode and the acl or dacl <lb/>attributes, the server must keep the two consistent with each <lb/>other. The value of the mode attribute (with the exception of the <lb/>three high-order bits described in Section 6.2.4) must be <lb/>determined entirely by the value of the ACL, so that use of the <lb/>mode is never required for anything other than setting the three <lb/>high-order bits. See Section 6.4.1 for exact requirements. <lb/>o When a mode attribute is set on an object, the ACL attributes may <lb/>need to be modified in order to not conflict with the new mode. <lb/>In such cases, it is desirable that the ACL keep as much <lb/>information as possible. This includes information about <lb/>inheritance, AUDIT and ALARM ACEs, and permissions granted and <lb/>denied that do not conflict with the new mode. <lb/>6.2. File Attributes Discussion <lb/>6.2.1. Attribute 12: acl <lb/>The NFSv4.1 ACL attribute contains an array of Access Control Entries <lb/>(ACEs) that are associated with the file system object. Although the <lb/>client can set and get the acl attribute, the server is responsible <lb/>for using the ACL to perform access control. The client can use the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 127] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>OPEN or ACCESS operations to check access without modifying or <lb/>reading data or metadata. <lb/>The NFS ACE structure is defined as follows: <lb/>typedef uint32_t <lb/>acetype4; <lb/>typedef uint32_t aceflag4; <lb/>typedef uint32_t <lb/>acemask4; <lb/>struct nfsace4 { <lb/>acetype4 <lb/>type; <lb/>aceflag4 <lb/>flag; <lb/>acemask4 <lb/>access_mask; <lb/>utf8str_mixed <lb/>who; <lb/>}; <lb/>To determine if a request succeeds, the server processes each nfsace4 <lb/>entry in order. Only ACEs that have a &quot;who&quot; that matches the <lb/>requester are considered. Each ACE is processed until all of the <lb/>bits of the requester&apos;s access have been ALLOWED. Once a bit (see <lb/>below) has been ALLOWED by an ACCESS_ALLOWED_ACE, it is no longer <lb/>considered in the processing of later ACEs. If an ACCESS_DENIED_ACE <lb/>is encountered where the requester&apos;s access still has unALLOWED bits <lb/>in common with the &quot;access_mask&quot; of the ACE, the request is denied. <lb/>When the ACL is fully processed, if there are bits in the requester&apos;s <lb/>mask that have not been ALLOWED or DENIED, access is denied. <lb/>Unlike the ALLOW and DENY ACE types, the ALARM and AUDIT ACE types do <lb/>not affect a requester&apos;s access, and instead are for triggering <lb/>events as a result of a requester&apos;s access attempt. Therefore, AUDIT <lb/>and ALARM ACEs are processed only after processing ALLOW and DENY <lb/>ACEs. <lb/>The NFSv4.1 ACL model is quite rich. Some server platforms may <lb/>provide access-control functionality that goes beyond the UNIX-style <lb/>mode attribute, but that is not as rich as the NFS ACL model. So <lb/>that users can take advantage of this more limited functionality, the <lb/>server may support the acl attributes by mapping between its ACL <lb/>model and the NFSv4.1 ACL model. Servers must ensure that the ACL <lb/>they actually store or enforce is at least as strict as the NFSv4 ACL <lb/>that was set. It is tempting to accomplish this by rejecting any ACL <lb/>that falls outside the small set that can be represented accurately. <lb/>However, such an approach can render ACLs unusable without special <lb/>client-side knowledge of the server&apos;s mapping, which defeats the <lb/>purpose of having a common NFSv4 ACL protocol. Therefore, servers <lb/>should accept every ACL that they can without compromising security. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 128] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>To help accomplish this, servers may make a special exception, in the <lb/>case of unsupported permission bits, to the rule that bits not <lb/>ALLOWED or DENIED by an ACL must be denied. For example, a UNIX-<lb/>style server might choose to silently allow read attribute <lb/>permissions even though an ACL does not explicitly allow those <lb/>permissions. (An ACL that explicitly denies permission to read <lb/>attributes should still be rejected.) <lb/>The situation is complicated by the fact that a server may have <lb/>multiple modules that enforce ACLs. For example, the enforcement for <lb/>NFSv4.1 access may be different from, but not weaker than, the <lb/>enforcement for local access, and both may be different from the <lb/>enforcement for access through other protocols such as SMB (Server <lb/>Message Block). So it may be useful for a server to accept an ACL <lb/>even if not all of its modules are able to support it. <lb/>The guiding principle with regard to NFSv4 access is that the server <lb/>must not accept ACLs that appear to make access to the file more <lb/>restrictive than it really is. <lb/>6.2.1.1. ACE Type <lb/>The constants used for the type field (acetype4) are as follows: <lb/>const ACE4_ACCESS_ALLOWED_ACE_TYPE <lb/>= 0x00000000; <lb/>const ACE4_ACCESS_DENIED_ACE_TYPE <lb/>= 0x00000001; <lb/>const ACE4_SYSTEM_AUDIT_ACE_TYPE <lb/>= 0x00000002; <lb/>const ACE4_SYSTEM_ALARM_ACE_TYPE <lb/>= 0x00000003; <lb/>Only the ALLOWED and DENIED bits may be used in the dacl attribute, <lb/>and only the AUDIT and ALARM bits may be used in the sacl attribute. <lb/>All four are permitted in the acl attribute. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 129] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>+------------------------------+--------------+---------------------+ <lb/>| Value <lb/>| Abbreviation | Description <lb/>| <lb/>+------------------------------+--------------+---------------------+ <lb/>| ACE4_ACCESS_ALLOWED_ACE_TYPE | ALLOW <lb/>| Explicitly grants <lb/>| <lb/>| <lb/>| <lb/>| the access defined | <lb/>| <lb/>| <lb/>| in acemask4 to the | <lb/>| <lb/>| <lb/>| file or directory. | <lb/>| ACE4_ACCESS_DENIED_ACE_TYPE | DENY <lb/>| Explicitly denies <lb/>| <lb/>| <lb/>| <lb/>| the access defined | <lb/>| <lb/>| <lb/>| in acemask4 to the | <lb/>| <lb/>| <lb/>| file or directory. | <lb/>| ACE4_SYSTEM_AUDIT_ACE_TYPE <lb/>| AUDIT <lb/>| Log (in a system-<lb/>| <lb/>| <lb/>| <lb/>| dependent way) any | <lb/>| <lb/>| <lb/>| access attempt to a | <lb/>| <lb/>| <lb/>| file or directory <lb/>| <lb/>| <lb/>| <lb/>| that uses any of <lb/>| <lb/>| <lb/>| <lb/>| the access methods | <lb/>| <lb/>| <lb/>| specified in <lb/>| <lb/>| <lb/>| <lb/>| acemask4. <lb/>| <lb/>| ACE4_SYSTEM_ALARM_ACE_TYPE <lb/>| ALARM <lb/>| Generate an alarm <lb/>| <lb/>| <lb/>| <lb/>| (in a system-<lb/>| <lb/>| <lb/>| <lb/>| dependent way) when | <lb/>| <lb/>| <lb/>| any access attempt | <lb/>| <lb/>| <lb/>| is made to a file <lb/>| <lb/>| <lb/>| <lb/>| or directory for <lb/>| <lb/>| <lb/>| <lb/>| the access methods | <lb/>| <lb/>| <lb/>| specified in <lb/>| <lb/>| <lb/>| <lb/>| acemask4. <lb/>| <lb/>+------------------------------+--------------+---------------------+ <lb/>The &quot;Abbreviation&quot; column denotes how the types will be referred to <lb/>throughout the rest of this section. <lb/>6.2.1.2. Attribute 13: aclsupport <lb/>A server need not support all of the above ACE types. This attribute <lb/>indicates which ACE types are supported for the current file system. <lb/>The bitmask constants used to represent the above definitions within <lb/>the aclsupport attribute are as follows: <lb/>const ACL4_SUPPORT_ALLOW_ACL <lb/>= 0x00000001; <lb/>const ACL4_SUPPORT_DENY_ACL <lb/>= 0x00000002; <lb/>const ACL4_SUPPORT_AUDIT_ACL <lb/>= 0x00000004; <lb/>const ACL4_SUPPORT_ALARM_ACL <lb/>= 0x00000008; <lb/>Servers that support either the ALLOW or DENY ACE type SHOULD support <lb/>both ALLOW and DENY ACE types. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 130] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Clients should not attempt to set an ACE unless the server claims <lb/>support for that ACE type. If the server receives a request to set <lb/>an ACE that it cannot store, it MUST reject the request with <lb/>NFS4ERR_ATTRNOTSUPP. If the server receives a request to set an ACE <lb/>that it can store but cannot enforce, the server SHOULD reject the <lb/>request with NFS4ERR_ATTRNOTSUPP. <lb/>Support for any of the ACL attributes is optional (albeit <lb/>RECOMMENDED). However, a server that supports either of the new ACL <lb/>attributes (dacl or sacl) MUST allow use of the new ACL attributes to <lb/>access all of the ACE types that it supports. In other words, if <lb/>such a server supports ALLOW or DENY ACEs, then it MUST support the <lb/>dacl attribute, and if it supports AUDIT or ALARM ACEs, then it MUST <lb/>support the sacl attribute. <lb/>6.2.1.3. ACE Access Mask <lb/>The bitmask constants used for the access mask field are as follows: <lb/>const ACE4_READ_DATA <lb/>= 0x00000001; <lb/>const ACE4_LIST_DIRECTORY <lb/>= 0x00000001; <lb/>const ACE4_WRITE_DATA <lb/>= 0x00000002; <lb/>const ACE4_ADD_FILE <lb/>= 0x00000002; <lb/>const ACE4_APPEND_DATA <lb/>= 0x00000004; <lb/>const ACE4_ADD_SUBDIRECTORY <lb/>= 0x00000004; <lb/>const ACE4_READ_NAMED_ATTRS <lb/>= 0x00000008; <lb/>const ACE4_WRITE_NAMED_ATTRS <lb/>= 0x00000010; <lb/>const ACE4_EXECUTE <lb/>= 0x00000020; <lb/>const ACE4_DELETE_CHILD <lb/>= 0x00000040; <lb/>const ACE4_READ_ATTRIBUTES <lb/>= 0x00000080; <lb/>const ACE4_WRITE_ATTRIBUTES <lb/>= 0x00000100; <lb/>const ACE4_WRITE_RETENTION <lb/>= 0x00000200; <lb/>const ACE4_WRITE_RETENTION_HOLD = 0x00000400; <lb/>const ACE4_DELETE <lb/>= 0x00010000; <lb/>const ACE4_READ_ACL <lb/>= 0x00020000; <lb/>const ACE4_WRITE_ACL <lb/>= 0x00040000; <lb/>const ACE4_WRITE_OWNER <lb/>= 0x00080000; <lb/>const ACE4_SYNCHRONIZE <lb/>= 0x00100000; <lb/>Note that some masks have coincident values, for example, <lb/>ACE4_READ_DATA and ACE4_LIST_DIRECTORY. The mask entries <lb/>ACE4_LIST_DIRECTORY, ACE4_ADD_FILE, and ACE4_ADD_SUBDIRECTORY are <lb/>intended to be used with directory objects, while ACE4_READ_DATA, <lb/>ACE4_WRITE_DATA, and ACE4_APPEND_DATA are intended to be used with <lb/>non-directory objects. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 131] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>6.2.1.3.1. Discussion of Mask Attributes <lb/>ACE4_READ_DATA <lb/>Operation(s) affected: <lb/>READ <lb/>OPEN <lb/>Discussion: <lb/>Permission to read the data of the file. <lb/>Servers SHOULD allow a user the ability to read the data of the <lb/>file when only the ACE4_EXECUTE access mask bit is allowed. <lb/>ACE4_LIST_DIRECTORY <lb/>Operation(s) affected: <lb/>READDIR <lb/>Discussion: <lb/>Permission to list the contents of a directory. <lb/>ACE4_WRITE_DATA <lb/>Operation(s) affected: <lb/>WRITE <lb/>OPEN <lb/>SETATTR of size <lb/>Discussion: <lb/>Permission to modify a file&apos;s data. <lb/>ACE4_ADD_FILE <lb/>Operation(s) affected: <lb/>CREATE <lb/>LINK <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 132] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>OPEN <lb/>RENAME <lb/>Discussion: <lb/>Permission to add a new file in a directory. The CREATE <lb/>operation is affected when nfs_ftype4 is NF4LNK, NF4BLK, <lb/>NF4CHR, NF4SOCK, or NF4FIFO. (NF4DIR is not listed because it <lb/>is covered by ACE4_ADD_SUBDIRECTORY.) OPEN is affected when <lb/>used to create a regular file. LINK and RENAME are always <lb/>affected. <lb/>ACE4_APPEND_DATA <lb/>Operation(s) affected: <lb/>WRITE <lb/>OPEN <lb/>SETATTR of size <lb/>Discussion: <lb/>The ability to modify a file&apos;s data, but only starting at EOF. <lb/>This allows for the notion of append-only files, by allowing <lb/>ACE4_APPEND_DATA and denying ACE4_WRITE_DATA to the same user <lb/>or group. If a file has an ACL such as the one described above <lb/>and a WRITE request is made for somewhere other than EOF, the <lb/>server SHOULD return NFS4ERR_ACCESS. <lb/>ACE4_ADD_SUBDIRECTORY <lb/>Operation(s) affected: <lb/>CREATE <lb/>RENAME <lb/>Discussion: <lb/>Permission to create a subdirectory in a directory. The CREATE <lb/>operation is affected when nfs_ftype4 is NF4DIR. The RENAME <lb/>operation is always affected. <lb/>ACE4_READ_NAMED_ATTRS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 133] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Operation(s) affected: <lb/>OPENATTR <lb/>Discussion: <lb/>Permission to read the named attributes of a file or to look up <lb/>the named attribute directory. OPENATTR is affected when it is <lb/>not used to create a named attribute directory. This is when <lb/>1) createdir is TRUE, but a named attribute directory already <lb/>exists, or 2) createdir is FALSE. <lb/>ACE4_WRITE_NAMED_ATTRS <lb/>Operation(s) affected: <lb/>OPENATTR <lb/>Discussion: <lb/>Permission to write the named attributes of a file or to create <lb/>a named attribute directory. OPENATTR is affected when it is <lb/>used to create a named attribute directory. This is when <lb/>createdir is TRUE and no named attribute directory exists. The <lb/>ability to check whether or not a named attribute directory <lb/>exists depends on the ability to look it up; therefore, users <lb/>also need the ACE4_READ_NAMED_ATTRS permission in order to <lb/>create a named attribute directory. <lb/>ACE4_EXECUTE <lb/>Operation(s) affected: <lb/>READ <lb/>OPEN <lb/>REMOVE <lb/>RENAME <lb/>LINK <lb/>CREATE <lb/>Discussion: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 134] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Permission to execute a file. <lb/>Servers SHOULD allow a user the ability to read the data of the <lb/>file when only the ACE4_EXECUTE access mask bit is allowed. <lb/>This is because there is no way to execute a file without <lb/>reading the contents. Though a server may treat ACE4_EXECUTE <lb/>and ACE4_READ_DATA bits identically when deciding to permit a <lb/>READ operation, it SHOULD still allow the two bits to be set <lb/>independently in ACLs, and MUST distinguish between them when <lb/>replying to ACCESS operations. In particular, servers SHOULD <lb/>NOT silently turn on one of the two bits when the other is set, <lb/>as that would make it impossible for the client to correctly <lb/>enforce the distinction between read and execute permissions. <lb/>As an example, following a SETATTR of the following ACL: <lb/>nfsuser:ACE4_EXECUTE:ALLOW <lb/>A subsequent GETATTR of ACL for that file SHOULD return: <lb/>nfsuser:ACE4_EXECUTE:ALLOW <lb/>Rather than: <lb/>nfsuser:ACE4_EXECUTE/ACE4_READ_DATA:ALLOW <lb/>ACE4_EXECUTE <lb/>Operation(s) affected: <lb/>LOOKUP <lb/>Discussion: <lb/>Permission to traverse/search a directory. <lb/>ACE4_DELETE_CHILD <lb/>Operation(s) affected: <lb/>REMOVE <lb/>RENAME <lb/>Discussion: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 135] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Permission to delete a file or directory within a directory. <lb/>See Section 6.2.1.3.2 for information on ACE4_DELETE and <lb/>ACE4_DELETE_CHILD interact. <lb/>ACE4_READ_ATTRIBUTES <lb/>Operation(s) affected: <lb/>GETATTR of file system object attributes <lb/>VERIFY <lb/>NVERIFY <lb/>READDIR <lb/>Discussion: <lb/>The ability to read basic attributes (non-ACLs) of a file. On <lb/>a UNIX system, basic attributes can be thought of as the stat-<lb/>level attributes. Allowing this access mask bit would mean <lb/>that the entity can execute &quot;ls -l&quot; and stat. If a READDIR <lb/>operation requests attributes, this mask must be allowed for <lb/>the READDIR to succeed. <lb/>ACE4_WRITE_ATTRIBUTES <lb/>Operation(s) affected: <lb/>SETATTR of time_access_set, time_backup, <lb/>time_create, time_modify_set, mimetype, hidden, system <lb/>Discussion: <lb/>Permission to change the times associated with a file or <lb/>directory to an arbitrary value. Also permission to change the <lb/>mimetype, hidden, and system attributes. A user having <lb/>ACE4_WRITE_DATA or ACE4_WRITE_ATTRIBUTES will be allowed to set <lb/>the times associated with a file to the current server time. <lb/>ACE4_WRITE_RETENTION <lb/>Operation(s) affected: <lb/>SETATTR of retention_set, retentevt_set. <lb/>Discussion: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 136] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Permission to modify the durations of event and non-event-based <lb/>retention. Also permission to enable event and non-event-based <lb/>retention. A server MAY behave such that setting <lb/>ACE4_WRITE_ATTRIBUTES allows ACE4_WRITE_RETENTION. <lb/>ACE4_WRITE_RETENTION_HOLD <lb/>Operation(s) affected: <lb/>SETATTR of retention_hold. <lb/>Discussion: <lb/>Permission to modify the administration retention holds. A <lb/>server MAY map ACE4_WRITE_ATTRIBUTES to <lb/>ACE_WRITE_RETENTION_HOLD. <lb/>ACE4_DELETE <lb/>Operation(s) affected: <lb/>REMOVE <lb/>Discussion: <lb/>Permission to delete the file or directory. See <lb/>Section 6.2.1.3.2 for information on ACE4_DELETE and <lb/>ACE4_DELETE_CHILD interact. <lb/>ACE4_READ_ACL <lb/>Operation(s) affected: <lb/>GETATTR of acl, dacl, or sacl <lb/>NVERIFY <lb/>VERIFY <lb/>Discussion: <lb/>Permission to read the ACL. <lb/>ACE4_WRITE_ACL <lb/>Operation(s) affected: <lb/>SETATTR of acl and mode <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 137] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Discussion: <lb/>Permission to write the acl and mode attributes. <lb/>ACE4_WRITE_OWNER <lb/>Operation(s) affected: <lb/>SETATTR of owner and owner_group <lb/>Discussion: <lb/>Permission to write the owner and owner_group attributes. On <lb/>UNIX systems, this is the ability to execute chown() and <lb/>chgrp(). <lb/>ACE4_SYNCHRONIZE <lb/>Operation(s) affected: <lb/>NONE <lb/>Discussion: <lb/>Permission to use the file object as a synchronization <lb/>primitive for interprocess communication. This permission is <lb/>not enforced or interpreted by the NFSv4.1 server on behalf of <lb/>the client. <lb/>Typically, the ACE4_SYNCHRONIZE permission is only meaningful <lb/>on local file systems, i.e., file systems not accessed via <lb/>NFSv4.1. The reason that the permission bit exists is that <lb/>some operating environments, such as Windows, use <lb/>ACE4_SYNCHRONIZE. <lb/>For example, if a client copies a file that has <lb/>ACE4_SYNCHRONIZE set from a local file system to an NFSv4.1 <lb/>server, and then later copies the file from the NFSv4.1 server <lb/>to a local file system, it is likely that if ACE4_SYNCHRONIZE <lb/>was set in the original file, the client will want it set in <lb/>the second copy. The first copy will not have the permission <lb/>set unless the NFSv4.1 server has the means to set the <lb/>ACE4_SYNCHRONIZE bit. The second copy will not have the <lb/>permission set unless the NFSv4.1 server has the means to <lb/>retrieve the ACE4_SYNCHRONIZE bit. <lb/>Server implementations need not provide the granularity of control <lb/>that is implied by this list of masks. For example, POSIX-based <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 138] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>systems might not distinguish ACE4_APPEND_DATA (the ability to append <lb/>to a file) from ACE4_WRITE_DATA (the ability to modify existing <lb/>contents); both masks would be tied to a single &quot;write&quot; permission <lb/>[17]. When such a server returns attributes to the client, it would <lb/>show both ACE4_APPEND_DATA and ACE4_WRITE_DATA if and only if the <lb/>write permission is enabled. <lb/>If a server receives a SETATTR request that it cannot accurately <lb/>implement, it should err in the direction of more restricted access, <lb/>except in the previously discussed cases of execute and read. For <lb/>example, suppose a server cannot distinguish overwriting data from <lb/>appending new data, as described in the previous paragraph. If a <lb/>client submits an ALLOW ACE where ACE4_APPEND_DATA is set but <lb/>ACE4_WRITE_DATA is not (or vice versa), the server should either turn <lb/>off ACE4_APPEND_DATA or reject the request with NFS4ERR_ATTRNOTSUPP. <lb/>6.2.1.3.2. ACE4_DELETE vs. ACE4_DELETE_CHILD <lb/>Two access mask bits govern the ability to delete a directory entry: <lb/>ACE4_DELETE on the object itself (the &quot;target&quot;) and ACE4_DELETE_CHILD <lb/>on the containing directory (the &quot;parent&quot;). <lb/>Many systems also take the &quot;sticky bit&quot; (MODE4_SVTX) on a directory <lb/>to allow unlink only to a user that owns either the target or the <lb/>parent; on some such systems the decision also depends on whether the <lb/>target is writable. <lb/>Servers SHOULD allow unlink if either ACE4_DELETE is permitted on the <lb/>target, or ACE4_DELETE_CHILD is permitted on the parent. (Note that <lb/>this is true even if the parent or target explicitly denies one of <lb/>these permissions.) <lb/>If the ACLs in question neither explicitly ALLOW nor DENY either of <lb/>the above, and if MODE4_SVTX is not set on the parent, then the <lb/>server SHOULD allow the removal if and only if ACE4_ADD_FILE is <lb/>permitted. In the case where MODE4_SVTX is set, the server may also <lb/>require the remover to own either the parent or the target, or may <lb/>require the target to be writable. <lb/>This allows servers to support something close to traditional UNIX-<lb/>like semantics, with ACE4_ADD_FILE taking the place of the write bit. <lb/>6.2.1.4. ACE flag <lb/>The bitmask constants used for the flag field are as follows: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 139] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>const ACE4_FILE_INHERIT_ACE <lb/>= 0x00000001; <lb/>const ACE4_DIRECTORY_INHERIT_ACE <lb/>= 0x00000002; <lb/>const ACE4_NO_PROPAGATE_INHERIT_ACE <lb/>= 0x00000004; <lb/>const ACE4_INHERIT_ONLY_ACE <lb/>= 0x00000008; <lb/>const ACE4_SUCCESSFUL_ACCESS_ACE_FLAG <lb/>= 0x00000010; <lb/>const ACE4_FAILED_ACCESS_ACE_FLAG <lb/>= 0x00000020; <lb/>const ACE4_IDENTIFIER_GROUP <lb/>= 0x00000040; <lb/>const ACE4_INHERITED_ACE <lb/>= 0x00000080; <lb/>A server need not support any of these flags. If the server supports <lb/>flags that are similar to, but not exactly the same as, these flags, <lb/>the implementation may define a mapping between the protocol-defined <lb/>flags and the implementation-defined flags. <lb/>For example, suppose a client tries to set an ACE with <lb/>ACE4_FILE_INHERIT_ACE set but not ACE4_DIRECTORY_INHERIT_ACE. If the <lb/>server does not support any form of ACL inheritance, the server <lb/>should reject the request with NFS4ERR_ATTRNOTSUPP. If the server <lb/>supports a single &quot;inherit ACE&quot; flag that applies to both files and <lb/>directories, the server may reject the request (i.e., requiring the <lb/>client to set both the file and directory inheritance flags). The <lb/>server may also accept the request and silently turn on the <lb/>ACE4_DIRECTORY_INHERIT_ACE flag. <lb/>6.2.1.4.1. Discussion of Flag Bits <lb/>ACE4_FILE_INHERIT_ACE <lb/>Any non-directory file in any sub-directory will get this ACE <lb/>inherited. <lb/>ACE4_DIRECTORY_INHERIT_ACE <lb/>Can be placed on a directory and indicates that this ACE should be <lb/>added to each new directory created. <lb/>If this flag is set in an ACE in an ACL attribute to be set on a <lb/>non-directory file system object, the operation attempting to set <lb/>the ACL SHOULD fail with NFS4ERR_ATTRNOTSUPP. <lb/>ACE4_NO_PROPAGATE_INHERIT_ACE <lb/>Can be placed on a directory. This flag tells the server that <lb/>inheritance of this ACE should stop at newly created child <lb/>directories. <lb/>ACE4_INHERIT_ONLY_ACE <lb/>Can be placed on a directory but does not apply to the directory; <lb/>ALLOW and DENY ACEs with this bit set do not affect access to the <lb/>directory, and AUDIT and ALARM ACEs with this bit set do not <lb/>trigger log or alarm events. Such ACEs only take effect once they <lb/>are applied (with this bit cleared) to newly created files and <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 140] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>directories as specified by the ACE4_FILE_INHERIT_ACE and <lb/>ACE4_DIRECTORY_INHERIT_ACE flags. <lb/>If this flag is present on an ACE, but neither <lb/>ACE4_DIRECTORY_INHERIT_ACE nor ACE4_FILE_INHERIT_ACE is present, <lb/>then an operation attempting to set such an attribute SHOULD fail <lb/>with NFS4ERR_ATTRNOTSUPP. <lb/>ACE4_SUCCESSFUL_ACCESS_ACE_FLAG <lb/>ACE4_FAILED_ACCESS_ACE_FLAG <lb/>The ACE4_SUCCESSFUL_ACCESS_ACE_FLAG (SUCCESS) and <lb/>ACE4_FAILED_ACCESS_ACE_FLAG (FAILED) flag bits may be set only on <lb/>ACE4_SYSTEM_AUDIT_ACE_TYPE (AUDIT) and ACE4_SYSTEM_ALARM_ACE_TYPE <lb/>(ALARM) ACE types. If during the processing of the file&apos;s ACL, <lb/>the server encounters an AUDIT or ALARM ACE that matches the <lb/>principal attempting the OPEN, the server notes that fact, and the <lb/>presence, if any, of the SUCCESS and FAILED flags encountered in <lb/>the AUDIT or ALARM ACE. Once the server completes the ACL <lb/>processing, it then notes if the operation succeeded or failed. <lb/>If the operation succeeded, and if the SUCCESS flag was set for a <lb/>matching AUDIT or ALARM ACE, then the appropriate AUDIT or ALARM <lb/>event occurs. If the operation failed, and if the FAILED flag was <lb/>set for the matching AUDIT or ALARM ACE, then the appropriate <lb/>AUDIT or ALARM event occurs. Either or both of the SUCCESS or <lb/>FAILED can be set, but if neither is set, the AUDIT or ALARM ACE <lb/>is not useful. <lb/>The previously described processing applies to ACCESS operations <lb/>even when they return NFS4_OK. For the purposes of AUDIT and <lb/>ALARM, we consider an ACCESS operation to be a &quot;failure&quot; if it <lb/>fails to return a bit that was requested and supported. <lb/>ACE4_IDENTIFIER_GROUP <lb/>Indicates that the &quot;who&quot; refers to a GROUP as defined under UNIX <lb/>or a GROUP ACCOUNT as defined under Windows. Clients and servers <lb/>MUST ignore the ACE4_IDENTIFIER_GROUP flag on ACEs with a who <lb/>value equal to one of the special identifiers outlined in <lb/>Section 6.2.1.5. <lb/>ACE4_INHERITED_ACE <lb/>Indicates that this ACE is inherited from a parent directory. A <lb/>server that supports automatic inheritance will place this flag on <lb/>any ACEs inherited from the parent directory when creating a new <lb/>object. Client applications will use this to perform automatic <lb/>inheritance. Clients and servers MUST clear this bit in the acl <lb/>attribute; it may only be used in the dacl and sacl attributes. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 141] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>6.2.1.5. ACE Who <lb/>The &quot;who&quot; field of an ACE is an identifier that specifies the <lb/>principal or principals to whom the ACE applies. It may refer to a <lb/>user or a group, with the flag bit ACE4_IDENTIFIER_GROUP specifying <lb/>which. <lb/>There are several special identifiers that need to be understood <lb/>universally, rather than in the context of a particular DNS domain. <lb/>Some of these identifiers cannot be understood when an NFS client <lb/>accesses the server, but have meaning when a local process accesses <lb/>the file. The ability to display and modify these permissions is <lb/>permitted over NFS, even if none of the access methods on the server <lb/>understands the identifiers. <lb/>+---------------+---------------------------------------------------+ <lb/>| Who <lb/>| Description <lb/>| <lb/>+---------------+---------------------------------------------------+ <lb/>| OWNER <lb/>| The owner of the file. <lb/>| <lb/>| GROUP <lb/>| The group associated with the file. <lb/>| <lb/>| EVERYONE <lb/>| The world, including the owner and owning group. | <lb/>| INTERACTIVE <lb/>| Accessed from an interactive terminal. <lb/>| <lb/>| NETWORK <lb/>| Accessed via the network. <lb/>| <lb/>| DIALUP <lb/>| Accessed as a dialup user to the server. <lb/>| <lb/>| BATCH <lb/>| Accessed from a batch job. <lb/>| <lb/>| ANONYMOUS <lb/>| Accessed without any authentication. <lb/>| <lb/>| AUTHENTICATED | Any authenticated user (opposite of ANONYMOUS). <lb/>| <lb/>| SERVICE <lb/>| Access from a system service. <lb/>| <lb/>+---------------+---------------------------------------------------+ <lb/>Table 4 <lb/>To avoid conflict, these special identifiers are distinguished by an <lb/>appended &quot;@&quot; and should appear in the form &quot;xxxx@&quot; (with no domain <lb/>name after the &quot;@&quot;), for example, ANONYMOUS@. <lb/>The ACE4_IDENTIFIER_GROUP flag MUST be ignored on entries with these <lb/>special identifiers. When encoding entries with these special <lb/>identifiers, the ACE4_IDENTIFIER_GROUP flag SHOULD be set to zero. <lb/>6.2.1.5.1. Discussion of EVERYONE@ <lb/>It is important to note that &quot;EVERYONE@&quot; is not equivalent to the <lb/>UNIX &quot;other&quot; entity. This is because, by definition, UNIX &quot;other&quot; <lb/>does not include the owner or owning group of a file. &quot;EVERYONE@&quot; <lb/>means literally everyone, including the owner or owning group. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 142] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>6.2.2. Attribute 58: dacl <lb/>The dacl attribute is like the acl attribute, but dacl allows just <lb/>ALLOW and DENY ACEs. The dacl attribute supports automatic <lb/>inheritance (see Section 6.4.3.2). <lb/>6.2.3. Attribute 59: sacl <lb/>The sacl attribute is like the acl attribute, but sacl allows just <lb/>AUDIT and ALARM ACEs. The sacl attribute supports automatic <lb/>inheritance (see Section 6.4.3.2). <lb/>6.2.4. Attribute 33: mode <lb/>The NFSv4.1 mode attribute is based on the UNIX mode bits. The <lb/>following bits are defined: <lb/>const MODE4_SUID = 0x800; /* set user id on execution */ <lb/>const MODE4_SGID = 0x400; /* set group id on execution */ <lb/>const MODE4_SVTX = 0x200; /* save text even after use */ <lb/>const MODE4_RUSR = 0x100; /* read permission: owner */ <lb/>const MODE4_WUSR = 0x080; /* write permission: owner */ <lb/>const MODE4_XUSR = 0x040; /* execute permission: owner */ <lb/>const MODE4_RGRP = 0x020; /* read permission: group */ <lb/>const MODE4_WGRP = 0x010; /* write permission: group */ <lb/>const MODE4_XGRP = 0x008; /* execute permission: group */ <lb/>const MODE4_ROTH = 0x004; /* read permission: other */ <lb/>const MODE4_WOTH = 0x002; /* write permission: other */ <lb/>const MODE4_XOTH = 0x001; /* execute permission: other */ <lb/>Bits MODE4_RUSR, MODE4_WUSR, and MODE4_XUSR apply to the principal <lb/>identified in the owner attribute. Bits MODE4_RGRP, MODE4_WGRP, and <lb/>MODE4_XGRP apply to principals identified in the owner_group <lb/>attribute but who are not identified in the owner attribute. Bits <lb/>MODE4_ROTH, MODE4_WOTH, and MODE4_XOTH apply to any principal that <lb/>does not match that in the owner attribute and does not have a group <lb/>matching that of the owner_group attribute. <lb/>Bits within a mode other than those specified above are not defined <lb/>by this protocol. A server MUST NOT return bits other than those <lb/>defined above in a GETATTR or READDIR operation, and it MUST return <lb/>NFS4ERR_INVAL if bits other than those defined above are set in a <lb/>SETATTR, CREATE, OPEN, VERIFY, or NVERIFY operation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 143] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>6.2.5. Attribute 74: mode_set_masked <lb/>The mode_set_masked attribute is a write-only attribute that allows <lb/>individual bits in the mode attribute to be set or reset, without <lb/>changing others. It allows, for example, the bits MODE4_SUID, <lb/>MODE4_SGID, and MODE4_SVTX to be modified while leaving unmodified <lb/>any of the nine low-order mode bits devoted to permissions. <lb/>In such instances that the nine low-order bits are left unmodified, <lb/>then neither the acl nor the dacl attribute should be automatically <lb/>modified as discussed in Section 6.4.1. <lb/>The mode_set_masked attribute consists of two words, each in the form <lb/>of a mode4. The first consists of the value to be applied to the <lb/>current mode value and the second is a mask. Only bits set to one in <lb/>the mask word are changed (set or reset) in the file&apos;s mode. All <lb/>other bits in the mode remain unchanged. Bits in the first word that <lb/>correspond to bits that are zero in the mask are ignored, except that <lb/>undefined bits are checked for validity and can result in <lb/>NFS4ERR_INVAL as described below. <lb/>The mode_set_masked attribute is only valid in a SETATTR operation. <lb/>If it is used in a CREATE or OPEN operation, the server MUST return <lb/>NFS4ERR_INVAL. <lb/>Bits not defined as valid in the mode attribute are not valid in <lb/>either word of the mode_set_masked attribute. The server MUST return <lb/>NFS4ERR_INVAL if any such bits are set to one in a SETATTR. If the <lb/>mode and mode_set_masked attributes are both specified in the same <lb/>SETATTR, the server MUST also return NFS4ERR_INVAL. <lb/>6.3. Common Methods <lb/>The requirements in this section will be referred to in future <lb/>sections, especially Section 6.4. <lb/>6.3.1. Interpreting an ACL <lb/>6.3.1.1. Server Considerations <lb/>The server uses the algorithm described in Section 6.2.1 to determine <lb/>whether an ACL allows access to an object. However, the ACL might <lb/>not be the sole determiner of access. For example: <lb/>o In the case of a file system exported as read-only, the server may <lb/>deny write access even though an object&apos;s ACL grants it. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 144] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o Server implementations MAY grant ACE4_WRITE_ACL and ACE4_READ_ACL <lb/>permissions to prevent a situation from arising in which there is <lb/>no valid way to ever modify the ACL. <lb/>o All servers will allow a user the ability to read the data of the <lb/>file when only the execute permission is granted (i.e., if the ACL <lb/>denies the user the ACE4_READ_DATA access and allows the user <lb/>ACE4_EXECUTE, the server will allow the user to read the data of <lb/>the file). <lb/>o Many servers have the notion of owner-override in which the owner <lb/>of the object is allowed to override accesses that are denied by <lb/>the ACL. This may be helpful, for example, to allow users <lb/>continued access to open files on which the permissions have <lb/>changed. <lb/>o Many servers have the notion of a &quot;superuser&quot; that has privileges <lb/>beyond an ordinary user. The superuser may be able to read or <lb/>write data or metadata in ways that would not be permitted by the <lb/>ACL. <lb/>o A retention attribute might also block access otherwise allowed by <lb/>ACLs (see Section 5.13). <lb/>6.3.1.2. Client Considerations <lb/>Clients SHOULD NOT do their own access checks based on their <lb/>interpretation of the ACL, but rather use the OPEN and ACCESS <lb/>operations to do access checks. This allows the client to act on the <lb/>results of having the server determine whether or not access should <lb/>be granted based on its interpretation of the ACL. <lb/>Clients must be aware of situations in which an object&apos;s ACL will <lb/>define a certain access even though the server will not enforce it. <lb/>In general, but especially in these situations, the client needs to <lb/>do its part in the enforcement of access as defined by the ACL. To <lb/>do this, the client MAY send the appropriate ACCESS operation prior <lb/>to servicing the request of the user or application in order to <lb/>determine whether the user or application should be granted the <lb/>access requested. For examples in which the ACL may define accesses <lb/>that the server doesn&apos;t enforce, see Section 6.3.1.1. <lb/>6.3.2. Computing a Mode Attribute from an ACL <lb/>The following method can be used to calculate the MODE4_R*, MODE4_W*, <lb/>and MODE4_X* bits of a mode attribute, based upon an ACL. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 145] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>First, for each of the special identifiers OWNER@, GROUP@, and <lb/>EVERYONE@, evaluate the ACL in order, considering only ALLOW and DENY <lb/>ACEs for the identifier EVERYONE@ and for the identifier under <lb/>consideration. The result of the evaluation will be an NFSv4 ACL <lb/>mask showing exactly which bits are permitted to that identifier. <lb/>Then translate the calculated mask for OWNER@, GROUP@, and EVERYONE@ <lb/>into mode bits for, respectively, the user, group, and other, as <lb/>follows: <lb/>1. Set the read bit (MODE4_RUSR, MODE4_RGRP, or MODE4_ROTH) if and <lb/>only if ACE4_READ_DATA is set in the corresponding mask. <lb/>2. Set the write bit (MODE4_WUSR, MODE4_WGRP, or MODE4_WOTH) if and <lb/>only if ACE4_WRITE_DATA and ACE4_APPEND_DATA are both set in the <lb/>corresponding mask. <lb/>3. Set the execute bit (MODE4_XUSR, MODE4_XGRP, or MODE4_XOTH), if <lb/>and only if ACE4_EXECUTE is set in the corresponding mask. <lb/>6.3.2.1. Discussion <lb/>Some server implementations also add bits permitted to named users <lb/>and groups to the group bits (MODE4_RGRP, MODE4_WGRP, and <lb/>MODE4_XGRP). <lb/>Implementations are discouraged from doing this, because it has been <lb/>found to cause confusion for users who see members of a file&apos;s group <lb/>denied access that the mode bits appear to allow. (The presence of <lb/>DENY ACEs may also lead to such behavior, but DENY ACEs are expected <lb/>to be more rarely used.) <lb/>The same user confusion seen when fetching the mode also results if <lb/>setting the mode does not effectively control permissions for the <lb/>owner, group, and other users; this motivates some of the <lb/>requirements that follow. <lb/>6.4. Requirements <lb/>The server that supports both mode and ACL must take care to <lb/>synchronize the MODE4_*USR, MODE4_*GRP, and MODE4_*OTH bits with the <lb/>ACEs that have respective who fields of &quot;OWNER@&quot;, &quot;GROUP@&quot;, and <lb/>&quot;EVERYONE@&quot;. This way, the client can see if semantically equivalent <lb/>access permissions exist whether the client asks for the owner, <lb/>owner_group, and mode attributes or for just the ACL. <lb/>In this section, much is made of the methods in Section 6.3.2. Many <lb/>requirements refer to this section. But note that the methods have <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 146] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>behaviors specified with &quot;SHOULD&quot;. This is intentional, to avoid <lb/>invalidating existing implementations that compute the mode according <lb/>to the withdrawn POSIX ACL draft (1003.1e draft 17), rather than by <lb/>actual permissions on owner, group, and other. <lb/>6.4.1. Setting the Mode and/or ACL Attributes <lb/>In the case where a server supports the sacl or dacl attribute, in <lb/>addition to the acl attribute, the server MUST fail a request to set <lb/>the acl attribute simultaneously with a dacl or sacl attribute. The <lb/>error to be given is NFS4ERR_ATTRNOTSUPP. <lb/>6.4.1.1. Setting Mode and not ACL <lb/>When any of the nine low-order mode bits are subject to change, <lb/>either because the mode attribute was set or because the <lb/>mode_set_masked attribute was set and the mask included one or more <lb/>bits from the nine low-order mode bits, and no ACL attribute is <lb/>explicitly set, the acl and dacl attributes must be modified in <lb/>accordance with the updated value of those bits. This must happen <lb/>even if the value of the low-order bits is the same after the mode is <lb/>set as before. <lb/>Note that any AUDIT or ALARM ACEs (hence any ACEs in the sacl <lb/>attribute) are unaffected by changes to the mode. <lb/>In cases in which the permissions bits are subject to change, the acl <lb/>and dacl attributes MUST be modified such that the mode computed via <lb/>the method in Section 6.3.2 yields the low-order nine bits (MODE4_R*, <lb/>MODE4_W*, MODE4_X*) of the mode attribute as modified by the <lb/>attribute change. The ACL attributes SHOULD also be modified such <lb/>that: <lb/>1. If MODE4_RGRP is not set, entities explicitly listed in the ACL <lb/>other than OWNER@ and EVERYONE@ SHOULD NOT be granted <lb/>ACE4_READ_DATA. <lb/>2. If MODE4_WGRP is not set, entities explicitly listed in the ACL <lb/>other than OWNER@ and EVERYONE@ SHOULD NOT be granted <lb/>ACE4_WRITE_DATA or ACE4_APPEND_DATA. <lb/>3. If MODE4_XGRP is not set, entities explicitly listed in the ACL <lb/>other than OWNER@ and EVERYONE@ SHOULD NOT be granted <lb/>ACE4_EXECUTE. <lb/>Access mask bits other than those listed above, appearing in ALLOW <lb/>ACEs, MAY also be disabled. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 147] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Note that ACEs with the flag ACE4_INHERIT_ONLY_ACE set do not affect <lb/>the permissions of the ACL itself, nor do ACEs of the type AUDIT and <lb/>ALARM. As such, it is desirable to leave these ACEs unmodified when <lb/>modifying the ACL attributes. <lb/>Also note that the requirement may be met by discarding the acl and <lb/>dacl, in favor of an ACL that represents the mode and only the mode. <lb/>This is permitted, but it is preferable for a server to preserve as <lb/>much of the ACL as possible without violating the above requirements. <lb/>Discarding the ACL makes it effectively impossible for a file created <lb/>with a mode attribute to inherit an ACL (see Section 6.4.3). <lb/>6.4.1.2. Setting ACL and Not Mode <lb/>When setting the acl or dacl and not setting the mode or <lb/>mode_set_masked attributes, the permission bits of the mode need to <lb/>be derived from the ACL. In this case, the ACL attribute SHOULD be <lb/>set as given. The nine low-order bits of the mode attribute <lb/>(MODE4_R*, MODE4_W*, MODE4_X*) MUST be modified to match the result <lb/>of the method in Section 6.3.2. The three high-order bits of the <lb/>mode (MODE4_SUID, MODE4_SGID, MODE4_SVTX) SHOULD remain unchanged. <lb/>6.4.1.3. Setting Both ACL and Mode <lb/>When setting both the mode (includes use of either the mode attribute <lb/>or the mode_set_masked attribute) and the acl or dacl attributes in <lb/>the same operation, the attributes MUST be applied in this order: <lb/>mode (or mode_set_masked), then ACL. The mode-related attribute is <lb/>set as given, then the ACL attribute is set as given, possibly <lb/>changing the final mode, as described above in Section 6.4.1.2. <lb/>6.4.2. Retrieving the Mode and/or ACL Attributes <lb/>This section applies only to servers that support both the mode and <lb/>ACL attributes. <lb/>Some server implementations may have a concept of &quot;objects without <lb/>ACLs&quot;, meaning that all permissions are granted and denied according <lb/>to the mode attribute and that no ACL attribute is stored for that <lb/>object. If an ACL attribute is requested of such a server, the <lb/>server SHOULD return an ACL that does not conflict with the mode; <lb/>that is to say, the ACL returned SHOULD represent the nine low-order <lb/>bits of the mode attribute (MODE4_R*, MODE4_W*, MODE4_X*) as <lb/>described in Section 6.3.2. <lb/>For other server implementations, the ACL attribute is always present <lb/>for every object. Such servers SHOULD store at least the three high-<lb/>order bits of the mode attribute (MODE4_SUID, MODE4_SGID, <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 148] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>MODE4_SVTX). The server SHOULD return a mode attribute if one is <lb/>requested, and the low-order nine bits of the mode (MODE4_R*, <lb/>MODE4_W*, MODE4_X*) MUST match the result of applying the method in <lb/>Section 6.3.2 to the ACL attribute. <lb/>6.4.3. Creating New Objects <lb/>If a server supports any ACL attributes, it may use the ACL <lb/>attributes on the parent directory to compute an initial ACL <lb/>attribute for a newly created object. This will be referred to as <lb/>the inherited ACL within this section. The act of adding one or more <lb/>ACEs to the inherited ACL that are based upon ACEs in the parent <lb/>directory&apos;s ACL will be referred to as inheriting an ACE within this <lb/>section. <lb/>Implementors should standardize what the behavior of CREATE and OPEN <lb/>must be depending on the presence or absence of the mode and ACL <lb/>attributes. <lb/>1. If just the mode is given in the call: <lb/>In this case, inheritance SHOULD take place, but the mode MUST be <lb/>applied to the inherited ACL as described in Section 6.4.1.1, <lb/>thereby modifying the ACL. <lb/>2. If just the ACL is given in the call: <lb/>In this case, inheritance SHOULD NOT take place, and the ACL as <lb/>defined in the CREATE or OPEN will be set without modification, <lb/>and the mode modified as in Section 6.4.1.2. <lb/>3. If both mode and ACL are given in the call: <lb/>In this case, inheritance SHOULD NOT take place, and both <lb/>attributes will be set as described in Section 6.4.1.3. <lb/>4. If neither mode nor ACL is given in the call: <lb/>In the case where an object is being created without any initial <lb/>attributes at all, e.g., an OPEN operation with an opentype4 of <lb/>OPEN4_CREATE and a createmode4 of EXCLUSIVE4, inheritance SHOULD <lb/>NOT take place (note that EXCLUSIVE4_1 is a better choice of <lb/>createmode4, since it does permit initial attributes). Instead, <lb/>the server SHOULD set permissions to deny all access to the newly <lb/>created object. It is expected that the appropriate client will <lb/>set the desired attributes in a subsequent SETATTR operation, and <lb/>the server SHOULD allow that operation to succeed, regardless of <lb/>what permissions the object is created with. For example, an <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 149] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>empty ACL denies all permissions, but the server should allow the <lb/>owner&apos;s SETATTR to succeed even though WRITE_ACL is implicitly <lb/>denied. <lb/>In other cases, inheritance SHOULD take place, and no <lb/>modifications to the ACL will happen. The mode attribute, if <lb/>supported, MUST be as computed in Section 6.3.2, with the <lb/>MODE4_SUID, MODE4_SGID, and MODE4_SVTX bits clear. If no <lb/>inheritable ACEs exist on the parent directory, the rules for <lb/>creating acl, dacl, or sacl attributes are implementation <lb/>defined. If either the dacl or sacl attribute is supported, then <lb/>the ACL4_DEFAULTED flag SHOULD be set on the newly created <lb/>attributes. <lb/>6.4.3.1. The Inherited ACL <lb/>If the object being created is not a directory, the inherited ACL <lb/>SHOULD NOT inherit ACEs from the parent directory ACL unless the <lb/>ACE4_FILE_INHERIT_FLAG is set. <lb/>If the object being created is a directory, the inherited ACL should <lb/>inherit all inheritable ACEs from the parent directory, that is, <lb/>those that have the ACE4_FILE_INHERIT_ACE or <lb/>ACE4_DIRECTORY_INHERIT_ACE flag set. If the inheritable ACE has <lb/>ACE4_FILE_INHERIT_ACE set but ACE4_DIRECTORY_INHERIT_ACE is clear, <lb/>the inherited ACE on the newly created directory MUST have the <lb/>ACE4_INHERIT_ONLY_ACE flag set to prevent the directory from being <lb/>affected by ACEs meant for non-directories. <lb/>When a new directory is created, the server MAY split any inherited <lb/>ACE that is both inheritable and effective (in other words, that has <lb/>neither ACE4_INHERIT_ONLY_ACE nor ACE4_NO_PROPAGATE_INHERIT_ACE set), <lb/>into two ACEs, one with no inheritance flags and one with <lb/>ACE4_INHERIT_ONLY_ACE set. (In the case of a dacl or sacl attribute, <lb/>both of those ACEs SHOULD also have the ACE4_INHERITED_ACE flag set.) <lb/>This makes it simpler to modify the effective permissions on the <lb/>directory without modifying the ACE that is to be inherited to the <lb/>new directory&apos;s children. <lb/>6.4.3.2. Automatic Inheritance <lb/>The acl attribute consists only of an array of ACEs, but the sacl <lb/>(Section 6.2.3) and dacl (Section 6.2.2) attributes also include an <lb/>additional flag field. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 150] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct nfsacl41 { <lb/>aclflag4 <lb/>na41_flag; <lb/>nfsace4 <lb/>na41_aces&lt;&gt;; <lb/>}; <lb/>The flag field applies to the entire sacl or dacl; three flag values <lb/>are defined: <lb/>const ACL4_AUTO_INHERIT <lb/>= 0x00000001; <lb/>const ACL4_PROTECTED <lb/>= 0x00000002; <lb/>const ACL4_DEFAULTED <lb/>= 0x00000004; <lb/>and all other bits must be cleared. The ACE4_INHERITED_ACE flag may <lb/>be set in the ACEs of the sacl or dacl (whereas it must always be <lb/>cleared in the acl). <lb/>Together these features allow a server to support automatic <lb/>inheritance, which we now explain in more detail. <lb/>Inheritable ACEs are normally inherited by child objects only at the <lb/>time that the child objects are created; later modifications to <lb/>inheritable ACEs do not result in modifications to inherited ACEs on <lb/>descendants. <lb/>However, the dacl and sacl provide an OPTIONAL mechanism that allows <lb/>a client application to propagate changes to inheritable ACEs to an <lb/>entire directory hierarchy. <lb/>A server that supports this performs inheritance at object creation <lb/>time in the normal way, and SHOULD set the ACE4_INHERITED_ACE flag on <lb/>any inherited ACEs as they are added to the new object. <lb/>A client application such as an ACL editor may then propagate changes <lb/>to inheritable ACEs on a directory by recursively traversing that <lb/>directory&apos;s descendants and modifying each ACL encountered to remove <lb/>any ACEs with the ACE4_INHERITED_ACE flag and to replace them by the <lb/>new inheritable ACEs (also with the ACE4_INHERITED_ACE flag set). It <lb/>uses the existing ACE inheritance flags in the obvious way to decide <lb/>which ACEs to propagate. (Note that it may encounter further <lb/>inheritable ACEs when descending the directory hierarchy and that <lb/>those will also need to be taken into account when propagating <lb/>inheritable ACEs to further descendants.) <lb/>The reach of this propagation may be limited in two ways: first, <lb/>automatic inheritance is not performed from any directory ACL that <lb/>has the ACL4_AUTO_INHERIT flag cleared; and second, automatic <lb/>inheritance stops wherever an ACL with the ACL4_PROTECTED flag is <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 151] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>set, preventing modification of that ACL and also (if the ACL is set <lb/>on a directory) of the ACL on any of the object&apos;s descendants. <lb/>This propagation is performed independently for the sacl and the dacl <lb/>attributes; thus, the ACL4_AUTO_INHERIT and ACL4_PROTECTED flags may <lb/>be independently set for the sacl and the dacl, and propagation of <lb/>one type of acl may continue down a hierarchy even where propagation <lb/>of the other acl has stopped. <lb/>New objects should be created with a dacl and a sacl that both have <lb/>the ACL4_PROTECTED flag cleared and the ACL4_AUTO_INHERIT flag set to <lb/>the same value as that on, respectively, the sacl or dacl of the <lb/>parent object. <lb/>Both the dacl and sacl attributes are RECOMMENDED, and a server may <lb/>support one without supporting the other. <lb/>A server that supports both the old acl attribute and one or both of <lb/>the new dacl or sacl attributes must do so in such a way as to keep <lb/>all three attributes consistent with each other. Thus, the ACEs <lb/>reported in the acl attribute should be the union of the ACEs <lb/>reported in the dacl and sacl attributes, except that the <lb/>ACE4_INHERITED_ACE flag must be cleared from the ACEs in the acl. <lb/>And of course a client that queries only the acl will be unable to <lb/>determine the values of the sacl or dacl flag fields. <lb/>When a client performs a SETATTR for the acl attribute, the server <lb/>SHOULD set the ACL4_PROTECTED flag to true on both the sacl and the <lb/>dacl. By using the acl attribute, as opposed to the dacl or sacl <lb/>attributes, the client signals that it may not understand automatic <lb/>inheritance, and thus cannot be trusted to set an ACL for which <lb/>automatic inheritance would make sense. <lb/>When a client application queries an ACL, modifies it, and sets it <lb/>again, it should leave any ACEs marked with ACE4_INHERITED_ACE <lb/>unchanged, in their original order, at the end of the ACL. If the <lb/>application is unable to do this, it should set the ACL4_PROTECTED <lb/>flag. This behavior is not enforced by servers, but violations of <lb/>this rule may lead to unexpected results when applications perform <lb/>automatic inheritance. <lb/>If a server also supports the mode attribute, it SHOULD set the mode <lb/>in such a way that leaves inherited ACEs unchanged, in their original <lb/>order, at the end of the ACL. If it is unable to do so, it SHOULD <lb/>set the ACL4_PROTECTED flag on the file&apos;s dacl. <lb/>Finally, in the case where the request that creates a new file or <lb/>directory does not also set permissions for that file or directory, <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 152] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>and there are also no ACEs to inherit from the parent&apos;s directory, <lb/>then the server&apos;s choice of ACL for the new object is implementation-<lb/>dependent. In this case, the server SHOULD set the ACL4_DEFAULTED <lb/>flag on the ACL it chooses for the new object. An application <lb/>performing automatic inheritance takes the ACL4_DEFAULTED flag as a <lb/>sign that the ACL should be completely replaced by one generated <lb/>using the automatic inheritance rules. <lb/>7. Single-Server Namespace <lb/>This section describes the NFSv4 single-server namespace. Single-<lb/>server namespaces may be presented directly to clients, or they may <lb/>be used as a basis to form larger multi-server namespaces (e.g., <lb/>site-wide or organization-wide) to be presented to clients, as <lb/>described in Section 11. <lb/>7.1. Server Exports <lb/>On a UNIX server, the namespace describes all the files reachable by <lb/>pathnames under the root directory or &quot;/&quot;. On a Windows server, the <lb/>namespace constitutes all the files on disks named by mapped disk <lb/>letters. NFS server administrators rarely make the entire server&apos;s <lb/>file system namespace available to NFS clients. More often, portions <lb/>of the namespace are made available via an &quot;export&quot; feature. In <lb/>previous versions of the NFS protocol, the root filehandle for each <lb/>export is obtained through the MOUNT protocol; the client sent a <lb/>string that identified the export name within the namespace and the <lb/>server returned the root filehandle for that export. The MOUNT <lb/>protocol also provided an EXPORTS procedure that enumerated the <lb/>server&apos;s exports. <lb/>7.2. Browsing Exports <lb/>The NFSv4.1 protocol provides a root filehandle that clients can use <lb/>to obtain filehandles for the exports of a particular server, via a <lb/>series of LOOKUP operations within a COMPOUND, to traverse a path. A <lb/>common user experience is to use a graphical user interface (perhaps <lb/>a file &quot;Open&quot; dialog window) to find a file via progressive browsing <lb/>through a directory tree. The client must be able to move from one <lb/>export to another export via single-component, progressive LOOKUP <lb/>operations. <lb/>This style of browsing is not well supported by the NFSv3 protocol. <lb/>In NFSv3, the client expects all LOOKUP operations to remain within a <lb/>single server file system. For example, the device attribute will <lb/>not change. This prevents a client from taking namespace paths that <lb/>span exports. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 153] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>In the case of NFSv3, an automounter on the client can obtain a <lb/>snapshot of the server&apos;s namespace using the EXPORTS procedure of the <lb/>MOUNT protocol. If it understands the server&apos;s pathname syntax, it <lb/>can create an image of the server&apos;s namespace on the client. The <lb/>parts of the namespace that are not exported by the server are filled <lb/>in with directories that might be constructed similarly to an NFSv4.1 <lb/>&quot;pseudo file system&quot; (see Section 7.3) that allows the user to browse <lb/>from one mounted file system to another. There is a drawback to this <lb/>representation of the server&apos;s namespace on the client: it is static. <lb/>If the server administrator adds a new export, the client will be <lb/>unaware of it. <lb/>7.3. Server Pseudo File System <lb/>NFSv4.1 servers avoid this namespace inconsistency by presenting all <lb/>the exports for a given server within the framework of a single <lb/>namespace for that server. An NFSv4.1 client uses LOOKUP and READDIR <lb/>operations to browse seamlessly from one export to another. <lb/>Where there are portions of the server namespace that are not <lb/>exported, clients require some way of traversing those portions to <lb/>reach actual exported file systems. A technique that servers may use <lb/>to provide for this is to bridge the unexported portion of the <lb/>namespace via a &quot;pseudo file system&quot; that provides a view of exported <lb/>directories only. A pseudo file system has a unique fsid and behaves <lb/>like a normal, read-only file system. <lb/>Based on the construction of the server&apos;s namespace, it is possible <lb/>that multiple pseudo file systems may exist. For example, <lb/>/a <lb/>pseudo file system <lb/>/a/b <lb/>real file system <lb/>/a/b/c <lb/>pseudo file system <lb/>/a/b/c/d <lb/>real file system <lb/>Each of the pseudo file systems is considered a separate entity and <lb/>therefore MUST have its own fsid, unique among all the fsids for that <lb/>server. <lb/>7.4. Multiple Roots <lb/>Certain operating environments are sometimes described as having <lb/>&quot;multiple roots&quot;. In such environments, individual file systems are <lb/>commonly represented by disk or volume names. NFSv4 servers for <lb/>these platforms can construct a pseudo file system above these root <lb/>names so that disk letters or volume names are simply directory names <lb/>in the pseudo root. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 154] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>7.5. Filehandle Volatility <lb/>The nature of the server&apos;s pseudo file system is that it is a logical <lb/>representation of file system(s) available from the server. <lb/>Therefore, the pseudo file system is most likely constructed <lb/>dynamically when the server is first instantiated. It is expected <lb/>that the pseudo file system may not have an on-disk counterpart from <lb/>which persistent filehandles could be constructed. Even though it is <lb/>preferable that the server provide persistent filehandles for the <lb/>pseudo file system, the NFS client should expect that pseudo file <lb/>system filehandles are volatile. This can be confirmed by checking <lb/>the associated &quot;fh_expire_type&quot; attribute for those filehandles in <lb/>question. If the filehandles are volatile, the NFS client must be <lb/>prepared to recover a filehandle value (e.g., with a series of LOOKUP <lb/>operations) when receiving an error of NFS4ERR_FHEXPIRED. <lb/>Because it is quite likely that servers will implement pseudo file <lb/>systems using volatile filehandles, clients need to be prepared for <lb/>them, rather than assuming that all filehandles will be persistent. <lb/>7.6. Exported Root <lb/>If the server&apos;s root file system is exported, one might conclude that <lb/>a pseudo file system is unneeded. This is not necessarily so. <lb/>Assume the following file systems on a server: <lb/>/ <lb/>fs1 (exported) <lb/>/a <lb/>fs2 (not exported) <lb/>/a/b <lb/>fs3 (exported) <lb/>Because fs2 is not exported, fs3 cannot be reached with simple <lb/>LOOKUPs. The server must bridge the gap with a pseudo file system. <lb/>7.7. Mount Point Crossing <lb/>The server file system environment may be constructed in such a way <lb/>that one file system contains a directory that is &apos;covered&apos; or <lb/>mounted upon by a second file system. For example: <lb/>/a/b <lb/>(file system 1) <lb/>/a/b/c/d <lb/>(file system 2) <lb/>The pseudo file system for this server may be constructed to look <lb/>like: <lb/>/ <lb/>(place holder/not exported) <lb/>/a/b <lb/>(file system 1) <lb/>/a/b/c/d <lb/>(file system 2) <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 155] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>It is the server&apos;s responsibility to present the pseudo file system <lb/>that is complete to the client. If the client sends a LOOKUP request <lb/>for the path /a/b/c/d, the server&apos;s response is the filehandle of the <lb/>root of the file system /a/b/c/d. In previous versions of the NFS <lb/>protocol, the server would respond with the filehandle of directory <lb/>/a/b/c/d within the file system /a/b. <lb/>The NFS client will be able to determine if it crosses a server mount <lb/>point by a change in the value of the &quot;fsid&quot; attribute. <lb/>7.8. Security Policy and Namespace Presentation <lb/>Because NFSv4 clients possess the ability to change the security <lb/>mechanisms used, after determining what is allowed, by using SECINFO <lb/>and SECINFO_NONAME, the server SHOULD NOT present a different view of <lb/>the namespace based on the security mechanism being used by a client. <lb/>Instead, it should present a consistent view and return <lb/>NFS4ERR_WRONGSEC if an attempt is made to access data with an <lb/>inappropriate security mechanism. <lb/>If security considerations make it necessary to hide the existence of <lb/>a particular file system, as opposed to all of the data within it, <lb/>the server can apply the security policy of a shared resource in the <lb/>server&apos;s namespace to components of the resource&apos;s ancestors. For <lb/>example: <lb/>/ <lb/>(place holder/not exported) <lb/>/a/b <lb/>(file system 1) <lb/>/a/b/MySecretProject <lb/>(file system 2) <lb/>The /a/b/MySecretProject directory is a real file system and is the <lb/>shared resource. Suppose the security policy for /a/b/ <lb/>MySecretProject is Kerberos with integrity and it is desired to limit <lb/>knowledge of the existence of this file system. In this case, the <lb/>server should apply the same security policy to /a/b. This allows <lb/>for knowledge of the existence of a file system to be secured when <lb/>desirable. <lb/>For the case of the use of multiple, disjoint security mechanisms in <lb/>the server&apos;s resources, applying that sort of policy would result in <lb/>the higher-level file system not being accessible using any security <lb/>flavor. Therefore, that sort of configuration is not compatible with <lb/>hiding the existence (as opposed to the contents) from clients using <lb/>multiple disjoint sets of security flavors. <lb/>In other circumstances, a desirable policy is for the security of a <lb/>particular object in the server&apos;s namespace to include the union of <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 156] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>all security mechanisms of all direct descendants. A common and <lb/>convenient practice, unless strong security requirements dictate <lb/>otherwise, is to make the entire the pseudo file system accessible by <lb/>all of the valid security mechanisms. <lb/>Where there is concern about the security of data on the network, <lb/>clients should use strong security mechanisms to access the pseudo <lb/>file system in order to prevent man-in-the-middle attacks. <lb/>8. State Management <lb/>Integrating locking into the NFS protocol necessarily causes it to be <lb/>stateful. With the inclusion of such features as share reservations, <lb/>file and directory delegations, recallable layouts, and support for <lb/>mandatory byte-range locking, the protocol becomes substantially more <lb/>dependent on proper management of state than the traditional <lb/>combination of NFS and NLM (Network Lock Manager) [49]. These <lb/>features include expanded locking facilities, which provide some <lb/>measure of inter-client exclusion, but the state also offers features <lb/>not readily providable using a stateless model. There are three <lb/>components to making this state manageable: <lb/>o clear division between client and server <lb/>o ability to reliably detect inconsistency in state between client <lb/>and server <lb/>o simple and robust recovery mechanisms <lb/>In this model, the server owns the state information. The client <lb/>requests changes in locks and the server responds with the changes <lb/>made. Non-client-initiated changes in locking state are infrequent. <lb/>The client receives prompt notification of such changes and can <lb/>adjust its view of the locking state to reflect the server&apos;s changes. <lb/>Individual pieces of state created by the server and passed to the <lb/>client at its request are represented by 128-bit stateids. These <lb/>stateids may represent a particular open file, a set of byte-range <lb/>locks held by a particular owner, or a recallable delegation of <lb/>privileges to access a file in particular ways or at a particular <lb/>location. <lb/>In all cases, there is a transition from the most general information <lb/>that represents a client as a whole to the eventual lightweight <lb/>stateid used for most client and server locking interactions. The <lb/>details of this transition will vary with the type of object but it <lb/>always starts with a client ID. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 157] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>8.1. Client and Session ID <lb/>A client must establish a client ID (see Section 2.4) and then one or <lb/>more sessionids (see Section 2.10) before performing any operations <lb/>to open, byte-range lock, delegate, or obtain a layout for a file <lb/>object. Each session ID is associated with a specific client ID, and <lb/>thus serves as a shorthand reference to an NFSv4.1 client. <lb/>For some types of locking interactions, the client will represent <lb/>some number of internal locking entities called &quot;owners&quot;, which <lb/>normally correspond to processes internal to the client. For other <lb/>types of locking-related objects, such as delegations and layouts, no <lb/>such intermediate entities are provided for, and the locking-related <lb/>objects are considered to be transferred directly between the server <lb/>and a unitary client. <lb/>8.2. Stateid Definition <lb/>When the server grants a lock of any type (including opens, byte-<lb/>range locks, delegations, and layouts), it responds with a unique <lb/>stateid that represents a set of locks (often a single lock) for the <lb/>same file, of the same type, and sharing the same ownership <lb/>characteristics. Thus, opens of the same file by different open-<lb/>owners each have an identifying stateid. Similarly, each set of <lb/>byte-range locks on a file owned by a specific lock-owner has its own <lb/>identifying stateid. Delegations and layouts also have associated <lb/>stateids by which they may be referenced. The stateid is used as a <lb/>shorthand reference to a lock or set of locks, and given a stateid, <lb/>the server can determine the associated state-owner or state-owners <lb/>(in the case of an open-owner/lock-owner pair) and the associated <lb/>filehandle. When stateids are used, the current filehandle must be <lb/>the one associated with that stateid. <lb/>All stateids associated with a given client ID are associated with a <lb/>common lease that represents the claim of those stateids and the <lb/>objects they represent to be maintained by the server. See <lb/>Section 8.3 for a discussion of the lease. <lb/>The server may assign stateids independently for different clients. <lb/>A stateid with the same bit pattern for one client may designate an <lb/>entirely different set of locks for a different client. The stateid <lb/>is always interpreted with respect to the client ID associated with <lb/>the current session. Stateids apply to all sessions associated with <lb/>the given client ID, and the client may use a stateid obtained from <lb/>one session on another session associated with the same client ID. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 158] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>8.2.1. Stateid Types <lb/>With the exception of special stateids (see Section 8.2.3), each <lb/>stateid represents locking objects of one of a set of types defined <lb/>by the NFSv4.1 protocol. Note that in all these cases, where we <lb/>speak of guarantee, it is understood there are situations such as a <lb/>client restart, or lock revocation, that allow the guarantee to be <lb/>voided. <lb/>o Stateids may represent opens of files. <lb/>Each stateid in this case represents the OPEN state for a given <lb/>client ID/open-owner/filehandle triple. Such stateids are subject <lb/>to change (with consequent incrementing of the stateid&apos;s seqid) in <lb/>response to OPENs that result in upgrade and OPEN_DOWNGRADE <lb/>operations. <lb/>o Stateids may represent sets of byte-range locks. <lb/>All locks held on a particular file by a particular owner and <lb/>gotten under the aegis of a particular open file are associated <lb/>with a single stateid with the seqid being incremented whenever <lb/>LOCK and LOCKU operations affect that set of locks. <lb/>o Stateids may represent file delegations, which are recallable <lb/>guarantees by the server to the client that other clients will not <lb/>reference or modify a particular file, until the delegation is <lb/>returned. In NFSv4.1, file delegations may be obtained on both <lb/>regular and non-regular files. <lb/>A stateid represents a single delegation held by a client for a <lb/>particular filehandle. <lb/>o Stateids may represent directory delegations, which are recallable <lb/>guarantees by the server to the client that other clients will not <lb/>modify the directory, until the delegation is returned. <lb/>A stateid represents a single delegation held by a client for a <lb/>particular directory filehandle. <lb/>o Stateids may represent layouts, which are recallable guarantees by <lb/>the server to the client that particular files may be accessed via <lb/>an alternate data access protocol at specific locations. Such <lb/>access is limited to particular sets of byte-ranges and may <lb/>proceed until those byte-ranges are reduced or the layout is <lb/>returned. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 159] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>A stateid represents the set of all layouts held by a particular <lb/>client for a particular filehandle with a given layout type. The <lb/>seqid is updated as the layouts of that set of byte-ranges change, <lb/>via layout stateid changing operations such as LAYOUTGET and <lb/>LAYOUTRETURN. <lb/>8.2.2. Stateid Structure <lb/>Stateids are divided into two fields, a 96-bit &quot;other&quot; field <lb/>identifying the specific set of locks and a 32-bit &quot;seqid&quot; sequence <lb/>value. Except in the case of special stateids (see Section 8.2.3), a <lb/>particular value of the &quot;other&quot; field denotes a set of locks of the <lb/>same type (for example, byte-range locks, opens, delegations, or <lb/>layouts), for a specific file or directory, and sharing the same <lb/>ownership characteristics. The seqid designates a specific instance <lb/>of such a set of locks, and is incremented to indicate changes in <lb/>such a set of locks, either by the addition or deletion of locks from <lb/>the set, a change in the byte-range they apply to, or an upgrade or <lb/>downgrade in the type of one or more locks. <lb/>When such a set of locks is first created, the server returns a <lb/>stateid with seqid value of one. On subsequent operations that <lb/>modify the set of locks, the server is required to increment the <lb/>&quot;seqid&quot; field by one whenever it returns a stateid for the same <lb/>state-owner/file/type combination and there is some change in the set <lb/>of locks actually designated. In this case, the server will return a <lb/>stateid with an &quot;other&quot; field the same as previously used for that <lb/>state-owner/file/type combination, with an incremented &quot;seqid&quot; field. <lb/>This pattern continues until the seqid is incremented past <lb/>NFS4_UINT32_MAX, and one (not zero) is the next seqid value. <lb/>The purpose of the incrementing of the seqid is to allow the server <lb/>to communicate to the client the order in which operations that <lb/>modified locking state associated with a stateid have been processed <lb/>and to make it possible for the client to send requests that are <lb/>conditional on the set of locks not having changed since the stateid <lb/>in question was returned. <lb/>Except for layout stateids (Section 12.5.3), when a client sends a <lb/>stateid to the server, it has two choices with regard to the seqid <lb/>sent. It may set the seqid to zero to indicate to the server that it <lb/>wishes the most up-to-date seqid for that stateid&apos;s &quot;other&quot; field to <lb/>be used. This would be the common choice in the case of a stateid <lb/>sent with a READ or WRITE operation. It also may set a non-zero <lb/>value, in which case the server checks if that seqid is the correct <lb/>one. In that case, the server is required to return <lb/>NFS4ERR_OLD_STATEID if the seqid is lower than the most current value <lb/>and NFS4ERR_BAD_STATEID if the seqid is greater than the most current <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 160] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>value. This would be the common choice in the case of stateids sent <lb/>with a CLOSE or OPEN_DOWNGRADE. Because OPENs may be sent in <lb/>parallel for the same owner, a client might close a file without <lb/>knowing that an OPEN upgrade had been done by the server, changing <lb/>the lock in question. If CLOSE were sent with a zero seqid, the OPEN <lb/>upgrade would be cancelled before the client even received an <lb/>indication that an upgrade had happened. <lb/>When a stateid is sent by the server to the client as part of a <lb/>callback operation, it is not subject to checking for a current seqid <lb/>and returning NFS4ERR_OLD_STATEID. This is because the client is not <lb/>in a position to know the most up-to-date seqid and thus cannot <lb/>verify it. Unless specially noted, the seqid value for a stateid <lb/>sent by the server to the client as part of a callback is required to <lb/>be zero with NFS4ERR_BAD_STATEID returned if it is not. <lb/>In making comparisons between seqids, both by the client in <lb/>determining the order of operations and by the server in determining <lb/>whether the NFS4ERR_OLD_STATEID is to be returned, the possibility of <lb/>the seqid being swapped around past the NFS4_UINT32_MAX value needs <lb/>to be taken into account. When two seqid values are being compared, <lb/>the total count of slots for all sessions associated with the current <lb/>client is used to do this. When one seqid value is less than this <lb/>total slot count and another seqid value is greater than <lb/>NFS4_UINT32_MAX minus the total slot count, the former is to be <lb/>treated as lower than the latter, despite the fact that it is <lb/>numerically greater. <lb/>8.2.3. Special Stateids <lb/>Stateid values whose &quot;other&quot; field is either all zeros or all ones <lb/>are reserved. They may not be assigned by the server but have <lb/>special meanings defined by the protocol. The particular meaning <lb/>depends on whether the &quot;other&quot; field is all zeros or all ones and the <lb/>specific value of the &quot;seqid&quot; field. <lb/>The following combinations of &quot;other&quot; and &quot;seqid&quot; are defined in <lb/>NFSv4.1: <lb/>o When &quot;other&quot; and &quot;seqid&quot; are both zero, the stateid is treated as <lb/>a special anonymous stateid, which can be used in READ, WRITE, and <lb/>SETATTR requests to indicate the absence of any OPEN state <lb/>associated with the request. When an anonymous stateid value is <lb/>used and an existing open denies the form of access requested, <lb/>then access will be denied to the request. This stateid MUST NOT <lb/>be used on operations to data servers (Section 13.6). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 161] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o When &quot;other&quot; and &quot;seqid&quot; are both all ones, the stateid is a <lb/>special READ bypass stateid. When this value is used in WRITE or <lb/>SETATTR, it is treated like the anonymous value. When used in <lb/>READ, the server MAY grant access, even if access would normally <lb/>be denied to READ operations. This stateid MUST NOT be used on <lb/>operations to data servers. <lb/>o When &quot;other&quot; is zero and &quot;seqid&quot; is one, the stateid represents <lb/>the current stateid, which is whatever value is the last stateid <lb/>returned by an operation within the COMPOUND. In the case of an <lb/>OPEN, the stateid returned for the open file and not the <lb/>delegation is used. The stateid passed to the operation in place <lb/>of the special value has its &quot;seqid&quot; value set to zero, except <lb/>when the current stateid is used by the operation CLOSE or <lb/>OPEN_DOWNGRADE. If there is no operation in the COMPOUND that has <lb/>returned a stateid value, the server MUST return the error <lb/>NFS4ERR_BAD_STATEID. As illustrated in Figure 6, if the value of <lb/>a current stateid is a special stateid and the stateid of an <lb/>operation&apos;s arguments has &quot;other&quot; set to zero and &quot;seqid&quot; set to <lb/>one, then the server MUST return the error NFS4ERR_BAD_STATEID. <lb/>o When &quot;other&quot; is zero and &quot;seqid&quot; is NFS4_UINT32_MAX, the stateid <lb/>represents a reserved stateid value defined to be invalid. When <lb/>this stateid is used, the server MUST return the error <lb/>NFS4ERR_BAD_STATEID. <lb/>If a stateid value is used that has all zeros or all ones in the <lb/>&quot;other&quot; field but does not match one of the cases above, the server <lb/>MUST return the error NFS4ERR_BAD_STATEID. <lb/>Special stateids, unlike other stateids, are not associated with <lb/>individual client IDs or filehandles and can be used with all valid <lb/>client IDs and filehandles. In the case of a special stateid <lb/>designating the current stateid, the current stateid value <lb/>substituted for the special stateid is associated with a particular <lb/>client ID and filehandle, and so, if it is used where the current <lb/>filehandle does not match that associated with the current stateid, <lb/>the operation to which the stateid is passed will return <lb/>NFS4ERR_BAD_STATEID. <lb/>8.2.4. Stateid Lifetime and Validation <lb/>Stateids must remain valid until either a client restart or a server <lb/>restart or until the client returns all of the locks associated with <lb/>the stateid by means of an operation such as CLOSE or DELEGRETURN. <lb/>If the locks are lost due to revocation, as long as the client ID is <lb/>valid, the stateid remains a valid designation of that revoked state <lb/>until the client frees it by using FREE_STATEID. Stateids associated <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 162] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>with byte-range locks are an exception. They remain valid even if a <lb/>LOCKU frees all remaining locks, so long as the open file with which <lb/>they are associated remains open, unless the client frees the <lb/>stateids via the FREE_STATEID operation. <lb/>It should be noted that there are situations in which the client&apos;s <lb/>locks become invalid, without the client requesting they be returned. <lb/>These include lease expiration and a number of forms of lock <lb/>revocation within the lease period. It is important to note that in <lb/>these situations, the stateid remains valid and the client can use it <lb/>to determine the disposition of the associated lost locks. <lb/>An &quot;other&quot; value must never be reused for a different purpose (i.e., <lb/>different filehandle, owner, or type of locks) within the context of <lb/>a single client ID. A server may retain the &quot;other&quot; value for the <lb/>same purpose beyond the point where it may otherwise be freed, but if <lb/>it does so, it must maintain &quot;seqid&quot; continuity with previous values. <lb/>One mechanism that may be used to satisfy the requirement that the <lb/>server recognize invalid and out-of-date stateids is for the server <lb/>to divide the &quot;other&quot; field of the stateid into two fields. <lb/>o an index into a table of locking-state structures. <lb/>o a generation number that is incremented on each allocation of a <lb/>table entry for a particular use. <lb/>And then store in each table entry, <lb/>o the client ID with which the stateid is associated. <lb/>o the current generation number for the (at most one) valid stateid <lb/>sharing this index value. <lb/>o the filehandle of the file on which the locks are taken. <lb/>o an indication of the type of stateid (open, byte-range lock, file <lb/>delegation, directory delegation, layout). <lb/>o the last &quot;seqid&quot; value returned corresponding to the current <lb/>&quot;other&quot; value. <lb/>o an indication of the current status of the locks associated with <lb/>this stateid, in particular, whether these have been revoked and <lb/>if so, for what reason. <lb/>With this information, an incoming stateid can be validated and the <lb/>appropriate error returned when necessary. Special and non-special <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 163] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>stateids are handled separately. (See Section 8.2.3 for a discussion <lb/>of special stateids.) <lb/>Note that stateids are implicitly qualified by the current client ID, <lb/>as derived from the client ID associated with the current session. <lb/>Note, however, that the semantics of the session will prevent <lb/>stateids associated with a previous client or server instance from <lb/>being analyzed by this procedure. <lb/>If server restart has resulted in an invalid client ID or a session <lb/>ID that is invalid, SEQUENCE will return an error and the operation <lb/>that takes a stateid as an argument will never be processed. <lb/>If there has been a server restart where there is a persistent <lb/>session and all leased state has been lost, then the session in <lb/>question will, although valid, be marked as dead, and any operation <lb/>not satisfied by means of the reply cache will receive the error <lb/>NFS4ERR_DEADSESSION, and thus not be processed as indicated below. <lb/>When a stateid is being tested and the &quot;other&quot; field is all zeros or <lb/>all ones, a check that the &quot;other&quot; and &quot;seqid&quot; fields match a defined <lb/>combination for a special stateid is done and the results determined <lb/>as follows: <lb/>o If the &quot;other&quot; and &quot;seqid&quot; fields do not match a defined <lb/>combination associated with a special stateid, the error <lb/>NFS4ERR_BAD_STATEID is returned. <lb/>o If the special stateid is one designating the current stateid and <lb/>there is a current stateid, then the current stateid is <lb/>substituted for the special stateid and the checks appropriate to <lb/>non-special stateids are performed. <lb/>o If the combination is valid in general but is not appropriate to <lb/>the context in which the stateid is used (e.g., an all-zero <lb/>stateid is used when an OPEN stateid is required in a LOCK <lb/>operation), the error NFS4ERR_BAD_STATEID is also returned. <lb/>o Otherwise, the check is completed and the special stateid is <lb/>accepted as valid. <lb/>When a stateid is being tested, and the &quot;other&quot; field is neither all <lb/>zeros nor all ones, the following procedure could be used to validate <lb/>an incoming stateid and return an appropriate error, when necessary, <lb/>assuming that the &quot;other&quot; field would be divided into a table index <lb/>and an entry generation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 164] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o If the table index field is outside the range of the associated <lb/>table, return NFS4ERR_BAD_STATEID. <lb/>o If the selected table entry is of a different generation than that <lb/>specified in the incoming stateid, return NFS4ERR_BAD_STATEID. <lb/>o If the selected table entry does not match the current filehandle, <lb/>return NFS4ERR_BAD_STATEID. <lb/>o If the client ID in the table entry does not match the client ID <lb/>associated with the current session, return NFS4ERR_BAD_STATEID. <lb/>o If the stateid represents revoked state, then return <lb/>NFS4ERR_EXPIRED, NFS4ERR_ADMIN_REVOKED, or NFS4ERR_DELEG_REVOKED, <lb/>as appropriate. <lb/>o If the stateid type is not valid for the context in which the <lb/>stateid appears, return NFS4ERR_BAD_STATEID. Note that a stateid <lb/>may be valid in general, as would be reported by the TEST_STATEID <lb/>operation, but be invalid for a particular operation, as, for <lb/>example, when a stateid that doesn&apos;t represent byte-range locks is <lb/>passed to the non-from_open case of LOCK or to LOCKU, or when a <lb/>stateid that does not represent an open is passed to CLOSE or <lb/>OPEN_DOWNGRADE. In such cases, the server MUST return <lb/>NFS4ERR_BAD_STATEID. <lb/>o If the &quot;seqid&quot; field is not zero and it is greater than the <lb/>current sequence value corresponding to the current &quot;other&quot; field, <lb/>return NFS4ERR_BAD_STATEID. <lb/>o If the &quot;seqid&quot; field is not zero and it is less than the current <lb/>sequence value corresponding to the current &quot;other&quot; field, return <lb/>NFS4ERR_OLD_STATEID. <lb/>o Otherwise, the stateid is valid and the table entry should contain <lb/>any additional information about the type of stateid and <lb/>information associated with that particular type of stateid, such <lb/>as the associated set of locks, e.g., open-owner and lock-owner <lb/>information, as well as information on the specific locks, e.g., <lb/>open modes and byte-ranges. <lb/>8.2.5. Stateid Use for I/O Operations <lb/>Clients performing I/O operations need to select an appropriate <lb/>stateid based on the locks (including opens and delegations) held by <lb/>the client and the various types of state-owners sending the I/O <lb/>requests. SETATTR operations that change the file size are treated <lb/>like I/O operations in this regard. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 165] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The following rules, applied in order of decreasing priority, govern <lb/>the selection of the appropriate stateid. In following these rules, <lb/>the client will only consider locks of which it has actually received <lb/>notification by an appropriate operation response or callback. Note <lb/>that the rules are slightly different in the case of I/O to data <lb/>servers when file layouts are being used (see Section 13.9.1). <lb/>o If the client holds a delegation for the file in question, the <lb/>delegation stateid SHOULD be used. <lb/>o Otherwise, if the entity corresponding to the lock-owner (e.g., a <lb/>process) sending the I/O has a byte-range lock stateid for the <lb/>associated open file, then the byte-range lock stateid for that <lb/>lock-owner and open file SHOULD be used. <lb/>o If there is no byte-range lock stateid, then the OPEN stateid for <lb/>the open file in question SHOULD be used. <lb/>o Finally, if none of the above apply, then a special stateid SHOULD <lb/>be used. <lb/>Ignoring these rules may result in situations in which the server <lb/>does not have information necessary to properly process the request. <lb/>For example, when mandatory byte-range locks are in effect, if the <lb/>stateid does not indicate the proper lock-owner, via a lock stateid, <lb/>a request might be avoidably rejected. <lb/>The server however should not try to enforce these ordering rules and <lb/>should use whatever information is available to properly process I/O <lb/>requests. In particular, when a client has a delegation for a given <lb/>file, it SHOULD take note of this fact in processing a request, even <lb/>if it is sent with a special stateid. <lb/>8.2.6. Stateid Use for SETATTR Operations <lb/>Because each operation is associated with a session ID and from that <lb/>the clientid can be determined, operations do not need to include a <lb/>stateid for the server to be able to determine whether they should <lb/>cause a delegation to be recalled or are to be treated as done within <lb/>the scope of the delegation. <lb/>In the case of SETATTR operations, a stateid is present. In cases <lb/>other than those that set the file size, the client may send either a <lb/>special stateid or, when a delegation is held for the file in <lb/>question, a delegation stateid. While the server SHOULD validate the <lb/>stateid and may use the stateid to optimize the determination as to <lb/>whether a delegation is held, it SHOULD note the presence of a <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 166] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>delegation even when a special stateid is sent, and MUST accept a <lb/>valid delegation stateid when sent. <lb/>8.3. Lease Renewal <lb/>Each client/server pair, as represented by a client ID, has a single <lb/>lease. The purpose of the lease is to allow the client to indicate <lb/>to the server, in a low-overhead way, that it is active, and thus <lb/>that the server is to retain the client&apos;s locks. This arrangement <lb/>allows the server to remove stale locking-related objects that are <lb/>held by a client that has crashed or is otherwise unreachable, once <lb/>the relevant lease expires. This in turn allows other clients to <lb/>obtain conflicting locks without being delayed indefinitely by <lb/>inactive or unreachable clients. It is not a mechanism for cache <lb/>consistency and lease renewals may not be denied if the lease <lb/>interval has not expired. <lb/>Since each session is associated with a specific client (identified <lb/>by the client&apos;s client ID), any operation sent on that session is an <lb/>indication that the associated client is reachable. When a request <lb/>is sent for a given session, successful execution of a SEQUENCE <lb/>operation (or successful retrieval of the result of SEQUENCE from the <lb/>reply cache) on an unexpired lease will result in the lease being <lb/>implicitly renewed, for the standard renewal period (equal to the <lb/>lease_time attribute). <lb/>If the client ID&apos;s lease has not expired when the server receives a <lb/>SEQUENCE operation, then the server MUST renew the lease. If the <lb/>client ID&apos;s lease has expired when the server receives a SEQUENCE <lb/>operation, the server MAY renew the lease; this depends on whether <lb/>any state was revoked as a result of the client&apos;s failure to renew <lb/>the lease before expiration. <lb/>Absent other activity that would renew the lease, a COMPOUND <lb/>consisting of a single SEQUENCE operation will suffice. The client <lb/>should also take communication-related delays into account and take <lb/>steps to ensure that the renewal messages actually reach the server <lb/>in good time. For example: <lb/>o When trunking is in effect, the client should consider sending <lb/>multiple requests on different connections, in order to ensure <lb/>that renewal occurs, even in the event of blockage in the path <lb/>used for one of those connections. <lb/>o Transport retransmission delays might become so large as to <lb/>approach or exceed the length of the lease period. This may be <lb/>particularly likely when the server is unresponsive due to a <lb/>restart; see Section 8.4.2.1. If the client implementation is not <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 167] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>careful, transport retransmission delays can result in the client <lb/>failing to detect a server restart before the grace period ends. <lb/>The scenario is that the client is using a transport with <lb/>exponential backoff, such that the maximum retransmission timeout <lb/>exceeds both the grace period and the lease_time attribute. A <lb/>network partition causes the client&apos;s connection&apos;s retransmission <lb/>interval to back off, and even after the partition heals, the next <lb/>transport-level retransmission is sent after the server has <lb/>restarted and its grace period ends. <lb/>The client MUST either recover from the ensuing NFS4ERR_NO_GRACE <lb/>errors or it MUST ensure that, despite transport-level <lb/>retransmission intervals that exceed the lease_time, a SEQUENCE <lb/>operation is sent that renews the lease before expiration. The <lb/>client can achieve this by associating a new connection with the <lb/>session, and sending a SEQUENCE operation on it. However, if the <lb/>attempt to establish a new connection is delayed for some reason <lb/>(e.g., exponential backoff of the connection establishment <lb/>packets), the client will have to abort the connection <lb/>establishment attempt before the lease expires, and attempt to <lb/>reconnect. <lb/>If the server renews the lease upon receiving a SEQUENCE operation, <lb/>the server MUST NOT allow the lease to expire while the rest of the <lb/>operations in the COMPOUND procedure&apos;s request are still executing. <lb/>Once the last operation has finished, and the response to COMPOUND <lb/>has been sent, the server MUST set the lease to expire no sooner than <lb/>the sum of current time and the value of the lease_time attribute. <lb/>A client ID&apos;s lease can expire when it has been at least the lease <lb/>interval (lease_time) since the last lease-renewing SEQUENCE <lb/>operation was sent on any of the client ID&apos;s sessions and there are <lb/>no active COMPOUND operations on any such sessions. <lb/>Because the SEQUENCE operation is the basic mechanism to renew a <lb/>lease, and because it must be done at least once for each lease <lb/>period, it is the natural mechanism whereby the server will inform <lb/>the client of changes in the lease status that the client needs to be <lb/>informed of. The client should inspect the status flags <lb/>(sr_status_flags) returned by sequence and take the appropriate <lb/>action (see Section 18.46.3 for details). <lb/>o The status bits SEQ4_STATUS_CB_PATH_DOWN and <lb/>SEQ4_STATUS_CB_PATH_DOWN_SESSION indicate problems with the <lb/>backchannel that the client may need to address in order to <lb/>receive callback requests. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 168] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o The status bits SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRING and <lb/>SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRED indicate problems with GSS <lb/>contexts or RPCSEC_GSS handles for the backchannel that the client <lb/>might have to address in order to allow callback requests to be <lb/>sent. <lb/>o The status bits SEQ4_STATUS_EXPIRED_ALL_STATE_REVOKED, <lb/>SEQ4_STATUS_EXPIRED_SOME_STATE_REVOKED, <lb/>SEQ4_STATUS_ADMIN_STATE_REVOKED, and <lb/>SEQ4_STATUS_RECALLABLE_STATE_REVOKED notify the client of lock <lb/>revocation events. When these bits are set, the client should use <lb/>TEST_STATEID to find what stateids have been revoked and use <lb/>FREE_STATEID to acknowledge loss of the associated state. <lb/>o The status bit SEQ4_STATUS_LEASE_MOVE indicates that <lb/>responsibility for lease renewal has been transferred to one or <lb/>more new servers. <lb/>o The status bit SEQ4_STATUS_RESTART_RECLAIM_NEEDED indicates that <lb/>due to server restart the client must reclaim locking state. <lb/>o The status bit SEQ4_STATUS_BACKCHANNEL_FAULT indicates that the <lb/>server has encountered an unrecoverable fault with the backchannel <lb/>(e.g., it has lost track of a sequence ID for a slot in the <lb/>backchannel). <lb/>8.4. Crash Recovery <lb/>A critical requirement in crash recovery is that both the client and <lb/>the server know when the other has failed. Additionally, it is <lb/>required that a client sees a consistent view of data across server <lb/>restarts. All READ and WRITE operations that may have been queued <lb/>within the client or network buffers must wait until the client has <lb/>successfully recovered the locks protecting the READ and WRITE <lb/>operations. Any that reach the server before the server can safely <lb/>determine that the client has recovered enough locking state to be <lb/>sure that such operations can be safely processed must be rejected. <lb/>This will happen because either: <lb/>o The state presented is no longer valid since it is associated with <lb/>a now invalid client ID. In this case, the client will receive <lb/>either an NFS4ERR_BADSESSION or NFS4ERR_DEADSESSION error, and any <lb/>attempt to attach a new session to that invalid client ID will <lb/>result in an NFS4ERR_STALE_CLIENTID error. <lb/>o Subsequent recovery of locks may make execution of the operation <lb/>inappropriate (NFS4ERR_GRACE). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 169] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>8.4.1. Client Failure and Recovery <lb/>In the event that a client fails, the server may release the client&apos;s <lb/>locks when the associated lease has expired. Conflicting locks from <lb/>another client may only be granted after this lease expiration. As <lb/>discussed in Section 8.3, when a client has not failed and re-<lb/>establishes its lease before expiration occurs, requests for <lb/>conflicting locks will not be granted. <lb/>To minimize client delay upon restart, lock requests are associated <lb/>with an instance of the client by a client-supplied verifier. This <lb/>verifier is part of the client_owner4 sent in the initial EXCHANGE_ID <lb/>call made by the client. The server returns a client ID as a result <lb/>of the EXCHANGE_ID operation. The client then confirms the use of <lb/>the client ID by establishing a session associated with that client <lb/>ID (see Section 18.36.3 for a description of how this is done). All <lb/>locks, including opens, byte-range locks, delegations, and layouts <lb/>obtained by sessions using that client ID, are associated with that <lb/>client ID. <lb/>Since the verifier will be changed by the client upon each <lb/>initialization, the server can compare a new verifier to the verifier <lb/>associated with currently held locks and determine that they do not <lb/>match. This signifies the client&apos;s new instantiation and subsequent <lb/>loss (upon confirmation of the new client ID) of locking state. As a <lb/>result, the server is free to release all locks held that are <lb/>associated with the old client ID that was derived from the old <lb/>verifier. At this point, conflicting locks from other clients, kept <lb/>waiting while the lease had not yet expired, can be granted. In <lb/>addition, all stateids associated with the old client ID can also be <lb/>freed, as they are no longer reference-able. <lb/>Note that the verifier must have the same uniqueness properties as <lb/>the verifier for the COMMIT operation. <lb/>8.4.2. Server Failure and Recovery <lb/>If the server loses locking state (usually as a result of a restart), <lb/>it must allow clients time to discover this fact and re-establish the <lb/>lost locking state. The client must be able to re-establish the <lb/>locking state without having the server deny valid requests because <lb/>the server has granted conflicting access to another client. <lb/>Likewise, if there is a possibility that clients have not yet re-<lb/>established their locking state for a file and that such locking <lb/>state might make it invalid to perform READ or WRITE operations. For <lb/>example, if mandatory locks are a possibility, the server must <lb/>disallow READ and WRITE operations for that file. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 170] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>A client can determine that loss of locking state has occurred via <lb/>several methods. <lb/>1. When a SEQUENCE (most common) or other operation returns <lb/>NFS4ERR_BADSESSION, this may mean that the session has been <lb/>destroyed but the client ID is still valid. The client sends a <lb/>CREATE_SESSION request with the client ID to re-establish the <lb/>session. If CREATE_SESSION fails with NFS4ERR_STALE_CLIENTID, <lb/>the client must establish a new client ID (see Section 8.1) and <lb/>re-establish its lock state with the new client ID, after the <lb/>CREATE_SESSION operation succeeds (see Section 8.4.2.1). <lb/>2. When a SEQUENCE (most common) or other operation on a persistent <lb/>session returns NFS4ERR_DEADSESSION, this indicates that a <lb/>session is no longer usable for new, i.e., not satisfied from the <lb/>reply cache, operations. Once all pending operations are <lb/>determined to be either performed before the retry or not <lb/>performed, the client sends a CREATE_SESSION request with the <lb/>client ID to re-establish the session. If CREATE_SESSION fails <lb/>with NFS4ERR_STALE_CLIENTID, the client must establish a new <lb/>client ID (see Section 8.1) and re-establish its lock state after <lb/>the CREATE_SESSION, with the new client ID, succeeds <lb/>(Section 8.4.2.1). <lb/>3. When an operation, neither SEQUENCE nor preceded by SEQUENCE (for <lb/>example, CREATE_SESSION, DESTROY_SESSION), returns <lb/>NFS4ERR_STALE_CLIENTID, the client MUST establish a new client ID <lb/>(Section 8.1) and re-establish its lock state (Section 8.4.2.1). <lb/>8.4.2.1. State Reclaim <lb/>When state information and the associated locks are lost as a result <lb/>of a server restart, the protocol must provide a way to cause that <lb/>state to be re-established. The approach used is to define, for most <lb/>types of locking state (layouts are an exception), a request whose <lb/>function is to allow the client to re-establish on the server a lock <lb/>first obtained from a previous instance. Generally, these requests <lb/>are variants of the requests normally used to create locks of that <lb/>type and are referred to as &quot;reclaim-type&quot; requests, and the process <lb/>of re-establishing such locks is referred to as &quot;reclaiming&quot; them. <lb/>Because each client must have an opportunity to reclaim all of the <lb/>locks that it has without the possibility that some other client will <lb/>be granted a conflicting lock, a &quot;grace period&quot; is devoted to the <lb/>reclaim process. During this period, requests creating client IDs <lb/>and sessions are handled normally, but locking requests are subject <lb/>to special restrictions. Only reclaim-type locking requests are <lb/>allowed, unless the server can reliably determine (through state <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 171] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>persistently maintained across restart instances) that granting any <lb/>such lock cannot possibly conflict with a subsequent reclaim. When a <lb/>request is made to obtain a new lock (i.e., not a reclaim-type <lb/>request) during the grace period and such a determination cannot be <lb/>made, the server must return the error NFS4ERR_GRACE. <lb/>Once a session is established using the new client ID, the client <lb/>will use reclaim-type locking requests (e.g., LOCK operations with <lb/>reclaim set to TRUE and OPEN operations with a claim type of <lb/>CLAIM_PREVIOUS; see Section 9.11) to re-establish its locking state. <lb/>Once this is done, or if there is no such locking state to reclaim, <lb/>the client sends a global RECLAIM_COMPLETE operation, i.e., one with <lb/>the rca_one_fs argument set to FALSE, to indicate that it has <lb/>reclaimed all of the locking state that it will reclaim. Once a <lb/>client sends such a RECLAIM_COMPLETE operation, it may attempt non-<lb/>reclaim locking operations, although it might get an NFS4ERR_GRACE <lb/>status result from each such operation until the period of special <lb/>handling is over. See Section 11.10.9 for a discussion of the <lb/>analogous handling lock reclamation in the case of file systems <lb/>transitioning from server to server. <lb/>During the grace period, the server must reject READ and WRITE <lb/>operations and non-reclaim locking requests (i.e., other LOCK and <lb/>OPEN operations) with an error of NFS4ERR_GRACE, unless it can <lb/>guarantee that these may be done safely, as described below. <lb/>The grace period may last until all clients that are known to <lb/>possibly have had locks have done a global RECLAIM_COMPLETE <lb/>operation, indicating that they have finished reclaiming the locks <lb/>they held before the server restart. This means that a client that <lb/>has done a RECLAIM_COMPLETE must be prepared to receive an <lb/>NFS4ERR_GRACE when attempting to acquire new locks. In order for the <lb/>server to know that all clients with possible prior lock state have <lb/>done a RECLAIM_COMPLETE, the server must maintain in stable storage a <lb/>list clients that may have such locks. The server may also terminate <lb/>the grace period before all clients have done a global <lb/>RECLAIM_COMPLETE. The server SHOULD NOT terminate the grace period <lb/>before a time equal to the lease period in order to give clients an <lb/>opportunity to find out about the server restart, as a result of <lb/>sending requests on associated sessions with a frequency governed by <lb/>the lease time. Note that when a client does not send such requests <lb/>(or they are sent by the client but not received by the server), it <lb/>is possible for the grace period to expire before the client finds <lb/>out that the server restart has occurred. <lb/>Some additional time in order to allow a client to establish a new <lb/>client ID and session and to effect lock reclaims may be added to the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 172] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>lease time. Note that analogous rules apply to file system-specific <lb/>grace periods discussed in Section 11.10.9. <lb/>If the server can reliably determine that granting a non-reclaim <lb/>request will not conflict with reclamation of locks by other clients, <lb/>the NFS4ERR_GRACE error does not have to be returned even within the <lb/>grace period, although NFS4ERR_GRACE must always be returned to <lb/>clients attempting a non-reclaim lock request before doing their own <lb/>global RECLAIM_COMPLETE. For the server to be able to service READ <lb/>and WRITE operations during the grace period, it must again be able <lb/>to guarantee that no possible conflict could arise between a <lb/>potential reclaim locking request and the READ or WRITE operation. <lb/>If the server is unable to offer that guarantee, the NFS4ERR_GRACE <lb/>error must be returned to the client. <lb/>For a server to provide simple, valid handling during the grace <lb/>period, the easiest method is to simply reject all non-reclaim <lb/>locking requests and READ and WRITE operations by returning the <lb/>NFS4ERR_GRACE error. However, a server may keep information about <lb/>granted locks in stable storage. With this information, the server <lb/>could determine if a locking, READ or WRITE operation can be safely <lb/>processed. <lb/>For example, if the server maintained on stable storage summary <lb/>information on whether mandatory locks exist, either mandatory byte-<lb/>range locks, or share reservations specifying deny modes, many <lb/>requests could be allowed during the grace period. If it is known <lb/>that no such share reservations exist, OPEN request that do not <lb/>specify deny modes may be safely granted. If, in addition, it is <lb/>known that no mandatory byte-range locks exist, either through <lb/>information stored on stable storage or simply because the server <lb/>does not support such locks, READ and WRITE operations may be safely <lb/>processed during the grace period. Another important case is where <lb/>it is known that no mandatory byte-range locks exist, either because <lb/>the server does not provide support for them or because their absence <lb/>is known from persistently recorded data. In this case, READ and <lb/>WRITE operations specifying stateids derived from reclaim-type <lb/>operations may be validly processed during the grace period because <lb/>of the fact that the valid reclaim ensures that no lock subsequently <lb/>granted can prevent the I/O. <lb/>To reiterate, for a server that allows non-reclaim lock and I/O <lb/>requests to be processed during the grace period, it MUST determine <lb/>that no lock subsequently reclaimed will be rejected and that no lock <lb/>subsequently reclaimed would have prevented any I/O operation <lb/>processed during the grace period. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 173] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Clients should be prepared for the return of NFS4ERR_GRACE errors for <lb/>non-reclaim lock and I/O requests. In this case, the client should <lb/>employ a retry mechanism for the request. A delay (on the order of <lb/>several seconds) between retries should be used to avoid overwhelming <lb/>the server. Further discussion of the general issue is included in <lb/>[50]. The client must account for the server that can perform I/O <lb/>and non-reclaim locking requests within the grace period as well as <lb/>those that cannot do so. <lb/>A reclaim-type locking request outside the server&apos;s grace period can <lb/>only succeed if the server can guarantee that no conflicting lock or <lb/>I/O request has been granted since restart. <lb/>A server may, upon restart, establish a new value for the lease <lb/>period. Therefore, clients should, once a new client ID is <lb/>established, refetch the lease_time attribute and use it as the basis <lb/>for lease renewal for the lease associated with that server. <lb/>However, the server must establish, for this restart event, a grace <lb/>period at least as long as the lease period for the previous server <lb/>instantiation. This allows the client state obtained during the <lb/>previous server instance to be reliably re-established. <lb/>The possibility exists that, because of server configuration events, <lb/>the client will be communicating with a server different than the one <lb/>on which the locks were obtained, as shown by the combination of <lb/>eir_server_scope and eir_server_owner. This leads to the issue of if <lb/>and when the client should attempt to reclaim locks previously <lb/>obtained on what is being reported as a different server. The rules <lb/>to resolve this question are as follows: <lb/>o If the server scope is different, the client should not attempt to <lb/>reclaim locks. In this situation, no lock reclaim is possible. <lb/>Any attempt to re-obtain the locks with non-reclaim operations is <lb/>problematic since there is no guarantee that the existing <lb/>filehandles will be recognized by the new server, or that if <lb/>recognized, they denote the same objects. It is best to treat the <lb/>locks as having been revoked by the reconfiguration event. <lb/>o If the server scope is the same, the client should attempt to <lb/>reclaim locks, even if the eir_server_owner value is different. <lb/>In this situation, it is the responsibility of the server to <lb/>return NFS4ERR_NO_GRACE if it cannot provide correct support for <lb/>lock reclaim operations, including the prevention of edge <lb/>conditions. <lb/>The eir_server_owner field is not used in making this determination. <lb/>Its function is to specify trunking possibilities for the client (see <lb/>Section 2.10.5) and not to control lock reclaim. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 174] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>8.4.2.1.1. Security Considerations for State Reclaim <lb/>During the grace period, a client can reclaim state that it believes <lb/>or asserts it had before the server restarted. Unless the server <lb/>maintained a complete record of all the state the client had, the <lb/>server has little choice but to trust the client. (Of course, if the <lb/>server maintained a complete record, then it would not have to force <lb/>the client to reclaim state after server restart.) While the server <lb/>has to trust the client to tell the truth, such trust does not have <lb/>any negative consequences for security. The fundamental rule for the <lb/>server when processing reclaim requests is that it MUST NOT grant the <lb/>reclaim if an equivalent non-reclaim request would not be granted <lb/>during steady state due to access control or access conflict issues. <lb/>For example, an OPEN request during a reclaim will be refused with <lb/>NFS4ERR_ACCESS if the principal making the request does not have <lb/>access to open the file according to the discretionary ACL <lb/>(Section 6.2.2) on the file. <lb/>Nonetheless, it is possible that a client operating in error or <lb/>maliciously could, during reclaim, prevent another client from <lb/>reclaiming access to state. For example, an attacker could send an <lb/>OPEN reclaim operation with a deny mode that prevents another client <lb/>from reclaiming the OPEN state it had before the server restarted. <lb/>The attacker could perform the same denial of service during steady <lb/>state prior to server restart, as long as the attacker had <lb/>permissions. Given that the attack vectors are equivalent, the grace <lb/>period does not offer any additional opportunity for denial of <lb/>service, and any concerns about this attack vector, whether during <lb/>grace or steady state, are addressed the same way: use RPCSEC_GSS for <lb/>authentication and limit access to the file only to principals that <lb/>the owner of the file trusts. <lb/>Note that if prior to restart the server had client IDs with the <lb/>EXCHGID4_FLAG_BIND_PRINC_STATEID (Section 18.35) capability set, then <lb/>the server SHOULD record in stable storage the client owner and the <lb/>principal that established the client ID via EXCHANGE_ID. If the <lb/>server does not, then there is a risk a client will be unable to <lb/>reclaim state if it does not have a credential for a principal that <lb/>was originally authorized to establish the state. <lb/>8.4.3. Network Partitions and Recovery <lb/>If the duration of a network partition is greater than the lease <lb/>period provided by the server, the server will not have received a <lb/>lease renewal from the client. If this occurs, the server may free <lb/>all locks held for the client or it may allow the lock state to <lb/>remain for a considerable period, subject to the constraint that if a <lb/>request for a conflicting lock is made, locks associated with an <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 175] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>expired lease do not prevent such a conflicting lock from being <lb/>granted but MUST be revoked as necessary so as to avoid interfering <lb/>with such conflicting requests. <lb/>If the server chooses to delay freeing of lock state until there is a <lb/>conflict, it may either free all of the client&apos;s locks once there is <lb/>a conflict or it may only revoke the minimum set of locks necessary <lb/>to allow conflicting requests. When it adopts the finer-grained <lb/>approach, it must revoke all locks associated with a given stateid, <lb/>even if the conflict is with only a subset of locks. <lb/>When the server chooses to free all of a client&apos;s lock state, either <lb/>immediately upon lease expiration or as a result of the first attempt <lb/>to obtain a conflicting a lock, the server may report the loss of <lb/>lock state in a number of ways. <lb/>The server may choose to invalidate the session and the associated <lb/>client ID. In this case, once the client can communicate with the <lb/>server, it will receive an NFS4ERR_BADSESSION error. Upon attempting <lb/>to create a new session, it would get an NFS4ERR_STALE_CLIENTID. <lb/>Upon creating the new client ID and new session, the client will <lb/>attempt to reclaim locks. Normally, the server will not allow the <lb/>client to reclaim locks, because the server will not be in its <lb/>recovery grace period. <lb/>Another possibility is for the server to maintain the session and <lb/>client ID but for all stateids held by the client to become invalid <lb/>or stale. Once the client can reach the server after such a network <lb/>partition, the status returned by the SEQUENCE operation will <lb/>indicate a loss of locking state; i.e., the flag <lb/>SEQ4_STATUS_EXPIRED_ALL_STATE_REVOKED will be set in sr_status_flags. <lb/>In addition, all I/O submitted by the client with the now invalid <lb/>stateids will fail with the server returning the error <lb/>NFS4ERR_EXPIRED. Once the client learns of the loss of locking <lb/>state, it will suitably notify the applications that held the <lb/>invalidated locks. The client should then take action to free <lb/>invalidated stateids, either by establishing a new client ID using a <lb/>new verifier or by doing a FREE_STATEID operation to release each of <lb/>the invalidated stateids. <lb/>When the server adopts a finer-grained approach to revocation of <lb/>locks when a client&apos;s lease has expired, only a subset of stateids <lb/>will normally become invalid during a network partition. When the <lb/>client can communicate with the server after such a network partition <lb/>heals, the status returned by the SEQUENCE operation will indicate a <lb/>partial loss of locking state <lb/>(SEQ4_STATUS_EXPIRED_SOME_STATE_REVOKED). In addition, operations, <lb/>including I/O submitted by the client, with the now invalid stateids <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 176] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>will fail with the server returning the error NFS4ERR_EXPIRED. Once <lb/>the client learns of the loss of locking state, it will use the <lb/>TEST_STATEID operation on all of its stateids to determine which <lb/>locks have been lost and then suitably notify the applications that <lb/>held the invalidated locks. The client can then release the <lb/>invalidated locking state and acknowledge the revocation of the <lb/>associated locks by doing a FREE_STATEID operation on each of the <lb/>invalidated stateids. <lb/>When a network partition is combined with a server restart, there are <lb/>edge conditions that place requirements on the server in order to <lb/>avoid silent data corruption following the server restart. Two of <lb/>these edge conditions are known, and are discussed below. <lb/>The first edge condition arises as a result of the scenarios such as <lb/>the following: <lb/>1. Client A acquires a lock. <lb/>2. Client A and server experience mutual network partition, such <lb/>that client A is unable to renew its lease. <lb/>3. Client A&apos;s lease expires, and the server releases the lock. <lb/>4. Client B acquires a lock that would have conflicted with that of <lb/>client A. <lb/>5. Client B releases its lock. <lb/>6. Server restarts. <lb/>7. Network partition between client A and server heals. <lb/>8. Client A connects to a new server instance and finds out about <lb/>server restart. <lb/>9. Client A reclaims its lock within the server&apos;s grace period. <lb/>Thus, at the final step, the server has erroneously granted client <lb/>A&apos;s lock reclaim. If client B modified the object the lock was <lb/>protecting, client A will experience object corruption. <lb/>The second known edge condition arises in situations such as the <lb/>following: <lb/>1. <lb/>Client A acquires one or more locks. <lb/>2. <lb/>Server restarts. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 177] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>3. <lb/>Client A and server experience mutual network partition, such <lb/>that client A is unable to reclaim all of its locks within the <lb/>grace period. <lb/>4. <lb/>Server&apos;s reclaim grace period ends. Client A has either no <lb/>locks or an incomplete set of locks known to the server. <lb/>5. <lb/>Client B acquires a lock that would have conflicted with a lock <lb/>of client A that was not reclaimed. <lb/>6. <lb/>Client B releases the lock. <lb/>7. <lb/>Server restarts a second time. <lb/>8. <lb/>Network partition between client A and server heals. <lb/>9. <lb/>Client A connects to new server instance and finds out about <lb/>server restart. <lb/>10. Client A reclaims its lock within the server&apos;s grace period. <lb/>As with the first edge condition, the final step of the scenario of <lb/>the second edge condition has the server erroneously granting client <lb/>A&apos;s lock reclaim. <lb/>Solving the first and second edge conditions requires either that the <lb/>server always assumes after it restarts that some edge condition <lb/>occurs, and thus returns NFS4ERR_NO_GRACE for all reclaim attempts, <lb/>or that the server record some information in stable storage. The <lb/>amount of information the server records in stable storage is in <lb/>inverse proportion to how harsh the server intends to be whenever <lb/>edge conditions arise. The server that is completely tolerant of all <lb/>edge conditions will record in stable storage every lock that is <lb/>acquired, removing the lock record from stable storage only when the <lb/>lock is released. For the two edge conditions discussed above, the <lb/>harshest a server can be, and still support a grace period for <lb/>reclaims, requires that the server record in stable storage some <lb/>minimal information. For example, a server implementation could, for <lb/>each client, save in stable storage a record containing: <lb/>o the co_ownerid field from the client_owner4 presented in the <lb/>EXCHANGE_ID operation. <lb/>o a boolean that indicates if the client&apos;s lease expired or if there <lb/>was administrative intervention (see Section 8.5) to revoke a <lb/>byte-range lock, share reservation, or delegation and there has <lb/>been no acknowledgment, via FREE_STATEID, of such revocation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 178] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o a boolean that indicates whether the client may have locks that it <lb/>believes to be reclaimable in situations in which the grace period <lb/>was terminated, making the server&apos;s view of lock reclaimability <lb/>suspect. The server will set this for any client record in stable <lb/>storage where the client has not done a suitable RECLAIM_COMPLETE <lb/>(global or file system-specific depending on the target of the <lb/>lock request) before it grants any new (i.e., not reclaimed) lock <lb/>to any client. <lb/>Assuming the above record keeping, for the first edge condition, <lb/>after the server restarts, the record that client A&apos;s lease expired <lb/>means that another client could have acquired a conflicting byte-<lb/>range lock, share reservation, or delegation. Hence, the server must <lb/>reject a reclaim from client A with the error NFS4ERR_NO_GRACE. <lb/>For the second edge condition, after the server restarts for a second <lb/>time, the indication that the client had not completed its reclaims <lb/>at the time at which the grace period ended means that the server <lb/>must reject a reclaim from client A with the error NFS4ERR_NO_GRACE. <lb/>When either edge condition occurs, the client&apos;s attempt to reclaim <lb/>locks will result in the error NFS4ERR_NO_GRACE. When this is <lb/>received, or after the client restarts with no lock state, the client <lb/>will send a global RECLAIM_COMPLETE. When the RECLAIM_COMPLETE is <lb/>received, the server and client are again in agreement regarding <lb/>reclaimable locks and both booleans in persistent storage can be <lb/>reset, to be set again only when there is a subsequent event that <lb/>causes lock reclaim operations to be questionable. <lb/>Regardless of the level and approach to record keeping, the server <lb/>MUST implement one of the following strategies (which apply to <lb/>reclaims of share reservations, byte-range locks, and delegations): <lb/>1. Reject all reclaims with NFS4ERR_NO_GRACE. This is extremely <lb/>unforgiving, but necessary if the server does not record lock <lb/>state in stable storage. <lb/>2. Record sufficient state in stable storage such that all known <lb/>edge conditions involving server restart, including the two noted <lb/>in this section, are detected. It is acceptable to erroneously <lb/>recognize an edge condition and not allow a reclaim, when, with <lb/>sufficient knowledge, it would be allowed. The error the server <lb/>would return in this case is NFS4ERR_NO_GRACE. Note that it is <lb/>not known if there are other edge conditions. <lb/>In the event that, after a server restart, the server determines <lb/>there is unrecoverable damage or corruption to the information in <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 179] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>stable storage, then for all clients and/or locks that may be <lb/>affected, the server MUST return NFS4ERR_NO_GRACE. <lb/>A mandate for the client&apos;s handling of the NFS4ERR_NO_GRACE error is <lb/>outside the scope of this specification, since the strategies for <lb/>such handling are very dependent on the client&apos;s operating <lb/>environment. However, one potential approach is described below. <lb/>When the client receives NFS4ERR_NO_GRACE, it could examine the <lb/>change attribute of the objects for which the client is trying to <lb/>reclaim state, and use that to determine whether to re-establish the <lb/>state via normal OPEN or LOCK operations. This is acceptable <lb/>provided that the client&apos;s operating environment allows it. In other <lb/>words, the client implementor is advised to document for his users <lb/>the behavior. The client could also inform the application that its <lb/>byte-range lock or share reservations (whether or not they were <lb/>delegated) have been lost, such as via a UNIX signal, a Graphical <lb/>User Interface (GUI) pop-up window, etc. See Section 10.5 for a <lb/>discussion of what the client should do for dealing with unreclaimed <lb/>delegations on client state. <lb/>For further discussion of revocation of locks, see Section 8.5. <lb/>8.5. Server Revocation of Locks <lb/>At any point, the server can revoke locks held by a client, and the <lb/>client must be prepared for this event. When the client detects that <lb/>its locks have been or may have been revoked, the client is <lb/>responsible for validating the state information between itself and <lb/>the server. Validating locking state for the client means that it <lb/>must verify or reclaim state for each lock currently held. <lb/>The first occasion of lock revocation is upon server restart. Note <lb/>that this includes situations in which sessions are persistent and <lb/>locking state is lost. In this class of instances, the client will <lb/>receive an error (NFS4ERR_STALE_CLIENTID) on an operation that takes <lb/>client ID, usually as part of recovery in response to a problem with <lb/>the current session), and the client will proceed with normal crash <lb/>recovery as described in the Section 8.4.2.1. <lb/>The second occasion of lock revocation is the inability to renew the <lb/>lease before expiration, as discussed in Section 8.4.3. While this <lb/>is considered a rare or unusual event, the client must be prepared to <lb/>recover. The server is responsible for determining the precise <lb/>consequences of the lease expiration, informing the client of the <lb/>scope of the lock revocation decided upon. The client then uses the <lb/>status information provided by the server in the SEQUENCE results <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 180] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>(field sr_status_flags, see Section 18.46.3) to synchronize its <lb/>locking state with that of the server, in order to recover. <lb/>The third occasion of lock revocation can occur as a result of <lb/>revocation of locks within the lease period, either because of <lb/>administrative intervention or because a recallable lock (a <lb/>delegation or layout) was not returned within the lease period after <lb/>having been recalled. While these are considered rare events, they <lb/>are possible, and the client must be prepared to deal with them. <lb/>When either of these events occurs, the client finds out about the <lb/>situation through the status returned by the SEQUENCE operation. Any <lb/>use of stateids associated with locks revoked during the lease period <lb/>will receive the error NFS4ERR_ADMIN_REVOKED or <lb/>NFS4ERR_DELEG_REVOKED, as appropriate. <lb/>In all situations in which a subset of locking state may have been <lb/>revoked, which include all cases in which locking state is revoked <lb/>within the lease period, it is up to the client to determine which <lb/>locks have been revoked and which have not. It does this by using <lb/>the TEST_STATEID operation on the appropriate set of stateids. Once <lb/>the set of revoked locks has been determined, the applications can be <lb/>notified, and the invalidated stateids can be freed and lock <lb/>revocation acknowledged by using FREE_STATEID. <lb/>8.6. Short and Long Leases <lb/>When determining the time period for the server lease, the usual <lb/>lease tradeoffs apply. A short lease is good for fast server <lb/>recovery at a cost of increased operations to effect lease renewal <lb/>(when there are no other operations during the period to effect lease <lb/>renewal as a side effect). A long lease is certainly kinder and <lb/>gentler to servers trying to handle very large numbers of clients. <lb/>The number of extra requests to effect lock renewal drops in inverse <lb/>proportion to the lease time. The disadvantages of a long lease <lb/>include the possibility of slower recovery after certain failures. <lb/>After server failure, a longer grace period may be required when some <lb/>clients do not promptly reclaim their locks and do a global <lb/>RECLAIM_COMPLETE. In the event of client failure, the longer period <lb/>for a lease to expire will force conflicting requests to wait longer. <lb/>A long lease is practical if the server can store lease state in <lb/>stable storage. Upon recovery, the server can reconstruct the lease <lb/>state from its stable storage and continue operation with its <lb/>clients. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 181] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>8.7. Clocks, Propagation Delay, and Calculating Lease Expiration <lb/>To avoid the need for synchronized clocks, lease times are granted by <lb/>the server as a time delta. However, there is a requirement that the <lb/>client and server clocks do not drift excessively over the duration <lb/>of the lease. There is also the issue of propagation delay across <lb/>the network, which could easily be several hundred milliseconds, as <lb/>well as the possibility that requests will be lost and need to be <lb/>retransmitted. <lb/>To take propagation delay into account, the client should subtract it <lb/>from lease times (e.g., if the client estimates the one-way <lb/>propagation delay as 200 milliseconds, then it can assume that the <lb/>lease is already 200 milliseconds old when it gets it). In addition, <lb/>it will take another 200 milliseconds to get a response back to the <lb/>server. So the client must send a lease renewal or write data back <lb/>to the server at least 400 milliseconds before the lease would <lb/>expire. If the propagation delay varies over the life of the lease <lb/>(e.g., the client is on a mobile host), the client will need to <lb/>continuously subtract the increase in propagation delay from the <lb/>lease times. <lb/>The server&apos;s lease period configuration should take into account the <lb/>network distance of the clients that will be accessing the server&apos;s <lb/>resources. It is expected that the lease period will take into <lb/>account the network propagation delays and other network delay <lb/>factors for the client population. Since the protocol does not allow <lb/>for an automatic method to determine an appropriate lease period, the <lb/>server&apos;s administrator may have to tune the lease period. <lb/>8.8. Obsolete Locking Infrastructure from NFSv4.0 <lb/>There are a number of operations and fields within existing <lb/>operations that no longer have a function in NFSv4.1. In one way or <lb/>another, these changes are all due to the implementation of sessions <lb/>that provide client context and exactly once semantics as a base <lb/>feature of the protocol, separate from locking itself. <lb/>The following NFSv4.0 operations MUST NOT be implemented in NFSv4.1. <lb/>The server MUST return NFS4ERR_NOTSUPP if these operations are found <lb/>in an NFSv4.1 COMPOUND. <lb/>o SETCLIENTID since its function has been replaced by EXCHANGE_ID. <lb/>o SETCLIENTID_CONFIRM since client ID confirmation now happens by <lb/>means of CREATE_SESSION. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 182] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o OPEN_CONFIRM because state-owner-based seqids have been replaced <lb/>by the sequence ID in the SEQUENCE operation. <lb/>o RELEASE_LOCKOWNER because lock-owners with no associated locks do <lb/>not have any sequence-related state and so can be deleted by the <lb/>server at will. <lb/>o RENEW because every SEQUENCE operation for a session causes lease <lb/>renewal, making a separate operation superfluous. <lb/>Also, there are a number of fields, present in existing operations, <lb/>related to locking that have no use in minor version 1. They were <lb/>used in minor version 0 to perform functions now provided in a <lb/>different fashion. <lb/>o Sequence ids used to sequence requests for a given state-owner and <lb/>to provide retry protection, now provided via sessions. <lb/>o Client IDs used to identify the client associated with a given <lb/>request. Client identification is now available using the client <lb/>ID associated with the current session, without needing an <lb/>explicit client ID field. <lb/>Such vestigial fields in existing operations have no function in <lb/>NFSv4.1 and are ignored by the server. Note that client IDs in <lb/>operations new to NFSv4.1 (such as CREATE_SESSION and <lb/>DESTROY_CLIENTID) are not ignored. <lb/>9. File Locking and Share Reservations <lb/>To support Win32 share reservations, it is necessary to provide <lb/>operations that atomically open or create files. Having a separate <lb/>share/unshare operation would not allow correct implementation of the <lb/>Win32 OpenFile API. In order to correctly implement share semantics, <lb/>the previous NFS protocol mechanisms used when a file is opened or <lb/>created (LOOKUP, CREATE, ACCESS) need to be replaced. The NFSv4.1 <lb/>protocol defines an OPEN operation that is capable of atomically <lb/>looking up, creating, and locking a file on the server. <lb/>9.1. Opens and Byte-Range Locks <lb/>It is assumed that manipulating a byte-range lock is rare when <lb/>compared to READ and WRITE operations. It is also assumed that <lb/>server restarts and network partitions are relatively rare. <lb/>Therefore, it is important that the READ and WRITE operations have a <lb/>lightweight mechanism to indicate if they possess a held lock. A <lb/>LOCK operation contains the heavyweight information required to <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 183] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>establish a byte-range lock and uniquely define the owner of the <lb/>lock. <lb/>9.1.1. State-Owner Definition <lb/>When opening a file or requesting a byte-range lock, the client must <lb/>specify an identifier that represents the owner of the requested <lb/>lock. This identifier is in the form of a state-owner, represented <lb/>in the protocol by a state_owner4, a variable-length opaque array <lb/>that, when concatenated with the current client ID, uniquely defines <lb/>the owner of a lock managed by the client. This may be a thread ID, <lb/>process ID, or other unique value. <lb/>Owners of opens and owners of byte-range locks are separate entities <lb/>and remain separate even if the same opaque arrays are used to <lb/>designate owners of each. The protocol distinguishes between open-<lb/>owners (represented by open_owner4 structures) and lock-owners <lb/>(represented by lock_owner4 structures). <lb/>Each open is associated with a specific open-owner while each byte-<lb/>range lock is associated with a lock-owner and an open-owner, the <lb/>latter being the open-owner associated with the open file under which <lb/>the LOCK operation was done. Delegations and layouts, on the other <lb/>hand, are not associated with a specific owner but are associated <lb/>with the client as a whole (identified by a client ID). <lb/>9.1.2. Use of the Stateid and Locking <lb/>All READ, WRITE, and SETATTR operations contain a stateid. For the <lb/>purposes of this section, SETATTR operations that change the size <lb/>attribute of a file are treated as if they are writing the area <lb/>between the old and new sizes (i.e., the byte-range truncated or <lb/>added to the file by means of the SETATTR), even where SETATTR is not <lb/>explicitly mentioned in the text. The stateid passed to one of these <lb/>operations must be one that represents an open, a set of byte-range <lb/>locks, or a delegation, or it may be a special stateid representing <lb/>anonymous access or the special bypass stateid. <lb/>If the state-owner performs a READ or WRITE operation in a situation <lb/>in which it has established a byte-range lock or share reservation on <lb/>the server (any OPEN constitutes a share reservation), the stateid <lb/>(previously returned by the server) must be used to indicate what <lb/>locks, including both byte-range locks and share reservations, are <lb/>held by the state-owner. If no state is established by the client, <lb/>either a byte-range lock or a share reservation, a special stateid <lb/>for anonymous state (zero as the value for &quot;other&quot; and &quot;seqid&quot;) is <lb/>used. (See Section 8.2.3 for a description of &apos;special&apos; stateids in <lb/>general.) Regardless of whether a stateid for anonymous state or a <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 184] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>stateid returned by the server is used, if there is a conflicting <lb/>share reservation or mandatory byte-range lock held on the file, the <lb/>server MUST refuse to service the READ or WRITE operation. <lb/>Share reservations are established by OPEN operations and by their <lb/>nature are mandatory in that when the OPEN denies READ or WRITE <lb/>operations, that denial results in such operations being rejected <lb/>with error NFS4ERR_LOCKED. Byte-range locks may be implemented by <lb/>the server as either mandatory or advisory, or the choice of <lb/>mandatory or advisory behavior may be determined by the server on the <lb/>basis of the file being accessed (for example, some UNIX-based <lb/>servers support a &quot;mandatory lock bit&quot; on the mode attribute such <lb/>that if set, byte-range locks are required on the file before I/O is <lb/>possible). When byte-range locks are advisory, they only prevent the <lb/>granting of conflicting lock requests and have no effect on READs or <lb/>WRITEs. Mandatory byte-range locks, however, prevent conflicting I/O <lb/>operations. When they are attempted, they are rejected with <lb/>NFS4ERR_LOCKED. When the client gets NFS4ERR_LOCKED on a file for <lb/>which it knows it has the proper share reservation, it will need to <lb/>send a LOCK operation on the byte-range of the file that includes the <lb/>byte-range the I/O was to be performed on, with an appropriate <lb/>locktype field of the LOCK operation&apos;s arguments (i.e., READ*_LT for <lb/>a READ operation, WRITE*_LT for a WRITE operation). <lb/>Note that for UNIX environments that support mandatory byte-range <lb/>locking, the distinction between advisory and mandatory locking is <lb/>subtle. In fact, advisory and mandatory byte-range locks are exactly <lb/>the same as far as the APIs and requirements on implementation. If <lb/>the mandatory lock attribute is set on the file, the server checks to <lb/>see if the lock-owner has an appropriate shared (READ_LT) or <lb/>exclusive (WRITE_LT) byte-range lock on the byte-range it wishes to <lb/>READ from or WRITE to. If there is no appropriate lock, the server <lb/>checks if there is a conflicting lock (which can be done by <lb/>attempting to acquire the conflicting lock on behalf of the lock-<lb/>owner, and if successful, release the lock after the READ or WRITE <lb/>operation is done), and if there is, the server returns <lb/>NFS4ERR_LOCKED. <lb/>For Windows environments, byte-range locks are always mandatory, so <lb/>the server always checks for byte-range locks during I/O requests. <lb/>Thus, the LOCK operation does not need to distinguish between <lb/>advisory and mandatory byte-range locks. It is the server&apos;s <lb/>processing of the READ and WRITE operations that introduces the <lb/>distinction. <lb/>Every stateid that is validly passed to READ, WRITE, or SETATTR, with <lb/>the exception of special stateid values, defines an access mode for <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 185] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the file (i.e., OPEN4_SHARE_ACCESS_READ, OPEN4_SHARE_ACCESS_WRITE, or <lb/>OPEN4_SHARE_ACCESS_BOTH). <lb/>o For stateids associated with opens, this is the mode defined by <lb/>the original OPEN that caused the allocation of the OPEN stateid <lb/>and as modified by subsequent OPENs and OPEN_DOWNGRADEs for the <lb/>same open-owner/file pair. <lb/>o For stateids returned by byte-range LOCK operations, the <lb/>appropriate mode is the access mode for the OPEN stateid <lb/>associated with the lock set represented by the stateid. <lb/>o For delegation stateids, the access mode is based on the type of <lb/>delegation. <lb/>When a READ, WRITE, or SETATTR (that specifies the size attribute) <lb/>operation is done, the operation is subject to checking against the <lb/>access mode to verify that the operation is appropriate given the <lb/>stateid with which the operation is associated. <lb/>In the case of WRITE-type operations (i.e., WRITEs and SETATTRs that <lb/>set size), the server MUST verify that the access mode allows writing <lb/>and MUST return an NFS4ERR_OPENMODE error if it does not. In the <lb/>case of READ, the server may perform the corresponding check on the <lb/>access mode, or it may choose to allow READ on OPENs for <lb/>OPEN4_SHARE_ACCESS_WRITE, to accommodate clients whose WRITE <lb/>implementation may unavoidably do reads (e.g., due to buffer cache <lb/>constraints). However, even if READs are allowed in these <lb/>circumstances, the server MUST still check for locks that conflict <lb/>with the READ (e.g., another OPEN specified OPEN4_SHARE_DENY_READ or <lb/>OPEN4_SHARE_DENY_BOTH). Note that a server that does enforce the <lb/>access mode check on READs need not explicitly check for conflicting <lb/>share reservations since the existence of OPEN for <lb/>OPEN4_SHARE_ACCESS_READ guarantees that no conflicting share <lb/>reservation can exist. <lb/>The READ bypass special stateid (all bits of &quot;other&quot; and &quot;seqid&quot; set <lb/>to one) indicates a desire to bypass locking checks. The server MAY <lb/>allow READ operations to bypass locking checks at the server, when <lb/>this special stateid is used. However, WRITE operations with this <lb/>special stateid value MUST NOT bypass locking checks and are treated <lb/>exactly the same as if a special stateid for anonymous state were <lb/>used. <lb/>A lock may not be granted while a READ or WRITE operation using one <lb/>of the special stateids is being performed and the scope of the lock <lb/>to be granted would conflict with the READ or WRITE operation. This <lb/>can occur when: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 186] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o A mandatory byte-range lock is requested with a byte-range that <lb/>conflicts with the byte-range of the READ or WRITE operation. For <lb/>the purposes of this paragraph, a conflict occurs when a shared <lb/>lock is requested and a WRITE operation is being performed, or an <lb/>exclusive lock is requested and either a READ or a WRITE operation <lb/>is being performed. <lb/>o A share reservation is requested that denies reading and/or <lb/>writing and the corresponding operation is being performed. <lb/>o A delegation is to be granted and the delegation type would <lb/>prevent the I/O operation, i.e., READ and WRITE conflict with an <lb/>OPEN_DELEGATE_WRITE delegation and WRITE conflicts with an <lb/>OPEN_DELEGATE_READ delegation. <lb/>When a client holds a delegation, it needs to ensure that the stateid <lb/>sent conveys the association of operation with the delegation, to <lb/>avoid the delegation from being avoidably recalled. When the <lb/>delegation stateid, a stateid open associated with that delegation, <lb/>or a stateid representing byte-range locks derived from such an open <lb/>is used, the server knows that the READ, WRITE, or SETATTR does not <lb/>conflict with the delegation but is sent under the aegis of the <lb/>delegation. Even though it is possible for the server to determine <lb/>from the client ID (via the session ID) that the client does in fact <lb/>have a delegation, the server is not obliged to check this, so using <lb/>a special stateid can result in avoidable recall of the delegation. <lb/>9.2. Lock Ranges <lb/>The protocol allows a lock-owner to request a lock with a byte-range <lb/>and then either upgrade, downgrade, or unlock a sub-range of the <lb/>initial lock, or a byte-range that overlaps --fully or partially --<lb/>either with that initial lock or a combination of a set of existing <lb/>locks for the same lock-owner. It is expected that this will be an <lb/>uncommon type of request. In any case, servers or server file <lb/>systems may not be able to support sub-range lock semantics. In the <lb/>event that a server receives a locking request that represents a sub-<lb/>range of current locking state for the lock-owner, the server is <lb/>allowed to return the error NFS4ERR_LOCK_RANGE to signify that it <lb/>does not support sub-range lock operations. Therefore, the client <lb/>should be prepared to receive this error and, if appropriate, report <lb/>the error to the requesting application. <lb/>The client is discouraged from combining multiple independent locking <lb/>ranges that happen to be adjacent into a single request since the <lb/>server may not support sub-range requests for reasons related to the <lb/>recovery of byte-range locking state in the event of server failure. <lb/>As discussed in Section 8.4.2, the server may employ certain <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 187] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>optimizations during recovery that work effectively only when the <lb/>client&apos;s behavior during lock recovery is similar to the client&apos;s <lb/>locking behavior prior to server failure. <lb/>9.3. Upgrading and Downgrading Locks <lb/>If a client has a WRITE_LT lock on a byte-range, it can request an <lb/>atomic downgrade of the lock to a READ_LT lock via the LOCK <lb/>operation, by setting the type to READ_LT. If the server supports <lb/>atomic downgrade, the request will succeed. If not, it will return <lb/>NFS4ERR_LOCK_NOTSUPP. The client should be prepared to receive this <lb/>error and, if appropriate, report the error to the requesting <lb/>application. <lb/>If a client has a READ_LT lock on a byte-range, it can request an <lb/>atomic upgrade of the lock to a WRITE_LT lock via the LOCK operation <lb/>by setting the type to WRITE_LT or WRITEW_LT. If the server does not <lb/>support atomic upgrade, it will return NFS4ERR_LOCK_NOTSUPP. If the <lb/>upgrade can be achieved without an existing conflict, the request <lb/>will succeed. Otherwise, the server will return either <lb/>NFS4ERR_DENIED or NFS4ERR_DEADLOCK. The error NFS4ERR_DEADLOCK is <lb/>returned if the client sent the LOCK operation with the type set to <lb/>WRITEW_LT and the server has detected a deadlock. The client should <lb/>be prepared to receive such errors and, if appropriate, report the <lb/>error to the requesting application. <lb/>9.4. Stateid Seqid Values and Byte-Range Locks <lb/>When a LOCK or LOCKU operation is performed, the stateid returned has <lb/>the same &quot;other&quot; value as the argument&apos;s stateid, and a &quot;seqid&quot; value <lb/>that is incremented (relative to the argument&apos;s stateid) to reflect <lb/>the occurrence of the LOCK or LOCKU operation. The server MUST <lb/>increment the value of the &quot;seqid&quot; field whenever there is any change <lb/>to the locking status of any byte offset as described by any of the <lb/>locks covered by the stateid. A change in locking status includes a <lb/>change from locked to unlocked or the reverse or a change from being <lb/>locked for READ_LT to being locked for WRITE_LT or the reverse. <lb/>When there is no such change, as, for example, when a range already <lb/>locked for WRITE_LT is locked again for WRITE_LT, the server MAY <lb/>increment the &quot;seqid&quot; value. <lb/>9.5. Issues with Multiple Open-Owners <lb/>When the same file is opened by multiple open-owners, a client will <lb/>have multiple OPEN stateids for that file, each associated with a <lb/>different open-owner. In that case, there can be multiple LOCK and <lb/>LOCKU requests for the same lock-owner sent using the different OPEN <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 188] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>stateids, and so a situation may arise in which there are multiple <lb/>stateids, each representing byte-range locks on the same file and <lb/>held by the same lock-owner but each associated with a different <lb/>open-owner. <lb/>In such a situation, the locking status of each byte (i.e., whether <lb/>it is locked, the READ_LT or WRITE_LT type of the lock, and the lock-<lb/>owner holding the lock) MUST reflect the last LOCK or LOCKU operation <lb/>done for the lock-owner in question, independent of the stateid <lb/>through which the request was sent. <lb/>When a byte is locked by the lock-owner in question, the open-owner <lb/>to which that byte-range lock is assigned SHOULD be that of the open-<lb/>owner associated with the stateid through which the last LOCK of that <lb/>byte was done. When there is a change in the open-owner associated <lb/>with locks for the stateid through which a LOCK or LOCKU was done, <lb/>the &quot;seqid&quot; field of the stateid MUST be incremented, even if the <lb/>locking, in terms of lock-owners has not changed. When there is a <lb/>change to the set of locked bytes associated with a different stateid <lb/>for the same lock-owner, i.e., associated with a different open-<lb/>owner, the &quot;seqid&quot; value for that stateid MUST NOT be incremented. <lb/>9.6. Blocking Locks <lb/>Some clients require the support of blocking locks. While NFSv4.1 <lb/>provides a callback when a previously unavailable lock becomes <lb/>available, this is an OPTIONAL feature and clients cannot depend on <lb/>its presence. Clients need to be prepared to continually poll for <lb/>the lock. This presents a fairness problem. Two of the lock types, <lb/>READW_LT and WRITEW_LT, are used to indicate to the server that the <lb/>client is requesting a blocking lock. When the callback is not used, <lb/>the server should maintain an ordered list of pending blocking locks. <lb/>When the conflicting lock is released, the server may wait for the <lb/>period of time equal to lease_time for the first waiting client to <lb/>re-request the lock. After the lease period expires, the next <lb/>waiting client request is allowed the lock. Clients are required to <lb/>poll at an interval sufficiently small that it is likely to acquire <lb/>the lock in a timely manner. The server is not required to maintain <lb/>a list of pending blocked locks as it is used to increase fairness <lb/>and not correct operation. Because of the unordered nature of crash <lb/>recovery, storing of lock state to stable storage would be required <lb/>to guarantee ordered granting of blocking locks. <lb/>Servers may also note the lock types and delay returning denial of <lb/>the request to allow extra time for a conflicting lock to be <lb/>released, allowing a successful return. In this way, clients can <lb/>avoid the burden of needless frequent polling for blocking locks. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 189] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The server should take care in the length of delay in the event the <lb/>client retransmits the request. <lb/>If a server receives a blocking LOCK operation, denies it, and then <lb/>later receives a nonblocking request for the same lock, which is also <lb/>denied, then it should remove the lock in question from its list of <lb/>pending blocking locks. Clients should use such a nonblocking <lb/>request to indicate to the server that this is the last time they <lb/>intend to poll for the lock, as may happen when the process <lb/>requesting the lock is interrupted. This is a courtesy to the <lb/>server, to prevent it from unnecessarily waiting a lease period <lb/>before granting other LOCK operations. However, clients are not <lb/>required to perform this courtesy, and servers must not depend on <lb/>them doing so. Also, clients must be prepared for the possibility <lb/>that this final locking request will be accepted. <lb/>When a server indicates, via the flag OPEN4_RESULT_MAY_NOTIFY_LOCK, <lb/>that CB_NOTIFY_LOCK callbacks might be done for the current open <lb/>file, the client should take notice of this, but, since this is a <lb/>hint, cannot rely on a CB_NOTIFY_LOCK always being done. A client <lb/>may reasonably reduce the frequency with which it polls for a denied <lb/>lock, since the greater latency that might occur is likely to be <lb/>eliminated given a prompt callback, but it still needs to poll. When <lb/>it receives a CB_NOTIFY_LOCK, it should promptly try to obtain the <lb/>lock, but it should be aware that other clients may be polling and <lb/>that the server is under no obligation to reserve the lock for that <lb/>particular client. <lb/>9.7. Share Reservations <lb/>A share reservation is a mechanism to control access to a file. It <lb/>is a separate and independent mechanism from byte-range locking. <lb/>When a client opens a file, it sends an OPEN operation to the server <lb/>specifying the type of access required (READ, WRITE, or BOTH) and the <lb/>type of access to deny others (OPEN4_SHARE_DENY_NONE, <lb/>OPEN4_SHARE_DENY_READ, OPEN4_SHARE_DENY_WRITE, or <lb/>OPEN4_SHARE_DENY_BOTH). If the OPEN fails, the client will fail the <lb/>application&apos;s open request. <lb/>Pseudo-code definition of the semantics: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 190] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>if (request.access == 0) { <lb/>return (NFS4ERR_INVAL) <lb/>} else { <lb/>if ((request.access &amp; file_state.deny)) || <lb/>(request.deny &amp; file_state.access)) { <lb/>return (NFS4ERR_SHARE_DENIED) <lb/>} <lb/>return (NFS4ERR_OK); <lb/>When doing this checking of share reservations on OPEN, the current <lb/>file_state used in the algorithm includes bits that reflect all <lb/>current opens, including those for the open-owner making the new OPEN <lb/>request. <lb/>The constants used for the OPEN and OPEN_DOWNGRADE operations for the <lb/>access and deny fields are as follows: <lb/>const OPEN4_SHARE_ACCESS_READ <lb/>= 0x00000001; <lb/>const OPEN4_SHARE_ACCESS_WRITE = 0x00000002; <lb/>const OPEN4_SHARE_ACCESS_BOTH <lb/>= 0x00000003; <lb/>const OPEN4_SHARE_DENY_NONE <lb/>= 0x00000000; <lb/>const OPEN4_SHARE_DENY_READ <lb/>= 0x00000001; <lb/>const OPEN4_SHARE_DENY_WRITE <lb/>= 0x00000002; <lb/>const OPEN4_SHARE_DENY_BOTH <lb/>= 0x00000003; <lb/>9.8. OPEN/CLOSE Operations <lb/>To provide correct share semantics, a client MUST use the OPEN <lb/>operation to obtain the initial filehandle and indicate the desired <lb/>access and what access, if any, to deny. Even if the client intends <lb/>to use a special stateid for anonymous state or READ bypass, it must <lb/>still obtain the filehandle for the regular file with the OPEN <lb/>operation so the appropriate share semantics can be applied. Clients <lb/>that do not have a deny mode built into their programming interfaces <lb/>for opening a file should request a deny mode of <lb/>OPEN4_SHARE_DENY_NONE. <lb/>The OPEN operation with the CREATE flag also subsumes the CREATE <lb/>operation for regular files as used in previous versions of the NFS <lb/>protocol. This allows a create with a share to be done atomically. <lb/>The CLOSE operation removes all share reservations held by the open-<lb/>owner on that file. If byte-range locks are held, the client SHOULD <lb/>release all locks before sending a CLOSE operation. The server MAY <lb/>free all outstanding locks on CLOSE, but some servers may not support <lb/>the CLOSE of a file that still has byte-range locks held. The server <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 191] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>MUST return failure, NFS4ERR_LOCKS_HELD, if any locks would exist <lb/>after the CLOSE. <lb/>The LOOKUP operation will return a filehandle without establishing <lb/>any lock state on the server. Without a valid stateid, the server <lb/>will assume that the client has the least access. For example, if <lb/>one client opened a file with OPEN4_SHARE_DENY_BOTH and another <lb/>client accesses the file via a filehandle obtained through LOOKUP, <lb/>the second client could only read the file using the special read <lb/>bypass stateid. The second client could not WRITE the file at all <lb/>because it would not have a valid stateid from OPEN and the special <lb/>anonymous stateid would not be allowed access. <lb/>9.9. Open Upgrade and Downgrade <lb/>When an OPEN is done for a file and the open-owner for which the OPEN <lb/>is being done already has the file open, the result is to upgrade the <lb/>open file status maintained on the server to include the access and <lb/>deny bits specified by the new OPEN as well as those for the existing <lb/>OPEN. The result is that there is one open file, as far as the <lb/>protocol is concerned, and it includes the union of the access and <lb/>deny bits for all of the OPEN requests completed. The OPEN is <lb/>represented by a single stateid whose &quot;other&quot; value matches that of <lb/>the original open, and whose &quot;seqid&quot; value is incremented to reflect <lb/>the occurrence of the upgrade. The increment is required in cases in <lb/>which the &quot;upgrade&quot; results in no change to the open mode (e.g., an <lb/>OPEN is done for read when the existing open file is opened for <lb/>OPEN4_SHARE_ACCESS_BOTH). Only a single CLOSE will be done to reset <lb/>the effects of both OPENs. The client may use the stateid returned <lb/>by the OPEN effecting the upgrade or with a stateid sharing the same <lb/>&quot;other&quot; field and a seqid of zero, although care needs to be taken as <lb/>far as upgrades that happen while the CLOSE is pending. Note that <lb/>the client, when sending the OPEN, may not know that the same file is <lb/>in fact being opened. The above only applies if both OPENs result in <lb/>the OPENed object being designated by the same filehandle. <lb/>When the server chooses to export multiple filehandles corresponding <lb/>to the same file object and returns different filehandles on two <lb/>different OPENs of the same file object, the server MUST NOT &quot;OR&quot; <lb/>together the access and deny bits and coalesce the two open files. <lb/>Instead, the server must maintain separate OPENs with separate <lb/>stateids and will require separate CLOSEs to free them. <lb/>When multiple open files on the client are merged into a single OPEN <lb/>file object on the server, the close of one of the open files (on the <lb/>client) may necessitate change of the access and deny status of the <lb/>open file on the server. This is because the union of the access and <lb/>deny bits for the remaining opens may be smaller (i.e., a proper <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 192] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>subset) than previously. The OPEN_DOWNGRADE operation is used to <lb/>make the necessary change and the client should use it to update the <lb/>server so that share reservation requests by other clients are <lb/>handled properly. The stateid returned has the same &quot;other&quot; field as <lb/>that passed to the server. The &quot;seqid&quot; value in the returned stateid <lb/>MUST be incremented, even in situations in which there is no change <lb/>to the access and deny bits for the file. <lb/>9.10. Parallel OPENs <lb/>Unlike the case of NFSv4.0, in which OPEN operations for the same <lb/>open-owner are inherently serialized because of the owner-based <lb/>seqid, multiple OPENs for the same open-owner may be done in <lb/>parallel. When clients do this, they may encounter situations in <lb/>which, because of the existence of hard links, two OPEN operations <lb/>may turn out to open the same file, with a later OPEN performed being <lb/>an upgrade of the first, with this fact only visible to the client <lb/>once the operations complete. <lb/>In this situation, clients may determine the order in which the OPENs <lb/>were performed by examining the stateids returned by the OPENs. <lb/>Stateids that share a common value of the &quot;other&quot; field can be <lb/>recognized as having opened the same file, with the order of the <lb/>operations determinable from the order of the &quot;seqid&quot; fields, mod any <lb/>possible wraparound of the 32-bit field. <lb/>When the possibility exists that the client will send multiple OPENs <lb/>for the same open-owner in parallel, it may be the case that an open <lb/>upgrade may happen without the client knowing beforehand that this <lb/>could happen. Because of this possibility, CLOSEs and <lb/>OPEN_DOWNGRADEs should generally be sent with a non-zero seqid in the <lb/>stateid, to avoid the possibility that the status change associated <lb/>with an open upgrade is not inadvertently lost. <lb/>9.11. Reclaim of Open and Byte-Range Locks <lb/>Special forms of the LOCK and OPEN operations are provided when it is <lb/>necessary to re-establish byte-range locks or opens after a server <lb/>failure. <lb/>o To reclaim existing opens, an OPEN operation is performed using a <lb/>CLAIM_PREVIOUS. Because the client, in this type of situation, <lb/>will have already opened the file and have the filehandle of the <lb/>target file, this operation requires that the current filehandle <lb/>be the target file, rather than a directory, and no file name is <lb/>specified. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 193] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o To reclaim byte-range locks, a LOCK operation with the reclaim <lb/>parameter set to true is used. <lb/>Reclaims of opens associated with delegations are discussed in <lb/>Section 10.2.1. <lb/>10. Client-Side Caching <lb/>Client-side caching of data, of file attributes, and of file names is <lb/>essential to providing good performance with the NFS protocol. <lb/>Providing distributed cache coherence is a difficult problem, and <lb/>previous versions of the NFS protocol have not attempted it. <lb/>Instead, several NFS client implementation techniques have been used <lb/>to reduce the problems that a lack of coherence poses for users. <lb/>These techniques have not been clearly defined by earlier protocol <lb/>specifications, and it is often unclear what is valid or invalid <lb/>client behavior. <lb/>The NFSv4.1 protocol uses many techniques similar to those that have <lb/>been used in previous protocol versions. The NFSv4.1 protocol does <lb/>not provide distributed cache coherence. However, it defines a more <lb/>limited set of caching guarantees to allow locks and share <lb/>reservations to be used without destructive interference from client-<lb/>side caching. <lb/>In addition, the NFSv4.1 protocol introduces a delegation mechanism, <lb/>which allows many decisions normally made by the server to be made <lb/>locally by clients. This mechanism provides efficient support of the <lb/>common cases where sharing is infrequent or where sharing is read-<lb/>only. <lb/>10.1. Performance Challenges for Client-Side Caching <lb/>Caching techniques used in previous versions of the NFS protocol have <lb/>been successful in providing good performance. However, several <lb/>scalability challenges can arise when those techniques are used with <lb/>very large numbers of clients. This is particularly true when <lb/>clients are geographically distributed, which classically increases <lb/>the latency for cache revalidation requests. <lb/>The previous versions of the NFS protocol repeat their file data <lb/>cache validation requests at the time the file is opened. This <lb/>behavior can have serious performance drawbacks. A common case is <lb/>one in which a file is only accessed by a single client. Therefore, <lb/>sharing is infrequent. <lb/>In this case, repeated references to the server to find that no <lb/>conflicts exist are expensive. A better option with regards to <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 194] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>performance is to allow a client that repeatedly opens a file to do <lb/>so without reference to the server. This is done until potentially <lb/>conflicting operations from another client actually occur. <lb/>A similar situation arises in connection with byte-range locking. <lb/>Sending LOCK and LOCKU operations as well as the READ and WRITE <lb/>operations necessary to make data caching consistent with the locking <lb/>semantics (see Section 10.3.2) can severely limit performance. When <lb/>locking is used to provide protection against infrequent conflicts, a <lb/>large penalty is incurred. This penalty may discourage the use of <lb/>byte-range locking by applications. <lb/>The NFSv4.1 protocol provides more aggressive caching strategies with <lb/>the following design goals: <lb/>o Compatibility with a large range of server semantics. <lb/>o Providing the same caching benefits as previous versions of the <lb/>NFS protocol when unable to support the more aggressive model. <lb/>o Requirements for aggressive caching are organized so that a large <lb/>portion of the benefit can be obtained even when not all of the <lb/>requirements can be met. <lb/>The appropriate requirements for the server are discussed in later <lb/>sections in which specific forms of caching are covered (see <lb/>Section 10.4). <lb/>10.2. Delegation and Callbacks <lb/>Recallable delegation of server responsibilities for a file to a <lb/>client improves performance by avoiding repeated requests to the <lb/>server in the absence of inter-client conflict. With the use of a <lb/>&quot;callback&quot; RPC from server to client, a server recalls delegated <lb/>responsibilities when another client engages in sharing of a <lb/>delegated file. <lb/>A delegation is passed from the server to the client, specifying the <lb/>object of the delegation and the type of delegation. There are <lb/>different types of delegations, but each type contains a stateid to <lb/>be used to represent the delegation when performing operations that <lb/>depend on the delegation. This stateid is similar to those <lb/>associated with locks and share reservations but differs in that the <lb/>stateid for a delegation is associated with a client ID and may be <lb/>used on behalf of all the open-owners for the given client. A <lb/>delegation is made to the client as a whole and not to any specific <lb/>process or thread of control within it. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 195] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The backchannel is established by CREATE_SESSION and <lb/>BIND_CONN_TO_SESSION, and the client is required to maintain it. <lb/>Because the backchannel may be down, even temporarily, correct <lb/>protocol operation does not depend on them. Preliminary testing of <lb/>backchannel functionality by means of a CB_COMPOUND procedure with a <lb/>single operation, CB_SEQUENCE, can be used to check the continuity of <lb/>the backchannel. A server avoids delegating responsibilities until <lb/>it has determined that the backchannel exists. Because the granting <lb/>of a delegation is always conditional upon the absence of conflicting <lb/>access, clients MUST NOT assume that a delegation will be granted and <lb/>they MUST always be prepared for OPENs, WANT_DELEGATIONs, and <lb/>GET_DIR_DELEGATIONs to be processed without any delegations being <lb/>granted. <lb/>Unlike locks, an operation by a second client to a delegated file <lb/>will cause the server to recall a delegation through a callback. For <lb/>individual operations, we will describe, under IMPLEMENTATION, when <lb/>such operations are required to effect a recall. A number of points <lb/>should be noted, however. <lb/>o The server is free to recall a delegation whenever it feels it is <lb/>desirable and may do so even if no operations requiring recall are <lb/>being done. <lb/>o Operations done outside the NFSv4.1 protocol, due to, for example, <lb/>access by other protocols, or by local access, also need to result <lb/>in delegation recall when they make analogous changes to file <lb/>system data. What is crucial is if the change would invalidate <lb/>the guarantees provided by the delegation. When this is possible, <lb/>the delegation needs to be recalled and MUST be returned or <lb/>revoked before allowing the operation to proceed. <lb/>o The semantics of the file system are crucial in defining when <lb/>delegation recall is required. If a particular change within a <lb/>specific implementation causes change to a file attribute, then <lb/>delegation recall is required, whether that operation has been <lb/>specifically listed as requiring delegation recall. Again, what <lb/>is critical is whether the guarantees provided by the delegation <lb/>are being invalidated. <lb/>Despite those caveats, the implementation sections for a number of <lb/>operations describe situations in which delegation recall would be <lb/>required under some common circumstances: <lb/>o For GETATTR, see Section 18.7.4. <lb/>o For OPEN, see Section 18.16.4. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 196] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o For READ, see Section 18.22.4. <lb/>o For REMOVE, see Section 18.25.4. <lb/>o For RENAME, see Section 18.26.4. <lb/>o For SETATTR, see Section 18.30.4. <lb/>o For WRITE, see Section 18.32.4. <lb/>On recall, the client holding the delegation needs to flush modified <lb/>state (such as modified data) to the server and return the <lb/>delegation. The conflicting request will not be acted on until the <lb/>recall is complete. The recall is considered complete when the <lb/>client returns the delegation or the server times its wait for the <lb/>delegation to be returned and revokes the delegation as a result of <lb/>the timeout. In the interim, the server will either delay responding <lb/>to conflicting requests or respond to them with NFS4ERR_DELAY. <lb/>Following the resolution of the recall, the server has the <lb/>information necessary to grant or deny the second client&apos;s request. <lb/>At the time the client receives a delegation recall, it may have <lb/>substantial state that needs to be flushed to the server. Therefore, <lb/>the server should allow sufficient time for the delegation to be <lb/>returned since it may involve numerous RPCs to the server. If the <lb/>server is able to determine that the client is diligently flushing <lb/>state to the server as a result of the recall, the server may extend <lb/>the usual time allowed for a recall. However, the time allowed for <lb/>recall completion should not be unbounded. <lb/>An example of this is when responsibility to mediate opens on a given <lb/>file is delegated to a client (see Section 10.4). The server will <lb/>not know what opens are in effect on the client. Without this <lb/>knowledge, the server will be unable to determine if the access and <lb/>deny states for the file allow any particular open until the <lb/>delegation for the file has been returned. <lb/>A client failure or a network partition can result in failure to <lb/>respond to a recall callback. In this case, the server will revoke <lb/>the delegation, which in turn will render useless any modified state <lb/>still on the client. <lb/>10.2.1. Delegation Recovery <lb/>There are three situations that delegation recovery needs to deal <lb/>with: <lb/>o client restart <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 197] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o server restart <lb/>o network partition (full or backchannel-only) <lb/>In the event the client restarts, the failure to renew the lease will <lb/>result in the revocation of byte-range locks and share reservations. <lb/>Delegations, however, may be treated a bit differently. <lb/>There will be situations in which delegations will need to be re-<lb/>established after a client restarts. The reason for this is that the <lb/>client may have file data stored locally and this data was associated <lb/>with the previously held delegations. The client will need to re-<lb/>establish the appropriate file state on the server. <lb/>To allow for this type of client recovery, the server MAY extend the <lb/>period for delegation recovery beyond the typical lease expiration <lb/>period. This implies that requests from other clients that conflict <lb/>with these delegations will need to wait. Because the normal recall <lb/>process may require significant time for the client to flush changed <lb/>state to the server, other clients need be prepared for delays that <lb/>occur because of a conflicting delegation. This longer interval <lb/>would increase the window for clients to restart and consult stable <lb/>storage so that the delegations can be reclaimed. For OPEN <lb/>delegations, such delegations are reclaimed using OPEN with a claim <lb/>type of CLAIM_DELEGATE_PREV or CLAIM_DELEG_PREV_FH (see Sections 10.5 <lb/>and 18.16 for discussion of OPEN delegation and the details of OPEN, <lb/>respectively). <lb/>A server MAY support claim types of CLAIM_DELEGATE_PREV and <lb/>CLAIM_DELEG_PREV_FH, and if it does, it MUST NOT remove delegations <lb/>upon a CREATE_SESSION that confirm a client ID created by <lb/>EXCHANGE_ID. Instead, the server MUST, for a period of time no less <lb/>than that of the value of the lease_time attribute, maintain the <lb/>client&apos;s delegations to allow time for the client to send <lb/>CLAIM_DELEGATE_PREV and/or CLAIM_DELEG_PREV_FH requests. The server <lb/>that supports CLAIM_DELEGATE_PREV and/or CLAIM_DELEG_PREV_FH MUST <lb/>support the DELEGPURGE operation. <lb/>When the server restarts, delegations are reclaimed (using the OPEN <lb/>operation with CLAIM_PREVIOUS) in a similar fashion to byte-range <lb/>locks and share reservations. However, there is a slight semantic <lb/>difference. In the normal case, if the server decides that a <lb/>delegation should not be granted, it performs the requested action <lb/>(e.g., OPEN) without granting any delegation. For reclaim, the <lb/>server grants the delegation but a special designation is applied so <lb/>that the client treats the delegation as having been granted but <lb/>recalled by the server. Because of this, the client has the duty to <lb/>write all modified state to the server and then return the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 198] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>delegation. This process of handling delegation reclaim reconciles <lb/>three principles of the NFSv4.1 protocol: <lb/>o Upon reclaim, a client reporting resources assigned to it by an <lb/>earlier server instance must be granted those resources. <lb/>o The server has unquestionable authority to determine whether <lb/>delegations are to be granted and, once granted, whether they are <lb/>to be continued. <lb/>o The use of callbacks should not be depended upon until the client <lb/>has proven its ability to receive them. <lb/>When a client needs to reclaim a delegation and there is no <lb/>associated open, the client may use the CLAIM_PREVIOUS variant of the <lb/>WANT_DELEGATION operation. However, since the server is not required <lb/>to support this operation, an alternative is to reclaim via a dummy <lb/>OPEN together with the delegation using an OPEN of type <lb/>CLAIM_PREVIOUS. The dummy open file can be released using a CLOSE to <lb/>re-establish the original state to be reclaimed, a delegation without <lb/>an associated open. <lb/>When a client has more than a single open associated with a <lb/>delegation, state for those additional opens can be established using <lb/>OPEN operations of type CLAIM_DELEGATE_CUR. When these are used to <lb/>establish opens associated with reclaimed delegations, the server <lb/>MUST allow them when made within the grace period. <lb/>When a network partition occurs, delegations are subject to freeing <lb/>by the server when the lease renewal period expires. This is similar <lb/>to the behavior for locks and share reservations. For delegations, <lb/>however, the server may extend the period in which conflicting <lb/>requests are held off. Eventually, the occurrence of a conflicting <lb/>request from another client will cause revocation of the delegation. <lb/>A loss of the backchannel (e.g., by later network configuration <lb/>change) will have the same effect. A recall request will fail and <lb/>revocation of the delegation will result. <lb/>A client normally finds out about revocation of a delegation when it <lb/>uses a stateid associated with a delegation and receives one of the <lb/>errors NFS4ERR_EXPIRED, NFS4ERR_ADMIN_REVOKED, or <lb/>NFS4ERR_DELEG_REVOKED. It also may find out about delegation <lb/>revocation after a client restart when it attempts to reclaim a <lb/>delegation and receives that same error. Note that in the case of a <lb/>revoked OPEN_DELEGATE_WRITE delegation, there are issues because data <lb/>may have been modified by the client whose delegation is revoked and <lb/>separately by other clients. See Section 10.5.1 for a discussion of <lb/>such issues. Note also that when delegations are revoked, <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 199] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>information about the revoked delegation will be written by the <lb/>server to stable storage (as described in Section 8.4.3). This is <lb/>done to deal with the case in which a server restarts after revoking <lb/>a delegation but before the client holding the revoked delegation is <lb/>notified about the revocation. <lb/>10.3. Data Caching <lb/>When applications share access to a set of files, they need to be <lb/>implemented so as to take account of the possibility of conflicting <lb/>access by another application. This is true whether the applications <lb/>in question execute on different clients or reside on the same <lb/>client. <lb/>Share reservations and byte-range locks are the facilities the <lb/>NFSv4.1 protocol provides to allow applications to coordinate access <lb/>by using mutual exclusion facilities. The NFSv4.1 protocol&apos;s data <lb/>caching must be implemented such that it does not invalidate the <lb/>assumptions on which those using these facilities depend. <lb/>10.3.1. Data Caching and OPENs <lb/>In order to avoid invalidating the sharing assumptions on which <lb/>applications rely, NFSv4.1 clients should not provide cached data to <lb/>applications or modify it on behalf of an application when it would <lb/>not be valid to obtain or modify that same data via a READ or WRITE <lb/>operation. <lb/>Furthermore, in the absence of an OPEN delegation (see Section 10.4), <lb/>two additional rules apply. Note that these rules are obeyed in <lb/>practice by many NFSv3 clients. <lb/>o First, cached data present on a client must be revalidated after <lb/>doing an OPEN. Revalidating means that the client fetches the <lb/>change attribute from the server, compares it with the cached <lb/>change attribute, and if different, declares the cached data (as <lb/>well as the cached attributes) as invalid. This is to ensure that <lb/>the data for the OPENed file is still correctly reflected in the <lb/>client&apos;s cache. This validation must be done at least when the <lb/>client&apos;s OPEN operation includes a deny of OPEN4_SHARE_DENY_WRITE <lb/>or OPEN4_SHARE_DENY_BOTH, thus terminating a period in which other <lb/>clients may have had the opportunity to open the file with <lb/>OPEN4_SHARE_ACCESS_WRITE/OPEN4_SHARE_ACCESS_BOTH access. Clients <lb/>may choose to do the revalidation more often (i.e., at OPENs <lb/>specifying a deny mode of OPEN4_SHARE_DENY_NONE) to parallel the <lb/>NFSv3 protocol&apos;s practice for the benefit of users assuming this <lb/>degree of cache revalidation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 200] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Since the change attribute is updated for data and metadata <lb/>modifications, some client implementors may be tempted to use the <lb/>time_modify attribute and not the change attribute to validate <lb/>cached data, so that metadata changes do not spuriously invalidate <lb/>clean data. The implementor is cautioned in this approach. The <lb/>change attribute is guaranteed to change for each update to the <lb/>file, whereas time_modify is guaranteed to change only at the <lb/>granularity of the time_delta attribute. Use by the client&apos;s data <lb/>cache validation logic of time_modify and not change runs the risk <lb/>of the client incorrectly marking stale data as valid. Thus, any <lb/>cache validation approach by the client MUST include the use of <lb/>the change attribute. <lb/>o Second, modified data must be flushed to the server before closing <lb/>a file OPENed for OPEN4_SHARE_ACCESS_WRITE. This is complementary <lb/>to the first rule. If the data is not flushed at CLOSE, the <lb/>revalidation done after the client OPENs a file is unable to <lb/>achieve its purpose. The other aspect to flushing the data before <lb/>close is that the data must be committed to stable storage, at the <lb/>server, before the CLOSE operation is requested by the client. In <lb/>the case of a server restart and a CLOSEd file, it may not be <lb/>possible to retransmit the data to be written to the file, hence, <lb/>this requirement. <lb/>10.3.2. Data Caching and File Locking <lb/>For those applications that choose to use byte-range locking instead <lb/>of share reservations to exclude inconsistent file access, there is <lb/>an analogous set of constraints that apply to client-side data <lb/>caching. These rules are effective only if the byte-range locking is <lb/>used in a way that matches in an equivalent way the actual READ and <lb/>WRITE operations executed. This is as opposed to byte-range locking <lb/>that is based on pure convention. For example, it is possible to <lb/>manipulate a two-megabyte file by dividing the file into two one-<lb/>megabyte ranges and protecting access to the two byte-ranges by byte-<lb/>range locks on bytes zero and one. A WRITE_LT lock on byte zero of <lb/>the file would represent the right to perform READ and WRITE <lb/>operations on the first byte-range. A WRITE_LT lock on byte one of <lb/>the file would represent the right to perform READ and WRITE <lb/>operations on the second byte-range. As long as all applications <lb/>manipulating the file obey this convention, they will work on a local <lb/>file system. However, they may not work with the NFSv4.1 protocol <lb/>unless clients refrain from data caching. <lb/>The rules for data caching in the byte-range locking environment are: <lb/>o First, when a client obtains a byte-range lock for a particular <lb/>byte-range, the data cache corresponding to that byte-range (if <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 201] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>any cache data exists) must be revalidated. If the change <lb/>attribute indicates that the file may have been updated since the <lb/>cached data was obtained, the client must flush or invalidate the <lb/>cached data for the newly locked byte-range. A client might <lb/>choose to invalidate all of the non-modified cached data that it <lb/>has for the file, but the only requirement for correct operation <lb/>is to invalidate all of the data in the newly locked byte-range. <lb/>o Second, before releasing a WRITE_LT lock for a byte-range, all <lb/>modified data for that byte-range must be flushed to the server. <lb/>The modified data must also be written to stable storage. <lb/>Note that flushing data to the server and the invalidation of cached <lb/>data must reflect the actual byte-ranges locked or unlocked. <lb/>Rounding these up or down to reflect client cache block boundaries <lb/>will cause problems if not carefully done. For example, writing a <lb/>modified block when only half of that block is within an area being <lb/>unlocked may cause invalid modification to the byte-range outside the <lb/>unlocked area. This, in turn, may be part of a byte-range locked by <lb/>another client. Clients can avoid this situation by synchronously <lb/>performing portions of WRITE operations that overlap that portion <lb/>(initial or final) that is not a full block. Similarly, invalidating <lb/>a locked area that is not an integral number of full buffer blocks <lb/>would require the client to read one or two partial blocks from the <lb/>server if the revalidation procedure shows that the data that the <lb/>client possesses may not be valid. <lb/>The data that is written to the server as a prerequisite to the <lb/>unlocking of a byte-range must be written, at the server, to stable <lb/>storage. The client may accomplish this either with synchronous <lb/>writes or by following asynchronous writes with a COMMIT operation. <lb/>This is required because retransmission of the modified data after a <lb/>server restart might conflict with a lock held by another client. <lb/>A client implementation may choose to accommodate applications that <lb/>use byte-range locking in non-standard ways (e.g., using a byte-range <lb/>lock as a global semaphore) by flushing to the server more data upon <lb/>a LOCKU than is covered by the locked range. This may include <lb/>modified data within files other than the one for which the unlocks <lb/>are being done. In such cases, the client must not interfere with <lb/>applications whose READs and WRITEs are being done only within the <lb/>bounds of byte-range locks that the application holds. For example, <lb/>an application locks a single byte of a file and proceeds to write <lb/>that single byte. A client that chose to handle a LOCKU by flushing <lb/>all modified data to the server could validly write that single byte <lb/>in response to an unrelated LOCKU operation. However, it would not <lb/>be valid to write the entire block in which that single written byte <lb/>was located since it includes an area that is not locked and might be <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 202] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>locked by another client. Client implementations can avoid this <lb/>problem by dividing files with modified data into those for which all <lb/>modifications are done to areas covered by an appropriate byte-range <lb/>lock and those for which there are modifications not covered by a <lb/>byte-range lock. Any writes done for the former class of files must <lb/>not include areas not locked and thus not modified on the client. <lb/>10.3.3. Data Caching and Mandatory File Locking <lb/>Client-side data caching needs to respect mandatory byte-range <lb/>locking when it is in effect. The presence of mandatory byte-range <lb/>locking for a given file is indicated when the client gets back <lb/>NFS4ERR_LOCKED from a READ or WRITE operation on a file for which it <lb/>has an appropriate share reservation. When mandatory locking is in <lb/>effect for a file, the client must check for an appropriate byte-<lb/>range lock for data being read or written. If a byte-range lock <lb/>exists for the range being read or written, the client may satisfy <lb/>the request using the client&apos;s validated cache. If an appropriate <lb/>byte-range lock is not held for the range of the read or write, the <lb/>read or write request must not be satisfied by the client&apos;s cache and <lb/>the request must be sent to the server for processing. When a read <lb/>or write request partially overlaps a locked byte-range, the request <lb/>should be subdivided into multiple pieces with each byte-range <lb/>(locked or not) treated appropriately. <lb/>10.3.4. Data Caching and File Identity <lb/>When clients cache data, the file data needs to be organized <lb/>according to the file system object to which the data belongs. For <lb/>NFSv3 clients, the typical practice has been to assume for the <lb/>purpose of caching that distinct filehandles represent distinct file <lb/>system objects. The client then has the choice to organize and <lb/>maintain the data cache on this basis. <lb/>In the NFSv4.1 protocol, there is now the possibility to have <lb/>significant deviations from a &quot;one filehandle per object&quot; model <lb/>because a filehandle may be constructed on the basis of the object&apos;s <lb/>pathname. Therefore, clients need a reliable method to determine if <lb/>two filehandles designate the same file system object. If clients <lb/>were simply to assume that all distinct filehandles denote distinct <lb/>objects and proceed to do data caching on this basis, caching <lb/>inconsistencies would arise between the distinct client-side objects <lb/>that mapped to the same server-side object. <lb/>By providing a method to differentiate filehandles, the NFSv4.1 <lb/>protocol alleviates a potential functional regression in comparison <lb/>with the NFSv3 protocol. Without this method, caching <lb/>inconsistencies within the same client could occur, and this has not <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 203] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>been present in previous versions of the NFS protocol. Note that it <lb/>is possible to have such inconsistencies with applications executing <lb/>on multiple clients, but that is not the issue being addressed here. <lb/>For the purposes of data caching, the following steps allow an <lb/>NFSv4.1 client to determine whether two distinct filehandles denote <lb/>the same server-side object: <lb/>o If GETATTR directed to two filehandles returns different values of <lb/>the fsid attribute, then the filehandles represent distinct <lb/>objects. <lb/>o If GETATTR for any file with an fsid that matches the fsid of the <lb/>two filehandles in question returns a unique_handles attribute <lb/>with a value of TRUE, then the two objects are distinct. <lb/>o If GETATTR directed to the two filehandles does not return the <lb/>fileid attribute for both of the handles, then it cannot be <lb/>determined whether the two objects are the same. Therefore, <lb/>operations that depend on that knowledge (e.g., client-side data <lb/>caching) cannot be done reliably. Note that if GETATTR does not <lb/>return the fileid attribute for both filehandles, it will return <lb/>it for neither of the filehandles, since the fsid for both <lb/>filehandles is the same. <lb/>o If GETATTR directed to the two filehandles returns different <lb/>values for the fileid attribute, then they are distinct objects. <lb/>o Otherwise, they are the same object. <lb/>10.4. Open Delegation <lb/>When a file is being OPENed, the server may delegate further handling <lb/>of opens and closes for that file to the opening client. Any such <lb/>delegation is recallable since the circumstances that allowed for the <lb/>delegation are subject to change. In particular, if the server <lb/>receives a conflicting OPEN from another client, the server must <lb/>recall the delegation before deciding whether the OPEN from the other <lb/>client may be granted. Making a delegation is up to the server, and <lb/>clients should not assume that any particular OPEN either will or <lb/>will not result in an OPEN delegation. The following is a typical <lb/>set of conditions that servers might use in deciding whether an OPEN <lb/>should be delegated: <lb/>o The client must be able to respond to the server&apos;s callback <lb/>requests. If a backchannel has been established, the server will <lb/>send a CB_COMPOUND request, containing a single operation, <lb/>CB_SEQUENCE, for a test of backchannel availability. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 204] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o The client must have responded properly to previous recalls. <lb/>o There must be no current OPEN conflicting with the requested <lb/>delegation. <lb/>o There should be no current delegation that conflicts with the <lb/>delegation being requested. <lb/>o The probability of future conflicting open requests should be low <lb/>based on the recent history of the file. <lb/>o The existence of any server-specific semantics of OPEN/CLOSE that <lb/>would make the required handling incompatible with the prescribed <lb/>handling that the delegated client would apply (see below). <lb/>There are two types of OPEN delegations: OPEN_DELEGATE_READ and <lb/>OPEN_DELEGATE_WRITE. An OPEN_DELEGATE_READ delegation allows a <lb/>client to handle, on its own, requests to open a file for reading <lb/>that do not deny OPEN4_SHARE_ACCESS_READ access to others. Multiple <lb/>OPEN_DELEGATE_READ delegations may be outstanding simultaneously and <lb/>do not conflict. An OPEN_DELEGATE_WRITE delegation allows the client <lb/>to handle, on its own, all opens. Only OPEN_DELEGATE_WRITE <lb/>delegation may exist for a given file at a given time, and it is <lb/>inconsistent with any OPEN_DELEGATE_READ delegations. <lb/>When a client has an OPEN_DELEGATE_READ delegation, it is assured <lb/>that neither the contents, the attributes (with the exception of <lb/>time_access), nor the names of any links to the file will change <lb/>without its knowledge, so long as the delegation is held. When a <lb/>client has an OPEN_DELEGATE_WRITE delegation, it may modify the file <lb/>data locally since no other client will be accessing the file&apos;s data. <lb/>The client holding an OPEN_DELEGATE_WRITE delegation may only locally <lb/>affect file attributes that are intimately connected with the file <lb/>data: size, change, time_access, time_metadata, and time_modify. All <lb/>other attributes must be reflected on the server. <lb/>When a client has an OPEN delegation, it does not need to send OPENs <lb/>or CLOSEs to the server. Instead, the client may update the <lb/>appropriate status internally. For an OPEN_DELEGATE_READ delegation, <lb/>opens that cannot be handled locally (opens that are for <lb/>OPEN4_SHARE_ACCESS_WRITE/OPEN4_SHARE_ACCESS_BOTH or that deny <lb/>OPEN4_SHARE_ACCESS_READ access) must be sent to the server. <lb/>When an OPEN delegation is made, the reply to the OPEN contains an <lb/>OPEN delegation structure that specifies the following: <lb/>o the type of delegation (OPEN_DELEGATE_READ or <lb/>OPEN_DELEGATE_WRITE). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 205] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o space limitation information to control flushing of data on close <lb/>(OPEN_DELEGATE_WRITE delegation only; see Section 10.4.1) <lb/>o an nfsace4 specifying read and write permissions <lb/>o a stateid to represent the delegation <lb/>The delegation stateid is separate and distinct from the stateid for <lb/>the OPEN proper. The standard stateid, unlike the delegation <lb/>stateid, is associated with a particular lock-owner and will continue <lb/>to be valid after the delegation is recalled and the file remains <lb/>open. <lb/>When a request internal to the client is made to open a file and an <lb/>OPEN delegation is in effect, it will be accepted or rejected solely <lb/>on the basis of the following conditions. Any requirement for other <lb/>checks to be made by the delegate should result in the OPEN <lb/>delegation being denied so that the checks can be made by the server <lb/>itself. <lb/>o The access and deny bits for the request and the file as described <lb/>in Section 9.7. <lb/>o The read and write permissions as determined below. <lb/>The nfsace4 passed with delegation can be used to avoid frequent <lb/>ACCESS calls. The permission check should be as follows: <lb/>o If the nfsace4 indicates that the open may be done, then it should <lb/>be granted without reference to the server. <lb/>o If the nfsace4 indicates that the open may not be done, then an <lb/>ACCESS request must be sent to the server to obtain the definitive <lb/>answer. <lb/>The server may return an nfsace4 that is more restrictive than the <lb/>actual ACL of the file. This includes an nfsace4 that specifies <lb/>denial of all access. Note that some common practices such as <lb/>mapping the traditional user &quot;root&quot; to the user &quot;nobody&quot; (see <lb/>Section 5.9) may make it incorrect to return the actual ACL of the <lb/>file in the delegation response. <lb/>The use of a delegation together with various other forms of caching <lb/>creates the possibility that no server authentication and <lb/>authorization will ever be performed for a given user since all of <lb/>the user&apos;s requests might be satisfied locally. Where the client is <lb/>depending on the server for authentication and authorization, the <lb/>client should be sure authentication and authorization occurs for <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 206] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>each user by use of the ACCESS operation. This should be the case <lb/>even if an ACCESS operation would not be required otherwise. As <lb/>mentioned before, the server may enforce frequent authentication by <lb/>returning an nfsace4 denying all access with every OPEN delegation. <lb/>10.4.1. Open Delegation and Data Caching <lb/>An OPEN delegation allows much of the message overhead associated <lb/>with the opening and closing files to be eliminated. An open when an <lb/>OPEN delegation is in effect does not require that a validation <lb/>message be sent to the server. The continued endurance of the <lb/>&quot;OPEN_DELEGATE_READ delegation&quot; provides a guarantee that no OPEN for <lb/>OPEN4_SHARE_ACCESS_WRITE/OPEN4_SHARE_ACCESS_BOTH, and thus no write, <lb/>has occurred. Similarly, when closing a file opened for <lb/>OPEN4_SHARE_ACCESS_WRITE/OPEN4_SHARE_ACCESS_BOTH and if an <lb/>OPEN_DELEGATE_WRITE delegation is in effect, the data written does <lb/>not have to be written to the server until the OPEN delegation is <lb/>recalled. The continued endurance of the OPEN delegation provides a <lb/>guarantee that no open, and thus no READ or WRITE, has been done by <lb/>another client. <lb/>For the purposes of OPEN delegation, READs and WRITEs done without an <lb/>OPEN are treated as the functional equivalents of a corresponding <lb/>type of OPEN. Although a client SHOULD NOT use special stateids when <lb/>an open exists, delegation handling on the server can use the client <lb/>ID associated with the current session to determine if the operation <lb/>has been done by the holder of the delegation (in which case, no <lb/>recall is necessary) or by another client (in which case, the <lb/>delegation must be recalled and I/O not proceed until the delegation <lb/>is recalled or revoked). <lb/>With delegations, a client is able to avoid writing data to the <lb/>server when the CLOSE of a file is serviced. The file close system <lb/>call is the usual point at which the client is notified of a lack of <lb/>stable storage for the modified file data generated by the <lb/>application. At the close, file data is written to the server and, <lb/>through normal accounting, the server is able to determine if the <lb/>available file system space for the data has been exceeded (i.e., the <lb/>server returns NFS4ERR_NOSPC or NFS4ERR_DQUOT). This accounting <lb/>includes quotas. The introduction of delegations requires that an <lb/>alternative method be in place for the same type of communication to <lb/>occur between client and server. <lb/>In the delegation response, the server provides either the limit of <lb/>the size of the file or the number of modified blocks and associated <lb/>block size. The server must ensure that the client will be able to <lb/>write modified data to the server of a size equal to that provided in <lb/>the original delegation. The server must make this assurance for all <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 207] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>outstanding delegations. Therefore, the server must be careful in <lb/>its management of available space for new or modified data, taking <lb/>into account available file system space and any applicable quotas. <lb/>The server can recall delegations as a result of managing the <lb/>available file system space. The client should abide by the server&apos;s <lb/>state space limits for delegations. If the client exceeds the stated <lb/>limits for the delegation, the server&apos;s behavior is undefined. <lb/>Based on server conditions, quotas, or available file system space, <lb/>the server may grant OPEN_DELEGATE_WRITE delegations with very <lb/>restrictive space limitations. The limitations may be defined in a <lb/>way that will always force modified data to be flushed to the server <lb/>on close. <lb/>With respect to authentication, flushing modified data to the server <lb/>after a CLOSE has occurred may be problematic. For example, the user <lb/>of the application may have logged off the client, and unexpired <lb/>authentication credentials may not be present. In this case, the <lb/>client may need to take special care to ensure that local unexpired <lb/>credentials will in fact be available. This may be accomplished by <lb/>tracking the expiration time of credentials and flushing data well in <lb/>advance of their expiration or by making private copies of <lb/>credentials to assure their availability when needed. <lb/>10.4.2. Open Delegation and File Locks <lb/>When a client holds an OPEN_DELEGATE_WRITE delegation, lock <lb/>operations are performed locally. This includes those required for <lb/>mandatory byte-range locking. This can be done since the delegation <lb/>implies that there can be no conflicting locks. Similarly, all of <lb/>the revalidations that would normally be associated with obtaining <lb/>locks and the flushing of data associated with the releasing of locks <lb/>need not be done. <lb/>When a client holds an OPEN_DELEGATE_READ delegation, lock operations <lb/>are not performed locally. All lock operations, including those <lb/>requesting non-exclusive locks, are sent to the server for <lb/>resolution. <lb/>10.4.3. Handling of CB_GETATTR <lb/>The server needs to employ special handling for a GETATTR where the <lb/>target is a file that has an OPEN_DELEGATE_WRITE delegation in <lb/>effect. The reason for this is that the client holding the <lb/>OPEN_DELEGATE_WRITE delegation may have modified the data, and the <lb/>server needs to reflect this change to the second client that <lb/>submitted the GETATTR. Therefore, the client holding the <lb/>OPEN_DELEGATE_WRITE delegation needs to be interrogated. The server <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 208] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>will use the CB_GETATTR operation. The only attributes that the <lb/>server can reliably query via CB_GETATTR are size and change. <lb/>Since CB_GETATTR is being used to satisfy another client&apos;s GETATTR <lb/>request, the server only needs to know if the client holding the <lb/>delegation has a modified version of the file. If the client&apos;s copy <lb/>of the delegated file is not modified (data or size), the server can <lb/>satisfy the second client&apos;s GETATTR request from the attributes <lb/>stored locally at the server. If the file is modified, the server <lb/>only needs to know about this modified state. If the server <lb/>determines that the file is currently modified, it will respond to <lb/>the second client&apos;s GETATTR as if the file had been modified locally <lb/>at the server. <lb/>Since the form of the change attribute is determined by the server <lb/>and is opaque to the client, the client and server need to agree on a <lb/>method of communicating the modified state of the file. For the size <lb/>attribute, the client will report its current view of the file size. <lb/>For the change attribute, the handling is more involved. <lb/>For the client, the following steps will be taken when receiving an <lb/>OPEN_DELEGATE_WRITE delegation: <lb/>o The value of the change attribute will be obtained from the server <lb/>and cached. Let this value be represented by c. <lb/>o The client will create a value greater than c that will be used <lb/>for communicating that modified data is held at the client. Let <lb/>this value be represented by d. <lb/>o When the client is queried via CB_GETATTR for the change <lb/>attribute, it checks to see if it holds modified data. If the <lb/>file is modified, the value d is returned for the change attribute <lb/>value. If this file is not currently modified, the client returns <lb/>the value c for the change attribute. <lb/>For simplicity of implementation, the client MAY for each CB_GETATTR <lb/>return the same value d. This is true even if, between successive <lb/>CB_GETATTR operations, the client again modifies the file&apos;s data or <lb/>metadata in its cache. The client can return the same value because <lb/>the only requirement is that the client be able to indicate to the <lb/>server that the client holds modified data. Therefore, the value of <lb/>d may always be c + 1. <lb/>While the change attribute is opaque to the client in the sense that <lb/>it has no idea what units of time, if any, the server is counting <lb/>change with, it is not opaque in that the client has to treat it as <lb/>an unsigned integer, and the server has to be able to see the results <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 209] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>of the client&apos;s changes to that integer. Therefore, the server MUST <lb/>encode the change attribute in network order when sending it to the <lb/>client. The client MUST decode it from network order to its native <lb/>order when receiving it, and the client MUST encode it in network <lb/>order when sending it to the server. For this reason, change is <lb/>defined as an unsigned integer rather than an opaque array of bytes. <lb/>For the server, the following steps will be taken when providing an <lb/>OPEN_DELEGATE_WRITE delegation: <lb/>o Upon providing an OPEN_DELEGATE_WRITE delegation, the server will <lb/>cache a copy of the change attribute in the data structure it uses <lb/>to record the delegation. Let this value be represented by sc. <lb/>o When a second client sends a GETATTR operation on the same file to <lb/>the server, the server obtains the change attribute from the first <lb/>client. Let this value be cc. <lb/>o If the value cc is equal to sc, the file is not modified and the <lb/>server returns the current values for change, time_metadata, and <lb/>time_modify (for example) to the second client. <lb/>o If the value cc is NOT equal to sc, the file is currently modified <lb/>at the first client and most likely will be modified at the server <lb/>at a future time. The server then uses its current time to <lb/>construct attribute values for time_metadata and time_modify. A <lb/>new value of sc, which we will call nsc, is computed by the <lb/>server, such that nsc &gt;= sc + 1. The server then returns the <lb/>constructed time_metadata, time_modify, and nsc values to the <lb/>requester. The server replaces sc in the delegation record with <lb/>nsc. To prevent the possibility of time_modify, time_metadata, <lb/>and change from appearing to go backward (which would happen if <lb/>the client holding the delegation fails to write its modified data <lb/>to the server before the delegation is revoked or returned), the <lb/>server SHOULD update the file&apos;s metadata record with the <lb/>constructed attribute values. For reasons of reasonable <lb/>performance, committing the constructed attribute values to stable <lb/>storage is OPTIONAL. <lb/>As discussed earlier in this section, the client MAY return the same <lb/>cc value on subsequent CB_GETATTR calls, even if the file was <lb/>modified in the client&apos;s cache yet again between successive <lb/>CB_GETATTR calls. Therefore, the server must assume that the file <lb/>has been modified yet again, and MUST take care to ensure that the <lb/>new nsc it constructs and returns is greater than the previous nsc it <lb/>returned. An example implementation&apos;s delegation record would <lb/>satisfy this mandate by including a boolean field (let us call it <lb/>&quot;modified&quot;) that is set to FALSE when the delegation is granted, and <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 210] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>an sc value set at the time of grant to the change attribute value. <lb/>The modified field would be set to TRUE the first time cc != sc, and <lb/>would stay TRUE until the delegation is returned or revoked. The <lb/>processing for constructing nsc, time_modify, and time_metadata would <lb/>use this pseudo code: <lb/>if (!modified) { <lb/>do CB_GETATTR for change and size; <lb/>if (cc != sc) <lb/>modified = TRUE; <lb/>} else { <lb/>do CB_GETATTR for size; <lb/>} <lb/>if (modified) { <lb/>sc = sc + 1; <lb/>time_modify = time_metadata = current_time; <lb/>update sc, time_modify, time_metadata into file&apos;s metadata; <lb/>} <lb/>This would return to the client (that sent GETATTR) the attributes it <lb/>requested, but make sure size comes from what CB_GETATTR returned. <lb/>The server would not update the file&apos;s metadata with the client&apos;s <lb/>modified size. <lb/>In the case that the file attribute size is different than the <lb/>server&apos;s current value, the server treats this as a modification <lb/>regardless of the value of the change attribute retrieved via <lb/>CB_GETATTR and responds to the second client as in the last step. <lb/>This methodology resolves issues of clock differences between client <lb/>and server and other scenarios where the use of CB_GETATTR break <lb/>down. <lb/>It should be noted that the server is under no obligation to use <lb/>CB_GETATTR, and therefore the server MAY simply recall the delegation <lb/>to avoid its use. <lb/>10.4.4. Recall of Open Delegation <lb/>The following events necessitate recall of an OPEN delegation: <lb/>o potentially conflicting OPEN request (or a READ or WRITE operation <lb/>done with a special stateid) <lb/>o SETATTR sent by another client <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 211] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o REMOVE request for the file <lb/>o RENAME request for the file as either the source or target of the <lb/>RENAME <lb/>Whether a RENAME of a directory in the path leading to the file <lb/>results in recall of an OPEN delegation depends on the semantics of <lb/>the server&apos;s file system. If that file system denies such RENAMEs <lb/>when a file is open, the recall must be performed to determine <lb/>whether the file in question is, in fact, open. <lb/>In addition to the situations above, the server may choose to recall <lb/>OPEN delegations at any time if resource constraints make it <lb/>advisable to do so. Clients should always be prepared for the <lb/>possibility of recall. <lb/>When a client receives a recall for an OPEN delegation, it needs to <lb/>update state on the server before returning the delegation. These <lb/>same updates must be done whenever a client chooses to return a <lb/>delegation voluntarily. The following items of state need to be <lb/>dealt with: <lb/>o If the file associated with the delegation is no longer open and <lb/>no previous CLOSE operation has been sent to the server, a CLOSE <lb/>operation must be sent to the server. <lb/>o If a file has other open references at the client, then OPEN <lb/>operations must be sent to the server. The appropriate stateids <lb/>will be provided by the server for subsequent use by the client <lb/>since the delegation stateid will no longer be valid. These OPEN <lb/>requests are done with the claim type of CLAIM_DELEGATE_CUR. This <lb/>will allow the presentation of the delegation stateid so that the <lb/>client can establish the appropriate rights to perform the OPEN. <lb/>(see Section 18.16, which describes the OPEN operation, for <lb/>details.) <lb/>o If there are granted byte-range locks, the corresponding LOCK <lb/>operations need to be performed. This applies to the <lb/>OPEN_DELEGATE_WRITE delegation case only. <lb/>o For an OPEN_DELEGATE_WRITE delegation, if at the time of recall <lb/>the file is not open for OPEN4_SHARE_ACCESS_WRITE/ <lb/>OPEN4_SHARE_ACCESS_BOTH, all modified data for the file must be <lb/>flushed to the server. If the delegation had not existed, the <lb/>client would have done this data flush before the CLOSE operation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 212] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o For an OPEN_DELEGATE_WRITE delegation when a file is still open at <lb/>the time of recall, any modified data for the file needs to be <lb/>flushed to the server. <lb/>o With the OPEN_DELEGATE_WRITE delegation in place, it is possible <lb/>that the file was truncated during the duration of the delegation. <lb/>For example, the truncation could have occurred as a result of an <lb/>OPEN UNCHECKED with a size attribute value of zero. Therefore, if <lb/>a truncation of the file has occurred and this operation has not <lb/>been propagated to the server, the truncation must occur before <lb/>any modified data is written to the server. <lb/>In the case of OPEN_DELEGATE_WRITE delegation, byte-range locking <lb/>imposes some additional requirements. To precisely maintain the <lb/>associated invariant, it is required to flush any modified data in <lb/>any byte-range for which a WRITE_LT lock was released while the <lb/>OPEN_DELEGATE_WRITE delegation was in effect. However, because the <lb/>OPEN_DELEGATE_WRITE delegation implies no other locking by other <lb/>clients, a simpler implementation is to flush all modified data for <lb/>the file (as described just above) if any WRITE_LT lock has been <lb/>released while the OPEN_DELEGATE_WRITE delegation was in effect. <lb/>An implementation need not wait until delegation recall (or the <lb/>decision to voluntarily return a delegation) to perform any of the <lb/>above actions, if implementation considerations (e.g., resource <lb/>availability constraints) make that desirable. Generally, however, <lb/>the fact that the actual OPEN state of the file may continue to <lb/>change makes it not worthwhile to send information about opens and <lb/>closes to the server, except as part of delegation return. An <lb/>exception is when the client has no more internal opens of the file. <lb/>In this case, sending a CLOSE is useful because it reduces resource <lb/>utilization on the client and server. Regardless of the client&apos;s <lb/>choices on scheduling these actions, all must be performed before the <lb/>delegation is returned, including (when applicable) the close that <lb/>corresponds to the OPEN that resulted in the delegation. These <lb/>actions can be performed either in previous requests or in previous <lb/>operations in the same COMPOUND request. <lb/>10.4.5. Clients That Fail to Honor Delegation Recalls <lb/>A client may fail to respond to a recall for various reasons, such as <lb/>a failure of the backchannel from server to the client. The client <lb/>may be unaware of a failure in the backchannel. This lack of <lb/>awareness could result in the client finding out long after the <lb/>failure that its delegation has been revoked, and another client has <lb/>modified the data for which the client had a delegation. This is <lb/>especially a problem for the client that held an OPEN_DELEGATE_WRITE <lb/>delegation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 213] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Status bits returned by SEQUENCE operations help to provide an <lb/>alternate way of informing the client of issues regarding the status <lb/>of the backchannel and of recalled delegations. When the backchannel <lb/>is not available, the server returns the status bit <lb/>SEQ4_STATUS_CB_PATH_DOWN on SEQUENCE operations. The client can <lb/>react by attempting to re-establish the backchannel and by returning <lb/>recallable objects if a backchannel cannot be successfully re-<lb/>established. <lb/>Whether the backchannel is functioning or not, it may be that the <lb/>recalled delegation is not returned. Note that the client&apos;s lease <lb/>might still be renewed, even though the recalled delegation is not <lb/>returned. In this situation, servers SHOULD revoke delegations that <lb/>are not returned in a period of time equal to the lease period. This <lb/>period of time should allow the client time to note the backchannel-<lb/>down status and re-establish the backchannel. <lb/>When delegations are revoked, the server will return with the <lb/>SEQ4_STATUS_RECALLABLE_STATE_REVOKED status bit set on subsequent <lb/>SEQUENCE operations. The client should note this and then use <lb/>TEST_STATEID to find which delegations have been revoked. <lb/>10.4.6. Delegation Revocation <lb/>At the point a delegation is revoked, if there are associated opens <lb/>on the client, these opens may or may not be revoked. If no byte-<lb/>range lock or open is granted that is inconsistent with the existing <lb/>open, the stateid for the open may remain valid and be disconnected <lb/>from the revoked delegation, just as would be the case if the <lb/>delegation were returned. <lb/>For example, if an OPEN for OPEN4_SHARE_ACCESS_BOTH with a deny of <lb/>OPEN4_SHARE_DENY_NONE is associated with the delegation, granting of <lb/>another such OPEN to a different client will revoke the delegation <lb/>but need not revoke the OPEN, since the two OPENs are consistent with <lb/>each other. On the other hand, if an OPEN denying write access is <lb/>granted, then the existing OPEN must be revoked. <lb/>When opens and/or locks are revoked, the applications holding these <lb/>opens or locks need to be notified. This notification usually occurs <lb/>by returning errors for READ/WRITE operations or when a close is <lb/>attempted for the open file. <lb/>If no opens exist for the file at the point the delegation is <lb/>revoked, then notification of the revocation is unnecessary. <lb/>However, if there is modified data present at the client for the <lb/>file, the user of the application should be notified. Unfortunately, <lb/>it may not be possible to notify the user since active applications <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 214] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>may not be present at the client. See Section 10.5.1 for additional <lb/>details. <lb/>10.4.7. Delegations via WANT_DELEGATION <lb/>In addition to providing delegations as part of the reply to OPEN <lb/>operations, servers MAY provide delegations separate from open, via <lb/>the OPTIONAL WANT_DELEGATION operation. This allows delegations to <lb/>be obtained in advance of an OPEN that might benefit from them, for <lb/>objects that are not a valid target of OPEN, or to deal with cases in <lb/>which a delegation has been recalled and the client wants to make an <lb/>attempt to re-establish it if the absence of use by other clients <lb/>allows that. <lb/>The WANT_DELEGATION operation may be performed on any type of file <lb/>object other than a directory. <lb/>When a delegation is obtained using WANT_DELEGATION, any open files <lb/>for the same filehandle held by that client are to be treated as <lb/>subordinate to the delegation, just as if they had been created using <lb/>an OPEN of type CLAIM_DELEGATE_CUR. They are otherwise unchanged as <lb/>to seqid, access and deny modes, and the relationship with byte-range <lb/>locks. Similarly, because existing byte-range locks are subordinate <lb/>to an open, those byte-range locks also become indirectly subordinate <lb/>to that new delegation. <lb/>The WANT_DELEGATION operation provides for delivery of delegations <lb/>via callbacks, when the delegations are not immediately available. <lb/>When a requested delegation is available, it is delivered to the <lb/>client via a CB_PUSH_DELEG operation. When this happens, open files <lb/>for the same filehandle become subordinate to the new delegation at <lb/>the point at which the delegation is delivered, just as if they had <lb/>been created using an OPEN of type CLAIM_DELEGATE_CUR. Similarly, <lb/>this occurs for existing byte-range locks subordinate to an open. <lb/>10.5. Data Caching and Revocation <lb/>When locks and delegations are revoked, the assumptions upon which <lb/>successful caching depends are no longer guaranteed. For any locks <lb/>or share reservations that have been revoked, the corresponding <lb/>state-owner needs to be notified. This notification includes <lb/>applications with a file open that has a corresponding delegation <lb/>that has been revoked. Cached data associated with the revocation <lb/>must be removed from the client. In the case of modified data <lb/>existing in the client&apos;s cache, that data must be removed from the <lb/>client without being written to the server. As mentioned, the <lb/>assumptions made by the client are no longer valid at the point when <lb/>a lock or delegation has been revoked. For example, another client <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 215] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>may have been granted a conflicting byte-range lock after the <lb/>revocation of the byte-range lock at the first client. Therefore, <lb/>the data within the lock range may have been modified by the other <lb/>client. Obviously, the first client is unable to guarantee to the <lb/>application what has occurred to the file in the case of revocation. <lb/>Notification to a state-owner will in many cases consist of simply <lb/>returning an error on the next and all subsequent READs/WRITEs to the <lb/>open file or on the close. Where the methods available to a client <lb/>make such notification impossible because errors for certain <lb/>operations may not be returned, more drastic action such as signals <lb/>or process termination may be appropriate. The justification here is <lb/>that an invariant on which an application depends may be violated. <lb/>Depending on how errors are typically treated for the client-<lb/>operating environment, further levels of notification including <lb/>logging, console messages, and GUI pop-ups may be appropriate. <lb/>10.5.1. Revocation Recovery for Write Open Delegation <lb/>Revocation recovery for an OPEN_DELEGATE_WRITE delegation poses the <lb/>special issue of modified data in the client cache while the file is <lb/>not open. In this situation, any client that does not flush modified <lb/>data to the server on each close must ensure that the user receives <lb/>appropriate notification of the failure as a result of the <lb/>revocation. Since such situations may require human action to <lb/>correct problems, notification schemes in which the appropriate user <lb/>or administrator is notified may be necessary. Logging and console <lb/>messages are typical examples. <lb/>If there is modified data on the client, it must not be flushed <lb/>normally to the server. A client may attempt to provide a copy of <lb/>the file data as modified during the delegation under a different <lb/>name in the file system namespace to ease recovery. Note that when <lb/>the client can determine that the file has not been modified by any <lb/>other client, or when the client has a complete cached copy of the <lb/>file in question, such a saved copy of the client&apos;s view of the file <lb/>may be of particular value for recovery. In another case, recovery <lb/>using a copy of the file based partially on the client&apos;s cached data <lb/>and partially on the server&apos;s copy as modified by other clients will <lb/>be anything but straightforward, so clients may avoid saving file <lb/>contents in these situations or specially mark the results to warn <lb/>users of possible problems. <lb/>Saving of such modified data in delegation revocation situations may <lb/>be limited to files of a certain size or might be used only when <lb/>sufficient disk space is available within the target file system. <lb/>Such saving may also be restricted to situations when the client has <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 216] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>sufficient buffering resources to keep the cached copy available <lb/>until it is properly stored to the target file system. <lb/>10.6. Attribute Caching <lb/>This section pertains to the caching of a file&apos;s attributes on a <lb/>client when that client does not hold a delegation on the file. <lb/>The attributes discussed in this section do not include named <lb/>attributes. Individual named attributes are analogous to files, and <lb/>caching of the data for these needs to be handled just as data <lb/>caching is for ordinary files. Similarly, LOOKUP results from an <lb/>OPENATTR directory (as well as the directory&apos;s contents) are to be <lb/>cached on the same basis as any other pathnames. <lb/>Clients may cache file attributes obtained from the server and use <lb/>them to avoid subsequent GETATTR requests. Such caching is write <lb/>through in that modification to file attributes is always done by <lb/>means of requests to the server and should not be done locally and <lb/>should not be cached. The exception to this are modifications to <lb/>attributes that are intimately connected with data caching. <lb/>Therefore, extending a file by writing data to the local data cache <lb/>is reflected immediately in the size as seen on the client without <lb/>this change being immediately reflected on the server. Normally, <lb/>such changes are not propagated directly to the server, but when the <lb/>modified data is flushed to the server, analogous attribute changes <lb/>are made on the server. When OPEN delegation is in effect, the <lb/>modified attributes may be returned to the server in reaction to a <lb/>CB_RECALL call. <lb/>The result of local caching of attributes is that the attribute <lb/>caches maintained on individual clients will not be coherent. <lb/>Changes made in one order on the server may be seen in a different <lb/>order on one client and in a third order on another client. <lb/>The typical file system application programming interfaces do not <lb/>provide means to atomically modify or interrogate attributes for <lb/>multiple files at the same time. The following rules provide an <lb/>environment where the potential incoherencies mentioned above can be <lb/>reasonably managed. These rules are derived from the practice of <lb/>previous NFS protocols. <lb/>o All attributes for a given file (per-fsid attributes excepted) are <lb/>cached as a unit at the client so that no non-serializability can <lb/>arise within the context of a single file. <lb/>o An upper time boundary is maintained on how long a client cache <lb/>entry can be kept without being refreshed from the server. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 217] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o When operations are performed that change attributes at the <lb/>server, the updated attribute set is requested as part of the <lb/>containing RPC. This includes directory operations that update <lb/>attributes indirectly. This is accomplished by following the <lb/>modifying operation with a GETATTR operation and then using the <lb/>results of the GETATTR to update the client&apos;s cached attributes. <lb/>Note that if the full set of attributes to be cached is requested by <lb/>READDIR, the results can be cached by the client on the same basis as <lb/>attributes obtained via GETATTR. <lb/>A client may validate its cached version of attributes for a file by <lb/>fetching both the change and time_access attributes and assuming that <lb/>if the change attribute has the same value as it did when the <lb/>attributes were cached, then no attributes other than time_access <lb/>have changed. The reason why time_access is also fetched is because <lb/>many servers operate in environments where the operation that updates <lb/>change does not update time_access. For example, POSIX file <lb/>semantics do not update access time when a file is modified by the <lb/>write system call [15]. Therefore, the client that wants a current <lb/>time_access value should fetch it with change during the attribute <lb/>cache validation processing and update its cached time_access. <lb/>The client may maintain a cache of modified attributes for those <lb/>attributes intimately connected with data of modified regular files <lb/>(size, time_modify, and change). Other than those three attributes, <lb/>the client MUST NOT maintain a cache of modified attributes. <lb/>Instead, attribute changes are immediately sent to the server. <lb/>In some operating environments, the equivalent to time_access is <lb/>expected to be implicitly updated by each read of the content of the <lb/>file object. If an NFS client is caching the content of a file <lb/>object, whether it is a regular file, directory, or symbolic link, <lb/>the client SHOULD NOT update the time_access attribute (via SETATTR <lb/>or a small READ or READDIR request) on the server with each read that <lb/>is satisfied from cache. The reason is that this can defeat the <lb/>performance benefits of caching content, especially since an explicit <lb/>SETATTR of time_access may alter the change attribute on the server. <lb/>If the change attribute changes, clients that are caching the content <lb/>will think the content has changed, and will re-read unmodified data <lb/>from the server. Nor is the client encouraged to maintain a modified <lb/>version of time_access in its cache, since the client either would <lb/>eventually have to write the access time to the server with bad <lb/>performance effects or never update the server&apos;s time_access, thereby <lb/>resulting in a situation where an application that caches access time <lb/>between a close and open of the same file observes the access time <lb/>oscillating between the past and present. The time_access attribute <lb/>always means the time of last access to a file by a read that was <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 218] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>satisfied by the server. This way clients will tend to see only <lb/>time_access changes that go forward in time. <lb/>10.7. Data and Metadata Caching and Memory Mapped Files <lb/>Some operating environments include the capability for an application <lb/>to map a file&apos;s content into the application&apos;s address space. Each <lb/>time the application accesses a memory location that corresponds to a <lb/>block that has not been loaded into the address space, a page fault <lb/>occurs and the file is read (or if the block does not exist in the <lb/>file, the block is allocated and then instantiated in the <lb/>application&apos;s address space). <lb/>As long as each memory-mapped access to the file requires a page <lb/>fault, the relevant attributes of the file that are used to detect <lb/>access and modification (time_access, time_metadata, time_modify, and <lb/>change) will be updated. However, in many operating environments, <lb/>when page faults are not required, these attributes will not be <lb/>updated on reads or updates to the file via memory access (regardless <lb/>of whether the file is local or is accessed remotely). A client or <lb/>server MAY fail to update attributes of a file that is being accessed <lb/>via memory-mapped I/O. This has several implications: <lb/>o If there is an application on the server that has memory mapped a <lb/>file that a client is also accessing, the client may not be able <lb/>to get a consistent value of the change attribute to determine <lb/>whether or not its cache is stale. A server that knows that the <lb/>file is memory-mapped could always pessimistically return updated <lb/>values for change so as to force the application to always get the <lb/>most up-to-date data and metadata for the file. However, due to <lb/>the negative performance implications of this, such behavior is <lb/>OPTIONAL. <lb/>o If the memory-mapped file is not being modified on the server, and <lb/>instead is just being read by an application via the memory-mapped <lb/>interface, the client will not see an updated time_access <lb/>attribute. However, in many operating environments, neither will <lb/>any process running on the server. Thus, NFS clients are at no <lb/>disadvantage with respect to local processes. <lb/>o If there is another client that is memory mapping the file, and if <lb/>that client is holding an OPEN_DELEGATE_WRITE delegation, the same <lb/>set of issues as discussed in the previous two bullet points <lb/>apply. So, when a server does a CB_GETATTR to a file that the <lb/>client has modified in its cache, the reply from CB_GETATTR will <lb/>not necessarily be accurate. As discussed earlier, the client&apos;s <lb/>obligation is to report that the file has been modified since the <lb/>delegation was granted, not whether it has been modified again <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 219] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>between successive CB_GETATTR calls, and the server MUST assume <lb/>that any file the client has modified in cache has been modified <lb/>again between successive CB_GETATTR calls. Depending on the <lb/>nature of the client&apos;s memory management system, this weak <lb/>obligation may not be possible. A client MAY return stale <lb/>information in CB_GETATTR whenever the file is memory-mapped. <lb/>o The mixture of memory mapping and byte-range locking on the same <lb/>file is problematic. Consider the following scenario, where a <lb/>page size on each client is 8192 bytes. <lb/>* Client A memory maps the first page (8192 bytes) of file X. <lb/>* Client B memory maps the first page (8192 bytes) of file X. <lb/>* Client A WRITE_LT locks the first 4096 bytes. <lb/>* Client B WRITE_LT locks the second 4096 bytes. <lb/>* Client A, via a STORE instruction, modifies part of its locked <lb/>byte-range. <lb/>* Simultaneous to client A, client B executes a STORE on part of <lb/>its locked byte-range. <lb/>Here the challenge is for each client to resynchronize to get a <lb/>correct view of the first page. In many operating environments, the <lb/>virtual memory management systems on each client only know a page is <lb/>modified, not that a subset of the page corresponding to the <lb/>respective lock byte-ranges has been modified. So it is not possible <lb/>for each client to do the right thing, which is to write to the <lb/>server only that portion of the page that is locked. For example, if <lb/>client A simply writes out the page, and then client B writes out the <lb/>page, client A&apos;s data is lost. <lb/>Moreover, if mandatory locking is enabled on the file, then we have a <lb/>different problem. When clients A and B execute the STORE <lb/>instructions, the resulting page faults require a byte-range lock on <lb/>the entire page. Each client then tries to extend their locked range <lb/>to the entire page, which results in a deadlock. Communicating the <lb/>NFS4ERR_DEADLOCK error to a STORE instruction is difficult at best. <lb/>If a client is locking the entire memory-mapped file, there is no <lb/>problem with advisory or mandatory byte-range locking, at least until <lb/>the client unlocks a byte-range in the middle of the file. <lb/>Given the above issues, the following are permitted: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 220] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o Clients and servers MAY deny memory mapping a file for which they <lb/>know there are byte-range locks. <lb/>o Clients and servers MAY deny a byte-range lock on a file they know <lb/>is memory-mapped. <lb/>o A client MAY deny memory mapping a file that it knows requires <lb/>mandatory locking for I/O. If mandatory locking is enabled after <lb/>the file is opened and mapped, the client MAY deny the application <lb/>further access to its mapped file. <lb/>10.8. Name and Directory Caching without Directory Delegations <lb/>The NFSv4.1 directory delegation facility (described in Section 10.9 <lb/>below) is OPTIONAL for servers to implement. Even where it is <lb/>implemented, it may not always be functional because of resource <lb/>availability issues or other constraints. Thus, it is important to <lb/>understand how name and directory caching are done in the absence of <lb/>directory delegations. These topics are discussed in the next two <lb/>subsections. <lb/>10.8.1. Name Caching <lb/>The results of LOOKUP and READDIR operations may be cached to avoid <lb/>the cost of subsequent LOOKUP operations. Just as in the case of <lb/>attribute caching, inconsistencies may arise among the various client <lb/>caches. To mitigate the effects of these inconsistencies and given <lb/>the context of typical file system APIs, an upper time boundary is <lb/>maintained for how long a client name cache entry can be kept without <lb/>verifying that the entry has not been made invalid by a directory <lb/>change operation performed by another client. <lb/>When a client is not making changes to a directory for which there <lb/>exist name cache entries, the client needs to periodically fetch <lb/>attributes for that directory to ensure that it is not being <lb/>modified. After determining that no modification has occurred, the <lb/>expiration time for the associated name cache entries may be updated <lb/>to be the current time plus the name cache staleness bound. <lb/>When a client is making changes to a given directory, it needs to <lb/>determine whether there have been changes made to the directory by <lb/>other clients. It does this by using the change attribute as <lb/>reported before and after the directory operation in the associated <lb/>change_info4 value returned for the operation. The server is able to <lb/>communicate to the client whether the change_info4 data is provided <lb/>atomically with respect to the directory operation. If the change <lb/>values are provided atomically, the client has a basis for <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 221] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>determining, given proper care, whether other clients are modifying <lb/>the directory in question. <lb/>The simplest way to enable the client to make this determination is <lb/>for the client to serialize all changes made to a specific directory. <lb/>When this is done, and the server provides before and after values of <lb/>the change attribute atomically, the client can simply compare the <lb/>after value of the change attribute from one operation on a directory <lb/>with the before value on the subsequent operation modifying that <lb/>directory. When these are equal, the client is assured that no other <lb/>client is modifying the directory in question. <lb/>When such serialization is not used, and there may be multiple <lb/>simultaneous outstanding operations modifying a single directory sent <lb/>from a single client, making this sort of determination can be more <lb/>complicated. If two such operations complete in a different order <lb/>than they were actually performed, that might give an appearance <lb/>consistent with modification being made by another client. Where <lb/>this appears to happen, the client needs to await the completion of <lb/>all such modifications that were started previously, to see if the <lb/>outstanding before and after change numbers can be sorted into a <lb/>chain such that the before value of one change number matches the <lb/>after value of a previous one, in a chain consistent with this client <lb/>being the only one modifying the directory. <lb/>In either of these cases, the client is able to determine whether the <lb/>directory is being modified by another client. If the comparison <lb/>indicates that the directory was updated by another client, the name <lb/>cache associated with the modified directory is purged from the <lb/>client. If the comparison indicates no modification, the name cache <lb/>can be updated on the client to reflect the directory operation and <lb/>the associated timeout can be extended. The post-operation change <lb/>value needs to be saved as the basis for future change_info4 <lb/>comparisons. <lb/>As demonstrated by the scenario above, name caching requires that the <lb/>client revalidate name cache data by inspecting the change attribute <lb/>of a directory at the point when the name cache item was cached. <lb/>This requires that the server update the change attribute for <lb/>directories when the contents of the corresponding directory is <lb/>modified. For a client to use the change_info4 information <lb/>appropriately and correctly, the server must report the pre-and <lb/>post-operation change attribute values atomically. When the server <lb/>is unable to report the before and after values atomically with <lb/>respect to the directory operation, the server must indicate that <lb/>fact in the change_info4 return value. When the information is not <lb/>atomically reported, the client should not assume that other clients <lb/>have not changed the directory. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 222] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>10.8.2. Directory Caching <lb/>The results of READDIR operations may be used to avoid subsequent <lb/>READDIR operations. Just as in the cases of attribute and name <lb/>caching, inconsistencies may arise among the various client caches. <lb/>To mitigate the effects of these inconsistencies, and given the <lb/>context of typical file system APIs, the following rules should be <lb/>followed: <lb/>o Cached READDIR information for a directory that is not obtained in <lb/>a single READDIR operation must always be a consistent snapshot of <lb/>directory contents. This is determined by using a GETATTR before <lb/>the first READDIR and after the last READDIR that contributes to <lb/>the cache. <lb/>o An upper time boundary is maintained to indicate the length of <lb/>time a directory cache entry is considered valid before the client <lb/>must revalidate the cached information. <lb/>The revalidation technique parallels that discussed in the case of <lb/>name caching. When the client is not changing the directory in <lb/>question, checking the change attribute of the directory with GETATTR <lb/>is adequate. The lifetime of the cache entry can be extended at <lb/>these checkpoints. When a client is modifying the directory, the <lb/>client needs to use the change_info4 data to determine whether there <lb/>are other clients modifying the directory. If it is determined that <lb/>no other client modifications are occurring, the client may update <lb/>its directory cache to reflect its own changes. <lb/>As demonstrated previously, directory caching requires that the <lb/>client revalidate directory cache data by inspecting the change <lb/>attribute of a directory at the point when the directory was cached. <lb/>This requires that the server update the change attribute for <lb/>directories when the contents of the corresponding directory is <lb/>modified. For a client to use the change_info4 information <lb/>appropriately and correctly, the server must report the pre-and <lb/>post-operation change attribute values atomically. When the server <lb/>is unable to report the before and after values atomically with <lb/>respect to the directory operation, the server must indicate that <lb/>fact in the change_info4 return value. When the information is not <lb/>atomically reported, the client should not assume that other clients <lb/>have not changed the directory. <lb/>10.9. Directory Delegations <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 223] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>10.9.1. Introduction to Directory Delegations <lb/>Directory caching for the NFSv4.1 protocol, as previously described, <lb/>is similar to file caching in previous versions. Clients typically <lb/>cache directory information for a duration determined by the client. <lb/>At the end of a predefined timeout, the client will query the server <lb/>to see if the directory has been updated. By caching attributes, <lb/>clients reduce the number of GETATTR calls made to the server to <lb/>validate attributes. Furthermore, frequently accessed files and <lb/>directories, such as the current working directory, have their <lb/>attributes cached on the client so that some NFS operations can be <lb/>performed without having to make an RPC call. By caching name and <lb/>inode information about most recently looked up entries in a <lb/>Directory Name Lookup Cache (DNLC), clients do not need to send <lb/>LOOKUP calls to the server every time these files are accessed. <lb/>This caching approach works reasonably well at reducing network <lb/>traffic in many environments. However, it does not address <lb/>environments where there are numerous queries for files that do not <lb/>exist. In these cases of &quot;misses&quot;, the client sends requests to the <lb/>server in order to provide reasonable application semantics and <lb/>promptly detect the creation of new directory entries. Examples of <lb/>high miss activity are compilation in software development <lb/>environments. The current behavior of NFS limits its potential <lb/>scalability and wide-area sharing effectiveness in these types of <lb/>environments. Other distributed stateful file system architectures <lb/>such as AFS and DFS have proven that adding state around directory <lb/>contents can greatly reduce network traffic in high-miss <lb/>environments. <lb/>Delegation of directory contents is an OPTIONAL feature of NFSv4.1. <lb/>Directory delegations provide similar traffic reduction benefits as <lb/>with file delegations. By allowing clients to cache directory <lb/>contents (in a read-only fashion) while being notified of changes, <lb/>the client can avoid making frequent requests to interrogate the <lb/>contents of slowly-changing directories, reducing network traffic and <lb/>improving client performance. It can also simplify the task of <lb/>determining whether other clients are making changes to the directory <lb/>when the client itself is making many changes to the directory and <lb/>changes are not serialized. <lb/>Directory delegations allow improved namespace cache consistency to <lb/>be achieved through delegations and synchronous recalls, in the <lb/>absence of notifications. In addition, if time-based consistency is <lb/>sufficient, asynchronous notifications can provide performance <lb/>benefits for the client, and possibly the server, under some common <lb/>operating conditions such as slowly-changing and/or very large <lb/>directories. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 224] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>10.9.2. Directory Delegation Design <lb/>NFSv4.1 introduces the GET_DIR_DELEGATION (Section 18.39) operation <lb/>to allow the client to ask for a directory delegation. The <lb/>delegation covers directory attributes and all entries in the <lb/>directory. If either of these change, the delegation will be <lb/>recalled synchronously. The operation causing the recall will have <lb/>to wait before the recall is complete. Any changes to directory <lb/>entry attributes will not cause the delegation to be recalled. <lb/>In addition to asking for delegations, a client can also ask for <lb/>notifications for certain events. These events include changes to <lb/>the directory&apos;s attributes and/or its contents. If a client asks for <lb/>notification for a certain event, the server will notify the client <lb/>when that event occurs. This will not result in the delegation being <lb/>recalled for that client. The notifications are asynchronous and <lb/>provide a way of avoiding recalls in situations where a directory is <lb/>changing enough that the pure recall model may not be effective while <lb/>trying to allow the client to get substantial benefit. In the <lb/>absence of notifications, once the delegation is recalled the client <lb/>has to refresh its directory cache; this might not be very efficient <lb/>for very large directories. <lb/>The delegation is read-only and the client may not make changes to <lb/>the directory other than by performing NFSv4.1 operations that modify <lb/>the directory or the associated file attributes so that the server <lb/>has knowledge of these changes. In order to keep the client&apos;s <lb/>namespace synchronized with the server, the server will notify the <lb/>delegation-holding client (assuming it has requested notifications) <lb/>of the changes made as a result of that client&apos;s directory-modifying <lb/>operations. This is to avoid any need for that client to send <lb/>subsequent GETATTR or READDIR operations to the server. If a single <lb/>client is holding the delegation and that client makes any changes to <lb/>the directory (i.e., the changes are made via operations sent on a <lb/>session associated with the client ID holding the delegation), the <lb/>delegation will not be recalled. Multiple clients may hold a <lb/>delegation on the same directory, but if any such client modifies the <lb/>directory, the server MUST recall the delegation from the other <lb/>clients, unless those clients have made provisions to be notified of <lb/>that sort of modification. <lb/>Delegations can be recalled by the server at any time. Normally, the <lb/>server will recall the delegation when the directory changes in a way <lb/>that is not covered by the notification, or when the directory <lb/>changes and notifications have not been requested. If another client <lb/>removes the directory for which a delegation has been granted, the <lb/>server will recall the delegation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 225] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>10.9.3. Attributes in Support of Directory Notifications <lb/>See Section 5.11 for a description of the attributes associated with <lb/>directory notifications. <lb/>10.9.4. Directory Delegation Recall <lb/>The server will recall the directory delegation by sending a callback <lb/>to the client. It will use the same callback procedure as used for <lb/>recalling file delegations. The server will recall the delegation <lb/>when the directory changes in a way that is not covered by the <lb/>notification. However, the server need not recall the delegation if <lb/>attributes of an entry within the directory change. <lb/>If the server notices that handing out a delegation for a directory <lb/>is causing too many notifications to be sent out, it may decide to <lb/>not hand out delegations for that directory and/or recall those <lb/>already granted. If a client tries to remove the directory for which <lb/>a delegation has been granted, the server will recall all associated <lb/>delegations. <lb/>The implementation sections for a number of operations describe <lb/>situations in which notification or delegation recall would be <lb/>required under some common circumstances. In this regard, a similar <lb/>set of caveats to those listed in Section 10.2 apply. <lb/>o For CREATE, see Section 18.4.4. <lb/>o For LINK, see Section 18.9.4. <lb/>o For OPEN, see Section 18.16.4. <lb/>o For REMOVE, see Section 18.25.4. <lb/>o For RENAME, see Section 18.26.4. <lb/>o For SETATTR, see Section 18.30.4. <lb/>10.9.5. Directory Delegation Recovery <lb/>Recovery from client or server restart for state on regular files has <lb/>two main goals: avoiding the necessity of breaking application <lb/>guarantees with respect to locked files and delivery of updates <lb/>cached at the client. Neither of these goals applies to directories <lb/>protected by OPEN_DELEGATE_READ delegations and notifications. Thus, <lb/>no provision is made for reclaiming directory delegations in the <lb/>event of client or server restart. The client can simply establish a <lb/>directory delegation in the same fashion as was done initially. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 226] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>11. Multi-Server Namespace <lb/>NFSv4.1 supports attributes that allow a namespace to extend beyond <lb/>the boundaries of a single server. It is desirable that clients and <lb/>servers support construction of such multi-server namespaces. Use of <lb/>such multi-server namespaces is OPTIONAL however, and for many <lb/>purposes, single-server namespaces are perfectly acceptable. Use of <lb/>multi-server namespaces can provide many advantages, by separating a <lb/>file system&apos;s logical position in a namespace from the (possibly <lb/>changing) logistical and administrative considerations that result in <lb/>particular file systems being located on particular servers via a <lb/>single network access paths known in advance or determined using DNS. <lb/>11.1. Terminology <lb/>In this section as a whole (i.e within Section 11), the phrase <lb/>&quot;client ID&quot; always refers to the 64-bit shorthand identifier assigned <lb/>by the server (a clientid4) and never to the structure which the <lb/>client uses to identify itself to the server (called an <lb/>nfs_client_id4 or client_owner in NFSv4.0 and NFSv4.1 respectively). <lb/>The opaque identifier within those structures is referred to as a <lb/>&quot;client id string&quot;. <lb/>11.1.1. Terminology Related to Trunking <lb/>It is particularly important to clarify the distinction between <lb/>trunking detection and trunking discovery. The definitions we <lb/>present are applicable to all minor versions of NFSv4, but we will <lb/>focus on how these terms apply to NFS version 4.1. <lb/>o Trunking detection refers to ways of deciding whether two specific <lb/>network addresses are connected to the same NFSv4 server. The <lb/>means available to make this determination depends on the protocol <lb/>version, and, in some cases, on the client implementation. <lb/>In the case of NFS version 4.1 and later minor versions, the means <lb/>of trunking detection are as described in this document and are <lb/>available to every client. Two network addresses connected to the <lb/>same server are always server-trunkable but cannot necessarily be <lb/>used together to access a single session. <lb/>o Trunking discovery is a process by which a client using one <lb/>network address can obtain other addresses that are connected to <lb/>the same server. Typically, it builds on a trunking detection <lb/>facility by providing one or more methods by which candidate <lb/>addresses are made available to the client who can then use <lb/>trunking detection to appropriately filter them. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 227] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Despite the support for trunking detection there was no <lb/>description of trunking discovery provided in RFC5661 [60], making <lb/>it necessary to provide those means in this document. <lb/>The combination of a server network address and a particular <lb/>connection type to be used by a connection is referred to as a <lb/>&quot;server endpoint&quot;. Although using different connection types may <lb/>result in different ports being used, the use of different ports by <lb/>multiple connections to the same network address is not the essence <lb/>of the distinction between the two endpoints used. <lb/>Two network addresses connected to the same server are said to be <lb/>server-trunkable. Two such addresses support the use of clientid ID <lb/>trunking, as described in Section 2.10.5. <lb/>Two network addresses connected to the same server such that those <lb/>addresses can be used to support a single common session are referred <lb/>to as session-trunkable. Note that two addresses may be server-<lb/>trunkable without being session-trunkable and that when two <lb/>connections of different connection types are made to the same <lb/>network address and are based on a single file system location entry <lb/>they are always session-trunkable, independent of the connection <lb/>type, as specified by Section 2.10.5, since their derivation from the <lb/>same file system location entry together with the identity of their <lb/>network addresses assures that both connections are to the same <lb/>server and will return server-owner information allowing session <lb/>trunking to be used. <lb/>11.1.2. Terminology Related to File System Location <lb/>Regarding terminology relating to the construction of multi-server <lb/>namespaces out of a set of local per-server namespaces: <lb/>o Each server has a set of exported file systems which may be <lb/>accessed by NFSv4 clients. Typically, this is done by assigning <lb/>each file system a name within the pseudo-fs associated with the <lb/>server, although the pseudo-fs may be dispensed with if there is <lb/>only a single exported file system. Each such file system is part <lb/>of the server&apos;s local namespace, and can be considered as a file <lb/>system instance within a larger multi-server namespace. <lb/>o The set of all exported file systems for a given server <lb/>constitutes that server&apos;s local namespace. <lb/>o In some cases, a server will have a namespace more extensive than <lb/>its local namespace by using features associated with attributes <lb/>that provide file system location information. These features, <lb/>which allow construction of a multi-server namespace are all <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 228] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>described in individual sections below and include referrals <lb/>(described in Section 11.5.6), migration (described in <lb/>Section 11.5.5), and replication (described in Section 11.5.4). <lb/>o A file system present in a server&apos;s pseudo-fs may have multiple <lb/>file system instances on different servers associated with it. <lb/>All such instances are considered replicas of one another. <lb/>o When a file system is present in a server&apos;s pseudo-fs, but there <lb/>is no corresponding local file system, it is said to be &quot;absent&quot;. <lb/>In such cases, all associated instances will be accessed on other <lb/>servers. <lb/>Regarding terminology relating to attributes used in trunking <lb/>discovery and other multi-server namespace features: <lb/>o File system location attributes include the fs_locations and <lb/>fs_locations_info attributes. <lb/>o File system location entries provide the individual file system <lb/>locations within the file system location attributes. Each such <lb/>entry specifies a server, in the form of a host name or IP an <lb/>address, and an fs name, which designates the location of the file <lb/>system within the server&apos;s local namespace. A file system <lb/>location entry designates a set of server endpoints to which the <lb/>client may establish connections. There may be multiple endpoints <lb/>because a host name may map to multiple network addresses and <lb/>because multiple connection types may be used to communicate with <lb/>a single network address. However, all such endpoints MUST <lb/>provide a way of connecting to a single server. The exact form of <lb/>the location entry varies with the particular file system location <lb/>attribute used, as described in Section 11.2. <lb/>o File system location elements are derived from location entries <lb/>and each describes a particular network access path, consisting of <lb/>a network address and a location within the server&apos;s local <lb/>namespace. Such location elements need not appear within a file <lb/>system location attribute, but the existence of each location <lb/>element derives from a corresponding location entry. When a <lb/>location entry specifies an IP address there is only a single <lb/>corresponding location element. File system location entries that <lb/>contain a host name are resolved using DNS, and may result in one <lb/>or more location elements. All location elements consist of a <lb/>location address which is the IP address of an interface to a <lb/>server and an fs name which is the location of the file system <lb/>within the server&apos;s local namespace. The fs name can be empty if <lb/>the server has no pseudo-fs and only a single exported file system <lb/>at the root filehandle. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 229] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o Two file system location elements are said to be server-trunkable <lb/>if they specify the same fs name and the location addresses are <lb/>such that the location addresses are server-trunkable. When the <lb/>corresponding network paths are used, the client will always be <lb/>able to use client ID trunking, but will only be able to use <lb/>session trunking if the paths are also session-trunkable. <lb/>o Two file system location elements are said to be session-trunkable <lb/>if they specify the same fs name and the location addresses are <lb/>such that the location addresses are session-trunkable. When the <lb/>corresponding network paths are used, the client will be able to <lb/>able to use either client ID trunking or session trunking. <lb/>Discussion of the term &quot;replica&quot; is complicated by the fact that the <lb/>term was used in RFC5661 [60], with a meaning different from that in <lb/>this document. In short, in [60] each replica is identified by a <lb/>single network access path while, in the current document a set of <lb/>network access paths which have server-trunkable network addresses <lb/>and the same root-relative file system pathname is considered to be a <lb/>single replica with multiple network access paths. <lb/>Each set of server-trunkable location elements defines a set of <lb/>available network access paths to a particular file system. When <lb/>there are multiple such file systems, each of which contains the same <lb/>data, these file systems are considered replicas of one another. <lb/>Logically, such replication is symmetric, since the fs currently in <lb/>use and an alternate fs are replicas of each other. Often, in other <lb/>documents, the term &quot;replica&quot; is not applied to the fs currently in <lb/>use, despite the fact that the replication relation is inherently <lb/>symmetric. <lb/>11.2. File System Location Attributes <lb/>NFSv4.1 contains attributes that provide information about how (i.e., <lb/>at what network address and namespace position) a given file system <lb/>may be accessed. As a result, file systems in the namespace of one <lb/>server can be associated with one or more instances of that file <lb/>system on other servers. These attributes contain file system <lb/>location entries specifying a server address target (either as a DNS <lb/>name representing one or more IP addresses or as a specific IP <lb/>address) together with the pathname of that file system within the <lb/>associated single-server namespace. <lb/>The fs_locations_info RECOMMENDED attribute allows specification of <lb/>one or more file system instance locations where the data <lb/>corresponding to a given file system may be found. This attribute <lb/>provides to the client, in addition to specification of file system <lb/>instance locations, other helpful information such as: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 230] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o Information guiding choices among the various file system <lb/>instances provided (e.g., priority for use, writability, currency, <lb/>etc.). <lb/>o Information to help the client efficiently effect as seamless a <lb/>transition as possible among multiple file system instances, when <lb/>and if that should be necessary. <lb/>o Information helping to guide the selection of the appropriate <lb/>connection type to be used when establishing a connection. <lb/>Within the fs_locations_info attribute, each fs_locations_server4 <lb/>entry corresponds to a file system location entry with the fls_server <lb/>field designating the server, with the location pathname within the <lb/>server&apos;s pseudo-fs given by the fl_rootpath field of the encompassing <lb/>fs_locations_item4. <lb/>The fs_locations attribute defined in NFSv4.0 is also a part of <lb/>NFSv4.1. This attribute only allows specification of the file system <lb/>locations where the data corresponding to a given file system may be <lb/>found. Servers should make this attribute available whenever <lb/>fs_locations_info is supported, but client use of fs_locations_info <lb/>is preferable, as it provides more information. <lb/>Within the fs_location attribute, each fs_location4 contains a file <lb/>system location entry with the server field designating the server <lb/>and the rootpath field giving the location pathname within the <lb/>server&apos;s pseudo-fs. <lb/>11.3. File System Presence or Absence <lb/>A given location in an NFSv4.1 namespace (typically but not <lb/>necessarily a multi-server namespace) can have a number of file <lb/>system instance locations associated with it (via the fs_locations or <lb/>fs_locations_info attribute). There may also be an actual current <lb/>file system at that location, accessible via normal namespace <lb/>operations (e.g., LOOKUP). In this case, the file system is said to <lb/>be &quot;present&quot; at that position in the namespace, and clients will <lb/>typically use it, reserving use of additional locations specified via <lb/>the location-related attributes to situations in which the principal <lb/>location is no longer available. <lb/>When there is no actual file system at the namespace location in <lb/>question, the file system is said to be &quot;absent&quot;. An absent file <lb/>system contains no files or directories other than the root. Any <lb/>reference to it, except to access a small set of attributes useful in <lb/>determining alternate locations, will result in an error, <lb/>NFS4ERR_MOVED. Note that if the server ever returns the error <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 231] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>NFS4ERR_MOVED, it MUST support the fs_locations attribute and SHOULD <lb/>support the fs_locations_info and fs_status attributes. <lb/>While the error name suggests that we have a case of a file system <lb/>that once was present, and has only become absent later, this is only <lb/>one possibility. A position in the namespace may be permanently <lb/>absent with the set of file system(s) designated by the location <lb/>attributes being the only realization. The name NFS4ERR_MOVED <lb/>reflects an earlier, more limited conception of its function, but <lb/>this error will be returned whenever the referenced file system is <lb/>absent, whether it has moved or not. <lb/>Except in the case of GETATTR-type operations (to be discussed <lb/>later), when the current filehandle at the start of an operation is <lb/>within an absent file system, that operation is not performed and the <lb/>error NFS4ERR_MOVED is returned, to indicate that the file system is <lb/>absent on the current server. <lb/>Because a GETFH cannot succeed if the current filehandle is within an <lb/>absent file system, filehandles within an absent file system cannot <lb/>be transferred to the client. When a client does have filehandles <lb/>within an absent file system, it is the result of obtaining them when <lb/>the file system was present, and having the file system become absent <lb/>subsequently. <lb/>It should be noted that because the check for the current filehandle <lb/>being within an absent file system happens at the start of every <lb/>operation, operations that change the current filehandle so that it <lb/>is within an absent file system will not result in an error. This <lb/>allows such combinations as PUTFH-GETATTR and LOOKUP-GETATTR to be <lb/>used to get attribute information, particularly location attribute <lb/>information, as discussed below. <lb/>The RECOMMENDED file system attribute fs_status can be used to <lb/>interrogate the present/absent status of a given file system. <lb/>11.4. Getting Attributes for an Absent File System <lb/>When a file system is absent, most attributes are not available, but <lb/>it is necessary to allow the client access to the small set of <lb/>attributes that are available, and most particularly those that give <lb/>information about the correct current locations for this file system: <lb/>fs_locations and fs_locations_info. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 232] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>11.4.1. GETATTR within an Absent File System <lb/>As mentioned above, an exception is made for GETATTR in that <lb/>attributes may be obtained for a filehandle within an absent file <lb/>system. This exception only applies if the attribute mask contains <lb/>at least one attribute bit that indicates the client is interested in <lb/>a result regarding an absent file system: fs_locations, <lb/>fs_locations_info, or fs_status. If none of these attributes is <lb/>requested, GETATTR will result in an NFS4ERR_MOVED error. <lb/>When a GETATTR is done on an absent file system, the set of supported <lb/>attributes is very limited. Many attributes, including those that <lb/>are normally REQUIRED, will not be available on an absent file <lb/>system. In addition to the attributes mentioned above (fs_locations, <lb/>fs_locations_info, fs_status), the following attributes SHOULD be <lb/>available on absent file systems. In the case of RECOMMENDED <lb/>attributes, they should be available at least to the same degree that <lb/>they are available on present file systems. <lb/>change_policy: This attribute is useful for absent file systems and <lb/>can be helpful in summarizing to the client when any of the <lb/>location-related attributes change. <lb/>fsid: This attribute should be provided so that the client can <lb/>determine file system boundaries, including, in particular, the <lb/>boundary between present and absent file systems. This value must <lb/>be different from any other fsid on the current server and need <lb/>have no particular relationship to fsids on any particular <lb/>destination to which the client might be directed. <lb/>mounted_on_fileid: For objects at the top of an absent file system, <lb/>this attribute needs to be available. Since the fileid is within <lb/>the present parent file system, there should be no need to <lb/>reference the absent file system to provide this information. <lb/>Other attributes SHOULD NOT be made available for absent file <lb/>systems, even when it is possible to provide them. The server should <lb/>not assume that more information is always better and should avoid <lb/>gratuitously providing additional information. <lb/>When a GETATTR operation includes a bit mask for one of the <lb/>attributes fs_locations, fs_locations_info, or fs_status, but where <lb/>the bit mask includes attributes that are not supported, GETATTR will <lb/>not return an error, but will return the mask of the actual <lb/>attributes supported with the results. <lb/>Handling of VERIFY/NVERIFY is similar to GETATTR in that if the <lb/>attribute mask does not include fs_locations, fs_locations_info, or <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 233] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>fs_status, the error NFS4ERR_MOVED will result. It differs in that <lb/>any appearance in the attribute mask of an attribute not supported <lb/>for an absent file system (and note that this will include some <lb/>normally REQUIRED attributes) will also cause an NFS4ERR_MOVED <lb/>result. <lb/>11.4.2. READDIR and Absent File Systems <lb/>A READDIR performed when the current filehandle is within an absent <lb/>file system will result in an NFS4ERR_MOVED error, since, unlike the <lb/>case of GETATTR, no such exception is made for READDIR. <lb/>Attributes for an absent file system may be fetched via a READDIR for <lb/>a directory in a present file system, when that directory contains <lb/>the root directories of one or more absent file systems. In this <lb/>case, the handling is as follows: <lb/>o If the attribute set requested includes one of the attributes <lb/>fs_locations, fs_locations_info, or fs_status, then fetching of <lb/>attributes proceeds normally and no NFS4ERR_MOVED indication is <lb/>returned, even when the rdattr_error attribute is requested. <lb/>o If the attribute set requested does not include one of the <lb/>attributes fs_locations, fs_locations_info, or fs_status, then if <lb/>the rdattr_error attribute is requested, each directory entry for <lb/>the root of an absent file system will report NFS4ERR_MOVED as the <lb/>value of the rdattr_error attribute. <lb/>o If the attribute set requested does not include any of the <lb/>attributes fs_locations, fs_locations_info, fs_status, or <lb/>rdattr_error, then the occurrence of the root of an absent file <lb/>system within the directory will result in the READDIR failing <lb/>with an NFS4ERR_MOVED error. <lb/>o The unavailability of an attribute because of a file system&apos;s <lb/>absence, even one that is ordinarily REQUIRED, does not result in <lb/>any error indication. The set of attributes returned for the root <lb/>directory of the absent file system in that case is simply <lb/>restricted to those actually available. <lb/>11.5. Uses of File System Location Information <lb/>The file system location attributes (i.e. fs_locations and <lb/>fs_locations_info), together with the possibility of absent file <lb/>systems, provide a number of important facilities in providing <lb/>reliable, manageable, and scalable data access. <lb/>When a file system is present, these attributes can provide <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 234] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o The locations of alternative replicas, to be used to access the <lb/>same data in the event of server failures, communications <lb/>problems, or other difficulties that make continued access to the <lb/>current replica impossible or otherwise impractical. Provision <lb/>and use of such alternate replicas is referred to as &quot;replication&quot; <lb/>and is discussed in Section 11.5.4 below. <lb/>o The network address(es) to be used to access the current file <lb/>system instance or replicas of it. Client use of this information <lb/>is discussed in Section 11.5.2 below. <lb/>Under some circumstances, multiple replicas may be used <lb/>simultaneously to provide higher-performance access to the file <lb/>system in question, although the lack of state sharing between <lb/>servers may be an impediment to such use. <lb/>When a file system is present and becomes absent, clients can be <lb/>given the opportunity to have continued access to their data, using a <lb/>different replica. In this case, a continued attempt to use the data <lb/>in the now-absent file system will result in an NFS4ERR_MOVED error <lb/>and, at that point, the successor replica or set of possible replica <lb/>choices can be fetched and used to continue access. Transfer of <lb/>access to the new replica location is referred to as &quot;migration&quot;, and <lb/>is discussed in Section 11.5.4 below. <lb/>Where a file system had been absent, specification of file system <lb/>location provides a means by which file systems located on one server <lb/>can be associated with a namespace defined by another server, thus <lb/>allowing a general multi-server namespace facility. A designation of <lb/>such a remote instance, in place of a file system never previously <lb/>present, is called a &quot;pure referral&quot; and is discussed in <lb/>Section 11.5.6 below. <lb/>Because client support for attributes related to file system location <lb/>is OPTIONAL, a server may choose to take action to hide migration and <lb/>referral events from such clients, by acting as a proxy, for example. <lb/>The server can determine the presence of client support from the <lb/>arguments of the EXCHANGE_ID operation (see Section 18.35.3). <lb/>11.5.1. Combining Multiple Uses in a Single Attribute <lb/>A file system location attribute will sometimes contain information <lb/>relating to the location of multiple replicas which may be used in <lb/>different ways. <lb/>o File system location entries that relate to the file system <lb/>instance currently in use provide trunking information, allowing <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 235] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the client to find additional network addresses by which the <lb/>instance may be accessed. <lb/>o File system location entries that provide information about <lb/>replicas to which access is to be transferred. <lb/>o Other file system location entries that relate to replicas that <lb/>are available to use in the event that access to the current <lb/>replica becomes unsatisfactory. <lb/>In order to simplify client handling and allow the best choice of <lb/>replicas to access, the server should adhere to the following <lb/>guidelines. <lb/>o All file system location entries that relate to a single file <lb/>system instance should be adjacent. <lb/>o File system location entries that relate to the instance currently <lb/>in use should appear first. <lb/>o File system location entries that relate to replica(s) to which <lb/>migration is occurring should appear before replicas which are <lb/>available for later use if the current replica should become <lb/>inaccessible. <lb/>11.5.2. File System Location Attributes and Trunking <lb/>Trunking is the use of multiple connections between a client and <lb/>server in order to increase the speed of data transfer. A client may <lb/>determine the set of network addresses to use to access a given file <lb/>system in a number of ways: <lb/>o When the name of the server is known to the client, it may use DNS <lb/>to obtain a set of network addresses to use in accessing the <lb/>server. <lb/>o The client may fetch the file system location attribute for the <lb/>file system. This will provide either the name of the server <lb/>(which can be turned into a set of network addresses using DNS), <lb/>or a set of server-trunkable location entries. Using the latter <lb/>alternative, the server can provide addresses it regards as <lb/>desirable to use to access the file system in question. <lb/>It should be noted that the client, when it fetches a location <lb/>attribute for a file system, may encounter multiple entries for a <lb/>number of reasons, so that, when determining trunking information, it <lb/>may have to bypass addresses not trunkable with one already known. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 236] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The server can provide location entries that include either names or <lb/>network addresses. It might use the latter form because of DNS-<lb/>related security concerns or because the set of addresses to be used <lb/>might require active management by the server. <lb/>Locations entries used to discover candidate addresses for use in <lb/>trunking are subject to change, as discussed in Section 11.5.7 below. <lb/>The client may respond to such changes by using additional addresses <lb/>once they are verified or by ceasing to use existing ones. The <lb/>server can force the client to cease using an address by returning <lb/>NFS4ERR_MOVED when that address is used to access a file system. <lb/>This allows a transfer of client access which is similar to <lb/>migration, although the same file system instance is accessed <lb/>throughout. <lb/>11.5.3. File System Location Attributes and Connection Type Selection <lb/>Because of the need to support multiple types of connections, clients <lb/>face the issue of determining the proper connection type to use when <lb/>establishing a connection to a given server network address. In some <lb/>cases, this issue can be addressed through the use of the connection <lb/>&quot;step-up&quot; facility described in Section 18.36. However, because <lb/>there are cases is which that facility is not available, the client <lb/>may have to choose a connection type with no possibility of changing <lb/>it within the scope of a single connection. <lb/>The two file system location attributes differ as to the information <lb/>made available in this regard. Fs_locations provides no information <lb/>to support connection type selection. As a result, clients <lb/>supporting multiple connection types would need to attempt to <lb/>establish connections using multiple connection types until the one <lb/>preferred by the client is successfully established. <lb/>Fs_locations_info includes a flag, FSLI4TF_RDMA, which, when set <lb/>indicates that RPC-over-RDMA support is available using the specified <lb/>location entry, by &quot;stepping up&quot; an existing TCP connection to <lb/>include support for RDMA operation. This flag makes it convenient <lb/>for a client wishing to use RDMA. When this flag is set, it can <lb/>establish a TCP connection and then convert that connection to use <lb/>RDMA by using the step-up facility. <lb/>Irrespective of the particular attribute used, when there is no <lb/>indication that a step-up operation can be performed, a client <lb/>supporting RDMA operation can establish a new RDMA connection and it <lb/>can be bound to the session already established by the TCP <lb/>connection, allowing the TCP connection to be dropped and the session <lb/>converted to further use in RDMA node. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 237] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>11.5.4. File System Replication <lb/>The fs_locations and fs_locations_info attributes provide alternative <lb/>file system locations, to be used to access data in place of or in <lb/>addition to the current file system instance. On first access to a <lb/>file system, the client should obtain the set of alternate locations <lb/>by interrogating the fs_locations or fs_locations_info attribute, <lb/>with the latter being preferred. <lb/>In the event that the occurrence of server failures, communications <lb/>problems, or other difficulties make continued access to the current <lb/>file system impossible or otherwise impractical, the client can use <lb/>the alternate locations as a way to get continued access to its data. <lb/>The alternate locations may be physical replicas of the (typically <lb/>read-only) file system data, or they may provide for the use of <lb/>various forms of server clustering in which multiple servers provide <lb/>alternate ways of accessing the same physical file system. How these <lb/>different modes of file system transition are represented within the <lb/>fs_locations and fs_locations_info attributes and how the client <lb/>deals with file system transition issues will be discussed in detail <lb/>below. <lb/>11.5.5. File System Migration <lb/>When a file system is present and becomes absent, the NFSv4.1 <lb/>protocol provides a means by which clients can be given the <lb/>opportunity to have continued access to their data, using a different <lb/>replica. The location of this replica is specified by a file system <lb/>location attribute. The ensuing migration of access to another <lb/>replica includes the ability to retain locks across the transition, <lb/>either by using lock reclaim or by taking advantage of Transparent <lb/>State Migration. <lb/>Typically, a client will be accessing the file system in question, <lb/>get an NFS4ERR_MOVED error, and then use a file system location <lb/>attribute to determine the new location of the data. When <lb/>fs_locations_info is used, additional information will be available <lb/>that will define the nature of the client&apos;s handling of the <lb/>transition to a new server. <lb/>Such migration can be helpful in providing load balancing or general <lb/>resource reallocation. The protocol does not specify how the file <lb/>system will be moved between servers. It is anticipated that a <lb/>number of different server-to-server transfer mechanisms might be <lb/>used with the choice left to the server implementer. The NFSv4.1 <lb/>protocol specifies the method used to communicate the migration event <lb/>between client and server. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 238] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The new location may be, in the case of various forms of server <lb/>clustering, another server providing access to the same physical file <lb/>system. The client&apos;s responsibilities in dealing with this <lb/>transition will depend on whether migration has occurred and the <lb/>means the server has chosen to provide continuity of locking state. <lb/>These issues will be discussed in detail below. <lb/>Although a single successor location is typical, multiple locations <lb/>may be provided. When multiple locations are provided, the client <lb/>will typically use the first one provided. If that is inaccessible <lb/>for some reason, later ones can be used. In such cases the client <lb/>might consider that the transition to the new replica as a migration <lb/>event, even though some of the servers involved might not be aware of <lb/>the use of the server which was inaccessible. In such a case, a <lb/>client might lose access to locking state as a result of the access <lb/>transfer. <lb/>When an alternate location is designated as the target for migration, <lb/>it must designate the same data (with metadata being the same to the <lb/>degree indicated by the fs_locations_info attribute). Where file <lb/>systems are writable, a change made on the original file system must <lb/>be visible on all migration targets. Where a file system is not <lb/>writable but represents a read-only copy (possibly periodically <lb/>updated) of a writable file system, similar requirements apply to the <lb/>propagation of updates. Any change visible in the original file <lb/>system must already be effected on all migration targets, to avoid <lb/>any possibility that a client, in effecting a transition to the <lb/>migration target, will see any reversion in file system state. <lb/>11.5.6. Referrals <lb/>Referrals allow the server to associate a file system namespace entry <lb/>located on one server with a file system located on another server. <lb/>When this includes the use of pure referrals, servers are provided a <lb/>way of placing a file system in a location within the namespace <lb/>essentially without respect to its physical location on a particular <lb/>server. This allows a single server or a set of servers to present a <lb/>multi-server namespace that encompasses file systems located on a <lb/>wider range of servers. Some likely uses of this facility include <lb/>establishment of site-wide or organization-wide namespaces, with the <lb/>eventual possibility of combining such together into a truly global <lb/>namespace, such as the one provided by AFS (the Andrew File System) <lb/>[TBD: appropriate reference needed] <lb/>Referrals occur when a client determines, upon first referencing a <lb/>position in the current namespace, that it is part of a new file <lb/>system and that the file system is absent. When this occurs, <lb/>typically upon receiving the error NFS4ERR_MOVED, the actual location <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 239] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>or locations of the file system can be determined by fetching a <lb/>locations attribute. <lb/>The file system location attribute may designate a single file system <lb/>location or multiple file system locations, to be selected based on <lb/>the needs of the client. The server, in the fs_locations_info <lb/>attribute, may specify priorities to be associated with various file <lb/>system location choices. The server may assign different priorities <lb/>to different locations as reported to individual clients, in order to <lb/>adapt to client physical location or to effect load balancing. When <lb/>both read-only and read-write file systems are present, some of the <lb/>read-only locations might not be absolutely up-to-date (as they would <lb/>have to be in the case of replication and migration). Servers may <lb/>also specify file system locations that include client-substituted <lb/>variables so that different clients are referred to different file <lb/>systems (with different data contents) based on client attributes <lb/>such as CPU architecture. <lb/>When the fs_locations_info attribute is such that that there are <lb/>multiple possible targets listed, the relationships among them may be <lb/>important to the client in selecting which one to use. The same <lb/>rules specified in Section 11.5.5 below regarding multiple migration <lb/>targets apply to these multiple replicas as well. For example, the <lb/>client might prefer a writable target on a server that has additional <lb/>writable replicas to which it subsequently might switch. Note that, <lb/>as distinguished from the case of replication, there is no need to <lb/>deal with the case of propagation of updates made by the current <lb/>client, since the current client has not accessed the file system in <lb/>question. <lb/>Use of multi-server namespaces is enabled by NFSv4.1 but is not <lb/>required. The use of multi-server namespaces and their scope will <lb/>depend on the applications used and system administration <lb/>preferences. <lb/>Multi-server namespaces can be established by a single server <lb/>providing a large set of pure referrals to all of the included file <lb/>systems. Alternatively, a single multi-server namespace may be <lb/>administratively segmented with separate referral file systems (on <lb/>separate servers) for each separately administered portion of the <lb/>namespace. The top-level referral file system or any segment may use <lb/>replicated referral file systems for higher availability. <lb/>Generally, multi-server namespaces are for the most part uniform, in <lb/>that the same data made available to one client at a given location <lb/>in the namespace is made available to all clients at that namespace <lb/>location. However, there are facilities provided that allow <lb/>different clients to be directed to different sets of data, for <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 240] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>reasons such as enabling adaptation to such client characteristics as <lb/>CPU architecture. These facilities are described in Section 11.16.3. <lb/>Note that it is possible, when providing a uniform namespace, to <lb/>provide diffeent location entries to diffeent clients, in order to <lb/>provide each client with a copy of the data physically closest to it, <lb/>or otherwise optimize access (e.g. provide load balancing). <lb/>11.5.7. Changes in a File System Location Attribute <lb/>Although clients will typically fetch a file system location <lb/>attribute when first accessing a file system and when NFS4ERR_MOVED <lb/>is returned, a client can choose to fetch the attribute periodically, <lb/>in which case the value fetched may change over time. <lb/>For clients not prepared to access multiple replicas simultaneously <lb/>(see Section 11.10.1), the handling of the various cases of location <lb/>change are as follows: <lb/>o Changes in the list of replicas or in the network addresses <lb/>associated with replicas do not require immediate action. The <lb/>client will typically update its list of replicas to reflect the <lb/>new information. <lb/>o Additions to the list of network addresses for the current file <lb/>system instance need not be acted on promptly. However, to <lb/>prepare for the case in which a migration event occurs <lb/>subsequently, the client can choose to take note of the new <lb/>address and then use it whenever it needs to switch access to a <lb/>new replica. <lb/>o Deletions from the list of network addresses for the current file <lb/>system instance need not be acted on immediately, although the <lb/>client might need to be prepared for a shift in access whenever <lb/>the server indicates that a network access path is not usable to <lb/>access the current file system, by returning NFS4ERR_MOVED. <lb/>For clients that are prepared to access several replicas <lb/>simultaneously, the following additional cases need to be addressed. <lb/>As in the cases discussed above, changes in the set of replicas need <lb/>not be acted upon promptly, although the client has the option of <lb/>adjusting its access even in the absence of difficulties that would <lb/>lead to a new replica to be selected. <lb/>o When a new replica is added which may be accessed simultaneously <lb/>with one currently in use, the client is free to use the new <lb/>replica immediately. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 241] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o When a replica currently in use is deleted from the list, the <lb/>client need not cease using it immediately. However, since the <lb/>server may subsequently force such use to cease (by returning <lb/>NFS4ERR_MOVED), clients might decide to limit the need for later <lb/>state transfer. For example, new opens might be done on other <lb/>replicas, rather than on one not present in the list. <lb/>11.6. Users and Groups in a Multi-server Namespace <lb/>As in the case of a single-server environment (see Section 5.9, when <lb/>an owner or group name of the form &quot;id@domain&quot; is assigned to a file, <lb/>there is an implcit promise to return that same string when the <lb/>corresponding attribute is interrogated subsequently. In the case of <lb/>a multi-server namespace, that same promise applies even if server <lb/>boundaries have been crossed. Similarly, when the owner attribute of <lb/>a file is derived from the securiy principal which created the file, <lb/>that attribute should have the same value even if the interrogation <lb/>occurs on a different server from the file creation. <lb/>Similarly, the set of security principals recognized by all the <lb/>participating servers needs to be the same, with each such principal <lb/>having the same credentials, regardless of the particular server <lb/>being accessed. <lb/>In order to meet these requirements, those setting up multi-server <lb/>namespaces will need to limit the servers included so that: <lb/>o In all cases in which more than a single domain is supported, the <lb/>requirements stated in RFC8000 [30] are to be respected. <lb/>o All servers support a common set of domains which includes all of <lb/>the domains clients use and expect to see returned as the domain <lb/>portion of an owner or group in the form &quot;id@domain&quot;. Note that <lb/>although this set most ofen consists of a single domain, it is <lb/>possible for mutiple domains to be supported. <lb/>o All servers, for each domain that they support, accept the same <lb/>set of user and group ids as valid. <lb/>o All servers recognize the same set of security principals, and <lb/>each principal, the same credential are required, independent of <lb/>the server being accessed. In addition, the group membership for <lb/>each such prinicipal is to be the same, independent of the server <lb/>accessed. <lb/>Note that there is no requirment that the users corresponding to <lb/>particular security principals have the same local representation on <lb/>each server, even though it is most often the case that this is so. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 242] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>When AUTH_SYS is used, with or without the use of stringified owners <lb/>and groups, the following additional requirements must be met: <lb/>o Only a single NFSv4 domain can be supported. <lb/>o The &quot;local&quot; representation of all owners and groups must be the <lb/>same on all servers. The word &quot;local&quot; is used here since that is <lb/>the way that numeric user and group ids are described in <lb/>Section 5.9. However, when AUTH_SYS or stringified owners or <lb/>group are used, these identifiers are not truly local, since they <lb/>are known tothe clients as well as the server. <lb/>11.7. Additional Client-Side Considerations <lb/>When clients make use of servers that implement referrals, <lb/>replication, and migration, care should be taken that a user who <lb/>mounts a given file system that includes a referral or a relocated <lb/>file system continues to see a coherent picture of that user-side <lb/>file system despite the fact that it contains a number of server-side <lb/>file systems that may be on different servers. <lb/>One important issue is upward navigation from the root of a server-<lb/>side file system to its parent (specified as &quot;..&quot; in UNIX), in the <lb/>case in which it transitions to that file system as a result of <lb/>referral, migration, or a transition as a result of replication. <lb/>When the client is at such a point, and it needs to ascend to the <lb/>parent, it must go back to the parent as seen within the multi-server <lb/>namespace rather than sending a LOOKUPP operation to the server, <lb/>which would result in the parent within that server&apos;s single-server <lb/>namespace. In order to do this, the client needs to remember the <lb/>filehandles that represent such file system roots and use these <lb/>instead of sending a LOOKUPP operation to the current server. This <lb/>will allow the client to present to applications a consistent <lb/>namespace, where upward navigation and downward navigation are <lb/>consistent. <lb/>Another issue concerns refresh of referral locations. When referrals <lb/>are used extensively, they may change as server configurations <lb/>change. It is expected that clients will cache information related <lb/>to traversing referrals so that future client-side requests are <lb/>resolved locally without server communication. This is usually <lb/>rooted in client-side name look up caching. Clients should <lb/>periodically purge this data for referral points in order to detect <lb/>changes in location information. When the change_policy attribute <lb/>changes for directories that hold referral entries or for the <lb/>referral entries themselves, clients should consider any associated <lb/>cached referral information to be out of date. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 243] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>11.8. Overview of File Access Transitions <lb/>File access transitions are of two types: <lb/>o Those that involve a transition from accessing the current replica <lb/>to another one in connection with either replication or migration. <lb/>How these are dealt with is discussed in Section 11.10. <lb/>o Those in which access to the current file system instance is <lb/>retained, while the network path used to access that instance is <lb/>changed. This case is discussed in Section 11.9. <lb/>11.9. Effecting Network Endpoint Transitions <lb/>The endpoints used to access a particular file system instance may <lb/>change in a number of ways, as listed below. In each of these cases, <lb/>the same fsid, filehandles, stateids, client IDs and sessions are <lb/>used to continue access, with a continuity of lock state. <lb/>o When use of a particular address is to cease and there is also one <lb/>currently in use which is server-trunkable with it, requests that <lb/>would have been issued on the address whose use is to be <lb/>discontinued can be issued on the remaining address(es). When an <lb/>address is not a session-trunkable one, the request might need to <lb/>be modified to reflect the fact that a different session will be <lb/>used. <lb/>o When use of a particular connection is to cease, as indicated by <lb/>receiving NFS4ERR_MOVED when using that connection but that <lb/>address is still indicated as accessible according to the <lb/>appropriate file system location entries, it is likely that <lb/>requests can be issued on a new connection of a different <lb/>connection type, once that connection is established. Since any <lb/>two server endpoints that share a network address are inherently <lb/>session-trunkable, the client can use BIND_CONN_TO_SESSION to <lb/>access the existing session using the new connection and proceed <lb/>to access the file system using the new connection. <lb/>o When there are no potential replacement addresses in use but there <lb/>are valid addresses session-trunkable with the one whose use is to <lb/>be discontinued, the client can use BIND_CONN_TO_SESSION to access <lb/>the existing session using the new address. Although the target <lb/>session will generally be accessible, there may be cases in which <lb/>that session is no longer accessible. In this case, the client <lb/>can create a new session to enable continued access to the <lb/>existing instance and provide for use of existing filehandles, <lb/>stateids, and client ids while providing continuity of locking <lb/>state. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 244] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o When there is no potential replacement address in use and there <lb/>are no valid addresses session-trunkable with the one whose use is <lb/>to be discontinued, other server-trunkable addresses may be used <lb/>to provide continued access. Although use of CREATE_SESSION is <lb/>available to provide continued access to the existing instance, <lb/>servers have the option of providing continued access to the <lb/>existing session through the new network access path in a fashion <lb/>similar to that provided by session migration (see Section 11.11). <lb/>To take advantage of this possibility, clients can perform an <lb/>initial BIND_CONN_TO_SESSION, as in the previous case, and use <lb/>CREATE_SESSION only if that fails. <lb/>11.10. Effecting File System Transitions <lb/>There are a range of situations in which there is a change to be <lb/>effected in the set of replicas used to access a particular file <lb/>system. Some of these may involve an expansion or contraction of the <lb/>set of replicas used as discussed in Section 11.10.1 below. <lb/>For reasons explained in that section, most transitions will involve <lb/>a transition from a single replica to a corresponding replacement <lb/>replica. When effecting replica transition, some types of sharing <lb/>between the replicas may affect handling of the transition as <lb/>described in Sections 11.10.2 through 11.10.8 below. The attribute <lb/>fs_locations_info provides helpful information to allow the client to <lb/>determine the degree of inter-replica sharing. <lb/>With regard to some types of state, the degree of continuity across <lb/>the transition depends on the occasion prompting the transition, with <lb/>transitions initiated by the servers (i.e. migration) offering much <lb/>more scope for a non-disruptive transition than cases in which the <lb/>client on its own shifts its access to another replica (i.e. <lb/>replication). This issue potentially applies to locking state and to <lb/>session state, which are dealt with below as follows: <lb/>o An introduction to the possible means of providing continuity in <lb/>these areas appears in Section 11.10.9 below. <lb/>o Transparent State Migration is introduced in Section 11.11. The <lb/>possible transfer of session state is addressed there as well. <lb/>o The client handling of transitions, including determining how to <lb/>deal with the various means that the server might take to supply <lb/>effective continuity of locking state is discussed in <lb/>Section 11.12. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 245] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o The servers&apos; (source and destination) responsibilities in <lb/>effecting Transparent Migration of locking and session state are <lb/>discussed in Section 11.13. <lb/>11.10.1. File System Transitions and Simultaneous Access <lb/>The fs_locations_info attribute (described in Section 11.16) may <lb/>indicate that two replicas may be used simultaneously, (see <lb/>Section 11.7.2.1 of RFC5661 [60] for details). Although situations <lb/>in which multiple replicas may be accessed simultaneously are <lb/>somewhat similar to those in which a single replica is accessed by <lb/>multiple network addresses, there are important differences, since <lb/>locking state is not shared among multiple replicas. <lb/>Because of this difference in state handling, many clients will not <lb/>have the ability to take advantage of the fact that such replicas <lb/>represent the same data. Such clients will not be prepared to use <lb/>multiple replicas simultaneously but will access each file system <lb/>using only a single replica, although the replica selected might make <lb/>multiple server-trunkable addresses available. <lb/>Clients who are prepared to use multiple replicas simultaneously will <lb/>divide opens among replicas however they choose. Once that choice is <lb/>made, any subsequent transitions will treat the set of locking state <lb/>associated with each replica as a single entity. <lb/>For example, if one of the replicas become unavailable, access will <lb/>be transferred to a different replica, also capable of simultaneous <lb/>access with the one still in use. <lb/>When there is no such replica, the transition may be to the replica <lb/>already in use. At this point, the client has a choice between <lb/>merging the locking state for the two replicas under the aegis of the <lb/>sole replica in use or treating these separately, until another <lb/>replica capable of simultaneous access presents itself. <lb/>11.10.2. Filehandles and File System Transitions <lb/>There are a number of ways in which filehandles can be handled across <lb/>a file system transition. These can be divided into two broad <lb/>classes depending upon whether the two file systems across which the <lb/>transition happens share sufficient state to effect some sort of <lb/>continuity of file system handling. <lb/>When there is no such cooperation in filehandle assignment, the two <lb/>file systems are reported as being in different handle classes. In <lb/>this case, all filehandles are assumed to expire as part of the file <lb/>system transition. Note that this behavior does not depend on the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 246] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>fh_expire_type attribute and supersedes the specification of the <lb/>FH4_VOL_MIGRATION bit, which only affects behavior when <lb/>fs_locations_info is not available. <lb/>When there is cooperation in filehandle assignment, the two file <lb/>systems are reported as being in the same handle classes. In this <lb/>case, persistent filehandles remain valid after the file system <lb/>transition, while volatile filehandles (excluding those that are only <lb/>volatile due to the FH4_VOL_MIGRATION bit) are subject to expiration <lb/>on the target server. <lb/>11.10.3. Fileids and File System Transitions <lb/>In NFSv4.0, the issue of continuity of fileids in the event of a file <lb/>system transition was not addressed. The general expectation had <lb/>been that in situations in which the two file system instances are <lb/>created by a single vendor using some sort of file system image copy, <lb/>fileids would be consistent across the transition, while in the <lb/>analogous multi-vendor transitions they would not. This poses <lb/>difficulties, especially for the client without special knowledge of <lb/>the transition mechanisms adopted by the server. Note that although <lb/>fileid is not a REQUIRED attribute, many servers support fileids and <lb/>many clients provide APIs that depend on fileids. <lb/>It is important to note that while clients themselves may have no <lb/>trouble with a fileid changing as a result of a file system <lb/>transition event, applications do typically have access to the fileid <lb/>(e.g., via stat). The result is that an application may work <lb/>perfectly well if there is no file system instance transition or if <lb/>any such transition is among instances created by a single vendor, <lb/>yet be unable to deal with the situation in which a multi-vendor <lb/>transition occurs at the wrong time. <lb/>Providing the same fileids in a multi-vendor (multiple server <lb/>vendors) environment has generally been held to be quite difficult. <lb/>While there is work to be done, it needs to be pointed out that this <lb/>difficulty is partly self-imposed. Servers have typically identified <lb/>fileid with inode number, i.e. with a quantity used to find the file <lb/>in question. This identification poses special difficulties for <lb/>migration of a file system between vendors where assigning the same <lb/>index to a given file may not be possible. Note here that a fileid <lb/>is not required to be useful to find the file in question, only that <lb/>it is unique within the given file system. Servers prepared to <lb/>accept a fileid as a single piece of metadata and store it apart from <lb/>the value used to index the file information can relatively easily <lb/>maintain a fileid value across a migration event, allowing a truly <lb/>transparent migration event. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 247] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>In any case, where servers can provide continuity of fileids, they <lb/>should, and the client should be able to find out that such <lb/>continuity is available and take appropriate action. Information <lb/>about the continuity (or lack thereof) of fileids across a file <lb/>system transition is represented by specifying whether the file <lb/>systems in question are of the same fileid class. <lb/>Note that when consistent fileids do not exist across a transition <lb/>(either because there is no continuity of fileids or because fileid <lb/>is not a supported attribute on one of instances involved), and there <lb/>are no reliable filehandles across a transition event (either because <lb/>there is no filehandle continuity or because the filehandles are <lb/>volatile), the client is in a position where it cannot verify that <lb/>files it was accessing before the transition are the same objects. <lb/>It is forced to assume that no object has been renamed, and, unless <lb/>there are guarantees that provide this (e.g., the file system is <lb/>read-only), problems for applications may occur. Therefore, use of <lb/>such configurations should be limited to situations where the <lb/>problems that this may cause can be tolerated. <lb/>11.10.4. Fsids and File System Transitions <lb/>Since fsids are generally only unique on a per-server basis, it is <lb/>likely that they will change during a file system transition. <lb/>Clients should not make the fsids received from the server visible to <lb/>applications since they may not be globally unique, and because they <lb/>may change during a file system transition event. Applications are <lb/>best served if they are isolated from such transitions to the extent <lb/>possible. <lb/>Although normally a single source file system will transition to a <lb/>single target file system, there is a provision for splitting a <lb/>single source file system into multiple target file systems, by <lb/>specifying the FSLI4F_MULTI_FS flag. <lb/>11.10.4.1. File System Splitting <lb/>When a file system transition is made and the fs_locations_info <lb/>indicates that the file system in question might be split into <lb/>multiple file systems (via the FSLI4F_MULTI_FS flag), the client <lb/>SHOULD do GETATTRs to determine the fsid attribute on all known <lb/>objects within the file system undergoing transition to determine the <lb/>new file system boundaries. <lb/>Clients might choose to maintain the fsids passed to existing <lb/>applications by mapping all of the fsids for the descendant file <lb/>systems to the common fsid used for the original file system. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 248] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Splitting a file system can be done on a transition between file <lb/>systems of the same fileid class, since the fact that fileids are <lb/>unique within the source file system ensure they will be unique in <lb/>each of the target file systems. <lb/>11.10.5. The Change Attribute and File System Transitions <lb/>Since the change attribute is defined as a server-specific one, <lb/>change attributes fetched from one server are normally presumed to be <lb/>invalid on another server. Such a presumption is troublesome since <lb/>it would invalidate all cached change attributes, requiring <lb/>refetching. Even more disruptive, the absence of any assured <lb/>continuity for the change attribute means that even if the same value <lb/>is retrieved on refetch, no conclusions can be drawn as to whether <lb/>the object in question has changed. The identical change attribute <lb/>could be merely an artifact of a modified file with a different <lb/>change attribute construction algorithm, with that new algorithm just <lb/>happening to result in an identical change value. <lb/>When the two file systems have consistent change attribute formats, <lb/>and this fact is communicated to the client by reporting in the same <lb/>change class, the client may assume a continuity of change attribute <lb/>construction and handle this situation just as it would be handled <lb/>without any file system transition. <lb/>11.10.6. Write Verifiers and File System Transitions <lb/>In a file system transition, the two file systems might be clustered <lb/>in the handling of unstably written data. When this is the case, and <lb/>the two file systems belong to the same write-verifier class, write <lb/>verifiers returned from one system may be compared to those returned <lb/>by the other and superfluous writes avoided. <lb/>When two file systems belong to different write-verifier classes, any <lb/>verifier generated by one must not be compared to one provided by the <lb/>other. Instead, the two verifiers should be treated as not equal <lb/>even when the values are identical. <lb/>11.10.7. Readdir Cookies and Verifiers and File System Transitions <lb/>In a file system transition, the two file systems might be consistent <lb/>in their handling of READDIR cookies and verifiers. When this is the <lb/>case, and the two file systems belong to the same readdir class, <lb/>READDIR cookies and verifiers from one system may be recognized by <lb/>the other and READDIR operations started on one server may be validly <lb/>continued on the other, simply by presenting the cookie and verifier <lb/>returned by a READDIR operation done on the first file system to the <lb/>second. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 249] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>When two file systems belong to different readdir classes, any <lb/>READDIR cookie and verifier generated by one is not valid on the <lb/>second, and must not be presented to that server by the client. The <lb/>client should act as if the verifier was rejected. <lb/>11.10.8. File System Data and File System Transitions <lb/>When multiple replicas exist and are used simultaneously or in <lb/>succession by a client, applications using them will normally expect <lb/>that they contain either the same data or data that is consistent <lb/>with the normal sorts of changes that are made by other clients <lb/>updating the data of the file system (with metadata being the same to <lb/>the degree indicated by the fs_locations_info attribute). However, <lb/>when multiple file systems are presented as replicas of one another, <lb/>the precise relationship between the data of one and the data of <lb/>another is not, as a general matter, specified by the NFSv4.1 <lb/>protocol. It is quite possible to present as replicas file systems <lb/>where the data of those file systems is sufficiently different that <lb/>some applications have problems dealing with the transition between <lb/>replicas. The namespace will typically be constructed so that <lb/>applications can choose an appropriate level of support, so that in <lb/>one position in the namespace a varied set of replicas will be <lb/>listed, while in another only those that are up-to-date may be <lb/>considered replicas. The protocol does define three special cases of <lb/>the relationship among replicas to be specified by the server and <lb/>relied upon by clients: <lb/>o When multiple replicas exist and are used simultaneously by a <lb/>client (see the FSLIB4_CLSIMUL definition within <lb/>fs_locations_info), they must designate the same data. Where file <lb/>systems are writable, a change made on one instance must be <lb/>visible on all instances, immediately upon the earlier of the <lb/>return of the modifying requester or the visibility of that change <lb/>on any of the associated replicas. This allows a client to use <lb/>these replicas simultaneously without any special adaptation to <lb/>the fact that there are multiple replicas, beyond adapting to the <lb/>fact that locks obtained on one replica are maintained separately <lb/>(i.e. under a different client ID). In this case, locks (whether <lb/>share reservations or byte-range locks) and delegations obtained <lb/>on one replica are immediately reflected on all replicas, in the <lb/>sense that access from all other servers is prevented regardless <lb/>of the replica used. However, because the servers are not <lb/>required to treat two associated client IDs as representing the <lb/>same client, it is best to access each file using only a single <lb/>client ID. <lb/>o When one replica is designated as the successor instance to <lb/>another existing instance after return NFS4ERR_MOVED (i.e., the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 250] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>case of migration), the client may depend on the fact that all <lb/>changes written to stable storage on the original instance are <lb/>written to stable storage of the successor (uncommitted writes are <lb/>dealt with in Section 11.10.6 above). <lb/>o Where a file system is not writable but represents a read-only <lb/>copy (possibly periodically updated) of a writable file system, <lb/>clients have similar requirements with regard to the propagation <lb/>of updates. They may need a guarantee that any change visible on <lb/>the original file system instance must be immediately visible on <lb/>any replica before the client transitions access to that replica, <lb/>in order to avoid any possibility that a client, in effecting a <lb/>transition to a replica, will see any reversion in file system <lb/>state. The specific means of this guarantee varies based on the <lb/>value of the fss_type field that is reported as part of the <lb/>fs_status attribute (see Section 11.17). Since these file systems <lb/>are presumed to be unsuitable for simultaneous use, there is no <lb/>specification of how locking is handled; in general, locks <lb/>obtained on one file system will be separate from those on others. <lb/>Since these are expected to be read-only file systems, this is not <lb/>likely to pose an issue for clients or applications. <lb/>11.10.9. Lock State and File System Transitions <lb/>While accessing a file system, clients obtain locks enforced by the <lb/>server which may prevent actions by other clients that are <lb/>inconsistent with those locks. <lb/>When access is transferred between replicas, clients need to be <lb/>assured that the actions disallowed by holding these locks cannot <lb/>have occurred during the transition. This can be ensured by the <lb/>methods below. Unless at least one of these is implemented, clients <lb/>will not be assured of continuity of lock possession across a <lb/>migration event. <lb/>o Providing the client an opportunity to re-obtain his locks via a <lb/>per-fs grace period on the destination server. Because the lock <lb/>reclaim mechanism was originally defined to support server reboot, <lb/>it implicitly assumes that file handles will on reclaim will be <lb/>the same as those at open. In the case of migration, this <lb/>requires that source and destination servers use the same <lb/>filehandles, as evidenced by using the same server scope (see <lb/>Section 2.10.4) or by showing this agreement using <lb/>fs_locations_info (see Section 11.10.2 above). <lb/>o Locking state can be transferred as part of the transition by <lb/>providing Transparent State Migration as described in <lb/>Section 11.11. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 251] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Of these, Transparent State Migration provides the smoother <lb/>experience for clients in that there is no grace-period-based delay <lb/>before new locks can be obtained. However, it requires a greater <lb/>degree of inter-server co-ordination. In general, the servers taking <lb/>part in migration are free to provide either facility. However, when <lb/>the filehandles can differ across the migration event, Transparent <lb/>State Migration is the only available means of providing the needed <lb/>functionality. <lb/>It should be noted that these two methods are not mutually exclusive <lb/>and that a server might well provide both. In particular, if there <lb/>is some circumstance preventing a specific lock from being <lb/>transferred transparently, the destination server can allow it to be <lb/>reclaimed, by implementing a per-fs grace period for the migrated <lb/>file system. <lb/>11.10.9.1. Leases and File System Transitions <lb/>In the case of lease renewal, the client may not be submitting <lb/>requests for a file system that has been transferred to another <lb/>server. This can occur because of the lease renewal mechanism. The <lb/>client renews the lease associated with all file systems when <lb/>submitting a request on an associated session, regardless of the <lb/>specific file system being referenced. <lb/>In order for the client to schedule renewal of its lease where there <lb/>is locking state that may have been relocated to the new server, the <lb/>client must find out about lease relocation before that lease expire. <lb/>To accomplish this, the SEQUENCE operation will return the status bit <lb/>SEQ4_STATUS_LEASE_MOVED if responsibility for any of the renewed <lb/>locking state has been transferred to a new server. This will <lb/>continue until the client receives an NFS4ERR_MOVED error for each of <lb/>the file systems for which there has been locking state relocation. <lb/>When a client receives an SEQ4_STATUS_LEASE_MOVED indication from a <lb/>server, for each file system of the server for which the client has <lb/>locking state, the client should perform an operation. For <lb/>simplicity, the client may choose to reference all file systems, but <lb/>what is important is that it must reference all file systems for <lb/>which there was locking state where that state has moved. Once the <lb/>client receives an NFS4ERR_MOVED error for each such file system, the <lb/>server will clear the SEQ4_STATUS_LEASE_MOVED indication. The client <lb/>can terminate the process of checking file systems once this <lb/>indication is cleared (but only if the client has received a reply <lb/>for all outstanding SEQUENCE requests on all sessions it has with the <lb/>server), since there are no others for which locking state has moved. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 252] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>A client may use GETATTR of the fs_status (or fs_locations_info) <lb/>attribute on all of the file systems to get absence indications in a <lb/>single (or a few) request(s), since absent file systems will not <lb/>cause an error in this context. However, it still must do an <lb/>operation that receives NFS4ERR_MOVED on each file system, in order <lb/>to clear the SEQ4_STATUS_LEASE_MOVED indication. <lb/>Once the set of file systems with transferred locking state has been <lb/>determined, the client can follow the normal process to obtain the <lb/>new server information (through the fs_locations and <lb/>fs_locations_info attributes) and perform renewal of that lease on <lb/>the new server, unless information in the fs_locations_info attribute <lb/>shows that no state could have been transferred. If the server has <lb/>not had state transferred to it transparently, the client will <lb/>receive NFS4ERR_STALE_CLIENTID from the new server, as described <lb/>above, and the client can then reclaim locks as is done in the event <lb/>of server failure. <lb/>11.10.9.2. Transitions and the Lease_time Attribute <lb/>In order that the client may appropriately manage its lease in the <lb/>case of a file system transition, the destination server must <lb/>establish proper values for the lease_time attribute. <lb/>When state is transferred transparently, that state should include <lb/>the correct value of the lease_time attribute. The lease_time <lb/>attribute on the destination server must never be less than that on <lb/>the source, since this would result in premature expiration of a <lb/>lease granted by the source server. Upon transitions in which state <lb/>is transferred transparently, the client is under no obligation to <lb/>refetch the lease_time attribute and may continue to use the value <lb/>previously fetched (on the source server). <lb/>If state has not been transferred transparently, either because the <lb/>associated servers are shown as having different eir_server_scope <lb/>strings or because the client ID is rejected when presented to the <lb/>new server, the client should fetch the value of lease_time on the <lb/>new (i.e., destination) server, and use it for subsequent locking <lb/>requests. However, the server must respect a grace period of at <lb/>least as long as the lease_time on the source server, in order to <lb/>ensure that clients have ample time to reclaim their lock before <lb/>potentially conflicting non-reclaimed locks are granted. <lb/>11.11. Transferring State upon Migration <lb/>When the transition is a result of a server-initiated decision to <lb/>transition access and the source and destination servers have <lb/>implemented appropriate co-operation, it is possible to: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 253] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o Transfer locking state from the source to the destination server, <lb/>in a fashion similar to that provided by Transparent State <lb/>Migration in NFSv4.0, as described in [63]. Server <lb/>responsibilities are described in Section 11.13.2. <lb/>o Transfer session state from the source to the destination server. <lb/>Server responsibilities in effecting such a transfer are described <lb/>in Section 11.13.3. <lb/>The means by which the client determines which of these transfer <lb/>events has occurred are described in Section 11.12. <lb/>11.11.1. Transparent State Migration and pNFS <lb/>When pNFS is involved, the protocol is capable of supporting: <lb/>o Migration of the Metadata Server (MDS), leaving the Data Servers <lb/>(DS&apos;s) in place. <lb/>o Migration of the file system as a whole, including the MDS and <lb/>associated DS&apos;s. <lb/>o Replacement of one DS by another. <lb/>o Migration of a pNFS file system to one in which pNFS is not used. <lb/>o Migration of a file system not using pNFS to one in which layouts <lb/>are available. <lb/>Note that migration per se is only involved in the transfer of the <lb/>MDS function. Although the servicing of a layout may be transferred <lb/>from one data server to another, this not done using the file system <lb/>location attributes. The MDS can effect such transfers by recalling/ <lb/>revoking existing layouts and granting new ones on a different data <lb/>server. <lb/>Migration of the MDS function is directly supported by Transparent <lb/>State Migration. Layout state will normally be transparently <lb/>transferred, just as other state is. As a result, Transparent State <lb/>Migration provides a framework in which, given appropriate inter-MDS <lb/>data transfer, one MDS can be substituted for another. <lb/>Migration of the file system function as a whole can be accomplished <lb/>by recalling all layouts as part of the initial phase of the <lb/>migration process. As a result, IO will be done through the MDS <lb/>during the migration process, and new layouts can be granted once the <lb/>client is interacting with the new MDS. An MDS can also effect this <lb/>sort of transition by revoking all layouts as part of Transparent <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 254] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>State Migration, as long as the client is notified about the loss of <lb/>locking state. <lb/>In order to allow migration to a file system on which pNFS is not <lb/>supported, clients need to be prepared for a situation in which <lb/>layouts are not available or supported on the destination file system <lb/>and so direct IO requests to the destination server, rather than <lb/>depending on layouts being available. <lb/>Replacement of one DS by another is not addressed by migration as <lb/>such but can be effected by an MDS recalling layouts for the DS to be <lb/>replaced and issuing new ones to be served by the successor DS. <lb/>Migration may transfer a file system from a server which does not <lb/>support pNFS to one which does. In order to properly adapt to this <lb/>situation, clients which support pNFS, but function adequately in its <lb/>absence should check for pNFS support when a file system is migrated <lb/>and be prepared to use pNFS when support is available on the <lb/>destination. <lb/>11.12. Client Responsibilities when Access is Transitioned <lb/>For a client to respond to an access transition, it must become aware <lb/>of it. The ways in which this can happen are discussed in <lb/>Section 11.12.1 which discusses indications that a specific file <lb/>system access path has transitioned as well as situations in which <lb/>additional activity is necessary to determine the set of file systems <lb/>that have been migrated. Section 11.12.2 goes on to complete the <lb/>discussion of how the set of migrated file systems might be <lb/>determined. Sections 11.12.3 through 11.12.5 discuss how the client <lb/>should deal with each transition it becomes aware of, either directly <lb/>or as a result of migration discovery. <lb/>The following terms are used to describe client activities: <lb/>o &quot;Transition recovery&quot; refers to the process of restoring access to <lb/>a file system on which NFS4ERR_MOVED was received. <lb/>o &quot;Migration recovery&quot; to that subset of transition recovery which <lb/>applies when the file system has migrated to a different replica. <lb/>o &quot;Migration discovery&quot; refers to the process of determining which <lb/>file system(s) have been migrated. It is necessary to avoid a <lb/>situation in which leases could expire when a file system is not <lb/>accessed for a long period of time, since a client unaware of the <lb/>migration might be referencing an unmigrated file system and not <lb/>renewing the lease associated with the migrated file system. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 255] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>11.12.1. Client Transition Notifications <lb/>When there is a change in the network access path which a client is <lb/>to use to access a file system, there are a number of related status <lb/>indications with which clients need to deal: <lb/>o If an attempt is made to use or return a filehandle within a file <lb/>system that is no longer accessible at the address previously used <lb/>to access it, the error NFS4ERR_MOVED is returned. <lb/>Exceptions are made to allow such file handles to be used when <lb/>interrogating a file system location attribute. This enables a <lb/>client to determine a new replica&apos;s location or a new network <lb/>access path. <lb/>This condition continues on subsequent attempts to access the file <lb/>system in question. The only way the client can avoid the error <lb/>is to cease accessing the file system in question at its old <lb/>server location and access it instead using a different address at <lb/>which it is now available. <lb/>o Whenever a SEQUENCE operation is sent by a client to a server <lb/>which generated state held on that client which is associated with <lb/>a file system that is no longer accessible on the server at which <lb/>it was previously available, the response will contain a lease-<lb/>migrated indication, with the SEQ4_STATUS_LEASE_MOVED status bit <lb/>being set. <lb/>This condition continues until the client acknowledges the <lb/>notification by fetching a file system location attribute for the <lb/>file system whose network access path is being changed. When <lb/>there are multiple such file systems, a location attribute for <lb/>each such file system needs to be fetched. The location attribute <lb/>for all migrated file system needs to be fetched in order to clear <lb/>the condition. Even after the condition is cleared, the client <lb/>needs to respond by using the location information to access the <lb/>file system at its new location to ensure that leases are not <lb/>needlessly expired. <lb/>Unlike the case of NFSv4.0, in which the corresponding conditions are <lb/>both errors and thus mutually exclusive, in NFSv4.1 the client can, <lb/>and often will, receive both indications on the same request. As a <lb/>result, implementations need to address the question of how to co-<lb/>ordinate the necessary recovery actions when both indications arrive <lb/>in the response to the same request. It should be noted that when <lb/>processing an NFSv4 COMPOUND, the server will normally decide whether <lb/>SEQ4_STATUS_LEASE_MOVED is to be set before it determines which file <lb/>system will be referenced or whether NFS4ERR_MOVED is to be returned. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 256] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Since these indications are not mutually exclusive in NFSv4.1, the <lb/>following combinations are possible results when a COMPOUND is <lb/>issued: <lb/>o The COMPOUND status is NFS4ERR_MOVED and SEQ4_STATUS_LEASE_MOVED <lb/>is asserted. <lb/>In this case, transition recovery is required. While it is <lb/>possible that migration discovery is needed in addition, it is <lb/>likely that only the accessed file system has transitioned. In <lb/>any case, because addressing NFS4ERR_MOVED is necessary to allow <lb/>the rejected requests to be processed on the target, dealing with <lb/>it will typically have priority over migration discovery. <lb/>o The COMPOUND status is NFS4ERR_MOVED and SEQ4_STATUS_LEASE_MOVED <lb/>is clear. <lb/>In this case, transition recovery is also required. It is clear <lb/>that migration discovery is not needed to find file systems that <lb/>have been migrated other that the one returning NFS4ERR_MOVED. <lb/>Cases in which this result can arise include a referral or a <lb/>migration for which there is no associated locking state. This <lb/>can also arise in cases in which an access path transition other <lb/>than migration occurs within the same server. In such a case, <lb/>there is no need to set SEQ4_STATUS_LEASE_MOVED, since the lease <lb/>remains associated with the current server even though the access <lb/>path has changed. <lb/>o The COMPOUND status is not NFS4ERR_MOVED and <lb/>SEQ4_STATUS_LEASE_MOVED is asserted. <lb/>In this case, no transition recovery activity is required on the <lb/>file system(s) accessed by the request. However, to prevent <lb/>avoidable lease expiration, migration discovery needs to be done <lb/>o The COMPOUND status is not NFS4ERR_MOVED and <lb/>SEQ4_STATUS_LEASE_MOVED is clear. <lb/>In this case, neither transition-related activity nor migration <lb/>discovery is required. <lb/>Note that the specified actions only need to be taken if they are not <lb/>already going on. For example, when NFS4ERR_MOVED is received when <lb/>accessing a file system for which transition recovery already going <lb/>on, the client merely waits for that recovery to be completed while <lb/>the receipt of SEQ4_STATUS_LEASE_MOVED indication only needs to <lb/>initiate migration discovery for a server if such discovery is not <lb/>already underway for that server. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 257] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The fact that a lease-migrated condition does not result in an error <lb/>in NFSv4.1 has a number of important consequences. In addition to <lb/>the fact, discussed above, that the two indications are not mutually <lb/>exclusive, there are number of issues that are important in <lb/>considering implementation of migration discovery, as discussed in <lb/>Section 11.12.2. <lb/>Because of the absence of NFSV4ERR_LEASE_MOVED, it is possible for <lb/>file systems whose access path has not changed to be successfully <lb/>accessed on a given server even though recovery is necessary for <lb/>other file systems on the same server. As a result, access can go on <lb/>while, <lb/>o The migration discovery process is going on for that server. <lb/>o The transition recovery process is going on for on other file <lb/>systems connected to that server. <lb/>11.12.2. Performing Migration Discovery <lb/>Migration discovery can be performed in the same context as <lb/>transition recovery, allowing recovery for each migrated file system <lb/>to be invoked as it is discovered. Alternatively, it may be done in <lb/>a separate migration discovery thread, allowing migration discovery <lb/>to be done in parallel with one or more instances of transition <lb/>recovery. <lb/>In either case, because the lease-migrated indication does not result <lb/>in an error. other access to file systems on the server can proceed <lb/>normally, with the possibility that further such indications will be <lb/>received, raising the issue of how such indications are to be dealt <lb/>with. In general, <lb/>o No action needs to be taken for such indications received by the <lb/>those performing migration discovery, since continuation of that <lb/>work will address the issue. <lb/>o In other cases in which migration discovery is currently being <lb/>performed, nothing further needs to be done to respond to such <lb/>lease migration indications, as long as one can be certain that <lb/>the migration discovery process would deal with those indications. <lb/>See below for details. <lb/>o For such indications received in all other contexts, the <lb/>appropriate response is to initiate or otherwise provide for the <lb/>execution of migration discovery for file systems associated with <lb/>the server IP address returning the indication. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 258] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>This leaves a potential difficulty in situations in which the <lb/>migration discovery process is near to completion but is still <lb/>operating. One should not ignore a LEASE_MOVED indication if the <lb/>migration discovery process is not able to respond to the discovery <lb/>of additional migrating file systems without additional aid. A <lb/>further complexity relevant in addressing such situations is that a <lb/>lease-migrated indication may reflect the server&apos;s state at the time <lb/>the SEQUENCE operation was processed, which may be different from <lb/>that in effect at the time the response is received. Because new <lb/>migration events may occur at any time, and because a LEASE_MOVED <lb/>indication may reflect the situation in effect a considerable time <lb/>before the indication is received, special care needs to be taken to <lb/>ensure that LEASE_MOVED indications are not inappropriately ignored. <lb/>A useful approach to this issue involves the use of separate <lb/>externally-visible migration discovery states for each server. <lb/>Separate values could represent the various possible states for the <lb/>migration discovery process for a server: <lb/>o non-operation, in which migration discovery is not being performed <lb/>o normal operation, in which there is an ongoing scan for migrated <lb/>file systems. <lb/>o completion/verification of migration discovery processing, in <lb/>which the possible completion of migration discovery processing <lb/>needs to be verified. <lb/>Given that framework, migration discovery processing would proceed as <lb/>follows. <lb/>o While in the normal-operation state, the thread performing <lb/>discovery would fetch, for successive file systems known to the <lb/>client on the server being worked on, a file system location <lb/>attribute plus the fs_status attribute. <lb/>o If the fs_status attribute indicates that the file system is a <lb/>migrated one (i.e. fss_absent is true and fss_type != <lb/>STATUS4_REFERRAL) and thus that it is likely that the fetch of the <lb/>file system location attribute has cleared one the file systems <lb/>contributing to the lease-migrated indication. <lb/>o In cases in which that happened, the thread cannot know whether <lb/>the lease-migrated indication has been cleared and so it enters <lb/>the completion/verification state and proceeds to issue a COMPOUND <lb/>to see if the LEASE_MOVED indication has been cleared. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 259] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o When the discovery process is in the completion/verification <lb/>state, if other requests get a lease-migrated indication they note <lb/>that it was received. Laater, the existence of such indications <lb/>is used when the request completes, as described below. <lb/>When the request used in the completion/verification state completes: <lb/>o If a lease-migrated indication is returned, the discovery <lb/>continues normally. Note that this is so even if all file systems <lb/>have traversed, since new migrations could have occurred while the <lb/>process was going on. <lb/>o Otherwise, if there is any record that other requests saw a lease-<lb/>migrated indication while the request was going on, that record is <lb/>cleared and the verification request retried. The discovery <lb/>process remains in completion/verification state. <lb/>o If there have been no lease-migrated indications, the work of <lb/>migration discovery is considered completed and it enters the non-<lb/>operating state. Once it enters this state, subsequent lease-<lb/>migrated indication will trigger a new migration discovery <lb/>process. <lb/>It should be noted that the process described above is not guaranteed <lb/>to terminate, as a long series of new migration events might <lb/>continually delay the clearing of the LEASE_MOVED indication. To <lb/>prevent unnecessary lease expiration, it is appropriate for clients <lb/>to use the discovery of migrations to effect lease renewal <lb/>immediately, rather than waiting for clearing of the LEASE_MOVED <lb/>indication when the complete set of migrations is available. <lb/>11.12.3. Overview of Client Response to NFS4ERR_MOVED <lb/>This section outlines a way in which a client that receives <lb/>NFS4ERR_MOVED can effect transition recovery by using a new server or <lb/>server endpoint if one is available. As part of that process, it <lb/>will determine: <lb/>o Whether the NFS4ERR_MOVED indicates migration has occurred, or <lb/>whether it indicates another sort of file system access transition <lb/>as discussed in Section 11.9 above. <lb/>o In the case of migration, whether Transparent State Migration has <lb/>occurred. <lb/>o Whether any state has been lost during the process of Transparent <lb/>State Migration. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 260] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o Whether sessions have been transferred as part of Transparent <lb/>State Migration. <lb/>During the first phase of this process, the client proceeds to <lb/>examine file system location entries to find the initial network <lb/>address it will use to continue access to the file system or its <lb/>replacement. For each location entry that the client examines, the <lb/>process consists of five steps: <lb/>1. Performing an EXCHANGE_ID directed at the location address. This <lb/>operation is used to register the client owner (in the form of a <lb/>client_owner4) with the server, to obtain a client ID to be use <lb/>subsequently to communicate with it, to obtain that client ID&apos;s <lb/>confirmation status, and to determine server_owner and scope for <lb/>the purpose of determining if the entry is trunkable with that <lb/>previously being used to access the file system (i.e. that it <lb/>represents another network access path to the same file system <lb/>and can share locking state with it). <lb/>2. Making an initial determination of whether migration has <lb/>occurred. The initial determination will be based on whether the <lb/>EXCHANGE_ID results indicate that the current location element is <lb/>server-trunkable with that used to access the file system when <lb/>access was terminated by receiving NFS4ERR_MOVED. If it is, then <lb/>migration has not occurred. In that case, the transition is <lb/>dealt with, at least initially, as one involving continued access <lb/>to the same file system on the same server through a new network <lb/>address. <lb/>3. Obtaining access to existing session state or creating new <lb/>sessions. How this is done depends on the initial determination <lb/>of whether migration has occurred and can be done as described in <lb/>Section 11.12.4 below in the case of migration or as described in <lb/>Section 11.12.5 below in the case of a network address transfer <lb/>without migration. <lb/>4. Verification of the trunking relationship assumed in step 2 as <lb/>discussed in Section 2.10.5.1. Although this step will generally <lb/>confirm the initial determination, it is possible for <lb/>verification to fail with the result that an initial <lb/>determination that a network address shift (without migration) <lb/>has occurred may be invalidated and migration determined to have <lb/>occurred. There is no need to redo step 3 above, since it will <lb/>be possible to continue use of the session established already. <lb/>5. Obtaining access to existing locking state and/or reobtaining it. <lb/>How this is done depends on the final determination of whether <lb/>migration has occurred and can be done as described below in <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 261] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Section 11.12.4 in the case of migration or as described in <lb/>Section 11.12.5 in the case of a network address transfer without <lb/>migration. <lb/>Once the initial address has been determined, clients are free to <lb/>apply an abbreviated process to find additional addresses trunkable <lb/>with it (clients may seek session-trunkable or server-trunkable <lb/>addresses depending on whether they support clientid trunking). <lb/>During this later phase of the process, further location entries are <lb/>examined using the abbreviated procedure specified below: <lb/>A: Before the EXCHANGE_ID, the fs name of the location entry is <lb/>examined and if it does not match that currently being used, the <lb/>entry is ignored. otherwise, one proceeds as specified by step 1 <lb/>above. <lb/>B: In the case that the network address is session-trunkable with <lb/>one used previously a BIND_CONN_TO_SESSION is used to access that <lb/>session using the new network address. Otherwise, or if the bind <lb/>operation fails, a CREATE_SESSION is done. <lb/>C: The verification procedure referred to in step 4 above is used. <lb/>However, if it fails, the entry is ignored and the next available <lb/>entry is used. <lb/>11.12.4. Obtaining Access to Sessions and State after Migration <lb/>In the event that migration has occurred, migration recovery will <lb/>involve determining whether Transparent State Migration has occurred. <lb/>This decision is made based on the client ID returned by the <lb/>EXCHANGE_ID and the reported confirmation status. <lb/>o If the client ID is an unconfirmed client ID not previously known <lb/>to the client, then Transparent State Migration has not occurred. <lb/>o If the client ID is a confirmed client ID previously known to the <lb/>client, then any transferred state would have been merged with an <lb/>existing client ID representing the client to the destination <lb/>server. In this state merger case, Transparent State Migration <lb/>might or might not have occurred and a determination as to whether <lb/>it has occurred is deferred until sessions are established and the <lb/>client is ready to begin state recovery. <lb/>o If the client ID is a confirmed client ID not previously known to <lb/>the client, then the client can conclude that the client ID was <lb/>transferred as part of Transparent State Migration. In this <lb/>transferred client ID case, Transparent State Migration has <lb/>occurred although some state might have been lost. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 262] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Once the client ID has been obtained, it is necessary to obtain <lb/>access to sessions to continue communication with the new server. In <lb/>any of the cases in which Transparent State Migration has occurred, <lb/>it is possible that a session was transferred as well. To deal with <lb/>that possibility, clients can, after doing the EXCHANGE_ID, issue a <lb/>BIND_CONN_TO_SESSION to connect the transferred session to a <lb/>connection to the new server. If that fails, it is an indication <lb/>that the session was not transferred and that a new session needs to <lb/>be created to take its place. <lb/>In some situations, it is possible for a BIND_CONN_TO_SESSION to <lb/>succeed without session migration having occurred. If state merger <lb/>has taken place then the associated client ID may have already had a <lb/>set of existing sessions, with it being possible that the sessionid <lb/>of a given session is the same as one that might have been migrated. <lb/>In that event, a BIND_CONN_TO_SESSION might succeed, even though <lb/>there could have been no migration of the session with that <lb/>sessionid. In such cases, the client will receive sequence errors <lb/>when the slot sequence values used are not appropriate on the new <lb/>session. When this occurs, the client can create a new a session and <lb/>cease using the existing one. <lb/>Once the client has determined the initial migration status, and <lb/>determined that there was a shift to a new server, it needs to re-<lb/>establish its locking state, if possible. To enable this to happen <lb/>without loss of the guarantees normally provided by locking, the <lb/>destination server needs to implement a per-fs grace period in all <lb/>cases in which lock state was lost, including those in which <lb/>Transparent State Migration was not implemented. <lb/>Clients need to deal with the following cases: <lb/>o In the state merger case, it is possible that the server has not <lb/>attempted Transparent State Migration, in which case state may <lb/>have been lost without it being reflected in the SEQ4_STATUS bits. <lb/>To determine whether this has happened, the client can use <lb/>TEST_STATEID to check whether the stateids created on the source <lb/>server are still accessible on the destination server. Once a <lb/>single stateid is found to have been successfully transferred, the <lb/>client can conclude that Transparent State Migration was begun and <lb/>any failure to transport all of the stateids will be reflected in <lb/>the SEQ4_STATUS bits. Otherwise, Transparent State Migration has <lb/>not occurred. <lb/>o In a case in which Transparent State Migration has not occurred, <lb/>the client can use the per-fs grace period provided by the <lb/>destination server to reclaim locks that were held on the source <lb/>server. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 263] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o In a case in which Transparent State Migration has occurred, and <lb/>no lock state was lost (as shown by SEQ4_STATUS flags), no lock <lb/>reclaim is necessary. <lb/>o In a case in which Transparent State Migration has occurred, and <lb/>some lock state was lost (as shown by SEQ4_STATUS flags), existing <lb/>stateids need to be checked for validity using TEST_STATEID, and <lb/>reclaim used to re-establish any that were not transferred. <lb/>For all of the cases above, RECLAIM_COMPLETE with an rca_one_fs value <lb/>of TRUE needs to be done before normal use of the file system <lb/>including obtaining new locks for the file system. This applies even <lb/>if no locks were lost and there was no need for any to be reclaimed. <lb/>11.12.5. Obtaining Access to Sessions and State after Network Address <lb/>Transfer <lb/>The case in which there is a transfer to a new network address <lb/>without migration is similar to that described in Section 11.12.4 <lb/>above in that there is a need to obtain access to needed sessions and <lb/>locking state. However, the details are simpler and will vary <lb/>depending on the type of trunking between the address receiving <lb/>NFS4ERR_MOVED and that to which the transfer is to be made <lb/>To make a session available for use, a BIND_CONN_TO_SESSION should be <lb/>used to obtain access to the session previously in use. Only if this <lb/>fails, should a CREATE_SESSION be done. While this procedure mirrors <lb/>that in Section 11.12.4 above, there is an important difference in <lb/>that preservation of the session is not purely optional but depends <lb/>on the type of trunking. <lb/>Access to appropriate locking state will generally need no actions <lb/>beyond access to the session. However, the SEQ4_STATUS bits need to <lb/>be checked for lost locking state, including the need to reclaim <lb/>locks after a server reboot, since there is always a possibility of <lb/>locking state being lost. <lb/>11.13. Server Responsibilities Upon Migration <lb/>In the event of file system migration, when the client connects to <lb/>the destination server, that server needs to be able to provide the <lb/>client continued to access the files it had open on the source <lb/>server. There are two ways to provide this: <lb/>o By provision of an fs-specific grace period, allowing the client <lb/>the ability to reclaim its locks, in a fashion similar to what <lb/>would have been done in the case of recovery from a server <lb/>restart. See Section 11.13.1 for a more complete discussion. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 264] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o By implementing Transparent State Migration possibly in connection <lb/>with session migration, the server can provide the client <lb/>immediate access to the state built up on the source server, on <lb/>the destination. <lb/>These features are discussed separately in Sections 11.13.2 and <lb/>11.13.3, which discuss Transparent State Migration and session <lb/>migration respectively. <lb/>All the features described above can involve transfer of lock-related <lb/>information between source and destination servers. In some cases, <lb/>this transfer is a necessary part of the implementation while in <lb/>other cases it is a helpful implementation aid which servers might or <lb/>might not use. The sub-sections below discuss the information which <lb/>would be transferred but do not define the specifics of the transfer <lb/>protocol. This is left as an implementation choice although <lb/>standards in this area could be developed at a later time. <lb/>11.13.1. Server Responsibilities in Effecting State Reclaim after <lb/>Migration <lb/>In this case, destination server need have no knowledge of the locks <lb/>held on the source server, but relies on the clients to accurately <lb/>report (via reclaim operations) the locks previously held, not <lb/>allowing new locks to be granted on migrated file system until the <lb/>grace period expires. <lb/>During this grace period clients have the opportunity to use reclaim <lb/>operations to obtain locks for file system objects within the <lb/>migrated file system, in the same way that they do when recovering <lb/>from server restart, and the servers typically rely on clients to <lb/>accurately report their locks, although they have the option of <lb/>subjecting these requests to verification. If the clients only <lb/>reclaim locks held on the source server, no conflict can arise. Once <lb/>the client has reclaimed its locks, it indicates the completion of <lb/>lock reclamation by performing a RECLAIM_COMPLETE specifying <lb/>rca_one_fs as TRUE. <lb/>While it is not necessary for source and destination servers to co-<lb/>operate to transfer information about locks, implementations are <lb/>well-advised to consider transferring the following useful <lb/>information: <lb/>o If information about the set of clients that have locking state <lb/>for the transferred file system is made available, the destination <lb/>server will be able to terminate the grace period once all such <lb/>clients have reclaimed their locks, allowing normal locking <lb/>activity to resume earlier than it would have otherwise. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 265] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o Locking summary information for individual clients (at various <lb/>possible levels of detail) can detect some instances in which <lb/>clients do not accurately represent the locks held on the source <lb/>server. <lb/>11.13.2. Server Responsibilities in Effecting Transparent State <lb/>Migration <lb/>The basic responsibility of the source server in effecting <lb/>Transparent State Migration is to make available to the destination <lb/>server a description of each piece of locking state associated with <lb/>the file system being migrated. In addition to client id string and <lb/>verifier, the source server needs to provide, for each stateid: <lb/>o The stateid including the current sequence value. <lb/>o The associated client ID. <lb/>o The handle of the associated file. <lb/>o The type of the lock, such as open, byte-range lock, delegation, <lb/>or layout. <lb/>o For locks such as opens and byte-range locks, there will be <lb/>information about the owner(s) of the lock. <lb/>o For recallable/revocable lock types, the current recall status <lb/>needs to be included. <lb/>o For each lock type, there will be type-specific information, such <lb/>as share and deny modes for opens and type and byte ranges for <lb/>byte-range locks and layouts. <lb/>Such information will most probably be organized by client id string <lb/>on the destination server so that it can be used to provide <lb/>appropriate context to each client when it makes itself known to the <lb/>client. Issues connected with a client impersonating another by <lb/>presenting another client&apos;s id string are discussed in Section 21. <lb/>A further server responsibility concerns locks that are revoked or <lb/>otherwise lost during the process of file system migration. Because <lb/>locks that appear to be lost during the process of migration will be <lb/>reclaimed by the client, the servers have to take steps to ensure <lb/>that locks revoked soon before or soon after migration are not <lb/>inadvertently allowed to be reclaimed in situations in which the <lb/>continuity of lock possession cannot be assured. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 266] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o For locks lost on the source but whose loss has not yet been <lb/>acknowledged by the client (by using FREE_STATEID), the <lb/>destination must be aware of this loss so that it can deny a <lb/>request to reclaim them. <lb/>o For locks lost on the destination after the state transfer but <lb/>before the client&apos;s RECLAIM_COMPLTE is done, the destination <lb/>server should note these and not allow them to be reclaimed. <lb/>An additional responsibility of the cooperating servers concerns <lb/>situations in which a stateid cannot be transferred transparently <lb/>because it conflicts with an existing stateid held by the client and <lb/>associated with a different file system. In this case there are two <lb/>valid choices: <lb/>o Treat the transfer, as in NFSv4.0, as one without Transparent <lb/>State Migration. In this case, conflicting locks cannot be <lb/>granted until the client does a RECLAIM_COMPLETE, after reclaiming <lb/>the locks it had, with the exception of reclaims denied because <lb/>they were attempts to reclaim locks that had been lost. <lb/>o Implement Transparent State Migration, except for the lock with <lb/>the conflicting stateid. In this case, the client will be aware <lb/>of a lost lock (through the SEQ4_STATUS flags) and be allowed to <lb/>reclaim it. <lb/>When transferring state between the source and destination, the <lb/>issues discussed in Section 7.2 of [63] must still be attended to. <lb/>In this case, the use of NFS4ERR_DELAY may still necessary in <lb/>NFSv4.1, as it was in NFSv4.0, to prevent locking state changing <lb/>while it is being transferred. <lb/>There are a number of important differences in the NFS4.1 context: <lb/>o The absence of RELEASE_LOCKOWNER means that the one case in which <lb/>an operation could not be deferred by use of NFS4ERR_DELAY no <lb/>longer exists. <lb/>o Sequencing of operations is no longer done using owner-based <lb/>operation sequences numbers. Instead, sequencing is session-<lb/>based <lb/>As a result, when sessions are not transferred, the techniques <lb/>discussed in Section 7.2 of [63] are adequate and will not be further <lb/>discussed. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 267] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>11.13.3. Server Responsibilities in Effecting Session Transfer <lb/>The basic responsibility of the source server in effecting session <lb/>transfer is to make available to the destination server a description <lb/>of the current state of each slot with the session, including: <lb/>o The last sequence value received for that slot. <lb/>o Whether there is cached reply data for the last request executed <lb/>and, if so, the cached reply. <lb/>When sessions are transferred, there are a number of issues that pose <lb/>challenges in terms of making the transferred state unmodifiable <lb/>during the period it is gathered up and transferred to the <lb/>destination server. <lb/>o A single session may be used to access multiple file systems, not <lb/>all of which are being transferred. <lb/>o Requests made on a session may, even if rejected, affect the state <lb/>of the session by advancing the sequence number associated with <lb/>the slot used. <lb/>As a result, when the file system state might otherwise be considered <lb/>unmodifiable, the client might have any number of in-flight requests, <lb/>each of which is capable of changing session state, which may be of a <lb/>number of types: <lb/>1. Those requests that were processed on the migrating file system, <lb/>before migration began. <lb/>2. Those requests which got the error NFS4ERR_DELAY because the file <lb/>system being accessed was in the process of being migrated. <lb/>3. Those requests which got the error NFS4ERR_MOVED because the file <lb/>system being accessed had been migrated. <lb/>4. Those requests that accessed the migrating file system, in order <lb/>to obtain location or status information. <lb/>5. Those requests that did not reference the migrating file system. <lb/>It should be noted that the history of any particular slot is likely <lb/>to include a number of these request classes. In the case in which a <lb/>session which is migrated is used by file systems other than the one <lb/>migrated, requests of class 5 may be common and be the last request <lb/>processed, for many slots. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 268] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Since session state can change even after the locking state has been <lb/>fixed as part of the migration process, the session state known to <lb/>the client could be different from that on the destination server, <lb/>which necessarily reflects the session state on the source server, at <lb/>an earlier time. In deciding how to deal with this situation, it is <lb/>helpful to distinguish between two sorts of behavioral consequences <lb/>of the choice of initial sequence ID values. <lb/>o The error NFS4ERR_SEQ_MISORDERED is returned when the sequence ID <lb/>in a request is neither equal to the last one seen for the current <lb/>slot nor the next greater one. <lb/>In view of the difficulty of arriving at a mutually acceptable <lb/>value for the correct last sequence value at the point of <lb/>migration, it may be necessary for the server to show some degree <lb/>of forbearance, when the sequence ID is one that would be <lb/>considered unacceptable if session migration were not involved. <lb/>o Returning the cached reply for a previously executed request when <lb/>the sequence ID in the request matches the last value recorded for <lb/>the slot. <lb/>In the cases in which an error is returned and there is no <lb/>possibility of any non-idempotent operation having been executed, <lb/>it may not be necessary to adhere to this as strictly as might be <lb/>proper if session migration were not involved. For example, the <lb/>fact that the error NFS4ERR_DELAY was returned may not assist the <lb/>client in any material way, while the fact that NFS4ERR_MOVED was <lb/>returned by the source server may not be relevant when the request <lb/>was reissued, directed to the destination server. <lb/>An important issue is that the specification needs to take note of <lb/>all potential COMPOUNDs, even if they might be unlikely in practice. <lb/>For example, a COMPOUND is allowed to access multiple file systems <lb/>and might perform non-idempotent operations in some of them before <lb/>accessing a file system being migrated. Also, a COMPOUND may return <lb/>considerable data in the response, before being rejected with <lb/>NFS4ERR_DELAY or NFS4ERR_MOVED, and may in addition be marked as <lb/>sa_cachethis. <lb/>To address these issues, a destination server MAY do any of the <lb/>following when implementing session transfer. <lb/>o Avoid enforcing any sequencing semantics for a particular slot <lb/>until the client has established the starting sequence for that <lb/>slot on the destination server. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 269] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o For each slot, avoid returning a cached reply returning <lb/>NFS4ERR_DELAY or NFS4ERR_MOVED until the client has established <lb/>the starting sequence for that slot on the destination server. <lb/>o Until the client has established the starting sequence for a <lb/>particular slot on the destination server, avoid reporting <lb/>NFS4ERR_SEQ_MISORDERED or return a cached reply returning <lb/>NFS4ERR_DELAY or NFS4ERR_MOVED, where the reply consists solely of <lb/>a series of operations where the response is NFS4_OK until the <lb/>final error. <lb/>Because of the considerations mentioned above, the destination server <lb/>can respond appropriately to SEQUENCE operations received from the <lb/>client by adopting the three policies listed below: <lb/>o Not responding with NFS4ERR_SEQ_MISORDERED for the initial request <lb/>on a slot within a transferred session, since the destination <lb/>server cannot be aware of requests made by the client after the <lb/>server handoff but before the client became aware of the shift. <lb/>o Replying as it would for a retry whenever the sequence matches <lb/>that transferred by the source server, even though this would not <lb/>provide retry handling for requests issued after the server <lb/>handoff, under the assumption that when such requests are issued <lb/>they will never be responded to in a state-changing fashion, <lb/>making retry support for them unnecessary. <lb/>o Once a non-retry SEQUENCE is received for a given slot, using that <lb/>as the basis for further sequence checking, with no further <lb/>reference to the sequence value transferred by the sour server. <lb/>11.14. Effecting File System Referrals <lb/>Referrals are effected when an absent file system is encountered and <lb/>one or more alternate locations are made available by the <lb/>fs_locations or fs_locations_info attributes. The client will <lb/>typically get an NFS4ERR_MOVED error, fetch the appropriate location <lb/>information, and proceed to access the file system on a different <lb/>server, even though it retains its logical position within the <lb/>original namespace. Referrals differ from migration events in that <lb/>they happen only when the client has not previously referenced the <lb/>file system in question (so there is nothing to transition). <lb/>Referrals can only come into effect when an absent file system is <lb/>encountered at its root. <lb/>The examples given in the sections below are somewhat artificial in <lb/>that an actual client will not typically do a multi-component look <lb/>up, but will have cached information regarding the upper levels of <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 270] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the name hierarchy. However, these examples are chosen to make the <lb/>required behavior clear and easy to put within the scope of a small <lb/>number of requests, without getting a discussion of the details of <lb/>how specific clients might choose to cache things. <lb/>11.14.1. Referral Example (LOOKUP) <lb/>Let us suppose that the following COMPOUND is sent in an environment <lb/>in which /this/is/the/path is absent from the target server. This <lb/>may be for a number of reasons. It may be that the file system has <lb/>moved, or it may be that the target server is functioning mainly, or <lb/>solely, to refer clients to the servers on which various file systems <lb/>are located. <lb/>o PUTROOTFH <lb/>o LOOKUP &quot;this&quot; <lb/>o LOOKUP &quot;is&quot; <lb/>o LOOKUP &quot;the&quot; <lb/>o LOOKUP &quot;path&quot; <lb/>o GETFH <lb/>o GETATTR (fsid, fileid, size, time_modify) <lb/>Under the given circumstances, the following will be the result. <lb/>o PUTROOTFH --&gt; NFS_OK. The current fh is now the root of the <lb/>pseudo-fs. <lb/>o LOOKUP &quot;this&quot; --&gt; NFS_OK. The current fh is for /this and is <lb/>within the pseudo-fs. <lb/>o LOOKUP &quot;is&quot; --&gt; NFS_OK. The current fh is for /this/is and is <lb/>within the pseudo-fs. <lb/>o LOOKUP &quot;the&quot; --&gt; NFS_OK. The current fh is for /this/is/the and <lb/>is within the pseudo-fs. <lb/>o LOOKUP &quot;path&quot; --&gt; NFS_OK. The current fh is for /this/is/the/path <lb/>and is within a new, absent file system, but ... the client will <lb/>never see the value of that fh. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 271] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o GETFH --&gt; NFS4ERR_MOVED. Fails because current fh is in an absent <lb/>file system at the start of the operation, and the specification <lb/>makes no exception for GETFH. <lb/>o GETATTR (fsid, fileid, size, time_modify). Not executed because <lb/>the failure of the GETFH stops processing of the COMPOUND. <lb/>Given the failure of the GETFH, the client has the job of determining <lb/>the root of the absent file system and where to find that file <lb/>system, i.e., the server and path relative to that server&apos;s root fh. <lb/>Note that in this example, the client did not obtain filehandles and <lb/>attribute information (e.g., fsid) for the intermediate directories, <lb/>so that it would not be sure where the absent file system starts. It <lb/>could be the case, for example, that /this/is/the is the root of the <lb/>moved file system and that the reason that the look up of &quot;path&quot; <lb/>succeeded is that the file system was not absent on that operation <lb/>but was moved between the last LOOKUP and the GETFH (since COMPOUND <lb/>is not atomic). Even if we had the fsids for all of the intermediate <lb/>directories, we could have no way of knowing that /this/is/the/path <lb/>was the root of a new file system, since we don&apos;t yet have its fsid. <lb/>In order to get the necessary information, let us re-send the chain <lb/>of LOOKUPs with GETFHs and GETATTRs to at least get the fsids so we <lb/>can be sure where the appropriate file system boundaries are. The <lb/>client could choose to get fs_locations_info at the same time but in <lb/>most cases the client will have a good guess as to where file system <lb/>boundaries are (because of where NFS4ERR_MOVED was, and was not, <lb/>received) making fetching of fs_locations_info unnecessary. <lb/>OP01: PUTROOTFH --&gt; NFS_OK <lb/>-Current fh is root of pseudo-fs. <lb/>OP02: GETATTR(fsid) --&gt; NFS_OK <lb/>-Just for completeness. Normally, clients will know the fsid of <lb/>the pseudo-fs as soon as they establish communication with a <lb/>server. <lb/>OP03: LOOKUP &quot;this&quot; --&gt; NFS_OK <lb/>OP04: GETATTR(fsid) --&gt; NFS_OK <lb/>-Get current fsid to see where file system boundaries are. The <lb/>fsid will be that for the pseudo-fs in this example, so no <lb/>boundary. <lb/>OP05: GETFH --&gt; NFS_OK <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 272] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>-Current fh is for /this and is within pseudo-fs. <lb/>OP06: LOOKUP &quot;is&quot; --&gt; NFS_OK <lb/>-Current fh is for /this/is and is within pseudo-fs. <lb/>OP07: GETATTR(fsid) --&gt; NFS_OK <lb/>-Get current fsid to see where file system boundaries are. The <lb/>fsid will be that for the pseudo-fs in this example, so no <lb/>boundary. <lb/>OP08: GETFH --&gt; NFS_OK <lb/>-Current fh is for /this/is and is within pseudo-fs. <lb/>OP09: LOOKUP &quot;the&quot; --&gt; NFS_OK <lb/>-Current fh is for /this/is/the and is within pseudo-fs. <lb/>OP10: GETATTR(fsid) --&gt; NFS_OK <lb/>-Get current fsid to see where file system boundaries are. The <lb/>fsid will be that for the pseudo-fs in this example, so no <lb/>boundary. <lb/>OP11: GETFH --&gt; NFS_OK <lb/>-Current fh is for /this/is/the and is within pseudo-fs. <lb/>OP12: LOOKUP &quot;path&quot; --&gt; NFS_OK <lb/>-Current fh is for /this/is/the/path and is within a new, absent <lb/>file system, but ... <lb/>-The client will never see the value of that fh. <lb/>OP13: GETATTR(fsid, fs_locations_info) --&gt; NFS_OK <lb/>-We are getting the fsid to know where the file system boundaries <lb/>are. In this operation, the fsid will be different than that of <lb/>the parent directory (which in turn was retrieved in OP10). Note <lb/>that the fsid we are given will not necessarily be preserved at <lb/>the new location. That fsid might be different, and in fact the <lb/>fsid we have for this file system might be a valid fsid of a <lb/>different file system on that new server. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 273] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>-In this particular case, we are pretty sure anyway that what has <lb/>moved is /this/is/the/path rather than /this/is/the since we have <lb/>the fsid of the latter and it is that of the pseudo-fs, which <lb/>presumably cannot move. However, in other examples, we might not <lb/>have this kind of information to rely on (e.g., /this/is/the might <lb/>be a non-pseudo file system separate from /this/is/the/path), so <lb/>we need to have other reliable source information on the boundary <lb/>of the file system that is moved. If, for example, the file <lb/>system /this/is had moved, we would have a case of migration <lb/>rather than referral, and once the boundaries of the migrated file <lb/>system was clear we could fetch fs_locations_info. <lb/>-We are fetching fs_locations_info because the fact that we got an <lb/>NFS4ERR_MOVED at this point means that it is most likely that this <lb/>is a referral and we need the destination. Even if it is the case <lb/>that /this/is/the is a file system that has migrated, we will <lb/>still need the location information for that file system. <lb/>OP14: GETFH --&gt; NFS4ERR_MOVED <lb/>-Fails because current fh is in an absent file system at the start <lb/>of the operation, and the specification makes no exception for <lb/>GETFH. Note that this means the server will never send the client <lb/>a filehandle from within an absent file system. <lb/>Given the above, the client knows where the root of the absent file <lb/>system is (/this/is/the/path) by noting where the change of fsid <lb/>occurred (between &quot;the&quot; and &quot;path&quot;). The fs_locations_info attribute <lb/>also gives the client the actual location of the absent file system, <lb/>so that the referral can proceed. The server gives the client the <lb/>bare minimum of information about the absent file system so that <lb/>there will be very little scope for problems of conflict between <lb/>information sent by the referring server and information of the file <lb/>system&apos;s home. No filehandles and very few attributes are present on <lb/>the referring server, and the client can treat those it receives as <lb/>transient information with the function of enabling the referral. <lb/>11.14.2. Referral Example (READDIR) <lb/>Another context in which a client may encounter referrals is when it <lb/>does a READDIR on a directory in which some of the sub-directories <lb/>are the roots of absent file systems. <lb/>Suppose such a directory is read as follows: <lb/>o PUTROOTFH <lb/>o LOOKUP &quot;this&quot; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 274] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o LOOKUP &quot;is&quot; <lb/>o LOOKUP &quot;the&quot; <lb/>o READDIR (fsid, size, time_modify, mounted_on_fileid) <lb/>In this case, because rdattr_error is not requested, <lb/>fs_locations_info is not requested, and some of the attributes cannot <lb/>be provided, the result will be an NFS4ERR_MOVED error on the <lb/>READDIR, with the detailed results as follows: <lb/>o PUTROOTFH --&gt; NFS_OK. The current fh is at the root of the <lb/>pseudo-fs. <lb/>o LOOKUP &quot;this&quot; --&gt; NFS_OK. The current fh is for /this and is <lb/>within the pseudo-fs. <lb/>o LOOKUP &quot;is&quot; --&gt; NFS_OK. The current fh is for /this/is and is <lb/>within the pseudo-fs. <lb/>o LOOKUP &quot;the&quot; --&gt; NFS_OK. The current fh is for /this/is/the and <lb/>is within the pseudo-fs. <lb/>o READDIR (fsid, size, time_modify, mounted_on_fileid) --&gt; <lb/>NFS4ERR_MOVED. Note that the same error would have been returned <lb/>if /this/is/the had migrated, but it is returned because the <lb/>directory contains the root of an absent file system. <lb/>So now suppose that we re-send with rdattr_error: <lb/>o PUTROOTFH <lb/>o LOOKUP &quot;this&quot; <lb/>o LOOKUP &quot;is&quot; <lb/>o LOOKUP &quot;the&quot; <lb/>o READDIR (rdattr_error, fsid, size, time_modify, mounted_on_fileid) <lb/>The results will be: <lb/>o PUTROOTFH --&gt; NFS_OK. The current fh is at the root of the <lb/>pseudo-fs. <lb/>o LOOKUP &quot;this&quot; --&gt; NFS_OK. The current fh is for /this and is <lb/>within the pseudo-fs. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 275] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o LOOKUP &quot;is&quot; --&gt; NFS_OK. The current fh is for /this/is and is <lb/>within the pseudo-fs. <lb/>o LOOKUP &quot;the&quot; --&gt; NFS_OK. The current fh is for /this/is/the and <lb/>is within the pseudo-fs. <lb/>o READDIR (rdattr_error, fsid, size, time_modify, mounted_on_fileid) <lb/>--&gt; NFS_OK. The attributes for directory entry with the component <lb/>named &quot;path&quot; will only contain rdattr_error with the value <lb/>NFS4ERR_MOVED, together with an fsid value and a value for <lb/>mounted_on_fileid. <lb/>Suppose we do another READDIR to get fs_locations_info (although we <lb/>could have used a GETATTR directly, as in Section 11.14.1). <lb/>o PUTROOTFH <lb/>o LOOKUP &quot;this&quot; <lb/>o LOOKUP &quot;is&quot; <lb/>o LOOKUP &quot;the&quot; <lb/>o READDIR (rdattr_error, fs_locations_info, mounted_on_fileid, fsid, <lb/>size, time_modify) <lb/>The results would be: <lb/>o PUTROOTFH --&gt; NFS_OK. The current fh is at the root of the <lb/>pseudo-fs. <lb/>o LOOKUP &quot;this&quot; --&gt; NFS_OK. The current fh is for /this and is <lb/>within the pseudo-fs. <lb/>o LOOKUP &quot;is&quot; --&gt; NFS_OK. The current fh is for /this/is and is <lb/>within the pseudo-fs. <lb/>o LOOKUP &quot;the&quot; --&gt; NFS_OK. The current fh is for /this/is/the and <lb/>is within the pseudo-fs. <lb/>o READDIR (rdattr_error, fs_locations_info, mounted_on_fileid, fsid, <lb/>size, time_modify) --&gt; NFS_OK. The attributes will be as shown <lb/>below. <lb/>The attributes for the directory entry with the component named <lb/>&quot;path&quot; will only contain: <lb/>o rdattr_error (value: NFS_OK) <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 276] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o fs_locations_info <lb/>o mounted_on_fileid (value: unique fileid within referring file <lb/>system) <lb/>o fsid (value: unique value within referring server) <lb/>The attributes for entry &quot;path&quot; will not contain size or time_modify <lb/>because these attributes are not available within an absent file <lb/>system. <lb/>11.15. The Attribute fs_locations <lb/>The fs_locations attribute is structured in the following way: <lb/>struct fs_location4 { <lb/>utf8str_cis <lb/>server&lt;&gt;; <lb/>pathname4 <lb/>rootpath; <lb/>}; <lb/>struct fs_locations4 { <lb/>pathname4 <lb/>fs_root; <lb/>fs_location4 <lb/>locations&lt;&gt;; <lb/>}; <lb/>The fs_location4 data type is used to represent the location of a <lb/>file system by providing a server name and the path to the root of <lb/>the file system within that server&apos;s namespace. When a set of <lb/>servers have corresponding file systems at the same path within their <lb/>namespaces, an array of server names may be provided. An entry in <lb/>the server array is a UTF-8 string and represents one of a <lb/>traditional DNS host name, IPv4 address, IPv6 address, or a zero-<lb/>length string. An IPv4 or IPv6 address is represented as a universal <lb/>address (see Section 3.3.9 and [12]), minus the netid, and either <lb/>with or without the trailing &quot;.p1.p2&quot; suffix that represents the port <lb/>number. If the suffix is omitted, then the default port, 2049, <lb/>SHOULD be assumed. A zero-length string SHOULD be used to indicate <lb/>the current address being used for the RPC call. It is not a <lb/>requirement that all servers that share the same rootpath be listed <lb/>in one fs_location4 instance. The array of server names is provided <lb/>for convenience. Servers that share the same rootpath may also be <lb/>listed in separate fs_location4 entries in the fs_locations <lb/>attribute. <lb/>The fs_locations4 data type and the fs_locations attribute each <lb/>contain an array of such locations. Since the namespace of each <lb/>server may be constructed differently, the &quot;fs_root&quot; field is <lb/>provided. The path represented by fs_root represents the location of <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 277] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the file system in the current server&apos;s namespace, i.e., that of the <lb/>server from which the fs_locations attribute was obtained. The <lb/>fs_root path is meant to aid the client by clearly referencing the <lb/>root of the file system whose locations are being reported, no matter <lb/>what object within the current file system the current filehandle <lb/>designates. The fs_root is simply the pathname the client used to <lb/>reach the object on the current server (i.e., the object to which the <lb/>fs_locations attribute applies). <lb/>When the fs_locations attribute is interrogated and there are no <lb/>alternate file system locations, the server SHOULD return a zero-<lb/>length array of fs_location4 structures, together with a valid <lb/>fs_root. <lb/>As an example, suppose there is a replicated file system located at <lb/>two servers (servA and servB). At servA, the file system is located <lb/>at path /a/b/c. At, servB the file system is located at path /x/y/z. <lb/>If the client were to obtain the fs_locations value for the directory <lb/>at /a/b/c/d, it might not necessarily know that the file system&apos;s <lb/>root is located in servA&apos;s namespace at /a/b/c. When the client <lb/>switches to servB, it will need to determine that the directory it <lb/>first referenced at servA is now represented by the path /x/y/z/d on <lb/>servB. To facilitate this, the fs_locations attribute provided by <lb/>servA would have an fs_root value of /a/b/c and two entries in <lb/>fs_locations. One entry in fs_locations will be for itself (servA) <lb/>and the other will be for servB with a path of /x/y/z. With this <lb/>information, the client is able to substitute /x/y/z for the /a/b/c <lb/>at the beginning of its access path and construct /x/y/z/d to use for <lb/>the new server. <lb/>Note that there is no requirement that the number of components in <lb/>each rootpath be the same; there is no relation between the number of <lb/>components in rootpath or fs_root, and none of the components in a <lb/>rootpath and fs_root have to be the same. In the above example, we <lb/>could have had a third element in the locations array, with server <lb/>equal to &quot;servC&quot; and rootpath equal to &quot;/I/II&quot;, and a fourth element <lb/>in locations with server equal to &quot;servD&quot; and rootpath equal to <lb/>&quot;/aleph/beth/gimel/daleth/he&quot;. <lb/>The relationship between fs_root to a rootpath is that the client <lb/>replaces the pathname indicated in fs_root for the current server for <lb/>the substitute indicated in rootpath for the new server. <lb/>For an example of a referred or migrated file system, suppose there <lb/>is a file system located at serv1. At serv1, the file system is <lb/>located at /az/buky/vedi/glagoli. The client finds that object at <lb/>glagoli has migrated (or is a referral). The client gets the <lb/>fs_locations attribute, which contains an fs_root of /az/buky/vedi/ <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 278] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>glagoli, and one element in the locations array, with server equal to <lb/>serv2, and rootpath equal to /izhitsa/fita. The client replaces <lb/>/az/buky/vedi/glagoli with /izhitsa/fita, and uses the latter <lb/>pathname on serv2. <lb/>Thus, the server MUST return an fs_root that is equal to the path the <lb/>client used to reach the object to which the fs_locations attribute <lb/>applies. Otherwise, the client cannot determine the new path to use <lb/>on the new server. <lb/>Since the fs_locations attribute lacks information defining various <lb/>attributes of the various file system choices presented, it SHOULD <lb/>only be interrogated and used when fs_locations_info is not <lb/>available. When fs_locations is used, information about the specific <lb/>locations should be assumed based on the following rules. <lb/>The following rules are general and apply irrespective of the <lb/>context. <lb/>o All listed file system instances should be considered as of the <lb/>same handle class, if and only if, the current fh_expire_type <lb/>attribute does not include the FH4_VOL_MIGRATION bit. Note that <lb/>in the case of referral, filehandle issues do not apply since <lb/>there can be no filehandles known within the current file system, <lb/>nor is there any access to the fh_expire_type attribute on the <lb/>referring (absent) file system. <lb/>o All listed file system instances should be considered as of the <lb/>same fileid class if and only if the fh_expire_type attribute <lb/>indicates persistent filehandles and does not include the <lb/>FH4_VOL_MIGRATION bit. Note that in the case of referral, fileid <lb/>issues do not apply since there can be no fileids known within the <lb/>referring (absent) file system, nor is there any access to the <lb/>fh_expire_type attribute. <lb/>o All file system instances servers should be considered as of <lb/>different change classes. <lb/>For other class assignments, handling of file system transitions <lb/>depends on the reasons for the transition: <lb/>o When the transition is due to migration, that is, the client was <lb/>directed to a new file system after receiving an NFS4ERR_MOVED <lb/>error, the target should be treated as being of the same write-<lb/>verifier class as the source. <lb/>o When the transition is due to failover to another replica, that <lb/>is, the client selected another replica without receiving an <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 279] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>NFS4ERR_MOVED error, the target should be treated as being of a <lb/>different write-verifier class from the source. <lb/>The specific choices reflect typical implementation patterns for <lb/>failover and controlled migration, respectively. Since other choices <lb/>are possible and useful, this information is better obtained by using <lb/>fs_locations_info. When a server implementation needs to communicate <lb/>other choices, it MUST support the fs_locations_info attribute. <lb/>See Section 21 for a discussion on the recommendations for the <lb/>security flavor to be used by any GETATTR operation that requests the <lb/>&quot;fs_locations&quot; attribute. <lb/>11.16. The Attribute fs_locations_info <lb/>The fs_locations_info attribute is intended as a more functional <lb/>replacement for the fs_locations attribute which will continue to <lb/>exist and be supported. Clients can use it to get a more complete <lb/>set of data about alternative file system locations, including <lb/>additional network paths to access replicas in use and additional <lb/>replicas. When the server does not support fs_locations_info, <lb/>fs_locations can be used to get a subset of the data. A server that <lb/>supports fs_locations_info MUST support fs_locations as well. <lb/>There is additional data present in fs_locations_info, that is not <lb/>available in fs_locations: <lb/>o Attribute continuity information. This information will allow a <lb/>client to select a replica that meets the transparency <lb/>requirements of the applications accessing the data and to <lb/>leverage optimizations due to the server guarantees of attribute <lb/>continuity (e.g., if the change attribute of a file of the file <lb/>system is continuous between multiple replicas, the client does <lb/>not have to invalidate the file&apos;s cache when switching to a <lb/>different replica). <lb/>o File system identity information that indicates when multiple <lb/>replicas, from the client&apos;s point of view, correspond to the same <lb/>target file system, allowing them to be used interchangeably, <lb/>without disruption, as distinct synchronized replicas of the same <lb/>file data. <lb/>Note that having two replicas with common identity information is <lb/>distinct from the case of two (trunked) paths to the same replica. <lb/>o Information that will bear on the suitability of various replicas, <lb/>depending on the use that the client intends. For example, many <lb/>applications need an absolutely up-to-date copy (e.g., those that <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 280] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>write), while others may only need access to the most up-to-date <lb/>copy reasonably available. <lb/>o Server-derived preference information for replicas, which can be <lb/>used to implement load-balancing while giving the client the <lb/>entire file system list to be used in case the primary fails. <lb/>The fs_locations_info attribute is structured similarly to the <lb/>fs_locations attribute. A top-level structure (fs_locations_info4) <lb/>contains the entire attribute including the root pathname of the file <lb/>system and an array of lower-level structures that define replicas <lb/>that share a common rootpath on their respective servers. The lower-<lb/>level structure in turn (fs_locations_item4) contains a specific <lb/>pathname and information on one or more individual network access <lb/>paths. For that last lowest level, fs_locations_info has an <lb/>fs_locations_server4 structure that contains per-server-replica <lb/>information in addition to the file system location entry. This per-<lb/>server-replica information includes a nominally opaque array, <lb/>fls_info, within which specific pieces of information are located at <lb/>the specific indices listed below. <lb/>Two fs_location_server4 entries that are within different <lb/>fs_location_item4 structures are never trunkable, while two entries <lb/>within in the same fs_location_item4 structure might or might not be <lb/>trunkable. Two entries that are trunkable will have identical <lb/>identity information, although, as noted above, the converse is not <lb/>the case. <lb/>The attribute will always contain at least a single <lb/>fs_locations_server entry. Typically, there will be an entry with <lb/>the FS4LIGF_CUR_REQ flag set, although in the case of a referral <lb/>there will be no entry with that flag set. <lb/>It should be noted that fs_locations_info attributes returned by <lb/>servers for various replicas may differ for various reasons. One <lb/>server may know about a set of replicas that are not known to other <lb/>servers. Further, compatibility attributes may differ. Filehandles <lb/>might be of the same class going from replica A to replica B but not <lb/>going in the reverse direction. This might happen because the <lb/>filehandles are the same, but replica B&apos;s server implementation might <lb/>not have provision to note and report that equivalence. <lb/>The fs_locations_info attribute consists of a root pathname <lb/>(fli_fs_root, just like fs_root in the fs_locations attribute), <lb/>together with an array of fs_location_item4 structures. The <lb/>fs_location_item4 structures in turn consist of a root pathname <lb/>(fli_rootpath) together with an array (fli_entries) of elements of <lb/>data type fs_locations_server4, all defined as follows. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 281] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>/* <lb/>* Defines an individual server access path <lb/>*/ <lb/>struct fs_locations_server4 { <lb/>int32_t <lb/>fls_currency; <lb/>opaque <lb/>fls_info&lt;&gt;; <lb/>utf8str_cis <lb/>fls_server; <lb/>}; <lb/>/* <lb/>* Byte indices of items within <lb/>* fls_info: flag fields, class numbers, <lb/>* bytes indicating ranks and orders. <lb/>*/ <lb/>const FSLI4BX_GFLAGS <lb/>= 0; <lb/>const FSLI4BX_TFLAGS <lb/>= 1; <lb/>const FSLI4BX_CLSIMUL <lb/>= 2; <lb/>const FSLI4BX_CLHANDLE <lb/>= 3; <lb/>const FSLI4BX_CLFILEID <lb/>= 4; <lb/>const FSLI4BX_CLWRITEVER <lb/>= 5; <lb/>const FSLI4BX_CLCHANGE <lb/>= 6; <lb/>const FSLI4BX_CLREADDIR <lb/>= 7; <lb/>const FSLI4BX_READRANK <lb/>= 8; <lb/>const FSLI4BX_WRITERANK <lb/>= 9; <lb/>const FSLI4BX_READORDER <lb/>= 10; <lb/>const FSLI4BX_WRITEORDER <lb/>= 11; <lb/>/* <lb/>* Bits defined within the general flag byte. <lb/>*/ <lb/>const FSLI4GF_WRITABLE <lb/>= 0x01; <lb/>const FSLI4GF_CUR_REQ <lb/>= 0x02; <lb/>const FSLI4GF_ABSENT <lb/>= 0x04; <lb/>const FSLI4GF_GOING <lb/>= 0x08; <lb/>const FSLI4GF_SPLIT <lb/>= 0x10; <lb/>/* <lb/>* Bits defined within the transport flag byte. <lb/>*/ <lb/>const FSLI4TF_RDMA <lb/>= 0x01; <lb/>/* <lb/>* Defines a set of replicas sharing <lb/>* a common value of the rootpath <lb/>* within the corresponding <lb/>* single-server namespaces. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 282] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>*/ <lb/>struct fs_locations_item4 { <lb/>fs_locations_server4 <lb/>fli_entries&lt;&gt;; <lb/>pathname4 <lb/>fli_rootpath; <lb/>}; <lb/>/* <lb/>* Defines the overall structure of <lb/>* the fs_locations_info attribute. <lb/>*/ <lb/>struct fs_locations_info4 { <lb/>uint32_t <lb/>fli_flags; <lb/>int32_t <lb/>fli_valid_for; <lb/>pathname4 <lb/>fli_fs_root; <lb/>fs_locations_item4 <lb/>fli_items&lt;&gt;; <lb/>}; <lb/>/* <lb/>* Flag bits in fli_flags. <lb/>*/ <lb/>const FSLI4IF_VAR_SUB <lb/>= 0x00000001; <lb/>typedef fs_locations_info4 fattr4_fs_locations_info; <lb/>As noted above, the fs_locations_info attribute, when supported, may <lb/>be requested of absent file systems without causing NFS4ERR_MOVED to <lb/>be returned. It is generally expected that it will be available for <lb/>both present and absent file systems even if only a single <lb/>fs_locations_server4 entry is present, designating the current <lb/>(present) file system, or two fs_locations_server4 entries <lb/>designating the previous location of an absent file system (the one <lb/>just referenced) and its successor location. Servers are strongly <lb/>urged to support this attribute on all file systems if they support <lb/>it on any file system. <lb/>The data presented in the fs_locations_info attribute may be obtained <lb/>by the server in any number of ways, including specification by the <lb/>administrator or by current protocols for transferring data among <lb/>replicas and protocols not yet developed. NFSv4.1 only defines how <lb/>this information is presented by the server to the client. <lb/>11.16.1. The fs_locations_server4 Structure <lb/>The fs_locations_server4 structure consists of the following items in <lb/>addition to the fls_server field which specifies a network address or <lb/>set of addresses to be used to access the specified file system. <lb/>Note that both of these items (i.e., fls_currency and flinfo) specify <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 283] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>attributes of the file system replica and should not be different <lb/>when there are multiple fs_locations_server4 structures for the same <lb/>replica, each specifying a network path to the chosen replica. <lb/>When these values are different in two fs_locations_server4 <lb/>structures, a client has no basis for choosing one over the other and <lb/>is best off simply ignoring both entries, whether these entries apply <lb/>to migration replication or referral. When there are more than two <lb/>such entries, majority voting can be used to exclude a single <lb/>erroneous entry from consideration. In the case in which trunking <lb/>information is provided for a replica currently being accessed, the <lb/>additional trunked addresses can be ignored while access continues on <lb/>the address currently being used, even if the entry corresponding to <lb/>that path might be considered invalid. <lb/>o An indication of how up-to-date the file system is (fls_currency) <lb/>in seconds. This value is relative to the master copy. A <lb/>negative value indicates that the server is unable to give any <lb/>reasonably useful value here. A value of zero indicates that the <lb/>file system is the actual writable data or a reliably coherent and <lb/>fully up-to-date copy. Positive values indicate how out-of-date <lb/>this copy can normally be before it is considered for update. <lb/>Such a value is not a guarantee that such updates will always be <lb/>performed on the required schedule but instead serves as a hint <lb/>about how far the copy of the data would be expected to be behind <lb/>the most up-to-date copy. <lb/>o A counted array of one-byte values (fls_info) containing <lb/>information about the particular file system instance. This data <lb/>includes general flags, transport capability flags, file system <lb/>equivalence class information, and selection priority information. <lb/>The encoding will be discussed below. <lb/>o The server string (fls_server). For the case of the replica <lb/>currently being accessed (via GETATTR), a zero-length string MAY <lb/>be used to indicate the current address being used for the RPC <lb/>call. The fls_server field can also be an IPv4 or IPv6 address, <lb/>formatted the same way as an IPv4 or IPv6 address in the &quot;server&quot; <lb/>field of the fs_location4 data type (see Section 11.15). <lb/>With the exception of the transport-flag field (at offset <lb/>FSLI4BX_TFLAGS with the fls_info array), all of this data applies to <lb/>the replica specified by the entry, rather that the specific network <lb/>path used to access it. <lb/>Data within the fls_info array is in the form of 8-bit data items <lb/>with constants giving the offsets within the array of various values <lb/>describing this particular file system instance. This style of <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 284] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>definition was chosen, in preference to explicit XDR structure <lb/>definitions for these values, for a number of reasons. <lb/>o The kinds of data in the fls_info array, representing flags, file <lb/>system classes, and priorities among sets of file systems <lb/>representing the same data, are such that 8 bits provide a quite <lb/>acceptable range of values. Even where there might be more than <lb/>256 such file system instances, having more than 256 distinct <lb/>classes or priorities is unlikely. <lb/>o Explicit definition of the various specific data items within XDR <lb/>would limit expandability in that any extension within would <lb/>require yet another attribute, leading to specification and <lb/>implementation clumsiness. In the context of the NFSv4 extension <lb/>model in effect at the time fs_locations_info was designed (i.e. <lb/>that described in RFC5661 [60]), this would necessitate a new <lb/>minor version to effect any Standards Track extension to the data <lb/>in in fls_info. <lb/>The set of fls_info data is subject to expansion in a future minor <lb/>version, or in a Standards Track RFC, within the context of a single <lb/>minor version. The server SHOULD NOT send and the client MUST NOT <lb/>use indices within the fls_info array or flag bits that are not <lb/>defined in Standards Track RFCs. <lb/>In light of the new extension model defined in RFC8178 [61] and the <lb/>fact that the individual items within fls_info are not explicitly <lb/>referenced in the XDR, the following practices should be followed <lb/>when extending or otherwise changing the structure of the data <lb/>returned in fls_info within the scope of a single minor version. <lb/>o All extensions need to be described by Standards Track documents. <lb/>There is no need for such documents to be marked as updating <lb/>RFC5661 [60] or this document. <lb/>o It needs to be made clear whether the information in any added <lb/>data items applies to the replica specified by the entry or to the <lb/>specific network paths specified in the entry. <lb/>o There needs to be a reliable way defined to determine whether the <lb/>server is aware of the extension. This may be based on the length <lb/>field of the fls_info array, but it is more flexible to provide <lb/>fs-scope or server-scope attributes to indicate what extensions <lb/>are provided. <lb/>This encoding scheme can be adapted to the specification of multi-<lb/>byte numeric values, even though none are currently defined. If <lb/>extensions are made via Standards Track RFCs, multi-byte quantities <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 285] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>will be encoded as a range of bytes with a range of indices, with the <lb/>byte interpreted in big-endian byte order. Further, any such index <lb/>assignments will be constrained by the need for the relevant <lb/>quantities not to cross XDR word boundaries. <lb/>The fls_info array currently contains: <lb/>o Two 8-bit flag fields, one devoted to general file-system <lb/>characteristics and a second reserved for transport-related <lb/>capabilities. <lb/>o Six 8-bit class values that define various file system equivalence <lb/>classes as explained below. <lb/>o Four 8-bit priority values that govern file system selection as <lb/>explained below. <lb/>The general file system characteristics flag (at byte index <lb/>FSLI4BX_GFLAGS) has the following bits defined within it: <lb/>o FSLI4GF_WRITABLE indicates that this file system target is <lb/>writable, allowing it to be selected by clients that may need to <lb/>write on this file system. When the current file system instance <lb/>is writable and is defined as of the same simultaneous use class <lb/>(as specified by the value at index FSLI4BX_CLSIMUL) to which the <lb/>client was previously writing, then it must incorporate within its <lb/>data any committed write made on the source file system instance. <lb/>See Section 11.10.6, which discusses the write-verifier class. <lb/>While there is no harm in not setting this flag for a file system <lb/>that turns out to be writable, turning the flag on for a read-only <lb/>file system can cause problems for clients that select a migration <lb/>or replication target based on the flag and then find themselves <lb/>unable to write. <lb/>o FSLI4GF_CUR_REQ indicates that this replica is the one on which <lb/>the request is being made. Only a single server entry may have <lb/>this flag set and, in the case of a referral, no entry will have <lb/>it set. Note that this flag might be set even if the request was <lb/>made on a network access path different from any of those <lb/>specified in the current entry. <lb/>o FSLI4GF_ABSENT indicates that this entry corresponds to an absent <lb/>file system replica. It can only be set if FSLI4GF_CUR_REQ is <lb/>set. When both such bits are set, it indicates that a file system <lb/>instance is not usable but that the information in the entry can <lb/>be used to determine the sorts of continuity available when <lb/>switching from this replica to other possible replicas. Since <lb/>this bit can only be true if FSLI4GF_CUR_REQ is true, the value <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 286] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>could be determined using the fs_status attribute, but the <lb/>information is also made available here for the convenience of the <lb/>client. An entry with this bit, since it represents a true file <lb/>system (albeit absent), does not appear in the event of a <lb/>referral, but only when a file system has been accessed at this <lb/>location and has subsequently been migrated. <lb/>o FSLI4GF_GOING indicates that a replica, while still available, <lb/>should not be used further. The client, if using it, should make <lb/>an orderly transfer to another file system instance as <lb/>expeditiously as possible. It is expected that file systems going <lb/>out of service will be announced as FSLI4GF_GOING some time before <lb/>the actual loss of service. It is also expected that the <lb/>fli_valid_for value will be sufficiently small to allow clients to <lb/>detect and act on scheduled events, while large enough that the <lb/>cost of the requests to fetch the fs_locations_info values will <lb/>not be excessive. Values on the order of ten minutes seem <lb/>reasonable. <lb/>When this flag is seen as part of a transition into a new file <lb/>system, a client might choose to transfer immediately to another <lb/>replica, or it may reference the current file system and only <lb/>transition when a migration event occurs. Similarly, when this <lb/>flag appears as a replica in the referral, clients would likely <lb/>avoid being referred to this instance whenever there is another <lb/>choice. <lb/>This flag, like the other items within fls_info applies to the <lb/>replica, rather than to a particular path to that replica. When <lb/>it appears, a transition to a new replica rather than to a <lb/>different path to the same replica, is indicated. <lb/>o FSLI4GF_SPLIT indicates that when a transition occurs from the <lb/>current file system instance to this one, the replacement may <lb/>consist of multiple file systems. In this case, the client has to <lb/>be prepared for the possibility that objects on the same file <lb/>system before migration will be on different ones after. Note <lb/>that FSLI4GF_SPLIT is not incompatible with the file systems <lb/>belonging to the same fileid class since, if one has a set of <lb/>fileids that are unique within a file system, each subset assigned <lb/>to a smaller file system after migration would not have any <lb/>conflicts internal to that file system. <lb/>A client, in the case of a split file system, will interrogate <lb/>existing files with which it has continuing connection (it is free <lb/>to simply forget cached filehandles). If the client remembers the <lb/>directory filehandle associated with each open file, it may <lb/>proceed upward using LOOKUPP to find the new file system <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 287] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>boundaries. Note that in the event of a referral, there will not <lb/>be any such files and so these actions will not be performed. <lb/>Instead, a reference to a portion of the original file system now <lb/>split off into other file systems will encounter an fsid change <lb/>and possibly a further referral. <lb/>Once the client recognizes that one file system has been split <lb/>into two, it can prevent the disruption of running applications by <lb/>presenting the two file systems as a single one until a convenient <lb/>point to recognize the transition, such as a restart. This would <lb/>require a mapping from the server&apos;s fsids to fsids as seen by the <lb/>client, but this is already necessary for other reasons. As noted <lb/>above, existing fileids within the two descendant file systems <lb/>will not conflict. Providing non-conflicting fileids for newly <lb/>created files on the split file systems is the responsibility of <lb/>the server (or servers working in concert). The server can encode <lb/>filehandles such that filehandles generated before the split event <lb/>can be discerned from those generated after the split, allowing <lb/>the server to determine when the need for emulating two file <lb/>systems as one is over. <lb/>Although it is possible for this flag to be present in the event <lb/>of referral, it would generally be of little interest to the <lb/>client, since the client is not expected to have information <lb/>regarding the current contents of the absent file system. <lb/>The transport-flag field (at byte index FSLI4BX_TFLAGS) contains the <lb/>following bits related to the transport capabilities of the specific <lb/>network path(s) specified by the entry. <lb/>o FSLI4TF_RDMA indicates that any specified network paths provide <lb/>NFSv4.1 clients access using an RDMA-capable transport. <lb/>Attribute continuity and file system identity information are <lb/>expressed by defining equivalence relations on the sets of file <lb/>systems presented to the client. Each such relation is expressed as <lb/>a set of file system equivalence classes. For each relation, a file <lb/>system has an 8-bit class number. Two file systems belong to the <lb/>same class if both have identical non-zero class numbers. Zero is <lb/>treated as non-matching. Most often, the relevant question for the <lb/>client will be whether a given replica is identical to / continuous <lb/>with the current one in a given respect, but the information should <lb/>be available also as to whether two other replicas match in that <lb/>respect as well. <lb/>The following fields specify the file system&apos;s class numbers for the <lb/>equivalence relations used in determining the nature of file system <lb/>transitions. See Sections 11.8 through 11.13 and their various <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 288] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>subsections for details about how this information is to be used. <lb/>Servers may assign these values as they wish, so long as file system <lb/>instances that share the same value have the specified relationship <lb/>to one another; conversely, file systems that have the specified <lb/>relationship to one another share a common class value. As each <lb/>instance entry is added, the relationships of this instance to <lb/>previously entered instances can be consulted, and if one is found <lb/>that bears the specified relationship, that entry&apos;s class value can <lb/>be copied to the new entry. When no such previous entry exists, a <lb/>new value for that byte index (not previously used) can be selected, <lb/>most likely by incrementing the value of the last class value <lb/>assigned for that index. <lb/>o The field with byte index FSLI4BX_CLSIMUL defines the <lb/>simultaneous-use class for the file system. <lb/>o The field with byte index FSLI4BX_CLHANDLE defines the handle <lb/>class for the file system. <lb/>o The field with byte index FSLI4BX_CLFILEID defines the fileid <lb/>class for the file system. <lb/>o The field with byte index FSLI4BX_CLWRITEVER defines the write-<lb/>verifier class for the file system. <lb/>o The field with byte index FSLI4BX_CLCHANGE defines the change <lb/>class for the file system. <lb/>o The field with byte index FSLI4BX_CLREADDIR defines the readdir <lb/>class for the file system. <lb/>Server-specified preference information is also provided via 8-bit <lb/>values within the fls_info array. The values provide a rank and an <lb/>order (see below) to be used with separate values specifiable for the <lb/>cases of read-only and writable file systems. These values are <lb/>compared for different file systems to establish the server-specified <lb/>preference, with lower values indicating &quot;more preferred&quot;. <lb/>Rank is used to express a strict server-imposed ordering on clients, <lb/>with lower values indicating &quot;more preferred&quot;. Clients should <lb/>attempt to use all replicas with a given rank before they use one <lb/>with a higher rank. Only if all of those file systems are <lb/>unavailable should the client proceed to those of a higher rank. <lb/>Because specifying a rank will override client preferences, servers <lb/>should be conservative about using this mechanism, particularly when <lb/>the environment is one in which client communication characteristics <lb/>are neither tightly controlled nor visible to the server. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 289] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Within a rank, the order value is used to specify the server&apos;s <lb/>preference to guide the client&apos;s selection when the client&apos;s own <lb/>preferences are not controlling, with lower values of order <lb/>indicating &quot;more preferred&quot;. If replicas are approximately equal in <lb/>all respects, clients should defer to the order specified by the <lb/>server. When clients look at server latency as part of their <lb/>selection, they are free to use this criterion, but it is suggested <lb/>that when latency differences are not significant, the server-<lb/>specified order should guide selection. <lb/>o The field at byte index FSLI4BX_READRANK gives the rank value to <lb/>be used for read-only access. <lb/>o The field at byte index FSLI4BX_READORDER gives the order value to <lb/>be used for read-only access. <lb/>o The field at byte index FSLI4BX_WRITERANK gives the rank value to <lb/>be used for writable access. <lb/>o The field at byte index FSLI4BX_WRITEORDER gives the order value <lb/>to be used for writable access. <lb/>Depending on the potential need for write access by a given client, <lb/>one of the pairs of rank and order values is used. The read rank and <lb/>order should only be used if the client knows that only reading will <lb/>ever be done or if it is prepared to switch to a different replica in <lb/>the event that any write access capability is required in the future. <lb/>11.16.2. The fs_locations_info4 Structure <lb/>The fs_locations_info4 structure, encoding the fs_locations_info <lb/>attribute, contains the following: <lb/>o The fli_flags field, which contains general flags that affect the <lb/>interpretation of this fs_locations_info4 structure and all <lb/>fs_locations_item4 structures within it. The only flag currently <lb/>defined is FSLI4IF_VAR_SUB. All bits in the fli_flags field that <lb/>are not defined should always be returned as zero. <lb/>o The fli_fs_root field, which contains the pathname of the root of <lb/>the current file system on the current server, just as it does in <lb/>the fs_locations4 structure. <lb/>o An array called fli_items of fs_locations4_item structures, which <lb/>contain information about replicas of the current file system. <lb/>Where the current file system is actually present, or has been <lb/>present, i.e., this is not a referral situation, one of the <lb/>fs_locations_item4 structures will contain an fs_locations_server4 <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 290] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>for the current server. This structure will have FSLI4GF_ABSENT <lb/>set if the current file system is absent, i.e., normal access to <lb/>it will return NFS4ERR_MOVED. <lb/>o The fli_valid_for field specifies a time in seconds for which it <lb/>is reasonable for a client to use the fs_locations_info attribute <lb/>without refetch. The fli_valid_for value does not provide a <lb/>guarantee of validity since servers can unexpectedly go out of <lb/>service or become inaccessible for any number of reasons. Clients <lb/>are well-advised to refetch this information for an actively <lb/>accessed file system at every fli_valid_for seconds. This is <lb/>particularly important when file system replicas may go out of <lb/>service in a controlled way using the FSLI4GF_GOING flag to <lb/>communicate an ongoing change. The server should set <lb/>fli_valid_for to a value that allows well-behaved clients to <lb/>notice the FSLI4GF_GOING flag and make an orderly switch before <lb/>the loss of service becomes effective. If this value is zero, <lb/>then no refetch interval is appropriate and the client need not <lb/>refetch this data on any particular schedule. In the event of a <lb/>transition to a new file system instance, a new value of the <lb/>fs_locations_info attribute will be fetched at the destination. <lb/>It is to be expected that this may have a different fli_valid_for <lb/>value, which the client should then use in the same fashion as the <lb/>previous value. Because a refetch of the attribute causes <lb/>information from all component entries to be refetched, the server <lb/>will typically provide a low value for this field if any of the <lb/>replicas are likely to go out of service in a short time frame. <lb/>Note that, because of the ability of the server to return <lb/>NFS4ERR_MOVED to trigger the use of different paths, when <lb/>alternate trunked paths are available, there is generally no need <lb/>to use low values of fli_valid_for in connection with the <lb/>management of alternate paths to the same replica. <lb/>The FSLI4IF_VAR_SUB flag within fli_flags controls whether variable <lb/>substitution is to be enabled. See Section 11.16.3 for an <lb/>explanation of variable substitution. <lb/>11.16.3. The fs_locations_item4 Structure <lb/>The fs_locations_item4 structure contains a pathname (in the field <lb/>fli_rootpath) that encodes the path of the target file system <lb/>replicas on the set of servers designated by the included <lb/>fs_locations_server4 entries. The precise manner in which this <lb/>target location is specified depends on the value of the <lb/>FSLI4IF_VAR_SUB flag within the associated fs_locations_info4 <lb/>structure. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 291] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If this flag is not set, then fli_rootpath simply designates the <lb/>location of the target file system within each server&apos;s single-server <lb/>namespace just as it does for the rootpath within the fs_location4 <lb/>structure. When this bit is set, however, component entries of a <lb/>certain form are subject to client-specific variable substitution so <lb/>as to allow a degree of namespace non-uniformity in order to <lb/>accommodate the selection of client-specific file system targets to <lb/>adapt to different client architectures or other characteristics. <lb/>When such substitution is in effect, a variable beginning with the <lb/>string &quot;${&quot; and ending with the string &quot;}&quot; and containing a colon is <lb/>to be replaced by the client-specific value associated with that <lb/>variable. The string &quot;unknown&quot; should be used by the client when it <lb/>has no value for such a variable. The pathname resulting from such <lb/>substitutions is used to designate the target file system, so that <lb/>different clients may have different file systems, corresponding to <lb/>that location in the multi-server namespace. <lb/>As mentioned above, such substituted pathname variables contain a <lb/>colon. The part before the colon is to be a DNS domain name, and the <lb/>part after is to be a case-insensitive alphanumeric string. <lb/>Where the domain is &quot;ietf.org&quot;, only variable names defined in this <lb/>document or subsequent Standards Track RFCs are subject to such <lb/>substitution. Organizations are free to use their domain names to <lb/>create their own sets of client-specific variables, to be subject to <lb/>such substitution. In cases where such variables are intended to be <lb/>used more broadly than a single organization, publication of an <lb/>Informational RFC defining such variables is RECOMMENDED. <lb/>The variable ${ietf.org:CPU_ARCH} is used to denote that the CPU <lb/>architecture object files are compiled. This specification does not <lb/>limit the acceptable values (except that they must be valid UTF-8 <lb/>strings), but such values as &quot;x86&quot;, &quot;x86_64&quot;, and &quot;sparc&quot; would be <lb/>expected to be used in line with industry practice. <lb/>The variable ${ietf.org:OS_TYPE} is used to denote the operating <lb/>system, and thus the kernel and library APIs, for which code might be <lb/>compiled. This specification does not limit the acceptable values <lb/>(except that they must be valid UTF-8 strings), but such values as <lb/>&quot;linux&quot; and &quot;freebsd&quot; would be expected to be used in line with <lb/>industry practice. <lb/>The variable ${ietf.org:OS_VERSION} is used to denote the operating <lb/>system version, and thus the specific details of versioned <lb/>interfaces, for which code might be compiled. This specification <lb/>does not limit the acceptable values (except that they must be valid <lb/>UTF-8 strings). However, combinations of numbers and letters with <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 292] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>interspersed dots would be expected to be used in line with industry <lb/>practice, with the details of the version format depending on the <lb/>specific value of the variable ${ietf.org:OS_TYPE} with which it is <lb/>used. <lb/>Use of these variables could result in the direction of different <lb/>clients to different file systems on the same server, as appropriate <lb/>to particular clients. In cases in which the target file systems are <lb/>located on different servers, a single server could serve as a <lb/>referral point so that each valid combination of variable values <lb/>would designate a referral hosted on a single server, with the <lb/>targets of those referrals on a number of different servers. <lb/>Because namespace administration is affected by the values selected <lb/>to substitute for various variables, clients should provide <lb/>convenient means of determining what variable substitutions a client <lb/>will implement, as well as, where appropriate, providing means to <lb/>control the substitutions to be used. The exact means by which this <lb/>will be done is outside the scope of this specification. <lb/>Although variable substitution is most suitable for use in the <lb/>context of referrals, it may be used in the context of replication <lb/>and migration. If it is used in these contexts, the server must <lb/>ensure that no matter what values the client presents for the <lb/>substituted variables, the result is always a valid successor file <lb/>system instance to that from which a transition is occurring, i.e., <lb/>that the data is identical or represents a later image of a writable <lb/>file system. <lb/>Note that when fli_rootpath is a null pathname (that is, one with <lb/>zero components), the file system designated is at the root of the <lb/>specified server, whether or not the FSLI4IF_VAR_SUB flag within the <lb/>associated fs_locations_info4 structure is set. <lb/>11.17. The Attribute fs_status <lb/>In an environment in which multiple copies of the same basic set of <lb/>data are available, information regarding the particular source of <lb/>such data and the relationships among different copies can be very <lb/>helpful in providing consistent data to applications. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 293] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>enum fs4_status_type { <lb/>STATUS4_FIXED = 1, <lb/>STATUS4_UPDATED = 2, <lb/>STATUS4_VERSIONED = 3, <lb/>STATUS4_WRITABLE = 4, <lb/>STATUS4_REFERRAL = 5 <lb/>}; <lb/>struct fs4_status { <lb/>bool <lb/>fss_absent; <lb/>fs4_status_type fss_type; <lb/>utf8str_cs <lb/>fss_source; <lb/>utf8str_cs <lb/>fss_current; <lb/>int32_t <lb/>fss_age; <lb/>nfstime4 <lb/>fss_version; <lb/>}; <lb/>The boolean fss_absent indicates whether the file system is currently <lb/>absent. This value will be set if the file system was previously <lb/>present and becomes absent, or if the file system has never been <lb/>present and the type is STATUS4_REFERRAL. When this boolean is set <lb/>and the type is not STATUS4_REFERRAL, the remaining information in <lb/>the fs4_status reflects that last valid when the file system was <lb/>present. <lb/>The fss_type field indicates the kind of file system image <lb/>represented. This is of particular importance when using the version <lb/>values to determine appropriate succession of file system images. <lb/>When fss_absent is set, and the file system was previously present, <lb/>the value of fss_type reflected is that when the file was last <lb/>present. Five values are distinguished: <lb/>o STATUS4_FIXED, which indicates a read-only image in the sense that <lb/>it will never change. The possibility is allowed that, as a <lb/>result of migration or switch to a different image, changed data <lb/>can be accessed, but within the confines of this instance, no <lb/>change is allowed. The client can use this fact to cache <lb/>aggressively. <lb/>o STATUS4_VERSIONED, which indicates that the image, like the <lb/>STATUS4_UPDATED case, is updated externally, but it provides a <lb/>guarantee that the server will carefully update an associated <lb/>version value so that the client can protect itself from a <lb/>situation in which it reads data from one version of the file <lb/>system and then later reads data from an earlier version of the <lb/>same file system. See below for a discussion of how this can be <lb/>done. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 294] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o STATUS4_UPDATED, which indicates an image that cannot be updated <lb/>by the user writing to it but that may be changed externally, <lb/>typically because it is a periodically updated copy of another <lb/>writable file system somewhere else. In this case, version <lb/>information is not provided, and the client does not have the <lb/>responsibility of making sure that this version only advances upon <lb/>a file system instance transition. In this case, it is the <lb/>responsibility of the server to make sure that the data presented <lb/>after a file system instance transition is a proper successor <lb/>image and includes all changes seen by the client and any change <lb/>made before all such changes. <lb/>o STATUS4_WRITABLE, which indicates that the file system is an <lb/>actual writable one. The client need not, of course, actually <lb/>write to the file system, but once it does, it should not accept a <lb/>transition to anything other than a writable instance of that same <lb/>file system. <lb/>o STATUS4_REFERRAL, which indicates that the file system in question <lb/>is absent and has never been present on this server. <lb/>Note that in the STATUS4_UPDATED and STATUS4_VERSIONED cases, the <lb/>server is responsible for the appropriate handling of locks that are <lb/>inconsistent with external changes to delegations. If a server gives <lb/>out delegations, they SHOULD be recalled before an inconsistent <lb/>change is made to the data, and MUST be revoked if this is not <lb/>possible. Similarly, if an OPEN is inconsistent with data that is <lb/>changed (the OPEN has OPEN4_SHARE_DENY_WRITE/OPEN4_SHARE_DENY_BOTH <lb/>and the data is changed), that OPEN SHOULD be considered <lb/>administratively revoked. <lb/>The opaque strings fss_source and fss_current provide a way of <lb/>presenting information about the source of the file system image <lb/>being present. It is not intended that the client do anything with <lb/>this information other than make it available to administrative <lb/>tools. It is intended that this information be helpful when <lb/>researching possible problems with a file system image that might <lb/>arise when it is unclear if the correct image is being accessed and, <lb/>if not, how that image came to be made. This kind of diagnostic <lb/>information will be helpful, if, as seems likely, copies of file <lb/>systems are made in many different ways (e.g., simple user-level <lb/>copies, file-system-level point-in-time copies, clones of the <lb/>underlying storage), under a variety of administrative arrangements. <lb/>In such environments, determining how a given set of data was <lb/>constructed can be very helpful in resolving problems. <lb/>The opaque string fss_source is used to indicate the source of a <lb/>given file system with the expectation that tools capable of creating <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 295] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>a file system image propagate this information, when possible. It is <lb/>understood that this may not always be possible since a user-level <lb/>copy may be thought of as creating a new data set and the tools used <lb/>may have no mechanism to propagate this data. When a file system is <lb/>initially created, it is desirable to associate with it data <lb/>regarding how the file system was created, where it was created, who <lb/>created it, etc. Making this information available in this attribute <lb/>in a human-readable string will be helpful for applications and <lb/>system administrators and will also serve to make it available when <lb/>the original file system is used to make subsequent copies. <lb/>The opaque string fss_current should provide whatever information is <lb/>available about the source of the current copy. Such information <lb/>includes the tool creating it, any relevant parameters to that tool, <lb/>the time at which the copy was done, the user making the change, the <lb/>server on which the change was made, etc. All information should be <lb/>in a human-readable string. <lb/>The field fss_age provides an indication of how out-of-date the file <lb/>system currently is with respect to its ultimate data source (in case <lb/>of cascading data updates). This complements the fls_currency field <lb/>of fs_locations_server4 (see Section 11.16) in the following way: the <lb/>information in fls_currency gives a bound for how out of date the <lb/>data in a file system might typically get, while the value in fss_age <lb/>gives a bound on how out-of-date that data actually is. Negative <lb/>values imply that no information is available. A zero means that <lb/>this data is known to be current. A positive value means that this <lb/>data is known to be no older than that number of seconds with respect <lb/>to the ultimate data source. Using this value, the client may be <lb/>able to decide that a data copy is too old, so that it may search for <lb/>a newer version to use. <lb/>The fss_version field provides a version identification, in the form <lb/>of a time value, such that successive versions always have later time <lb/>values. When the fs_type is anything other than STATUS4_VERSIONED, <lb/>the server may provide such a value, but there is no guarantee as to <lb/>its validity and clients will not use it except to provide additional <lb/>information to add to fss_source and fss_current. <lb/>When fss_type is STATUS4_VERSIONED, servers SHOULD provide a value of <lb/>fss_version that progresses monotonically whenever any new version of <lb/>the data is established. This allows the client, if reliable image <lb/>progression is important to it, to fetch this attribute as part of <lb/>each COMPOUND where data or metadata from the file system is used. <lb/>When it is important to the client to make sure that only valid <lb/>successor images are accepted, it must make sure that it does not <lb/>read data or metadata from the file system without updating its sense <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 296] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>of the current state of the image. This is to avoid the possibility <lb/>that the fs_status that the client holds will be one for an earlier <lb/>image, which would cause the client to accept a new file system <lb/>instance that is later than that but still earlier than the updated <lb/>data read by the client. <lb/>In order to accept valid images reliably, the client must do a <lb/>GETATTR of the fs_status attribute that follows any interrogation of <lb/>data or metadata within the file system in question. Often this is <lb/>most conveniently done by appending such a GETATTR after all other <lb/>operations that reference a given file system. When errors occur <lb/>between reading file system data and performing such a GETATTR, care <lb/>must be exercised to make sure that the data in question is not used <lb/>before obtaining the proper fs_status value. In this connection, <lb/>when an OPEN is done within such a versioned file system and the <lb/>associated GETATTR of fs_status is not successfully completed, the <lb/>open file in question must not be accessed until that fs_status is <lb/>fetched. <lb/>The procedure above will ensure that before using any data from the <lb/>file system the client has in hand a newly-fetched current version of <lb/>the file system image. Multiple values for multiple requests in <lb/>flight can be resolved by assembling them into the required partial <lb/>order (and the elements should form a total order within the partial <lb/>order) and using the last. The client may then, when switching among <lb/>file system instances, decline to use an instance that does not have <lb/>an fss_type of STATUS4_VERSIONED or whose fss_version field is <lb/>earlier than the last one obtained from the predecessor file system <lb/>instance. <lb/>12. Parallel NFS (pNFS) <lb/>12.1. Introduction <lb/>pNFS is an OPTIONAL feature within NFSv4.1; the pNFS feature set <lb/>allows direct client access to the storage devices containing file <lb/>data. When file data for a single NFSv4 server is stored on multiple <lb/>and/or higher-throughput storage devices (by comparison to the <lb/>server&apos;s throughput capability), the result can be significantly <lb/>better file access performance. The relationship among multiple <lb/>clients, a single server, and multiple storage devices for pNFS <lb/>(server and clients have access to all storage devices) is shown in <lb/>Figure 1. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 297] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>+-----------+ <lb/>|+-----------+ <lb/>+-----------+ <lb/>||+-----------+ <lb/>| <lb/>| <lb/>||| <lb/>| <lb/>NFSv4.1 + pNFS <lb/>| <lb/>| <lb/>+|| Clients |&lt;------------------------------&gt;| <lb/>Server | <lb/>+| <lb/>| <lb/>| <lb/>| <lb/>+-----------+ <lb/>| <lb/>| <lb/>||| <lb/>+-----------+ <lb/>||| <lb/>| <lb/>||| <lb/>| <lb/>||| Storage <lb/>+-----------+ <lb/>| <lb/>||| Protocol <lb/>|+-----------+ <lb/>| <lb/>||+----------------||+-----------+ Control <lb/>| <lb/>|+-----------------||| <lb/>| <lb/>Protocol| <lb/>+------------------+|| Storage |------------+ <lb/>+| Devices | <lb/>+-----------+ <lb/>Figure 1 <lb/>In this model, the clients, server, and storage devices are <lb/>responsible for managing file access. This is in contrast to NFSv4 <lb/>without pNFS, where it is primarily the server&apos;s responsibility; some <lb/>of this responsibility may be delegated to the client under strictly <lb/>specified conditions. See Section 12.2.5 for a discussion of the <lb/>Storage Protocol. See Section 12.2.6 for a discussion of the Control <lb/>Protocol. <lb/>pNFS takes the form of OPTIONAL operations that manage protocol <lb/>objects called &apos;layouts&apos; (Section 12.2.7) that contain a byte-range <lb/>and storage location information. The layout is managed in a similar <lb/>fashion as NFSv4.1 data delegations. For example, the layout is <lb/>leased, recallable, and revocable. However, layouts are distinct <lb/>abstractions and are manipulated with new operations. When a client <lb/>holds a layout, it is granted the ability to directly access the <lb/>byte-range at the storage location specified in the layout. <lb/>There are interactions between layouts and other NFSv4.1 abstractions <lb/>such as data delegations and byte-range locking. Delegation issues <lb/>are discussed in Section 12.5.5. Byte-range locking issues are <lb/>discussed in Sections 12.2.9 and 12.5.1. <lb/>12.2. pNFS Definitions <lb/>NFSv4.1&apos;s pNFS feature provides parallel data access to a file system <lb/>that stripes its content across multiple storage servers. The first <lb/>instantiation of pNFS, as part of NFSv4.1, separates the file system <lb/>protocol processing into two parts: metadata processing and data <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 298] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>processing. Data consist of the contents of regular files that are <lb/>striped across storage servers. Data striping occurs in at least two <lb/>ways: on a file-by-file basis and, within sufficiently large files, <lb/>on a block-by-block basis. In contrast, striped access to metadata <lb/>by pNFS clients is not provided in NFSv4.1, even though the file <lb/>system back end of a pNFS server might stripe metadata. Metadata <lb/>consist of everything else, including the contents of non-regular <lb/>files (e.g., directories); see Section 12.2.1. The metadata <lb/>functionality is implemented by an NFSv4.1 server that supports pNFS <lb/>and the operations described in Section 18; such a server is called a <lb/>metadata server (Section 12.2.2). <lb/>The data functionality is implemented by one or more storage devices, <lb/>each of which are accessed by the client via a storage protocol. A <lb/>subset (defined in Section 13.6) of NFSv4.1 is one such storage <lb/>protocol. New terms are introduced to the NFSv4.1 nomenclature and <lb/>existing terms are clarified to allow for the description of the pNFS <lb/>feature. <lb/>12.2.1. Metadata <lb/>Information about a file system object, such as its name, location <lb/>within the namespace, owner, ACL, and other attributes. Metadata may <lb/>also include storage location information, and this will vary based <lb/>on the underlying storage mechanism that is used. <lb/>12.2.2. Metadata Server <lb/>An NFSv4.1 server that supports the pNFS feature. A variety of <lb/>architectural choices exist for the metadata server and its use of <lb/>file system information held at the server. Some servers may contain <lb/>metadata only for file objects residing at the metadata server, while <lb/>the file data resides on associated storage devices. Other metadata <lb/>servers may hold both metadata and a varying degree of file data. <lb/>12.2.3. pNFS Client <lb/>An NFSv4.1 client that supports pNFS operations and supports at least <lb/>one storage protocol for performing I/O to storage devices. <lb/>12.2.4. Storage Device <lb/>A storage device stores a regular file&apos;s data, but leaves metadata <lb/>management to the metadata server. A storage device could be another <lb/>NFSv4.1 server, an object-based storage device (OSD), a block device <lb/>accessed over a System Area Network (SAN, e.g., either FiberChannel <lb/>or iSCSI SAN), or some other entity. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 299] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>12.2.5. Storage Protocol <lb/>As noted in Figure 1, the storage protocol is the method used by the <lb/>client to store and retrieve data directly from the storage devices. <lb/>The NFSv4.1 pNFS feature has been structured to allow for a variety <lb/>of storage protocols to be defined and used. One example storage <lb/>protocol is NFSv4.1 itself (as documented in Section 13). Other <lb/>options for the storage protocol are described elsewhere and include: <lb/>o Block/volume protocols such as Internet SCSI (iSCSI) [51] and FCP <lb/>[52]. The block/volume protocol support can be independent of the <lb/>addressing structure of the block/volume protocol used, allowing <lb/>more than one protocol to access the same file data and enabling <lb/>extensibility to other block/volume protocols. See [44] for a <lb/>layout specification that allows pNFS to use block/volume storage <lb/>protocols. <lb/>o Object protocols such as OSD over iSCSI or Fibre Channel [53]. <lb/>See [43] for a layout specification that allows pNFS to use object <lb/>storage protocols. <lb/>It is possible that various storage protocols are available to both <lb/>client and server and it may be possible that a client and server do <lb/>not have a matching storage protocol available to them. Because of <lb/>this, the pNFS server MUST support normal NFSv4.1 access to any file <lb/>accessible by the pNFS feature; this will allow for continued <lb/>interoperability between an NFSv4.1 client and server. <lb/>12.2.6. Control Protocol <lb/>As noted in Figure 1, the control protocol is used by the exported <lb/>file system between the metadata server and storage devices. <lb/>Specification of such protocols is outside the scope of the NFSv4.1 <lb/>protocol. Such control protocols would be used to control activities <lb/>such as the allocation and deallocation of storage, the management of <lb/>state required by the storage devices to perform client access <lb/>control, and, depending on the storage protocol, the enforcement of <lb/>authentication and authorization so that restrictions that would be <lb/>enforced by the metadata server are also enforced by the storage <lb/>device. <lb/>A particular control protocol is not REQUIRED by NFSv4.1 but <lb/>requirements are placed on the control protocol for maintaining <lb/>attributes like modify time, the change attribute, and the end-of-<lb/>file (EOF) position. Note that if pNFS is layered over a clustered, <lb/>parallel file system (e.g., PVFS [54]), the mechanisms that enable <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 300] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>clustering and parallelism in that file system can be considered the <lb/>control protocol. <lb/>12.2.7. Layout Types <lb/>A layout describes the mapping of a file&apos;s data to the storage <lb/>devices that hold the data. A layout is said to belong to a specific <lb/>layout type (data type layouttype4, see Section 3.3.13). The layout <lb/>type allows for variants to handle different storage protocols, such <lb/>as those associated with block/volume [44], object [43], and file <lb/>(Section 13) layout types. A metadata server, along with its control <lb/>protocol, MUST support at least one layout type. A private sub-range <lb/>of the layout type namespace is also defined. Values from the <lb/>private layout type range MAY be used for internal testing or <lb/>experimentation (see Section 3.3.13). <lb/>As an example, the organization of the file layout type could be an <lb/>array of tuples (e.g., device ID, filehandle), along with a <lb/>definition of how the data is stored across the devices (e.g., <lb/>striping). A block/volume layout might be an array of tuples that <lb/>store &lt;device ID, block number, block count&gt; along with information <lb/>about block size and the associated file offset of the block number. <lb/>An object layout might be an array of tuples &lt;device ID, object ID&gt; <lb/>and an additional structure (i.e., the aggregation map) that defines <lb/>how the logical byte sequence of the file data is serialized into the <lb/>different objects. Note that the actual layouts are typically more <lb/>complex than these simple expository examples. <lb/>Requests for pNFS-related operations will often specify a layout <lb/>type. Examples of such operations are GETDEVICEINFO and LAYOUTGET. <lb/>The response for these operations will include structures such as a <lb/>device_addr4 or a layout4, each of which includes a layout type <lb/>within it. The layout type sent by the server MUST always be the <lb/>same one requested by the client. When a server sends a response <lb/>that includes a different layout type, the client SHOULD ignore the <lb/>response and behave as if the server had returned an error response. <lb/>12.2.8. Layout <lb/>A layout defines how a file&apos;s data is organized on one or more <lb/>storage devices. There are many potential layout types; each of the <lb/>layout types are differentiated by the storage protocol used to <lb/>access data and by the aggregation scheme that lays out the file data <lb/>on the underlying storage devices. A layout is precisely identified <lb/>by the tuple &lt;client ID, filehandle, layout type, iomode, range&gt;, <lb/>where filehandle refers to the filehandle of the file on the metadata <lb/>server. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 301] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>It is important to define when layouts overlap and/or conflict with <lb/>each other. For two layouts with overlapping byte-ranges to actually <lb/>overlap each other, both layouts must be of the same layout type, <lb/>correspond to the same filehandle, and have the same iomode. Layouts <lb/>conflict when they overlap and differ in the content of the layout <lb/>(i.e., the storage device/file mapping parameters differ). Note that <lb/>differing iomodes do not lead to conflicting layouts. It is <lb/>permissible for layouts with different iomodes, pertaining to the <lb/>same byte-range, to be held by the same client. An example of this <lb/>would be copy-on-write functionality for a block/volume layout type. <lb/>12.2.9. Layout Iomode <lb/>The layout iomode (data type layoutiomode4, see Section 3.3.20) <lb/>indicates to the metadata server the client&apos;s intent to perform <lb/>either just READ operations or a mixture containing READ and WRITE <lb/>operations. For certain layout types, it is useful for a client to <lb/>specify this intent at the time it sends LAYOUTGET (Section 18.43). <lb/>For example, for block/volume-based protocols, block allocation could <lb/>occur when a LAYOUTIOMODE4_RW iomode is specified. A special <lb/>LAYOUTIOMODE4_ANY iomode is defined and can only be used for <lb/>LAYOUTRETURN and CB_LAYOUTRECALL, not for LAYOUTGET. It specifies <lb/>that layouts pertaining to both LAYOUTIOMODE4_READ and <lb/>LAYOUTIOMODE4_RW iomodes are being returned or recalled, <lb/>respectively. <lb/>A storage device may validate I/O with regard to the iomode; this is <lb/>dependent upon storage device implementation and layout type. Thus, <lb/>if the client&apos;s layout iomode is inconsistent with the I/O being <lb/>performed, the storage device may reject the client&apos;s I/O with an <lb/>error indicating that a new layout with the correct iomode should be <lb/>obtained via LAYOUTGET. For example, if a client gets a layout with <lb/>a LAYOUTIOMODE4_READ iomode and performs a WRITE to a storage device, <lb/>the storage device is allowed to reject that WRITE. <lb/>The use of the layout iomode does not conflict with OPEN share modes <lb/>or byte-range LOCK operations; open share mode and byte-range lock <lb/>conflicts are enforced as they are without the use of pNFS and are <lb/>logically separate from the pNFS layout level. Open share modes and <lb/>byte-range locks are the preferred method for restricting user access <lb/>to data files. For example, an OPEN of OPEN4_SHARE_ACCESS_WRITE does <lb/>not conflict with a LAYOUTGET containing an iomode of <lb/>LAYOUTIOMODE4_RW performed by another client. Applications that <lb/>depend on writing into the same file concurrently may use byte-range <lb/>locking to serialize their accesses. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 302] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>12.2.10. Device IDs <lb/>The device ID (data type deviceid4, see Section 3.3.14) identifies a <lb/>group of storage devices. The scope of a device ID is the pair <lb/>&lt;client ID, layout type&gt;. In practice, a significant amount of <lb/>information may be required to fully address a storage device. <lb/>Rather than embedding all such information in a layout, layouts embed <lb/>device IDs. The NFSv4.1 operation GETDEVICEINFO (Section 18.40) is <lb/>used to retrieve the complete address information (including all <lb/>device addresses for the device ID) regarding the storage device <lb/>according to its layout type and device ID. For example, the address <lb/>of an NFSv4.1 data server or of an object-based storage device could <lb/>be an IP address and port. The address of a block storage device <lb/>could be a volume label. <lb/>Clients cannot expect the mapping between a device ID and its storage <lb/>device address(es) to persist across metadata server restart. See <lb/>Section 12.7.4 for a description of how recovery works in that <lb/>situation. <lb/>A device ID lives as long as there is a layout referring to the <lb/>device ID. If there are no layouts referring to the device ID, the <lb/>server is free to delete the device ID any time. Once a device ID is <lb/>deleted by the server, the server MUST NOT reuse the device ID for <lb/>the same layout type and client ID again. This requirement is <lb/>feasible because the device ID is 16 bytes long, leaving sufficient <lb/>room to store a generation number if the server&apos;s implementation <lb/>requires most of the rest of the device ID&apos;s content to be reused. <lb/>This requirement is necessary because otherwise the race conditions <lb/>between asynchronous notification of device ID addition and deletion <lb/>would be too difficult to sort out. <lb/>Device ID to device address mappings are not leased, and can be <lb/>changed at any time. (Note that while device ID to device address <lb/>mappings are likely to change after the metadata server restarts, the <lb/>server is not required to change the mappings.) A server has two <lb/>choices for changing mappings. It can recall all layouts referring <lb/>to the device ID or it can use a notification mechanism. <lb/>The NFSv4.1 protocol has no optimal way to recall all layouts that <lb/>referred to a particular device ID (unless the server associates a <lb/>single device ID with a single fsid or a single client ID; in which <lb/>case, CB_LAYOUTRECALL has options for recalling all layouts <lb/>associated with the fsid, client ID pair, or just the client ID). <lb/>Via a notification mechanism (see Section 20.12), device ID to device <lb/>address mappings can change over the duration of server operation <lb/>without recalling or revoking the layouts that refer to device ID. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 303] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The notification mechanism can also delete a device ID, but only if <lb/>the client has no layouts referring to the device ID. A notification <lb/>of a change to a device ID to device address mapping will immediately <lb/>or eventually invalidate some or all of the device ID&apos;s mappings. <lb/>The server MUST support notifications and the client must request <lb/>them before they can be used. For further information about the <lb/>notification types Section 20.12. <lb/>12.3. pNFS Operations <lb/>NFSv4.1 has several operations that are needed for pNFS servers, <lb/>regardless of layout type or storage protocol. These operations are <lb/>all sent to a metadata server and summarized here. While pNFS is an <lb/>OPTIONAL feature, if pNFS is implemented, some operations are <lb/>REQUIRED in order to comply with pNFS. See Section 17. <lb/>These are the fore channel pNFS operations: <lb/>GETDEVICEINFO (Section 18.40), as noted previously <lb/>(Section 12.2.10), returns the mapping of device ID to storage <lb/>device address. <lb/>GETDEVICELIST (Section 18.41) allows clients to fetch all device IDs <lb/>for a specific file system. <lb/>LAYOUTGET (Section 18.43) is used by a client to get a layout for a <lb/>file. <lb/>LAYOUTCOMMIT (Section 18.42) is used to inform the metadata server <lb/>of the client&apos;s intent to commit data that has been written to the <lb/>storage device (the storage device as originally indicated in the <lb/>return value of LAYOUTGET). <lb/>LAYOUTRETURN (Section 18.44) is used to return layouts for a file, a <lb/>file system ID (FSID), or a client ID. <lb/>These are the backchannel pNFS operations: <lb/>CB_LAYOUTRECALL (Section 20.3) recalls a layout, all layouts <lb/>belonging to a file system, or all layouts belonging to a client <lb/>ID. <lb/>CB_RECALL_ANY (Section 20.6) tells a client that it needs to return <lb/>some number of recallable objects, including layouts, to the <lb/>metadata server. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 304] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>CB_RECALLABLE_OBJ_AVAIL (Section 20.7) tells a client that a <lb/>recallable object that it was denied (in case of pNFS, a layout <lb/>denied by LAYOUTGET) due to resource exhaustion is now available. <lb/>CB_NOTIFY_DEVICEID (Section 20.12) notifies the client of changes to <lb/>device IDs. <lb/>12.4. pNFS Attributes <lb/>A number of attributes specific to pNFS are listed and described in <lb/>Section 5.12. <lb/>12.5. Layout Semantics <lb/>12.5.1. Guarantees Provided by Layouts <lb/>Layouts grant to the client the ability to access data located at a <lb/>storage device with the appropriate storage protocol. The client is <lb/>guaranteed the layout will be recalled when one of two things occur: <lb/>either a conflicting layout is requested or the state encapsulated by <lb/>the layout becomes invalid (this can happen when an event directly or <lb/>indirectly modifies the layout). When a layout is recalled and <lb/>returned by the client, the client continues with the ability to <lb/>access file data with normal NFSv4.1 operations through the metadata <lb/>server. Only the ability to access the storage devices is affected. <lb/>The requirement of NFSv4.1 that all user access rights MUST be <lb/>obtained through the appropriate OPEN, LOCK, and ACCESS operations is <lb/>not modified with the existence of layouts. Layouts are provided to <lb/>NFSv4.1 clients, and user access still follows the rules of the <lb/>protocol as if they did not exist. It is a requirement that for a <lb/>client to access a storage device, a layout must be held by the <lb/>client. If a storage device receives an I/O request for a byte-range <lb/>for which the client does not hold a layout, the storage device <lb/>SHOULD reject that I/O request. Note that the act of modifying a <lb/>file for which a layout is held does not necessarily conflict with <lb/>the holding of the layout that describes the file being modified. <lb/>Therefore, it is the requirement of the storage protocol or layout <lb/>type that determines the necessary behavior. For example, block/ <lb/>volume layout types require that the layout&apos;s iomode agree with the <lb/>type of I/O being performed. <lb/>Depending upon the layout type and storage protocol in use, storage <lb/>device access permissions may be granted by LAYOUTGET and may be <lb/>encoded within the type-specific layout. For an example of storage <lb/>device access permissions, see an object-based protocol such as [53]. <lb/>If access permissions are encoded within the layout, the metadata <lb/>server SHOULD recall the layout when those permissions become invalid <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 305] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>for any reason --for example, when a file becomes unwritable or <lb/>inaccessible to a client. Note, clients are still required to <lb/>perform the appropriate OPEN, LOCK, and ACCESS operations as <lb/>described above. The degree to which it is possible for the client <lb/>to circumvent these operations and the consequences of doing so must <lb/>be clearly specified by the individual layout type specifications. <lb/>In addition, these specifications must be clear about the <lb/>requirements and non-requirements for the checking performed by the <lb/>server. <lb/>In the presence of pNFS functionality, mandatory byte-range locks <lb/>MUST behave as they would without pNFS. Therefore, if mandatory file <lb/>locks and layouts are provided simultaneously, the storage device <lb/>MUST be able to enforce the mandatory byte-range locks. For example, <lb/>if one client obtains a mandatory byte-range lock and a second client <lb/>accesses the storage device, the storage device MUST appropriately <lb/>restrict I/O for the range of the mandatory byte-range lock. If the <lb/>storage device is incapable of providing this check in the presence <lb/>of mandatory byte-range locks, then the metadata server MUST NOT <lb/>grant layouts and mandatory byte-range locks simultaneously. <lb/>12.5.2. Getting a Layout <lb/>A client obtains a layout with the LAYOUTGET operation. The metadata <lb/>server will grant layouts of a particular type (e.g., block/volume, <lb/>object, or file). The client selects an appropriate layout type that <lb/>the server supports and the client is prepared to use. The layout <lb/>returned to the client might not exactly match the requested byte-<lb/>range as described in Section 18.43.3. As needed a client may send <lb/>multiple LAYOUTGET operations; these might result in multiple <lb/>overlapping, non-conflicting layouts (see Section 12.2.8). <lb/>In order to get a layout, the client must first have opened the file <lb/>via the OPEN operation. When a client has no layout on a file, it <lb/>MUST present an open stateid, a delegation stateid, or a byte-range <lb/>lock stateid in the loga_stateid argument. A successful LAYOUTGET <lb/>result includes a layout stateid. The first successful LAYOUTGET <lb/>processed by the server using a non-layout stateid as an argument <lb/>MUST have the &quot;seqid&quot; field of the layout stateid in the response set <lb/>to one. Thereafter, the client MUST use a layout stateid (see <lb/>Section 12.5.3) on future invocations of LAYOUTGET on the file, and <lb/>the &quot;seqid&quot; MUST NOT be set to zero. Once the layout has been <lb/>retrieved, it can be held across multiple OPEN and CLOSE sequences. <lb/>Therefore, a client may hold a layout for a file that is not <lb/>currently open by any user on the client. This allows for the <lb/>caching of layouts beyond CLOSE. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 306] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The storage protocol used by the client to access the data on the <lb/>storage device is determined by the layout&apos;s type. The client is <lb/>responsible for matching the layout type with an available method to <lb/>interpret and use the layout. The method for this layout type <lb/>selection is outside the scope of the pNFS functionality. <lb/>Although the metadata server is in control of the layout for a file, <lb/>the pNFS client can provide hints to the server when a file is opened <lb/>or created about the preferred layout type and aggregation schemes. <lb/>pNFS introduces a layout_hint attribute (Section 5.12.4) that the <lb/>client can set at file creation time to provide a hint to the server <lb/>for new files. Setting this attribute separately, after the file has <lb/>been created might make it difficult, or impossible, for the server <lb/>implementation to comply. <lb/>Because the EXCLUSIVE4 createmode4 does not allow the setting of <lb/>attributes at file creation time, NFSv4.1 introduces the EXCLUSIVE4_1 <lb/>createmode4, which does allow attributes to be set at file creation <lb/>time. In addition, if the session is created with persistent reply <lb/>caches, EXCLUSIVE4_1 is neither necessary nor allowed. Instead, <lb/>GUARDED4 both works better and is prescribed. Table 10 in <lb/>Section 18.16.3 summarizes how a client is allowed to send an <lb/>exclusive create. <lb/>12.5.3. Layout Stateid <lb/>As with all other stateids, the layout stateid consists of a &quot;seqid&quot; <lb/>and &quot;other&quot; field. Once a layout stateid is established, the &quot;other&quot; <lb/>field will stay constant unless the stateid is revoked or the client <lb/>returns all layouts on the file and the server disposes of the <lb/>stateid. The &quot;seqid&quot; field is initially set to one, and is never <lb/>zero on any NFSv4.1 operation that uses layout stateids, whether it <lb/>is a fore channel or backchannel operation. After the layout stateid <lb/>is established, the server increments by one the value of the &quot;seqid&quot; <lb/>in each subsequent LAYOUTGET and LAYOUTRETURN response, and in each <lb/>CB_LAYOUTRECALL request. <lb/>Given the design goal of pNFS to provide parallelism, the layout <lb/>stateid differs from other stateid types in that the client is <lb/>expected to send LAYOUTGET and LAYOUTRETURN operations in parallel. <lb/>The &quot;seqid&quot; value is used by the client to properly sort responses to <lb/>LAYOUTGET and LAYOUTRETURN. The &quot;seqid&quot; is also used to prevent race <lb/>conditions between LAYOUTGET and CB_LAYOUTRECALL. Given that the <lb/>processing rules differ from layout stateids and other stateid types, <lb/>only the pNFS sections of this document should be considered to <lb/>determine proper layout stateid handling. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 307] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Once the client receives a layout stateid, it MUST use the correct <lb/>&quot;seqid&quot; for subsequent LAYOUTGET or LAYOUTRETURN operations. The <lb/>correct &quot;seqid&quot; is defined as the highest &quot;seqid&quot; value from <lb/>responses of fully processed LAYOUTGET or LAYOUTRETURN operations or <lb/>arguments of a fully processed CB_LAYOUTRECALL operation. Since the <lb/>server is incrementing the &quot;seqid&quot; value on each layout operation, <lb/>the client may determine the order of operation processing by <lb/>inspecting the &quot;seqid&quot; value. In the case of overlapping layout <lb/>ranges, the ordering information will provide the client the <lb/>knowledge of which layout ranges are held. Note that overlapping <lb/>layout ranges may occur because of the client&apos;s specific requests or <lb/>because the server is allowed to expand the range of a requested <lb/>layout and notify the client in the LAYOUTRETURN results. Additional <lb/>layout stateid sequencing requirements are provided in <lb/>Section 12.5.5.2. <lb/>The client&apos;s receipt of a &quot;seqid&quot; is not sufficient for subsequent <lb/>use. The client must fully process the operations before the &quot;seqid&quot; <lb/>can be used. For LAYOUTGET results, if the client is not using the <lb/>forgetful model (Section 12.5.5.1), it MUST first update its record <lb/>of what ranges of the file&apos;s layout it has before using the seqid. <lb/>For LAYOUTRETURN results, the client MUST delete the range from its <lb/>record of what ranges of the file&apos;s layout it had before using the <lb/>seqid. For CB_LAYOUTRECALL arguments, the client MUST send a <lb/>response to the recall before using the seqid. The fundamental <lb/>requirement in client processing is that the &quot;seqid&quot; is used to <lb/>provide the order of processing. LAYOUTGET results may be processed <lb/>in parallel. LAYOUTRETURN results may be processed in parallel. <lb/>LAYOUTGET and LAYOUTRETURN responses may be processed in parallel as <lb/>long as the ranges do not overlap. CB_LAYOUTRECALL request <lb/>processing MUST be processed in &quot;seqid&quot; order at all times. <lb/>Once a client has no more layouts on a file, the layout stateid is no <lb/>longer valid and MUST NOT be used. Any attempt to use such a layout <lb/>stateid will result in NFS4ERR_BAD_STATEID. <lb/>12.5.4. Committing a Layout <lb/>Allowing for varying storage protocol capabilities, the pNFS protocol <lb/>does not require the metadata server and storage devices to have a <lb/>consistent view of file attributes and data location mappings. Data <lb/>location mapping refers to aspects such as which offsets store data <lb/>as opposed to storing holes (see Section 13.4.4 for a discussion). <lb/>Related issues arise for storage protocols where a layout may hold <lb/>provisionally allocated blocks where the allocation of those blocks <lb/>does not survive a complete restart of both the client and server. <lb/>Because of this inconsistency, it is necessary to resynchronize the <lb/>client with the metadata server and its storage devices and make any <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 308] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>potential changes available to other clients. This is accomplished <lb/>by use of the LAYOUTCOMMIT operation. <lb/>The LAYOUTCOMMIT operation is responsible for committing a modified <lb/>layout to the metadata server. The data should be written and <lb/>committed to the appropriate storage devices before the LAYOUTCOMMIT <lb/>occurs. The scope of the LAYOUTCOMMIT operation depends on the <lb/>storage protocol in use. It is important to note that the level of <lb/>synchronization is from the point of view of the client that sent the <lb/>LAYOUTCOMMIT. The updated state on the metadata server need only <lb/>reflect the state as of the client&apos;s last operation previous to the <lb/>LAYOUTCOMMIT. The metadata server is not REQUIRED to maintain a <lb/>global view that accounts for other clients&apos; I/O that may have <lb/>occurred within the same time frame. <lb/>For block/volume-based layouts, LAYOUTCOMMIT may require updating the <lb/>block list that comprises the file and committing this layout to <lb/>stable storage. For file-based layouts, synchronization of <lb/>attributes between the metadata and storage devices, primarily the <lb/>size attribute, is required. <lb/>The control protocol is free to synchronize the attributes before it <lb/>receives a LAYOUTCOMMIT; however, upon successful completion of a <lb/>LAYOUTCOMMIT, state that exists on the metadata server that describes <lb/>the file MUST be synchronized with the state that exists on the <lb/>storage devices that comprise that file as of the client&apos;s last sent <lb/>operation. Thus, a client that queries the size of a file between a <lb/>WRITE to a storage device and the LAYOUTCOMMIT might observe a size <lb/>that does not reflect the actual data written. <lb/>The client MUST have a layout in order to send a LAYOUTCOMMIT <lb/>operation. <lb/>12.5.4.1. LAYOUTCOMMIT and change/time_modify <lb/>The change and time_modify attributes may be updated by the server <lb/>when the LAYOUTCOMMIT operation is processed. The reason for this is <lb/>that some layout types do not support the update of these attributes <lb/>when the storage devices process I/O operations. If a client has a <lb/>layout with the LAYOUTIOMODE4_RW iomode on the file, the client MAY <lb/>provide a suggested value to the server for time_modify within the <lb/>arguments to LAYOUTCOMMIT. Based on the layout type, the provided <lb/>value may or may not be used. The server should sanity-check the <lb/>client-provided values before they are used. For example, the server <lb/>should ensure that time does not flow backwards. The client always <lb/>has the option to set time_modify through an explicit SETATTR <lb/>operation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 309] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>For some layout protocols, the storage device is able to notify the <lb/>metadata server of the occurrence of an I/O; as a result, the change <lb/>and time_modify attributes may be updated at the metadata server. <lb/>For a metadata server that is capable of monitoring updates to the <lb/>change and time_modify attributes, LAYOUTCOMMIT processing is not <lb/>required to update the change attribute. In this case, the metadata <lb/>server must ensure that no further update to the data has occurred <lb/>since the last update of the attributes; file-based protocols may <lb/>have enough information to make this determination or may update the <lb/>change attribute upon each file modification. This also applies for <lb/>the time_modify attribute. If the server implementation is able to <lb/>determine that the file has not been modified since the last <lb/>time_modify update, the server need not update time_modify at <lb/>LAYOUTCOMMIT. At LAYOUTCOMMIT completion, the updated attributes <lb/>should be visible if that file was modified since the latest previous <lb/>LAYOUTCOMMIT or LAYOUTGET. <lb/>12.5.4.2. LAYOUTCOMMIT and size <lb/>The size of a file may be updated when the LAYOUTCOMMIT operation is <lb/>used by the client. One of the fields in the argument to <lb/>LAYOUTCOMMIT is loca_last_write_offset; this field indicates the <lb/>highest byte offset written but not yet committed with the <lb/>LAYOUTCOMMIT operation. The data type of loca_last_write_offset is <lb/>newoffset4 and is switched on a boolean value, no_newoffset, that <lb/>indicates if a previous write occurred or not. If no_newoffset is <lb/>FALSE, an offset is not given. If the client has a layout with <lb/>LAYOUTIOMODE4_RW iomode on the file, with a byte-range (denoted by <lb/>the values of lo_offset and lo_length) that overlaps <lb/>loca_last_write_offset, then the client MAY set no_newoffset to TRUE <lb/>and provide an offset that will update the file size. Keep in mind <lb/>that offset is not the same as length, though they are related. For <lb/>example, a loca_last_write_offset value of zero means that one byte <lb/>was written at offset zero, and so the length of the file is at least <lb/>one byte. <lb/>The metadata server may do one of the following: <lb/>1. Update the file&apos;s size using the last write offset provided by <lb/>the client as either the true file size or as a hint of the file <lb/>size. If the metadata server has a method available, any new <lb/>value for file size should be sanity-checked. For example, the <lb/>file must not be truncated if the client presents a last write <lb/>offset less than the file&apos;s current size. <lb/>2. Ignore the client-provided last write offset; the metadata server <lb/>must have sufficient knowledge from other sources to determine <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 310] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the file&apos;s size. For example, the metadata server queries the <lb/>storage devices with the control protocol. <lb/>The method chosen to update the file&apos;s size will depend on the <lb/>storage device&apos;s and/or the control protocol&apos;s capabilities. For <lb/>example, if the storage devices are block devices with no knowledge <lb/>of file size, the metadata server must rely on the client to set the <lb/>last write offset appropriately. <lb/>The results of LAYOUTCOMMIT contain a new size value in the form of a <lb/>newsize4 union data type. If the file&apos;s size is set as a result of <lb/>LAYOUTCOMMIT, the metadata server must reply with the new size; <lb/>otherwise, the new size is not provided. If the file size is <lb/>updated, the metadata server SHOULD update the storage devices such <lb/>that the new file size is reflected when LAYOUTCOMMIT processing is <lb/>complete. For example, the client should be able to read up to the <lb/>new file size. <lb/>The client can extend the length of a file or truncate a file by <lb/>sending a SETATTR operation to the metadata server with the size <lb/>attribute specified. If the size specified is larger than the <lb/>current size of the file, the file is &quot;zero extended&quot;, i.e., zeros <lb/>are implicitly added between the file&apos;s previous EOF and the new EOF. <lb/>(In many implementations, the zero-extended byte-range of the file <lb/>consists of unallocated holes in the file.) When the client writes <lb/>past EOF via WRITE, the SETATTR operation does not need to be used. <lb/>12.5.4.3. LAYOUTCOMMIT and layoutupdate <lb/>The LAYOUTCOMMIT argument contains a loca_layoutupdate field <lb/>(Section 18.42.1) of data type layoutupdate4 (Section 3.3.18). This <lb/>argument is a layout-type-specific structure. The structure can be <lb/>used to pass arbitrary layout-type-specific information from the <lb/>client to the metadata server at LAYOUTCOMMIT time. For example, if <lb/>using a block/volume layout, the client can indicate to the metadata <lb/>server which reserved or allocated blocks the client used or did not <lb/>use. The content of loca_layoutupdate (field lou_body) need not be <lb/>the same layout-type-specific content returned by LAYOUTGET <lb/>(Section 18.43.2) in the loc_body field of the lo_content field of <lb/>the logr_layout field. The content of loca_layoutupdate is defined <lb/>by the layout type specification and is opaque to LAYOUTCOMMIT. <lb/>12.5.5. Recalling a Layout <lb/>Since a layout protects a client&apos;s access to a file via a direct <lb/>client-storage-device path, a layout need only be recalled when it is <lb/>semantically unable to serve this function. Typically, this occurs <lb/>when the layout no longer encapsulates the true location of the file <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 311] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>over the byte-range it represents. Any operation or action, such as <lb/>server-driven restriping or load balancing, that changes the layout <lb/>will result in a recall of the layout. A layout is recalled by the <lb/>CB_LAYOUTRECALL callback operation (see Section 20.3) and returned <lb/>with LAYOUTRETURN (see Section 18.44). The CB_LAYOUTRECALL operation <lb/>may recall a layout identified by a byte-range, all layouts <lb/>associated with a file system ID (FSID), or all layouts associated <lb/>with a client ID. Section 12.5.5.2 discusses sequencing issues <lb/>surrounding the getting, returning, and recalling of layouts. <lb/>An iomode is also specified when recalling a layout. Generally, the <lb/>iomode in the recall request must match the layout being returned; <lb/>for example, a recall with an iomode of LAYOUTIOMODE4_RW should cause <lb/>the client to only return LAYOUTIOMODE4_RW layouts and not <lb/>LAYOUTIOMODE4_READ layouts. However, a special LAYOUTIOMODE4_ANY <lb/>enumeration is defined to enable recalling a layout of any iomode; in <lb/>other words, the client must return both LAYOUTIOMODE4_READ and <lb/>LAYOUTIOMODE4_RW layouts. <lb/>A REMOVE operation SHOULD cause the metadata server to recall the <lb/>layout to prevent the client from accessing a non-existent file and <lb/>to reclaim state stored on the client. Since a REMOVE may be delayed <lb/>until the last close of the file has occurred, the recall may also be <lb/>delayed until this time. After the last reference on the file has <lb/>been released and the file has been removed, the client should no <lb/>longer be able to perform I/O using the layout. In the case of a <lb/>file-based layout, the data server SHOULD return NFS4ERR_STALE in <lb/>response to any operation on the removed file. <lb/>Once a layout has been returned, the client MUST NOT send I/Os to the <lb/>storage devices for the file, byte-range, and iomode represented by <lb/>the returned layout. If a client does send an I/O to a storage <lb/>device for which it does not hold a layout, the storage device SHOULD <lb/>reject the I/O. <lb/>Although pNFS does not alter the file data caching capabilities of <lb/>clients, or their semantics, it recognizes that some clients may <lb/>perform more aggressive write-behind caching to optimize the benefits <lb/>provided by pNFS. However, write-behind caching may negatively <lb/>affect the latency in returning a layout in response to a <lb/>CB_LAYOUTRECALL; this is similar to file delegations and the impact <lb/>that file data caching has on DELEGRETURN. Client implementations <lb/>SHOULD limit the amount of unwritten data they have outstanding at <lb/>any one time in order to prevent excessively long responses to <lb/>CB_LAYOUTRECALL. Once a layout is recalled, a server MUST wait one <lb/>lease period before taking further action. As soon as a lease period <lb/>has passed, the server may choose to fence the client&apos;s access to the <lb/>storage devices if the server perceives the client has taken too long <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 312] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>to return a layout. However, just as in the case of data delegation <lb/>and DELEGRETURN, the server may choose to wait, given that the client <lb/>is showing forward progress on its way to returning the layout. This <lb/>forward progress can take the form of successful interaction with the <lb/>storage devices or of sub-portions of the layout being returned by <lb/>the client. The server can also limit exposure to these problems by <lb/>limiting the byte-ranges initially provided in the layouts and thus <lb/>the amount of outstanding modified data. <lb/>12.5.5.1. Layout Recall Callback Robustness <lb/>It has been assumed thus far that pNFS client state (layout ranges <lb/>and iomode) for a file exactly matches that of the pNFS server for <lb/>that file. This assumption leads to the implication that any <lb/>callback results in a LAYOUTRETURN or set of LAYOUTRETURNs that <lb/>exactly match the range in the callback, since both client and server <lb/>agree about the state being maintained. However, it can be useful if <lb/>this assumption does not always hold. For example: <lb/>o If conflicts that require callbacks are very rare, and a server <lb/>can use a multi-file callback to recover per-client resources <lb/>(e.g., via an FSID recall or a multi-file recall within a single <lb/>CB_COMPOUND), the result may be significantly less client-server <lb/>pNFS traffic. <lb/>o It may be useful for servers to maintain information about what <lb/>ranges are held by a client on a coarse-grained basis, leading to <lb/>the server&apos;s layout ranges being beyond those actually held by the <lb/>client. In the extreme, a server could manage conflicts on a per-<lb/>file basis, only sending whole-file callbacks even though clients <lb/>may request and be granted sub-file ranges. <lb/>o It may be useful for clients to &quot;forget&quot; details about what <lb/>layouts and ranges the client actually has, leading to the <lb/>server&apos;s layout ranges being beyond those that the client &quot;thinks&quot; <lb/>it has. As long as the client does not assume it has layouts that <lb/>are beyond what the server has granted, this is a safe practice. <lb/>When a client forgets what ranges and layouts it has, and it <lb/>receives a CB_LAYOUTRECALL operation, the client MUST follow up <lb/>with a LAYOUTRETURN for what the server recalled, or alternatively <lb/>return the NFS4ERR_NOMATCHING_LAYOUT error if it has no layout to <lb/>return in the recalled range. <lb/>o In order to avoid errors, it is vital that a client not assign <lb/>itself layout permissions beyond what the server has granted, and <lb/>that the server not forget layout permissions that have been <lb/>granted. On the other hand, if a server believes that a client <lb/>holds a layout that the client does not know about, it is useful <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 313] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>for the client to cleanly indicate completion of the requested <lb/>recall either by sending a LAYOUTRETURN operation for the entire <lb/>requested range or by returning an NFS4ERR_NOMATCHING_LAYOUT error <lb/>to the CB_LAYOUTRECALL. <lb/>Thus, in light of the above, it is useful for a server to be able to <lb/>send callbacks for layout ranges it has not granted to a client, and <lb/>for a client to return ranges it does not hold. A pNFS client MUST <lb/>always return layouts that comprise the full range specified by the <lb/>recall. Note, the full recalled layout range need not be returned as <lb/>part of a single operation, but may be returned in portions. This <lb/>allows the client to stage the flushing of dirty data and commits and <lb/>returns of layouts. Also, it indicates to the metadata server that <lb/>the client is making progress. <lb/>When a layout is returned, the client MUST NOT have any outstanding <lb/>I/O requests to the storage devices involved in the layout. <lb/>Rephrasing, the client MUST NOT return the layout while it has <lb/>outstanding I/O requests to the storage device. <lb/>Even with this requirement for the client, it is possible that I/O <lb/>requests may be presented to a storage device no longer allowed to <lb/>perform them. Since the server has no strict control as to when the <lb/>client will return the layout, the server may later decide to <lb/>unilaterally revoke the client&apos;s access to the storage devices as <lb/>provided by the layout. In choosing to revoke access, the server <lb/>must deal with the possibility of lingering I/O requests, i.e., I/O <lb/>requests that are still in flight to storage devices identified by <lb/>the revoked layout. All layout type specifications MUST define <lb/>whether unilateral layout revocation by the metadata server is <lb/>supported; if it is, the specification must also describe how <lb/>lingering writes are processed. For example, storage devices <lb/>identified by the revoked layout could be fenced off from the client <lb/>that held the layout. <lb/>In order to ensure client/server convergence with regard to layout <lb/>state, the final LAYOUTRETURN operation in a sequence of LAYOUTRETURN <lb/>operations for a particular recall MUST specify the entire range <lb/>being recalled, echoing the recalled layout type, iomode, recall/ <lb/>return type (FILE, FSID, or ALL), and byte-range, even if layouts <lb/>pertaining to partial ranges were previously returned. In addition, <lb/>if the client holds no layouts that overlap the range being recalled, <lb/>the client should return the NFS4ERR_NOMATCHING_LAYOUT error code to <lb/>CB_LAYOUTRECALL. This allows the server to update its view of the <lb/>client&apos;s layout state. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 314] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>12.5.5.2. Sequencing of Layout Operations <lb/>As with other stateful operations, pNFS requires the correct <lb/>sequencing of layout operations. pNFS uses the &quot;seqid&quot; in the layout <lb/>stateid to provide the correct sequencing between regular operations <lb/>and callbacks. It is the server&apos;s responsibility to avoid <lb/>inconsistencies regarding the layouts provided and the client&apos;s <lb/>responsibility to properly serialize its layout requests and layout <lb/>returns. <lb/>12.5.5.2.1. Layout Recall and Return Sequencing <lb/>One critical issue with regard to layout operations sequencing <lb/>concerns callbacks. The protocol must defend against races between <lb/>the reply to a LAYOUTGET or LAYOUTRETURN operation and a subsequent <lb/>CB_LAYOUTRECALL. A client MUST NOT process a CB_LAYOUTRECALL that <lb/>implies one or more outstanding LAYOUTGET or LAYOUTRETURN operations <lb/>to which the client has not yet received a reply. The client detects <lb/>such a CB_LAYOUTRECALL by examining the &quot;seqid&quot; field of the recall&apos;s <lb/>layout stateid. If the &quot;seqid&quot; is not exactly one higher than what <lb/>the client currently has recorded, and the client has at least one <lb/>LAYOUTGET and/or LAYOUTRETURN operation outstanding, the client knows <lb/>the server sent the CB_LAYOUTRECALL after sending a response to an <lb/>outstanding LAYOUTGET or LAYOUTRETURN. The client MUST wait before <lb/>processing such a CB_LAYOUTRECALL until it processes all replies for <lb/>outstanding LAYOUTGET and LAYOUTRETURN operations for the <lb/>corresponding file with seqid less than the seqid given by <lb/>CB_LAYOUTRECALL (lor_stateid; see Section 20.3.) <lb/>In addition to the seqid-based mechanism, Section 2.10.6.3 describes <lb/>the sessions mechanism for allowing the client to detect callback <lb/>race conditions and delay processing such a CB_LAYOUTRECALL. The <lb/>server MAY reference conflicting operations in the CB_SEQUENCE that <lb/>precedes the CB_LAYOUTRECALL. Because the server has already sent <lb/>replies for these operations before sending the callback, the replies <lb/>may race with the CB_LAYOUTRECALL. The client MUST wait for all the <lb/>referenced calls to complete and update its view of the layout state <lb/>before processing the CB_LAYOUTRECALL. <lb/>12.5.5.2.1.1. Get/Return Sequencing <lb/>The protocol allows the client to send concurrent LAYOUTGET and <lb/>LAYOUTRETURN operations to the server. The protocol does not provide <lb/>any means for the server to process the requests in the same order in <lb/>which they were created. However, through the use of the &quot;seqid&quot; <lb/>field in the layout stateid, the client can determine the order in <lb/>which parallel outstanding operations were processed by the server. <lb/>Thus, when a layout retrieved by an outstanding LAYOUTGET operation <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 315] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>intersects with a layout returned by an outstanding LAYOUTRETURN on <lb/>the same file, the order in which the two conflicting operations are <lb/>processed determines the final state of the overlapping layout. The <lb/>order is determined by the &quot;seqid&quot; returned in each operation: the <lb/>operation with the higher seqid was executed later. <lb/>It is permissible for the client to send multiple parallel LAYOUTGET <lb/>operations for the same file or multiple parallel LAYOUTRETURN <lb/>operations for the same file or a mix of both. <lb/>It is permissible for the client to use the current stateid (see <lb/>Section 16.2.3.1.2) for LAYOUTGET operations, for example, when <lb/>compounding LAYOUTGETs or compounding OPEN and LAYOUTGETs. It is <lb/>also permissible to use the current stateid when compounding <lb/>LAYOUTRETURNs. <lb/>It is permissible for the client to use the current stateid when <lb/>combining LAYOUTRETURN and LAYOUTGET operations for the same file in <lb/>the same COMPOUND request since the server MUST process these in <lb/>order. However, if a client does send such COMPOUND requests, it <lb/>MUST NOT have more than one outstanding for the same file at the same <lb/>time, and it MUST NOT have other LAYOUTGET or LAYOUTRETURN operations <lb/>outstanding at the same time for that same file. <lb/>12.5.5.2.1.2. Client Considerations <lb/>Consider a pNFS client that has sent a LAYOUTGET, and before it <lb/>receives the reply to LAYOUTGET, it receives a CB_LAYOUTRECALL for <lb/>the same file with an overlapping range. There are two <lb/>possibilities, which the client can distinguish via the layout <lb/>stateid in the recall. <lb/>1. The server processed the LAYOUTGET before sending the recall, so <lb/>the LAYOUTGET must be waited for because it may be carrying <lb/>layout information that will need to be returned to deal with the <lb/>CB_LAYOUTRECALL. <lb/>2. The server sent the callback before receiving the LAYOUTGET. The <lb/>server will not respond to the LAYOUTGET until the <lb/>CB_LAYOUTRECALL is processed. <lb/>If these possibilities cannot be distinguished, a deadlock could <lb/>result, as the client must wait for the LAYOUTGET response before <lb/>processing the recall in the first case, but that response will not <lb/>arrive until after the recall is processed in the second case. Note <lb/>that in the first case, the &quot;seqid&quot; in the layout stateid of the <lb/>recall is two greater than what the client has recorded; in the <lb/>second case, the &quot;seqid&quot; is one greater than what the client has <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 316] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>recorded. This allows the client to disambiguate between the two <lb/>cases. The client thus knows precisely which possibility applies. <lb/>In case 1, the client knows it needs to wait for the LAYOUTGET <lb/>response before processing the recall (or the client can return <lb/>NFS4ERR_DELAY). <lb/>In case 2, the client will not wait for the LAYOUTGET response before <lb/>processing the recall because waiting would cause deadlock. <lb/>Therefore, the action at the client will only require waiting in the <lb/>case that the client has not yet seen the server&apos;s earlier responses <lb/>to the LAYOUTGET operation(s). <lb/>The recall process can be considered completed when the final <lb/>LAYOUTRETURN operation for the recalled range is completed. The <lb/>LAYOUTRETURN uses the layout stateid (with seqid) specified in <lb/>CB_LAYOUTRECALL. If the client uses multiple LAYOUTRETURNs in <lb/>processing the recall, the first LAYOUTRETURN will use the layout <lb/>stateid as specified in CB_LAYOUTRECALL. Subsequent LAYOUTRETURNs <lb/>will use the highest seqid as is the usual case. <lb/>12.5.5.2.1.3. Server Considerations <lb/>Consider a race from the metadata server&apos;s point of view. The <lb/>metadata server has sent a CB_LAYOUTRECALL and receives an <lb/>overlapping LAYOUTGET for the same file before the LAYOUTRETURN(s) <lb/>that respond to the CB_LAYOUTRECALL. There are three cases: <lb/>1. The client sent the LAYOUTGET before processing the <lb/>CB_LAYOUTRECALL. The &quot;seqid&quot; in the layout stateid of the <lb/>arguments of LAYOUTGET is one less than the &quot;seqid&quot; in <lb/>CB_LAYOUTRECALL. The server returns NFS4ERR_RECALLCONFLICT to <lb/>the client, which indicates to the client that there is a pending <lb/>recall. <lb/>2. The client sent the LAYOUTGET after processing the <lb/>CB_LAYOUTRECALL, but the LAYOUTGET arrived before the <lb/>LAYOUTRETURN and the response to CB_LAYOUTRECALL that completed <lb/>that processing. The &quot;seqid&quot; in the layout stateid of LAYOUTGET <lb/>is equal to or greater than that of the &quot;seqid&quot; in <lb/>CB_LAYOUTRECALL. The server has not received a response to the <lb/>CB_LAYOUTRECALL, so it returns NFS4ERR_RECALLCONFLICT. <lb/>3. The client sent the LAYOUTGET after processing the <lb/>CB_LAYOUTRECALL; the server received the CB_LAYOUTRECALL <lb/>response, but the LAYOUTGET arrived before the LAYOUTRETURN that <lb/>completed that processing. The &quot;seqid&quot; in the layout stateid of <lb/>LAYOUTGET is equal to that of the &quot;seqid&quot; in CB_LAYOUTRECALL. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 317] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The server has received a response to the CB_LAYOUTRECALL, so it <lb/>returns NFS4ERR_RETURNCONFLICT. <lb/>12.5.5.2.1.4. Wraparound and Validation of Seqid <lb/>The rules for layout stateid processing differ from other stateids in <lb/>the protocol because the &quot;seqid&quot; value cannot be zero and the <lb/>stateid&apos;s &quot;seqid&quot; value changes in a CB_LAYOUTRECALL operation. The <lb/>non-zero requirement combined with the inherent parallelism of layout <lb/>operations means that a set of LAYOUTGET and LAYOUTRETURN operations <lb/>may contain the same value for &quot;seqid&quot;. The server uses a slightly <lb/>modified version of the modulo arithmetic as described in <lb/>Section 2.10.6.1 when incrementing the layout stateid&apos;s &quot;seqid&quot;. The <lb/>difference is that zero is not a valid value for &quot;seqid&quot;; when the <lb/>value of a &quot;seqid&quot; is 0xFFFFFFFF, the next valid value will be <lb/>0x00000001. The modulo arithmetic is also used for the comparisons <lb/>of &quot;seqid&quot; values in the processing of CB_LAYOUTRECALL events as <lb/>described above in Section 12.5.5.2.1.3. <lb/>Just as the server validates the &quot;seqid&quot; in the event of <lb/>CB_LAYOUTRECALL usage, as described in Section 12.5.5.2.1.3, the <lb/>server also validates the &quot;seqid&quot; value to ensure that it is within <lb/>an appropriate range. This range represents the degree of <lb/>parallelism the server supports for layout stateids. If the client <lb/>is sending multiple layout operations to the server in parallel, by <lb/>definition, the &quot;seqid&quot; value in the supplied stateid will not be the <lb/>current &quot;seqid&quot; as held by the server. The range of parallelism <lb/>spans from the highest or current &quot;seqid&quot; to a &quot;seqid&quot; value in the <lb/>past. To assist in the discussion, the server&apos;s current &quot;seqid&quot; <lb/>value for a layout stateid is defined as SERVER_CURRENT_SEQID. The <lb/>lowest &quot;seqid&quot; value that is acceptable to the server is represented <lb/>by PAST_SEQID. And the value for the range of valid &quot;seqid&quot;s or <lb/>range of parallelism is VALID_SEQID_RANGE. Therefore, the following <lb/>holds: VALID_SEQID_RANGE = SERVER_CURRENT_SEQID -PAST_SEQID. In the <lb/>following, all arithmetic is the modulo arithmetic as described <lb/>above. <lb/>The server MUST support a minimum VALID_SEQID_RANGE. The minimum is <lb/>defined as: VALID_SEQID_RANGE = summation over 1..N of <lb/>(ca_maxoperations(i) -1), where N is the number of session fore <lb/>channels and ca_maxoperations(i) is the value of the ca_maxoperations <lb/>returned from CREATE_SESSION of the i&apos;th session. The reason for &quot;-<lb/>1&quot; is to allow for the required SEQUENCE operation. The server MAY <lb/>support a VALID_SEQID_RANGE value larger than the minimum. The <lb/>maximum VALID_SEQID_RANGE is (2 ^ 32 -2) (accounting for zero not <lb/>being a valid &quot;seqid&quot; value). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 318] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If the server finds the &quot;seqid&quot; is zero, the NFS4ERR_BAD_STATEID <lb/>error is returned to the client. The server further validates the <lb/>&quot;seqid&quot; to ensure it is within the range of parallelism, <lb/>VALID_SEQID_RANGE. If the &quot;seqid&quot; value is outside of that range, <lb/>the error NFS4ERR_OLD_STATEID is returned to the client. Upon <lb/>receipt of NFS4ERR_OLD_STATEID, the client updates the stateid in the <lb/>layout request based on processing of other layout requests and re-<lb/>sends the operation to the server. <lb/>12.5.5.2.1.5. Bulk Recall and Return <lb/>pNFS supports recalling and returning all layouts that are for files <lb/>belonging to a particular fsid (LAYOUTRECALL4_FSID, <lb/>LAYOUTRETURN4_FSID) or client ID (LAYOUTRECALL4_ALL, <lb/>LAYOUTRETURN4_ALL). There are no &quot;bulk&quot; stateids, so detection of <lb/>races via the seqid is not possible. The server MUST NOT initiate <lb/>bulk recall while another recall is in progress, or the corresponding <lb/>LAYOUTRETURN is in progress or pending. In the event the server <lb/>sends a bulk recall while the client has a pending or in-progress <lb/>LAYOUTRETURN, CB_LAYOUTRECALL, or LAYOUTGET, the client returns <lb/>NFS4ERR_DELAY. In the event the client sends a LAYOUTGET or <lb/>LAYOUTRETURN while a bulk recall is in progress, the server returns <lb/>NFS4ERR_RECALLCONFLICT. If the client sends a LAYOUTGET or <lb/>LAYOUTRETURN after the server receives NFS4ERR_DELAY from a bulk <lb/>recall, then to ensure forward progress, the server MAY return <lb/>NFS4ERR_RECALLCONFLICT. <lb/>Once a CB_LAYOUTRECALL of LAYOUTRECALL4_ALL is sent, the server MUST <lb/>NOT allow the client to use any layout stateid except for <lb/>LAYOUTCOMMIT operations. Once the client receives a CB_LAYOUTRECALL <lb/>of LAYOUTRECALL4_ALL, it MUST NOT use any layout stateid except for <lb/>LAYOUTCOMMIT operations. Once a LAYOUTRETURN of LAYOUTRETURN4_ALL is <lb/>sent, all layout stateids granted to the client ID are freed. The <lb/>client MUST NOT use the layout stateids again. It MUST use LAYOUTGET <lb/>to obtain new layout stateids. <lb/>Once a CB_LAYOUTRECALL of LAYOUTRECALL4_FSID is sent, the server MUST <lb/>NOT allow the client to use any layout stateid that refers to a file <lb/>with the specified fsid except for LAYOUTCOMMIT operations. Once the <lb/>client receives a CB_LAYOUTRECALL of LAYOUTRECALL4_ALL, it MUST NOT <lb/>use any layout stateid that refers to a file with the specified fsid <lb/>except for LAYOUTCOMMIT operations. Once a LAYOUTRETURN of <lb/>LAYOUTRETURN4_FSID is sent, all layout stateids granted to the <lb/>referenced fsid are freed. The client MUST NOT use those freed <lb/>layout stateids for files with the referenced fsid again. <lb/>Subsequently, for any file with the referenced fsid, to use a layout, <lb/>the client MUST first send a LAYOUTGET operation in order to obtain a <lb/>new layout stateid for that file. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 319] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If the server has sent a bulk CB_LAYOUTRECALL and receives a <lb/>LAYOUTGET, or a LAYOUTRETURN with a stateid, the server MUST return <lb/>NFS4ERR_RECALLCONFLICT. If the server has sent a bulk <lb/>CB_LAYOUTRECALL and receives a LAYOUTRETURN with an lr_returntype <lb/>that is not equal to the lor_recalltype of the CB_LAYOUTRECALL, the <lb/>server MUST return NFS4ERR_RECALLCONFLICT. <lb/>12.5.6. Revoking Layouts <lb/>Parallel NFS permits servers to revoke layouts from clients that fail <lb/>to respond to recalls and/or fail to renew their lease in time. <lb/>Depending on the layout type, the server might revoke the layout and <lb/>might take certain actions with respect to the client&apos;s I/O to data <lb/>servers. <lb/>12.5.7. Metadata Server Write Propagation <lb/>Asynchronous writes written through the metadata server may be <lb/>propagated lazily to the storage devices. For data written <lb/>asynchronously through the metadata server, a client performing a <lb/>read at the appropriate storage device is not guaranteed to see the <lb/>newly written data until a COMMIT occurs at the metadata server. <lb/>While the write is pending, reads to the storage device may give out <lb/>either the old data, the new data, or a mixture of new and old. Upon <lb/>completion of a synchronous WRITE or COMMIT (for asynchronously <lb/>written data), the metadata server MUST ensure that storage devices <lb/>give out the new data and that the data has been written to stable <lb/>storage. If the server implements its storage in any way such that <lb/>it cannot obey these constraints, then it MUST recall the layouts to <lb/>prevent reads being done that cannot be handled correctly. Note that <lb/>the layouts MUST be recalled prior to the server responding to the <lb/>associated WRITE operations. <lb/>12.6. pNFS Mechanics <lb/>This section describes the operations flow taken by a pNFS client to <lb/>a metadata server and storage device. <lb/>When a pNFS client encounters a new FSID, it sends a GETATTR to the <lb/>NFSv4.1 server for the fs_layout_type (Section 5.12.1) attribute. If <lb/>the attribute returns at least one layout type, and the layout types <lb/>returned are among the set supported by the client, the client knows <lb/>that pNFS is a possibility for the file system. If, from the server <lb/>that returned the new FSID, the client does not have a client ID that <lb/>came from an EXCHANGE_ID result that returned <lb/>EXCHGID4_FLAG_USE_PNFS_MDS, it MUST send an EXCHANGE_ID to the server <lb/>with the EXCHGID4_FLAG_USE_PNFS_MDS bit set. If the server&apos;s <lb/>response does not have EXCHGID4_FLAG_USE_PNFS_MDS, then contrary to <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 320] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>what the fs_layout_type attribute said, the server does not support <lb/>pNFS, and the client will not be able use pNFS to that server; in <lb/>this case, the server MUST return NFS4ERR_NOTSUPP in response to any <lb/>pNFS operation. <lb/>The client then creates a session, requesting a persistent session, <lb/>so that exclusive creates can be done with single round trip via the <lb/>createmode4 of GUARDED4. If the session ends up not being <lb/>persistent, the client will use EXCLUSIVE4_1 for exclusive creates. <lb/>If a file is to be created on a pNFS-enabled file system, the client <lb/>uses the OPEN operation. With the normal set of attributes that may <lb/>be provided upon OPEN used for creation, there is an OPTIONAL <lb/>layout_hint attribute. The client&apos;s use of layout_hint allows the <lb/>client to express its preference for a layout type and its associated <lb/>layout details. The use of a createmode4 of UNCHECKED4, GUARDED4, or <lb/>EXCLUSIVE4_1 will allow the client to provide the layout_hint <lb/>attribute at create time. The client MUST NOT use EXCLUSIVE4 (see <lb/>Table 10). The client is RECOMMENDED to combine a GETATTR operation <lb/>after the OPEN within the same COMPOUND. The GETATTR may then <lb/>retrieve the layout_type attribute for the newly created file. The <lb/>client will then know what layout type the server has chosen for the <lb/>file and therefore what storage protocol the client must use. <lb/>If the client wants to open an existing file, then it also includes a <lb/>GETATTR to determine what layout type the file supports. <lb/>The GETATTR in either the file creation or plain file open case can <lb/>also include the layout_blksize and layout_alignment attributes so <lb/>that the client can determine optimal offsets and lengths for I/O on <lb/>the file. <lb/>Assuming the client supports the layout type returned by GETATTR and <lb/>it chooses to use pNFS for data access, it then sends LAYOUTGET using <lb/>the filehandle and stateid returned by OPEN, specifying the range it <lb/>wants to do I/O on. The response is a layout, which may be a subset <lb/>of the range for which the client asked. It also includes device IDs <lb/>and a description of how data is organized (or in the case of <lb/>writing, how data is to be organized) across the devices. The device <lb/>IDs and data description are encoded in a format that is specific to <lb/>the layout type, but the client is expected to understand. <lb/>When the client wants to send an I/O, it determines to which device <lb/>ID it needs to send the I/O command by examining the data description <lb/>in the layout. It then sends a GETDEVICEINFO to find the device <lb/>address(es) of the device ID. The client then sends the I/O request <lb/>to one of device ID&apos;s device addresses, using the storage protocol <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 321] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>defined for the layout type. Note that if a client has multiple I/Os <lb/>to send, these I/O requests may be done in parallel. <lb/>If the I/O was a WRITE, then at some point the client may want to use <lb/>LAYOUTCOMMIT to commit the modification time and the new size of the <lb/>file (if it believes it extended the file size) to the metadata <lb/>server and the modified data to the file system. <lb/>12.7. Recovery <lb/>Recovery is complicated by the distributed nature of the pNFS <lb/>protocol. In general, crash recovery for layouts is similar to crash <lb/>recovery for delegations in the base NFSv4.1 protocol. However, the <lb/>client&apos;s ability to perform I/O without contacting the metadata <lb/>server introduces subtleties that must be handled correctly if the <lb/>possibility of file system corruption is to be avoided. <lb/>12.7.1. Recovery from Client Restart <lb/>Client recovery for layouts is similar to client recovery for other <lb/>lock and delegation state. When a pNFS client restarts, it will lose <lb/>all information about the layouts that it previously owned. There <lb/>are two methods by which the server can reclaim these resources and <lb/>allow otherwise conflicting layouts to be provided to other clients. <lb/>The first is through the expiry of the client&apos;s lease. If the client <lb/>recovery time is longer than the lease period, the client&apos;s lease <lb/>will expire and the server will know that state may be released. For <lb/>layouts, the server may release the state immediately upon lease <lb/>expiry or it may allow the layout to persist, awaiting possible lease <lb/>revival, as long as no other layout conflicts. <lb/>The second is through the client restarting in less time than it <lb/>takes for the lease period to expire. In such a case, the client <lb/>will contact the server through the standard EXCHANGE_ID protocol. <lb/>The server will find that the client&apos;s co_ownerid matches the <lb/>co_ownerid of the previous client invocation, but that the verifier <lb/>is different. The server uses this as a signal to release all layout <lb/>state associated with the client&apos;s previous invocation. In this <lb/>scenario, the data written by the client but not covered by a <lb/>successful LAYOUTCOMMIT is in an undefined state; it may have been <lb/>written or it may now be lost. This is acceptable behavior and it is <lb/>the client&apos;s responsibility to use LAYOUTCOMMIT to achieve the <lb/>desired level of stability. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 322] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>12.7.2. Dealing with Lease Expiration on the Client <lb/>If a client believes its lease has expired, it MUST NOT send I/O to <lb/>the storage device until it has validated its lease. The client can <lb/>send a SEQUENCE operation to the metadata server. If the SEQUENCE <lb/>operation is successful, but sr_status_flag has <lb/>SEQ4_STATUS_EXPIRED_ALL_STATE_REVOKED, <lb/>SEQ4_STATUS_EXPIRED_SOME_STATE_REVOKED, or <lb/>SEQ4_STATUS_ADMIN_STATE_REVOKED set, the client MUST NOT use <lb/>currently held layouts. The client has two choices to recover from <lb/>the lease expiration. First, for all modified but uncommitted data, <lb/>the client writes it to the metadata server using the FILE_SYNC4 flag <lb/>for the WRITEs, or WRITE and COMMIT. Second, the client re-<lb/>establishes a client ID and session with the server and obtains new <lb/>layouts and device-ID-to-device-address mappings for the modified <lb/>data ranges and then writes the data to the storage devices with the <lb/>newly obtained layouts. <lb/>If sr_status_flags from the metadata server has <lb/>SEQ4_STATUS_RESTART_RECLAIM_NEEDED set (or SEQUENCE returns <lb/>NFS4ERR_BAD_SESSION and CREATE_SESSION returns <lb/>NFS4ERR_STALE_CLIENTID), then the metadata server has restarted, and <lb/>the client SHOULD recover using the methods described in <lb/>Section 12.7.4. <lb/>If sr_status_flags from the metadata server has <lb/>SEQ4_STATUS_LEASE_MOVED set, then the client recovers by following <lb/>the procedure described in Section 11.10.9.1. After that, the client <lb/>may get an indication that the layout state was not moved with the <lb/>file system. The client recovers as in the other applicable <lb/>situations discussed in the first two paragraphs of this section. <lb/>If sr_status_flags reports no loss of state, then the lease for the <lb/>layouts that the client has are valid and renewed, and the client can <lb/>once again send I/O requests to the storage devices. <lb/>While clients SHOULD NOT send I/Os to storage devices that may extend <lb/>past the lease expiration time period, this is not always possible, <lb/>for example, an extended network partition that starts after the I/O <lb/>is sent and does not heal until the I/O request is received by the <lb/>storage device. Thus, the metadata server and/or storage devices are <lb/>responsible for protecting themselves from I/Os that are both sent <lb/>before the lease expires and arrive after the lease expires. See <lb/>Section 12.7.3. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 323] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>12.7.3. Dealing with Loss of Layout State on the Metadata Server <lb/>This is a description of the case where all of the following are <lb/>true: <lb/>o the metadata server has not restarted <lb/>o a pNFS client&apos;s layouts have been discarded (usually because the <lb/>client&apos;s lease expired) and are invalid <lb/>o an I/O from the pNFS client arrives at the storage device <lb/>The metadata server and its storage devices MUST solve this by <lb/>fencing the client. In other words, they MUST solve this by <lb/>preventing the execution of I/O operations from the client to the <lb/>storage devices after layout state loss. The details of how fencing <lb/>is done are specific to the layout type. The solution for NFSv4.1 <lb/>file-based layouts is described in (Section 13.11), and solutions for <lb/>other layout types are in their respective external specification <lb/>documents. <lb/>12.7.4. Recovery from Metadata Server Restart <lb/>The pNFS client will discover that the metadata server has restarted <lb/>via the methods described in Section 8.4.2 and discussed in a pNFS-<lb/>specific context in Section 12.7.2, Paragraph 2. The client MUST <lb/>stop using layouts and delete the device ID to device address <lb/>mappings it previously received from the metadata server. Having <lb/>done that, if the client wrote data to the storage device without <lb/>committing the layouts via LAYOUTCOMMIT, then the client has <lb/>additional work to do in order to have the client, metadata server, <lb/>and storage device(s) all synchronized on the state of the data. <lb/>o If the client has data still modified and unwritten in the <lb/>client&apos;s memory, the client has only two choices. <lb/>1. The client can obtain a layout via LAYOUTGET after the <lb/>server&apos;s grace period and write the data to the storage <lb/>devices. <lb/>2. The client can WRITE that data through the metadata server <lb/>using the WRITE (Section 18.32) operation, and then obtain <lb/>layouts as desired. <lb/>o If the client asynchronously wrote data to the storage device, but <lb/>still has a copy of the data in its memory, then it has available <lb/>to it the recovery options listed above in the previous bullet <lb/>point. If the metadata server is also in its grace period, the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 324] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>client has available to it the options below in the next bullet <lb/>point. <lb/>o The client does not have a copy of the data in its memory and the <lb/>metadata server is still in its grace period. The client cannot <lb/>use LAYOUTGET (within or outside the grace period) to reclaim a <lb/>layout because the contents of the response from LAYOUTGET may not <lb/>match what it had previously. The range might be different or the <lb/>client might get the same range but the content of the layout <lb/>might be different. Even if the content of the layout appears to <lb/>be the same, the device IDs may map to different device addresses, <lb/>and even if the device addresses are the same, the device <lb/>addresses could have been assigned to a different storage device. <lb/>The option of retrieving the data from the storage device and <lb/>writing it to the metadata server per the recovery scenario <lb/>described above is not available because, again, the mappings of <lb/>range to device ID, device ID to device address, and device <lb/>address to physical device are stale, and new mappings via new <lb/>LAYOUTGET do not solve the problem. <lb/>The only recovery option for this scenario is to send a <lb/>LAYOUTCOMMIT in reclaim mode, which the metadata server will <lb/>accept as long as it is in its grace period. The use of <lb/>LAYOUTCOMMIT in reclaim mode informs the metadata server that the <lb/>layout has changed. It is critical that the metadata server <lb/>receive this information before its grace period ends, and thus <lb/>before it starts allowing updates to the file system. <lb/>To send LAYOUTCOMMIT in reclaim mode, the client sets the <lb/>loca_reclaim field of the operation&apos;s arguments (Section 18.42.1) <lb/>to TRUE. During the metadata server&apos;s recovery grace period (and <lb/>only during the recovery grace period) the metadata server is <lb/>prepared to accept LAYOUTCOMMIT requests with the loca_reclaim <lb/>field set to TRUE. <lb/>When loca_reclaim is TRUE, the client is attempting to commit <lb/>changes to the layout that occurred prior to the restart of the <lb/>metadata server. The metadata server applies some consistency <lb/>checks on the loca_layoutupdate field of the arguments to <lb/>determine whether the client can commit the data written to the <lb/>storage device to the file system. The loca_layoutupdate field is <lb/>of data type layoutupdate4 and contains layout-type-specific <lb/>content (in the lou_body field of loca_layoutupdate). The layout-<lb/>type-specific information that loca_layoutupdate might have is <lb/>discussed in Section 12.5.4.3. If the metadata server&apos;s <lb/>consistency checks on loca_layoutupdate succeed, then the metadata <lb/>server MUST commit the data (as described by the loca_offset, <lb/>loca_length, and loca_layoutupdate fields of the arguments) that <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 325] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>was written to the storage device. If the metadata server&apos;s <lb/>consistency checks on loca_layoutupdate fail, the metadata server <lb/>rejects the LAYOUTCOMMIT operation and makes no changes to the <lb/>file system. However, any time LAYOUTCOMMIT with loca_reclaim <lb/>TRUE fails, the pNFS client has lost all the data in the range <lb/>defined by &lt;loca_offset, loca_length&gt;. A client can defend <lb/>against this risk by caching all data, whether written <lb/>synchronously or asynchronously in its memory, and by not <lb/>releasing the cached data until a successful LAYOUTCOMMIT. This <lb/>condition does not hold true for all layout types; for example, <lb/>file-based storage devices need not suffer from this limitation. <lb/>o The client does not have a copy of the data in its memory and the <lb/>metadata server is no longer in its grace period; i.e., the <lb/>metadata server returns NFS4ERR_NO_GRACE. As with the scenario in <lb/>the above bullet point, the failure of LAYOUTCOMMIT means the data <lb/>in the range &lt;loca_offset, loca_length&gt; lost. The defense against <lb/>the risk is the same --cache all written data on the client until <lb/>a successful LAYOUTCOMMIT. <lb/>12.7.5. Operations during Metadata Server Grace Period <lb/>Some of the recovery scenarios thus far noted that some operations <lb/>(namely, WRITE and LAYOUTGET) might be permitted during the metadata <lb/>server&apos;s grace period. The metadata server may allow these <lb/>operations during its grace period. For LAYOUTGET, the metadata <lb/>server must reliably determine that servicing such a request will not <lb/>conflict with an impending LAYOUTCOMMIT reclaim request. For WRITE, <lb/>the metadata server must reliably determine that servicing the <lb/>request will not conflict with an impending OPEN or with a LOCK where <lb/>the file has mandatory byte-range locking enabled. <lb/>As mentioned previously, for expediency, the metadata server might <lb/>reject some operations (namely, WRITE and LAYOUTGET) during its grace <lb/>period, because the simplest correct approach is to reject all non-<lb/>reclaim pNFS requests and WRITE operations by returning the <lb/>NFS4ERR_GRACE error. However, depending on the storage protocol <lb/>(which is specific to the layout type) and metadata server <lb/>implementation, the metadata server may be able to determine that a <lb/>particular request is safe. For example, a metadata server may save <lb/>provisional allocation mappings for each file to stable storage, as <lb/>well as information about potentially conflicting OPEN share modes <lb/>and mandatory byte-range locks that might have been in effect at the <lb/>time of restart, and the metadata server may use this information <lb/>during the recovery grace period to determine that a WRITE request is <lb/>safe. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 326] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>12.7.6. Storage Device Recovery <lb/>Recovery from storage device restart is mostly dependent upon the <lb/>layout type in use. However, there are a few general techniques a <lb/>client can use if it discovers a storage device has crashed while <lb/>holding modified, uncommitted data that was asynchronously written. <lb/>First and foremost, it is important to realize that the client is the <lb/>only one that has the information necessary to recover non-committed <lb/>data since it holds the modified data and probably nothing else does. <lb/>Second, the best solution is for the client to err on the side of <lb/>caution and attempt to rewrite the modified data through another <lb/>path. <lb/>The client SHOULD immediately WRITE the data to the metadata server, <lb/>with the stable field in the WRITE4args set to FILE_SYNC4. Once it <lb/>does this, there is no need to wait for the original storage device. <lb/>12.8. Metadata and Storage Device Roles <lb/>If the same physical hardware is used to implement both a metadata <lb/>server and storage device, then the same hardware entity is to be <lb/>understood to be implementing two distinct roles and it is important <lb/>that it be clearly understood on behalf of which role the hardware is <lb/>executing at any given time. <lb/>Two sub-cases can be distinguished. <lb/>1. The storage device uses NFSv4.1 as the storage protocol, i.e., <lb/>the same physical hardware is used to implement both a metadata <lb/>and data server. See Section 13.1 for a description of how <lb/>multiple roles are handled. <lb/>2. The storage device does not use NFSv4.1 as the storage protocol, <lb/>and the same physical hardware is used to implement both a <lb/>metadata and storage device. Whether distinct network addresses <lb/>are used to access the metadata server and storage device is <lb/>immaterial. This is because it is always clear to the pNFS <lb/>client and server, from the upper-layer protocol being used <lb/>(NFSv4.1 or non-NFSv4.1), to which role the request to the common <lb/>server network address is directed. <lb/>12.9. Security Considerations for pNFS <lb/>pNFS separates file system metadata and data and provides access to <lb/>both. There are pNFS-specific operations (listed in Section 12.3) <lb/>that provide access to the metadata; all existing NFSv4.1 <lb/>conventional (non-pNFS) security mechanisms and features apply to <lb/>accessing the metadata. The combination of components in a pNFS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 327] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>system (see Figure 1) is required to preserve the security properties <lb/>of NFSv4.1 with respect to an entity that is accessing a storage <lb/>device from a client, including security countermeasures to defend <lb/>against threats for which NFSv4.1 provides defenses in environments <lb/>where these threats are considered significant. <lb/>In some cases, the security countermeasures for connections to <lb/>storage devices may take the form of physical isolation or a <lb/>recommendation to avoid the use of pNFS in an environment. For <lb/>example, it may be impractical to provide confidentiality protection <lb/>for some storage protocols to protect against eavesdropping. In <lb/>environments where eavesdropping on such protocols is of sufficient <lb/>concern to require countermeasures, physical isolation of the <lb/>communication channel (e.g., via direct connection from client(s) to <lb/>storage device(s)) and/or a decision to forgo use of pNFS (e.g., and <lb/>fall back to conventional NFSv4.1) may be appropriate courses of <lb/>action. <lb/>Where communication with storage devices is subject to the same <lb/>threats as client-to-metadata server communication, the protocols <lb/>used for that communication need to provide security mechanisms as <lb/>strong as or no weaker than those available via RPCSEC_GSS for <lb/>NFSv4.1. Except for the storage protocol used for the <lb/>LAYOUT4_NFSV4_1_FILES layout (see Section 13), i.e., except for <lb/>NFSv4.1, it is beyond the scope of this document to specify the <lb/>security mechanisms for storage access protocols. <lb/>pNFS implementations MUST NOT remove NFSv4.1&apos;s access controls. The <lb/>combination of clients, storage devices, and the metadata server are <lb/>responsible for ensuring that all client-to-storage-device file data <lb/>access respects NFSv4.1&apos;s ACLs and file open modes. This entails <lb/>performing both of these checks on every access in the client, the <lb/>storage device, or both (as applicable; when the storage device is an <lb/>NFSv4.1 server, the storage device is ultimately responsible for <lb/>controlling access as described in Section 13.9.2). If a pNFS <lb/>configuration performs these checks only in the client, the risk of a <lb/>misbehaving client obtaining unauthorized access is an important <lb/>consideration in determining when it is appropriate to use such a <lb/>pNFS configuration. Such layout types SHOULD NOT be used when <lb/>client-only access checks do not provide sufficient assurance that <lb/>NFSv4.1 access control is being applied correctly. (This is not a <lb/>problem for the file layout type described in Section 13 because the <lb/>storage access protocol for LAYOUT4_NFSV4_1_FILES is NFSv4.1, and <lb/>thus the security model for storage device access via <lb/>LAYOUT4_NFSv4_1_FILES is the same as that of the metadata server.) <lb/>For handling of access control specific to a layout, the reader <lb/>should examine the layout specification, such as the NFSv4.1/file-<lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 328] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>based layout (Section 13) of this document, the blocks layout [44], <lb/>and objects layout [43]. <lb/>13. NFSv4.1 as a Storage Protocol in pNFS: the File Layout Type <lb/>This section describes the semantics and format of NFSv4.1 file-based <lb/>layouts for pNFS. NFSv4.1 file-based layouts use the <lb/>LAYOUT4_NFSV4_1_FILES layout type. The LAYOUT4_NFSV4_1_FILES type <lb/>defines striping data across multiple NFSv4.1 data servers. <lb/>13.1. Client ID and Session Considerations <lb/>Sessions are a REQUIRED feature of NFSv4.1, and this extends to both <lb/>the metadata server and file-based (NFSv4.1-based) data servers. <lb/>The role a server plays in pNFS is determined by the result it <lb/>returns from EXCHANGE_ID. The roles are: <lb/>o Metadata server (EXCHGID4_FLAG_USE_PNFS_MDS is set in the result <lb/>eir_flags). <lb/>o Data server (EXCHGID4_FLAG_USE_PNFS_DS). <lb/>o Non-metadata server (EXCHGID4_FLAG_USE_NON_PNFS). This is an <lb/>NFSv4.1 server that does not support operations (e.g., LAYOUTGET) <lb/>or attributes that pertain to pNFS. <lb/>The client MAY request zero or more of EXCHGID4_FLAG_USE_NON_PNFS, <lb/>EXCHGID4_FLAG_USE_PNFS_DS, or EXCHGID4_FLAG_USE_PNFS_MDS, even though <lb/>some combinations (e.g., EXCHGID4_FLAG_USE_NON_PNFS | <lb/>EXCHGID4_FLAG_USE_PNFS_MDS) are contradictory. However, the server <lb/>MUST only return the following acceptable combinations: <lb/>+---------------------------------------------------------+ <lb/>| Acceptable Results from EXCHANGE_ID <lb/>| <lb/>+---------------------------------------------------------+ <lb/>| EXCHGID4_FLAG_USE_PNFS_MDS <lb/>| <lb/>| EXCHGID4_FLAG_USE_PNFS_MDS | EXCHGID4_FLAG_USE_PNFS_DS | <lb/>| EXCHGID4_FLAG_USE_PNFS_DS <lb/>| <lb/>| EXCHGID4_FLAG_USE_NON_PNFS <lb/>| <lb/>| EXCHGID4_FLAG_USE_PNFS_DS | EXCHGID4_FLAG_USE_NON_PNFS | <lb/>+---------------------------------------------------------+ <lb/>As the above table implies, a server can have one or two roles. A <lb/>server can be both a metadata server and a data server, or it can be <lb/>both a data server and non-metadata server. In addition to returning <lb/>two roles in the EXCHANGE_ID&apos;s results, and thus serving both roles <lb/>via a common client ID, a server can serve two roles by returning a <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 329] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>unique client ID and server owner for each role in each of two <lb/>EXCHANGE_ID results, with each result indicating each role. <lb/>In the case of a server with concurrent pNFS roles that are served by <lb/>a common client ID, if the EXCHANGE_ID request from the client has <lb/>zero or a combination of the bits set in eia_flags, the server result <lb/>should set bits that represent the higher of the acceptable <lb/>combination of the server roles, with a preference to match the roles <lb/>requested by the client. Thus, if a client request has <lb/>(EXCHGID4_FLAG_USE_NON_PNFS | EXCHGID4_FLAG_USE_PNFS_MDS | <lb/>EXCHGID4_FLAG_USE_PNFS_DS) flags set, and the server is both a <lb/>metadata server and a data server, serving both the roles by a common <lb/>client ID, the server SHOULD return with <lb/>(EXCHGID4_FLAG_USE_PNFS_MDS | EXCHGID4_FLAG_USE_PNFS_DS) set. <lb/>In the case of a server that has multiple concurrent pNFS roles, each <lb/>role served by a unique client ID, if the client specifies zero or a <lb/>combination of roles in the request, the server results SHOULD return <lb/>only one of the roles from the combination specified by the client <lb/>request. If the role specified by the server result does not match <lb/>the intended use by the client, the client should send the <lb/>EXCHANGE_ID specifying just the interested pNFS role. <lb/>If a pNFS metadata client gets a layout that refers it to an NFSv4.1 <lb/>data server, it needs a client ID on that data server. If it does <lb/>not yet have a client ID from the server that had the <lb/>EXCHGID4_FLAG_USE_PNFS_DS flag set in the EXCHANGE_ID results, then <lb/>the client needs to send an EXCHANGE_ID to the data server, using the <lb/>same co_ownerid as it sent to the metadata server, with the <lb/>EXCHGID4_FLAG_USE_PNFS_DS flag set in the arguments. If the server&apos;s <lb/>EXCHANGE_ID results have EXCHGID4_FLAG_USE_PNFS_DS set, then the <lb/>client may use the client ID to create sessions that will exchange <lb/>pNFS data operations. The client ID returned by the data server has <lb/>no relationship with the client ID returned by a metadata server <lb/>unless the client IDs are equal, and the server owners and server <lb/>scopes of the data server and metadata server are equal. <lb/>In NFSv4.1, the session ID in the SEQUENCE operation implies the <lb/>client ID, which in turn might be used by the server to map the <lb/>stateid to the right client/server pair. However, when a data server <lb/>is presented with a READ or WRITE operation with a stateid, because <lb/>the stateid is associated with a client ID on a metadata server, and <lb/>because the session ID in the preceding SEQUENCE operation is tied to <lb/>the client ID of the data server, the data server has no obvious way <lb/>to determine the metadata server from the COMPOUND procedure, and <lb/>thus has no way to validate the stateid. One RECOMMENDED approach is <lb/>for pNFS servers to encode metadata server routing and/or identity <lb/>information in the data server filehandles as returned in the layout. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 330] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If metadata server routing and/or identity information is encoded in <lb/>data server filehandles, when the metadata server identity or <lb/>location changes, the data server filehandles it gave out will become <lb/>invalid (stale), and so the metadata server MUST first recall the <lb/>layouts. Invalidating a data server filehandle does not render the <lb/>NFS client&apos;s data cache invalid. The client&apos;s cache should map a <lb/>data server filehandle to a metadata server filehandle, and a <lb/>metadata server filehandle to cached data. <lb/>If a server is both a metadata server and a data server, the server <lb/>might need to distinguish operations on files that are directed to <lb/>the metadata server from those that are directed to the data server. <lb/>It is RECOMMENDED that the values of the filehandles returned by the <lb/>LAYOUTGET operation be different than the value of the filehandle <lb/>returned by the OPEN of the same file. <lb/>Another scenario is for the metadata server and the storage device to <lb/>be distinct from one client&apos;s point of view, and the roles reversed <lb/>from another client&apos;s point of view. For example, in the cluster <lb/>file system model, a metadata server to one client might be a data <lb/>server to another client. If NFSv4.1 is being used as the storage <lb/>protocol, then pNFS servers need to encode the values of filehandles <lb/>according to their specific roles. <lb/>13.1.1. Sessions Considerations for Data Servers <lb/>Section 2.10.11.2 states that a client has to keep its lease renewed <lb/>in order to prevent a session from being deleted by the server. If <lb/>the reply to EXCHANGE_ID has just the EXCHGID4_FLAG_USE_PNFS_DS role <lb/>set, then (as noted in Section 13.6) the client will not be able to <lb/>determine the data server&apos;s lease_time attribute because GETATTR will <lb/>not be permitted. Instead, the rule is that any time a client <lb/>receives a layout referring it to a data server that returns just the <lb/>EXCHGID4_FLAG_USE_PNFS_DS role, the client MAY assume that the <lb/>lease_time attribute from the metadata server that returned the <lb/>layout applies to the data server. Thus, the data server MUST be <lb/>aware of the values of all lease_time attributes of all metadata <lb/>servers for which it is providing I/O, and it MUST use the maximum of <lb/>all such lease_time values as the lease interval for all client IDs <lb/>and sessions established on it. <lb/>For example, if one metadata server has a lease_time attribute of 20 <lb/>seconds, and a second metadata server has a lease_time attribute of <lb/>10 seconds, then if both servers return layouts that refer to an <lb/>EXCHGID4_FLAG_USE_PNFS_DS-only data server, the data server MUST <lb/>renew a client&apos;s lease if the interval between two SEQUENCE <lb/>operations on different COMPOUND requests is less than 20 seconds. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 331] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>13.2. File Layout Definitions <lb/>The following definitions apply to the LAYOUT4_NFSV4_1_FILES layout <lb/>type and may be applicable to other layout types. <lb/>Unit. A unit is a fixed-size quantity of data written to a data <lb/>server. <lb/>Pattern. A pattern is a method of distributing one or more equal <lb/>sized units across a set of data servers. A pattern is iterated <lb/>one or more times. <lb/>Stripe. A stripe is a set of data distributed across a set of data <lb/>servers in a pattern before that pattern repeats. <lb/>Stripe Count. A stripe count is the number of units in a pattern. <lb/>Stripe Width. A stripe width is the size of a stripe in bytes. The <lb/>stripe width = the stripe count * the size of the stripe unit. <lb/>Hereafter, this document will refer to a unit that is a written in a <lb/>pattern as a &quot;stripe unit&quot;. <lb/>A pattern may have more stripe units than data servers. If so, some <lb/>data servers will have more than one stripe unit per stripe. A data <lb/>server that has multiple stripe units per stripe MAY store each unit <lb/>in a different data file (and depending on the implementation, will <lb/>possibly assign a unique data filehandle to each data file). <lb/>13.3. File Layout Data Types <lb/>The high level NFSv4.1 layout types are nfsv4_1_file_layouthint4, <lb/>nfsv4_1_file_layout_ds_addr4, and nfsv4_1_file_layout4. <lb/>The SETATTR operation supports a layout hint attribute <lb/>(Section 5.12.4). When the client sets a layout hint (data type <lb/>layouthint4) with a layout type of LAYOUT4_NFSV4_1_FILES (the <lb/>loh_type field), the loh_body field contains a value of data type <lb/>nfsv4_1_file_layouthint4. <lb/>const NFL4_UFLG_MASK <lb/>= 0x0000003F; <lb/>const NFL4_UFLG_DENSE <lb/>= 0x00000001; <lb/>const NFL4_UFLG_COMMIT_THRU_MDS = 0x00000002; <lb/>const NFL4_UFLG_STRIPE_UNIT_SIZE_MASK <lb/>= 0xFFFFFFC0; <lb/>typedef uint32_t nfl_util4; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 332] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>enum filelayout_hint_care4 { <lb/>NFLH4_CARE_DENSE <lb/>= NFL4_UFLG_DENSE, <lb/>NFLH4_CARE_COMMIT_THRU_MDS <lb/>= NFL4_UFLG_COMMIT_THRU_MDS, <lb/>NFLH4_CARE_STRIPE_UNIT_SIZE <lb/>= 0x00000040, <lb/>NFLH4_CARE_STRIPE_COUNT = 0x00000080 <lb/>}; <lb/>/* Encoded in the loh_body field of data type layouthint4: */ <lb/>struct nfsv4_1_file_layouthint4 { <lb/>uint32_t <lb/>nflh_care; <lb/>nfl_util4 <lb/>nflh_util; <lb/>count4 <lb/>nflh_stripe_count; <lb/>}; <lb/>The generic layout hint structure is described in Section 3.3.19. <lb/>The client uses the layout hint in the layout_hint (Section 5.12.4) <lb/>attribute to indicate the preferred type of layout to be used for a <lb/>newly created file. The LAYOUT4_NFSV4_1_FILES layout-type-specific <lb/>content for the layout hint is composed of three fields. The first <lb/>field, nflh_care, is a set of flags indicating which values of the <lb/>hint the client cares about. If the NFLH4_CARE_DENSE flag is set, <lb/>then the client indicates in the second field, nflh_util, a <lb/>preference for how the data file is packed (Section 13.4.4), which is <lb/>controlled by the value of the expression nflh_util &amp; NFL4_UFLG_DENSE <lb/>(&quot;&amp;&quot; represents the bitwise AND operator). If the <lb/>NFLH4_CARE_COMMIT_THRU_MDS flag is set, then the client indicates a <lb/>preference for whether the client should send COMMIT operations to <lb/>the metadata server or data server (Section 13.7), which is <lb/>controlled by the value of nflh_util &amp; NFL4_UFLG_COMMIT_THRU_MDS. If <lb/>the NFLH4_CARE_STRIPE_UNIT_SIZE flag is set, the client indicates its <lb/>preferred stripe unit size, which is indicated in nflh_util &amp; <lb/>NFL4_UFLG_STRIPE_UNIT_SIZE_MASK (thus, the stripe unit size MUST be a <lb/>multiple of 64 bytes). The minimum stripe unit size is 64 bytes. If <lb/>the NFLH4_CARE_STRIPE_COUNT flag is set, the client indicates in the <lb/>third field, nflh_stripe_count, the stripe count. The stripe count <lb/>multiplied by the stripe unit size is the stripe width. <lb/>When LAYOUTGET returns a LAYOUT4_NFSV4_1_FILES layout (indicated in <lb/>the loc_type field of the lo_content field), the loc_body field of <lb/>the lo_content field contains a value of data type <lb/>nfsv4_1_file_layout4. Among other content, nfsv4_1_file_layout4 has <lb/>a storage device ID (field nfl_deviceid) of data type deviceid4. The <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 333] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>GETDEVICEINFO operation maps a device ID to a storage device address <lb/>(type device_addr4). When GETDEVICEINFO returns a device address <lb/>with a layout type of LAYOUT4_NFSV4_1_FILES (the da_layout_type <lb/>field), the da_addr_body field contains a value of data type <lb/>nfsv4_1_file_layout_ds_addr4. <lb/>typedef netaddr4 multipath_list4&lt;&gt;; <lb/>/* <lb/>* Encoded in the da_addr_body field of <lb/>* data type device_addr4: <lb/>*/ <lb/>struct nfsv4_1_file_layout_ds_addr4 { <lb/>uint32_t <lb/>nflda_stripe_indices&lt;&gt;; <lb/>multipath_list4 nflda_multipath_ds_list&lt;&gt;; <lb/>}; <lb/>The nfsv4_1_file_layout_ds_addr4 data type represents the device <lb/>address. It is composed of two fields: <lb/>1. nflda_multipath_ds_list: An array of lists of data servers, where <lb/>each list can be one or more elements, and each element <lb/>represents a data server address that may serve equally as the <lb/>target of I/O operations (see Section 13.5). The length of this <lb/>array might be different than the stripe count. <lb/>2. nflda_stripe_indices: An array of indices used to index into <lb/>nflda_multipath_ds_list. The value of each element of <lb/>nflda_stripe_indices MUST be less than the number of elements in <lb/>nflda_multipath_ds_list. Each element of nflda_multipath_ds_list <lb/>SHOULD be referred to by one or more elements of <lb/>nflda_stripe_indices. The number of elements in <lb/>nflda_stripe_indices is always equal to the stripe count. <lb/>/* <lb/>* Encoded in the loc_body field of <lb/>* data type layout_content4: <lb/>*/ <lb/>struct nfsv4_1_file_layout4 { <lb/>deviceid4 <lb/>nfl_deviceid; <lb/>nfl_util4 <lb/>nfl_util; <lb/>uint32_t <lb/>nfl_first_stripe_index; <lb/>offset4 <lb/>nfl_pattern_offset; <lb/>nfs_fh4 <lb/>nfl_fh_list&lt;&gt;; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 334] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The nfsv4_1_file_layout4 data type represents the layout. It is <lb/>composed of the following fields: <lb/>1. nfl_deviceid: The device ID that maps to a value of type <lb/>nfsv4_1_file_layout_ds_addr4. <lb/>2. nfl_util: Like the nflh_util field of data type <lb/>nfsv4_1_file_layouthint4, a compact representation of how the <lb/>data on a file on each data server is packed, whether the client <lb/>should send COMMIT operations to the metadata server or data <lb/>server, and the stripe unit size. If a server returns two or <lb/>more overlapping layouts, each stripe unit size in each <lb/>overlapping layout MUST be the same. <lb/>3. nfl_first_stripe_index: The index into the first element of the <lb/>nflda_stripe_indices array to use. <lb/>4. nfl_pattern_offset: This field is the logical offset into the <lb/>file where the striping pattern starts. It is required for <lb/>converting the client&apos;s logical I/O offset (e.g., the current <lb/>offset in a POSIX file descriptor before the read() or write() <lb/>system call is sent) into the stripe unit number (see <lb/>Section 13.4.1). <lb/>If dense packing is used, then nfl_pattern_offset is also needed <lb/>to convert the client&apos;s logical I/O offset to an offset on the <lb/>file on the data server corresponding to the stripe unit number <lb/>(see Section 13.4.4). <lb/>Note that nfl_pattern_offset is not always the same as lo_offset. <lb/>For example, via the LAYOUTGET operation, a client might request <lb/>a layout starting at offset 1000 of a file that has its striping <lb/>pattern start at offset zero. <lb/>5. nfl_fh_list: An array of data server filehandles for each list of <lb/>data servers in each element of the nflda_multipath_ds_list <lb/>array. The number of elements in nfl_fh_list depends on whether <lb/>sparse or dense packing is being used. <lb/>* If sparse packing is being used, the number of elements in <lb/>nfl_fh_list MUST be one of three values: <lb/>+ Zero. This means that filehandles used for each data <lb/>server are the same as the filehandle returned by the OPEN <lb/>operation from the metadata server. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 335] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>+ One. This means that every data server uses the same <lb/>filehandle: what is specified in nfl_fh_list[0]. <lb/>+ The same number of elements in nflda_multipath_ds_list. <lb/>Thus, in this case, when sending an I/O operation to any <lb/>data server in nflda_multipath_ds_list[X], the filehandle <lb/>in nfl_fh_list[X] MUST be used. <lb/>See the discussion on sparse packing in Section 13.4.4. <lb/>* If dense packing is being used, the number of elements in <lb/>nfl_fh_list MUST be the same as the number of elements in <lb/>nflda_stripe_indices. Thus, when sending an I/O operation to <lb/>any data server in <lb/>nflda_multipath_ds_list[nflda_stripe_indices[Y]], the <lb/>filehandle in nfl_fh_list[Y] MUST be used. In addition, any <lb/>time there exists i and j, (i != j), such that the <lb/>intersection of <lb/>nflda_multipath_ds_list[nflda_stripe_indices[i]] and <lb/>nflda_multipath_ds_list[nflda_stripe_indices[j]] is not empty, <lb/>then nfl_fh_list[i] MUST NOT equal nfl_fh_list[j]. In other <lb/>words, when dense packing is being used, if a data server <lb/>appears in two or more units of a striping pattern, each <lb/>reference to the data server MUST use a different filehandle. <lb/>Indeed, if there are multiple striping patterns, as indicated <lb/>by the presence of multiple objects of data type layout4 <lb/>(either returned in one or multiple LAYOUTGET operations), and <lb/>a data server is the target of a unit of one pattern and <lb/>another unit of another pattern, then each reference to each <lb/>data server MUST use a different filehandle. <lb/>See the discussion on dense packing in Section 13.4.4. <lb/>The details on the interpretation of the layout are in Section 13.4. <lb/>13.4. Interpreting the File Layout <lb/>13.4.1. Determining the Stripe Unit Number <lb/>To find the stripe unit number that corresponds to the client&apos;s <lb/>logical file offset, the pattern offset will also be used. The i&apos;th <lb/>stripe unit (SUi) is: <lb/>relative_offset = file_offset -nfl_pattern_offset; <lb/>SUi = floor(relative_offset / stripe_unit_size); <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 336] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>13.4.2. Interpreting the File Layout Using Sparse Packing <lb/>When sparse packing is used, the algorithm for determining the <lb/>filehandle and set of data-server network addresses to write stripe <lb/>unit i (SUi) to is: <lb/>stripe_count = number of elements in nflda_stripe_indices; <lb/>j = (SUi + nfl_first_stripe_index) % stripe_count; <lb/>idx = nflda_stripe_indices[j]; <lb/>fh_count = number of elements in nfl_fh_list; <lb/>ds_count = number of elements in nflda_multipath_ds_list; <lb/>switch (fh_count) { <lb/>case ds_count: <lb/>fh = nfl_fh_list[idx]; <lb/>break; <lb/>case 1: <lb/>fh = nfl_fh_list[0]; <lb/>break; <lb/>case 0: <lb/>fh = filehandle returned by OPEN; <lb/>break; <lb/>default: <lb/>throw a fatal exception; <lb/>break; <lb/>} <lb/>address_list = nflda_multipath_ds_list[idx]; <lb/>The client would then select a data server from address_list, and <lb/>send a READ or WRITE operation using the filehandle specified in fh. <lb/>Consider the following example: <lb/>Suppose we have a device address consisting of seven data servers, <lb/>arranged in three equivalence (Section 13.5) classes: <lb/>{ A, B, C, D }, { E }, { F, G } <lb/>where A through G are network addresses. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 337] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Then <lb/>nflda_multipath_ds_list&lt;&gt; = { A, B, C, D }, { E }, { F, G } <lb/>i.e., <lb/>nflda_multipath_ds_list[0] = { A, B, C, D } <lb/>nflda_multipath_ds_list[1] = { E } <lb/>nflda_multipath_ds_list[2] = { F, G } <lb/>Suppose the striping index array is: <lb/>nflda_stripe_indices&lt;&gt; = { 2, 0, 1, 0 } <lb/>Now suppose the client gets a layout that has a device ID that maps <lb/>to the above device address. The initial index contains <lb/>nfl_first_stripe_index = 2, <lb/>and the filehandle list is <lb/>nfl_fh_list = { 0x36, 0x87, 0x67 }. <lb/>If the client wants to write to SU0, the set of valid { network <lb/>address, filehandle } combinations for SUi are determined by: <lb/>nfl_first_stripe_index = 2 <lb/>So <lb/>idx = nflda_stripe_indices[(0 + 2) % 4] <lb/>= nflda_stripe_indices[2] <lb/>= 1 <lb/>So <lb/>nflda_multipath_ds_list[1] = { E } <lb/>and <lb/>nfl_fh_list[1] = { 0x87 } <lb/>The client can thus write SU0 to { 0x87, { E } }. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 338] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The destinations of the first 13 storage units are: <lb/>+-----+------------+--------------+ <lb/>| SUi | filehandle | data servers | <lb/>+-----+------------+--------------+ <lb/>| 0 <lb/>| 87 <lb/>| E <lb/>| <lb/>| 1 <lb/>| 36 <lb/>| A,B,C,D <lb/>| <lb/>| 2 <lb/>| 67 <lb/>| F,G <lb/>| <lb/>| 3 <lb/>| 36 <lb/>| A,B,C,D <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| 4 <lb/>| 87 <lb/>| E <lb/>| <lb/>| 5 <lb/>| 36 <lb/>| A,B,C,D <lb/>| <lb/>| 6 <lb/>| 67 <lb/>| F,G <lb/>| <lb/>| 7 <lb/>| 36 <lb/>| A,B,C,D <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| 8 <lb/>| 87 <lb/>| E <lb/>| <lb/>| 9 <lb/>| 36 <lb/>| A,B,C,D <lb/>| <lb/>| 10 | 67 <lb/>| F,G <lb/>| <lb/>| 11 | 36 <lb/>| A,B,C,D <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| 12 | 87 <lb/>| E <lb/>| <lb/>+-----+------------+--------------+ <lb/>13.4.3. Interpreting the File Layout Using Dense Packing <lb/>When dense packing is used, the algorithm for determining the <lb/>filehandle and set of data server network addresses to write stripe <lb/>unit i (SUi) to is: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 339] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>stripe_count = number of elements in nflda_stripe_indices; <lb/>j = (SUi + nfl_first_stripe_index) % stripe_count; <lb/>idx = nflda_stripe_indices[j]; <lb/>fh_count = number of elements in nfl_fh_list; <lb/>ds_count = number of elements in nflda_multipath_ds_list; <lb/>switch (fh_count) { <lb/>case stripe_count: <lb/>fh = nfl_fh_list[j]; <lb/>break; <lb/>default: <lb/>throw a fatal exception; <lb/>break; <lb/>} <lb/>address_list = nflda_multipath_ds_list[idx]; <lb/>The client would then select a data server from address_list, and <lb/>send a READ or WRITE operation using the filehandle specified in fh. <lb/>Consider the following example (which is the same as the sparse <lb/>packing example, except for the filehandle list): <lb/>Suppose we have a device address consisting of seven data servers, <lb/>arranged in three equivalence (Section 13.5) classes: <lb/>{ A, B, C, D }, { E }, { F, G } <lb/>where A through G are network addresses. <lb/>Then <lb/>nflda_multipath_ds_list&lt;&gt; = { A, B, C, D }, { E }, { F, G } <lb/>i.e., <lb/>nflda_multipath_ds_list[0] = { A, B, C, D } <lb/>nflda_multipath_ds_list[1] = { E } <lb/>nflda_multipath_ds_list[2] = { F, G } <lb/>Suppose the striping index array is: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 340] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>nflda_stripe_indices&lt;&gt; = { 2, 0, 1, 0 } <lb/>Now suppose the client gets a layout that has a device ID that maps <lb/>to the above device address. The initial index contains <lb/>nfl_first_stripe_index = 2, <lb/>and <lb/>nfl_fh_list = { 0x67, 0x37, 0x87, 0x36 }. <lb/>The interesting examples for dense packing are SU1 and SU3 because <lb/>each stripe unit refers to the same data server list, yet each stripe <lb/>unit MUST use a different filehandle. If the client wants to write <lb/>to SU1, the set of valid { network address, filehandle } combinations <lb/>for SUi are determined by: <lb/>nfl_first_stripe_index = 2 <lb/>So <lb/>j = (1 + 2) % 4 = 3 <lb/>idx = nflda_stripe_indices[j] <lb/>= nflda_stripe_indices[3] <lb/>= 0 <lb/>So <lb/>nflda_multipath_ds_list[0] = { A, B, C, D } <lb/>and <lb/>nfl_fh_list[3] = { 0x36 } <lb/>The client can thus write SU1 to { 0x36, { A, B, C, D } }. <lb/>For SU3, j = (3 + 2) % 4 = 1, and nflda_stripe_indices[1] = 0. Then <lb/>nflda_multipath_ds_list[0] = { A, B, C, D }, and nfl_fh_list[1] = <lb/>0x37. The client can thus write SU3 to { 0x37, { A, B, C, D } }. <lb/>The destinations of the first 13 storage units are: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 341] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>+-----+------------+--------------+ <lb/>| SUi | filehandle | data servers | <lb/>+-----+------------+--------------+ <lb/>| 0 <lb/>| 87 <lb/>| E <lb/>| <lb/>| 1 <lb/>| 36 <lb/>| A,B,C,D <lb/>| <lb/>| 2 <lb/>| 67 <lb/>| F,G <lb/>| <lb/>| 3 <lb/>| 37 <lb/>| A,B,C,D <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| 4 <lb/>| 87 <lb/>| E <lb/>| <lb/>| 5 <lb/>| 36 <lb/>| A,B,C,D <lb/>| <lb/>| 6 <lb/>| 67 <lb/>| F,G <lb/>| <lb/>| 7 <lb/>| 37 <lb/>| A,B,C,D <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| 8 <lb/>| 87 <lb/>| E <lb/>| <lb/>| 9 <lb/>| 36 <lb/>| A,B,C,D <lb/>| <lb/>| 10 | 67 <lb/>| F,G <lb/>| <lb/>| 11 | 37 <lb/>| A,B,C,D <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| 12 | 87 <lb/>| E <lb/>| <lb/>+-----+------------+--------------+ <lb/>13.4.4. Sparse and Dense Stripe Unit Packing <lb/>The flag NFL4_UFLG_DENSE of the nfl_util4 data type (field nflh_util <lb/>of the data type nfsv4_1_file_layouthint4 and field nfl_util of data <lb/>type nfsv4_1_file_layout_ds_addr4) specifies how the data is packed <lb/>within the data file on a data server. It allows for two different <lb/>data packings: sparse and dense. The packing type determines the <lb/>calculation that will be made to map the client-visible file offset <lb/>to the offset within the data file located on the data server. <lb/>If nfl_util &amp; NFL4_UFLG_DENSE is zero, this means that sparse packing <lb/>is being used. Hence, the logical offsets of the file as viewed by a <lb/>client sending READs and WRITEs directly to the metadata server are <lb/>the same offsets each data server uses when storing a stripe unit. <lb/>The effect then, for striping patterns consisting of at least two <lb/>stripe units, is for each data server file to be sparse or &quot;holey&quot;. <lb/>So for example, suppose there is a pattern with three stripe units, <lb/>the stripe unit size is 4096 bytes, and there are three data servers <lb/>in the pattern. Then, the file in data server 1 will have stripe <lb/>units 0, 3, 6, 9, ... filled; data server 2&apos;s file will have stripe <lb/>units 1, 4, 7, 10, ... filled; and data server 3&apos;s file will have <lb/>stripe units 2, 5, 8, 11, ... filled. The unfilled stripe units of <lb/>each file will be holes; hence, the files in each data server are <lb/>sparse. <lb/>If sparse packing is being used and a client attempts I/O to one of <lb/>the holes, then an error MUST be returned by the data server. Using <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 342] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the above example, if data server 3 received a READ or WRITE <lb/>operation for block 4, the data server would return <lb/>NFS4ERR_PNFS_IO_HOLE. Thus, data servers need to understand the <lb/>striping pattern in order to support sparse packing. <lb/>If nfl_util &amp; NFL4_UFLG_DENSE is one, this means that dense packing <lb/>is being used, and the data server files have no holes. Dense <lb/>packing might be selected because the data server does not <lb/>(efficiently) support holey files or because the data server cannot <lb/>recognize read-ahead unless there are no holes. If dense packing is <lb/>indicated in the layout, the data files will be packed. Using the <lb/>same striping pattern and stripe unit size that were used for the <lb/>sparse packing example, the corresponding dense packing example would <lb/>have all stripe units of all data files filled as follows: <lb/>o Logical stripe units 0, 3, 6, ... of the file would live on stripe <lb/>units 0, 1, 2, ... of the file of data server 1. <lb/>o Logical stripe units 1, 4, 7, ... of the file would live on stripe <lb/>units 0, 1, 2, ... of the file of data server 2. <lb/>o Logical stripe units 2, 5, 8, ... of the file would live on stripe <lb/>units 0, 1, 2, ... of the file of data server 3. <lb/>Because dense packing does not leave holes on the data servers, the <lb/>pNFS client is allowed to write to any offset of any data file of any <lb/>data server in the stripe. Thus, the data servers need not know the <lb/>file&apos;s striping pattern. <lb/>The calculation to determine the byte offset within the data file for <lb/>dense data server layouts is: <lb/>stripe_width = stripe_unit_size * N; <lb/>where N = number of elements in nflda_stripe_indices. <lb/>relative_offset = file_offset -nfl_pattern_offset; <lb/>data_file_offset = floor(relative_offset / stripe_width) <lb/>* stripe_unit_size <lb/>+ relative_offset % stripe_unit_size <lb/>If dense packing is being used, and a data server appears more than <lb/>once in a striping pattern, then to distinguish one stripe unit from <lb/>another, the data server MUST use a different filehandle. Let&apos;s <lb/>suppose there are two data servers. Logical stripe units 0, 3, 6 are <lb/>served by data server 1; logical stripe units 1, 4, 7 are served by <lb/>data server 2; and logical stripe units 2, 5, 8 are also served by <lb/>data server 2. Unless data server 2 has two filehandles (each <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 343] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>referring to a different data file), then, for example, a write to <lb/>logical stripe unit 1 overwrites the write to logical stripe unit 2 <lb/>because both logical stripe units are located in the same stripe unit <lb/>(0) of data server 2. <lb/>13.5. Data Server Multipathing <lb/>The NFSv4.1 file layout supports multipathing to multiple data server <lb/>addresses. Data-server-level multipathing is used for bandwidth <lb/>scaling via trunking (Section 2.10.5) and for higher availability of <lb/>use in the case of a data-server failure. Multipathing allows the <lb/>client to switch to another data server address which may be that of <lb/>another data server that is exporting the same data stripe unit, <lb/>without having to contact the metadata server for a new layout. <lb/>To support data server multipathing, each element of the <lb/>nflda_multipath_ds_list contains an array of one more data server <lb/>network addresses. This array (data type multipath_list4) represents <lb/>a list of data servers (each identified by a network address), with <lb/>the possibility that some data servers will appear in the list <lb/>multiple times. <lb/>The client is free to use any of the network addresses as a <lb/>destination to send data server requests. If some network addresses <lb/>are less optimal paths to the data than others, then the MDS SHOULD <lb/>NOT include those network addresses in an element of <lb/>nflda_multipath_ds_list. If less optimal network addresses exist to <lb/>provide failover, the RECOMMENDED method to offer the addresses is to <lb/>provide them in a replacement device-ID-to-device-address mapping, or <lb/>a replacement device ID. When a client finds that no data server in <lb/>an element of nflda_multipath_ds_list responds, it SHOULD send a <lb/>GETDEVICEINFO to attempt to replace the existing device-ID-to-device-<lb/>address mappings. If the MDS detects that all data servers <lb/>represented by an element of nflda_multipath_ds_list are unavailable, <lb/>the MDS SHOULD send a CB_NOTIFY_DEVICEID (if the client has indicated <lb/>it wants device ID notifications for changed device IDs) to change <lb/>the device-ID-to-device-address mappings to the available data <lb/>servers. If the device ID itself will be replaced, the MDS SHOULD <lb/>recall all layouts with the device ID, and thus force the client to <lb/>get new layouts and device ID mappings via LAYOUTGET and <lb/>GETDEVICEINFO. <lb/>Generally, if two network addresses appear in an element of <lb/>nflda_multipath_ds_list, they will designate the same data server, <lb/>and the two data server addresses will support the implementation of <lb/>client ID or session trunking (the latter is RECOMMENDED) as defined <lb/>in Section 2.10.5. The two data server addresses will share the same <lb/>server owner or major ID of the server owner. It is not always <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 344] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>necessary for the two data server addresses to designate the same <lb/>server with trunking being used. For example, the data could be <lb/>read-only, and the data consist of exact replicas. <lb/>13.6. Operations Sent to NFSv4.1 Data Servers <lb/>Clients accessing data on an NFSv4.1 data server MUST send only the <lb/>NULL procedure and COMPOUND procedures whose operations are taken <lb/>only from two restricted subsets of the operations defined as valid <lb/>NFSv4.1 operations. Clients MUST use the filehandle specified by the <lb/>layout when accessing data on NFSv4.1 data servers. <lb/>The first of these operation subsets consists of management <lb/>operations. This subset consists of the BACKCHANNEL_CTL, <lb/>BIND_CONN_TO_SESSION, CREATE_SESSION, DESTROY_CLIENTID, <lb/>DESTROY_SESSION, EXCHANGE_ID, SECINFO_NO_NAME, SET_SSV, and SEQUENCE <lb/>operations. The client may use these operations in order to set up <lb/>and maintain the appropriate client IDs, sessions, and security <lb/>contexts involved in communication with the data server. Henceforth, <lb/>these will be referred to as data-server housekeeping operations. <lb/>The second subset consists of COMMIT, READ, WRITE, and PUTFH. These <lb/>operations MUST be used with a current filehandle specified by the <lb/>layout. In the case of PUTFH, the new current filehandle MUST be one <lb/>taken from the layout. Henceforth, these will be referred to as <lb/>data-server I/O operations. As described in Section 12.5.1, a client <lb/>MUST NOT send an I/O to a data server for which it does not hold a <lb/>valid layout; the data server MUST reject such an I/O. <lb/>Unless the server has a concurrent non-data-server personality --<lb/>i.e., EXCHANGE_ID results returned (EXCHGID4_FLAG_USE_PNFS_DS | <lb/>EXCHGID4_FLAG_USE_PNFS_MDS) or (EXCHGID4_FLAG_USE_PNFS_DS | <lb/>EXCHGID4_FLAG_USE_NON_PNFS) see Section 13.1 --any attempted use of <lb/>operations against a data server other than those specified in the <lb/>two subsets above MUST return NFS4ERR_NOTSUPP to the client. <lb/>When the server has concurrent data-server and non-data-server <lb/>personalities, each COMPOUND sent by the client MUST be constructed <lb/>so that it is appropriate to one of the two personalities, and it <lb/>MUST NOT contain operations directed to a mix of those personalities. <lb/>The server MUST enforce this. To understand the constraints, <lb/>operations within a COMPOUND are divided into the following three <lb/>classes: <lb/>1. An operation that is ambiguous regarding its personality <lb/>assignment. This includes all of the data-server housekeeping <lb/>operations. Additionally, if the server has assigned filehandles <lb/>so that the ones defined by the layout are the same as those used <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 345] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>by the metadata server, all operations using such filehandles are <lb/>within this class, with the following exception. The exception <lb/>is that if the operation uses a stateid that is incompatible with <lb/>a data-server personality (e.g., a special stateid or the stateid <lb/>has a non-zero &quot;seqid&quot; field, see Section 13.9.1), the operation <lb/>is in class 3, as described below. A COMPOUND containing <lb/>multiple class 1 operations (and operations of no other class) <lb/>MAY be sent to a server with multiple concurrent data server and <lb/>non-data-server personalities. <lb/>2. An operation that is unambiguously referable to the data-server <lb/>personality. This includes data-server I/O operations where the <lb/>filehandle is one that can only be validly directed to the data-<lb/>server personality. <lb/>3. An operation that is unambiguously referable to the non-data-<lb/>server personality. This includes all COMPOUND operations that <lb/>are neither data-server housekeeping nor data-server I/O <lb/>operations, plus data-server I/O operations where the current fh <lb/>(or the one to be made the current fh in the case of PUTFH) is <lb/>only valid on the metadata server or where a stateid is used that <lb/>is incompatible with the data server, i.e., is a special stateid <lb/>or has a non-zero seqid value. <lb/>When a COMPOUND first executes an operation from class 3 above, it <lb/>acts as a normal COMPOUND on any other server, and the data-server <lb/>personality ceases to be relevant. There are no special restrictions <lb/>on the operations in the COMPOUND to limit them to those for a data <lb/>server. When a PUTFH is done, filehandles derived from the layout <lb/>are not valid. If their format is not normally acceptable, then <lb/>NFS4ERR_BADHANDLE MUST result. Similarly, current filehandles for <lb/>other operations do not accept filehandles derived from layouts and <lb/>are not normally usable on the metadata server. Using these will <lb/>result in NFS4ERR_STALE. <lb/>When a COMPOUND first executes an operation from class 2, which would <lb/>be PUTFH where the filehandle is one from a layout, the COMPOUND <lb/>henceforth is interpreted with respect to the data-server <lb/>personality. Operations outside the two classes discussed above MUST <lb/>result in NFS4ERR_NOTSUPP. Filehandles are validated using the rules <lb/>of the data server, resulting in NFS4ERR_BADHANDLE and/or <lb/>NFS4ERR_STALE even when they would not normally do so when addressed <lb/>to the non-data-server personality. Stateids must obey the rules of <lb/>the data server in that any use of special stateids or stateids with <lb/>non-zero seqid values must result in NFS4ERR_BAD_STATEID. <lb/>Until the server first executes an operation from class 2 or class 3, <lb/>the client MUST NOT depend on the operation being executed by either <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 346] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the data-server or the non-data-server personality. The server MUST <lb/>pick one personality consistently for a given COMPOUND, with the only <lb/>possible transition being a single one when the first operation from <lb/>class 2 or class 3 is executed. <lb/>Because of the complexity induced by assigning filehandles so they <lb/>can be used on both a data server and a metadata server, it is <lb/>RECOMMENDED that where the same server can have both personalities, <lb/>the server assign separate unique filehandles to both personalities. <lb/>This makes it unambiguous for which server a given request is <lb/>intended. <lb/>GETATTR and SETATTR MUST be directed to the metadata server. In the <lb/>case of a SETATTR of the size attribute, the control protocol is <lb/>responsible for propagating size updates/truncations to the data <lb/>servers. In the case of extending WRITEs to the data servers, the <lb/>new size must be visible on the metadata server once a LAYOUTCOMMIT <lb/>has completed (see Section 12.5.4.2). Section 13.10 describes the <lb/>mechanism by which the client is to handle data-server files that do <lb/>not reflect the metadata server&apos;s size. <lb/>13.7. COMMIT through Metadata Server <lb/>The file layout provides two alternate means of providing for the <lb/>commit of data written through data servers. The flag <lb/>NFL4_UFLG_COMMIT_THRU_MDS in the field nfl_util of the file layout <lb/>(data type nfsv4_1_file_layout4) is an indication from the metadata <lb/>server to the client of the REQUIRED way of performing COMMIT, either <lb/>by sending the COMMIT to the data server or the metadata server. <lb/>These two methods of dealing with the issue correspond to broad <lb/>styles of implementation for a pNFS server supporting the file layout <lb/>type. <lb/>o When the flag is FALSE, COMMIT operations MUST to be sent to the <lb/>data server to which the corresponding WRITE operations were sent. <lb/>This approach is sometimes useful when file striping is <lb/>implemented within the pNFS server (instead of the file system), <lb/>with the individual data servers each implementing their own file <lb/>systems. <lb/>o When the flag is TRUE, COMMIT operations MUST be sent to the <lb/>metadata server, rather than to the individual data servers. This <lb/>approach is sometimes useful when file striping is implemented <lb/>within the clustered file system that is the backend to the pNFS <lb/>server. In such an implementation, each COMMIT to each data <lb/>server might result in repeated writes of metadata blocks to the <lb/>detriment of write performance. Sending a single COMMIT to the <lb/>metadata server can be more efficient when there exists a <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 347] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>clustered file system capable of implementing such a coordinated <lb/>COMMIT. <lb/>If nfl_util &amp; NFL4_UFLG_COMMIT_THRU_MDS is TRUE, then in order to <lb/>maintain the current NFSv4.1 commit and recovery model, the data <lb/>servers MUST return a common writeverf verifier in all WRITE <lb/>responses for a given file layout, and the metadata server&apos;s <lb/>COMMIT implementation must return the same writeverf. The value <lb/>of the writeverf verifier MUST be changed at the metadata server <lb/>or any data server that is referenced in the layout, whenever <lb/>there is a server event that can possibly lead to loss of <lb/>uncommitted data. The scope of the verifier can be for a file or <lb/>for the entire pNFS server. It might be more difficult for the <lb/>server to maintain the verifier at the file level, but the benefit <lb/>is that only events that impact a given file will require recovery <lb/>action. <lb/>Note that if the layout specified dense packing, then the offset used <lb/>to a COMMIT to the MDS may differ than that of an offset used to a <lb/>COMMIT to the data server. <lb/>The single COMMIT to the metadata server will return a verifier, and <lb/>the client should compare it to all the verifiers from the WRITEs and <lb/>fail the COMMIT if there are any mismatched verifiers. If COMMIT to <lb/>the metadata server fails, the client should re-send WRITEs for all <lb/>the modified data in the file. The client should treat modified data <lb/>with a mismatched verifier as a WRITE failure and try to recover by <lb/>resending the WRITEs to the original data server or using another <lb/>path to that data if the layout has not been recalled. <lb/>Alternatively, the client can obtain a new layout or it could rewrite <lb/>the data directly to the metadata server. If nfl_util &amp; <lb/>NFL4_UFLG_COMMIT_THRU_MDS is FALSE, sending a COMMIT to the metadata <lb/>server might have no effect. If nfl_util &amp; NFL4_UFLG_COMMIT_THRU_MDS <lb/>is FALSE, a COMMIT sent to the metadata server should be used only to <lb/>commit data that was written to the metadata server. See <lb/>Section 12.7.6 for recovery options. <lb/>13.8. The Layout Iomode <lb/>The layout iomode need not be used by the metadata server when <lb/>servicing NFSv4.1 file-based layouts, although in some circumstances <lb/>it may be useful. For example, if the server implementation supports <lb/>reading from read-only replicas or mirrors, it would be useful for <lb/>the server to return a layout enabling the client to do so. As such, <lb/>the client SHOULD set the iomode based on its intent to read or write <lb/>the data. The client may default to an iomode of LAYOUTIOMODE4_RW. <lb/>The iomode need not be checked by the data servers when clients <lb/>perform I/O. However, the data servers SHOULD still validate that <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 348] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the client holds a valid layout and return an error if the client <lb/>does not. <lb/>13.9. Metadata and Data Server State Coordination <lb/>13.9.1. Global Stateid Requirements <lb/>When the client sends I/O to a data server, the stateid used MUST NOT <lb/>be a layout stateid as returned by LAYOUTGET or sent by <lb/>CB_LAYOUTRECALL. Permitted stateids are based on one of the <lb/>following: an OPEN stateid (the stateid field of data type OPEN4resok <lb/>as returned by OPEN), a delegation stateid (the stateid field of data <lb/>types open_read_delegation4 and open_write_delegation4 as returned by <lb/>OPEN or WANT_DELEGATION, or as sent by CB_PUSH_DELEG), or a stateid <lb/>returned by the LOCK or LOCKU operations. The stateid sent to the <lb/>data server MUST be sent with the seqid set to zero, indicating the <lb/>most current version of that stateid, rather than indicating a <lb/>specific non-zero seqid value. In no case is the use of special <lb/>stateid values allowed. <lb/>The stateid used for I/O MUST have the same effect and be subject to <lb/>the same validation on a data server as it would if the I/O was being <lb/>performed on the metadata server itself in the absence of pNFS. This <lb/>has the implication that stateids are globally valid on both the <lb/>metadata and data servers. This requires the metadata server to <lb/>propagate changes in LOCK and OPEN state to the data servers, so that <lb/>the data servers can validate I/O accesses. This is discussed <lb/>further in Section 13.9.2. Depending on when stateids are <lb/>propagated, the existence of a valid stateid on the data server may <lb/>act as proof of a valid layout. <lb/>Clients performing I/O operations need to select an appropriate <lb/>stateid based on the locks (including opens and delegations) held by <lb/>the client and the various types of state-owners sending the I/O <lb/>requests. The rules for doing so when referencing data servers are <lb/>somewhat different from those discussed in Section 8.2.5, which apply <lb/>when accessing metadata servers. <lb/>The following rules, applied in order of decreasing priority, govern <lb/>the selection of the appropriate stateid: <lb/>o If the client holds a delegation for the file in question, the <lb/>delegation stateid should be used. <lb/>o Otherwise, there must be an OPEN stateid for the current open-<lb/>owner, and that OPEN stateid for the open file in question is <lb/>used, unless mandatory locking prevents that. See below. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 349] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o If the data server had previously responded with NFS4ERR_LOCKED to <lb/>use of the OPEN stateid, then the client should use the byte-range <lb/>lock stateid whenever one exists for that open file with the <lb/>current lock-owner. <lb/>o Special stateids should never be used. If they are used, the data <lb/>server MUST reject the I/O with an NFS4ERR_BAD_STATEID error. <lb/>13.9.2. Data Server State Propagation <lb/>Since the metadata server, which handles byte-range lock and open-<lb/>mode state changes as well as ACLs, might not be co-located with the <lb/>data servers where I/O accesses are validated, the server <lb/>implementation MUST take care of propagating changes of this state to <lb/>the data servers. Once the propagation to the data servers is <lb/>complete, the full effect of those changes MUST be in effect at the <lb/>data servers. However, some state changes need not be propagated <lb/>immediately, although all changes SHOULD be propagated promptly. <lb/>These state propagations have an impact on the design of the control <lb/>protocol, even though the control protocol is outside of the scope of <lb/>this specification. Immediate propagation refers to the synchronous <lb/>propagation of state from the metadata server to the data server(s); <lb/>the propagation must be complete before returning to the client. <lb/>13.9.2.1. Lock State Propagation <lb/>If the pNFS server supports mandatory byte-range locking, any <lb/>mandatory byte-range locks on a file MUST be made effective at the <lb/>data servers before the request that establishes them returns to the <lb/>caller. The effect MUST be the same as if the mandatory byte-range <lb/>lock state were synchronously propagated to the data servers, even <lb/>though the details of the control protocol may avoid actual transfer <lb/>of the state under certain circumstances. <lb/>On the other hand, since advisory byte-range lock state is not used <lb/>for checking I/O accesses at the data servers, there is no semantic <lb/>reason for propagating advisory byte-range lock state to the data <lb/>servers. Since updates to advisory locks neither confer nor remove <lb/>privileges, these changes need not be propagated immediately, and may <lb/>not need to be propagated promptly. The updates to advisory locks <lb/>need only be propagated when the data server needs to resolve a <lb/>question about a stateid. In fact, if byte-range locking is not <lb/>mandatory (i.e., is advisory) the clients are advised to avoid using <lb/>the byte-range lock-based stateids for I/O. The stateids returned by <lb/>OPEN are sufficient and eliminate overhead for this kind of state <lb/>propagation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 350] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If a client gets back an NFS4ERR_LOCKED error from a data server, <lb/>this is an indication that mandatory byte-range locking is in force. <lb/>The client recovers from this by getting a byte-range lock that <lb/>covers the affected range and re-sends the I/O with the stateid of <lb/>the byte-range lock. <lb/>13.9.2.2. Open and Deny Mode Validation <lb/>Open and deny mode validation MUST be performed against the open and <lb/>deny mode(s) held by the data servers. When access is reduced or a <lb/>deny mode made more restrictive (because of CLOSE or OPEN_DOWNGRADE), <lb/>the data server MUST prevent any I/Os that would be denied if <lb/>performed on the metadata server. When access is expanded, the data <lb/>server MUST make sure that no requests are subsequently rejected <lb/>because of open or deny issues that no longer apply, given the <lb/>previous relaxation. <lb/>13.9.2.3. File Attributes <lb/>Since the SETATTR operation has the ability to modify state that is <lb/>visible on both the metadata and data servers (e.g., the size), care <lb/>must be taken to ensure that the resultant state across the set of <lb/>data servers is consistent, especially when truncating or growing the <lb/>file. <lb/>As described earlier, the LAYOUTCOMMIT operation is used to ensure <lb/>that the metadata is synchronized with changes made to the data <lb/>servers. For the NFSv4.1-based data storage protocol, it is <lb/>necessary to re-synchronize state such as the size attribute, and the <lb/>setting of mtime/change/atime. See Section 12.5.4 for a full <lb/>description of the semantics regarding LAYOUTCOMMIT and attribute <lb/>synchronization. It should be noted that by using an NFSv4.1-based <lb/>layout type, it is possible to synchronize this state before <lb/>LAYOUTCOMMIT occurs. For example, the control protocol can be used <lb/>to query the attributes present on the data servers. <lb/>Any changes to file attributes that control authorization or access <lb/>as reflected by ACCESS calls or READs and WRITEs on the metadata <lb/>server, MUST be propagated to the data servers for enforcement on <lb/>READ and WRITE I/O calls. If the changes made on the metadata server <lb/>result in more restrictive access permissions for any user, those <lb/>changes MUST be propagated to the data servers synchronously. <lb/>The OPEN operation (Section 18.16.4) does not impose any requirement <lb/>that I/O operations on an open file have the same credentials as the <lb/>OPEN itself (unless EXCHGID4_FLAG_BIND_PRINC_STATEID is set when <lb/>EXCHANGE_ID creates the client ID), and so it requires the server&apos;s <lb/>READ and WRITE operations to perform appropriate access checking. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 351] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Changes to ACLs also require new access checking by READ and WRITE on <lb/>the server. The propagation of access-right changes due to changes <lb/>in ACLs may be asynchronous only if the server implementation is able <lb/>to determine that the updated ACL is not more restrictive for any <lb/>user specified in the old ACL. Due to the relative infrequency of <lb/>ACL updates, it is suggested that all changes be propagated <lb/>synchronously. <lb/>13.10. Data Server Component File Size <lb/>A potential problem exists when a component data file on a particular <lb/>data server has grown past EOF; the problem exists for both dense and <lb/>sparse layouts. Imagine the following scenario: a client creates a <lb/>new file (size == 0) and writes to byte 131072; the client then seeks <lb/>to the beginning of the file and reads byte 100. The client should <lb/>receive zeroes back as a result of the READ. However, if the <lb/>striping pattern directs the client to send the READ to a data server <lb/>other than the one that received the client&apos;s original WRITE, the <lb/>data server servicing the READ may believe that the file&apos;s size is <lb/>still 0 bytes. In that event, the data server&apos;s READ response will <lb/>contain zero bytes and an indication of EOF. The data server can <lb/>only return zeroes if it knows that the file&apos;s size has been <lb/>extended. This would require the immediate propagation of the file&apos;s <lb/>size to all data servers, which is potentially very costly. <lb/>Therefore, the client that has initiated the extension of the file&apos;s <lb/>size MUST be prepared to deal with these EOF conditions. When the <lb/>offset in the arguments to READ is less than the client&apos;s view of the <lb/>file size, if the READ response indicates EOF and/or contains fewer <lb/>bytes than requested, the client will interpret such a response as a <lb/>hole in the file, and the NFS client will substitute zeroes for the <lb/>data. <lb/>The NFSv4.1 protocol only provides close-to-open file data cache <lb/>semantics; meaning that when the file is closed, all modified data is <lb/>written to the server. When a subsequent OPEN of the file is done, <lb/>the change attribute is inspected for a difference from a cached <lb/>value for the change attribute. For the case above, this means that <lb/>a LAYOUTCOMMIT will be done at close (along with the data WRITEs) and <lb/>will update the file&apos;s size and change attribute. Access from <lb/>another client after that point will result in the appropriate size <lb/>being returned. <lb/>13.11. Layout Revocation and Fencing <lb/>As described in Section 12.7, the layout-type-specific storage <lb/>protocol is responsible for handling the effects of I/Os that started <lb/>before lease expiration and extend through lease expiration. The <lb/>LAYOUT4_NFSV4_1_FILES layout type can prevent all I/Os to data <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 352] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>servers from being executed after lease expiration (this prevention <lb/>is called &quot;fencing&quot;), without relying on a precise client lease timer <lb/>and without requiring data servers to maintain lease timers. The <lb/>LAYOUT4_NFSV4_1_FILES pNFS server has the flexibility to revoke <lb/>individual layouts, and thus fence I/O on a per-file basis. <lb/>In addition to lease expiration, the reasons a layout can be revoked <lb/>include: client fails to respond to a CB_LAYOUTRECALL, the metadata <lb/>server restarts, or administrative intervention. Regardless of the <lb/>reason, once a client&apos;s layout has been revoked, the pNFS server MUST <lb/>prevent the client from sending I/O for the affected file from and to <lb/>all data servers; in other words, it MUST fence the client from the <lb/>affected file on the data servers. <lb/>Fencing works as follows. As described in Section 13.1, in COMPOUND <lb/>procedure requests to the data server, the data filehandle provided <lb/>by the PUTFH operation and the stateid in the READ or WRITE operation <lb/>are used to ensure that the client has a valid layout for the I/O <lb/>being performed; if it does not, the I/O is rejected with <lb/>NFS4ERR_PNFS_NO_LAYOUT. The server can simply check the stateid and, <lb/>additionally, make the data filehandle stale if the layout specified <lb/>a data filehandle that is different from the metadata server&apos;s <lb/>filehandle for the file (see the nfl_fh_list description in <lb/>Section 13.3). <lb/>Before the metadata server takes any action to revoke layout state <lb/>given out by a previous instance, it must make sure that all layout <lb/>state from that previous instance are invalidated at the data <lb/>servers. This has the following implications. <lb/>o The metadata server must not restripe a file until it has <lb/>contacted all of the data servers to invalidate the layouts from <lb/>the previous instance. <lb/>o The metadata server must not give out mandatory locks that <lb/>conflict with layouts from the previous instance without either <lb/>doing a specific layout invalidation (as it would have to do <lb/>anyway) or doing a global data server invalidation. <lb/>13.12. Security Considerations for the File Layout Type <lb/>The NFSv4.1 file layout type MUST adhere to the security <lb/>considerations outlined in Section 12.9. NFSv4.1 data servers MUST <lb/>make all of the required access checks on each READ or WRITE I/O as <lb/>determined by the NFSv4.1 protocol. If the metadata server would <lb/>deny a READ or WRITE operation on a file due to its ACL, mode <lb/>attribute, open access mode, open deny mode, mandatory byte-range <lb/>lock state, or any other attributes and state, the data server MUST <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 353] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>also deny the READ or WRITE operation. This impacts the control <lb/>protocol and the propagation of state from the metadata server to the <lb/>data servers; see Section 13.9.2 for more details. <lb/>The methods for authentication, integrity, and privacy for data <lb/>servers based on the LAYOUT4_NFSV4_1_FILES layout type are the same <lb/>as those used by metadata servers. Metadata and data servers use ONC <lb/>RPC security flavors to authenticate, and SECINFO and SECINFO_NO_NAME <lb/>to negotiate the security mechanism and services to be used. Thus, <lb/>when using the LAYOUT4_NFSV4_1_FILES layout type, the impact on the <lb/>RPC-based security model due to pNFS (as alluded to in Sections 1.8.1 <lb/>and 1.8.2.2) is zero. <lb/>For a given file object, a metadata server MAY require different <lb/>security parameters (secinfo4 value) than the data server. For a <lb/>given file object with multiple data servers, the secinfo4 value <lb/>SHOULD be the same across all data servers. If the secinfo4 values <lb/>across a metadata server and its data servers differ for a specific <lb/>file, the mapping of the principal to the server&apos;s internal user <lb/>identifier MUST be the same in order for the access-control checks <lb/>based on ACL, mode, open and deny mode, and mandatory locking to be <lb/>consistent across on the pNFS server. <lb/>If an NFSv4.1 implementation supports pNFS and supports NFSv4.1 file <lb/>layouts, then the implementation MUST support the SECINFO_NO_NAME <lb/>operation on both the metadata and data servers. <lb/>14. Internationalization <lb/>The primary issue in which NFSv4.1 needs to deal with <lb/>internationalization, or I18N, is with respect to file names and <lb/>other strings as used within the protocol. The choice of string <lb/>representation must allow reasonable name/string access to clients <lb/>that use various languages. The UTF-8 encoding of the UCS (Universal <lb/>Multiple-Octet Coded Character Set) as defined by ISO10646 [18] <lb/>allows for this type of access and follows the policy described in <lb/>&quot;IETF Policy on Character Sets and Languages&quot;, RFC 2277 [19]. <lb/>RFC 3454 [16], otherwise know as &quot;stringprep&quot;, documents a framework <lb/>for using Unicode/UTF-8 in networking protocols so as &quot;to increase <lb/>the likelihood that string input and string comparison work in ways <lb/>that make sense for typical users throughout the world&quot;. A protocol <lb/>must define a profile of stringprep &quot;in order to fully specify the <lb/>processing options&quot;. The remainder of this section defines the <lb/>NFSv4.1 stringprep profiles. Much of the terminology used for the <lb/>remainder of this section comes from stringprep. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 354] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>There are three UTF-8 string types defined for NFSv4.1: utf8str_cs, <lb/>utf8str_cis, and utf8str_mixed. Separate profiles are defined for <lb/>each. Each profile defines the following, as required by stringprep: <lb/>o The intended applicability of the profile. <lb/>o The character repertoire that is the input and output to <lb/>stringprep (which is Unicode 3.2 for the referenced version of <lb/>stringprep). However, NFSv4.1 implementations are not limited to <lb/>3.2. <lb/>o The mapping tables from stringprep used (as described in Section 3 <lb/>of stringprep). <lb/>o Any additional mapping tables specific to the profile. <lb/>o The Unicode normalization used, if any (as described in Section 4 <lb/>of stringprep). <lb/>o The tables from the stringprep listing of characters that are <lb/>prohibited as output (as described in Section 5 of stringprep). <lb/>o The bidirectional string testing used, if any (as described in <lb/>Section 6 of stringprep). <lb/>o Any additional characters that are prohibited as output specific <lb/>to the profile. <lb/>Stringprep discusses Unicode characters, whereas NFSv4.1 renders <lb/>UTF-8 characters. Since there is a one-to-one mapping from UTF-8 to <lb/>Unicode, when the remainder of this document refers to Unicode, the <lb/>reader should assume UTF-8. <lb/>Much of the text for the profiles comes from RFC 3491 [20]. <lb/>14.1. Stringprep Profile for the utf8str_cs Type <lb/>Every use of the utf8str_cs type definition in the NFSv4 protocol <lb/>specification follows the profile named nfs4_cs_prep. <lb/>14.1.1. Intended Applicability of the nfs4_cs_prep Profile <lb/>The utf8str_cs type is a case-sensitive string of UTF-8 characters. <lb/>Its primary use in NFSv4.1 is for naming components and pathnames. <lb/>Components and pathnames are stored on the server&apos;s file system. Two <lb/>valid distinct UTF-8 strings might be the same after processing via <lb/>the utf8str_cs profile. If the strings are two names inside a <lb/>directory, the NFSv4.1 server will need to either: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 355] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o disallow the creation of a second name if its post-processed form <lb/>collides with that of an existing name, or <lb/>o allow the creation of the second name, but arrange so that after <lb/>post-processing, the second name is different than the post-<lb/>processed form of the first name. <lb/>14.1.2. Character Repertoire of nfs4_cs_prep <lb/>The nfs4_cs_prep profile uses Unicode 3.2, as defined in stringprep&apos;s <lb/>Appendix A.1. However, NFSv4.1 implementations are not limited to <lb/>3.2. <lb/>14.1.3. Mapping Used by nfs4_cs_prep <lb/>The nfs4_cs_prep profile specifies mapping using the following tables <lb/>from stringprep: <lb/>Table B.1 <lb/>Table B.2 is normally not part of the nfs4_cs_prep profile as it is <lb/>primarily for dealing with case-insensitive comparisons. However, if <lb/>the NFSv4.1 file server supports the case_insensitive file system <lb/>attribute, and if case_insensitive is TRUE, the NFSv4.1 server MUST <lb/>use Table B.2 (in addition to Table B1) when processing utf8str_cs <lb/>strings, and the NFSv4.1 client MUST assume Table B.2 (in addition to <lb/>Table B.1) is being used. <lb/>If the case_preserving attribute is present and set to FALSE, then <lb/>the NFSv4.1 server MUST use Table B.2 to map case when processing <lb/>utf8str_cs strings. Whether the server maps from lower to upper case <lb/>or from upper to lower case is an implementation dependency. <lb/>14.1.4. Normalization used by nfs4_cs_prep <lb/>The nfs4_cs_prep profile does not specify a normalization form. A <lb/>later revision of this specification may specify a particular <lb/>normalization form. Therefore, the server and client can expect that <lb/>they may receive unnormalized characters within protocol requests and <lb/>responses. If the operating environment requires normalization, then <lb/>the implementation must normalize utf8str_cs strings within the <lb/>protocol before presenting the information to an application (at the <lb/>client) or local file system (at the server). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 356] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>14.1.5. Prohibited Output for nfs4_cs_prep <lb/>The nfs4_cs_prep profile RECOMMENDS prohibiting the use of the <lb/>following tables from stringprep: <lb/>Table C.5 <lb/>Table C.6 <lb/>14.1.6. Bidirectional Output for nfs4_cs_prep <lb/>The nfs4_cs_prep profile does not specify any checking of <lb/>bidirectional strings. <lb/>14.2. Stringprep Profile for the utf8str_cis Type <lb/>Every use of the utf8str_cis type definition in the NFSv4.1 protocol <lb/>specification follows the profile named nfs4_cis_prep. <lb/>14.2.1. Intended Applicability of the nfs4_cis_prep Profile <lb/>The utf8str_cis type is a case-insensitive string of UTF-8 <lb/>characters. Its primary use in NFSv4.1 is for naming NFS servers. <lb/>14.2.2. Character Repertoire of nfs4_cis_prep <lb/>The nfs4_cis_prep profile uses Unicode 3.2, as defined in <lb/>stringprep&apos;s Appendix A.1. However, NFSv4.1 implementations are not <lb/>limited to 3.2. <lb/>14.2.3. Mapping Used by nfs4_cis_prep <lb/>The nfs4_cis_prep profile specifies mapping using the following <lb/>tables from stringprep: <lb/>Table B.1 <lb/>Table B.2 <lb/>14.2.4. Normalization Used by nfs4_cis_prep <lb/>The nfs4_cis_prep profile specifies using Unicode normalization form <lb/>KC, as described in stringprep. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 357] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>14.2.5. Prohibited Output for nfs4_cis_prep <lb/>The nfs4_cis_prep profile specifies prohibiting using the following <lb/>tables from stringprep: <lb/>Table C.1.2 <lb/>Table C.2.2 <lb/>Table C.3 <lb/>Table C.4 <lb/>Table C.5 <lb/>Table C.6 <lb/>Table C.7 <lb/>Table C.8 <lb/>Table C.9 <lb/>14.2.6. Bidirectional Output for nfs4_cis_prep <lb/>The nfs4_cis_prep profile specifies checking bidirectional strings as <lb/>described in stringprep&apos;s Section 6. <lb/>14.3. Stringprep Profile for the utf8str_mixed Type <lb/>Every use of the utf8str_mixed type definition in the NFSv4.1 <lb/>protocol specification follows the profile named nfs4_mixed_prep. <lb/>14.3.1. Intended Applicability of the nfs4_mixed_prep Profile <lb/>The utf8str_mixed type is a string of UTF-8 characters, with a prefix <lb/>that is case sensitive, a separator equal to &apos;@&apos;, and a suffix that <lb/>is a fully qualified domain name. Its primary use in NFSv4.1 is for <lb/>naming principals identified in an Access Control Entry. <lb/>14.3.2. Character Repertoire of nfs4_mixed_prep <lb/>The nfs4_mixed_prep profile uses Unicode 3.2, as defined in <lb/>stringprep&apos;s Appendix A.1. However, NFSv4.1 implementations are not <lb/>limited to 3.2. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 358] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>14.3.3. Mapping Used by nfs4_cis_prep <lb/>For the prefix and the separator of a utf8str_mixed string, the <lb/>nfs4_mixed_prep profile specifies mapping using the following table <lb/>from stringprep: <lb/>Table B.1 <lb/>For the suffix of a utf8str_mixed string, the nfs4_mixed_prep profile <lb/>specifies mapping using the following tables from stringprep: <lb/>Table B.1 <lb/>Table B.2 <lb/>14.3.4. Normalization Used by nfs4_mixed_prep <lb/>The nfs4_mixed_prep profile specifies using Unicode normalization <lb/>form KC, as described in stringprep. <lb/>14.3.5. Prohibited Output for nfs4_mixed_prep <lb/>The nfs4_mixed_prep profile specifies prohibiting using the following <lb/>tables from stringprep: <lb/>Table C.1.2 <lb/>Table C.2.2 <lb/>Table C.3 <lb/>Table C.4 <lb/>Table C.5 <lb/>Table C.6 <lb/>Table C.7 <lb/>Table C.8 <lb/>Table C.9 <lb/>14.3.6. Bidirectional Output for nfs4_mixed_prep <lb/>The nfs4_mixed_prep profile specifies checking bidirectional strings <lb/>as described in stringprep&apos;s Section 6. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 359] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>14.4. UTF-8 Capabilities <lb/>const FSCHARSET_CAP4_CONTAINS_NON_UTF8 = 0x1; <lb/>const FSCHARSET_CAP4_ALLOWS_ONLY_UTF8 <lb/>= 0x2; <lb/>typedef uint32_t <lb/>fs_charset_cap4; <lb/>Because some operating environments and file systems do not enforce <lb/>character set encodings, NFSv4.1 supports the fs_charset_cap <lb/>attribute (Section 5.8.2.11) that indicates to the client a file <lb/>system&apos;s UTF-8 capabilities. The attribute is an integer containing <lb/>a pair of flags. The first flag is FSCHARSET_CAP4_CONTAINS_NON_UTF8, <lb/>which, if set to one, tells the client that the file system contains <lb/>non-UTF-8 characters, and the server will not convert non-UTF <lb/>characters to UTF-8 if the client reads a symlink or directory, <lb/>neither will operations with component names or pathnames in the <lb/>arguments convert the strings to UTF-8. The second flag is <lb/>FSCHARSET_CAP4_ALLOWS_ONLY_UTF8, which, if set to one, indicates that <lb/>the server will accept (and generate) only UTF-8 characters on the <lb/>file system. If FSCHARSET_CAP4_ALLOWS_ONLY_UTF8 is set to one, <lb/>FSCHARSET_CAP4_CONTAINS_NON_UTF8 MUST be set to zero. <lb/>FSCHARSET_CAP4_ALLOWS_ONLY_UTF8 SHOULD always be set to one. <lb/>14.5. UTF-8 Related Errors <lb/>Where the client sends an invalid UTF-8 string, the server should <lb/>return NFS4ERR_INVAL (see Table 5). This includes cases in which <lb/>inappropriate prefixes are detected and where the count includes <lb/>trailing bytes that do not constitute a full UCS character. <lb/>Where the client-supplied string is valid UTF-8 but contains <lb/>characters that are not supported by the server as a value for that <lb/>string (e.g., names containing characters outside of Unicode plane 0 <lb/>on file systems that fail to support such characters despite their <lb/>presence in the Unicode standard), the server should return <lb/>NFS4ERR_BADCHAR. <lb/>Where a UTF-8 string is used as a file name, and the file system <lb/>(while supporting all of the characters within the name) does not <lb/>allow that particular name to be used, the server should return the <lb/>error NFS4ERR_BADNAME (Table 5). This includes situations in which <lb/>the server file system imposes a normalization constraint on name <lb/>strings, but will also include such situations as file system <lb/>prohibitions of &quot;.&quot; and &quot;..&quot; as file names for certain operations, <lb/>and other such constraints. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 360] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>15. Error Values <lb/>NFS error numbers are assigned to failed operations within a Compound <lb/>(COMPOUND or CB_COMPOUND) request. A Compound request contains a <lb/>number of NFS operations that have their results encoded in sequence <lb/>in a Compound reply. The results of successful operations will <lb/>consist of an NFS4_OK status followed by the encoded results of the <lb/>operation. If an NFS operation fails, an error status will be <lb/>entered in the reply and the Compound request will be terminated. <lb/>15.1. Error Definitions <lb/>Protocol Error Definitions <lb/>+-----------------------------------+--------+-------------------+ <lb/>| Error <lb/>| Number | Description <lb/>| <lb/>+-----------------------------------+--------+-------------------+ <lb/>| NFS4_OK <lb/>| 0 <lb/>| Section 15.1.3.1 | <lb/>| NFS4ERR_ACCESS <lb/>| 13 <lb/>| Section 15.1.6.1 | <lb/>| NFS4ERR_ATTRNOTSUPP <lb/>| 10032 | Section 15.1.15.1 | <lb/>| NFS4ERR_ADMIN_REVOKED <lb/>| 10047 | Section 15.1.5.1 | <lb/>| NFS4ERR_BACK_CHAN_BUSY <lb/>| 10057 | Section 15.1.12.1 | <lb/>| NFS4ERR_BADCHAR <lb/>| 10040 | Section 15.1.7.1 | <lb/>| NFS4ERR_BADHANDLE <lb/>| 10001 | Section 15.1.2.1 | <lb/>| NFS4ERR_BADIOMODE <lb/>| 10049 | Section 15.1.10.1 | <lb/>| NFS4ERR_BADLAYOUT <lb/>| 10050 | Section 15.1.10.2 | <lb/>| NFS4ERR_BADNAME <lb/>| 10041 | Section 15.1.7.2 | <lb/>| NFS4ERR_BADOWNER <lb/>| 10039 | Section 15.1.15.2 | <lb/>| NFS4ERR_BADSESSION <lb/>| 10052 | Section 15.1.11.1 | <lb/>| NFS4ERR_BADSLOT <lb/>| 10053 | Section 15.1.11.2 | <lb/>| NFS4ERR_BADTYPE <lb/>| 10007 | Section 15.1.4.1 | <lb/>| NFS4ERR_BADXDR <lb/>| 10036 | Section 15.1.1.1 | <lb/>| NFS4ERR_BAD_COOKIE <lb/>| 10003 | Section 15.1.1.2 | <lb/>| NFS4ERR_BAD_HIGH_SLOT <lb/>| 10077 | Section 15.1.11.3 | <lb/>| NFS4ERR_BAD_RANGE <lb/>| 10042 | Section 15.1.8.1 | <lb/>| NFS4ERR_BAD_SEQID <lb/>| 10026 | Section 15.1.16.1 | <lb/>| NFS4ERR_BAD_SESSION_DIGEST <lb/>| 10051 | Section 15.1.12.2 | <lb/>| NFS4ERR_BAD_STATEID <lb/>| 10025 | Section 15.1.5.2 | <lb/>| NFS4ERR_CB_PATH_DOWN <lb/>| 10048 | Section 15.1.11.4 | <lb/>| NFS4ERR_CLID_INUSE <lb/>| 10017 | Section 15.1.13.2 | <lb/>| NFS4ERR_CLIENTID_BUSY <lb/>| 10074 | Section 15.1.13.1 | <lb/>| NFS4ERR_COMPLETE_ALREADY <lb/>| 10054 | Section 15.1.9.1 | <lb/>| NFS4ERR_CONN_NOT_BOUND_TO_SESSION | 10055 | Section 15.1.11.6 | <lb/>| NFS4ERR_DEADLOCK <lb/>| 10045 | Section 15.1.8.2 | <lb/>| NFS4ERR_DEADSESSION <lb/>| 10078 | Section 15.1.11.5 | <lb/>| NFS4ERR_DELAY <lb/>| 10008 | Section 15.1.1.3 | <lb/>| NFS4ERR_DELEG_ALREADY_WANTED <lb/>| 10056 | Section 15.1.14.1 | <lb/>| NFS4ERR_DELEG_REVOKED <lb/>| 10087 | Section 15.1.5.3 | <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 361] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| NFS4ERR_DENIED <lb/>| 10010 | Section 15.1.8.3 | <lb/>| NFS4ERR_DIRDELEG_UNAVAIL <lb/>| 10084 | Section 15.1.14.2 | <lb/>| NFS4ERR_DQUOT <lb/>| 69 <lb/>| Section 15.1.4.2 | <lb/>| NFS4ERR_ENCR_ALG_UNSUPP <lb/>| 10079 | Section 15.1.13.3 | <lb/>| NFS4ERR_EXIST <lb/>| 17 <lb/>| Section 15.1.4.3 | <lb/>| NFS4ERR_EXPIRED <lb/>| 10011 | Section 15.1.5.4 | <lb/>| NFS4ERR_FBIG <lb/>| 27 <lb/>| Section 15.1.4.4 | <lb/>| NFS4ERR_FHEXPIRED <lb/>| 10014 | Section 15.1.2.2 | <lb/>| NFS4ERR_FILE_OPEN <lb/>| 10046 | Section 15.1.4.5 | <lb/>| NFS4ERR_GRACE <lb/>| 10013 | Section 15.1.9.2 | <lb/>| NFS4ERR_HASH_ALG_UNSUPP <lb/>| 10072 | Section 15.1.13.4 | <lb/>| NFS4ERR_INVAL <lb/>| 22 <lb/>| Section 15.1.1.4 | <lb/>| NFS4ERR_IO <lb/>| 5 <lb/>| Section 15.1.4.6 | <lb/>| NFS4ERR_ISDIR <lb/>| 21 <lb/>| Section 15.1.2.3 | <lb/>| NFS4ERR_LAYOUTTRYLATER <lb/>| 10058 | Section 15.1.10.3 | <lb/>| NFS4ERR_LAYOUTUNAVAILABLE <lb/>| 10059 | Section 15.1.10.4 | <lb/>| NFS4ERR_LEASE_MOVED <lb/>| 10031 | Section 15.1.16.2 | <lb/>| NFS4ERR_LOCKED <lb/>| 10012 | Section 15.1.8.4 | <lb/>| NFS4ERR_LOCKS_HELD <lb/>| 10037 | Section 15.1.8.5 | <lb/>| NFS4ERR_LOCK_NOTSUPP <lb/>| 10043 | Section 15.1.8.6 | <lb/>| NFS4ERR_LOCK_RANGE <lb/>| 10028 | Section 15.1.8.7 | <lb/>| NFS4ERR_MINOR_VERS_MISMATCH <lb/>| 10021 | Section 15.1.3.2 | <lb/>| NFS4ERR_MLINK <lb/>| 31 <lb/>| Section 15.1.4.7 | <lb/>| NFS4ERR_MOVED <lb/>| 10019 | Section 15.1.2.4 | <lb/>| NFS4ERR_NAMETOOLONG <lb/>| 63 <lb/>| Section 15.1.7.3 | <lb/>| NFS4ERR_NOENT <lb/>| 2 <lb/>| Section 15.1.4.8 | <lb/>| NFS4ERR_NOFILEHANDLE <lb/>| 10020 | Section 15.1.2.5 | <lb/>| NFS4ERR_NOMATCHING_LAYOUT <lb/>| 10060 | Section 15.1.10.5 | <lb/>| NFS4ERR_NOSPC <lb/>| 28 <lb/>| Section 15.1.4.9 | <lb/>| NFS4ERR_NOTDIR <lb/>| 20 <lb/>| Section 15.1.2.6 | <lb/>| NFS4ERR_NOTEMPTY <lb/>| 66 <lb/>| Section 15.1.4.10 | <lb/>| NFS4ERR_NOTSUPP <lb/>| 10004 | Section 15.1.1.5 | <lb/>| NFS4ERR_NOT_ONLY_OP <lb/>| 10081 | Section 15.1.3.3 | <lb/>| NFS4ERR_NOT_SAME <lb/>| 10027 | Section 15.1.15.3 | <lb/>| NFS4ERR_NO_GRACE <lb/>| 10033 | Section 15.1.9.3 | <lb/>| NFS4ERR_NXIO <lb/>| 6 <lb/>| Section 15.1.16.3 | <lb/>| NFS4ERR_OLD_STATEID <lb/>| 10024 | Section 15.1.5.5 | <lb/>| NFS4ERR_OPENMODE <lb/>| 10038 | Section 15.1.8.8 | <lb/>| NFS4ERR_OP_ILLEGAL <lb/>| 10044 | Section 15.1.3.4 | <lb/>| NFS4ERR_OP_NOT_IN_SESSION <lb/>| 10071 | Section 15.1.3.5 | <lb/>| NFS4ERR_PERM <lb/>| 1 <lb/>| Section 15.1.6.2 | <lb/>| NFS4ERR_PNFS_IO_HOLE <lb/>| 10075 | Section 15.1.10.6 | <lb/>| NFS4ERR_PNFS_NO_LAYOUT <lb/>| 10080 | Section 15.1.10.7 | <lb/>| NFS4ERR_RECALLCONFLICT <lb/>| 10061 | Section 15.1.14.3 | <lb/>| NFS4ERR_RECLAIM_BAD <lb/>| 10034 | Section 15.1.9.4 | <lb/>| NFS4ERR_RECLAIM_CONFLICT <lb/>| 10035 | Section 15.1.9.5 | <lb/>| NFS4ERR_REJECT_DELEG <lb/>| 10085 | Section 15.1.14.4 | <lb/>| NFS4ERR_REP_TOO_BIG <lb/>| 10066 | Section 15.1.3.6 | <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 362] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| NFS4ERR_REP_TOO_BIG_TO_CACHE <lb/>| 10067 | Section 15.1.3.7 | <lb/>| NFS4ERR_REQ_TOO_BIG <lb/>| 10065 | Section 15.1.3.8 | <lb/>| NFS4ERR_RESTOREFH <lb/>| 10030 | Section 15.1.16.4 | <lb/>| NFS4ERR_RETRY_UNCACHED_REP <lb/>| 10068 | Section 15.1.3.9 | <lb/>| NFS4ERR_RETURNCONFLICT <lb/>| 10086 | Section 15.1.10.8 | <lb/>| NFS4ERR_ROFS <lb/>| 30 <lb/>| Section 15.1.4.11 | <lb/>| NFS4ERR_SAME <lb/>| 10009 | Section 15.1.15.4 | <lb/>| NFS4ERR_SHARE_DENIED <lb/>| 10015 | Section 15.1.8.9 | <lb/>| NFS4ERR_SEQUENCE_POS <lb/>| 10064 | Section 15.1.3.10 | <lb/>| NFS4ERR_SEQ_FALSE_RETRY <lb/>| 10076 | Section 15.1.11.7 | <lb/>| NFS4ERR_SEQ_MISORDERED <lb/>| 10063 | Section 15.1.11.8 | <lb/>| NFS4ERR_SERVERFAULT <lb/>| 10006 | Section 15.1.1.6 | <lb/>| NFS4ERR_STALE <lb/>| 70 <lb/>| Section 15.1.2.7 | <lb/>| NFS4ERR_STALE_CLIENTID <lb/>| 10022 | Section 15.1.13.5 | <lb/>| NFS4ERR_STALE_STATEID <lb/>| 10023 | Section 15.1.16.5 | <lb/>| NFS4ERR_SYMLINK <lb/>| 10029 | Section 15.1.2.8 | <lb/>| NFS4ERR_TOOSMALL <lb/>| 10005 | Section 15.1.1.7 | <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| 10070 | Section 15.1.3.11 | <lb/>| NFS4ERR_UNKNOWN_LAYOUTTYPE <lb/>| 10062 | Section 15.1.10.9 | <lb/>| NFS4ERR_UNSAFE_COMPOUND <lb/>| 10069 | Section 15.1.3.12 | <lb/>| NFS4ERR_WRONGSEC <lb/>| 10016 | Section 15.1.6.3 | <lb/>| NFS4ERR_WRONG_CRED <lb/>| 10082 | Section 15.1.6.4 | <lb/>| NFS4ERR_WRONG_TYPE <lb/>| 10083 | Section 15.1.2.9 | <lb/>| NFS4ERR_XDEV <lb/>| 18 <lb/>| Section 15.1.4.12 | <lb/>+-----------------------------------+--------+-------------------+ <lb/>Table 5 <lb/>15.1.1. General Errors <lb/>This section deals with errors that are applicable to a broad set of <lb/>different purposes. <lb/>15.1.1.1. NFS4ERR_BADXDR (Error Code 10036) <lb/>The arguments for this operation do not match those specified in the <lb/>XDR definition. This includes situations in which the request ends <lb/>before all the arguments have been seen. Note that this error <lb/>applies when fixed enumerations (these include booleans) have a value <lb/>within the input stream that is not valid for the enum. A replier <lb/>may pre-parse all operations for a Compound procedure before doing <lb/>any operation execution and return RPC-level XDR errors in that case. <lb/>15.1.1.2. NFS4ERR_BAD_COOKIE (Error Code 10003) <lb/>Used for operations that provide a set of information indexed by some <lb/>quantity provided by the client or cookie sent by the server for an <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 363] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>earlier invocation. Where the value cannot be used for its intended <lb/>purpose, this error results. <lb/>15.1.1.3. NFS4ERR_DELAY (Error Code 10008) <lb/>For any of a number of reasons, the replier could not process this <lb/>operation in what was deemed a reasonable time. The client should <lb/>wait and then try the request with a new slot and sequence value. <lb/>Some examples of scenarios that might lead to this situation: <lb/>o A server that supports hierarchical storage receives a request to <lb/>process a file that had been migrated. <lb/>o An operation requires a delegation recall to proceed, and waiting <lb/>for this delegation recall makes processing this request in a <lb/>timely fashion impossible. <lb/>In such cases, the error NFS4ERR_DELAY allows these preparatory <lb/>operations to proceed without holding up client resources such as a <lb/>session slot. After delaying for period of time, the client can then <lb/>re-send the operation in question (but not with the same slot ID and <lb/>sequence ID; one or both MUST be different on the re-send). <lb/>Note that without the ability to return NFS4ERR_DELAY and the <lb/>client&apos;s willingness to re-send when receiving it, deadlock might <lb/>result. For example, if a recall is done, and if the delegation <lb/>return or operations preparatory to delegation return are held up by <lb/>other operations that need the delegation to be returned, session <lb/>slots might not be available. The result could be deadlock. <lb/>15.1.1.4. NFS4ERR_INVAL (Error Code 22) <lb/>The arguments for this operation are not valid for some reason, even <lb/>though they do match those specified in the XDR definition for the <lb/>request. <lb/>15.1.1.5. NFS4ERR_NOTSUPP (Error Code 10004) <lb/>Operation not supported, either because the operation is an OPTIONAL <lb/>one and is not supported by this server or because the operation MUST <lb/>NOT be implemented in the current minor version. <lb/>15.1.1.6. NFS4ERR_SERVERFAULT (Error Code 10006) <lb/>An error occurred on the server that does not map to any of the <lb/>specific legal NFSv4.1 protocol error values. The client should <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 364] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>translate this into an appropriate error. UNIX clients may choose to <lb/>translate this to EIO. <lb/>15.1.1.7. NFS4ERR_TOOSMALL (Error Code 10005) <lb/>Used where an operation returns a variable amount of data, with a <lb/>limit specified by the client. Where the data returned cannot be fit <lb/>within the limit specified by the client, this error results. <lb/>15.1.2. Filehandle Errors <lb/>These errors deal with the situation in which the current or saved <lb/>filehandle, or the filehandle passed to PUTFH intended to become the <lb/>current filehandle, is invalid in some way. This includes situations <lb/>in which the filehandle is a valid filehandle in general but is not <lb/>of the appropriate object type for the current operation. <lb/>Where the error description indicates a problem with the current or <lb/>saved filehandle, it is to be understood that filehandles are only <lb/>checked for the condition if they are implicit arguments of the <lb/>operation in question. <lb/>15.1.2.1. NFS4ERR_BADHANDLE (Error Code 10001) <lb/>Illegal NFS filehandle for the current server. The current file <lb/>handle failed internal consistency checks. Once accepted as valid <lb/>(by PUTFH), no subsequent status change can cause the filehandle to <lb/>generate this error. <lb/>15.1.2.2. NFS4ERR_FHEXPIRED (Error Code 10014) <lb/>A current or saved filehandle that is an argument to the current <lb/>operation is volatile and has expired at the server. <lb/>15.1.2.3. NFS4ERR_ISDIR (Error Code 21) <lb/>The current or saved filehandle designates a directory when the <lb/>current operation does not allow a directory to be accepted as the <lb/>target of this operation. <lb/>15.1.2.4. NFS4ERR_MOVED (Error Code 10019) <lb/>The file system that contains the current filehandle object is not <lb/>present at the server. It may have been relocated or migrated to <lb/>another server, or it may have never been present. The client may <lb/>obtain the new file system location by obtaining the &quot;fs_locations&quot; <lb/>or &quot;fs_locations_info&quot; attribute for the current filehandle. For <lb/>further discussion, refer to Section 11.3. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 365] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>15.1.2.5. NFS4ERR_NOFILEHANDLE (Error Code 10020) <lb/>The logical current or saved filehandle value is required by the <lb/>current operation and is not set. This may be a result of a <lb/>malformed COMPOUND operation (i.e., no PUTFH or PUTROOTFH before an <lb/>operation that requires the current filehandle be set). <lb/>15.1.2.6. NFS4ERR_NOTDIR (Error Code 20) <lb/>The current (or saved) filehandle designates an object that is not a <lb/>directory for an operation in which a directory is required. <lb/>15.1.2.7. NFS4ERR_STALE (Error Code 70) <lb/>The current or saved filehandle value designating an argument to the <lb/>current operation is invalid. The file referred to by that <lb/>filehandle no longer exists or access to it has been revoked. <lb/>15.1.2.8. NFS4ERR_SYMLINK (Error Code 10029) <lb/>The current filehandle designates a symbolic link when the current <lb/>operation does not allow a symbolic link as the target. <lb/>15.1.2.9. NFS4ERR_WRONG_TYPE (Error Code 10083) <lb/>The current (or saved) filehandle designates an object that is of an <lb/>invalid type for the current operation, and there is no more specific <lb/>error (such as NFS4ERR_ISDIR or NFS4ERR_SYMLINK) that applies. Note <lb/>that in NFSv4.0, such situations generally resulted in the less-<lb/>specific error NFS4ERR_INVAL. <lb/>15.1.3. Compound Structure Errors <lb/>This section deals with errors that relate to the overall structure <lb/>of a Compound request (by which we mean to include both COMPOUND and <lb/>CB_COMPOUND), rather than to particular operations. <lb/>There are a number of basic constraints on the operations that may <lb/>appear in a Compound request. Sessions add to these basic <lb/>constraints by requiring a Sequence operation (either SEQUENCE or <lb/>CB_SEQUENCE) at the start of the Compound. <lb/>15.1.3.1. NFS_OK (Error code 0) <lb/>Indicates the operation completed successfully, in that all of the <lb/>constituent operations completed without error. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 366] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>15.1.3.2. NFS4ERR_MINOR_VERS_MISMATCH (Error code 10021) <lb/>The minor version specified is not one that the current listener <lb/>supports. This value is returned in the overall status for the <lb/>Compound but is not associated with a specific operation since the <lb/>results will specify a result count of zero. <lb/>15.1.3.3. NFS4ERR_NOT_ONLY_OP (Error Code 10081) <lb/>Certain operations, which are allowed to be executed outside of a <lb/>session, MUST be the only operation within a Compound whenever the <lb/>Compound does not start with a Sequence operation. This error <lb/>results when that constraint is not met. <lb/>15.1.3.4. NFS4ERR_OP_ILLEGAL (Error Code 10044) <lb/>The operation code is not a valid one for the current Compound <lb/>procedure. The opcode in the result stream matched with this error <lb/>is the ILLEGAL value, although the value that appears in the request <lb/>stream may be different. Where an illegal value appears and the <lb/>replier pre-parses all operations for a Compound procedure before <lb/>doing any operation execution, an RPC-level XDR error may be <lb/>returned. <lb/>15.1.3.5. NFS4ERR_OP_NOT_IN_SESSION (Error Code 10071) <lb/>Most forward operations and all callback operations are only valid <lb/>within the context of a session, so that the Compound request in <lb/>question MUST begin with a Sequence operation. If an attempt is made <lb/>to execute these operations outside the context of session, this <lb/>error results. <lb/>15.1.3.6. NFS4ERR_REP_TOO_BIG (Error Code 10066) <lb/>The reply to a Compound would exceed the channel&apos;s negotiated maximum <lb/>response size. <lb/>15.1.3.7. NFS4ERR_REP_TOO_BIG_TO_CACHE (Error Code 10067) <lb/>The reply to a Compound would exceed the channel&apos;s negotiated maximum <lb/>size for replies cached in the reply cache when the Sequence for the <lb/>current request specifies that this request is to be cached. <lb/>15.1.3.8. NFS4ERR_REQ_TOO_BIG (Error Code 10065) <lb/>The Compound request exceeds the channel&apos;s negotiated maximum size <lb/>for requests. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 367] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>15.1.3.9. NFS4ERR_RETRY_UNCACHED_REP (Error Code 10068) <lb/>The requester has attempted a retry of a Compound that it previously <lb/>requested not be placed in the reply cache. <lb/>15.1.3.10. NFS4ERR_SEQUENCE_POS (Error Code 10064) <lb/>A Sequence operation appeared in a position other than the first <lb/>operation of a Compound request. <lb/>15.1.3.11. NFS4ERR_TOO_MANY_OPS (Error Code 10070) <lb/>The Compound request has too many operations, exceeding the count <lb/>negotiated when the session was created. <lb/>15.1.3.12. NFS4ERR_UNSAFE_COMPOUND (Error Code 10068) <lb/>The client has sent a COMPOUND request with an unsafe mix of <lb/>operations --specifically, with a non-idempotent operation that <lb/>changes the current filehandle and that is not followed by a GETFH. <lb/>15.1.4. File System Errors <lb/>These errors describe situations that occurred in the underlying file <lb/>system implementation rather than in the protocol or any NFSv4.x <lb/>feature. <lb/>15.1.4.1. NFS4ERR_BADTYPE (Error Code 10007) <lb/>An attempt was made to create an object with an inappropriate type <lb/>specified to CREATE. This may be because the type is undefined, <lb/>because the type is not supported by the server, or because the type <lb/>is not intended to be created by CREATE (such as a regular file or <lb/>named attribute, for which OPEN is used to do the file creation). <lb/>15.1.4.2. NFS4ERR_DQUOT (Error Code 19) <lb/>Resource (quota) hard limit exceeded. The user&apos;s resource limit on <lb/>the server has been exceeded. <lb/>15.1.4.3. NFS4ERR_EXIST (Error Code 17) <lb/>A file of the specified target name (when creating, renaming, or <lb/>linking) already exists. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 368] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>15.1.4.4. NFS4ERR_FBIG (Error Code 27) <lb/>The file is too large. The operation would have caused the file to <lb/>grow beyond the server&apos;s limit. <lb/>15.1.4.5. NFS4ERR_FILE_OPEN (Error Code 10046) <lb/>The operation is not allowed because a file involved in the operation <lb/>is currently open. Servers may, but are not required to, disallow <lb/>linking-to, removing, or renaming open files. <lb/>15.1.4.6. NFS4ERR_IO (Error Code 5) <lb/>Indicates that an I/O error occurred for which the file system was <lb/>unable to provide recovery. <lb/>15.1.4.7. NFS4ERR_MLINK (Error Code 31) <lb/>The request would have caused the server&apos;s limit for the number of <lb/>hard links a file may have to be exceeded. <lb/>15.1.4.8. NFS4ERR_NOENT (Error Code 2) <lb/>Indicates no such file or directory. The file or directory name <lb/>specified does not exist. <lb/>15.1.4.9. NFS4ERR_NOSPC (Error Code 28) <lb/>Indicates there is no space left on the device. The operation would <lb/>have caused the server&apos;s file system to exceed its limit. <lb/>15.1.4.10. NFS4ERR_NOTEMPTY (Error Code 66) <lb/>An attempt was made to remove a directory that was not empty. <lb/>15.1.4.11. NFS4ERR_ROFS (Error Code 30) <lb/>Indicates a read-only file system. A modifying operation was <lb/>attempted on a read-only file system. <lb/>15.1.4.12. NFS4ERR_XDEV (Error Code 18) <lb/>Indicates an attempt to do an operation, such as linking, that <lb/>inappropriately crosses a boundary. This may be due to such <lb/>boundaries as: <lb/>o that between file systems (where the fsids are different). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 369] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o that between different named attribute directories or between a <lb/>named attribute directory and an ordinary directory. <lb/>o that between byte-ranges of a file system that the file system <lb/>implementation treats as separate (for example, for space <lb/>accounting purposes), and where cross-connection between the byte-<lb/>ranges are not allowed. <lb/>15.1.5. State Management Errors <lb/>These errors indicate problems with the stateid (or one of the <lb/>stateids) passed to a given operation. This includes situations in <lb/>which the stateid is invalid as well as situations in which the <lb/>stateid is valid but designates locking state that has been revoked. <lb/>Depending on the operation, the stateid when valid may designate <lb/>opens, byte-range locks, file or directory delegations, layouts, or <lb/>device maps. <lb/>15.1.5.1. NFS4ERR_ADMIN_REVOKED (Error Code 10047) <lb/>A stateid designates locking state of any type that has been revoked <lb/>due to administrative interaction, possibly while the lease is valid. <lb/>15.1.5.2. NFS4ERR_BAD_STATEID (Error Code 10026) <lb/>A stateid does not properly designate any valid state. See Sections <lb/>8.2.4 and 8.2.3 for a discussion of how stateids are validated. <lb/>15.1.5.3. NFS4ERR_DELEG_REVOKED (Error Code 10087) <lb/>A stateid designates recallable locking state of any type (delegation <lb/>or layout) that has been revoked due to the failure of the client to <lb/>return the lock when it was recalled. <lb/>15.1.5.4. NFS4ERR_EXPIRED (Error Code 10011) <lb/>A stateid designates locking state of any type that has been revoked <lb/>due to expiration of the client&apos;s lease, either immediately upon <lb/>lease expiration, or following a later request for a conflicting <lb/>lock. <lb/>15.1.5.5. NFS4ERR_OLD_STATEID (Error Code 10024) <lb/>A stateid with a non-zero seqid value does match the current seqid <lb/>for the state designated by the user. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 370] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>15.1.6. Security Errors <lb/>These are the various permission-related errors in NFSv4.1. <lb/>15.1.6.1. NFS4ERR_ACCESS (Error Code 13) <lb/>Indicates permission denied. The caller does not have the correct <lb/>permission to perform the requested operation. Contrast this with <lb/>NFS4ERR_PERM (Section 15.1.6.2), which restricts itself to owner or <lb/>privileged-user permission failures, and NFS4ERR_WRONG_CRED <lb/>(Section 15.1.6.4), which deals with appropriate permission to delete <lb/>or modify transient objects based on the credentials of the user that <lb/>created them. <lb/>15.1.6.2. NFS4ERR_PERM (Error Code 1) <lb/>Indicates requester is not the owner. The operation was not allowed <lb/>because the caller is neither a privileged user (root) nor the owner <lb/>of the target of the operation. <lb/>15.1.6.3. NFS4ERR_WRONGSEC (Error Code 10016) <lb/>Indicates that the security mechanism being used by the client for <lb/>the operation does not match the server&apos;s security policy. The <lb/>client should change the security mechanism being used and re-send <lb/>the operation (but not with the same slot ID and sequence ID; one or <lb/>both MUST be different on the re-send). SECINFO and SECINFO_NO_NAME <lb/>can be used to determine the appropriate mechanism. <lb/>15.1.6.4. NFS4ERR_WRONG_CRED (Error Code 10082) <lb/>An operation that manipulates state was attempted by a principal that <lb/>was not allowed to modify that piece of state. <lb/>15.1.7. Name Errors <lb/>Names in NFSv4 are UTF-8 strings. When the strings are not valid <lb/>UTF-8 or are of length zero, the error NFS4ERR_INVAL results. <lb/>Besides this, there are a number of other errors to indicate specific <lb/>problems with names. <lb/>15.1.7.1. NFS4ERR_BADCHAR (Error Code 10040) <lb/>A UTF-8 string contains a character that is not supported by the <lb/>server in the context in which it being used. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 371] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>15.1.7.2. NFS4ERR_BADNAME (Error Code 10041) <lb/>A name string in a request consisted of valid UTF-8 characters <lb/>supported by the server, but the name is not supported by the server <lb/>as a valid name for the current operation. An example might be <lb/>creating a file or directory named &quot;..&quot; on a server whose file system <lb/>uses that name for links to parent directories. <lb/>15.1.7.3. NFS4ERR_NAMETOOLONG (Error Code 63) <lb/>Returned when the filename in an operation exceeds the server&apos;s <lb/>implementation limit. <lb/>15.1.8. Locking Errors <lb/>This section deals with errors related to locking, both as to share <lb/>reservations and byte-range locking. It does not deal with errors <lb/>specific to the process of reclaiming locks. Those are dealt with in <lb/>Section 15.1.9. <lb/>15.1.8.1. NFS4ERR_BAD_RANGE (Error Code 10042) <lb/>The byte-range of a LOCK, LOCKT, or LOCKU operation is not allowed by <lb/>the server. For example, this error results when a server that only <lb/>supports 32-bit ranges receives a range that cannot be handled by <lb/>that server. (See Section 18.10.3.) <lb/>15.1.8.2. NFS4ERR_DEADLOCK (Error Code 10045) <lb/>The server has been able to determine a byte-range locking deadlock <lb/>condition for a READW_LT or WRITEW_LT LOCK operation. <lb/>15.1.8.3. NFS4ERR_DENIED (Error Code 10010) <lb/>An attempt to lock a file is denied. Since this may be a temporary <lb/>condition, the client is encouraged to re-send the lock request (but <lb/>not with the same slot ID and sequence ID; one or both MUST be <lb/>different on the re-send) until the lock is accepted. See <lb/>Section 9.6 for a discussion of the re-send. <lb/>15.1.8.4. NFS4ERR_LOCKED (Error Code 10012) <lb/>A READ or WRITE operation was attempted on a file where there was a <lb/>conflict between the I/O and an existing lock: <lb/>o There is a share reservation inconsistent with the I/O being done. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 372] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o The range to be read or written intersects an existing mandatory <lb/>byte-range lock. <lb/>15.1.8.5. NFS4ERR_LOCKS_HELD (Error Code 10037) <lb/>An operation was prevented by the unexpected presence of locks. <lb/>15.1.8.6. NFS4ERR_LOCK_NOTSUPP (Error Code 10043) <lb/>A LOCK operation was attempted that would require the upgrade or <lb/>downgrade of a byte-range lock range already held by the owner, and <lb/>the server does not support atomic upgrade or downgrade of locks. <lb/>15.1.8.7. NFS4ERR_LOCK_RANGE (Error Code 10028) <lb/>A LOCK operation is operating on a range that overlaps in part a <lb/>currently held byte-range lock for the current lock-owner and does <lb/>not precisely match a single such byte-range lock where the server <lb/>does not support this type of request, and thus does not implement <lb/>POSIX locking semantics [21]. See Sections 18.10.4, 18.11.4, and <lb/>18.12.4 for a discussion of how this applies to LOCK, LOCKT, and <lb/>LOCKU respectively. <lb/>15.1.8.8. NFS4ERR_OPENMODE (Error Code 10038) <lb/>The client attempted a READ, WRITE, LOCK, or other operation not <lb/>sanctioned by the stateid passed (e.g., writing to a file opened for <lb/>read-only access). <lb/>15.1.8.9. NFS4ERR_SHARE_DENIED (Error Code 10015) <lb/>An attempt to OPEN a file with a share reservation has failed because <lb/>of a share conflict. <lb/>15.1.9. Reclaim Errors <lb/>These errors relate to the process of reclaiming locks after a server <lb/>restart. <lb/>15.1.9.1. NFS4ERR_COMPLETE_ALREADY (Error Code 10054) <lb/>The client previously sent a successful RECLAIM_COMPLETE operation. <lb/>An additional RECLAIM_COMPLETE operation is not necessary and results <lb/>in this error. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 373] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>15.1.9.2. NFS4ERR_GRACE (Error Code 10013) <lb/>The server was in its recovery or grace period. The locking request <lb/>was not a reclaim request and so could not be granted during that <lb/>period. <lb/>15.1.9.3. NFS4ERR_NO_GRACE (Error Code 10033) <lb/>A reclaim of client state was attempted in circumstances in which the <lb/>server cannot guarantee that conflicting state has not been provided <lb/>to another client. This can occur because the reclaim has been done <lb/>outside of the grace period of the server, after the client has done <lb/>a RECLAIM_COMPLETE operation, or because previous operations have <lb/>created a situation in which the server is not able to determine that <lb/>a reclaim-interfering edge condition does not exist. <lb/>15.1.9.4. NFS4ERR_RECLAIM_BAD (Error Code 10034) <lb/>The server has determined that a reclaim attempted by the client is <lb/>not valid, i.e. the lock specified as being reclaimed could not <lb/>possibly have existed before the server restart. A server is not <lb/>obliged to make this determination and will typically rely on the <lb/>client to only reclaim locks that the client was granted prior to <lb/>restart. However, when a server does have reliable information to <lb/>enable it make this determination, this error indicates that the <lb/>reclaim has been rejected as invalid. This is as opposed to the <lb/>error NFS4ERR_RECLAIM_CONFLICT (see Section 15.1.9.5) where the <lb/>server can only determine that there has been an invalid reclaim, but <lb/>cannot determine which request is invalid. <lb/>15.1.9.5. NFS4ERR_RECLAIM_CONFLICT (Error Code 10035) <lb/>The reclaim attempted by the client has encountered a conflict and <lb/>cannot be satisfied. Potentially indicates a misbehaving client, <lb/>although not necessarily the one receiving the error. The <lb/>misbehavior might be on the part of the client that established the <lb/>lock with which this client conflicted. See also Section 15.1.9.4 <lb/>for the related error, NFS4ERR_RECLAIM_BAD. <lb/>15.1.10. pNFS Errors <lb/>This section deals with pNFS-related errors including those that are <lb/>associated with using NFSv4.1 to communicate with a data server. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 374] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>15.1.10.1. NFS4ERR_BADIOMODE (Error Code 10049) <lb/>An invalid or inappropriate layout iomode was specified. For example <lb/>an inappropriate layout iomode, suppose a client&apos;s LAYOUTGET <lb/>operation specified an iomode of LAYOUTIOMODE4_RW, and the server is <lb/>neither able nor willing to let the client send write requests to <lb/>data servers; the server can reply with NFS4ERR_BADIOMODE. The <lb/>client would then send another LAYOUTGET with an iomode of <lb/>LAYOUTIOMODE4_READ. <lb/>15.1.10.2. NFS4ERR_BADLAYOUT (Error Code 10050) <lb/>The layout specified is invalid in some way. For LAYOUTCOMMIT, this <lb/>indicates that the specified layout is not held by the client or is <lb/>not of mode LAYOUTIOMODE4_RW. For LAYOUTGET, it indicates that a <lb/>layout matching the client&apos;s specification as to minimum length <lb/>cannot be granted. <lb/>15.1.10.3. NFS4ERR_LAYOUTTRYLATER (Error Code 10058) <lb/>Layouts are temporarily unavailable for the file. The client should <lb/>re-send later (but not with the same slot ID and sequence ID; one or <lb/>both MUST be different on the re-send). <lb/>15.1.10.4. NFS4ERR_LAYOUTUNAVAILABLE (Error Code 10059) <lb/>Returned when layouts are not available for the current file system <lb/>or the particular specified file. <lb/>15.1.10.5. NFS4ERR_NOMATCHING_LAYOUT (Error Code 10060) <lb/>Returned when layouts are recalled and the client has no layouts <lb/>matching the specification of the layouts being recalled. <lb/>15.1.10.6. NFS4ERR_PNFS_IO_HOLE (Error Code 10075) <lb/>The pNFS client has attempted to read from or write to an illegal <lb/>hole of a file of a data server that is using sparse packing. See <lb/>Section 13.4.4. <lb/>15.1.10.7. NFS4ERR_PNFS_NO_LAYOUT (Error Code 10080) <lb/>The pNFS client has attempted to read from or write to a file (using <lb/>a request to a data server) without holding a valid layout. This <lb/>includes the case where the client had a layout, but the iomode does <lb/>not allow a WRITE. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 375] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>15.1.10.8. NFS4ERR_RETURNCONFLICT (Error Code 10086) <lb/>A layout is unavailable due to an attempt to perform the LAYOUTGET <lb/>before a pending LAYOUTRETURN on the file has been received. See <lb/>Section 12.5.5.2.1.3. <lb/>15.1.10.9. NFS4ERR_UNKNOWN_LAYOUTTYPE (Error Code 10062) <lb/>The client has specified a layout type that is not supported by the <lb/>server. <lb/>15.1.11. Session Use Errors <lb/>This section deals with errors encountered when using sessions, that <lb/>is, errors encountered when a request uses a Sequence (i.e., either <lb/>SEQUENCE or CB_SEQUENCE) operation. <lb/>15.1.11.1. NFS4ERR_BADSESSION (Error Code 10052) <lb/>The specified session ID is unknown to the server to which the <lb/>operation is addressed. <lb/>15.1.11.2. NFS4ERR_BADSLOT (Error Code 10053) <lb/>The requester sent a Sequence operation that attempted to use a slot <lb/>the replier does not have in its slot table. It is possible the slot <lb/>may have been retired. <lb/>15.1.11.3. NFS4ERR_BAD_HIGH_SLOT (Error Code 10077) <lb/>The highest_slot argument in a Sequence operation exceeds the <lb/>replier&apos;s enforced highest_slotid. <lb/>15.1.11.4. NFS4ERR_CB_PATH_DOWN (Error Code 10048) <lb/>There is a problem contacting the client via the callback path. The <lb/>function of this error has been mostly superseded by the use of <lb/>status flags in the reply to the SEQUENCE operation (see <lb/>Section 18.46). <lb/>15.1.11.5. NFS4ERR_DEADSESSION (Error Code 10078) <lb/>The specified session is a persistent session that is dead and does <lb/>not accept new requests or perform new operations on existing <lb/>requests (in the case in which a request was partially executed <lb/>before server restart). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 376] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>15.1.11.6. NFS4ERR_CONN_NOT_BOUND_TO_SESSION (Error Code 10055) <lb/>A Sequence operation was sent on a connection that has not been <lb/>associated with the specified session, where the client specified <lb/>that connection association was to be enforced with SP4_MACH_CRED or <lb/>SP4_SSV state protection. <lb/>15.1.11.7. NFS4ERR_SEQ_FALSE_RETRY (Error Code 10076) <lb/>The requester sent a Sequence operation with a slot ID and sequence <lb/>ID that are in the reply cache, but the replier has detected that the <lb/>retried request is not the same as the original request. See <lb/>Section 2.10.6.1.3.1. <lb/>15.1.11.8. NFS4ERR_SEQ_MISORDERED (Error Code 10063) <lb/>The requester sent a Sequence operation with an invalid sequence ID. <lb/>15.1.12. Session Management Errors <lb/>This section deals with errors associated with requests used in <lb/>session management. <lb/>15.1.12.1. NFS4ERR_BACK_CHAN_BUSY (Error Code 10057) <lb/>An attempt was made to destroy a session when the session cannot be <lb/>destroyed because the server has callback requests outstanding. <lb/>15.1.12.2. NFS4ERR_BAD_SESSION_DIGEST (Error Code 10051) <lb/>The digest used in a SET_SSV request is not valid. <lb/>15.1.13. Client Management Errors <lb/>This section deals with errors associated with requests used to <lb/>create and manage client IDs. <lb/>15.1.13.1. NFS4ERR_CLIENTID_BUSY (Error Code 10074) <lb/>The DESTROY_CLIENTID operation has found there are sessions and/or <lb/>unexpired state associated with the client ID to be destroyed. <lb/>15.1.13.2. NFS4ERR_CLID_INUSE (Error Code 10017) <lb/>While processing an EXCHANGE_ID operation, the server was presented <lb/>with a co_ownerid field that matches an existing client with valid <lb/>leased state, but the principal sending the EXCHANGE_ID operation <lb/>differs from the principal that established the existing client. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 377] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>This indicates a collision (most likely due to chance) between <lb/>clients. The client should recover by changing the co_ownerid and <lb/>re-sending EXCHANGE_ID (but not with the same slot ID and sequence <lb/>ID; one or both MUST be different on the re-send). <lb/>15.1.13.3. NFS4ERR_ENCR_ALG_UNSUPP (Error Code 10079) <lb/>An EXCHANGE_ID was sent that specified state protection via SSV, and <lb/>where the set of encryption algorithms presented by the client did <lb/>not include any supported by the server. <lb/>15.1.13.4. NFS4ERR_HASH_ALG_UNSUPP (Error Code 10072) <lb/>An EXCHANGE_ID was sent that specified state protection via SSV, and <lb/>where the set of hashing algorithms presented by the client did not <lb/>include any supported by the server. <lb/>15.1.13.5. NFS4ERR_STALE_CLIENTID (Error Code 10022) <lb/>A client ID not recognized by the server was passed to an operation. <lb/>Note that unlike the case of NFSv4.0, client IDs are not passed <lb/>explicitly to the server in ordinary locking operations and cannot <lb/>result in this error. Instead, when there is a server restart, it is <lb/>first manifested through an error on the associated session, and the <lb/>staleness of the client ID is detected when trying to associate a <lb/>client ID with a new session. <lb/>15.1.14. Delegation Errors <lb/>This section deals with errors associated with requesting and <lb/>returning delegations. <lb/>15.1.14.1. NFS4ERR_DELEG_ALREADY_WANTED (Error Code 10056) <lb/>The client has requested a delegation when it had already registered <lb/>that it wants that same delegation. <lb/>15.1.14.2. NFS4ERR_DIRDELEG_UNAVAIL (Error Code 10084) <lb/>This error is returned when the server is unable or unwilling to <lb/>provide a requested directory delegation. <lb/>15.1.14.3. NFS4ERR_RECALLCONFLICT (Error Code 10061) <lb/>A recallable object (i.e., a layout or delegation) is unavailable due <lb/>to a conflicting recall operation that is currently in progress for <lb/>that object. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 378] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>15.1.14.4. NFS4ERR_REJECT_DELEG (Error Code 10085) <lb/>The callback operation invoked to deal with a new delegation has <lb/>rejected it. <lb/>15.1.15. Attribute Handling Errors <lb/>This section deals with errors specific to attribute handling within <lb/>NFSv4. <lb/>15.1.15.1. NFS4ERR_ATTRNOTSUPP (Error Code 10032) <lb/>An attribute specified is not supported by the server. This error <lb/>MUST NOT be returned by the GETATTR operation. <lb/>15.1.15.2. NFS4ERR_BADOWNER (Error Code 10039) <lb/>This error is returned when an owner or owner_group attribute value <lb/>or the who field of an ACE within an ACL attribute value cannot be <lb/>translated to a local representation. <lb/>15.1.15.3. NFS4ERR_NOT_SAME (Error Code 10027) <lb/>This error is returned by the VERIFY operation to signify that the <lb/>attributes compared were not the same as those provided in the <lb/>client&apos;s request. <lb/>15.1.15.4. NFS4ERR_SAME (Error Code 10009) <lb/>This error is returned by the NVERIFY operation to signify that the <lb/>attributes compared were the same as those provided in the client&apos;s <lb/>request. <lb/>15.1.16. Obsoleted Errors <lb/>These errors MUST NOT be generated by any NFSv4.1 operation. This <lb/>can be for a number of reasons. <lb/>o The function provided by the error has been superseded by one of <lb/>the status bits returned by the SEQUENCE operation. <lb/>o The new session structure and associated change in locking have <lb/>made the error unnecessary. <lb/>o There has been a restructuring of some errors for NFSv4.1 that <lb/>resulted in the elimination of certain errors. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 379] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>15.1.16.1. NFS4ERR_BAD_SEQID (Error Code 10026) <lb/>The sequence number (seqid) in a locking request is neither the next <lb/>expected number or the last number processed. These seqids are <lb/>ignored in NFSv4.1. <lb/>15.1.16.2. NFS4ERR_LEASE_MOVED (Error Code 10031) <lb/>A lease being renewed is associated with a file system that has been <lb/>migrated to a new server. The error has been superseded by the <lb/>SEQ4_STATUS_LEASE_MOVED status bit (see Section 18.46). <lb/>15.1.16.3. NFS4ERR_NXIO (Error Code 5) <lb/>I/O error. No such device or address. This error is for errors <lb/>involving block and character device access, but because NFSv4.1 is <lb/>not a device-access protocol, this error is not applicable. <lb/>15.1.16.4. NFS4ERR_RESTOREFH (Error Code 10030) <lb/>The RESTOREFH operation does not have a saved filehandle (identified <lb/>by SAVEFH) to operate upon. In NFSv4.1, this error has been <lb/>superseded by NFS4ERR_NOFILEHANDLE. <lb/>15.1.16.5. NFS4ERR_STALE_STATEID (Error Code 10023) <lb/>A stateid generated by an earlier server instance was used. This <lb/>error is moot in NFSv4.1 because all operations that take a stateid <lb/>MUST be preceded by the SEQUENCE operation, and the earlier server <lb/>instance is detected by the session infrastructure that supports <lb/>SEQUENCE. <lb/>15.2. Operations and Their Valid Errors <lb/>This section contains a table that gives the valid error returns for <lb/>each protocol operation. The error code NFS4_OK (indicating no <lb/>error) is not listed but should be understood to be returnable by all <lb/>operations with two important exceptions: <lb/>o The operations that MUST NOT be implemented: OPEN_CONFIRM, <lb/>RELEASE_LOCKOWNER, RENEW, SETCLIENTID, and SETCLIENTID_CONFIRM. <lb/>o The invalid operation: ILLEGAL. <lb/>Valid Error Returns for Each Protocol Operation <lb/>+----------------------+--------------------------------------------+ <lb/>| Operation <lb/>| Errors <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 380] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>+----------------------+--------------------------------------------+ <lb/>| ACCESS <lb/>| NFS4ERR_ACCESS, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_IO, NFS4ERR_MOVED, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| BACKCHANNEL_CTL <lb/>| NFS4ERR_BADXDR, NFS4ERR_DEADSESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_NOENT, NFS4ERR_OP_NOT_IN_SESSION, | <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| BIND_CONN_TO_SESSION | NFS4ERR_BADSESSION, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_SESSION_DIGEST, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_NOT_ONLY_OP, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_TOO_MANY_OPS | <lb/>| <lb/>| <lb/>| <lb/>| CLOSE <lb/>| NFS4ERR_ADMIN_REVOKED, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_STATEID, NFS4ERR_DEADSESSION, | <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_EXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_LOCKS_HELD, <lb/>| <lb/>| <lb/>| NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_OLD_STATEID, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONG_CRED <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| COMMIT <lb/>| NFS4ERR_ACCESS, NFS4ERR_BADXDR, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 381] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_IO, <lb/>| <lb/>| <lb/>| NFS4ERR_ISDIR, NFS4ERR_MOVED, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CREATE <lb/>| NFS4ERR_ACCESS, NFS4ERR_ATTRNOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_BADCHAR, NFS4ERR_BADNAME, <lb/>| <lb/>| <lb/>| NFS4ERR_BADOWNER, NFS4ERR_BADTYPE, <lb/>| <lb/>| <lb/>| NFS4ERR_BADXDR, NFS4ERR_DEADSESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_DQUOT, <lb/>| <lb/>| <lb/>| NFS4ERR_EXIST, NFS4ERR_FHEXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_IO, NFS4ERR_MLINK, | <lb/>| <lb/>| NFS4ERR_MOVED, NFS4ERR_NAMETOOLONG, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOSPC, <lb/>| <lb/>| <lb/>| NFS4ERR_NOTDIR, NFS4ERR_OP_NOT_IN_SESSION, | <lb/>| <lb/>| NFS4ERR_PERM, NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, NFS4ERR_ROFS, | <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_UNSAFE_COMPOUND <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CREATE_SESSION <lb/>| NFS4ERR_BADXDR, NFS4ERR_CLID_INUSE, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_NOENT, <lb/>| <lb/>| <lb/>| NFS4ERR_NOT_ONLY_OP, NFS4ERR_NOSPC, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SEQ_MISORDERED, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, <lb/>| <lb/>| <lb/>| NFS4ERR_STALE_CLIENTID, NFS4ERR_TOOSMALL, | <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONG_CRED <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| DELEGPURGE <lb/>| NFS4ERR_BADXDR, NFS4ERR_DEADSESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 382] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_TOO_MANY_OPS, | <lb/>| <lb/>| NFS4ERR_WRONG_CRED <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| DELEGRETURN <lb/>| NFS4ERR_ADMIN_REVOKED, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_STATEID, NFS4ERR_DEADSESSION, | <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_DELEG_REVOKED, <lb/>| <lb/>| <lb/>| NFS4ERR_EXPIRED, NFS4ERR_FHEXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_MOVED, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OLD_STATEID, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONG_CRED <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID <lb/>| NFS4ERR_BADXDR, NFS4ERR_CLIENTID_BUSY, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_NOT_ONLY_OP, NFS4ERR_REP_TOO_BIG, | <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, <lb/>| <lb/>| <lb/>| NFS4ERR_STALE_CLIENTID, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONG_CRED <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| DESTROY_SESSION <lb/>| NFS4ERR_BACK_CHAN_BUSY, <lb/>| <lb/>| <lb/>| NFS4ERR_BADSESSION, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_CB_PATH_DOWN, <lb/>| <lb/>| <lb/>| NFS4ERR_CONN_NOT_BOUND_TO_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_NOT_ONLY_OP, NFS4ERR_REP_TOO_BIG, | <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, <lb/>| <lb/>| <lb/>| NFS4ERR_STALE_CLIENTID, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONG_CRED <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| EXCHANGE_ID <lb/>| NFS4ERR_BADCHAR, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_CLID_INUSE, NFS4ERR_DEADSESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_ENCR_ALG_UNSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_HASH_ALG_UNSUPP, NFS4ERR_INVAL, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 383] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_NOENT, NFS4ERR_NOT_ONLY_OP, <lb/>| <lb/>| <lb/>| NFS4ERR_NOT_SAME, NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_TOO_MANY_OPS | <lb/>| <lb/>| <lb/>| <lb/>| FREE_STATEID <lb/>| NFS4ERR_BADXDR, NFS4ERR_BAD_STATEID, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_LOCKS_HELD, NFS4ERR_OLD_STATEID, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_TOO_MANY_OPS, | <lb/>| <lb/>| NFS4ERR_WRONG_CRED <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| GET_DIR_DELEGATION <lb/>| NFS4ERR_ACCESS, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_DIRDELEG_UNAVAIL, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_GRACE, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_IO, NFS4ERR_MOVED, | <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTDIR, <lb/>| <lb/>| <lb/>| NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| GETATTR <lb/>| NFS4ERR_ACCESS, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_GRACE, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_IO, NFS4ERR_MOVED, | <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| GETDEVICEINFO <lb/>| NFS4ERR_BADXDR, NFS4ERR_DEADSESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_INVAL, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 384] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_NOENT, NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_TOOSMALL, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_UNKNOWN_LAYOUTTYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| GETDEVICELIST <lb/>| NFS4ERR_BADXDR, NFS4ERR_BAD_COOKIE, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_IO, NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_NOTSUPP, NFS4ERR_NOT_SAME, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_TOO_MANY_OPS, | <lb/>| <lb/>| NFS4ERR_UNKNOWN_LAYOUTTYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| GETFH <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_MOVED, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, NFS4ERR_STALE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| ILLEGAL <lb/>| NFS4ERR_BADXDR, NFS4ERR_OP_ILLEGAL <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT <lb/>| NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED, <lb/>| <lb/>| <lb/>| NFS4ERR_ATTRNOTSUPP, NFS4ERR_BADIOMODE, <lb/>| <lb/>| <lb/>| NFS4ERR_BADLAYOUT, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_DELEG_REVOKED, NFS4ERR_EXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_FBIG, NFS4ERR_FHEXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_GRACE, NFS4ERR_INVAL, NFS4ERR_IO, | <lb/>| <lb/>| NFS4ERR_ISDIR NFS4ERR_MOVED, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_NO_GRACE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_RECLAIM_BAD, <lb/>| <lb/>| <lb/>| NFS4ERR_RECLAIM_CONFLICT, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 385] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_UNKNOWN_LAYOUTTYPE, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_CRED <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| LAYOUTGET <lb/>| NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED, <lb/>| <lb/>| <lb/>| NFS4ERR_BADIOMODE, NFS4ERR_BADLAYOUT, <lb/>| <lb/>| <lb/>| NFS4ERR_BADXDR, NFS4ERR_BAD_STATEID, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_DELEG_REVOKED, NFS4ERR_DQUOT, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_GRACE, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_IO, <lb/>| <lb/>| <lb/>| NFS4ERR_LAYOUTTRYLATER, <lb/>| <lb/>| <lb/>| NFS4ERR_LAYOUTUNAVAILABLE, NFS4ERR_LOCKED, | <lb/>| <lb/>| NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_NOSPC, NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OLD_STATEID, NFS4ERR_OPENMODE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_RECALLCONFLICT, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOOSMALL, NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_UNKNOWN_LAYOUTTYPE, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| LAYOUTRETURN <lb/>| NFS4ERR_ADMIN_REVOKED, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_STATEID, NFS4ERR_DEADSESSION, | <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_DELEG_REVOKED, <lb/>| <lb/>| <lb/>| NFS4ERR_EXPIRED, NFS4ERR_FHEXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_GRACE, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_ISDIR, NFS4ERR_MOVED, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_NO_GRACE, NFS4ERR_OLD_STATEID, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_UNKNOWN_LAYOUTTYPE, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_CRED, NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| LINK <lb/>| NFS4ERR_ACCESS, NFS4ERR_BADCHAR, <lb/>| <lb/>| <lb/>| NFS4ERR_BADNAME, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_DQUOT, NFS4ERR_EXIST, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 386] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_FILE_OPEN, <lb/>| <lb/>| <lb/>| NFS4ERR_GRACE, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_ISDIR, NFS4ERR_IO, NFS4ERR_MLINK, | <lb/>| <lb/>| NFS4ERR_MOVED, NFS4ERR_NAMETOOLONG, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOSPC, <lb/>| <lb/>| <lb/>| NFS4ERR_NOTDIR, NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, NFS4ERR_ROFS, | <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONGSEC, NFS4ERR_WRONG_TYPE, <lb/>| <lb/>| <lb/>| NFS4ERR_XDEV <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| LOCK <lb/>| NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED, <lb/>| <lb/>| <lb/>| NFS4ERR_BADXDR, NFS4ERR_BAD_RANGE, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_STATEID, NFS4ERR_DEADLOCK, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_DENIED, NFS4ERR_EXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_GRACE, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_ISDIR, <lb/>| <lb/>| <lb/>| NFS4ERR_LOCK_NOTSUPP, NFS4ERR_LOCK_RANGE, | <lb/>| <lb/>| NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_NO_GRACE, NFS4ERR_OLD_STATEID, <lb/>| <lb/>| <lb/>| NFS4ERR_OPENMODE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_RECLAIM_BAD, <lb/>| <lb/>| <lb/>| NFS4ERR_RECLAIM_CONFLICT, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, NFS4ERR_ROFS, | <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_CRED, NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| LOCKT <lb/>| NFS4ERR_ACCESS, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_RANGE, NFS4ERR_DEADSESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_DENIED, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_GRACE, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_ISDIR, <lb/>| <lb/>| <lb/>| NFS4ERR_LOCK_RANGE, NFS4ERR_MOVED, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 387] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, NFS4ERR_ROFS, | <lb/>| <lb/>| NFS4ERR_STALE, NFS4ERR_SYMLINK, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONG_CRED, | <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| LOCKU <lb/>| NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED, <lb/>| <lb/>| <lb/>| NFS4ERR_BADXDR, NFS4ERR_BAD_RANGE, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_STATEID, NFS4ERR_DEADSESSION, | <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_EXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_LOCK_RANGE, NFS4ERR_MOVED, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_OLD_STATEID, | <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONG_CRED <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| LOOKUP <lb/>| NFS4ERR_ACCESS, NFS4ERR_BADCHAR, <lb/>| <lb/>| <lb/>| NFS4ERR_BADNAME, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_IO, NFS4ERR_MOVED, <lb/>| <lb/>| <lb/>| NFS4ERR_NAMETOOLONG, NFS4ERR_NOENT, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTDIR, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONGSEC <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| LOOKUPP <lb/>| NFS4ERR_ACCESS, NFS4ERR_DEADSESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_FHEXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_IO, NFS4ERR_MOVED, NFS4ERR_NOENT, | <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTDIR, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 388] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_WRONGSEC <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NVERIFY <lb/>| NFS4ERR_ACCESS, NFS4ERR_ATTRNOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_BADCHAR, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_GRACE, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_IO, NFS4ERR_MOVED, | <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, NFS4ERR_SAME, | <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_UNKNOWN_LAYOUTTYPE, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| OPEN <lb/>| NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED, <lb/>| <lb/>| <lb/>| NFS4ERR_ATTRNOTSUPP, NFS4ERR_BADCHAR, <lb/>| <lb/>| <lb/>| NFS4ERR_BADNAME, NFS4ERR_BADOWNER, <lb/>| <lb/>| <lb/>| NFS4ERR_BADXDR, NFS4ERR_BAD_STATEID, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_DELEG_ALREADY_WANTED, <lb/>| <lb/>| <lb/>| NFS4ERR_DELEG_REVOKED, NFS4ERR_DQUOT, <lb/>| <lb/>| <lb/>| NFS4ERR_EXIST, NFS4ERR_EXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_FBIG, NFS4ERR_FHEXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_GRACE, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_ISDIR, NFS4ERR_IO, NFS4ERR_MOVED, | <lb/>| <lb/>| NFS4ERR_NAMETOOLONG, NFS4ERR_NOENT, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOSPC, <lb/>| <lb/>| <lb/>| NFS4ERR_NOTDIR, NFS4ERR_NO_GRACE, <lb/>| <lb/>| <lb/>| NFS4ERR_OLD_STATEID, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, NFS4ERR_PERM, <lb/>| <lb/>| <lb/>| NFS4ERR_RECLAIM_BAD, <lb/>| <lb/>| <lb/>| NFS4ERR_RECLAIM_CONFLICT, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, NFS4ERR_ROFS, | <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_SHARE_DENIED, | <lb/>| <lb/>| NFS4ERR_STALE, NFS4ERR_SYMLINK, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_UNSAFE_COMPOUND, NFS4ERR_WRONGSEC, | <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| OPEN_CONFIRM <lb/>| NFS4ERR_NOTSUPP <lb/>| <lb/>| <lb/>| <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 389] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| OPEN_DOWNGRADE <lb/>| NFS4ERR_ADMIN_REVOKED, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_STATEID, NFS4ERR_DEADSESSION, | <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_EXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_OLD_STATEID, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, NFS4ERR_ROFS, | <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONG_CRED <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| OPENATTR <lb/>| NFS4ERR_ACCESS, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_DQUOT, NFS4ERR_FHEXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_IO, NFS4ERR_MOVED, NFS4ERR_NOENT, | <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOSPC, <lb/>| <lb/>| <lb/>| NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, NFS4ERR_ROFS, | <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_UNSAFE_COMPOUND, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| PUTFH <lb/>| NFS4ERR_BADHANDLE, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_MOVED, NFS4ERR_OP_NOT_IN_SESSION, | <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONGSEC <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| PUTPUBFH <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_TOO_MANY_OPS, | <lb/>| <lb/>| NFS4ERR_WRONGSEC <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 390] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| <lb/>| <lb/>| PUTROOTFH <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_TOO_MANY_OPS, | <lb/>| <lb/>| NFS4ERR_WRONGSEC <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| READ <lb/>| NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED, <lb/>| <lb/>| <lb/>| NFS4ERR_BADXDR, NFS4ERR_BAD_STATEID, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_DELEG_REVOKED, NFS4ERR_EXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_GRACE, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_ISDIR, NFS4ERR_IO, | <lb/>| <lb/>| NFS4ERR_LOCKED, NFS4ERR_MOVED, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_OLD_STATEID, | <lb/>| <lb/>| NFS4ERR_OPENMODE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_PNFS_IO_HOLE, <lb/>| <lb/>| <lb/>| NFS4ERR_PNFS_NO_LAYOUT, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| READDIR <lb/>| NFS4ERR_ACCESS, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_COOKIE, NFS4ERR_DEADSESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_FHEXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_IO, NFS4ERR_MOVED, | <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTDIR, <lb/>| <lb/>| <lb/>| NFS4ERR_NOT_SAME, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOOSMALL, NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| READLINK <lb/>| NFS4ERR_ACCESS, NFS4ERR_DEADSESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_FHEXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_IO, NFS4ERR_MOVED, | <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 391] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE <lb/>| NFS4ERR_BADXDR, NFS4ERR_COMPLETE_ALREADY, | <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONG_CRED, | <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| RELEASE_LOCKOWNER <lb/>| NFS4ERR_NOTSUPP <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| REMOVE <lb/>| NFS4ERR_ACCESS, NFS4ERR_BADCHAR, <lb/>| <lb/>| <lb/>| NFS4ERR_BADNAME, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_FILE_OPEN, <lb/>| <lb/>| <lb/>| NFS4ERR_GRACE, NFS4ERR_INVAL, NFS4ERR_IO, | <lb/>| <lb/>| NFS4ERR_MOVED, NFS4ERR_NAMETOOLONG, <lb/>| <lb/>| <lb/>| NFS4ERR_NOENT, NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_NOTDIR, NFS4ERR_NOTEMPTY, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, NFS4ERR_ROFS, | <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| RENAME <lb/>| NFS4ERR_ACCESS, NFS4ERR_BADCHAR, <lb/>| <lb/>| <lb/>| NFS4ERR_BADNAME, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_DQUOT, NFS4ERR_EXIST, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_FILE_OPEN, <lb/>| <lb/>| <lb/>| NFS4ERR_GRACE, NFS4ERR_INVAL, NFS4ERR_IO, | <lb/>| <lb/>| NFS4ERR_MLINK, NFS4ERR_MOVED, <lb/>| <lb/>| <lb/>| NFS4ERR_NAMETOOLONG, NFS4ERR_NOENT, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOSPC, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 392] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_NOTDIR, NFS4ERR_NOTEMPTY, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, NFS4ERR_ROFS, | <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONGSEC, <lb/>| <lb/>| <lb/>| NFS4ERR_XDEV <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| RENEW <lb/>| NFS4ERR_NOTSUPP <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| RESTOREFH <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_FHEXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONGSEC <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| SAVEFH <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_FHEXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| SECINFO <lb/>| NFS4ERR_ACCESS, NFS4ERR_BADCHAR, <lb/>| <lb/>| <lb/>| NFS4ERR_BADNAME, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_MOVED, NFS4ERR_NAMETOOLONG, <lb/>| <lb/>| <lb/>| NFS4ERR_NOENT, NFS4ERR_NOFILEHANDLE, <lb/>| <lb/>| <lb/>| NFS4ERR_NOTDIR, NFS4ERR_OP_NOT_IN_SESSION, | <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| SECINFO_NO_NAME <lb/>| NFS4ERR_ACCESS, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 393] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_MOVED, NFS4ERR_NOENT, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTDIR, <lb/>| <lb/>| <lb/>| NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| SEQUENCE <lb/>| NFS4ERR_BADSESSION, NFS4ERR_BADSLOT, <lb/>| <lb/>| <lb/>| NFS4ERR_BADXDR, NFS4ERR_BAD_HIGH_SLOT, <lb/>| <lb/>| <lb/>| NFS4ERR_CONN_NOT_BOUND_TO_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SEQUENCE_POS, <lb/>| <lb/>| <lb/>| NFS4ERR_SEQ_FALSE_RETRY, <lb/>| <lb/>| <lb/>| NFS4ERR_SEQ_MISORDERED, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| SET_SSV <lb/>| NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_SESSION_DIGEST, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_OP_NOT_IN_SESSION, | <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| SETATTR <lb/>| NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED, <lb/>| <lb/>| <lb/>| NFS4ERR_ATTRNOTSUPP, NFS4ERR_BADCHAR, <lb/>| <lb/>| <lb/>| NFS4ERR_BADOWNER, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_STATEID, NFS4ERR_DEADSESSION, | <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_DELEG_REVOKED, <lb/>| <lb/>| <lb/>| NFS4ERR_DQUOT, NFS4ERR_EXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_FBIG, NFS4ERR_FHEXPIRED, <lb/>| <lb/>| <lb/>| NFS4ERR_GRACE, NFS4ERR_INVAL, NFS4ERR_IO, | <lb/>| <lb/>| NFS4ERR_LOCKED, NFS4ERR_MOVED, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOSPC, <lb/>| <lb/>| <lb/>| NFS4ERR_OLD_STATEID, NFS4ERR_OPENMODE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, NFS4ERR_PERM, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 394] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, NFS4ERR_ROFS, | <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_UNKNOWN_LAYOUTTYPE, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| SETCLIENTID <lb/>| NFS4ERR_NOTSUPP <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| SETCLIENTID_CONFIRM | NFS4ERR_NOTSUPP <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| TEST_STATEID <lb/>| NFS4ERR_BADXDR, NFS4ERR_DEADSESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_OP_NOT_IN_SESSION, | <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_TOO_MANY_OPS | <lb/>| <lb/>| <lb/>| <lb/>| VERIFY <lb/>| NFS4ERR_ACCESS, NFS4ERR_ATTRNOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_BADCHAR, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_GRACE, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_IO, NFS4ERR_MOVED, | <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOT_SAME, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_UNKNOWN_LAYOUTTYPE, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| WANT_DELEGATION <lb/>| NFS4ERR_BADXDR, NFS4ERR_DEADSESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_DELEG_ALREADY_WANTED, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_GRACE, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_IO, NFS4ERR_MOVED, | <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_NO_GRACE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_RECALLCONFLICT, <lb/>| <lb/>| <lb/>| NFS4ERR_RECLAIM_BAD, <lb/>| <lb/>| <lb/>| NFS4ERR_RECLAIM_CONFLICT, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 395] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| WRITE <lb/>| NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED, <lb/>| <lb/>| <lb/>| NFS4ERR_BADXDR, NFS4ERR_BAD_STATEID, <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_DELEG_REVOKED, NFS4ERR_DQUOT, <lb/>| <lb/>| <lb/>| NFS4ERR_EXPIRED, NFS4ERR_FBIG, <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED, NFS4ERR_GRACE, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_IO, NFS4ERR_ISDIR, | <lb/>| <lb/>| NFS4ERR_LOCKED, NFS4ERR_MOVED, <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE, NFS4ERR_NOSPC, <lb/>| <lb/>| <lb/>| NFS4ERR_OLD_STATEID, NFS4ERR_OPENMODE, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_PNFS_IO_HOLE, <lb/>| <lb/>| <lb/>| NFS4ERR_PNFS_NO_LAYOUT, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, NFS4ERR_ROFS, | <lb/>| <lb/>| NFS4ERR_SERVERFAULT, NFS4ERR_STALE, <lb/>| <lb/>| <lb/>| NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>+----------------------+--------------------------------------------+ <lb/>Table 6 <lb/>15.3. Callback Operations and Their Valid Errors <lb/>This section contains a table that gives the valid error returns for <lb/>each callback operation. The error code NFS4_OK (indicating no <lb/>error) is not listed but should be understood to be returnable by all <lb/>callback operations with the exception of CB_ILLEGAL. <lb/>Valid Error Returns for Each Protocol Callback Operation <lb/>+-------------------------+-----------------------------------------+ <lb/>| Callback Operation <lb/>| Errors <lb/>| <lb/>+-------------------------+-----------------------------------------+ <lb/>| CB_GETATTR <lb/>| NFS4ERR_BADHANDLE, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 396] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CB_ILLEGAL <lb/>| NFS4ERR_BADXDR, NFS4ERR_OP_ILLEGAL <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CB_LAYOUTRECALL <lb/>| NFS4ERR_BADHANDLE, NFS4ERR_BADIOMODE, <lb/>| <lb/>| <lb/>| NFS4ERR_BADXDR, NFS4ERR_BAD_STATEID, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_NOMATCHING_LAYOUT, <lb/>| <lb/>| <lb/>| NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_UNKNOWN_LAYOUTTYPE, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CB_NOTIFY <lb/>| NFS4ERR_BADHANDLE, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_STATEID, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CB_NOTIFY_DEVICEID <lb/>| NFS4ERR_BADXDR, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CB_NOTIFY_LOCK <lb/>| NFS4ERR_BADHANDLE, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_STATEID, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 397] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CB_PUSH_DELEG <lb/>| NFS4ERR_BADHANDLE, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REJECT_DELEG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS, <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CB_RECALL <lb/>| NFS4ERR_BADHANDLE, NFS4ERR_BADXDR, <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_STATEID, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CB_RECALL_ANY <lb/>| NFS4ERR_BADXDR, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CB_RECALLABLE_OBJ_AVAIL | NFS4ERR_BADXDR, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL, NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CB_RECALL_SLOT <lb/>| NFS4ERR_BADXDR, NFS4ERR_BAD_HIGH_SLOT, | <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 398] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CB_SEQUENCE <lb/>| NFS4ERR_BADSESSION, NFS4ERR_BADSLOT, <lb/>| <lb/>| <lb/>| NFS4ERR_BADXDR, NFS4ERR_BAD_HIGH_SLOT, | <lb/>| <lb/>| NFS4ERR_CONN_NOT_BOUND_TO_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY, NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SEQUENCE_POS, <lb/>| <lb/>| <lb/>| NFS4ERR_SEQ_FALSE_RETRY, <lb/>| <lb/>| <lb/>| NFS4ERR_SEQ_MISORDERED, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| CB_WANTS_CANCELLED <lb/>| NFS4ERR_BADXDR, NFS4ERR_DELAY, <lb/>| <lb/>| <lb/>| NFS4ERR_NOTSUPP, <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE, <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG, <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP, <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT, <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| <lb/>| <lb/>+-------------------------+-----------------------------------------+ <lb/>Table 7 <lb/>15.4. Errors and the Operations That Use Them <lb/>+-----------------------------------+-------------------------------+ <lb/>| Error <lb/>| Operations <lb/>| <lb/>+-----------------------------------+-------------------------------+ <lb/>| NFS4ERR_ACCESS <lb/>| ACCESS, COMMIT, CREATE, <lb/>| <lb/>| <lb/>| GETATTR, GET_DIR_DELEGATION, | <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LINK, LOCK, LOCKT, LOCKU, <lb/>| <lb/>| <lb/>| LOOKUP, LOOKUPP, NVERIFY, <lb/>| <lb/>| <lb/>| OPEN, OPENATTR, READ, <lb/>| <lb/>| <lb/>| READDIR, READLINK, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, SECINFO, <lb/>| <lb/>| <lb/>| SECINFO_NO_NAME, SETATTR, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 399] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| VERIFY, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_ADMIN_REVOKED <lb/>| CLOSE, DELEGRETURN, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LOCK, LOCKU, <lb/>| <lb/>| <lb/>| OPEN, OPEN_DOWNGRADE, READ, <lb/>| <lb/>| <lb/>| SETATTR, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_ATTRNOTSUPP <lb/>| CREATE, LAYOUTCOMMIT, <lb/>| <lb/>| <lb/>| NVERIFY, OPEN, SETATTR, <lb/>| <lb/>| <lb/>| VERIFY <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BACK_CHAN_BUSY <lb/>| DESTROY_SESSION <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BADCHAR <lb/>| CREATE, EXCHANGE_ID, LINK, <lb/>| <lb/>| <lb/>| LOOKUP, NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| REMOVE, RENAME, SECINFO, <lb/>| <lb/>| <lb/>| SETATTR, VERIFY <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BADHANDLE <lb/>| CB_GETATTR, CB_LAYOUTRECALL, | <lb/>| <lb/>| CB_NOTIFY, CB_NOTIFY_LOCK, <lb/>| <lb/>| <lb/>| CB_PUSH_DELEG, CB_RECALL, <lb/>| <lb/>| <lb/>| PUTFH <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BADIOMODE <lb/>| CB_LAYOUTRECALL, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BADLAYOUT <lb/>| LAYOUTCOMMIT, LAYOUTGET <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BADNAME <lb/>| CREATE, LINK, LOOKUP, OPEN, <lb/>| <lb/>| <lb/>| REMOVE, RENAME, SECINFO <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BADOWNER <lb/>| CREATE, OPEN, SETATTR <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BADSESSION <lb/>| BIND_CONN_TO_SESSION, <lb/>| <lb/>| <lb/>| CB_SEQUENCE, DESTROY_SESSION, | <lb/>| <lb/>| SEQUENCE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BADSLOT <lb/>| CB_SEQUENCE, SEQUENCE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BADTYPE <lb/>| CREATE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BADXDR <lb/>| ACCESS, BACKCHANNEL_CTL, <lb/>| <lb/>| <lb/>| BIND_CONN_TO_SESSION, <lb/>| <lb/>| <lb/>| CB_GETATTR, CB_ILLEGAL, <lb/>| <lb/>| <lb/>| CB_LAYOUTRECALL, CB_NOTIFY, <lb/>| <lb/>| <lb/>| CB_NOTIFY_DEVICEID, <lb/>| <lb/>| <lb/>| CB_NOTIFY_LOCK, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 400] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| CB_PUSH_DELEG, CB_RECALL, <lb/>| <lb/>| <lb/>| CB_RECALLABLE_OBJ_AVAIL, <lb/>| <lb/>| <lb/>| CB_RECALL_ANY, <lb/>| <lb/>| <lb/>| CB_RECALL_SLOT, CB_SEQUENCE, | <lb/>| <lb/>| CB_WANTS_CANCELLED, CLOSE, <lb/>| <lb/>| <lb/>| COMMIT, CREATE, <lb/>| <lb/>| <lb/>| CREATE_SESSION, DELEGPURGE, <lb/>| <lb/>| <lb/>| DELEGRETURN, <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID, <lb/>| <lb/>| <lb/>| DESTROY_SESSION, EXCHANGE_ID, | <lb/>| <lb/>| FREE_STATEID, GETATTR, <lb/>| <lb/>| <lb/>| GETDEVICEINFO, GETDEVICELIST, | <lb/>| <lb/>| GET_DIR_DELEGATION, ILLEGAL, | <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| NVERIFY, OPEN, OPENATTR, <lb/>| <lb/>| <lb/>| OPEN_DOWNGRADE, PUTFH, READ, | <lb/>| <lb/>| READDIR, RECLAIM_COMPLETE, <lb/>| <lb/>| <lb/>| REMOVE, RENAME, SECINFO, <lb/>| <lb/>| <lb/>| SECINFO_NO_NAME, SEQUENCE, <lb/>| <lb/>| <lb/>| SETATTR, SET_SSV, <lb/>| <lb/>| <lb/>| TEST_STATEID, VERIFY, <lb/>| <lb/>| <lb/>| WANT_DELEGATION, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_COOKIE <lb/>| GETDEVICELIST, READDIR <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_HIGH_SLOT <lb/>| CB_RECALL_SLOT, CB_SEQUENCE, | <lb/>| <lb/>| SEQUENCE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_RANGE <lb/>| LOCK, LOCKT, LOCKU <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_SESSION_DIGEST <lb/>| BIND_CONN_TO_SESSION, SET_SSV | <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_BAD_STATEID <lb/>| CB_LAYOUTRECALL, CB_NOTIFY, <lb/>| <lb/>| <lb/>| CB_NOTIFY_LOCK, CB_RECALL, <lb/>| <lb/>| <lb/>| CLOSE, DELEGRETURN, <lb/>| <lb/>| <lb/>| FREE_STATEID, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LOCK, LOCKU, <lb/>| <lb/>| <lb/>| OPEN, OPEN_DOWNGRADE, READ, <lb/>| <lb/>| <lb/>| SETATTR, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_CB_PATH_DOWN <lb/>| DESTROY_SESSION <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_CLID_INUSE <lb/>| CREATE_SESSION, EXCHANGE_ID <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_CLIENTID_BUSY <lb/>| DESTROY_CLIENTID <lb/>| <lb/>| <lb/>| <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 401] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| NFS4ERR_COMPLETE_ALREADY <lb/>| RECLAIM_COMPLETE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_CONN_NOT_BOUND_TO_SESSION | CB_SEQUENCE, DESTROY_SESSION, | <lb/>| <lb/>| SEQUENCE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_DEADLOCK <lb/>| LOCK <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_DEADSESSION <lb/>| ACCESS, BACKCHANNEL_CTL, <lb/>| <lb/>| <lb/>| BIND_CONN_TO_SESSION, CLOSE, | <lb/>| <lb/>| COMMIT, CREATE, <lb/>| <lb/>| <lb/>| CREATE_SESSION, DELEGPURGE, <lb/>| <lb/>| <lb/>| DELEGRETURN, <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID, <lb/>| <lb/>| <lb/>| DESTROY_SESSION, EXCHANGE_ID, | <lb/>| <lb/>| FREE_STATEID, GETATTR, <lb/>| <lb/>| <lb/>| GETDEVICEINFO, GETDEVICELIST, | <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| LOOKUPP, NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| OPENATTR, OPEN_DOWNGRADE, <lb/>| <lb/>| <lb/>| PUTFH, PUTPUBFH, PUTROOTFH, <lb/>| <lb/>| <lb/>| READ, READDIR, READLINK, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, RESTOREFH, SAVEFH, <lb/>| <lb/>| <lb/>| SECINFO, SECINFO_NO_NAME, <lb/>| <lb/>| <lb/>| SEQUENCE, SETATTR, SET_SSV, <lb/>| <lb/>| <lb/>| TEST_STATEID, VERIFY, <lb/>| <lb/>| <lb/>| WANT_DELEGATION, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY <lb/>| ACCESS, BACKCHANNEL_CTL, <lb/>| <lb/>| <lb/>| BIND_CONN_TO_SESSION, <lb/>| <lb/>| <lb/>| CB_GETATTR, CB_LAYOUTRECALL, | <lb/>| <lb/>| CB_NOTIFY, <lb/>| <lb/>| <lb/>| CB_NOTIFY_DEVICEID, <lb/>| <lb/>| <lb/>| CB_NOTIFY_LOCK, <lb/>| <lb/>| <lb/>| CB_PUSH_DELEG, CB_RECALL, <lb/>| <lb/>| <lb/>| CB_RECALLABLE_OBJ_AVAIL, <lb/>| <lb/>| <lb/>| CB_RECALL_ANY, <lb/>| <lb/>| <lb/>| CB_RECALL_SLOT, CB_SEQUENCE, | <lb/>| <lb/>| CB_WANTS_CANCELLED, CLOSE, <lb/>| <lb/>| <lb/>| COMMIT, CREATE, <lb/>| <lb/>| <lb/>| CREATE_SESSION, DELEGPURGE, <lb/>| <lb/>| <lb/>| DELEGRETURN, <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID, <lb/>| <lb/>| <lb/>| DESTROY_SESSION, EXCHANGE_ID, | <lb/>| <lb/>| FREE_STATEID, GETATTR, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 402] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| GETDEVICEINFO, GETDEVICELIST, | <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| LOOKUPP, NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| OPENATTR, OPEN_DOWNGRADE, <lb/>| <lb/>| <lb/>| PUTFH, PUTPUBFH, PUTROOTFH, <lb/>| <lb/>| <lb/>| READ, READDIR, READLINK, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, SECINFO, <lb/>| <lb/>| <lb/>| SECINFO_NO_NAME, SEQUENCE, <lb/>| <lb/>| <lb/>| SETATTR, SET_SSV, <lb/>| <lb/>| <lb/>| TEST_STATEID, VERIFY, <lb/>| <lb/>| <lb/>| WANT_DELEGATION, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_DELEG_ALREADY_WANTED <lb/>| OPEN, WANT_DELEGATION <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_DELEG_REVOKED <lb/>| DELEGRETURN, LAYOUTCOMMIT, <lb/>| <lb/>| <lb/>| LAYOUTGET, LAYOUTRETURN, <lb/>| <lb/>| <lb/>| OPEN, READ, SETATTR, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_DENIED <lb/>| LOCK, LOCKT <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_DIRDELEG_UNAVAIL <lb/>| GET_DIR_DELEGATION <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_DQUOT <lb/>| CREATE, LAYOUTGET, LINK, <lb/>| <lb/>| <lb/>| OPEN, OPENATTR, RENAME, <lb/>| <lb/>| <lb/>| SETATTR, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_ENCR_ALG_UNSUPP <lb/>| EXCHANGE_ID <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_EXIST <lb/>| CREATE, LINK, OPEN, RENAME <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_EXPIRED <lb/>| CLOSE, DELEGRETURN, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTRETURN, <lb/>| <lb/>| <lb/>| LOCK, LOCKU, OPEN, <lb/>| <lb/>| <lb/>| OPEN_DOWNGRADE, READ, <lb/>| <lb/>| <lb/>| SETATTR, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_FBIG <lb/>| LAYOUTCOMMIT, OPEN, SETATTR, | <lb/>| <lb/>| WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_FHEXPIRED <lb/>| ACCESS, CLOSE, COMMIT, <lb/>| <lb/>| <lb/>| CREATE, DELEGRETURN, GETATTR, | <lb/>| <lb/>| GETDEVICELIST, GETFH, <lb/>| <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 403] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| LOOKUPP, NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| OPENATTR, OPEN_DOWNGRADE, <lb/>| <lb/>| <lb/>| READ, READDIR, READLINK, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, RESTOREFH, SAVEFH, <lb/>| <lb/>| <lb/>| SECINFO, SECINFO_NO_NAME, <lb/>| <lb/>| <lb/>| SETATTR, VERIFY, <lb/>| <lb/>| <lb/>| WANT_DELEGATION, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_FILE_OPEN <lb/>| LINK, REMOVE, RENAME <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_GRACE <lb/>| GETATTR, GET_DIR_DELEGATION, | <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, NVERIFY, OPEN, READ, <lb/>| <lb/>| <lb/>| REMOVE, RENAME, SETATTR, <lb/>| <lb/>| <lb/>| VERIFY, WANT_DELEGATION, <lb/>| <lb/>| <lb/>| WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_HASH_ALG_UNSUPP <lb/>| EXCHANGE_ID <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL <lb/>| ACCESS, BACKCHANNEL_CTL, <lb/>| <lb/>| <lb/>| BIND_CONN_TO_SESSION, <lb/>| <lb/>| <lb/>| CB_GETATTR, CB_LAYOUTRECALL, | <lb/>| <lb/>| CB_NOTIFY, <lb/>| <lb/>| <lb/>| CB_NOTIFY_DEVICEID, <lb/>| <lb/>| <lb/>| CB_PUSH_DELEG, <lb/>| <lb/>| <lb/>| CB_RECALLABLE_OBJ_AVAIL, <lb/>| <lb/>| <lb/>| CB_RECALL_ANY, CREATE, <lb/>| <lb/>| <lb/>| CREATE_SESSION, DELEGRETURN, | <lb/>| <lb/>| EXCHANGE_ID, GETATTR, <lb/>| <lb/>| <lb/>| GETDEVICEINFO, GETDEVICELIST, | <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| OPEN_DOWNGRADE, READ, <lb/>| <lb/>| <lb/>| READDIR, READLINK, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, SECINFO, <lb/>| <lb/>| <lb/>| SECINFO_NO_NAME, SETATTR, <lb/>| <lb/>| <lb/>| SET_SSV, VERIFY, <lb/>| <lb/>| <lb/>| WANT_DELEGATION, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_IO <lb/>| ACCESS, COMMIT, CREATE, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 404] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| GETATTR, GETDEVICELIST, <lb/>| <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LINK, LOOKUP, LOOKUPP, <lb/>| <lb/>| <lb/>| NVERIFY, OPEN, OPENATTR, <lb/>| <lb/>| <lb/>| READ, READDIR, READLINK, <lb/>| <lb/>| <lb/>| REMOVE, RENAME, SETATTR, <lb/>| <lb/>| <lb/>| VERIFY, WANT_DELEGATION, <lb/>| <lb/>| <lb/>| WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_ISDIR <lb/>| COMMIT, LAYOUTCOMMIT, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, OPEN, READ, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_LAYOUTTRYLATER <lb/>| LAYOUTGET <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_LAYOUTUNAVAILABLE <lb/>| LAYOUTGET <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_LOCKED <lb/>| LAYOUTGET, READ, SETATTR, <lb/>| <lb/>| <lb/>| WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_LOCKS_HELD <lb/>| CLOSE, FREE_STATEID <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_LOCK_NOTSUPP <lb/>| LOCK <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_LOCK_RANGE <lb/>| LOCK, LOCKT, LOCKU <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_MLINK <lb/>| CREATE, LINK, RENAME <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_MOVED <lb/>| ACCESS, CLOSE, COMMIT, <lb/>| <lb/>| <lb/>| CREATE, DELEGRETURN, GETATTR, | <lb/>| <lb/>| GETFH, GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| LOOKUPP, NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| OPENATTR, OPEN_DOWNGRADE, <lb/>| <lb/>| <lb/>| PUTFH, READ, READDIR, <lb/>| <lb/>| <lb/>| READLINK, RECLAIM_COMPLETE, <lb/>| <lb/>| <lb/>| REMOVE, RENAME, RESTOREFH, <lb/>| <lb/>| <lb/>| SAVEFH, SECINFO, <lb/>| <lb/>| <lb/>| SECINFO_NO_NAME, SETATTR, <lb/>| <lb/>| <lb/>| VERIFY, WANT_DELEGATION, <lb/>| <lb/>| <lb/>| WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_NAMETOOLONG <lb/>| CREATE, LINK, LOOKUP, OPEN, <lb/>| <lb/>| <lb/>| REMOVE, RENAME, SECINFO <lb/>| <lb/>| <lb/>| <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 405] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| NFS4ERR_NOENT <lb/>| BACKCHANNEL_CTL, <lb/>| <lb/>| <lb/>| CREATE_SESSION, EXCHANGE_ID, | <lb/>| <lb/>| GETDEVICEINFO, LOOKUP, <lb/>| <lb/>| <lb/>| LOOKUPP, OPEN, OPENATTR, <lb/>| <lb/>| <lb/>| REMOVE, RENAME, SECINFO, <lb/>| <lb/>| <lb/>| SECINFO_NO_NAME <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_NOFILEHANDLE <lb/>| ACCESS, CLOSE, COMMIT, <lb/>| <lb/>| <lb/>| CREATE, DELEGRETURN, GETATTR, | <lb/>| <lb/>| GETDEVICELIST, GETFH, <lb/>| <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| LOOKUPP, NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| OPENATTR, OPEN_DOWNGRADE, <lb/>| <lb/>| <lb/>| READ, READDIR, READLINK, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, RESTOREFH, SAVEFH, <lb/>| <lb/>| <lb/>| SECINFO, SECINFO_NO_NAME, <lb/>| <lb/>| <lb/>| SETATTR, VERIFY, <lb/>| <lb/>| <lb/>| WANT_DELEGATION, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_NOMATCHING_LAYOUT <lb/>| CB_LAYOUTRECALL <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_NOSPC <lb/>| CREATE, CREATE_SESSION, <lb/>| <lb/>| <lb/>| LAYOUTGET, LINK, OPEN, <lb/>| <lb/>| <lb/>| OPENATTR, RENAME, SETATTR, <lb/>| <lb/>| <lb/>| WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_NOTDIR <lb/>| CREATE, GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LINK, LOOKUP, LOOKUPP, OPEN, | <lb/>| <lb/>| READDIR, REMOVE, RENAME, <lb/>| <lb/>| <lb/>| SECINFO, SECINFO_NO_NAME <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_NOTEMPTY <lb/>| REMOVE, RENAME <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_NOTSUPP <lb/>| CB_LAYOUTRECALL, CB_NOTIFY, <lb/>| <lb/>| <lb/>| CB_NOTIFY_DEVICEID, <lb/>| <lb/>| <lb/>| CB_NOTIFY_LOCK, <lb/>| <lb/>| <lb/>| CB_PUSH_DELEG, <lb/>| <lb/>| <lb/>| CB_RECALLABLE_OBJ_AVAIL, <lb/>| <lb/>| <lb/>| CB_WANTS_CANCELLED, <lb/>| <lb/>| <lb/>| DELEGPURGE, DELEGRETURN, <lb/>| <lb/>| <lb/>| GETDEVICEINFO, GETDEVICELIST, | <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, OPENATTR, | <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 406] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| OPEN_CONFIRM, <lb/>| <lb/>| <lb/>| RELEASE_LOCKOWNER, RENEW, <lb/>| <lb/>| <lb/>| SECINFO_NO_NAME, SETCLIENTID, | <lb/>| <lb/>| SETCLIENTID_CONFIRM, <lb/>| <lb/>| <lb/>| WANT_DELEGATION <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_NOT_ONLY_OP <lb/>| BIND_CONN_TO_SESSION, <lb/>| <lb/>| <lb/>| CREATE_SESSION, <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID, <lb/>| <lb/>| <lb/>| DESTROY_SESSION, EXCHANGE_ID | <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_NOT_SAME <lb/>| EXCHANGE_ID, GETDEVICELIST, <lb/>| <lb/>| <lb/>| READDIR, VERIFY <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_NO_GRACE <lb/>| LAYOUTCOMMIT, LAYOUTRETURN, <lb/>| <lb/>| <lb/>| LOCK, OPEN, WANT_DELEGATION <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_OLD_STATEID <lb/>| CLOSE, DELEGRETURN, <lb/>| <lb/>| <lb/>| FREE_STATEID, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LOCK, LOCKU, <lb/>| <lb/>| <lb/>| OPEN, OPEN_DOWNGRADE, READ, <lb/>| <lb/>| <lb/>| SETATTR, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_OPENMODE <lb/>| LAYOUTGET, LOCK, READ, <lb/>| <lb/>| <lb/>| SETATTR, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_OP_ILLEGAL <lb/>| CB_ILLEGAL, ILLEGAL <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_OP_NOT_IN_SESSION <lb/>| ACCESS, BACKCHANNEL_CTL, <lb/>| <lb/>| <lb/>| CB_GETATTR, CB_LAYOUTRECALL, | <lb/>| <lb/>| CB_NOTIFY, <lb/>| <lb/>| <lb/>| CB_NOTIFY_DEVICEID, <lb/>| <lb/>| <lb/>| CB_NOTIFY_LOCK, <lb/>| <lb/>| <lb/>| CB_PUSH_DELEG, CB_RECALL, <lb/>| <lb/>| <lb/>| CB_RECALLABLE_OBJ_AVAIL, <lb/>| <lb/>| <lb/>| CB_RECALL_ANY, <lb/>| <lb/>| <lb/>| CB_RECALL_SLOT, <lb/>| <lb/>| <lb/>| CB_WANTS_CANCELLED, CLOSE, <lb/>| <lb/>| <lb/>| COMMIT, CREATE, DELEGPURGE, <lb/>| <lb/>| <lb/>| DELEGRETURN, FREE_STATEID, <lb/>| <lb/>| <lb/>| GETATTR, GETDEVICEINFO, <lb/>| <lb/>| <lb/>| GETDEVICELIST, GETFH, <lb/>| <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| LOOKUPP, NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| OPENATTR, OPEN_DOWNGRADE, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 407] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| PUTFH, PUTPUBFH, PUTROOTFH, <lb/>| <lb/>| <lb/>| READ, READDIR, READLINK, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, RESTOREFH, SAVEFH, <lb/>| <lb/>| <lb/>| SECINFO, SECINFO_NO_NAME, <lb/>| <lb/>| <lb/>| SETATTR, SET_SSV, <lb/>| <lb/>| <lb/>| TEST_STATEID, VERIFY, <lb/>| <lb/>| <lb/>| WANT_DELEGATION, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_PERM <lb/>| CREATE, OPEN, SETATTR <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_PNFS_IO_HOLE <lb/>| READ, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_PNFS_NO_LAYOUT <lb/>| READ, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_RECALLCONFLICT <lb/>| LAYOUTGET, WANT_DELEGATION <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_RECLAIM_BAD <lb/>| LAYOUTCOMMIT, LOCK, OPEN, <lb/>| <lb/>| <lb/>| WANT_DELEGATION <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_RECLAIM_CONFLICT <lb/>| LAYOUTCOMMIT, LOCK, OPEN, <lb/>| <lb/>| <lb/>| WANT_DELEGATION <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_REJECT_DELEG <lb/>| CB_PUSH_DELEG <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG <lb/>| ACCESS, BACKCHANNEL_CTL, <lb/>| <lb/>| <lb/>| BIND_CONN_TO_SESSION, <lb/>| <lb/>| <lb/>| CB_GETATTR, CB_LAYOUTRECALL, | <lb/>| <lb/>| CB_NOTIFY, <lb/>| <lb/>| <lb/>| CB_NOTIFY_DEVICEID, <lb/>| <lb/>| <lb/>| CB_NOTIFY_LOCK, <lb/>| <lb/>| <lb/>| CB_PUSH_DELEG, CB_RECALL, <lb/>| <lb/>| <lb/>| CB_RECALLABLE_OBJ_AVAIL, <lb/>| <lb/>| <lb/>| CB_RECALL_ANY, <lb/>| <lb/>| <lb/>| CB_RECALL_SLOT, CB_SEQUENCE, | <lb/>| <lb/>| CB_WANTS_CANCELLED, CLOSE, <lb/>| <lb/>| <lb/>| COMMIT, CREATE, <lb/>| <lb/>| <lb/>| CREATE_SESSION, DELEGPURGE, <lb/>| <lb/>| <lb/>| DELEGRETURN, <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID, <lb/>| <lb/>| <lb/>| DESTROY_SESSION, EXCHANGE_ID, | <lb/>| <lb/>| FREE_STATEID, GETATTR, <lb/>| <lb/>| <lb/>| GETDEVICEINFO, GETDEVICELIST, | <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| LOOKUPP, NVERIFY, OPEN, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 408] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| OPENATTR, OPEN_DOWNGRADE, <lb/>| <lb/>| <lb/>| PUTFH, PUTPUBFH, PUTROOTFH, <lb/>| <lb/>| <lb/>| READ, READDIR, READLINK, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, RESTOREFH, SAVEFH, <lb/>| <lb/>| <lb/>| SECINFO, SECINFO_NO_NAME, <lb/>| <lb/>| <lb/>| SEQUENCE, SETATTR, SET_SSV, <lb/>| <lb/>| <lb/>| TEST_STATEID, VERIFY, <lb/>| <lb/>| <lb/>| WANT_DELEGATION, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE <lb/>| ACCESS, BACKCHANNEL_CTL, <lb/>| <lb/>| <lb/>| BIND_CONN_TO_SESSION, <lb/>| <lb/>| <lb/>| CB_GETATTR, CB_LAYOUTRECALL, | <lb/>| <lb/>| CB_NOTIFY, <lb/>| <lb/>| <lb/>| CB_NOTIFY_DEVICEID, <lb/>| <lb/>| <lb/>| CB_NOTIFY_LOCK, <lb/>| <lb/>| <lb/>| CB_PUSH_DELEG, CB_RECALL, <lb/>| <lb/>| <lb/>| CB_RECALLABLE_OBJ_AVAIL, <lb/>| <lb/>| <lb/>| CB_RECALL_ANY, <lb/>| <lb/>| <lb/>| CB_RECALL_SLOT, CB_SEQUENCE, | <lb/>| <lb/>| CB_WANTS_CANCELLED, CLOSE, <lb/>| <lb/>| <lb/>| COMMIT, CREATE, <lb/>| <lb/>| <lb/>| CREATE_SESSION, DELEGPURGE, <lb/>| <lb/>| <lb/>| DELEGRETURN, <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID, <lb/>| <lb/>| <lb/>| DESTROY_SESSION, EXCHANGE_ID, | <lb/>| <lb/>| FREE_STATEID, GETATTR, <lb/>| <lb/>| <lb/>| GETDEVICEINFO, GETDEVICELIST, | <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| LOOKUPP, NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| OPENATTR, OPEN_DOWNGRADE, <lb/>| <lb/>| <lb/>| PUTFH, PUTPUBFH, PUTROOTFH, <lb/>| <lb/>| <lb/>| READ, READDIR, READLINK, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, RESTOREFH, SAVEFH, <lb/>| <lb/>| <lb/>| SECINFO, SECINFO_NO_NAME, <lb/>| <lb/>| <lb/>| SEQUENCE, SETATTR, SET_SSV, <lb/>| <lb/>| <lb/>| TEST_STATEID, VERIFY, <lb/>| <lb/>| <lb/>| WANT_DELEGATION, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG <lb/>| ACCESS, BACKCHANNEL_CTL, <lb/>| <lb/>| <lb/>| BIND_CONN_TO_SESSION, <lb/>| <lb/>| <lb/>| CB_GETATTR, CB_LAYOUTRECALL, | <lb/>| <lb/>| CB_NOTIFY, <lb/>| <lb/>| <lb/>| CB_NOTIFY_DEVICEID, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 409] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| CB_NOTIFY_LOCK, <lb/>| <lb/>| <lb/>| CB_PUSH_DELEG, CB_RECALL, <lb/>| <lb/>| <lb/>| CB_RECALLABLE_OBJ_AVAIL, <lb/>| <lb/>| <lb/>| CB_RECALL_ANY, <lb/>| <lb/>| <lb/>| CB_RECALL_SLOT, CB_SEQUENCE, | <lb/>| <lb/>| CB_WANTS_CANCELLED, CLOSE, <lb/>| <lb/>| <lb/>| COMMIT, CREATE, <lb/>| <lb/>| <lb/>| CREATE_SESSION, DELEGPURGE, <lb/>| <lb/>| <lb/>| DELEGRETURN, <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID, <lb/>| <lb/>| <lb/>| DESTROY_SESSION, EXCHANGE_ID, | <lb/>| <lb/>| FREE_STATEID, GETATTR, <lb/>| <lb/>| <lb/>| GETDEVICEINFO, GETDEVICELIST, | <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| LOOKUPP, NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| OPENATTR, OPEN_DOWNGRADE, <lb/>| <lb/>| <lb/>| PUTFH, PUTPUBFH, PUTROOTFH, <lb/>| <lb/>| <lb/>| READ, READDIR, READLINK, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, RESTOREFH, SAVEFH, <lb/>| <lb/>| <lb/>| SECINFO, SECINFO_NO_NAME, <lb/>| <lb/>| <lb/>| SEQUENCE, SETATTR, SET_SSV, <lb/>| <lb/>| <lb/>| TEST_STATEID, VERIFY, <lb/>| <lb/>| <lb/>| WANT_DELEGATION, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_RETRY_UNCACHED_REP <lb/>| ACCESS, BACKCHANNEL_CTL, <lb/>| <lb/>| <lb/>| BIND_CONN_TO_SESSION, <lb/>| <lb/>| <lb/>| CB_GETATTR, CB_LAYOUTRECALL, | <lb/>| <lb/>| CB_NOTIFY, <lb/>| <lb/>| <lb/>| CB_NOTIFY_DEVICEID, <lb/>| <lb/>| <lb/>| CB_NOTIFY_LOCK, <lb/>| <lb/>| <lb/>| CB_PUSH_DELEG, CB_RECALL, <lb/>| <lb/>| <lb/>| CB_RECALLABLE_OBJ_AVAIL, <lb/>| <lb/>| <lb/>| CB_RECALL_ANY, <lb/>| <lb/>| <lb/>| CB_RECALL_SLOT, CB_SEQUENCE, | <lb/>| <lb/>| CB_WANTS_CANCELLED, CLOSE, <lb/>| <lb/>| <lb/>| COMMIT, CREATE, <lb/>| <lb/>| <lb/>| CREATE_SESSION, DELEGPURGE, <lb/>| <lb/>| <lb/>| DELEGRETURN, <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID, <lb/>| <lb/>| <lb/>| DESTROY_SESSION, EXCHANGE_ID, | <lb/>| <lb/>| FREE_STATEID, GETATTR, <lb/>| <lb/>| <lb/>| GETDEVICEINFO, GETDEVICELIST, | <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 410] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| LOOKUPP, NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| OPENATTR, OPEN_DOWNGRADE, <lb/>| <lb/>| <lb/>| PUTFH, PUTPUBFH, PUTROOTFH, <lb/>| <lb/>| <lb/>| READ, READDIR, READLINK, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, RESTOREFH, SAVEFH, <lb/>| <lb/>| <lb/>| SECINFO, SECINFO_NO_NAME, <lb/>| <lb/>| <lb/>| SEQUENCE, SETATTR, SET_SSV, <lb/>| <lb/>| <lb/>| TEST_STATEID, VERIFY, <lb/>| <lb/>| <lb/>| WANT_DELEGATION, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_ROFS <lb/>| CREATE, LINK, LOCK, LOCKT, <lb/>| <lb/>| <lb/>| OPEN, OPENATTR, <lb/>| <lb/>| <lb/>| OPEN_DOWNGRADE, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, SETATTR, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_SAME <lb/>| NVERIFY <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_SEQUENCE_POS <lb/>| CB_SEQUENCE, SEQUENCE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_SEQ_FALSE_RETRY <lb/>| CB_SEQUENCE, SEQUENCE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_SEQ_MISORDERED <lb/>| CB_SEQUENCE, CREATE_SESSION, | <lb/>| <lb/>| SEQUENCE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_SERVERFAULT <lb/>| ACCESS, BIND_CONN_TO_SESSION, | <lb/>| <lb/>| CB_GETATTR, CB_NOTIFY, <lb/>| <lb/>| <lb/>| CB_NOTIFY_DEVICEID, <lb/>| <lb/>| <lb/>| CB_NOTIFY_LOCK, <lb/>| <lb/>| <lb/>| CB_PUSH_DELEG, CB_RECALL, <lb/>| <lb/>| <lb/>| CB_RECALLABLE_OBJ_AVAIL, <lb/>| <lb/>| <lb/>| CB_WANTS_CANCELLED, CLOSE, <lb/>| <lb/>| <lb/>| COMMIT, CREATE, <lb/>| <lb/>| <lb/>| CREATE_SESSION, DELEGPURGE, <lb/>| <lb/>| <lb/>| DELEGRETURN, <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID, <lb/>| <lb/>| <lb/>| DESTROY_SESSION, EXCHANGE_ID, | <lb/>| <lb/>| FREE_STATEID, GETATTR, <lb/>| <lb/>| <lb/>| GETDEVICEINFO, GETDEVICELIST, | <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKU, LOOKUP, LOOKUPP, <lb/>| <lb/>| <lb/>| NVERIFY, OPEN, OPENATTR, <lb/>| <lb/>| <lb/>| OPEN_DOWNGRADE, PUTFH, <lb/>| <lb/>| <lb/>| PUTPUBFH, PUTROOTFH, READ, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 411] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| READDIR, READLINK, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, RESTOREFH, SAVEFH, <lb/>| <lb/>| <lb/>| SECINFO, SECINFO_NO_NAME, <lb/>| <lb/>| <lb/>| SETATTR, TEST_STATEID, <lb/>| <lb/>| <lb/>| VERIFY, WANT_DELEGATION, <lb/>| <lb/>| <lb/>| WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_SHARE_DENIED <lb/>| OPEN <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_STALE <lb/>| ACCESS, CLOSE, COMMIT, <lb/>| <lb/>| <lb/>| CREATE, DELEGRETURN, GETATTR, | <lb/>| <lb/>| GETFH, GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| LOOKUPP, NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| OPENATTR, OPEN_DOWNGRADE, <lb/>| <lb/>| <lb/>| PUTFH, READ, READDIR, <lb/>| <lb/>| <lb/>| READLINK, RECLAIM_COMPLETE, <lb/>| <lb/>| <lb/>| REMOVE, RENAME, RESTOREFH, <lb/>| <lb/>| <lb/>| SAVEFH, SECINFO, <lb/>| <lb/>| <lb/>| SECINFO_NO_NAME, SETATTR, <lb/>| <lb/>| <lb/>| VERIFY, WANT_DELEGATION, <lb/>| <lb/>| <lb/>| WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_STALE_CLIENTID <lb/>| CREATE_SESSION, <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID, <lb/>| <lb/>| <lb/>| DESTROY_SESSION <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_SYMLINK <lb/>| COMMIT, LAYOUTCOMMIT, LINK, <lb/>| <lb/>| <lb/>| LOCK, LOCKT, LOOKUP, LOOKUPP, | <lb/>| <lb/>| OPEN, READ, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_TOOSMALL <lb/>| CREATE_SESSION, <lb/>| <lb/>| <lb/>| GETDEVICEINFO, LAYOUTGET, <lb/>| <lb/>| <lb/>| READDIR <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| ACCESS, BACKCHANNEL_CTL, <lb/>| <lb/>| <lb/>| BIND_CONN_TO_SESSION, <lb/>| <lb/>| <lb/>| CB_GETATTR, CB_LAYOUTRECALL, | <lb/>| <lb/>| CB_NOTIFY, <lb/>| <lb/>| <lb/>| CB_NOTIFY_DEVICEID, <lb/>| <lb/>| <lb/>| CB_NOTIFY_LOCK, <lb/>| <lb/>| <lb/>| CB_PUSH_DELEG, CB_RECALL, <lb/>| <lb/>| <lb/>| CB_RECALLABLE_OBJ_AVAIL, <lb/>| <lb/>| <lb/>| CB_RECALL_ANY, <lb/>| <lb/>| <lb/>| CB_RECALL_SLOT, CB_SEQUENCE, | <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 412] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| CB_WANTS_CANCELLED, CLOSE, <lb/>| <lb/>| <lb/>| COMMIT, CREATE, <lb/>| <lb/>| <lb/>| CREATE_SESSION, DELEGPURGE, <lb/>| <lb/>| <lb/>| DELEGRETURN, <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID, <lb/>| <lb/>| <lb/>| DESTROY_SESSION, EXCHANGE_ID, | <lb/>| <lb/>| FREE_STATEID, GETATTR, <lb/>| <lb/>| <lb/>| GETDEVICEINFO, GETDEVICELIST, | <lb/>| <lb/>| GET_DIR_DELEGATION, <lb/>| <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/>| <lb/>| LOCKT, LOCKU, LOOKUP, <lb/>| <lb/>| <lb/>| LOOKUPP, NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| OPENATTR, OPEN_DOWNGRADE, <lb/>| <lb/>| <lb/>| PUTFH, PUTPUBFH, PUTROOTFH, <lb/>| <lb/>| <lb/>| READ, READDIR, READLINK, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE, REMOVE, <lb/>| <lb/>| <lb/>| RENAME, RESTOREFH, SAVEFH, <lb/>| <lb/>| <lb/>| SECINFO, SECINFO_NO_NAME, <lb/>| <lb/>| <lb/>| SEQUENCE, SETATTR, SET_SSV, <lb/>| <lb/>| <lb/>| TEST_STATEID, VERIFY, <lb/>| <lb/>| <lb/>| WANT_DELEGATION, WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_UNKNOWN_LAYOUTTYPE <lb/>| CB_LAYOUTRECALL, <lb/>| <lb/>| <lb/>| GETDEVICEINFO, GETDEVICELIST, | <lb/>| <lb/>| LAYOUTCOMMIT, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, NVERIFY, <lb/>| <lb/>| <lb/>| SETATTR, VERIFY <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_UNSAFE_COMPOUND <lb/>| CREATE, OPEN, OPENATTR <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_WRONGSEC <lb/>| LINK, LOOKUP, LOOKUPP, OPEN, | <lb/>| <lb/>| PUTFH, PUTPUBFH, PUTROOTFH, <lb/>| <lb/>| <lb/>| RENAME, RESTOREFH <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_CRED <lb/>| CLOSE, CREATE_SESSION, <lb/>| <lb/>| <lb/>| DELEGPURGE, DELEGRETURN, <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID, <lb/>| <lb/>| <lb/>| DESTROY_SESSION, <lb/>| <lb/>| <lb/>| FREE_STATEID, LAYOUTCOMMIT, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LOCK, LOCKT, <lb/>| <lb/>| <lb/>| LOCKU, OPEN_DOWNGRADE, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_WRONG_TYPE <lb/>| CB_LAYOUTRECALL, <lb/>| <lb/>| <lb/>| CB_PUSH_DELEG, COMMIT, <lb/>| <lb/>| <lb/>| GETATTR, LAYOUTGET, <lb/>| <lb/>| <lb/>| LAYOUTRETURN, LINK, LOCK, <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 413] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| LOCKT, NVERIFY, OPEN, <lb/>| <lb/>| <lb/>| OPENATTR, READ, READLINK, <lb/>| <lb/>| <lb/>| RECLAIM_COMPLETE, SETATTR, <lb/>| <lb/>| <lb/>| VERIFY, WANT_DELEGATION, <lb/>| <lb/>| <lb/>| WRITE <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NFS4ERR_XDEV <lb/>| LINK, RENAME <lb/>| <lb/>| <lb/>| <lb/>| <lb/>+-----------------------------------+-------------------------------+ <lb/>Table 8 <lb/>16. NFSv4.1 Procedures <lb/>Both procedures, NULL and COMPOUND, MUST be implemented. <lb/>16.1. Procedure 0: NULL -No Operation <lb/>16.1.1. ARGUMENTS <lb/>void; <lb/>16.1.2. RESULTS <lb/>void; <lb/>16.1.3. DESCRIPTION <lb/>This is the standard NULL procedure with the standard void argument <lb/>and void response. This procedure has no functionality associated <lb/>with it. Because of this, it is sometimes used to measure the <lb/>overhead of processing a service request. Therefore, the server <lb/>SHOULD ensure that no unnecessary work is done in servicing this <lb/>procedure. <lb/>16.1.4. ERRORS <lb/>None. <lb/>16.2. Procedure 1: COMPOUND -Compound Operations <lb/>16.2.1. ARGUMENTS <lb/>enum nfs_opnum4 { <lb/>OP_ACCESS <lb/>= 3, <lb/>OP_CLOSE <lb/>= 4, <lb/>OP_COMMIT <lb/>= 5, <lb/>OP_CREATE <lb/>= 6, <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 414] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>OP_DELEGPURGE <lb/>= 7, <lb/>OP_DELEGRETURN <lb/>= 8, <lb/>OP_GETATTR <lb/>= 9, <lb/>OP_GETFH <lb/>= 10, <lb/>OP_LINK <lb/>= 11, <lb/>OP_LOCK <lb/>= 12, <lb/>OP_LOCKT <lb/>= 13, <lb/>OP_LOCKU <lb/>= 14, <lb/>OP_LOOKUP <lb/>= 15, <lb/>OP_LOOKUPP <lb/>= 16, <lb/>OP_NVERIFY <lb/>= 17, <lb/>OP_OPEN <lb/>= 18, <lb/>OP_OPENATTR <lb/>= 19, <lb/>OP_OPEN_CONFIRM <lb/>= 20, /* Mandatory not-to-implement */ <lb/>OP_OPEN_DOWNGRADE <lb/>= 21, <lb/>OP_PUTFH <lb/>= 22, <lb/>OP_PUTPUBFH <lb/>= 23, <lb/>OP_PUTROOTFH <lb/>= 24, <lb/>OP_READ <lb/>= 25, <lb/>OP_READDIR <lb/>= 26, <lb/>OP_READLINK <lb/>= 27, <lb/>OP_REMOVE <lb/>= 28, <lb/>OP_RENAME <lb/>= 29, <lb/>OP_RENEW <lb/>= 30, /* Mandatory not-to-implement */ <lb/>OP_RESTOREFH <lb/>= 31, <lb/>OP_SAVEFH <lb/>= 32, <lb/>OP_SECINFO <lb/>= 33, <lb/>OP_SETATTR <lb/>= 34, <lb/>OP_SETCLIENTID <lb/>= 35, /* Mandatory not-to-implement */ <lb/>OP_SETCLIENTID_CONFIRM = 36, /* Mandatory not-to-implement */ <lb/>OP_VERIFY <lb/>= 37, <lb/>OP_WRITE <lb/>= 38, <lb/>OP_RELEASE_LOCKOWNER <lb/>= 39, /* Mandatory not-to-implement */ <lb/>/* new operations for NFSv4.1 */ <lb/>OP_BACKCHANNEL_CTL <lb/>= 40, <lb/>OP_BIND_CONN_TO_SESSION = 41, <lb/>OP_EXCHANGE_ID <lb/>= 42, <lb/>OP_CREATE_SESSION <lb/>= 43, <lb/>OP_DESTROY_SESSION <lb/>= 44, <lb/>OP_FREE_STATEID <lb/>= 45, <lb/>OP_GET_DIR_DELEGATION = 46, <lb/>OP_GETDEVICEINFO <lb/>= 47, <lb/>OP_GETDEVICELIST <lb/>= 48, <lb/>OP_LAYOUTCOMMIT <lb/>= 49, <lb/>OP_LAYOUTGET <lb/>= 50, <lb/>OP_LAYOUTRETURN <lb/>= 51, <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 415] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>OP_SECINFO_NO_NAME <lb/>= 52, <lb/>OP_SEQUENCE <lb/>= 53, <lb/>OP_SET_SSV <lb/>= 54, <lb/>OP_TEST_STATEID <lb/>= 55, <lb/>OP_WANT_DELEGATION <lb/>= 56, <lb/>OP_DESTROY_CLIENTID <lb/>= 57, <lb/>OP_RECLAIM_COMPLETE <lb/>= 58, <lb/>OP_ILLEGAL <lb/>= 10044 <lb/>}; <lb/>union nfs_argop4 switch (nfs_opnum4 argop) { <lb/>case OP_ACCESS: <lb/>ACCESS4args opaccess; <lb/>case OP_CLOSE: <lb/>CLOSE4args opclose; <lb/>case OP_COMMIT: <lb/>COMMIT4args opcommit; <lb/>case OP_CREATE: <lb/>CREATE4args opcreate; <lb/>case OP_DELEGPURGE: <lb/>DELEGPURGE4args opdelegpurge; <lb/>case OP_DELEGRETURN: <lb/>DELEGRETURN4args opdelegreturn; <lb/>case OP_GETATTR: <lb/>GETATTR4args opgetattr; <lb/>case OP_GETFH: <lb/>void; <lb/>case OP_LINK: <lb/>LINK4args oplink; <lb/>case OP_LOCK: <lb/>LOCK4args oplock; <lb/>case OP_LOCKT: <lb/>LOCKT4args oplockt; <lb/>case OP_LOCKU: <lb/>LOCKU4args oplocku; <lb/>case OP_LOOKUP: <lb/>LOOKUP4args oplookup; <lb/>case OP_LOOKUPP: <lb/>void; <lb/>case OP_NVERIFY: <lb/>NVERIFY4args opnverify; <lb/>case OP_OPEN: <lb/>OPEN4args opopen; <lb/>case OP_OPENATTR: <lb/>OPENATTR4args opopenattr; <lb/>/* Not for NFSv4.1 */ <lb/>case OP_OPEN_CONFIRM: OPEN_CONFIRM4args opopen_confirm; <lb/>case OP_OPEN_DOWNGRADE: <lb/>OPEN_DOWNGRADE4args opopen_downgrade; <lb/>case OP_PUTFH: <lb/>PUTFH4args opputfh; <lb/>case OP_PUTPUBFH: <lb/>void; <lb/>case OP_PUTROOTFH: <lb/>void; <lb/>case OP_READ: <lb/>READ4args opread; <lb/>case OP_READDIR: <lb/>READDIR4args opreaddir; <lb/>case OP_READLINK: <lb/>void; <lb/>case OP_REMOVE: <lb/>REMOVE4args opremove; <lb/>case OP_RENAME: <lb/>RENAME4args oprename; <lb/>/* Not for NFSv4.1 */ <lb/>case OP_RENEW: <lb/>RENEW4args oprenew; <lb/>case OP_RESTOREFH: <lb/>void; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 416] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>case OP_SAVEFH: <lb/>void; <lb/>case OP_SECINFO: <lb/>SECINFO4args opsecinfo; <lb/>case OP_SETATTR: <lb/>SETATTR4args opsetattr; <lb/>/* Not for NFSv4.1 */ <lb/>case OP_SETCLIENTID: SETCLIENTID4args opsetclientid; <lb/>/* Not for NFSv4.1 */ <lb/>case OP_SETCLIENTID_CONFIRM: SETCLIENTID_CONFIRM4args <lb/>opsetclientid_confirm; <lb/>case OP_VERIFY: <lb/>VERIFY4args opverify; <lb/>case OP_WRITE: <lb/>WRITE4args opwrite; <lb/>/* Not for NFSv4.1 */ <lb/>case OP_RELEASE_LOCKOWNER: <lb/>RELEASE_LOCKOWNER4args <lb/>oprelease_lockowner; <lb/>/* Operations new to NFSv4.1 */ <lb/>case OP_BACKCHANNEL_CTL: <lb/>BACKCHANNEL_CTL4args opbackchannel_ctl; <lb/>case OP_BIND_CONN_TO_SESSION: <lb/>BIND_CONN_TO_SESSION4args <lb/>opbind_conn_to_session; <lb/>case OP_EXCHANGE_ID: <lb/>EXCHANGE_ID4args opexchange_id; <lb/>case OP_CREATE_SESSION: <lb/>CREATE_SESSION4args opcreate_session; <lb/>case OP_DESTROY_SESSION: <lb/>DESTROY_SESSION4args opdestroy_session; <lb/>case OP_FREE_STATEID: FREE_STATEID4args opfree_stateid; <lb/>case OP_GET_DIR_DELEGATION: <lb/>GET_DIR_DELEGATION4args <lb/>opget_dir_delegation; <lb/>case OP_GETDEVICEINFO: GETDEVICEINFO4args opgetdeviceinfo; <lb/>case OP_GETDEVICELIST: GETDEVICELIST4args opgetdevicelist; <lb/>case OP_LAYOUTCOMMIT: LAYOUTCOMMIT4args oplayoutcommit; <lb/>case OP_LAYOUTGET: <lb/>LAYOUTGET4args oplayoutget; <lb/>case OP_LAYOUTRETURN: LAYOUTRETURN4args oplayoutreturn; <lb/>case OP_SECINFO_NO_NAME: <lb/>SECINFO_NO_NAME4args opsecinfo_no_name; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 417] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>case OP_SEQUENCE: <lb/>SEQUENCE4args opsequence; <lb/>case OP_SET_SSV: <lb/>SET_SSV4args opset_ssv; <lb/>case OP_TEST_STATEID: TEST_STATEID4args optest_stateid; <lb/>case OP_WANT_DELEGATION: <lb/>WANT_DELEGATION4args opwant_delegation; <lb/>case OP_DESTROY_CLIENTID: <lb/>DESTROY_CLIENTID4args <lb/>opdestroy_clientid; <lb/>case OP_RECLAIM_COMPLETE: <lb/>RECLAIM_COMPLETE4args <lb/>opreclaim_complete; <lb/>/* Operations not new to NFSv4.1 */ <lb/>case OP_ILLEGAL: <lb/>void; <lb/>}; <lb/>struct COMPOUND4args { <lb/>utf8str_cs <lb/>tag; <lb/>uint32_t <lb/>minorversion; <lb/>nfs_argop4 <lb/>argarray&lt;&gt;; <lb/>}; <lb/>16.2.2. RESULTS <lb/>union nfs_resop4 switch (nfs_opnum4 resop) { <lb/>case OP_ACCESS: <lb/>ACCESS4res opaccess; <lb/>case OP_CLOSE: <lb/>CLOSE4res opclose; <lb/>case OP_COMMIT: <lb/>COMMIT4res opcommit; <lb/>case OP_CREATE: <lb/>CREATE4res opcreate; <lb/>case OP_DELEGPURGE: <lb/>DELEGPURGE4res opdelegpurge; <lb/>case OP_DELEGRETURN: <lb/>DELEGRETURN4res opdelegreturn; <lb/>case OP_GETATTR: <lb/>GETATTR4res opgetattr; <lb/>case OP_GETFH: <lb/>GETFH4res opgetfh; <lb/>case OP_LINK: <lb/>LINK4res oplink; <lb/>case OP_LOCK: <lb/>LOCK4res oplock; <lb/>case OP_LOCKT: <lb/>LOCKT4res oplockt; <lb/>case OP_LOCKU: <lb/>LOCKU4res oplocku; <lb/>case OP_LOOKUP: <lb/>LOOKUP4res oplookup; <lb/>case OP_LOOKUPP: <lb/>LOOKUPP4res oplookupp; <lb/>case OP_NVERIFY: <lb/>NVERIFY4res opnverify; <lb/>case OP_OPEN: <lb/>OPEN4res opopen; <lb/>case OP_OPENATTR: <lb/>OPENATTR4res opopenattr; <lb/>/* Not for NFSv4.1 */ <lb/>case OP_OPEN_CONFIRM: OPEN_CONFIRM4res opopen_confirm; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 418] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>case OP_OPEN_DOWNGRADE: <lb/>OPEN_DOWNGRADE4res <lb/>opopen_downgrade; <lb/>case OP_PUTFH: <lb/>PUTFH4res opputfh; <lb/>case OP_PUTPUBFH: <lb/>PUTPUBFH4res opputpubfh; <lb/>case OP_PUTROOTFH: <lb/>PUTROOTFH4res opputrootfh; <lb/>case OP_READ: <lb/>READ4res opread; <lb/>case OP_READDIR: <lb/>READDIR4res opreaddir; <lb/>case OP_READLINK: <lb/>READLINK4res opreadlink; <lb/>case OP_REMOVE: <lb/>REMOVE4res opremove; <lb/>case OP_RENAME: <lb/>RENAME4res oprename; <lb/>/* Not for NFSv4.1 */ <lb/>case OP_RENEW: <lb/>RENEW4res oprenew; <lb/>case OP_RESTOREFH: <lb/>RESTOREFH4res oprestorefh; <lb/>case OP_SAVEFH: <lb/>SAVEFH4res opsavefh; <lb/>case OP_SECINFO: <lb/>SECINFO4res opsecinfo; <lb/>case OP_SETATTR: <lb/>SETATTR4res opsetattr; <lb/>/* Not for NFSv4.1 */ <lb/>case OP_SETCLIENTID: SETCLIENTID4res opsetclientid; <lb/>/* Not for NFSv4.1 */ <lb/>case OP_SETCLIENTID_CONFIRM: <lb/>SETCLIENTID_CONFIRM4res <lb/>opsetclientid_confirm; <lb/>case OP_VERIFY: <lb/>VERIFY4res opverify; <lb/>case OP_WRITE: <lb/>WRITE4res opwrite; <lb/>/* Not for NFSv4.1 */ <lb/>case OP_RELEASE_LOCKOWNER: <lb/>RELEASE_LOCKOWNER4res <lb/>oprelease_lockowner; <lb/>/* Operations new to NFSv4.1 */ <lb/>case OP_BACKCHANNEL_CTL: <lb/>BACKCHANNEL_CTL4res <lb/>opbackchannel_ctl; <lb/>case OP_BIND_CONN_TO_SESSION: <lb/>BIND_CONN_TO_SESSION4res <lb/>opbind_conn_to_session; <lb/>case OP_EXCHANGE_ID: <lb/>EXCHANGE_ID4res opexchange_id; <lb/>case OP_CREATE_SESSION: <lb/>CREATE_SESSION4res <lb/>opcreate_session; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 419] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>case OP_DESTROY_SESSION: <lb/>DESTROY_SESSION4res <lb/>opdestroy_session; <lb/>case OP_FREE_STATEID: FREE_STATEID4res <lb/>opfree_stateid; <lb/>case OP_GET_DIR_DELEGATION: <lb/>GET_DIR_DELEGATION4res <lb/>opget_dir_delegation; <lb/>case OP_GETDEVICEINFO: GETDEVICEINFO4res <lb/>opgetdeviceinfo; <lb/>case OP_GETDEVICELIST: GETDEVICELIST4res <lb/>opgetdevicelist; <lb/>case OP_LAYOUTCOMMIT: LAYOUTCOMMIT4res oplayoutcommit; <lb/>case OP_LAYOUTGET: <lb/>LAYOUTGET4res oplayoutget; <lb/>case OP_LAYOUTRETURN: LAYOUTRETURN4res oplayoutreturn; <lb/>case OP_SECINFO_NO_NAME: <lb/>SECINFO_NO_NAME4res <lb/>opsecinfo_no_name; <lb/>case OP_SEQUENCE: <lb/>SEQUENCE4res opsequence; <lb/>case OP_SET_SSV: <lb/>SET_SSV4res opset_ssv; <lb/>case OP_TEST_STATEID: TEST_STATEID4res optest_stateid; <lb/>case OP_WANT_DELEGATION: <lb/>WANT_DELEGATION4res <lb/>opwant_delegation; <lb/>case OP_DESTROY_CLIENTID: <lb/>DESTROY_CLIENTID4res <lb/>opdestroy_clientid; <lb/>case OP_RECLAIM_COMPLETE: <lb/>RECLAIM_COMPLETE4res <lb/>opreclaim_complete; <lb/>/* Operations not new to NFSv4.1 */ <lb/>case OP_ILLEGAL: <lb/>ILLEGAL4res opillegal; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 420] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct COMPOUND4res { <lb/>nfsstat4 <lb/>status; <lb/>utf8str_cs <lb/>tag; <lb/>nfs_resop4 <lb/>resarray&lt;&gt;; <lb/>}; <lb/>16.2.3. DESCRIPTION <lb/>The COMPOUND procedure is used to combine one or more NFSv4 <lb/>operations into a single RPC request. The server interprets each of <lb/>the operations in turn. If an operation is executed by the server <lb/>and the status of that operation is NFS4_OK, then the next operation <lb/>in the COMPOUND procedure is executed. The server continues this <lb/>process until there are no more operations to be executed or until <lb/>one of the operations has a status value other than NFS4_OK. <lb/>In the processing of the COMPOUND procedure, the server may find that <lb/>it does not have the available resources to execute any or all of the <lb/>operations within the COMPOUND sequence. See Section 2.10.6.4 for a <lb/>more detailed discussion. <lb/>The server will generally choose between two methods of decoding the <lb/>client&apos;s request. The first would be the traditional one-pass XDR <lb/>decode. If there is an XDR decoding error in this case, the RPC XDR <lb/>decode error would be returned. The second method would be to make <lb/>an initial pass to decode the basic COMPOUND request and then to XDR <lb/>decode the individual operations; the most interesting is the decode <lb/>of attributes. In this case, the server may encounter an XDR decode <lb/>error during the second pass. If it does, the server would return <lb/>the error NFS4ERR_BADXDR to signify the decode error. <lb/>The COMPOUND arguments contain a &quot;minorversion&quot; field. For NFSv4.1, <lb/>the value for this field is 1. If the server receives a COMPOUND <lb/>procedure with a minorversion field value that it does not support, <lb/>the server MUST return an error of NFS4ERR_MINOR_VERS_MISMATCH and a <lb/>zero-length resultdata array. <lb/>Contained within the COMPOUND results is a &quot;status&quot; field. If the <lb/>results array length is non-zero, this status must be equivalent to <lb/>the status of the last operation that was executed within the <lb/>COMPOUND procedure. Therefore, if an operation incurred an error <lb/>then the &quot;status&quot; value will be the same error value as is being <lb/>returned for the operation that failed. <lb/>Note that operations zero and one are not defined for the COMPOUND <lb/>procedure. Operation 2 is not defined and is reserved for future <lb/>definition and use with minor versioning. If the server receives an <lb/>operation array that contains operation 2 and the minorversion field <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 421] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>has a value of zero, an error of NFS4ERR_OP_ILLEGAL, as described in <lb/>the next paragraph, is returned to the client. If an operation array <lb/>contains an operation 2 and the minorversion field is non-zero and <lb/>the server does not support the minor version, the server returns an <lb/>error of NFS4ERR_MINOR_VERS_MISMATCH. Therefore, the <lb/>NFS4ERR_MINOR_VERS_MISMATCH error takes precedence over all other <lb/>errors. <lb/>It is possible that the server receives a request that contains an <lb/>operation that is less than the first legal operation (OP_ACCESS) or <lb/>greater than the last legal operation (OP_RELEASE_LOCKOWNER). In <lb/>this case, the server&apos;s response will encode the opcode OP_ILLEGAL <lb/>rather than the illegal opcode of the request. The status field in <lb/>the ILLEGAL return results will be set to NFS4ERR_OP_ILLEGAL. The <lb/>COMPOUND procedure&apos;s return results will also be NFS4ERR_OP_ILLEGAL. <lb/>The definition of the &quot;tag&quot; in the request is left to the <lb/>implementor. It may be used to summarize the content of the Compound <lb/>request for the benefit of packet-sniffers and engineers debugging <lb/>implementations. However, the value of &quot;tag&quot; in the response SHOULD <lb/>be the same value as provided in the request. This applies to the <lb/>tag field of the CB_COMPOUND procedure as well. <lb/>16.2.3.1. Current Filehandle and Stateid <lb/>The COMPOUND procedure offers a simple environment for the execution <lb/>of the operations specified by the client. The first two relate to <lb/>the filehandle while the second two relate to the current stateid. <lb/>16.2.3.1.1. Current Filehandle <lb/>The current and saved filehandles are used throughout the protocol. <lb/>Most operations implicitly use the current filehandle as an argument, <lb/>and many set the current filehandle as part of the results. The <lb/>combination of client-specified sequences of operations and current <lb/>and saved filehandle arguments and results allows for greater <lb/>protocol flexibility. The best or easiest example of current <lb/>filehandle usage is a sequence like the following: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 422] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>PUTFH fh1 <lb/>{fh1} <lb/>LOOKUP &quot;compA&quot; <lb/>{fh2} <lb/>GETATTR <lb/>{fh2} <lb/>LOOKUP &quot;compB&quot; <lb/>{fh3} <lb/>GETATTR <lb/>{fh3} <lb/>LOOKUP &quot;compC&quot; <lb/>{fh4} <lb/>GETATTR <lb/>{fh4} <lb/>GETFH <lb/>Figure 2 <lb/>In this example, the PUTFH (Section 18.19) operation explicitly sets <lb/>the current filehandle value while the result of each LOOKUP <lb/>operation sets the current filehandle value to the resultant file <lb/>system object. Also, the client is able to insert GETATTR operations <lb/>using the current filehandle as an argument. <lb/>The PUTROOTFH (Section 18.21) and PUTPUBFH (Section 18.20) operations <lb/>also set the current filehandle. The above example would replace <lb/>&quot;PUTFH fh1&quot; with PUTROOTFH or PUTPUBFH with no filehandle argument in <lb/>order to achieve the same effect (on the assumption that &quot;compA&quot; is <lb/>directly below the root of the namespace). <lb/>Along with the current filehandle, there is a saved filehandle. <lb/>While the current filehandle is set as the result of operations like <lb/>LOOKUP, the saved filehandle must be set directly with the use of the <lb/>SAVEFH operation. The SAVEFH operation copies the current filehandle <lb/>value to the saved value. The saved filehandle value is used in <lb/>combination with the current filehandle value for the LINK and RENAME <lb/>operations. The RESTOREFH operation will copy the saved filehandle <lb/>value to the current filehandle value; as a result, the saved <lb/>filehandle value may be used a sort of &quot;scratch&quot; area for the <lb/>client&apos;s series of operations. <lb/>16.2.3.1.2. Current Stateid <lb/>With NFSv4.1, additions of a current stateid and a saved stateid have <lb/>been made to the COMPOUND processing environment; this allows for the <lb/>passing of stateids between operations. There are no changes to the <lb/>syntax of the protocol, only changes to the semantics of a few <lb/>operations. <lb/>A &quot;current stateid&quot; is the stateid that is associated with the <lb/>current filehandle. The current stateid may only be changed by an <lb/>operation that modifies the current filehandle or returns a stateid. <lb/>If an operation returns a stateid, it MUST set the current stateid to <lb/>the returned value. If an operation sets the current filehandle but <lb/>does not return a stateid, the current stateid MUST be set to the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 423] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>all-zeros special stateid, i.e., (seqid, other) = (0, 0). If an <lb/>operation uses a stateid as an argument but does not return a <lb/>stateid, the current stateid MUST NOT be changed. For example, <lb/>PUTFH, PUTROOTFH, and PUTPUBFH will change the current server state <lb/>from {ocfh, (osid)} to {cfh, (0, 0)}, while LOCK will change the <lb/>current state from {cfh, (osid} to {cfh, (nsid)}. Operations like <lb/>LOOKUP that transform a current filehandle and component name into a <lb/>new current filehandle will also change the current state to {0, 0}. <lb/>The SAVEFH and RESTOREFH operations will save and restore both the <lb/>current filehandle and the current stateid as a set. <lb/>The following example is the common case of a simple READ operation <lb/>with a normal stateid showing that the PUTFH initializes the current <lb/>stateid to (0, 0). The subsequent READ with stateid (sid1) leaves <lb/>the current stateid unchanged. <lb/>PUTFH fh1 <lb/>--&gt; {fh1, (0, 0)} <lb/>READ (sid1), 0, 1024 <lb/>{fh1, (0, 0)} -&gt; {fh1, (0, 0)} <lb/>Figure 3 <lb/>This next example performs an OPEN with the root filehandle and, as a <lb/>result, generates stateid (sid1). The next operation specifies the <lb/>READ with the argument stateid set such that (seqid, other) are equal <lb/>to (1, 0), but the current stateid set by the previous operation is <lb/>actually used when the operation is evaluated. This allows correct <lb/>interaction with any existing, potentially conflicting, locks. <lb/>PUTROOTFH <lb/>--&gt; {fh1, (0, 0)} <lb/>OPEN &quot;compA&quot; <lb/>{fh1, (0, 0)} -&gt; {fh2, (sid1)} <lb/>READ (1, 0), 0, 1024 <lb/>{fh2, (sid1)} -&gt; {fh2, (sid1)} <lb/>CLOSE (1, 0) <lb/>{fh2, (sid1)} -&gt; {fh2, (sid2)} <lb/>Figure 4 <lb/>This next example is similar to the second in how it passes the <lb/>stateid sid2 generated by the LOCK operation to the next READ <lb/>operation. This allows the client to explicitly surround a single I/ <lb/>O operation with a lock and its appropriate stateid to guarantee <lb/>correctness with other client locks. The example also shows how <lb/>SAVEFH and RESTOREFH can save and later reuse a filehandle and <lb/>stateid, passing them as the current filehandle and stateid to a READ <lb/>operation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 424] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>PUTFH fh1 <lb/>--&gt; {fh1, (0, 0)} <lb/>LOCK 0, 1024, (sid1) <lb/>{fh1, (sid1)} -&gt; {fh1, (sid2)} <lb/>READ (1, 0), 0, 1024 <lb/>{fh1, (sid2)} -&gt; {fh1, (sid2)} <lb/>LOCKU 0, 1024, (1, 0) <lb/>{fh1, (sid2)} -&gt; {fh1, (sid3)} <lb/>SAVEFH <lb/>{fh1, (sid3)} -&gt; {fh1, (sid3)} <lb/>PUTFH fh2 <lb/>{fh1, (sid3)} -&gt; {fh2, (0, 0)} <lb/>WRITE (1, 0), 0, 1024 <lb/>{fh2, (0, 0)} -&gt; {fh2, (0, 0)} <lb/>RESTOREFH <lb/>{fh2, (0, 0)} -&gt; {fh1, (sid3)} <lb/>READ (1, 0), 1024, 1024 <lb/>{fh1, (sid3)} -&gt; {fh1, (sid3)} <lb/>Figure 5 <lb/>The final example shows a disallowed use of the current stateid. The <lb/>client is attempting to implicitly pass an anonymous special stateid, <lb/>(0,0), to the READ operation. The server MUST return <lb/>NFS4ERR_BAD_STATEID in the reply to the READ operation. <lb/>PUTFH fh1 <lb/>--&gt; {fh1, (0, 0)} <lb/>READ (1, 0), 0, 1024 <lb/>{fh1, (0, 0)} -&gt; NFS4ERR_BAD_STATEID <lb/>Figure 6 <lb/>16.2.4. ERRORS <lb/>COMPOUND will of course return every error that each operation on the <lb/>fore channel can return (see Table 6). However, if COMPOUND returns <lb/>zero operations, obviously the error returned by COMPOUND has nothing <lb/>to do with an error returned by an operation. The list of errors <lb/>COMPOUND will return if it processes zero operations include: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 425] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>COMPOUND Error Returns <lb/>+------------------------------+------------------------------------+ <lb/>| Error <lb/>| Notes <lb/>| <lb/>+------------------------------+------------------------------------+ <lb/>| NFS4ERR_BADCHAR <lb/>| The tag argument has a character <lb/>| <lb/>| <lb/>| the replier does not support. <lb/>| <lb/>| NFS4ERR_BADXDR <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL <lb/>| The tag argument is not in UTF-8 <lb/>| <lb/>| <lb/>| encoding. <lb/>| <lb/>| NFS4ERR_MINOR_VERS_MISMATCH | <lb/>| <lb/>| NFS4ERR_SERVERFAULT <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE | <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG <lb/>| <lb/>| <lb/>+------------------------------+------------------------------------+ <lb/>Table 9 <lb/>17. Operations: REQUIRED, RECOMMENDED, or OPTIONAL <lb/>The following tables summarize the operations of the NFSv4.1 protocol <lb/>and the corresponding designation of REQUIRED, RECOMMENDED, and <lb/>OPTIONAL to implement or MUST NOT implement. The designation of MUST <lb/>NOT implement is reserved for those operations that were defined in <lb/>NFSv4.0 and MUST NOT be implemented in NFSv4.1. <lb/>For the most part, the REQUIRED, RECOMMENDED, or OPTIONAL designation <lb/>for operations sent by the client is for the server implementation. <lb/>The client is generally required to implement the operations needed <lb/>for the operating environment for which it serves. For example, a <lb/>read-only NFSv4.1 client would have no need to implement the WRITE <lb/>operation and is not required to do so. <lb/>The REQUIRED or OPTIONAL designation for callback operations sent by <lb/>the server is for both the client and server. Generally, the client <lb/>has the option of creating the backchannel and sending the operations <lb/>on the fore channel that will be a catalyst for the server sending <lb/>callback operations. A partial exception is CB_RECALL_SLOT; the only <lb/>way the client can avoid supporting this operation is by not creating <lb/>a backchannel. <lb/>Since this is a summary of the operations and their designation, <lb/>there are subtleties that are not presented here. Therefore, if <lb/>there is a question of the requirements of implementation, the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 426] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>operation descriptions themselves must be consulted along with other <lb/>relevant explanatory text within this specification. <lb/>The abbreviations used in the second and third columns of the table <lb/>are defined as follows. <lb/>REQ REQUIRED to implement <lb/>REC RECOMMEND to implement <lb/>OPT OPTIONAL to implement <lb/>MNI MUST NOT implement <lb/>For the NFSv4.1 features that are OPTIONAL, the operations that <lb/>support those features are OPTIONAL, and the server would return <lb/>NFS4ERR_NOTSUPP in response to the client&apos;s use of those operations. <lb/>If an OPTIONAL feature is supported, it is possible that a set of <lb/>operations related to the feature become REQUIRED to implement. The <lb/>third column of the table designates the feature(s) and if the <lb/>operation is REQUIRED or OPTIONAL in the presence of support for the <lb/>feature. <lb/>The OPTIONAL features identified and their abbreviations are as <lb/>follows: <lb/>pNFS Parallel NFS <lb/>FDELG File Delegations <lb/>DDELG Directory Delegations <lb/>Operations <lb/>+----------------------+------------+--------------+----------------+ <lb/>| Operation <lb/>| REQ, REC, | Feature <lb/>| Definition <lb/>| <lb/>| <lb/>| OPT, or <lb/>| (REQ, REC, <lb/>| <lb/>| <lb/>| <lb/>| MNI <lb/>| or OPT) <lb/>| <lb/>| <lb/>+----------------------+------------+--------------+----------------+ <lb/>| ACCESS <lb/>| REQ <lb/>| <lb/>| Section 18.1 <lb/>| <lb/>| BACKCHANNEL_CTL <lb/>| REQ <lb/>| <lb/>| Section 18.33 | <lb/>| BIND_CONN_TO_SESSION | REQ <lb/>| <lb/>| Section 18.34 | <lb/>| CLOSE <lb/>| REQ <lb/>| <lb/>| Section 18.2 <lb/>| <lb/>| COMMIT <lb/>| REQ <lb/>| <lb/>| Section 18.3 <lb/>| <lb/>| CREATE <lb/>| REQ <lb/>| <lb/>| Section 18.4 <lb/>| <lb/>| CREATE_SESSION <lb/>| REQ <lb/>| <lb/>| Section 18.36 | <lb/>| DELEGPURGE <lb/>| OPT <lb/>| FDELG (REQ) | Section 18.5 <lb/>| <lb/>| DELEGRETURN <lb/>| OPT <lb/>| FDELG, <lb/>| Section 18.6 <lb/>| <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 427] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| <lb/>| <lb/>| DDELG, pNFS | <lb/>| <lb/>| <lb/>| <lb/>| (REQ) <lb/>| <lb/>| <lb/>| DESTROY_CLIENTID <lb/>| REQ <lb/>| <lb/>| Section 18.50 | <lb/>| DESTROY_SESSION <lb/>| REQ <lb/>| <lb/>| Section 18.37 | <lb/>| EXCHANGE_ID <lb/>| REQ <lb/>| <lb/>| Section 18.35 | <lb/>| FREE_STATEID <lb/>| REQ <lb/>| <lb/>| Section 18.38 | <lb/>| GETATTR <lb/>| REQ <lb/>| <lb/>| Section 18.7 <lb/>| <lb/>| GETDEVICEINFO <lb/>| OPT <lb/>| pNFS (REQ) <lb/>| Section 18.40 | <lb/>| GETDEVICELIST <lb/>| OPT <lb/>| pNFS (OPT) <lb/>| Section 18.41 | <lb/>| GETFH <lb/>| REQ <lb/>| <lb/>| Section 18.8 <lb/>| <lb/>| GET_DIR_DELEGATION <lb/>| OPT <lb/>| DDELG (REQ) | Section 18.39 | <lb/>| LAYOUTCOMMIT <lb/>| OPT <lb/>| pNFS (REQ) <lb/>| Section 18.42 | <lb/>| LAYOUTGET <lb/>| OPT <lb/>| pNFS (REQ) <lb/>| Section 18.43 | <lb/>| LAYOUTRETURN <lb/>| OPT <lb/>| pNFS (REQ) <lb/>| Section 18.44 | <lb/>| LINK <lb/>| OPT <lb/>| <lb/>| Section 18.9 <lb/>| <lb/>| LOCK <lb/>| REQ <lb/>| <lb/>| Section 18.10 | <lb/>| LOCKT <lb/>| REQ <lb/>| <lb/>| Section 18.11 | <lb/>| LOCKU <lb/>| REQ <lb/>| <lb/>| Section 18.12 | <lb/>| LOOKUP <lb/>| REQ <lb/>| <lb/>| Section 18.13 | <lb/>| LOOKUPP <lb/>| REQ <lb/>| <lb/>| Section 18.14 | <lb/>| NVERIFY <lb/>| REQ <lb/>| <lb/>| Section 18.15 | <lb/>| OPEN <lb/>| REQ <lb/>| <lb/>| Section 18.16 | <lb/>| OPENATTR <lb/>| OPT <lb/>| <lb/>| Section 18.17 | <lb/>| OPEN_CONFIRM <lb/>| MNI <lb/>| <lb/>| N/A <lb/>| <lb/>| OPEN_DOWNGRADE <lb/>| REQ <lb/>| <lb/>| Section 18.18 | <lb/>| PUTFH <lb/>| REQ <lb/>| <lb/>| Section 18.19 | <lb/>| PUTPUBFH <lb/>| REQ <lb/>| <lb/>| Section 18.20 | <lb/>| PUTROOTFH <lb/>| REQ <lb/>| <lb/>| Section 18.21 | <lb/>| READ <lb/>| REQ <lb/>| <lb/>| Section 18.22 | <lb/>| READDIR <lb/>| REQ <lb/>| <lb/>| Section 18.23 | <lb/>| READLINK <lb/>| OPT <lb/>| <lb/>| Section 18.24 | <lb/>| RECLAIM_COMPLETE <lb/>| REQ <lb/>| <lb/>| Section 18.51 | <lb/>| RELEASE_LOCKOWNER <lb/>| MNI <lb/>| <lb/>| N/A <lb/>| <lb/>| REMOVE <lb/>| REQ <lb/>| <lb/>| Section 18.25 | <lb/>| RENAME <lb/>| REQ <lb/>| <lb/>| Section 18.26 | <lb/>| RENEW <lb/>| MNI <lb/>| <lb/>| N/A <lb/>| <lb/>| RESTOREFH <lb/>| REQ <lb/>| <lb/>| Section 18.27 | <lb/>| SAVEFH <lb/>| REQ <lb/>| <lb/>| Section 18.28 | <lb/>| SECINFO <lb/>| REQ <lb/>| <lb/>| Section 18.29 | <lb/>| SECINFO_NO_NAME <lb/>| REC <lb/>| pNFS file <lb/>| Section 18.45, | <lb/>| <lb/>| <lb/>| layout (REQ) | Section 13.12 | <lb/>| SEQUENCE <lb/>| REQ <lb/>| <lb/>| Section 18.46 | <lb/>| SETATTR <lb/>| REQ <lb/>| <lb/>| Section 18.30 | <lb/>| SETCLIENTID <lb/>| MNI <lb/>| <lb/>| N/A <lb/>| <lb/>| SETCLIENTID_CONFIRM | MNI <lb/>| <lb/>| N/A <lb/>| <lb/>| SET_SSV <lb/>| REQ <lb/>| <lb/>| Section 18.47 | <lb/>| TEST_STATEID <lb/>| REQ <lb/>| <lb/>| Section 18.48 | <lb/>| VERIFY <lb/>| REQ <lb/>| <lb/>| Section 18.31 | <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 428] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>| WANT_DELEGATION <lb/>| OPT <lb/>| FDELG (OPT) | Section 18.49 | <lb/>| WRITE <lb/>| REQ <lb/>| <lb/>| Section 18.32 | <lb/>+----------------------+------------+--------------+----------------+ <lb/>Callback Operations <lb/>+-------------------------+------------+---------------+------------+ <lb/>| Operation <lb/>| REQ, REC, | Feature (REQ, | Definition | <lb/>| <lb/>| OPT, or <lb/>| REC, or OPT) | <lb/>| <lb/>| <lb/>| MNI <lb/>| <lb/>| <lb/>| <lb/>+-------------------------+------------+---------------+------------+ <lb/>| CB_GETATTR <lb/>| OPT <lb/>| FDELG (REQ) <lb/>| Section <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| 20.1 <lb/>| <lb/>| CB_LAYOUTRECALL <lb/>| OPT <lb/>| pNFS (REQ) <lb/>| Section <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| 20.3 <lb/>| <lb/>| CB_NOTIFY <lb/>| OPT <lb/>| DDELG (REQ) <lb/>| Section <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| 20.4 <lb/>| <lb/>| CB_NOTIFY_DEVICEID <lb/>| OPT <lb/>| pNFS (OPT) <lb/>| Section <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| 20.12 <lb/>| <lb/>| CB_NOTIFY_LOCK <lb/>| OPT <lb/>| <lb/>| Section <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| 20.11 <lb/>| <lb/>| CB_PUSH_DELEG <lb/>| OPT <lb/>| FDELG (OPT) <lb/>| Section <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| 20.5 <lb/>| <lb/>| CB_RECALL <lb/>| OPT <lb/>| FDELG, DDELG, | Section <lb/>| <lb/>| <lb/>| <lb/>| pNFS (REQ) <lb/>| 20.2 <lb/>| <lb/>| CB_RECALL_ANY <lb/>| OPT <lb/>| FDELG, DDELG, | Section <lb/>| <lb/>| <lb/>| <lb/>| pNFS (REQ) <lb/>| 20.6 <lb/>| <lb/>| CB_RECALL_SLOT <lb/>| REQ <lb/>| <lb/>| Section <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| 20.8 <lb/>| <lb/>| CB_RECALLABLE_OBJ_AVAIL | OPT <lb/>| DDELG, pNFS <lb/>| Section <lb/>| <lb/>| <lb/>| <lb/>| (REQ) <lb/>| 20.7 <lb/>| <lb/>| CB_SEQUENCE <lb/>| OPT <lb/>| FDELG, DDELG, | Section <lb/>| <lb/>| <lb/>| <lb/>| pNFS (REQ) <lb/>| 20.9 <lb/>| <lb/>| CB_WANTS_CANCELLED <lb/>| OPT <lb/>| FDELG, DDELG, | Section <lb/>| <lb/>| <lb/>| <lb/>| pNFS (REQ) <lb/>| 20.10 <lb/>| <lb/>+-------------------------+------------+---------------+------------+ <lb/>18. NFSv4.1 Operations <lb/>18.1. Operation 3: ACCESS -Check Access Rights <lb/>18.1.1. ARGUMENTS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 429] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>const ACCESS4_READ <lb/>= 0x00000001; <lb/>const ACCESS4_LOOKUP <lb/>= 0x00000002; <lb/>const ACCESS4_MODIFY <lb/>= 0x00000004; <lb/>const ACCESS4_EXTEND <lb/>= 0x00000008; <lb/>const ACCESS4_DELETE <lb/>= 0x00000010; <lb/>const ACCESS4_EXECUTE <lb/>= 0x00000020; <lb/>struct ACCESS4args { <lb/>/* CURRENT_FH: object */ <lb/>uint32_t <lb/>access; <lb/>}; <lb/>18.1.2. RESULTS <lb/>struct ACCESS4resok { <lb/>uint32_t <lb/>supported; <lb/>uint32_t <lb/>access; <lb/>}; <lb/>union ACCESS4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>ACCESS4resok <lb/>resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.1.3. DESCRIPTION <lb/>ACCESS determines the access rights that a user, as identified by the <lb/>credentials in the RPC request, has with respect to the file system <lb/>object specified by the current filehandle. The client encodes the <lb/>set of access rights that are to be checked in the bit mask &quot;access&quot;. <lb/>The server checks the permissions encoded in the bit mask. If a <lb/>status of NFS4_OK is returned, two bit masks are included in the <lb/>response. The first, &quot;supported&quot;, represents the access rights for <lb/>which the server can verify reliably. The second, &quot;access&quot;, <lb/>represents the access rights available to the user for the filehandle <lb/>provided. On success, the current filehandle retains its value. <lb/>Note that the reply&apos;s supported and access fields MUST NOT contain <lb/>more values than originally set in the request&apos;s access field. For <lb/>example, if the client sends an ACCESS operation with just the <lb/>ACCESS4_READ value set and the server supports this value, the server <lb/>MUST NOT set more than ACCESS4_READ in the supported field even if it <lb/>could have reliably checked other values. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 430] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The reply&apos;s access field MUST NOT contain more values than the <lb/>supported field. <lb/>The results of this operation are necessarily advisory in nature. A <lb/>return status of NFS4_OK and the appropriate bit set in the bit mask <lb/>do not imply that such access will be allowed to the file system <lb/>object in the future. This is because access rights can be revoked <lb/>by the server at any time. <lb/>The following access permissions may be requested: <lb/>ACCESS4_READ Read data from file or read a directory. <lb/>ACCESS4_LOOKUP Look up a name in a directory (no meaning for non-<lb/>directory objects). <lb/>ACCESS4_MODIFY Rewrite existing file data or modify existing <lb/>directory entries. <lb/>ACCESS4_EXTEND Write new data or add directory entries. <lb/>ACCESS4_DELETE Delete an existing directory entry. <lb/>ACCESS4_EXECUTE Execute a regular file (no meaning for a directory). <lb/>On success, the current filehandle retains its value. <lb/>ACCESS4_EXECUTE is a challenging semantic to implement because NFS <lb/>provides remote file access, not remote execution. This leads to the <lb/>following: <lb/>o Whether or not a regular file is executable ought to be the <lb/>responsibility of the NFS client and not the server. And yet the <lb/>ACCESS operation is specified to seemingly require a server to own <lb/>that responsibility. <lb/>o When a client executes a regular file, it has to read the file <lb/>from the server. Strictly speaking, the server should not allow <lb/>the client to read a file being executed unless the user has read <lb/>permissions on the file. Requiring explicit read permissions on <lb/>executable files in order to access them over NFS is not going to <lb/>be acceptable to some users and storage administrators. <lb/>Historically, NFS servers have allowed a user to READ a file if <lb/>the user has execute access to the file. <lb/>As a practical example, the UNIX specification [55] states that an <lb/>implementation claiming conformance to UNIX may indicate in the <lb/>access() programming interface&apos;s result that a privileged user has <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 431] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>execute rights, even if no execute permission bits are set on the <lb/>regular file&apos;s attributes. It is possible to claim conformance to <lb/>the UNIX specification and instead not indicate execute rights in <lb/>that situation, which is true for some operating environments. <lb/>Suppose the operating environments of the client and server are <lb/>implementing the access() semantics for privileged users differently, <lb/>and the ACCESS operation implementations of the client and server <lb/>follow their respective access() semantics. This can cause undesired <lb/>behavior: <lb/>o Suppose the client&apos;s access() interface returns X_OK if the user <lb/>is privileged and no execute permission bits are set on the <lb/>regular file&apos;s attribute, and the server&apos;s access() interface does <lb/>not return X_OK in that situation. Then the client will be unable <lb/>to execute files stored on the NFS server that could be executed <lb/>if stored on a non-NFS file system. <lb/>o Suppose the client&apos;s access() interface does not return X_OK if <lb/>the user is privileged, and no execute permission bits are set on <lb/>the regular file&apos;s attribute, and the server&apos;s access() interface <lb/>does return X_OK in that situation. Then: <lb/>* The client will be able to execute files stored on the NFS <lb/>server that could be executed if stored on a non-NFS file <lb/>system, unless the client&apos;s execution subsystem also checks for <lb/>execute permission bits. <lb/>* Even if the execution subsystem is checking for execute <lb/>permission bits, there are more potential issues. For example, <lb/>suppose the client is invoking access() to build a &quot;path search <lb/>table&quot; of all executable files in the user&apos;s &quot;search path&quot;, <lb/>where the path is a list of directories each containing <lb/>executable files. Suppose there are two files each in separate <lb/>directories of the search path, such that files have the same <lb/>component name. In the first directory the file has no execute <lb/>permission bits set, and in the second directory the file has <lb/>execute bits set. The path search table will indicate that the <lb/>first directory has the executable file, but the execute <lb/>subsystem will fail to execute it. The command shell might <lb/>fail to try the second file in the second directory. And even <lb/>if it did, this is a potential performance issue. Clearly, the <lb/>desired outcome for the client is for the path search table to <lb/>not contain the first file. <lb/>To deal with the problems described above, the &quot;smart client, stupid <lb/>server&quot; principle is used. The client owns overall responsibility <lb/>for determining execute access and relies on the server to parse the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 432] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>execution permissions within the file&apos;s mode, acl, and dacl <lb/>attributes. The rules for the client and server follow: <lb/>o If the client is sending ACCESS in order to determine if the user <lb/>can read the file, the client SHOULD set ACCESS4_READ in the <lb/>request&apos;s access field. <lb/>o If the client&apos;s operating environment only grants execution to the <lb/>user if the user has execute access according to the execute <lb/>permissions in the mode, acl, and dacl attributes, then if the <lb/>client wants to determine execute access, the client SHOULD send <lb/>an ACCESS request with ACCESS4_EXECUTE bit set in the request&apos;s <lb/>access field. <lb/>o If the client&apos;s operating environment grants execution to the user <lb/>even if the user does not have execute access according to the <lb/>execute permissions in the mode, acl, and dacl attributes, then if <lb/>the client wants to determine execute access, it SHOULD send an <lb/>ACCESS request with both the ACCESS4_EXECUTE and ACCESS4_READ bits <lb/>set in the request&apos;s access field. This way, if any read or <lb/>execute permission grants the user read or execute access (or if <lb/>the server interprets the user as privileged), as indicated by the <lb/>presence of ACCESS4_EXECUTE and/or ACCESS4_READ in the reply&apos;s <lb/>access field, the client will be able to grant the user execute <lb/>access to the file. <lb/>o If the server supports execute permission bits, or some other <lb/>method for denoting executability (e.g., the suffix of the name of <lb/>the file might indicate execute), it MUST check only execute <lb/>permissions, not read permissions, when determining whether or not <lb/>the reply will have ACCESS4_EXECUTE set in the access field. The <lb/>server MUST NOT also examine read permission bits when determining <lb/>whether or not the reply will have ACCESS4_EXECUTE set in the <lb/>access field. Even if the server&apos;s operating environment would <lb/>grant execute access to the user (e.g., the user is privileged), <lb/>the server MUST NOT reply with ACCESS4_EXECUTE set in reply&apos;s <lb/>access field unless there is at least one execute permission bit <lb/>set in the mode, acl, or dacl attributes. In the case of acl and <lb/>dacl, the &quot;one execute permission bit&quot; MUST be an ACE4_EXECUTE bit <lb/>set in an ALLOW ACE. <lb/>o If the server does not support execute permission bits or some <lb/>other method for denoting executability, it MUST NOT set <lb/>ACCESS4_EXECUTE in the reply&apos;s supported and access fields. If <lb/>the client set ACCESS4_EXECUTE in the ACCESS request&apos;s access <lb/>field, and ACCESS4_EXECUTE is not set in the reply&apos;s supported <lb/>field, then the client will have to send an ACCESS request with <lb/>the ACCESS4_READ bit set in the request&apos;s access field. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 433] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o If the server supports read permission bits, it MUST only check <lb/>for read permissions in the mode, acl, and dacl attributes when it <lb/>receives an ACCESS request with ACCESS4_READ set in the access <lb/>field. The server MUST NOT also examine execute permission bits <lb/>when determining whether the reply will have ACCESS4_READ set in <lb/>the access field or not. <lb/>Note that if the ACCESS reply has ACCESS4_READ or ACCESS_EXECUTE set, <lb/>then the user also has permissions to OPEN (Section 18.16) or READ <lb/>(Section 18.22) the file. In other words, if the client sends an <lb/>ACCESS request with the ACCESS4_READ and ACCESS_EXECUTE set in the <lb/>access field (or two separate requests, one with ACCESS4_READ set and <lb/>the other with ACCESS4_EXECUTE set), and the reply has just <lb/>ACCESS4_EXECUTE set in the access field (or just one reply has <lb/>ACCESS4_EXECUTE set), then the user has authorization to OPEN or READ <lb/>the file. <lb/>18.1.4. IMPLEMENTATION <lb/>In general, it is not sufficient for the client to attempt to deduce <lb/>access permissions by inspecting the uid, gid, and mode fields in the <lb/>file attributes or by attempting to interpret the contents of the ACL <lb/>attribute. This is because the server may perform uid or gid mapping <lb/>or enforce additional access-control restrictions. It is also <lb/>possible that the server may not be in the same ID space as the <lb/>client. In these cases (and perhaps others), the client cannot <lb/>reliably perform an access check with only current file attributes. <lb/>In the NFSv2 protocol, the only reliable way to determine whether an <lb/>operation was allowed was to try it and see if it succeeded or <lb/>failed. Using the ACCESS operation in the NFSv4.1 protocol, the <lb/>client can ask the server to indicate whether or not one or more <lb/>classes of operations are permitted. The ACCESS operation is <lb/>provided to allow clients to check before doing a series of <lb/>operations that will result in an access failure. The OPEN operation <lb/>provides a point where the server can verify access to the file <lb/>object and a method to return that information to the client. The <lb/>ACCESS operation is still useful for directory operations or for use <lb/>in the case that the UNIX interface access() is used on the client. <lb/>The information returned by the server in response to an ACCESS call <lb/>is not permanent. It was correct at the exact time that the server <lb/>performed the checks, but not necessarily afterwards. The server can <lb/>revoke access permission at any time. <lb/>The client should use the effective credentials of the user to build <lb/>the authentication information in the ACCESS request used to <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 434] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>determine access rights. It is the effective user and group <lb/>credentials that are used in subsequent READ and WRITE operations. <lb/>Many implementations do not directly support the ACCESS4_DELETE <lb/>permission. Operating systems like UNIX will ignore the <lb/>ACCESS4_DELETE bit if set on an access request on a non-directory <lb/>object. In these systems, delete permission on a file is determined <lb/>by the access permissions on the directory in which the file resides, <lb/>instead of being determined by the permissions of the file itself. <lb/>Therefore, the mask returned enumerating which access rights can be <lb/>determined will have the ACCESS4_DELETE value set to 0. This <lb/>indicates to the client that the server was unable to check that <lb/>particular access right. The ACCESS4_DELETE bit in the access mask <lb/>returned will then be ignored by the client. <lb/>18.2. Operation 4: CLOSE -Close File <lb/>18.2.1. ARGUMENTS <lb/>struct CLOSE4args { <lb/>/* CURRENT_FH: object */ <lb/>seqid4 <lb/>seqid; <lb/>stateid4 <lb/>open_stateid; <lb/>}; <lb/>18.2.2. RESULTS <lb/>union CLOSE4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>stateid4 <lb/>open_stateid; <lb/>default: <lb/>void; <lb/>}; <lb/>18.2.3. DESCRIPTION <lb/>The CLOSE operation releases share reservations for the regular or <lb/>named attribute file as specified by the current filehandle. The <lb/>share reservations and other state information released at the server <lb/>as a result of this CLOSE are only those associated with the supplied <lb/>stateid. State associated with other OPENs is not affected. <lb/>If byte-range locks are held, the client SHOULD release all locks <lb/>before sending a CLOSE. The server MAY free all outstanding locks on <lb/>CLOSE, but some servers may not support the CLOSE of a file that <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 435] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>still has byte-range locks held. The server MUST return failure if <lb/>any locks would exist after the CLOSE. <lb/>The argument seqid MAY have any value, and the server MUST ignore <lb/>seqid. <lb/>On success, the current filehandle retains its value. <lb/>The server MAY require that the combination of principal, security <lb/>flavor, and, if applicable, GSS mechanism that sent the OPEN request <lb/>also be the one to CLOSE the file. This might not be possible if <lb/>credentials for the principal are no longer available. The server <lb/>MAY allow the machine credential or SSV credential (see <lb/>Section 18.35) to send CLOSE. <lb/>18.2.4. IMPLEMENTATION <lb/>Even though CLOSE returns a stateid, this stateid is not useful to <lb/>the client and should be treated as deprecated. CLOSE &quot;shuts down&quot; <lb/>the state associated with all OPENs for the file by a single open-<lb/>owner. As noted above, CLOSE will either release all file-locking <lb/>state or return an error. Therefore, the stateid returned by CLOSE <lb/>is not useful for operations that follow. To help find any uses of <lb/>this stateid by clients, the server SHOULD return the invalid special <lb/>stateid (the &quot;other&quot; value is zero and the &quot;seqid&quot; field is <lb/>NFS4_UINT32_MAX, see Section 8.2.3). <lb/>A CLOSE operation may make delegations grantable where they were not <lb/>previously. Servers may choose to respond immediately if there are <lb/>pending delegation want requests or may respond to the situation at a <lb/>later time. <lb/>18.3. Operation 5: COMMIT -Commit Cached Data <lb/>18.3.1. ARGUMENTS <lb/>struct COMMIT4args { <lb/>/* CURRENT_FH: file */ <lb/>offset4 <lb/>offset; <lb/>count4 <lb/>count; <lb/>}; <lb/>18.3.2. RESULTS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 436] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct COMMIT4resok { <lb/>verifier4 <lb/>writeverf; <lb/>}; <lb/>union COMMIT4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>COMMIT4resok <lb/>resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.3.3. DESCRIPTION <lb/>The COMMIT operation forces or flushes uncommitted, modified data to <lb/>stable storage for the file specified by the current filehandle. The <lb/>flushed data is that which was previously written with one or more <lb/>WRITE operations that had the &quot;committed&quot; field of their results <lb/>field set to UNSTABLE4. <lb/>The offset specifies the position within the file where the flush is <lb/>to begin. An offset value of zero means to flush data starting at <lb/>the beginning of the file. The count specifies the number of bytes <lb/>of data to flush. If the count is zero, a flush from the offset to <lb/>the end of the file is done. <lb/>The server returns a write verifier upon successful completion of the <lb/>COMMIT. The write verifier is used by the client to determine if the <lb/>server has restarted between the initial WRITE operations and the <lb/>COMMIT. The client does this by comparing the write verifier <lb/>returned from the initial WRITE operations and the verifier returned <lb/>by the COMMIT operation. The server must vary the value of the write <lb/>verifier at each server event or instantiation that may lead to a <lb/>loss of uncommitted data. Most commonly this occurs when the server <lb/>is restarted; however, other events at the server may result in <lb/>uncommitted data loss as well. <lb/>On success, the current filehandle retains its value. <lb/>18.3.4. IMPLEMENTATION <lb/>The COMMIT operation is similar in operation and semantics to the <lb/>POSIX fsync() [22] system interface that synchronizes a file&apos;s state <lb/>with the disk (file data and metadata is flushed to disk or stable <lb/>storage). COMMIT performs the same operation for a client, flushing <lb/>any unsynchronized data and metadata on the server to the server&apos;s <lb/>disk or stable storage for the specified file. Like fsync(), it may <lb/>be that there is some modified data or no modified data to <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 437] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>synchronize. The data may have been synchronized by the server&apos;s <lb/>normal periodic buffer synchronization activity. COMMIT should <lb/>return NFS4_OK, unless there has been an unexpected error. <lb/>COMMIT differs from fsync() in that it is possible for the client to <lb/>flush a range of the file (most likely triggered by a buffer-<lb/>reclamation scheme on the client before the file has been completely <lb/>written). <lb/>The server implementation of COMMIT is reasonably simple. If the <lb/>server receives a full file COMMIT request, that is, starting at <lb/>offset zero and count zero, it should do the equivalent of applying <lb/>fsync() to the entire file. Otherwise, it should arrange to have the <lb/>modified data in the range specified by offset and count to be <lb/>flushed to stable storage. In both cases, any metadata associated <lb/>with the file must be flushed to stable storage before returning. It <lb/>is not an error for there to be nothing to flush on the server. This <lb/>means that the data and metadata that needed to be flushed have <lb/>already been flushed or lost during the last server failure. <lb/>The client implementation of COMMIT is a little more complex. There <lb/>are two reasons for wanting to commit a client buffer to stable <lb/>storage. The first is that the client wants to reuse a buffer. In <lb/>this case, the offset and count of the buffer are sent to the server <lb/>in the COMMIT request. The server then flushes any modified data <lb/>based on the offset and count, and flushes any modified metadata <lb/>associated with the file. It then returns the status of the flush <lb/>and the write verifier. The second reason for the client to generate <lb/>a COMMIT is for a full file flush, such as may be done at close. In <lb/>this case, the client would gather all of the buffers for this file <lb/>that contain uncommitted data, do the COMMIT operation with an offset <lb/>of zero and count of zero, and then free all of those buffers. Any <lb/>other dirty buffers would be sent to the server in the normal <lb/>fashion. <lb/>After a buffer is written (via the WRITE operation) by the client <lb/>with the &quot;committed&quot; field in the result of WRITE set to UNSTABLE4, <lb/>the buffer must be considered as modified by the client until the <lb/>buffer has either been flushed via a COMMIT operation or written via <lb/>a WRITE operation with the &quot;committed&quot; field in the result set to <lb/>FILE_SYNC4 or DATA_SYNC4. This is done to prevent the buffer from <lb/>being freed and reused before the data can be flushed to stable <lb/>storage on the server. <lb/>When a response is returned from either a WRITE or a COMMIT operation <lb/>and it contains a write verifier that differs from that previously <lb/>returned by the server, the client will need to retransmit all of the <lb/>buffers containing uncommitted data to the server. How this is to be <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 438] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>done is up to the implementor. If there is only one buffer of <lb/>interest, then it should be sent in a WRITE request with the <lb/>FILE_SYNC4 stable parameter. If there is more than one buffer, it <lb/>might be worthwhile retransmitting all of the buffers in WRITE <lb/>operations with the stable parameter set to UNSTABLE4 and then <lb/>retransmitting the COMMIT operation to flush all of the data on the <lb/>server to stable storage. However, if the server repeatably returns <lb/>from COMMIT a verifier that differs from that returned by WRITE, the <lb/>only way to ensure progress is to retransmit all of the buffers with <lb/>WRITE requests with the FILE_SYNC4 stable parameter. <lb/>The above description applies to page-cache-based systems as well as <lb/>buffer-cache-based systems. In the former systems, the virtual <lb/>memory system will need to be modified instead of the buffer cache. <lb/>18.4. Operation 6: CREATE -Create a Non-Regular File Object <lb/>18.4.1. ARGUMENTS <lb/>union createtype4 switch (nfs_ftype4 type) { <lb/>case NF4LNK: <lb/>linktext4 linkdata; <lb/>case NF4BLK: <lb/>case NF4CHR: <lb/>specdata4 devdata; <lb/>case NF4SOCK: <lb/>case NF4FIFO: <lb/>case NF4DIR: <lb/>void; <lb/>default: <lb/>void; /* server should return NFS4ERR_BADTYPE */ <lb/>}; <lb/>struct CREATE4args { <lb/>/* CURRENT_FH: directory for creation */ <lb/>createtype4 <lb/>objtype; <lb/>component4 <lb/>objname; <lb/>fattr4 <lb/>createattrs; <lb/>}; <lb/>18.4.2. RESULTS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 439] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct CREATE4resok { <lb/>change_info4 <lb/>cinfo; <lb/>bitmap4 <lb/>attrset; <lb/>/* attributes set */ <lb/>}; <lb/>union CREATE4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>/* new CURRENTFH: created object */ <lb/>CREATE4resok resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.4.3. DESCRIPTION <lb/>The CREATE operation creates a file object other than an ordinary <lb/>file in a directory with a given name. The OPEN operation MUST be <lb/>used to create a regular file or a named attribute. <lb/>The current filehandle must be a directory: an object of type NF4DIR. <lb/>If the current filehandle is an attribute directory (type <lb/>NF4ATTRDIR), the error NFS4ERR_WRONG_TYPE is returned. If the <lb/>current file handle designates any other type of object, the error <lb/>NFS4ERR_NOTDIR results. <lb/>The objname specifies the name for the new object. The objtype <lb/>determines the type of object to be created: directory, symlink, etc. <lb/>If the object type specified is that of an ordinary file, a named <lb/>attribute, or a named attribute directory, the error NFS4ERR_BADTYPE <lb/>results. <lb/>If an object of the same name already exists in the directory, the <lb/>server will return the error NFS4ERR_EXIST. <lb/>For the directory where the new file object was created, the server <lb/>returns change_info4 information in cinfo. With the atomic field of <lb/>the change_info4 data type, the server will indicate if the before <lb/>and after change attributes were obtained atomically with respect to <lb/>the file object creation. <lb/>If the objname has a length of zero, or if objname does not obey the <lb/>UTF-8 definition, the error NFS4ERR_INVAL will be returned. <lb/>The current filehandle is replaced by that of the new object. <lb/>The createattrs specifies the initial set of attributes for the <lb/>object. The set of attributes may include any writable attribute <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 440] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>valid for the object type. When the operation is successful, the <lb/>server will return to the client an attribute mask signifying which <lb/>attributes were successfully set for the object. <lb/>If createattrs includes neither the owner attribute nor an ACL with <lb/>an ACE for the owner, and if the server&apos;s file system both supports <lb/>and requires an owner attribute (or an owner ACE), then the server <lb/>MUST derive the owner (or the owner ACE). This would typically be <lb/>from the principal indicated in the RPC credentials of the call, but <lb/>the server&apos;s operating environment or file system semantics may <lb/>dictate other methods of derivation. Similarly, if createattrs <lb/>includes neither the group attribute nor a group ACE, and if the <lb/>server&apos;s file system both supports and requires the notion of a group <lb/>attribute (or group ACE), the server MUST derive the group attribute <lb/>(or the corresponding owner ACE) for the file. This could be from <lb/>the RPC call&apos;s credentials, such as the group principal if the <lb/>credentials include it (such as with AUTH_SYS), from the group <lb/>identifier associated with the principal in the credentials (e.g., <lb/>POSIX systems have a user database [23] that has a group identifier <lb/>for every user identifier), inherited from the directory in which the <lb/>object is created, or whatever else the server&apos;s operating <lb/>environment or file system semantics dictate. This applies to the <lb/>OPEN operation too. <lb/>Conversely, it is possible that the client will specify in <lb/>createattrs an owner attribute, group attribute, or ACL that the <lb/>principal indicated the RPC call&apos;s credentials does not have <lb/>permissions to create files for. The error to be returned in this <lb/>instance is NFS4ERR_PERM. This applies to the OPEN operation too. <lb/>If the current filehandle designates a directory for which another <lb/>client holds a directory delegation, then, unless the delegation is <lb/>such that the situation can be resolved by sending a notification, <lb/>the delegation MUST be recalled, and the CREATE operation MUST NOT <lb/>proceed until the delegation is returned or revoked. Except where <lb/>this happens very quickly, one or more NFS4ERR_DELAY errors will be <lb/>returned to requests made while delegation remains outstanding. <lb/>When the current filehandle designates a directory for which one or <lb/>more directory delegations exist, then, when those delegations <lb/>request such notifications, NOTIFY4_ADD_ENTRY will be generated as a <lb/>result of this operation. <lb/>If the capability FSCHARSET_CAP4_ALLOWS_ONLY_UTF8 is set <lb/>(Section 14.4), and a symbolic link is being created, then the <lb/>content of the symbolic link MUST be in UTF-8 encoding. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 441] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.4.4. IMPLEMENTATION <lb/>If the client desires to set attribute values after the create, a <lb/>SETATTR operation can be added to the COMPOUND request so that the <lb/>appropriate attributes will be set. <lb/>18.5. Operation 7: DELEGPURGE -Purge Delegations Awaiting Recovery <lb/>18.5.1. ARGUMENTS <lb/>struct DELEGPURGE4args { <lb/>clientid4 <lb/>clientid; <lb/>}; <lb/>18.5.2. RESULTS <lb/>struct DELEGPURGE4res { <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/>18.5.3. DESCRIPTION <lb/>This operation purges all of the delegations awaiting recovery for a <lb/>given client. This is useful for clients that do not commit <lb/>delegation information to stable storage to indicate that conflicting <lb/>requests need not be delayed by the server awaiting recovery of <lb/>delegation information. <lb/>The client is NOT specified by the clientid field of the request. <lb/>The client SHOULD set the client field to zero, and the server MUST <lb/>ignore the clientid field. Instead, the server MUST derive the <lb/>client ID from the value of the session ID in the arguments of the <lb/>SEQUENCE operation that precedes DELEGPURGE in the COMPOUND request. <lb/>The DELEGPURGE operation should be used by clients that record <lb/>delegation information on stable storage on the client. In this <lb/>case, after the client recovers all delegations it knows of, it <lb/>should immediately send a DELEGPURGE operation. Doing so will notify <lb/>the server that no additional delegations for the client will be <lb/>recovered allowing it to free resources, and avoid delaying other <lb/>clients which make requests that conflict with the unrecovered <lb/>delegations. The set of delegations known to the server and the <lb/>client might be different. The reason for this is that after sending <lb/>a request that resulted in a delegation, the client might experience <lb/>a failure before it both received the delegation and committed the <lb/>delegation to the client&apos;s stable storage. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 442] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The server MAY support DELEGPURGE, but if it does not, it MUST NOT <lb/>support CLAIM_DELEGATE_PREV and MUST NOT support CLAIM_DELEG_PREV_FH. <lb/>18.6. Operation 8: DELEGRETURN -Return Delegation <lb/>18.6.1. ARGUMENTS <lb/>struct DELEGRETURN4args { <lb/>/* CURRENT_FH: delegated object */ <lb/>stateid4 <lb/>deleg_stateid; <lb/>}; <lb/>18.6.2. RESULTS <lb/>struct DELEGRETURN4res { <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/>18.6.3. DESCRIPTION <lb/>The DELEGRETURN operation returns the delegation represented by the <lb/>current filehandle and stateid. <lb/>Delegations may be returned voluntarily (i.e., before the server has <lb/>recalled them) or when recalled. In either case, the client must <lb/>properly propagate state changed under the context of the delegation <lb/>to the server before returning the delegation. <lb/>The server MAY require that the principal, security flavor, and if <lb/>applicable, the GSS mechanism, combination that acquired the <lb/>delegation also be the one to send DELEGRETURN on the file. This <lb/>might not be possible if credentials for the principal are no longer <lb/>available. The server MAY allow the machine credential or SSV <lb/>credential (see Section 18.35) to send DELEGRETURN. <lb/>18.7. Operation 9: GETATTR -Get Attributes <lb/>18.7.1. ARGUMENTS <lb/>struct GETATTR4args { <lb/>/* CURRENT_FH: object */ <lb/>bitmap4 <lb/>attr_request; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 443] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.7.2. RESULTS <lb/>struct GETATTR4resok { <lb/>fattr4 <lb/>obj_attributes; <lb/>}; <lb/>union GETATTR4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>GETATTR4resok resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.7.3. DESCRIPTION <lb/>The GETATTR operation will obtain attributes for the file system <lb/>object specified by the current filehandle. The client sets a bit in <lb/>the bitmap argument for each attribute value that it would like the <lb/>server to return. The server returns an attribute bitmap that <lb/>indicates the attribute values that it was able to return, which will <lb/>include all attributes requested by the client that are attributes <lb/>supported by the server for the target file system. This bitmap is <lb/>followed by the attribute values ordered lowest attribute number <lb/>first. <lb/>The server MUST return a value for each attribute that the client <lb/>requests if the attribute is supported by the server for the target <lb/>file system. If the server does not support a particular attribute <lb/>on the target file system, then it MUST NOT return the attribute <lb/>value and MUST NOT set the attribute bit in the result bitmap. The <lb/>server MUST return an error if it supports an attribute on the target <lb/>but cannot obtain its value. In that case, no attribute values will <lb/>be returned. <lb/>File systems that are absent should be treated as having support for <lb/>a very small set of attributes as described in Section 11.4.1, even <lb/>if previously, when the file system was present, more attributes were <lb/>supported. <lb/>All servers MUST support the REQUIRED attributes as specified in <lb/>Section 5.6, for all file systems, with the exception of absent file <lb/>systems. <lb/>On success, the current filehandle retains its value. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 444] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.7.4. IMPLEMENTATION <lb/>Suppose there is an OPEN_DELEGATE_WRITE delegation held by another <lb/>client for the file in question and size and/or change are among the <lb/>set of attributes being interrogated. The server has two choices. <lb/>First, the server can obtain the actual current value of these <lb/>attributes from the client holding the delegation by using the <lb/>CB_GETATTR callback. Second, the server, particularly when the <lb/>delegated client is unresponsive, can recall the delegation in <lb/>question. The GETATTR MUST NOT proceed until one of the following <lb/>occurs: <lb/>o The requested attribute values are returned in the response to <lb/>CB_GETATTR. <lb/>o The OPEN_DELEGATE_WRITE delegation is returned. <lb/>o The OPEN_DELEGATE_WRITE delegation is revoked. <lb/>Unless one of the above happens very quickly, one or more <lb/>NFS4ERR_DELAY errors will be returned while a delegation is <lb/>outstanding. <lb/>18.8. Operation 10: GETFH -Get Current Filehandle <lb/>18.8.1. ARGUMENTS <lb/>/* CURRENT_FH: */ <lb/>void; <lb/>18.8.2. RESULTS <lb/>struct GETFH4resok { <lb/>nfs_fh4 <lb/>object; <lb/>}; <lb/>union GETFH4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>GETFH4resok <lb/>resok4; <lb/>default: <lb/>void; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 445] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.8.3. DESCRIPTION <lb/>This operation returns the current filehandle value. <lb/>On success, the current filehandle retains its value. <lb/>As described in Section 2.10.6.4, GETFH is REQUIRED or RECOMMENDED to <lb/>immediately follow certain operations, and servers are free to reject <lb/>such operations if the client fails to insert GETFH in the request as <lb/>REQUIRED or RECOMMENDED. Section 18.16.4.1 provides additional <lb/>justification for why GETFH MUST follow OPEN. <lb/>18.8.4. IMPLEMENTATION <lb/>Operations that change the current filehandle like LOOKUP or CREATE <lb/>do not automatically return the new filehandle as a result. For <lb/>instance, if a client needs to look up a directory entry and obtain <lb/>its filehandle, then the following request is needed. <lb/>PUTFH (directory filehandle) <lb/>LOOKUP (entry name) <lb/>GETFH <lb/>18.9. Operation 11: LINK -Create Link to a File <lb/>18.9.1. ARGUMENTS <lb/>struct LINK4args { <lb/>/* SAVED_FH: source object */ <lb/>/* CURRENT_FH: target directory */ <lb/>component4 <lb/>newname; <lb/>}; <lb/>18.9.2. RESULTS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 446] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct LINK4resok { <lb/>change_info4 <lb/>cinfo; <lb/>}; <lb/>union LINK4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>LINK4resok resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.9.3. DESCRIPTION <lb/>The LINK operation creates an additional newname for the file <lb/>represented by the saved filehandle, as set by the SAVEFH operation, <lb/>in the directory represented by the current filehandle. The existing <lb/>file and the target directory must reside within the same file system <lb/>on the server. On success, the current filehandle will continue to <lb/>be the target directory. If an object exists in the target directory <lb/>with the same name as newname, the server must return NFS4ERR_EXIST. <lb/>For the target directory, the server returns change_info4 information <lb/>in cinfo. With the atomic field of the change_info4 data type, the <lb/>server will indicate if the before and after change attributes were <lb/>obtained atomically with respect to the link creation. <lb/>If the newname has a length of zero, or if newname does not obey the <lb/>UTF-8 definition, the error NFS4ERR_INVAL will be returned. <lb/>18.9.4. IMPLEMENTATION <lb/>The server MAY impose restrictions on the LINK operation such that <lb/>LINK may not be done when the file is open or when that open is done <lb/>by particular protocols, or with particular options or access modes. <lb/>When LINK is rejected because of such restrictions, the error <lb/>NFS4ERR_FILE_OPEN is returned. <lb/>If a server does implement such restrictions and those restrictions <lb/>include cases of NFSv4 opens preventing successful execution of a <lb/>link, the server needs to recall any delegations that could hide the <lb/>existence of opens relevant to that decision. The reason is that <lb/>when a client holds a delegation, the server might not have an <lb/>accurate account of the opens for that client, since the client may <lb/>execute OPENs and CLOSEs locally. The LINK operation must be delayed <lb/>only until a definitive result can be obtained. For example, suppose <lb/>there are multiple delegations and one of them establishes an open <lb/>whose presence would prevent the link. Given the server&apos;s semantics, <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 447] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>NFS4ERR_FILE_OPEN may be returned to the caller as soon as that <lb/>delegation is returned without waiting for other delegations to be <lb/>returned. Similarly, if such opens are not associated with <lb/>delegations, NFS4ERR_FILE_OPEN can be returned immediately with no <lb/>delegation recall being done. <lb/>If the current filehandle designates a directory for which another <lb/>client holds a directory delegation, then, unless the delegation is <lb/>such that the situation can be resolved by sending a notification, <lb/>the delegation MUST be recalled, and the operation cannot be <lb/>performed successfully until the delegation is returned or revoked. <lb/>Except where this happens very quickly, one or more NFS4ERR_DELAY <lb/>errors will be returned to requests made while delegation remains <lb/>outstanding. <lb/>When the current filehandle designates a directory for which one or <lb/>more directory delegations exist, then, when those delegations <lb/>request such notifications, instead of a recall, NOTIFY4_ADD_ENTRY <lb/>will be generated as a result of the LINK operation. <lb/>If the current file system supports the numlinks attribute, and other <lb/>clients have delegations to the file being linked, then those <lb/>delegations MUST be recalled and the LINK operation MUST NOT proceed <lb/>until all delegations are returned or revoked. Except where this <lb/>happens very quickly, one or more NFS4ERR_DELAY errors will be <lb/>returned to requests made while delegation remains outstanding. <lb/>Changes to any property of the &quot;hard&quot; linked files are reflected in <lb/>all of the linked files. When a link is made to a file, the <lb/>attributes for the file should have a value for numlinks that is one <lb/>greater than the value before the LINK operation. <lb/>The statement &quot;file and the target directory must reside within the <lb/>same file system on the server&quot; means that the fsid fields in the <lb/>attributes for the objects are the same. If they reside on different <lb/>file systems, the error NFS4ERR_XDEV is returned. This error may be <lb/>returned by some servers when there is an internal partitioning of a <lb/>file system that the LINK operation would violate. <lb/>On some servers, &quot;.&quot; and &quot;..&quot; are illegal values for newname and the <lb/>error NFS4ERR_BADNAME will be returned if they are specified. <lb/>When the current filehandle designates a named attribute directory <lb/>and the object to be linked (the saved filehandle) is not a named <lb/>attribute for the same object, the error NFS4ERR_XDEV MUST be <lb/>returned. When the saved filehandle designates a named attribute and <lb/>the current filehandle is not the appropriate named attribute <lb/>directory, the error NFS4ERR_XDEV MUST also be returned. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 448] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>When the current filehandle designates a named attribute directory <lb/>and the object to be linked (the saved filehandle) is a named <lb/>attribute within that directory, the server may return the error <lb/>NFS4ERR_NOTSUPP. <lb/>In the case that newname is already linked to the file represented by <lb/>the saved filehandle, the server will return NFS4ERR_EXIST. <lb/>Note that symbolic links are created with the CREATE operation. <lb/>18.10. Operation 12: LOCK -Create Lock <lb/>18.10.1. ARGUMENTS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 449] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>/* <lb/>* For LOCK, transition from open_stateid and lock_owner <lb/>* to a lock stateid. <lb/>*/ <lb/>struct open_to_lock_owner4 { <lb/>seqid4 <lb/>open_seqid; <lb/>stateid4 <lb/>open_stateid; <lb/>seqid4 <lb/>lock_seqid; <lb/>lock_owner4 <lb/>lock_owner; <lb/>}; <lb/>/* <lb/>* For LOCK, existing lock stateid continues to request new <lb/>* file lock for the same lock_owner and open_stateid. <lb/>*/ <lb/>struct exist_lock_owner4 { <lb/>stateid4 <lb/>lock_stateid; <lb/>seqid4 <lb/>lock_seqid; <lb/>}; <lb/>union locker4 switch (bool new_lock_owner) { <lb/>case TRUE: <lb/>open_to_lock_owner4 <lb/>open_owner; <lb/>case FALSE: <lb/>exist_lock_owner4 <lb/>lock_owner; <lb/>}; <lb/>/* <lb/>* LOCK/LOCKT/LOCKU: Record lock management <lb/>*/ <lb/>struct LOCK4args { <lb/>/* CURRENT_FH: file */ <lb/>nfs_lock_type4 locktype; <lb/>bool <lb/>reclaim; <lb/>offset4 <lb/>offset; <lb/>length4 <lb/>length; <lb/>locker4 <lb/>locker; <lb/>}; <lb/>18.10.2. RESULTS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 450] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct LOCK4denied { <lb/>offset4 <lb/>offset; <lb/>length4 <lb/>length; <lb/>nfs_lock_type4 locktype; <lb/>lock_owner4 <lb/>owner; <lb/>}; <lb/>struct LOCK4resok { <lb/>stateid4 <lb/>lock_stateid; <lb/>}; <lb/>union LOCK4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>LOCK4resok <lb/>resok4; <lb/>case NFS4ERR_DENIED: <lb/>LOCK4denied <lb/>denied; <lb/>default: <lb/>void; <lb/>}; <lb/>18.10.3. DESCRIPTION <lb/>The LOCK operation requests a byte-range lock for the byte-range <lb/>specified by the offset and length parameters, and lock type <lb/>specified in the locktype parameter. If this is a reclaim request, <lb/>the reclaim parameter will be TRUE. <lb/>Bytes in a file may be locked even if those bytes are not currently <lb/>allocated to the file. To lock the file from a specific offset <lb/>through the end-of-file (no matter how long the file actually is) use <lb/>a length field equal to NFS4_UINT64_MAX. The server MUST return <lb/>NFS4ERR_INVAL under the following combinations of length and offset: <lb/>o Length is equal to zero. <lb/>o Length is not equal to NFS4_UINT64_MAX, and the sum of length and <lb/>offset exceeds NFS4_UINT64_MAX. <lb/>32-bit servers are servers that support locking for byte offsets that <lb/>fit within 32 bits (i.e., less than or equal to NFS4_UINT32_MAX). If <lb/>the client specifies a range that overlaps one or more bytes beyond <lb/>offset NFS4_UINT32_MAX but does not end at offset NFS4_UINT64_MAX, <lb/>then such a 32-bit server MUST return the error NFS4ERR_BAD_RANGE. <lb/>If the server returns NFS4ERR_DENIED, the owner, offset, and length <lb/>of a conflicting lock are returned. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 451] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The locker argument specifies the lock-owner that is associated with <lb/>the LOCK operation. The locker4 structure is a switched union that <lb/>indicates whether the client has already created byte-range locking <lb/>state associated with the current open file and lock-owner. In the <lb/>case in which it has, the argument is just a stateid representing the <lb/>set of locks associated with that open file and lock-owner, together <lb/>with a lock_seqid value that MAY be any value and MUST be ignored by <lb/>the server. In the case where no byte-range locking state has been <lb/>established, or the client does not have the stateid available, the <lb/>argument contains the stateid of the open file with which this lock <lb/>is to be associated, together with the lock-owner with which the lock <lb/>is to be associated. The open_to_lock_owner case covers the very <lb/>first lock done by a lock-owner for a given open file and offers a <lb/>method to use the established state of the open_stateid to transition <lb/>to the use of a lock stateid. <lb/>The following fields of the locker parameter MAY be set to any value <lb/>by the client and MUST be ignored by the server: <lb/>o The clientid field of the lock_owner field of the open_owner field <lb/>(locker.open_owner.lock_owner.clientid). The reason the server <lb/>MUST ignore the clientid field is that the server MUST derive the <lb/>client ID from the session ID from the SEQUENCE operation of the <lb/>COMPOUND request. <lb/>o The open_seqid and lock_seqid fields of the open_owner field <lb/>(locker.open_owner.open_seqid and locker.open_owner.lock_seqid). <lb/>o The lock_seqid field of the lock_owner field <lb/>(locker.lock_owner.lock_seqid). <lb/>Note that the client ID appearing in a LOCK4denied structure is the <lb/>actual client associated with the conflicting lock, whether this is <lb/>the client ID associated with the current session or a different one. <lb/>Thus, if the server returns NFS4ERR_DENIED, it MUST set the clientid <lb/>field of the owner field of the denied field. <lb/>If the current filehandle is not an ordinary file, an error will be <lb/>returned to the client. In the case that the current filehandle <lb/>represents an object of type NF4DIR, NFS4ERR_ISDIR is returned. If <lb/>the current filehandle designates a symbolic link, NFS4ERR_SYMLINK is <lb/>returned. In all other cases, NFS4ERR_WRONG_TYPE is returned. <lb/>On success, the current filehandle retains its value. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 452] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.10.4. IMPLEMENTATION <lb/>If the server is unable to determine the exact offset and length of <lb/>the conflicting byte-range lock, the same offset and length that were <lb/>provided in the arguments should be returned in the denied results. <lb/>LOCK operations are subject to permission checks and to checks <lb/>against the access type of the associated file. However, the <lb/>specific right and modes required for various types of locks reflect <lb/>the semantics of the server-exported file system, and are not <lb/>specified by the protocol. For example, Windows 2000 allows a write <lb/>lock of a file open for read access, while a POSIX-compliant system <lb/>does not. <lb/>When the client sends a LOCK operation that corresponds to a range <lb/>that the lock-owner has locked already (with the same or different <lb/>lock type), or to a sub-range of such a range, or to a byte-range <lb/>that includes multiple locks already granted to that lock-owner, in <lb/>whole or in part, and the server does not support such locking <lb/>operations (i.e., does not support POSIX locking semantics), the <lb/>server will return the error NFS4ERR_LOCK_RANGE. In that case, the <lb/>client may return an error, or it may emulate the required <lb/>operations, using only LOCK for ranges that do not include any bytes <lb/>already locked by that lock-owner and LOCKU of locks held by that <lb/>lock-owner (specifying an exactly matching range and type). <lb/>Similarly, when the client sends a LOCK operation that amounts to <lb/>upgrading (changing from a READ_LT lock to a WRITE_LT lock) or <lb/>downgrading (changing from WRITE_LT lock to a READ_LT lock) an <lb/>existing byte-range lock, and the server does not support such a <lb/>lock, the server will return NFS4ERR_LOCK_NOTSUPP. Such operations <lb/>may not perfectly reflect the required semantics in the face of <lb/>conflicting LOCK operations from other clients. <lb/>When a client holds an OPEN_DELEGATE_WRITE delegation, the client <lb/>holding that delegation is assured that there are no opens by other <lb/>clients. Thus, there can be no conflicting LOCK operations from such <lb/>clients. Therefore, the client may be handling locking requests <lb/>locally, without doing LOCK operations on the server. If it does <lb/>that, it must be prepared to update the lock status on the server, by <lb/>sending appropriate LOCK and LOCKU operations before returning the <lb/>delegation. <lb/>When one or more clients hold OPEN_DELEGATE_READ delegations, any <lb/>LOCK operation where the server is implementing mandatory locking <lb/>semantics MUST result in the recall of all such delegations. The <lb/>LOCK operation may not be granted until all such delegations are <lb/>returned or revoked. Except where this happens very quickly, one or <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 453] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>more NFS4ERR_DELAY errors will be returned to requests made while the <lb/>delegation remains outstanding. <lb/>18.11. Operation 13: LOCKT -Test for Lock <lb/>18.11.1. ARGUMENTS <lb/>struct LOCKT4args { <lb/>/* CURRENT_FH: file */ <lb/>nfs_lock_type4 locktype; <lb/>offset4 <lb/>offset; <lb/>length4 <lb/>length; <lb/>lock_owner4 <lb/>owner; <lb/>}; <lb/>18.11.2. RESULTS <lb/>union LOCKT4res switch (nfsstat4 status) { <lb/>case NFS4ERR_DENIED: <lb/>LOCK4denied <lb/>denied; <lb/>case NFS4_OK: <lb/>void; <lb/>default: <lb/>void; <lb/>}; <lb/>18.11.3. DESCRIPTION <lb/>The LOCKT operation tests the lock as specified in the arguments. If <lb/>a conflicting lock exists, the owner, offset, length, and type of the <lb/>conflicting lock are returned. The owner field in the results <lb/>includes the client ID of the owner of the conflicting lock, whether <lb/>this is the client ID associated with the current session or a <lb/>different client ID. If no lock is held, nothing other than NFS4_OK <lb/>is returned. Lock types READ_LT and READW_LT are processed in the <lb/>same way in that a conflicting lock test is done without regard to <lb/>blocking or non-blocking. The same is true for WRITE_LT and <lb/>WRITEW_LT. <lb/>The ranges are specified as for LOCK. The NFS4ERR_INVAL and <lb/>NFS4ERR_BAD_RANGE errors are returned under the same circumstances as <lb/>for LOCK. <lb/>The clientid field of the owner MAY be set to any value by the client <lb/>and MUST be ignored by the server. The reason the server MUST ignore <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 454] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the clientid field is that the server MUST derive the client ID from <lb/>the session ID from the SEQUENCE operation of the COMPOUND request. <lb/>If the current filehandle is not an ordinary file, an error will be <lb/>returned to the client. In the case that the current filehandle <lb/>represents an object of type NF4DIR, NFS4ERR_ISDIR is returned. If <lb/>the current filehandle designates a symbolic link, NFS4ERR_SYMLINK is <lb/>returned. In all other cases, NFS4ERR_WRONG_TYPE is returned. <lb/>On success, the current filehandle retains its value. <lb/>18.11.4. IMPLEMENTATION <lb/>If the server is unable to determine the exact offset and length of <lb/>the conflicting lock, the same offset and length that were provided <lb/>in the arguments should be returned in the denied results. <lb/>LOCKT uses a lock_owner4 rather a stateid4, as is used in LOCK to <lb/>identify the owner. This is because the client does not have to open <lb/>the file to test for the existence of a lock, so a stateid might not <lb/>be available. <lb/>As noted in Section 18.10.4, some servers may return <lb/>NFS4ERR_LOCK_RANGE to certain (otherwise non-conflicting) LOCK <lb/>operations that overlap ranges already granted to the current lock-<lb/>owner. <lb/>The LOCKT operation&apos;s test for conflicting locks SHOULD exclude locks <lb/>for the current lock-owner, and thus should return NFS4_OK in such <lb/>cases. Note that this means that a server might return NFS4_OK to a <lb/>LOCKT request even though a LOCK operation for the same range and <lb/>lock-owner would fail with NFS4ERR_LOCK_RANGE. <lb/>When a client holds an OPEN_DELEGATE_WRITE delegation, it may choose <lb/>(see Section 18.10.4) to handle LOCK requests locally. In such a <lb/>case, LOCKT requests will similarly be handled locally. <lb/>18.12. Operation 14: LOCKU -Unlock File <lb/>18.12.1. ARGUMENTS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 455] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct LOCKU4args { <lb/>/* CURRENT_FH: file */ <lb/>nfs_lock_type4 locktype; <lb/>seqid4 <lb/>seqid; <lb/>stateid4 <lb/>lock_stateid; <lb/>offset4 <lb/>offset; <lb/>length4 <lb/>length; <lb/>}; <lb/>18.12.2. RESULTS <lb/>union LOCKU4res switch (nfsstat4 status) { <lb/>case <lb/>NFS4_OK: <lb/>stateid4 <lb/>lock_stateid; <lb/>default: <lb/>void; <lb/>}; <lb/>18.12.3. DESCRIPTION <lb/>The LOCKU operation unlocks the byte-range lock specified by the <lb/>parameters. The client may set the locktype field to any value that <lb/>is legal for the nfs_lock_type4 enumerated type, and the server MUST <lb/>accept any legal value for locktype. Any legal value for locktype <lb/>has no effect on the success or failure of the LOCKU operation. <lb/>The ranges are specified as for LOCK. The NFS4ERR_INVAL and <lb/>NFS4ERR_BAD_RANGE errors are returned under the same circumstances as <lb/>for LOCK. <lb/>The seqid parameter MAY be any value and the server MUST ignore it. <lb/>If the current filehandle is not an ordinary file, an error will be <lb/>returned to the client. In the case that the current filehandle <lb/>represents an object of type NF4DIR, NFS4ERR_ISDIR is returned. If <lb/>the current filehandle designates a symbolic link, NFS4ERR_SYMLINK is <lb/>returned. In all other cases, NFS4ERR_WRONG_TYPE is returned. <lb/>On success, the current filehandle retains its value. <lb/>The server MAY require that the principal, security flavor, and if <lb/>applicable, the GSS mechanism, combination that sent a LOCK operation <lb/>also be the one to send LOCKU on the file. This might not be <lb/>possible if credentials for the principal are no longer available. <lb/>The server MAY allow the machine credential or SSV credential (see <lb/>Section 18.35) to send LOCKU. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 456] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.12.4. IMPLEMENTATION <lb/>If the area to be unlocked does not correspond exactly to a lock <lb/>actually held by the lock-owner, the server may return the error <lb/>NFS4ERR_LOCK_RANGE. This includes the case in which the area is not <lb/>locked, where the area is a sub-range of the area locked, where it <lb/>overlaps the area locked without matching exactly, or the area <lb/>specified includes multiple locks held by the lock-owner. In all of <lb/>these cases, allowed by POSIX locking [21] semantics, a client <lb/>receiving this error should, if it desires support for such <lb/>operations, simulate the operation using LOCKU on ranges <lb/>corresponding to locks it actually holds, possibly followed by LOCK <lb/>operations for the sub-ranges not being unlocked. <lb/>When a client holds an OPEN_DELEGATE_WRITE delegation, it may choose <lb/>(see Section 18.10.4) to handle LOCK requests locally. In such a <lb/>case, LOCKU operations will similarly be handled locally. <lb/>18.13. Operation 15: LOOKUP -Lookup Filename <lb/>18.13.1. ARGUMENTS <lb/>struct LOOKUP4args { <lb/>/* CURRENT_FH: directory */ <lb/>component4 <lb/>objname; <lb/>}; <lb/>18.13.2. RESULTS <lb/>struct LOOKUP4res { <lb/>/* New CURRENT_FH: object */ <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/>18.13.3. DESCRIPTION <lb/>The LOOKUP operation looks up or finds a file system object using the <lb/>directory specified by the current filehandle. LOOKUP evaluates the <lb/>component and if the object exists, the current filehandle is <lb/>replaced with the component&apos;s filehandle. <lb/>If the component cannot be evaluated either because it does not exist <lb/>or because the client does not have permission to evaluate the <lb/>component, then an error will be returned and the current filehandle <lb/>will be unchanged. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 457] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If the component is a zero-length string or if any component does not <lb/>obey the UTF-8 definition, the error NFS4ERR_INVAL will be returned. <lb/>18.13.4. IMPLEMENTATION <lb/>If the client wants to achieve the effect of a multi-component look <lb/>up, it may construct a COMPOUND request such as (and obtain each <lb/>filehandle): <lb/>PUTFH (directory filehandle) <lb/>LOOKUP &quot;pub&quot; <lb/>GETFH <lb/>LOOKUP &quot;foo&quot; <lb/>GETFH <lb/>LOOKUP &quot;bar&quot; <lb/>GETFH <lb/>Unlike NFSv3, NFSv4.1 allows LOOKUP requests to cross mountpoints on <lb/>the server. The client can detect a mountpoint crossing by comparing <lb/>the fsid attribute of the directory with the fsid attribute of the <lb/>directory looked up. If the fsids are different, then the new <lb/>directory is a server mountpoint. UNIX clients that detect a <lb/>mountpoint crossing will need to mount the server&apos;s file system. <lb/>This needs to be done to maintain the file object identity checking <lb/>mechanisms common to UNIX clients. <lb/>Servers that limit NFS access to &quot;shared&quot; or &quot;exported&quot; file systems <lb/>should provide a pseudo file system into which the exported file <lb/>systems can be integrated, so that clients can browse the server&apos;s <lb/>namespace. The clients view of a pseudo file system will be limited <lb/>to paths that lead to exported file systems. <lb/>Note: previous versions of the protocol assigned special semantics to <lb/>the names &quot;.&quot; and &quot;..&quot;. NFSv4.1 assigns no special semantics to <lb/>these names. The LOOKUPP operator must be used to look up a parent <lb/>directory. <lb/>Note that this operation does not follow symbolic links. The client <lb/>is responsible for all parsing of filenames including filenames that <lb/>are modified by symbolic links encountered during the look up <lb/>process. <lb/>If the current filehandle supplied is not a directory but a symbolic <lb/>link, the error NFS4ERR_SYMLINK is returned as the error. For all <lb/>other non-directory file types, the error NFS4ERR_NOTDIR is returned. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 458] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.14. Operation 16: LOOKUPP -Lookup Parent Directory <lb/>18.14.1. ARGUMENTS <lb/>/* CURRENT_FH: object */ <lb/>void; <lb/>18.14.2. RESULTS <lb/>struct LOOKUPP4res { <lb/>/* new CURRENT_FH: parent directory */ <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/>18.14.3. DESCRIPTION <lb/>The current filehandle is assumed to refer to a regular directory or <lb/>a named attribute directory. LOOKUPP assigns the filehandle for its <lb/>parent directory to be the current filehandle. If there is no parent <lb/>directory, an NFS4ERR_NOENT error must be returned. Therefore, <lb/>NFS4ERR_NOENT will be returned by the server when the current <lb/>filehandle is at the root or top of the server&apos;s file tree. <lb/>As is the case with LOOKUP, LOOKUPP will also cross mountpoints. <lb/>If the current filehandle is not a directory or named attribute <lb/>directory, the error NFS4ERR_NOTDIR is returned. <lb/>If the requester&apos;s security flavor does not match that configured for <lb/>the parent directory, then the server SHOULD return NFS4ERR_WRONGSEC <lb/>(a future minor revision of NFSv4 may upgrade this to MUST) in the <lb/>LOOKUPP response. However, if the server does so, it MUST support <lb/>the SECINFO_NO_NAME operation (Section 18.45), so that the client can <lb/>gracefully determine the correct security flavor. <lb/>If the current filehandle is a named attribute directory that is <lb/>associated with a file system object via OPENATTR (i.e., not a sub-<lb/>directory of a named attribute directory), LOOKUPP SHOULD return the <lb/>filehandle of the associated file system object. <lb/>18.14.4. IMPLEMENTATION <lb/>An issue to note is upward navigation from named attribute <lb/>directories. The named attribute directories are essentially <lb/>detached from the namespace, and this property should be safely <lb/>represented in the client operating environment. LOOKUPP on a named <lb/>attribute directory may return the filehandle of the associated file, <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 459] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>and conveying this to applications might be unsafe as many <lb/>applications expect the parent of an object to always be a directory. <lb/>Therefore, the client may want to hide the parent of named attribute <lb/>directories (represented as &quot;..&quot; in UNIX) or represent the named <lb/>attribute directory as its own parent (as is typically done for the <lb/>file system root directory in UNIX). <lb/>18.15. Operation 17: NVERIFY -Verify Difference in Attributes <lb/>18.15.1. ARGUMENTS <lb/>struct NVERIFY4args { <lb/>/* CURRENT_FH: object */ <lb/>fattr4 <lb/>obj_attributes; <lb/>}; <lb/>18.15.2. RESULTS <lb/>struct NVERIFY4res { <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/>18.15.3. DESCRIPTION <lb/>This operation is used to prefix a sequence of operations to be <lb/>performed if one or more attributes have changed on some file system <lb/>object. If all the attributes match, then the error NFS4ERR_SAME <lb/>MUST be returned. <lb/>On success, the current filehandle retains its value. <lb/>18.15.4. IMPLEMENTATION <lb/>This operation is useful as a cache validation operator. If the <lb/>object to which the attributes belong has changed, then the following <lb/>operations may obtain new data associated with that object, for <lb/>instance, to check if a file has been changed and obtain new data if <lb/>it has: <lb/>SEQUENCE <lb/>PUTFH fh <lb/>NVERIFY attrbits attrs <lb/>READ 0 32767 <lb/>Contrast this with NFSv3, which would first send a GETATTR in one <lb/>request/reply round trip, and then if attributes indicated that the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 460] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>client&apos;s cache was stale, then send a READ in another request/reply <lb/>round trip. <lb/>In the case that a RECOMMENDED attribute is specified in the NVERIFY <lb/>operation and the server does not support that attribute for the file <lb/>system object, the error NFS4ERR_ATTRNOTSUPP is returned to the <lb/>client. <lb/>When the attribute rdattr_error or any set-only attribute (e.g., <lb/>time_modify_set) is specified, the error NFS4ERR_INVAL is returned to <lb/>the client. <lb/>18.16. Operation 18: OPEN -Open a Regular File <lb/>18.16.1. ARGUMENTS <lb/>/* <lb/>* Various definitions for OPEN <lb/>*/ <lb/>enum createmode4 { <lb/>UNCHECKED4 <lb/>= 0, <lb/>GUARDED4 <lb/>= 1, <lb/>/* Deprecated in NFSv4.1. */ <lb/>EXCLUSIVE4 <lb/>= 2, <lb/>/* <lb/>* New to NFSv4.1. If session is persistent, <lb/>* GUARDED4 MUST be used. Otherwise, use <lb/>* EXCLUSIVE4_1 instead of EXCLUSIVE4. <lb/>*/ <lb/>EXCLUSIVE4_1 <lb/>= 3 <lb/>}; <lb/>struct creatverfattr { <lb/>verifier4 <lb/>cva_verf; <lb/>fattr4 <lb/>cva_attrs; <lb/>}; <lb/>union createhow4 switch (createmode4 mode) { <lb/>case UNCHECKED4: <lb/>case GUARDED4: <lb/>fattr4 <lb/>createattrs; <lb/>case EXCLUSIVE4: <lb/>verifier4 <lb/>createverf; <lb/>case EXCLUSIVE4_1: <lb/>creatverfattr ch_createboth; <lb/>}; <lb/>enum opentype4 { <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 461] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>OPEN4_NOCREATE = 0, <lb/>OPEN4_CREATE <lb/>= 1 <lb/>}; <lb/>union openflag4 switch (opentype4 opentype) { <lb/>case OPEN4_CREATE: <lb/>createhow4 <lb/>how; <lb/>default: <lb/>void; <lb/>}; <lb/>/* Next definitions used for OPEN delegation */ <lb/>enum limit_by4 { <lb/>NFS_LIMIT_SIZE <lb/>= 1, <lb/>NFS_LIMIT_BLOCKS <lb/>= 2 <lb/>/* others as needed */ <lb/>}; <lb/>struct nfs_modified_limit4 { <lb/>uint32_t <lb/>num_blocks; <lb/>uint32_t <lb/>bytes_per_block; <lb/>}; <lb/>union nfs_space_limit4 switch (limit_by4 limitby) { <lb/>/* limit specified as file size */ <lb/>case NFS_LIMIT_SIZE: <lb/>uint64_t <lb/>filesize; <lb/>/* limit specified by number of blocks */ <lb/>case NFS_LIMIT_BLOCKS: <lb/>nfs_modified_limit4 <lb/>mod_blocks; <lb/>} ; <lb/>/* <lb/>* Share Access and Deny constants for open argument <lb/>*/ <lb/>const OPEN4_SHARE_ACCESS_READ <lb/>= 0x00000001; <lb/>const OPEN4_SHARE_ACCESS_WRITE = 0x00000002; <lb/>const OPEN4_SHARE_ACCESS_BOTH <lb/>= 0x00000003; <lb/>const OPEN4_SHARE_DENY_NONE <lb/>= 0x00000000; <lb/>const OPEN4_SHARE_DENY_READ <lb/>= 0x00000001; <lb/>const OPEN4_SHARE_DENY_WRITE <lb/>= 0x00000002; <lb/>const OPEN4_SHARE_DENY_BOTH <lb/>= 0x00000003; <lb/>/* new flags for share_access field of OPEN4args */ <lb/>const OPEN4_SHARE_ACCESS_WANT_DELEG_MASK <lb/>= 0xFF00; <lb/>const OPEN4_SHARE_ACCESS_WANT_NO_PREFERENCE <lb/>= 0x0000; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 462] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>const OPEN4_SHARE_ACCESS_WANT_READ_DELEG <lb/>= 0x0100; <lb/>const OPEN4_SHARE_ACCESS_WANT_WRITE_DELEG <lb/>= 0x0200; <lb/>const OPEN4_SHARE_ACCESS_WANT_ANY_DELEG <lb/>= 0x0300; <lb/>const OPEN4_SHARE_ACCESS_WANT_NO_DELEG <lb/>= 0x0400; <lb/>const OPEN4_SHARE_ACCESS_WANT_CANCEL <lb/>= 0x0500; <lb/>const <lb/>OPEN4_SHARE_ACCESS_WANT_SIGNAL_DELEG_WHEN_RESRC_AVAIL <lb/>= 0x10000; <lb/>const <lb/>OPEN4_SHARE_ACCESS_WANT_PUSH_DELEG_WHEN_UNCONTENDED <lb/>= 0x20000; <lb/>enum open_delegation_type4 { <lb/>OPEN_DELEGATE_NONE <lb/>= 0, <lb/>OPEN_DELEGATE_READ <lb/>= 1, <lb/>OPEN_DELEGATE_WRITE <lb/>= 2, <lb/>OPEN_DELEGATE_NONE_EXT = 3 /* new to v4.1 */ <lb/>}; <lb/>enum open_claim_type4 { <lb/>/* <lb/>* Not a reclaim. <lb/>*/ <lb/>CLAIM_NULL <lb/>= 0, <lb/>CLAIM_PREVIOUS <lb/>= 1, <lb/>CLAIM_DELEGATE_CUR <lb/>= 2, <lb/>CLAIM_DELEGATE_PREV <lb/>= 3, <lb/>/* <lb/>* Not a reclaim. <lb/>* <lb/>* Like CLAIM_NULL, but object identified <lb/>* by the current filehandle. <lb/>*/ <lb/>CLAIM_FH <lb/>= 4, /* new to v4.1 */ <lb/>/* <lb/>* Like CLAIM_DELEGATE_CUR, but object identified <lb/>* by current filehandle. <lb/>*/ <lb/>CLAIM_DELEG_CUR_FH <lb/>= 5, /* new to v4.1 */ <lb/>/* <lb/>* Like CLAIM_DELEGATE_PREV, but object identified <lb/>* by current filehandle. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 463] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>*/ <lb/>CLAIM_DELEG_PREV_FH <lb/>= 6 /* new to v4.1 */ <lb/>}; <lb/>struct open_claim_delegate_cur4 { <lb/>stateid4 <lb/>delegate_stateid; <lb/>component4 <lb/>file; <lb/>}; <lb/>union open_claim4 switch (open_claim_type4 claim) { <lb/>/* <lb/>* No special rights to file. <lb/>* Ordinary OPEN of the specified file. <lb/>*/ <lb/>case CLAIM_NULL: <lb/>/* CURRENT_FH: directory */ <lb/>component4 <lb/>file; <lb/>/* <lb/>* Right to the file established by an <lb/>* open previous to server reboot. File <lb/>* identified by filehandle obtained at <lb/>* that time rather than by name. <lb/>*/ <lb/>case CLAIM_PREVIOUS: <lb/>/* CURRENT_FH: file being reclaimed */ <lb/>open_delegation_type4 <lb/>delegate_type; <lb/>/* <lb/>* Right to file based on a delegation <lb/>* granted by the server. File is <lb/>* specified by name. <lb/>*/ <lb/>case CLAIM_DELEGATE_CUR: <lb/>/* CURRENT_FH: directory */ <lb/>open_claim_delegate_cur4 <lb/>delegate_cur_info; <lb/>/* <lb/>* Right to file based on a delegation <lb/>* granted to a previous boot instance <lb/>* of the client. File is specified by name. <lb/>*/ <lb/>case CLAIM_DELEGATE_PREV: <lb/>/* CURRENT_FH: directory */ <lb/>component4 <lb/>file_delegate_prev; <lb/>/* <lb/>* Like CLAIM_NULL. No special rights <lb/>* to file. Ordinary OPEN of the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 464] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>* specified file by current filehandle. <lb/>*/ <lb/>case CLAIM_FH: /* new to v4.1 */ <lb/>/* CURRENT_FH: regular file to open */ <lb/>void; <lb/>/* <lb/>* Like CLAIM_DELEGATE_PREV. Right to file based on a <lb/>* delegation granted to a previous boot <lb/>* instance of the client. File is identified by <lb/>* by filehandle. <lb/>*/ <lb/>case CLAIM_DELEG_PREV_FH: /* new to v4.1 */ <lb/>/* CURRENT_FH: file being opened */ <lb/>void; <lb/>/* <lb/>* Like CLAIM_DELEGATE_CUR. Right to file based on <lb/>* a delegation granted by the server. <lb/>* File is identified by filehandle. <lb/>*/ <lb/>case CLAIM_DELEG_CUR_FH: /* new to v4.1 */ <lb/>/* CURRENT_FH: file being opened */ <lb/>stateid4 <lb/>oc_delegate_stateid; <lb/>}; <lb/>/* <lb/>* OPEN: Open a file, potentially receiving an OPEN delegation <lb/>*/ <lb/>struct OPEN4args { <lb/>seqid4 <lb/>seqid; <lb/>uint32_t <lb/>share_access; <lb/>uint32_t <lb/>share_deny; <lb/>open_owner4 <lb/>owner; <lb/>openflag4 <lb/>openhow; <lb/>open_claim4 <lb/>claim; <lb/>}; <lb/>18.16.2. RESULTS <lb/>struct open_read_delegation4 { <lb/>stateid4 stateid; <lb/>/* Stateid for delegation*/ <lb/>bool <lb/>recall; <lb/>/* Pre-recalled flag for <lb/>delegations obtained <lb/>by reclaim (CLAIM_PREVIOUS) */ <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 465] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>nfsace4 permissions; /* Defines users who don&apos;t <lb/>need an ACCESS call to <lb/>open for read */ <lb/>}; <lb/>struct open_write_delegation4 { <lb/>stateid4 stateid; <lb/>/* Stateid for delegation */ <lb/>bool <lb/>recall; <lb/>/* Pre-recalled flag for <lb/>delegations obtained <lb/>by reclaim <lb/>(CLAIM_PREVIOUS) */ <lb/>nfs_space_limit4 <lb/>space_limit; /* Defines condition that <lb/>the client must check to <lb/>determine whether the <lb/>file needs to be flushed <lb/>to the server on close. */ <lb/>nfsace4 <lb/>permissions; /* Defines users who don&apos;t <lb/>need an ACCESS call as <lb/>part of a delegated <lb/>open. */ <lb/>}; <lb/>enum why_no_delegation4 { /* new to v4.1 */ <lb/>WND4_NOT_WANTED <lb/>= 0, <lb/>WND4_CONTENTION <lb/>= 1, <lb/>WND4_RESOURCE <lb/>= 2, <lb/>WND4_NOT_SUPP_FTYPE <lb/>= 3, <lb/>WND4_WRITE_DELEG_NOT_SUPP_FTYPE = 4, <lb/>WND4_NOT_SUPP_UPGRADE <lb/>= 5, <lb/>WND4_NOT_SUPP_DOWNGRADE = 6, <lb/>WND4_CANCELLED <lb/>= 7, <lb/>WND4_IS_DIR <lb/>= 8 <lb/>}; <lb/>union open_none_delegation4 /* new to v4.1 */ <lb/>switch (why_no_delegation4 ond_why) { <lb/>case WND4_CONTENTION: <lb/>bool ond_server_will_push_deleg; <lb/>case WND4_RESOURCE: <lb/>bool ond_server_will_signal_avail; <lb/>default: <lb/>void; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 466] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>union open_delegation4 <lb/>switch (open_delegation_type4 delegation_type) { <lb/>case OPEN_DELEGATE_NONE: <lb/>void; <lb/>case OPEN_DELEGATE_READ: <lb/>open_read_delegation4 read; <lb/>case OPEN_DELEGATE_WRITE: <lb/>open_write_delegation4 write; <lb/>case OPEN_DELEGATE_NONE_EXT: /* new to v4.1 */ <lb/>open_none_delegation4 od_whynone; <lb/>}; <lb/>/* <lb/>* Result flags <lb/>*/ <lb/>/* Client must confirm open */ <lb/>const OPEN4_RESULT_CONFIRM <lb/>= 0x00000002; <lb/>/* Type of file locking behavior at the server */ <lb/>const OPEN4_RESULT_LOCKTYPE_POSIX = 0x00000004; <lb/>/* Server will preserve file if removed while open */ <lb/>const OPEN4_RESULT_PRESERVE_UNLINKED = 0x00000008; <lb/>/* <lb/>* Server may use CB_NOTIFY_LOCK on locks <lb/>* derived from this open <lb/>*/ <lb/>const OPEN4_RESULT_MAY_NOTIFY_LOCK = 0x00000020; <lb/>struct OPEN4resok { <lb/>stateid4 <lb/>stateid; <lb/>/* Stateid for open */ <lb/>change_info4 <lb/>cinfo; <lb/>/* Directory Change Info */ <lb/>uint32_t <lb/>rflags; <lb/>/* Result flags */ <lb/>bitmap4 <lb/>attrset; <lb/>/* attribute set for create*/ <lb/>open_delegation4 delegation; /* Info on any open <lb/>delegation */ <lb/>}; <lb/>union OPEN4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>/* New CURRENT_FH: opened file */ <lb/>OPEN4resok <lb/>resok4; <lb/>default: <lb/>void; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 467] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.16.3. DESCRIPTION <lb/>The OPEN operation opens a regular file in a directory with the <lb/>provided name or filehandle. OPEN can also create a file if a name <lb/>is provided, and the client specifies it wants to create a file. <lb/>Specification of whether or not a file is to be created, and the <lb/>method of creation is via the openhow parameter. The openhow <lb/>parameter consists of a switched union (data type opengflag4), which <lb/>switches on the value of opentype (OPEN4_NOCREATE or OPEN4_CREATE). <lb/>If OPEN4_CREATE is specified, this leads to another switched union <lb/>(data type createhow4) that supports four cases of creation methods: <lb/>UNCHECKED4, GUARDED4, EXCLUSIVE4, or EXCLUSIVE4_1. If opentype is <lb/>OPEN4_CREATE, then the claim field of the claim field MUST be one of <lb/>CLAIM_NULL, CLAIM_DELEGATE_CUR, or CLAIM_DELEGATE_PREV, because these <lb/>claim methods include a component of a file name. <lb/>Upon success (which might entail creation of a new file), the current <lb/>filehandle is replaced by that of the created or existing object. <lb/>If the current filehandle is a named attribute directory, OPEN will <lb/>then create or open a named attribute file. Note that exclusive <lb/>create of a named attribute is not supported. If the createmode is <lb/>EXCLUSIVE4 or EXCLUSIVE4_1 and the current filehandle is a named <lb/>attribute directory, the server will return EINVAL. <lb/>UNCHECKED4 means that the file should be created if a file of that <lb/>name does not exist and encountering an existing regular file of that <lb/>name is not an error. For this type of create, createattrs specifies <lb/>the initial set of attributes for the file. The set of attributes <lb/>may include any writable attribute valid for regular files. When an <lb/>UNCHECKED4 create encounters an existing file, the attributes <lb/>specified by createattrs are not used, except that when createattrs <lb/>specifies the size attribute with a size of zero, the existing file <lb/>is truncated. <lb/>If GUARDED4 is specified, the server checks for the presence of a <lb/>duplicate object by name before performing the create. If a <lb/>duplicate exists, NFS4ERR_EXIST is returned. If the object does not <lb/>exist, the request is performed as described for UNCHECKED4. <lb/>For the UNCHECKED4 and GUARDED4 cases, where the operation is <lb/>successful, the server will return to the client an attribute mask <lb/>signifying which attributes were successfully set for the object. <lb/>EXCLUSIVE4_1 and EXCLUSIVE4 specify that the server is to follow <lb/>exclusive creation semantics, using the verifier to ensure exclusive <lb/>creation of the target. The server should check for the presence of <lb/>a duplicate object by name. If the object does not exist, the server <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 468] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>creates the object and stores the verifier with the object. If the <lb/>object does exist and the stored verifier matches the client provided <lb/>verifier, the server uses the existing object as the newly created <lb/>object. If the stored verifier does not match, then an error of <lb/>NFS4ERR_EXIST is returned. <lb/>If using EXCLUSIVE4, and if the server uses attributes to store the <lb/>exclusive create verifier, the server will signify which attributes <lb/>it used by setting the appropriate bits in the attribute mask that is <lb/>returned in the results. Unlike UNCHECKED4, GUARDED4, and <lb/>EXCLUSIVE4_1, EXCLUSIVE4 does not support the setting of attributes <lb/>at file creation, and after a successful OPEN via EXCLUSIVE4, the <lb/>client MUST send a SETATTR to set attributes to a known state. <lb/>In NFSv4.1, EXCLUSIVE4 has been deprecated in favor of EXCLUSIVE4_1. <lb/>Unlike EXCLUSIVE4, attributes may be provided in the EXCLUSIVE4_1 <lb/>case, but because the server may use attributes of the target object <lb/>to store the verifier, the set of allowable attributes may be fewer <lb/>than the set of attributes SETATTR allows. The allowable attributes <lb/>for EXCLUSIVE4_1 are indicated in the suppattr_exclcreat <lb/>(Section 5.8.1.14) attribute. If the client attempts to set in <lb/>cva_attrs an attribute that is not in suppattr_exclcreat, the server <lb/>MUST return NFS4ERR_INVAL. The response field, attrset, indicates <lb/>both which attributes the server set from cva_attrs and which <lb/>attributes the server used to store the verifier. As described in <lb/>Section 18.16.4, the client can compare cva_attrs.attrmask with <lb/>attrset to determine which attributes were used to store the <lb/>verifier. <lb/>With the addition of persistent sessions and pNFS, under some <lb/>conditions EXCLUSIVE4 MUST NOT be used by the client or supported by <lb/>the server. The following table summarizes the appropriate and <lb/>mandated exclusive create methods for implementations of NFSv4.1: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 469] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Required methods for exclusive create <lb/>+----------------+-----------+---------------+----------------------+ <lb/>| Persistent <lb/>| Server <lb/>| Server <lb/>| Client Allowed <lb/>| <lb/>| Reply Cache <lb/>| Supports | REQUIRED <lb/>| <lb/>| <lb/>| Enabled <lb/>| pNFS <lb/>| <lb/>| <lb/>| <lb/>+----------------+-----------+---------------+----------------------+ <lb/>| no <lb/>| no <lb/>| EXCLUSIVE4_1 | EXCLUSIVE4_1 <lb/>| <lb/>| <lb/>| <lb/>| and <lb/>| (SHOULD) or <lb/>| <lb/>| <lb/>| <lb/>| EXCLUSIVE4 <lb/>| EXCLUSIVE4 (SHOULD <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| NOT) <lb/>| <lb/>| no <lb/>| yes <lb/>| EXCLUSIVE4_1 | EXCLUSIVE4_1 <lb/>| <lb/>| yes <lb/>| no <lb/>| GUARDED4 <lb/>| GUARDED4 <lb/>| <lb/>| yes <lb/>| yes <lb/>| GUARDED4 <lb/>| GUARDED4 <lb/>| <lb/>+----------------+-----------+---------------+----------------------+ <lb/>Table 10 <lb/>If CREATE_SESSION4_FLAG_PERSIST is set in the results of <lb/>CREATE_SESSION, the reply cache is persistent (see Section 18.36). <lb/>If the EXCHGID4_FLAG_USE_PNFS_MDS flag is set in the results from <lb/>EXCHANGE_ID, the server is a pNFS server (see Section 18.35). If the <lb/>client attempts to use EXCLUSIVE4 on a persistent session, or a <lb/>session derived from an EXCHGID4_FLAG_USE_PNFS_MDS client ID, the <lb/>server MUST return NFS4ERR_INVAL. <lb/>With persistent sessions, exclusive create semantics are fully <lb/>achievable via GUARDED4, and so EXCLUSIVE4 or EXCLUSIVE4_1 MUST NOT <lb/>be used. When pNFS is being used, the layout_hint attribute might <lb/>not be supported after the file is created. Only the EXCLUSIVE4_1 <lb/>and GUARDED methods of exclusive file creation allow the atomic <lb/>setting of attributes. <lb/>For the target directory, the server returns change_info4 information <lb/>in cinfo. With the atomic field of the change_info4 data type, the <lb/>server will indicate if the before and after change attributes were <lb/>obtained atomically with respect to the link creation. <lb/>The OPEN operation provides for Windows share reservation capability <lb/>with the use of the share_access and share_deny fields of the OPEN <lb/>arguments. The client specifies at OPEN the required share_access <lb/>and share_deny modes. For clients that do not directly support <lb/>SHAREs (i.e., UNIX), the expected deny value is <lb/>OPEN4_SHARE_DENY_NONE. In the case that there is an existing SHARE <lb/>reservation that conflicts with the OPEN request, the server returns <lb/>the error NFS4ERR_SHARE_DENIED. For additional discussion of SHARE <lb/>semantics, see Section 9.7. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 470] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>For each OPEN, the client provides a value for the owner field of the <lb/>OPEN argument. The owner field is of data type open_owner4, and <lb/>contains a field called clientid and a field called owner. The <lb/>client can set the clientid field to any value and the server MUST <lb/>ignore it. Instead, the server MUST derive the client ID from the <lb/>session ID of the SEQUENCE operation of the COMPOUND request. <lb/>The &quot;seqid&quot; field of the request is not used in NFSv4.1, but it MAY <lb/>be any value and the server MUST ignore it. <lb/>In the case that the client is recovering state from a server <lb/>failure, the claim field of the OPEN argument is used to signify that <lb/>the request is meant to reclaim state previously held. <lb/>The &quot;claim&quot; field of the OPEN argument is used to specify the file to <lb/>be opened and the state information that the client claims to <lb/>possess. There are seven claim types as follows: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 471] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>+----------------------+--------------------------------------------+ <lb/>| open type <lb/>| description <lb/>| <lb/>+----------------------+--------------------------------------------+ <lb/>| CLAIM_NULL, CLAIM_FH | For the client, this is a new OPEN request | <lb/>| <lb/>| and there is no previous state associated | <lb/>| <lb/>| with the file for the client. With <lb/>| <lb/>| <lb/>| CLAIM_NULL, the file is identified by the | <lb/>| <lb/>| current filehandle and the specified <lb/>| <lb/>| <lb/>| component name. With CLAIM_FH (new to <lb/>| <lb/>| <lb/>| NFSv4.1), the file is identified by just <lb/>| <lb/>| <lb/>| the current filehandle. <lb/>| <lb/>| CLAIM_PREVIOUS <lb/>| The client is claiming basic OPEN state <lb/>| <lb/>| <lb/>| for a file that was held previous to a <lb/>| <lb/>| <lb/>| server restart. Generally used when a <lb/>| <lb/>| <lb/>| server is returning persistent <lb/>| <lb/>| <lb/>| filehandles; the client may not have the <lb/>| <lb/>| <lb/>| file name to reclaim the OPEN. <lb/>| <lb/>| CLAIM_DELEGATE_CUR, | The client is claiming a delegation for <lb/>| <lb/>| CLAIM_DELEG_CUR_FH <lb/>| OPEN as granted by the server. Generally, | <lb/>| <lb/>| this is done as part of recalling a <lb/>| <lb/>| <lb/>| delegation. With CLAIM_DELEGATE_CUR, the | <lb/>| <lb/>| file is identified by the current <lb/>| <lb/>| <lb/>| filehandle and the specified component <lb/>| <lb/>| <lb/>| name. With CLAIM_DELEG_CUR_FH (new to <lb/>| <lb/>| <lb/>| NFSv4.1), the file is identified by just <lb/>| <lb/>| <lb/>| the current filehandle. <lb/>| <lb/>| CLAIM_DELEGATE_PREV, | The client is claiming a delegation <lb/>| <lb/>| CLAIM_DELEG_PREV_FH | granted to a previous client instance; <lb/>| <lb/>| <lb/>| used after the client restarts. The server | <lb/>| <lb/>| MAY support CLAIM_DELEGATE_PREV and/or <lb/>| <lb/>| <lb/>| CLAIM_DELEG_PREV_FH (new to NFSv4.1). If | <lb/>| <lb/>| it does support either claim type, <lb/>| <lb/>| <lb/>| CREATE_SESSION MUST NOT remove the <lb/>| <lb/>| <lb/>| client&apos;s delegation state, and the server | <lb/>| <lb/>| MUST support the DELEGPURGE operation. <lb/>| <lb/>+----------------------+--------------------------------------------+ <lb/>For OPEN requests that reach the server during the grace period, the <lb/>server returns an error of NFS4ERR_GRACE. The following claim types <lb/>are exceptions: <lb/>o OPEN requests specifying the claim type CLAIM_PREVIOUS are devoted <lb/>to reclaiming opens after a server restart and are typically only <lb/>valid during the grace period. <lb/>o OPEN requests specifying the claim types CLAIM_DELEGATE_CUR and <lb/>CLAIM_DELEG_CUR_FH are valid both during and after the grace <lb/>period. Since the granting of the delegation that they are <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 472] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>subordinate to assures that there is no conflict with locks to be <lb/>reclaimed by other clients, the server need not return <lb/>NFS4ERR_GRACE when these are received during the grace period. <lb/>For any OPEN request, the server may return an OPEN delegation, which <lb/>allows further opens and closes to be handled locally on the client <lb/>as described in Section 10.4. Note that delegation is up to the <lb/>server to decide. The client should never assume that delegation <lb/>will or will not be granted in a particular instance. It should <lb/>always be prepared for either case. A partial exception is the <lb/>reclaim (CLAIM_PREVIOUS) case, in which a delegation type is claimed. <lb/>In this case, delegation will always be granted, although the server <lb/>may specify an immediate recall in the delegation structure. <lb/>The rflags returned by a successful OPEN allow the server to return <lb/>information governing how the open file is to be handled. <lb/>o OPEN4_RESULT_CONFIRM is deprecated and MUST NOT be returned by an <lb/>NFSv4.1 server. <lb/>o OPEN4_RESULT_LOCKTYPE_POSIX indicates that the server&apos;s byte-range <lb/>locking behavior supports the complete set of POSIX locking <lb/>techniques [21]. From this, the client can choose to manage byte-<lb/>range locking state in a way to handle a mismatch of byte-range <lb/>locking management. <lb/>o OPEN4_RESULT_PRESERVE_UNLINKED indicates that the server will <lb/>preserve the open file if the client (or any other client) removes <lb/>the file as long as it is open. Furthermore, the server promises <lb/>to preserve the file through the grace period after server <lb/>restart, thereby giving the client the opportunity to reclaim its <lb/>open. <lb/>o OPEN4_RESULT_MAY_NOTIFY_LOCK indicates that the server may attempt <lb/>CB_NOTIFY_LOCK callbacks for locks on this file. This flag is a <lb/>hint only, and may be safely ignored by the client. <lb/>If the component is of zero length, NFS4ERR_INVAL will be returned. <lb/>The component is also subject to the normal UTF-8, character support, <lb/>and name checks. See Section 14.5 for further discussion. <lb/>When an OPEN is done and the specified open-owner already has the <lb/>resulting filehandle open, the result is to &quot;OR&quot; together the new <lb/>share and deny status together with the existing status. In this <lb/>case, only a single CLOSE need be done, even though multiple OPENs <lb/>were completed. When such an OPEN is done, checking of share <lb/>reservations for the new OPEN proceeds normally, with no exception <lb/>for the existing OPEN held by the same open-owner. In this case, the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 473] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>stateid returned as an &quot;other&quot; field that matches that of the <lb/>previous open while the &quot;seqid&quot; field is incremented to reflect the <lb/>change status due to the new open. <lb/>If the underlying file system at the server is only accessible in a <lb/>read-only mode and the OPEN request has specified ACCESS_WRITE or <lb/>ACCESS_BOTH, the server will return NFS4ERR_ROFS to indicate a read-<lb/>only file system. <lb/>As with the CREATE operation, the server MUST derive the owner, owner <lb/>ACE, group, or group ACE if any of the four attributes are required <lb/>and supported by the server&apos;s file system. For an OPEN with the <lb/>EXCLUSIVE4 createmode, the server has no choice, since such OPEN <lb/>calls do not include the createattrs field. Conversely, if <lb/>createattrs (UNCHECKED4 or GUARDED4) or cva_attrs (EXCLUSIVE4_1) is <lb/>specified, and includes an owner, owner_group, or ACE that the <lb/>principal in the RPC call&apos;s credentials does not have authorization <lb/>to create files for, then the server may return NFS4ERR_PERM. <lb/>In the case of an OPEN that specifies a size of zero (e.g., <lb/>truncation) and the file has named attributes, the named attributes <lb/>are left as is and are not removed. <lb/>NFSv4.1 gives more precise control to clients over acquisition of <lb/>delegations via the following new flags for the share_access field of <lb/>OPEN4args: <lb/>OPEN4_SHARE_ACCESS_WANT_READ_DELEG <lb/>OPEN4_SHARE_ACCESS_WANT_WRITE_DELEG <lb/>OPEN4_SHARE_ACCESS_WANT_ANY_DELEG <lb/>OPEN4_SHARE_ACCESS_WANT_NO_DELEG <lb/>OPEN4_SHARE_ACCESS_WANT_CANCEL <lb/>OPEN4_SHARE_ACCESS_WANT_SIGNAL_DELEG_WHEN_RESRC_AVAIL <lb/>OPEN4_SHARE_ACCESS_WANT_PUSH_DELEG_WHEN_UNCONTENDED <lb/>If (share_access &amp; OPEN4_SHARE_ACCESS_WANT_DELEG_MASK) is not zero, <lb/>then the client will have specified one and only one of: <lb/>OPEN4_SHARE_ACCESS_WANT_READ_DELEG <lb/>OPEN4_SHARE_ACCESS_WANT_WRITE_DELEG <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 474] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>OPEN4_SHARE_ACCESS_WANT_ANY_DELEG <lb/>OPEN4_SHARE_ACCESS_WANT_NO_DELEG <lb/>OPEN4_SHARE_ACCESS_WANT_CANCEL <lb/>Otherwise, the client is neither indicating a desire nor a non-desire <lb/>for a delegation, and the server MAY or MAY not return a delegation <lb/>in the OPEN response. <lb/>If the server supports the new _WANT_ flags and the client sends one <lb/>or more of the new flags, then in the event the server does not <lb/>return a delegation, it MUST return a delegation type of <lb/>OPEN_DELEGATE_NONE_EXT. The field ond_why in the reply indicates why <lb/>no delegation was returned and will be one of: <lb/>WND4_NOT_WANTED The client specified <lb/>OPEN4_SHARE_ACCESS_WANT_NO_DELEG. <lb/>WND4_CONTENTION There is a conflicting delegation or open on the <lb/>file. <lb/>WND4_RESOURCE Resource limitations prevent the server from granting <lb/>a delegation. <lb/>WND4_NOT_SUPP_FTYPE The server does not support delegations on this <lb/>file type. <lb/>WND4_WRITE_DELEG_NOT_SUPP_FTYPE The server does not support <lb/>OPEN_DELEGATE_WRITE delegations on this file type. <lb/>WND4_NOT_SUPP_UPGRADE The server does not support atomic upgrade of <lb/>an OPEN_DELEGATE_READ delegation to an OPEN_DELEGATE_WRITE <lb/>delegation. <lb/>WND4_NOT_SUPP_DOWNGRADE The server does not support atomic downgrade <lb/>of an OPEN_DELEGATE_WRITE delegation to an OPEN_DELEGATE_READ <lb/>delegation. <lb/>WND4_CANCELED The client specified OPEN4_SHARE_ACCESS_WANT_CANCEL <lb/>and now any &quot;want&quot; for this file object is cancelled. <lb/>WND4_IS_DIR The specified file object is a directory, and the <lb/>operation is OPEN or WANT_DELEGATION, which do not support <lb/>delegations on directories. <lb/>OPEN4_SHARE_ACCESS_WANT_READ_DELEG, <lb/>OPEN_SHARE_ACCESS_WANT_WRITE_DELEG, or <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 475] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>OPEN_SHARE_ACCESS_WANT_ANY_DELEG mean, respectively, the client wants <lb/>an OPEN_DELEGATE_READ, OPEN_DELEGATE_WRITE, or any delegation <lb/>regardless which of OPEN4_SHARE_ACCESS_READ, <lb/>OPEN4_SHARE_ACCESS_WRITE, or OPEN4_SHARE_ACCESS_BOTH is set. If the <lb/>client has an OPEN_DELEGATE_READ delegation on a file and requests an <lb/>OPEN_DELEGATE_WRITE delegation, then the client is requesting atomic <lb/>upgrade of its OPEN_DELEGATE_READ delegation to an <lb/>OPEN_DELEGATE_WRITE delegation. If the client has an <lb/>OPEN_DELEGATE_WRITE delegation on a file and requests an <lb/>OPEN_DELEGATE_READ delegation, then the client is requesting atomic <lb/>downgrade to an OPEN_DELEGATE_READ delegation. A server MAY support <lb/>atomic upgrade or downgrade. If it does, then the returned <lb/>delegation_type of OPEN_DELEGATE_READ or OPEN_DELEGATE_WRITE that is <lb/>different from the delegation type the client currently has, <lb/>indicates successful upgrade or downgrade. If the server does not <lb/>support atomic delegation upgrade or downgrade, then ond_why will be <lb/>set to WND4_NOT_SUPP_UPGRADE or WND4_NOT_SUPP_DOWNGRADE. <lb/>OPEN4_SHARE_ACCESS_WANT_NO_DELEG means that the client wants no <lb/>delegation. <lb/>OPEN4_SHARE_ACCESS_WANT_CANCEL means that the client wants no <lb/>delegation and wants to cancel any previously registered &quot;want&quot; for a <lb/>delegation. <lb/>The client may set one or both of <lb/>OPEN4_SHARE_ACCESS_WANT_SIGNAL_DELEG_WHEN_RESRC_AVAIL and <lb/>OPEN4_SHARE_ACCESS_WANT_PUSH_DELEG_WHEN_UNCONTENDED. However, they <lb/>will have no effect unless one of following is set: <lb/>o OPEN4_SHARE_ACCESS_WANT_READ_DELEG <lb/>o OPEN4_SHARE_ACCESS_WANT_WRITE_DELEG <lb/>o OPEN4_SHARE_ACCESS_WANT_ANY_DELEG <lb/>If the client specifies <lb/>OPEN4_SHARE_ACCESS_WANT_SIGNAL_DELEG_WHEN_RESRC_AVAIL, then it wishes <lb/>to register a &quot;want&quot; for a delegation, in the event the OPEN results <lb/>do not include a delegation. If so and the server denies the <lb/>delegation due to insufficient resources, the server MAY later inform <lb/>the client, via the CB_RECALLABLE_OBJ_AVAIL operation, that the <lb/>resource limitation condition has eased. The server will tell the <lb/>client that it intends to send a future CB_RECALLABLE_OBJ_AVAIL <lb/>operation by setting delegation_type in the results to <lb/>OPEN_DELEGATE_NONE_EXT, ond_why to WND4_RESOURCE, and <lb/>ond_server_will_signal_avail set to TRUE. If <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 476] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>ond_server_will_signal_avail is set to TRUE, the server MUST later <lb/>send a CB_RECALLABLE_OBJ_AVAIL operation. <lb/>If the client specifies <lb/>OPEN4_SHARE_ACCESS_WANT_SIGNAL_DELEG_WHEN_UNCONTENDED, then it wishes <lb/>to register a &quot;want&quot; for a delegation, in the event the OPEN results <lb/>do not include a delegation. If so and the server denies the <lb/>delegation due to contention, the server MAY later inform the client, <lb/>via the CB_PUSH_DELEG operation, that the contention condition has <lb/>eased. The server will tell the client that it intends to send a <lb/>future CB_PUSH_DELEG operation by setting delegation_type in the <lb/>results to OPEN_DELEGATE_NONE_EXT, ond_why to WND4_CONTENTION, and <lb/>ond_server_will_push_deleg to TRUE. If ond_server_will_push_deleg is <lb/>TRUE, the server MUST later send a CB_PUSH_DELEG operation. <lb/>If the client has previously registered a want for a delegation on a <lb/>file, and then sends a request to register a want for a delegation on <lb/>the same file, the server MUST return a new error: <lb/>NFS4ERR_DELEG_ALREADY_WANTED. If the client wishes to register a <lb/>different type of delegation want for the same file, it MUST cancel <lb/>the existing delegation WANT. <lb/>18.16.4. IMPLEMENTATION <lb/>In absence of a persistent session, the client invokes exclusive <lb/>create by setting the how parameter to EXCLUSIVE4 or EXCLUSIVE4_1. <lb/>In these cases, the client provides a verifier that can reasonably be <lb/>expected to be unique. A combination of a client identifier, perhaps <lb/>the client network address, and a unique number generated by the <lb/>client, perhaps the RPC transaction identifier, may be appropriate. <lb/>If the object does not exist, the server creates the object and <lb/>stores the verifier in stable storage. For file systems that do not <lb/>provide a mechanism for the storage of arbitrary file attributes, the <lb/>server may use one or more elements of the object&apos;s metadata to store <lb/>the verifier. The verifier MUST be stored in stable storage to <lb/>prevent erroneous failure on retransmission of the request. It is <lb/>assumed that an exclusive create is being performed because exclusive <lb/>semantics are critical to the application. Because of the expected <lb/>usage, exclusive CREATE does not rely solely on the server&apos;s reply <lb/>cache for storage of the verifier. A nonpersistent reply cache does <lb/>not survive a crash and the session and reply cache may be deleted <lb/>after a network partition that exceeds the lease time, thus opening <lb/>failure windows. <lb/>An NFSv4.1 server SHOULD NOT store the verifier in any of the file&apos;s <lb/>RECOMMENDED or REQUIRED attributes. If it does, the server SHOULD <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 477] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>use time_modify_set or time_access_set to store the verifier. The <lb/>server SHOULD NOT store the verifier in the following attributes: <lb/>acl (it is desirable for access control to be established at <lb/>creation), <lb/>dacl (ditto), <lb/>mode (ditto), <lb/>owner (ditto), <lb/>owner_group (ditto), <lb/>retentevt_set (it may be desired to establish retention at <lb/>creation) <lb/>retention_hold (ditto), <lb/>retention_set (ditto), <lb/>sacl (it is desirable for auditing control to be established at <lb/>creation), <lb/>size (on some servers, size may have a limited range of values), <lb/>mode_set_masked (as with mode), <lb/>and <lb/>time_creation (a meaningful file creation should be set when the <lb/>file is created). <lb/>Another alternative for the server is to use a named attribute to <lb/>store the verifier. <lb/>Because the EXCLUSIVE4 create method does not specify initial <lb/>attributes when processing an EXCLUSIVE4 create, the server <lb/>o SHOULD set the owner of the file to that corresponding to the <lb/>credential of request&apos;s RPC header. <lb/>o SHOULD NOT leave the file&apos;s access control to anyone but the owner <lb/>of the file. <lb/>If the server cannot support exclusive create semantics, possibly <lb/>because of the requirement to commit the verifier to stable storage, <lb/>it should fail the OPEN request with the error NFS4ERR_NOTSUPP. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 478] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>During an exclusive CREATE request, if the object already exists, the <lb/>server reconstructs the object&apos;s verifier and compares it with the <lb/>verifier in the request. If they match, the server treats the <lb/>request as a success. The request is presumed to be a duplicate of <lb/>an earlier, successful request for which the reply was lost and that <lb/>the server duplicate request cache mechanism did not detect. If the <lb/>verifiers do not match, the request is rejected with the status <lb/>NFS4ERR_EXIST. <lb/>After the client has performed a successful exclusive create, the <lb/>attrset response indicates which attributes were used to store the <lb/>verifier. If EXCLUSIVE4 was used, the attributes set in attrset were <lb/>used for the verifier. If EXCLUSIVE4_1 was used, the client <lb/>determines the attributes used for the verifier by comparing attrset <lb/>with cva_attrs.attrmask; any bits set in the former but not the <lb/>latter identify the attributes used to store the verifier. The <lb/>client MUST immediately send a SETATTR to set attributes used to <lb/>store the verifier. Until it does so, the attributes used to store <lb/>the verifier cannot be relied upon. The subsequent SETATTR MUST NOT <lb/>occur in the same COMPOUND request as the OPEN. <lb/>Unless a persistent session is used, use of the GUARDED4 attribute <lb/>does not provide exactly once semantics. In particular, if a reply <lb/>is lost and the server does not detect the retransmission of the <lb/>request, the operation can fail with NFS4ERR_EXIST, even though the <lb/>create was performed successfully. The client would use this <lb/>behavior in the case that the application has not requested an <lb/>exclusive create but has asked to have the file truncated when the <lb/>file is opened. In the case of the client timing out and <lb/>retransmitting the create request, the client can use GUARDED4 to <lb/>prevent against a sequence like create, write, create (retransmitted) <lb/>from occurring. <lb/>For SHARE reservations, the value of the expression (share_access &amp; <lb/>~OPEN4_SHARE_ACCESS_WANT_DELEG_MASK) MUST be one of <lb/>OPEN4_SHARE_ACCESS_READ, OPEN4_SHARE_ACCESS_WRITE, or <lb/>OPEN4_SHARE_ACCESS_BOTH. If not, the server MUST return <lb/>NFS4ERR_INVAL. The value of share_deny MUST be one of <lb/>OPEN4_SHARE_DENY_NONE, OPEN4_SHARE_DENY_READ, OPEN4_SHARE_DENY_WRITE, <lb/>or OPEN4_SHARE_DENY_BOTH. If not, the server MUST return <lb/>NFS4ERR_INVAL. <lb/>Based on the share_access value (OPEN4_SHARE_ACCESS_READ, <lb/>OPEN4_SHARE_ACCESS_WRITE, or OPEN4_SHARE_ACCESS_BOTH), the client <lb/>should check that the requester has the proper access rights to <lb/>perform the specified operation. This would generally be the results <lb/>of applying the ACL access rules to the file for the current <lb/>requester. However, just as with the ACCESS operation, the client <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 479] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>should not attempt to second-guess the server&apos;s decisions, as access <lb/>rights may change and may be subject to server administrative <lb/>controls outside the ACL framework. If the requester&apos;s READ or WRITE <lb/>operation is not authorized (depending on the share_access value), <lb/>the server MUST return NFS4ERR_ACCESS. <lb/>Note that if the client ID was not created with the <lb/>EXCHGID4_FLAG_BIND_PRINC_STATEID capability set in the reply to <lb/>EXCHANGE_ID, then the server MUST NOT impose any requirement that <lb/>READs and WRITEs sent for an open file have the same credentials as <lb/>the OPEN itself, and the server is REQUIRED to perform access <lb/>checking on the READs and WRITEs themselves. Otherwise, if the reply <lb/>to EXCHANGE_ID did have EXCHGID4_FLAG_BIND_PRINC_STATEID set, then <lb/>with one exception, the credentials used in the OPEN request MUST <lb/>match those used in the READs and WRITEs, and the stateids in the <lb/>READs and WRITEs MUST match, or be derived from the stateid from the <lb/>reply to OPEN. The exception is if SP4_SSV or SP4_MACH_CRED state <lb/>protection is used, and the spo_must_allow result of EXCHANGE_ID <lb/>includes the READ and/or WRITE operations. In that case, the machine <lb/>or SSV credential will be allowed to send READ and/or WRITE. See <lb/>Section 18.35. <lb/>If the component provided to OPEN is a symbolic link, the error <lb/>NFS4ERR_SYMLINK will be returned to the client, while if it is a <lb/>directory the error NFS4ERR_ISDIR will be returned. If the component <lb/>is neither of those but not an ordinary file, the error <lb/>NFS4ERR_WRONG_TYPE is returned. If the current filehandle is not a <lb/>directory, the error NFS4ERR_NOTDIR will be returned. <lb/>The use of the OPEN4_RESULT_PRESERVE_UNLINKED result flag allows a <lb/>client to avoid the common implementation practice of renaming an <lb/>open file to &quot;.nfs&lt;unique value&gt;&quot; after it removes the file. After <lb/>the server returns OPEN4_RESULT_PRESERVE_UNLINKED, if a client sends <lb/>a REMOVE operation that would reduce the file&apos;s link count to zero, <lb/>the server SHOULD report a value of zero for the numlinks attribute <lb/>on the file. <lb/>If another client has a delegation of the file being opened that <lb/>conflicts with open being done (sometimes depending on the <lb/>share_access or share_deny value specified), the delegation(s) MUST <lb/>be recalled, and the operation cannot proceed until each such <lb/>delegation is returned or revoked. Except where this happens very <lb/>quickly, one or more NFS4ERR_DELAY errors will be returned to <lb/>requests made while delegation remains outstanding. In the case of <lb/>an OPEN_DELEGATE_WRITE delegation, any open by a different client <lb/>will conflict, while for an OPEN_DELEGATE_READ delegation, only opens <lb/>with one of the following characteristics will be considered <lb/>conflicting: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 480] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o The value of share_access includes the bit <lb/>OPEN4_SHARE_ACCESS_WRITE. <lb/>o The value of share_deny specifies OPEN4_SHARE_DENY_READ or <lb/>OPEN4_SHARE_DENY_BOTH. <lb/>o OPEN4_CREATE is specified together with UNCHECKED4, the size <lb/>attribute is specified as zero (for truncation), and an existing <lb/>file is truncated. <lb/>If OPEN4_CREATE is specified and the file does not exist and the <lb/>current filehandle designates a directory for which another client <lb/>holds a directory delegation, then, unless the delegation is such <lb/>that the situation can be resolved by sending a notification, the <lb/>delegation MUST be recalled, and the operation cannot proceed until <lb/>the delegation is returned or revoked. Except where this happens <lb/>very quickly, one or more NFS4ERR_DELAY errors will be returned to <lb/>requests made while delegation remains outstanding. <lb/>If OPEN4_CREATE is specified and the file does not exist and the <lb/>current filehandle designates a directory for which one or more <lb/>directory delegations exist, then, when those delegations request <lb/>such notifications, NOTIFY4_ADD_ENTRY will be generated as a result <lb/>of this operation. <lb/>18.16.4.1. Warning to Client Implementors <lb/>OPEN resembles LOOKUP in that it generates a filehandle for the <lb/>client to use. Unlike LOOKUP though, OPEN creates server state on <lb/>the filehandle. In normal circumstances, the client can only release <lb/>this state with a CLOSE operation. CLOSE uses the current filehandle <lb/>to determine which file to close. Therefore, the client MUST follow <lb/>every OPEN operation with a GETFH operation in the same COMPOUND <lb/>procedure. This will supply the client with the filehandle such that <lb/>CLOSE can be used appropriately. <lb/>Simply waiting for the lease on the file to expire is insufficient <lb/>because the server may maintain the state indefinitely as long as <lb/>another client does not attempt to make a conflicting access to the <lb/>same file. <lb/>See also Section 2.10.6.4. <lb/>18.17. Operation 19: OPENATTR -Open Named Attribute Directory <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 481] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.17.1. ARGUMENTS <lb/>struct OPENATTR4args { <lb/>/* CURRENT_FH: object */ <lb/>bool <lb/>createdir; <lb/>}; <lb/>18.17.2. RESULTS <lb/>struct OPENATTR4res { <lb/>/* <lb/>* If status is NFS4_OK, <lb/>* <lb/>new CURRENT_FH: named attribute <lb/>* <lb/>directory <lb/>*/ <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/>18.17.3. DESCRIPTION <lb/>The OPENATTR operation is used to obtain the filehandle of the named <lb/>attribute directory associated with the current filehandle. The <lb/>result of the OPENATTR will be a filehandle to an object of type <lb/>NF4ATTRDIR. From this filehandle, READDIR and LOOKUP operations can <lb/>be used to obtain filehandles for the various named attributes <lb/>associated with the original file system object. Filehandles <lb/>returned within the named attribute directory will designate objects <lb/>of type of NF4NAMEDATTR. <lb/>The createdir argument allows the client to signify if a named <lb/>attribute directory should be created as a result of the OPENATTR <lb/>operation. Some clients may use the OPENATTR operation with a value <lb/>of FALSE for createdir to determine if any named attributes exist for <lb/>the object. If none exist, then NFS4ERR_NOENT will be returned. If <lb/>createdir has a value of TRUE and no named attribute directory <lb/>exists, one is created and its filehandle becomes the current <lb/>filehandle. On the other hand, if createdir has a value of TRUE and <lb/>the named attribute directory already exists, no error results and <lb/>the filehandle of the existing directory becomes the current <lb/>filehandle. The creation of a named attribute directory assumes that <lb/>the server has implemented named attribute support in this fashion <lb/>and is not required to do so by this definition. <lb/>If the current file handle designates an object of type NF4NAMEDATTR <lb/>(a named attribute) or NF4ATTRDIR (a named attribute directory), an <lb/>error of NFS4ERR_WRONG_TYPE is returned to the client. Named <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 482] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>attributes or a named attribute directory MUST NOT have their own <lb/>named attributes. <lb/>18.17.4. IMPLEMENTATION <lb/>If the server does not support named attributes for the current <lb/>filehandle, an error of NFS4ERR_NOTSUPP will be returned to the <lb/>client. <lb/>18.18. Operation 21: OPEN_DOWNGRADE -Reduce Open File Access <lb/>18.18.1. ARGUMENTS <lb/>struct OPEN_DOWNGRADE4args { <lb/>/* CURRENT_FH: opened file */ <lb/>stateid4 <lb/>open_stateid; <lb/>seqid4 <lb/>seqid; <lb/>uint32_t <lb/>share_access; <lb/>uint32_t <lb/>share_deny; <lb/>}; <lb/>18.18.2. RESULTS <lb/>struct OPEN_DOWNGRADE4resok { <lb/>stateid4 <lb/>open_stateid; <lb/>}; <lb/>union OPEN_DOWNGRADE4res switch(nfsstat4 status) { <lb/>case NFS4_OK: <lb/>OPEN_DOWNGRADE4resok <lb/>resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.18.3. DESCRIPTION <lb/>This operation is used to adjust the access and deny states for a <lb/>given open. This is necessary when a given open-owner opens the same <lb/>file multiple times with different access and deny values. In this <lb/>situation, a close of one of the opens may change the appropriate <lb/>share_access and share_deny flags to remove bits associated with <lb/>opens no longer in effect. <lb/>Valid values for the expression (share_access &amp; <lb/>~OPEN4_SHARE_ACCESS_WANT_DELEG_MASK) are OPEN4_SHARE_ACCESS_READ, <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 483] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>OPEN4_SHARE_ACCESS_WRITE, or OPEN4_SHARE_ACCESS_BOTH. If the client <lb/>specifies other values, the server MUST reply with NFS4ERR_INVAL. <lb/>Valid values for the share_deny field are OPEN4_SHARE_DENY_NONE, <lb/>OPEN4_SHARE_DENY_READ, OPEN4_SHARE_DENY_WRITE, or <lb/>OPEN4_SHARE_DENY_BOTH. If the client specifies other values, the <lb/>server MUST reply with NFS4ERR_INVAL. <lb/>After checking for valid values of share_access and share_deny, the <lb/>server replaces the current access and deny modes on the file with <lb/>share_access and share_deny subject to the following constraints: <lb/>o The bits in share_access SHOULD equal the union of the <lb/>share_access bits (not including OPEN4_SHARE_WANT_* bits) <lb/>specified for some subset of the OPENs in effect for the current <lb/>open-owner on the current file. <lb/>o The bits in share_deny SHOULD equal the union of the share_deny <lb/>bits specified for some subset of the OPENs in effect for the <lb/>current open-owner on the current file. <lb/>If the above constraints are not respected, the server SHOULD return <lb/>the error NFS4ERR_INVAL. Since share_access and share_deny bits <lb/>should be subsets of those already granted, short of a defect in the <lb/>client or server implementation, it is not possible for the <lb/>OPEN_DOWNGRADE request to be denied because of conflicting share <lb/>reservations. <lb/>The seqid argument is not used in NFSv4.1, MAY be any value, and MUST <lb/>be ignored by the server. <lb/>On success, the current filehandle retains its value. <lb/>18.18.4. IMPLEMENTATION <lb/>An OPEN_DOWNGRADE operation may make OPEN_DELEGATE_READ delegations <lb/>grantable where they were not previously. Servers may choose to <lb/>respond immediately if there are pending delegation want requests or <lb/>may respond to the situation at a later time. <lb/>18.19. Operation 22: PUTFH -Set Current Filehandle <lb/>18.19.1. ARGUMENTS <lb/>struct PUTFH4args { <lb/>nfs_fh4 <lb/>object; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 484] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.19.2. RESULTS <lb/>struct PUTFH4res { <lb/>/* <lb/>* If status is NFS4_OK, <lb/>* <lb/>new CURRENT_FH: argument to PUTFH <lb/>*/ <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/>18.19.3. DESCRIPTION <lb/>This operation replaces the current filehandle with the filehandle <lb/>provided as an argument. It clears the current stateid. <lb/>If the security mechanism used by the requester does not meet the <lb/>requirements of the filehandle provided to this operation, the server <lb/>MUST return NFS4ERR_WRONGSEC. <lb/>See Section 16.2.3.1.1 for more details on the current filehandle. <lb/>See Section 16.2.3.1.2 for more details on the current stateid. <lb/>18.19.4. IMPLEMENTATION <lb/>This operation is used in an NFS request to set the context for file <lb/>accessing operations that follow in the same COMPOUND request. <lb/>18.20. Operation 23: PUTPUBFH -Set Public Filehandle <lb/>18.20.1. ARGUMENT <lb/>void; <lb/>18.20.2. RESULT <lb/>struct PUTPUBFH4res { <lb/>/* <lb/>* If status is NFS4_OK, <lb/>* <lb/>new CURRENT_FH: public fh <lb/>*/ <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 485] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.20.3. DESCRIPTION <lb/>This operation replaces the current filehandle with the filehandle <lb/>that represents the public filehandle of the server&apos;s namespace. <lb/>This filehandle may be different from the &quot;root&quot; filehandle that may <lb/>be associated with some other directory on the server. <lb/>PUTPUBFH also clears the current stateid. <lb/>The public filehandle represents the concepts embodied in RFC 2054 <lb/>[45], RFC 2055 [46], and RFC 2224 [56]. The intent for NFSv4.1 is <lb/>that the public filehandle (represented by the PUTPUBFH operation) be <lb/>used as a method of providing WebNFS server compatibility with NFSv3. <lb/>The public filehandle and the root filehandle (represented by the <lb/>PUTROOTFH operation) SHOULD be equivalent. If the public and root <lb/>filehandles are not equivalent, then the directory corresponding to <lb/>the public filehandle MUST be a descendant of the directory <lb/>corresponding to the root filehandle. <lb/>See Section 16.2.3.1.1 for more details on the current filehandle. <lb/>See Section 16.2.3.1.2 for more details on the current stateid. <lb/>18.20.4. IMPLEMENTATION <lb/>This operation is used in an NFS request to set the context for file <lb/>accessing operations that follow in the same COMPOUND request. <lb/>With the NFSv3 public filehandle, the client is able to specify <lb/>whether the pathname provided in the LOOKUP should be evaluated as <lb/>either an absolute path relative to the server&apos;s root or relative to <lb/>the public filehandle. RFC 2224 [56] contains further discussion of <lb/>the functionality. With NFSv4.1, that type of specification is not <lb/>directly available in the LOOKUP operation. The reason for this is <lb/>because the component separators needed to specify absolute vs. <lb/>relative are not allowed in NFSv4. Therefore, the client is <lb/>responsible for constructing its request such that the use of either <lb/>PUTROOTFH or PUTPUBFH signifies absolute or relative evaluation of an <lb/>NFS URL, respectively. <lb/>Note that there are warnings mentioned in RFC 2224 [56] with respect <lb/>to the use of absolute evaluation and the restrictions the server may <lb/>place on that evaluation with respect to how much of its namespace <lb/>has been made available. These same warnings apply to NFSv4.1. It <lb/>is likely, therefore, that because of server implementation details, <lb/>an NFSv3 absolute public filehandle look up may behave differently <lb/>than an NFSv4.1 absolute resolution. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 486] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>There is a form of security negotiation as described in RFC 2755 [57] <lb/>that uses the public filehandle and an overloading of the pathname. <lb/>This method is not available with NFSv4.1 as filehandles are not <lb/>overloaded with special meaning and therefore do not provide the same <lb/>framework as NFSv3. Clients should therefore use the security <lb/>negotiation mechanisms described in Section 2.6. <lb/>18.21. Operation 24: PUTROOTFH -Set Root Filehandle <lb/>18.21.1. ARGUMENTS <lb/>void; <lb/>18.21.2. RESULTS <lb/>struct PUTROOTFH4res { <lb/>/* <lb/>* If status is NFS4_OK, <lb/>* <lb/>new CURRENT_FH: root fh <lb/>*/ <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/>18.21.3. DESCRIPTION <lb/>This operation replaces the current filehandle with the filehandle <lb/>that represents the root of the server&apos;s namespace. From this <lb/>filehandle, a LOOKUP operation can locate any other filehandle on the <lb/>server. This filehandle may be different from the &quot;public&quot; <lb/>filehandle that may be associated with some other directory on the <lb/>server. <lb/>PUTROOTFH also clears the current stateid. <lb/>See Section 16.2.3.1.1 for more details on the current filehandle. <lb/>See Section 16.2.3.1.2 for more details on the current stateid. <lb/>18.21.4. IMPLEMENTATION <lb/>This operation is used in an NFS request to set the context for file <lb/>accessing operations that follow in the same COMPOUND request. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 487] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.22. Operation 25: READ -Read from File <lb/>18.22.1. ARGUMENTS <lb/>struct READ4args { <lb/>/* CURRENT_FH: file */ <lb/>stateid4 <lb/>stateid; <lb/>offset4 <lb/>offset; <lb/>count4 <lb/>count; <lb/>}; <lb/>18.22.2. RESULTS <lb/>struct READ4resok { <lb/>bool <lb/>eof; <lb/>opaque <lb/>data&lt;&gt;; <lb/>}; <lb/>union READ4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>READ4resok <lb/>resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.22.3. DESCRIPTION <lb/>The READ operation reads data from the regular file identified by the <lb/>current filehandle. <lb/>The client provides an offset of where the READ is to start and a <lb/>count of how many bytes are to be read. An offset of zero means to <lb/>read data starting at the beginning of the file. If offset is <lb/>greater than or equal to the size of the file, the status NFS4_OK is <lb/>returned with a data length set to zero and eof is set to TRUE. The <lb/>READ is subject to access permissions checking. <lb/>If the client specifies a count value of zero, the READ succeeds and <lb/>returns zero bytes of data again subject to access permissions <lb/>checking. The server may choose to return fewer bytes than specified <lb/>by the client. The client needs to check for this condition and <lb/>handle the condition appropriately. <lb/>Except when special stateids are used, the stateid value for a READ <lb/>request represents a value returned from a previous byte-range lock <lb/>or share reservation request or the stateid associated with a <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 488] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>delegation. The stateid identifies the associated owners if any and <lb/>is used by the server to verify that the associated locks are still <lb/>valid (e.g., have not been revoked). <lb/>If the read ended at the end-of-file (formally, in a correctly formed <lb/>READ operation, if offset + count is equal to the size of the file), <lb/>or the READ operation extends beyond the size of the file (if offset <lb/>+ count is greater than the size of the file), eof is returned as <lb/>TRUE; otherwise, it is FALSE. A successful READ of an empty file <lb/>will always return eof as TRUE. <lb/>If the current filehandle is not an ordinary file, an error will be <lb/>returned to the client. In the case that the current filehandle <lb/>represents an object of type NF4DIR, NFS4ERR_ISDIR is returned. If <lb/>the current filehandle designates a symbolic link, NFS4ERR_SYMLINK is <lb/>returned. In all other cases, NFS4ERR_WRONG_TYPE is returned. <lb/>For a READ with a stateid value of all bits equal to zero, the server <lb/>MAY allow the READ to be serviced subject to mandatory byte-range <lb/>locks or the current share deny modes for the file. For a READ with <lb/>a stateid value of all bits equal to one, the server MAY allow READ <lb/>operations to bypass locking checks at the server. <lb/>On success, the current filehandle retains its value. <lb/>18.22.4. IMPLEMENTATION <lb/>If the server returns a &quot;short read&quot; (i.e., fewer data than requested <lb/>and eof is set to FALSE), the client should send another READ to get <lb/>the remaining data. A server may return less data than requested <lb/>under several circumstances. The file may have been truncated by <lb/>another client or perhaps on the server itself, changing the file <lb/>size from what the requesting client believes to be the case. This <lb/>would reduce the actual amount of data available to the client. It <lb/>is possible that the server reduce the transfer size and so return a <lb/>short read result. Server resource exhaustion may also occur in a <lb/>short read. <lb/>If mandatory byte-range locking is in effect for the file, and if the <lb/>byte-range corresponding to the data to be read from the file is <lb/>WRITE_LT locked by an owner not associated with the stateid, the <lb/>server will return the NFS4ERR_LOCKED error. The client should try <lb/>to get the appropriate READ_LT via the LOCK operation before re-<lb/>attempting the READ. When the READ completes, the client should <lb/>release the byte-range lock via LOCKU. <lb/>If another client has an OPEN_DELEGATE_WRITE delegation for the file <lb/>being read, the delegation must be recalled, and the operation cannot <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 489] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>proceed until that delegation is returned or revoked. Except where <lb/>this happens very quickly, one or more NFS4ERR_DELAY errors will be <lb/>returned to requests made while the delegation remains outstanding. <lb/>Normally, delegations will not be recalled as a result of a READ <lb/>operation since the recall will occur as a result of an earlier OPEN. <lb/>However, since it is possible for a READ to be done with a special <lb/>stateid, the server needs to check for this case even though the <lb/>client should have done an OPEN previously. <lb/>18.23. Operation 26: READDIR -Read Directory <lb/>18.23.1. ARGUMENTS <lb/>struct READDIR4args { <lb/>/* CURRENT_FH: directory */ <lb/>nfs_cookie4 <lb/>cookie; <lb/>verifier4 <lb/>cookieverf; <lb/>count4 <lb/>dircount; <lb/>count4 <lb/>maxcount; <lb/>bitmap4 <lb/>attr_request; <lb/>}; <lb/>18.23.2. RESULTS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 490] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct entry4 { <lb/>nfs_cookie4 <lb/>cookie; <lb/>component4 <lb/>name; <lb/>fattr4 <lb/>attrs; <lb/>entry4 <lb/>*nextentry; <lb/>}; <lb/>struct dirlist4 { <lb/>entry4 <lb/>*entries; <lb/>bool <lb/>eof; <lb/>}; <lb/>struct READDIR4resok { <lb/>verifier4 <lb/>cookieverf; <lb/>dirlist4 <lb/>reply; <lb/>}; <lb/>union READDIR4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>READDIR4resok resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.23.3. DESCRIPTION <lb/>The READDIR operation retrieves a variable number of entries from a <lb/>file system directory and returns client-requested attributes for <lb/>each entry along with information to allow the client to request <lb/>additional directory entries in a subsequent READDIR. <lb/>The arguments contain a cookie value that represents where the <lb/>READDIR should start within the directory. A value of zero for the <lb/>cookie is used to start reading at the beginning of the directory. <lb/>For subsequent READDIR requests, the client specifies a cookie value <lb/>that is provided by the server on a previous READDIR request. <lb/>The request&apos;s cookieverf field should be set to 0 zero) when the <lb/>request&apos;s cookie field is zero (first read of the directory). On <lb/>subsequent requests, the cookieverf field must match the cookieverf <lb/>returned by the READDIR in which the cookie was acquired. If the <lb/>server determines that the cookieverf is no longer valid for the <lb/>directory, the error NFS4ERR_NOT_SAME must be returned. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 491] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The dircount field of the request is a hint of the maximum number of <lb/>bytes of directory information that should be returned. This value <lb/>represents the total length of the names of the directory entries and <lb/>the cookie value for these entries. This length represents the XDR <lb/>encoding of the data (names and cookies) and not the length in the <lb/>native format of the server. <lb/>The maxcount field of the request represents the maximum total size <lb/>of all of the data being returned within the READDIR4resok structure <lb/>and includes the XDR overhead. The server MAY return less data. If <lb/>the server is unable to return a single directory entry within the <lb/>maxcount limit, the error NFS4ERR_TOOSMALL MUST be returned to the <lb/>client. <lb/>Finally, the request&apos;s attr_request field represents the list of <lb/>attributes to be returned for each directory entry supplied by the <lb/>server. <lb/>A successful reply consists of a list of directory entries. Each of <lb/>these entries contains the name of the directory entry, a cookie <lb/>value for that entry, and the associated attributes as requested. <lb/>The &quot;eof&quot; flag has a value of TRUE if there are no more entries in <lb/>the directory. <lb/>The cookie value is only meaningful to the server and is used as a <lb/>cursor for the directory entry. As mentioned, this cookie is used by <lb/>the client for subsequent READDIR operations so that it may continue <lb/>reading a directory. The cookie is similar in concept to a READ <lb/>offset but MUST NOT be interpreted as such by the client. Ideally, <lb/>the cookie value SHOULD NOT change if the directory is modified since <lb/>the client may be caching these values. <lb/>In some cases, the server may encounter an error while obtaining the <lb/>attributes for a directory entry. Instead of returning an error for <lb/>the entire READDIR operation, the server can instead return the <lb/>attribute rdattr_error (Section 5.8.1.12). With this, the server is <lb/>able to communicate the failure to the client and not fail the entire <lb/>operation in the instance of what might be a transient failure. <lb/>Obviously, the client must request the fattr4_rdattr_error attribute <lb/>for this method to work properly. If the client does not request the <lb/>attribute, the server has no choice but to return failure for the <lb/>entire READDIR operation. <lb/>For some file system environments, the directory entries &quot;.&quot; and &quot;..&quot; <lb/>have special meaning, and in other environments, they do not. If the <lb/>server supports these special entries within a directory, they SHOULD <lb/>NOT be returned to the client as part of the READDIR response. To <lb/>enable some client environments, the cookie values of zero, 1, and 2 <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 492] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>are to be considered reserved. Note that the UNIX client will use <lb/>these values when combining the server&apos;s response and local <lb/>representations to enable a fully formed UNIX directory presentation <lb/>to the application. <lb/>For READDIR arguments, cookie values of one and two SHOULD NOT be <lb/>used, and for READDIR results, cookie values of zero, one, and two <lb/>SHOULD NOT be returned. <lb/>On success, the current filehandle retains its value. <lb/>18.23.4. IMPLEMENTATION <lb/>The server&apos;s file system directory representations can differ <lb/>greatly. A client&apos;s programming interfaces may also be bound to the <lb/>local operating environment in a way that does not translate well <lb/>into the NFS protocol. Therefore, the use of the dircount and <lb/>maxcount fields are provided to enable the client to provide hints to <lb/>the server. If the client is aggressive about attribute collection <lb/>during a READDIR, the server has an idea of how to limit the encoded <lb/>response. <lb/>If dircount is zero, the server bounds the reply&apos;s size based on the <lb/>request&apos;s maxcount field. <lb/>The cookieverf may be used by the server to help manage cookie values <lb/>that may become stale. It should be a rare occurrence that a server <lb/>is unable to continue properly reading a directory with the provided <lb/>cookie/cookieverf pair. The server SHOULD make every effort to avoid <lb/>this condition since the application at the client might be unable to <lb/>properly handle this type of failure. <lb/>The use of the cookieverf will also protect the client from using <lb/>READDIR cookie values that might be stale. For example, if the file <lb/>system has been migrated, the server might or might not be able to <lb/>use the same cookie values to service READDIR as the previous server <lb/>used. With the client providing the cookieverf, the server is able <lb/>to provide the appropriate response to the client. This prevents the <lb/>case where the server accepts a cookie value but the underlying <lb/>directory has changed and the response is invalid from the client&apos;s <lb/>context of its previous READDIR. <lb/>Since some servers will not be returning &quot;.&quot; and &quot;..&quot; entries as has <lb/>been done with previous versions of the NFS protocol, the client that <lb/>requires these entries be present in READDIR responses must fabricate <lb/>them. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 493] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.24. Operation 27: READLINK -Read Symbolic Link <lb/>18.24.1. ARGUMENTS <lb/>/* CURRENT_FH: symlink */ <lb/>void; <lb/>18.24.2. RESULTS <lb/>struct READLINK4resok { <lb/>linktext4 <lb/>link; <lb/>}; <lb/>union READLINK4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>READLINK4resok resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.24.3. DESCRIPTION <lb/>READLINK reads the data associated with a symbolic link. Depending <lb/>on the value of the UTF-8 capability attribute (Section 14.4), the <lb/>data is encoded in UTF-8. Whether created by an NFS client or <lb/>created locally on the server, the data in a symbolic link is not <lb/>interpreted (except possibly to check for proper UTF-8 encoding) when <lb/>created, but is simply stored. <lb/>On success, the current filehandle retains its value. <lb/>18.24.4. IMPLEMENTATION <lb/>A symbolic link is nominally a pointer to another file. The data is <lb/>not necessarily interpreted by the server, just stored in the file. <lb/>It is possible for a client implementation to store a pathname that <lb/>is not meaningful to the server operating system in a symbolic link. <lb/>A READLINK operation returns the data to the client for <lb/>interpretation. If different implementations want to share access to <lb/>symbolic links, then they must agree on the interpretation of the <lb/>data in the symbolic link. <lb/>The READLINK operation is only allowed on objects of type NF4LNK. <lb/>The server should return the error NFS4ERR_WRONG_TYPE if the object <lb/>is not of type NF4LNK. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 494] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.25. Operation 28: REMOVE -Remove File System Object <lb/>18.25.1. ARGUMENTS <lb/>struct REMOVE4args { <lb/>/* CURRENT_FH: directory */ <lb/>component4 <lb/>target; <lb/>}; <lb/>18.25.2. RESULTS <lb/>struct REMOVE4resok { <lb/>change_info4 <lb/>cinfo; <lb/>}; <lb/>union REMOVE4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>REMOVE4resok <lb/>resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.25.3. DESCRIPTION <lb/>The REMOVE operation removes (deletes) a directory entry named by <lb/>filename from the directory corresponding to the current filehandle. <lb/>If the entry in the directory was the last reference to the <lb/>corresponding file system object, the object may be destroyed. The <lb/>directory may be either of type NF4DIR or NF4ATTRDIR. <lb/>For the directory where the filename was removed, the server returns <lb/>change_info4 information in cinfo. With the atomic field of the <lb/>change_info4 data type, the server will indicate if the before and <lb/>after change attributes were obtained atomically with respect to the <lb/>removal. <lb/>If the target has a length of zero, or if the target does not obey <lb/>the UTF-8 definition (and the server is enforcing UTF-8 encoding; see <lb/>Section 14.4), the error NFS4ERR_INVAL will be returned. <lb/>On success, the current filehandle retains its value. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 495] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.25.4. IMPLEMENTATION <lb/>NFSv3 required a different operator RMDIR for directory removal and <lb/>REMOVE for non-directory removal. This allowed clients to skip <lb/>checking the file type when being passed a non-directory delete <lb/>system call (e.g., unlink() [24] in POSIX) to remove a directory, as <lb/>well as the converse (e.g., a rmdir() on a non-directory) because <lb/>they knew the server would check the file type. NFSv4.1 REMOVE can <lb/>be used to delete any directory entry independent of its file type. <lb/>The implementor of an NFSv4.1 client&apos;s entry points from the unlink() <lb/>and rmdir() system calls should first check the file type against the <lb/>types the system call is allowed to remove before sending a REMOVE <lb/>operation. Alternatively, the implementor can produce a COMPOUND <lb/>call that includes a LOOKUP/VERIFY sequence of operations to verify <lb/>the file type before a REMOVE operation in the same COMPOUND call. <lb/>The concept of last reference is server specific. However, if the <lb/>numlinks field in the previous attributes of the object had the value <lb/>1, the client should not rely on referring to the object via a <lb/>filehandle. Likewise, the client should not rely on the resources <lb/>(disk space, directory entry, and so on) formerly associated with the <lb/>object becoming immediately available. Thus, if a client needs to be <lb/>able to continue to access a file after using REMOVE to remove it, <lb/>the client should take steps to make sure that the file will still be <lb/>accessible. While the traditional mechanism used is to RENAME the <lb/>file from its old name to a new hidden name, the NFSv4.1 OPEN <lb/>operation MAY return a result flag, OPEN4_RESULT_PRESERVE_UNLINKED, <lb/>which indicates to the client that the file will be preserved if the <lb/>file has an outstanding open (see Section 18.16). <lb/>If the server finds that the file is still open when the REMOVE <lb/>arrives: <lb/>o The server SHOULD NOT delete the file&apos;s directory entry if the <lb/>file was opened with OPEN4_SHARE_DENY_WRITE or <lb/>OPEN4_SHARE_DENY_BOTH. <lb/>o If the file was not opened with OPEN4_SHARE_DENY_WRITE or <lb/>OPEN4_SHARE_DENY_BOTH, the server SHOULD delete the file&apos;s <lb/>directory entry. However, until last CLOSE of the file, the <lb/>server MAY continue to allow access to the file via its <lb/>filehandle. <lb/>o The server MUST NOT delete the directory entry if the reply from <lb/>OPEN had the flag OPEN4_RESULT_PRESERVE_UNLINKED set. <lb/>The server MAY implement its own restrictions on removal of a file <lb/>while it is open. The server might disallow such a REMOVE (or a <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 496] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>removal that occurs as part of RENAME). The conditions that <lb/>influence the restrictions on removal of a file while it is still <lb/>open include: <lb/>o Whether certain access protocols (i.e., not just NFS) are holding <lb/>the file open. <lb/>o Whether particular options, access modes, or policies on the <lb/>server are enabled. <lb/>If a file has an outstanding OPEN and this prevents the removal of <lb/>the file&apos;s directory entry, the error NFS4ERR_FILE_OPEN is returned. <lb/>Where the determination above cannot be made definitively because <lb/>delegations are being held, they MUST be recalled to allow processing <lb/>of the REMOVE to continue. When a delegation is held, the server has <lb/>no reliable knowledge of the status of OPENs for that client, so <lb/>unless there are files opened with the particular deny modes by <lb/>clients without delegations, the determination cannot be made until <lb/>delegations are recalled, and the operation cannot proceed until each <lb/>sufficient delegation has been returned or revoked to allow the <lb/>server to make a correct determination. <lb/>In all cases in which delegations are recalled, the server is likely <lb/>to return one or more NFS4ERR_DELAY errors while delegations remain <lb/>outstanding. <lb/>If the current filehandle designates a directory for which another <lb/>client holds a directory delegation, then, unless the situation can <lb/>be resolved by sending a notification, the directory delegation MUST <lb/>be recalled, and the operation MUST NOT proceed until the delegation <lb/>is returned or revoked. Except where this happens very quickly, one <lb/>or more NFS4ERR_DELAY errors will be returned to requests made while <lb/>delegation remains outstanding. <lb/>When the current filehandle designates a directory for which one or <lb/>more directory delegations exist, then, when those delegations <lb/>request such notifications, NOTIFY4_REMOVE_ENTRY will be generated as <lb/>a result of this operation. <lb/>Note that when a remove occurs as a result of a RENAME, <lb/>NOTIFY4_REMOVE_ENTRY will only be generated if the removal happens as <lb/>a separate operation. In the case in which the removal is integrated <lb/>and atomic with RENAME, the notification of the removal is integrated <lb/>with notification for the RENAME. See the discussion of the <lb/>NOTIFY4_RENAME_ENTRY notification in Section 20.4. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 497] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.26. Operation 29: RENAME -Rename Directory Entry <lb/>18.26.1. ARGUMENTS <lb/>struct RENAME4args { <lb/>/* SAVED_FH: source directory */ <lb/>component4 <lb/>oldname; <lb/>/* CURRENT_FH: target directory */ <lb/>component4 <lb/>newname; <lb/>}; <lb/>18.26.2. RESULTS <lb/>struct RENAME4resok { <lb/>change_info4 <lb/>source_cinfo; <lb/>change_info4 <lb/>target_cinfo; <lb/>}; <lb/>union RENAME4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>RENAME4resok <lb/>resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.26.3. DESCRIPTION <lb/>The RENAME operation renames the object identified by oldname in the <lb/>source directory corresponding to the saved filehandle, as set by the <lb/>SAVEFH operation, to newname in the target directory corresponding to <lb/>the current filehandle. The operation is required to be atomic to <lb/>the client. Source and target directories MUST reside on the same <lb/>file system on the server. On success, the current filehandle will <lb/>continue to be the target directory. <lb/>If the target directory already contains an entry with the name <lb/>newname, the source object MUST be compatible with the target: either <lb/>both are non-directories or both are directories and the target MUST <lb/>be empty. If compatible, the existing target is removed before the <lb/>rename occurs or, preferably, the target is removed atomically as <lb/>part of the rename. See Section 18.25.4 for client and server <lb/>actions whenever a target is removed. Note however that when the <lb/>removal is performed atomically with the rename, certain parts of the <lb/>removal described there are integrated with the rename. For example, <lb/>notification of the removal will not be via a NOTIFY4_REMOVE_ENTRY <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 498] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>but will be indicated as part of the NOTIFY4_ADD_ENTRY or <lb/>NOTIFY4_RENAME_ENTRY generated by the rename. <lb/>If the source object and the target are not compatible or if the <lb/>target is a directory but not empty, the server will return the error <lb/>NFS4ERR_EXIST. <lb/>If oldname and newname both refer to the same file (e.g., they might <lb/>be hard links of each other), then unless the file is open (see <lb/>Section 18.26.4), RENAME MUST perform no action and return NFS4_OK. <lb/>For both directories involved in the RENAME, the server returns <lb/>change_info4 information. With the atomic field of the change_info4 <lb/>data type, the server will indicate if the before and after change <lb/>attributes were obtained atomically with respect to the rename. <lb/>If oldname refers to a named attribute and the saved and current <lb/>filehandles refer to different file system objects, the server will <lb/>return NFS4ERR_XDEV just as if the saved and current filehandles <lb/>represented directories on different file systems. <lb/>If oldname or newname has a length of zero, or if oldname or newname <lb/>does not obey the UTF-8 definition, the error NFS4ERR_INVAL will be <lb/>returned. <lb/>18.26.4. IMPLEMENTATION <lb/>The server MAY impose restrictions on the RENAME operation such that <lb/>RENAME may not be done when the file being renamed is open or when <lb/>that open is done by particular protocols, or with particular options <lb/>or access modes. Similar restrictions may be applied when a file <lb/>exists with the target name and is open. When RENAME is rejected <lb/>because of such restrictions, the error NFS4ERR_FILE_OPEN is <lb/>returned. <lb/>When oldname and rename refer to the same file and that file is open <lb/>in a fashion such that RENAME would normally be rejected with <lb/>NFS4ERR_FILE_OPEN if oldname and newname were different files, then <lb/>RENAME SHOULD be rejected with NFS4ERR_FILE_OPEN. <lb/>If a server does implement such restrictions and those restrictions <lb/>include cases of NFSv4 opens preventing successful execution of a <lb/>rename, the server needs to recall any delegations that could hide <lb/>the existence of opens relevant to that decision. This is because <lb/>when a client holds a delegation, the server might not have an <lb/>accurate account of the opens for that client, since the client may <lb/>execute OPENs and CLOSEs locally. The RENAME operation need only be <lb/>delayed until a definitive result can be obtained. For example, if <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 499] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>there are multiple delegations and one of them establishes an open <lb/>whose presence would prevent the rename, given the server&apos;s <lb/>semantics, NFS4ERR_FILE_OPEN may be returned to the caller as soon as <lb/>that delegation is returned without waiting for other delegations to <lb/>be returned. Similarly, if such opens are not associated with <lb/>delegations, NFS4ERR_FILE_OPEN can be returned immediately with no <lb/>delegation recall being done. <lb/>If the current filehandle or the saved filehandle designates a <lb/>directory for which another client holds a directory delegation, <lb/>then, unless the situation can be resolved by sending a notification, <lb/>the delegation MUST be recalled, and the operation cannot proceed <lb/>until the delegation is returned or revoked. Except where this <lb/>happens very quickly, one or more NFS4ERR_DELAY errors will be <lb/>returned to requests made while delegation remains outstanding. <lb/>When the current and saved filehandles are the same and they <lb/>designate a directory for which one or more directory delegations <lb/>exist, then, when those delegations request such notifications, a <lb/>notification of type NOTIFY4_RENAME_ENTRY will be generated as a <lb/>result of this operation. When oldname and rename refer to the same <lb/>file, no notification is generated (because, as Section 18.26.3 <lb/>states, the server MUST take no action). When a file is removed <lb/>because it has the same name as the target, if that removal is done <lb/>atomically with the rename, a NOTIFY4_REMOVE_ENTRY notification will <lb/>not be generated. Instead, the deletion of the file will be reported <lb/>as part of the NOTIFY4_RENAME_ENTRY notification. <lb/>When the current and saved filehandles are not the same: <lb/>o If the current filehandle designates a directory for which one or <lb/>more directory delegations exist, then, when those delegations <lb/>request such notifications, NOTIFY4_ADD_ENTRY will be generated as <lb/>a result of this operation. When a file is removed because it has <lb/>the same name as the target, if that removal is done atomically <lb/>with the rename, a NOTIFY4_REMOVE_ENTRY notification will not be <lb/>generated. Instead, the deletion of the file will be reported as <lb/>part of the NOTIFY4_ADD_ENTRY notification. <lb/>o If the saved filehandle designates a directory for which one or <lb/>more directory delegations exist, then, when those delegations <lb/>request such notifications, NOTIFY4_REMOVE_ENTRY will be generated <lb/>as a result of this operation. <lb/>If the object being renamed has file delegations held by clients <lb/>other than the one doing the RENAME, the delegations MUST be <lb/>recalled, and the operation cannot proceed until each such delegation <lb/>is returned or revoked. Note that in the case of multiply linked <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 500] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>files, the delegation recall requirement applies even if the <lb/>delegation was obtained through a different name than the one being <lb/>renamed. In all cases in which delegations are recalled, the server <lb/>is likely to return one or more NFS4ERR_DELAY errors while the <lb/>delegation(s) remains outstanding, although it might not do that if <lb/>the delegations are returned quickly. <lb/>The RENAME operation must be atomic to the client. The statement <lb/>&quot;source and target directories MUST reside on the same file system on <lb/>the server&quot; means that the fsid fields in the attributes for the <lb/>directories are the same. If they reside on different file systems, <lb/>the error NFS4ERR_XDEV is returned. <lb/>Based on the value of the fh_expire_type attribute for the object, <lb/>the filehandle may or may not expire on a RENAME. However, server <lb/>implementors are strongly encouraged to attempt to keep filehandles <lb/>from expiring in this fashion. <lb/>On some servers, the file names &quot;.&quot; and &quot;..&quot; are illegal as either <lb/>oldname or newname, and will result in the error NFS4ERR_BADNAME. In <lb/>addition, on many servers the case of oldname or newname being an <lb/>alias for the source directory will be checked for. Such servers <lb/>will return the error NFS4ERR_INVAL in these cases. <lb/>If either of the source or target filehandles are not directories, <lb/>the server will return NFS4ERR_NOTDIR. <lb/>18.27. Operation 31: RESTOREFH -Restore Saved Filehandle <lb/>18.27.1. ARGUMENTS <lb/>/* SAVED_FH: */ <lb/>void; <lb/>18.27.2. RESULTS <lb/>struct RESTOREFH4res { <lb/>/* <lb/>* If status is NFS4_OK, <lb/>* <lb/>new CURRENT_FH: value of saved fh <lb/>*/ <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 501] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.27.3. DESCRIPTION <lb/>The RESTOREFH operation sets the current filehandle and stateid to <lb/>the values in the saved filehandle and stateid. If there is no saved <lb/>filehandle, then the server will return the error <lb/>NFS4ERR_NOFILEHANDLE. <lb/>See Section 16.2.3.1.1 for more details on the current filehandle. <lb/>See Section 16.2.3.1.2 for more details on the current stateid. <lb/>18.27.4. IMPLEMENTATION <lb/>Operations like OPEN and LOOKUP use the current filehandle to <lb/>represent a directory and replace it with a new filehandle. Assuming <lb/>that the previous filehandle was saved with a SAVEFH operator, the <lb/>previous filehandle can be restored as the current filehandle. This <lb/>is commonly used to obtain post-operation attributes for the <lb/>directory, e.g., <lb/>PUTFH (directory filehandle) <lb/>SAVEFH <lb/>GETATTR attrbits <lb/>(pre-op dir attrs) <lb/>CREATE optbits &quot;foo&quot; attrs <lb/>GETATTR attrbits <lb/>(file attributes) <lb/>RESTOREFH <lb/>GETATTR attrbits <lb/>(post-op dir attrs) <lb/>18.28. Operation 32: SAVEFH -Save Current Filehandle <lb/>18.28.1. ARGUMENTS <lb/>/* CURRENT_FH: */ <lb/>void; <lb/>18.28.2. RESULTS <lb/>struct SAVEFH4res { <lb/>/* <lb/>* If status is NFS4_OK, <lb/>* <lb/>new SAVED_FH: value of current fh <lb/>*/ <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 502] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.28.3. DESCRIPTION <lb/>The SAVEFH operation saves the current filehandle and stateid. If a <lb/>previous filehandle was saved, then it is no longer accessible. The <lb/>saved filehandle can be restored as the current filehandle with the <lb/>RESTOREFH operator. <lb/>On success, the current filehandle retains its value. <lb/>See Section 16.2.3.1.1 for more details on the current filehandle. <lb/>See Section 16.2.3.1.2 for more details on the current stateid. <lb/>18.28.4. IMPLEMENTATION <lb/>18.29. Operation 33: SECINFO -Obtain Available Security <lb/>18.29.1. ARGUMENTS <lb/>struct SECINFO4args { <lb/>/* CURRENT_FH: directory */ <lb/>component4 <lb/>name; <lb/>}; <lb/>18.29.2. RESULTS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 503] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>/* <lb/>* From RFC 2203 <lb/>*/ <lb/>enum rpc_gss_svc_t { <lb/>RPC_GSS_SVC_NONE <lb/>= 1, <lb/>RPC_GSS_SVC_INTEGRITY <lb/>= 2, <lb/>RPC_GSS_SVC_PRIVACY <lb/>= 3 <lb/>}; <lb/>struct rpcsec_gss_info { <lb/>sec_oid4 <lb/>oid; <lb/>qop4 <lb/>qop; <lb/>rpc_gss_svc_t <lb/>service; <lb/>}; <lb/>/* RPCSEC_GSS has a value of &apos;6&apos; -See RFC 2203 */ <lb/>union secinfo4 switch (uint32_t flavor) { <lb/>case RPCSEC_GSS: <lb/>rpcsec_gss_info <lb/>flavor_info; <lb/>default: <lb/>void; <lb/>}; <lb/>typedef secinfo4 SECINFO4resok&lt;&gt;; <lb/>union SECINFO4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>/* CURRENTFH: consumed */ <lb/>SECINFO4resok resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.29.3. DESCRIPTION <lb/>The SECINFO operation is used by the client to obtain a list of valid <lb/>RPC authentication flavors for a specific directory filehandle, file <lb/>name pair. SECINFO should apply the same access methodology used for <lb/>LOOKUP when evaluating the name. Therefore, if the requester does <lb/>not have the appropriate access to LOOKUP the name, then SECINFO MUST <lb/>behave the same way and return NFS4ERR_ACCESS. <lb/>The result will contain an array that represents the security <lb/>mechanisms available, with an order corresponding to the server&apos;s <lb/>preferences, the most preferred being first in the array. The client <lb/>is free to pick whatever security mechanism it both desires and <lb/>supports, or to pick in the server&apos;s preference order the first one <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 504] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>it supports. The array entries are represented by the secinfo4 <lb/>structure. The field &apos;flavor&apos; will contain a value of AUTH_NONE, <lb/>AUTH_SYS (as defined in RFC 5531 [3]), or RPCSEC_GSS (as defined in <lb/>RFC 2203 [4]). The field flavor can also be any other security <lb/>flavor registered with IANA. <lb/>For the flavors AUTH_NONE and AUTH_SYS, no additional security <lb/>information is returned. The same is true of many (if not most) <lb/>other security flavors, including AUTH_DH. For a return value of <lb/>RPCSEC_GSS, a security triple is returned that contains the mechanism <lb/>object identifier (OID, as defined in RFC 2743 [7]), the quality of <lb/>protection (as defined in RFC 2743 [7]), and the service type (as <lb/>defined in RFC 2203 [4]). It is possible for SECINFO to return <lb/>multiple entries with flavor equal to RPCSEC_GSS with different <lb/>security triple values. <lb/>On success, the current filehandle is consumed (see <lb/>Section 2.6.3.1.1.8), and if the next operation after SECINFO tries <lb/>to use the current filehandle, that operation will fail with the <lb/>status NFS4ERR_NOFILEHANDLE. <lb/>If the name has a length of zero, or if the name does not obey the <lb/>UTF-8 definition (assuming UTF-8 capabilities are enabled; see <lb/>Section 14.4), the error NFS4ERR_INVAL will be returned. <lb/>See Section 2.6 for additional information on the use of SECINFO. <lb/>18.29.4. IMPLEMENTATION <lb/>The SECINFO operation is expected to be used by the NFS client when <lb/>the error value of NFS4ERR_WRONGSEC is returned from another NFS <lb/>operation. This signifies to the client that the server&apos;s security <lb/>policy is different from what the client is currently using. At this <lb/>point, the client is expected to obtain a list of possible security <lb/>flavors and choose what best suits its policies. <lb/>As mentioned, the server&apos;s security policies will determine when a <lb/>client request receives NFS4ERR_WRONGSEC. See Table 8 for a list of <lb/>operations that can return NFS4ERR_WRONGSEC. In addition, when <lb/>READDIR returns attributes, the rdattr_error (Section 5.8.1.12) can <lb/>contain NFS4ERR_WRONGSEC. Note that CREATE and REMOVE MUST NOT <lb/>return NFS4ERR_WRONGSEC. The rationale for CREATE is that unless the <lb/>target name exists, it cannot have a separate security policy from <lb/>the parent directory, and the security policy of the parent was <lb/>checked when its filehandle was injected into the COMPOUND request&apos;s <lb/>operations stream (for similar reasons, an OPEN operation that <lb/>creates the target MUST NOT return NFS4ERR_WRONGSEC). If the target <lb/>name exists, while it might have a separate security policy, that is <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 505] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>irrelevant because CREATE MUST return NFS4ERR_EXIST. The rationale <lb/>for REMOVE is that while that target might have a separate security <lb/>policy, the target is going to be removed, and so the security policy <lb/>of the parent trumps that of the object being removed. RENAME and <lb/>LINK MAY return NFS4ERR_WRONGSEC, but the NFS4ERR_WRONGSEC error <lb/>applies only to the saved filehandle (see Section 2.6.3.1.2). Any <lb/>NFS4ERR_WRONGSEC error on the current filehandle used by LINK and <lb/>RENAME MUST be returned by the PUTFH, PUTPUBFH, PUTROOTFH, or <lb/>RESTOREFH operation that injected the current filehandle. <lb/>With the exception of LINK and RENAME, the set of operations that can <lb/>return NFS4ERR_WRONGSEC represents the point at which the client can <lb/>inject a filehandle into the &quot;current filehandle&quot; at the server. The <lb/>filehandle is either provided by the client (PUTFH, PUTPUBFH, <lb/>PUTROOTFH), generated as a result of a name-to-filehandle translation <lb/>(LOOKUP and OPEN), or generated from the saved filehandle via <lb/>RESTOREFH. As Section 2.6.3.1.1.1 states, a put filehandle operation <lb/>followed by SAVEFH MUST NOT return NFS4ERR_WRONGSEC. Thus, the <lb/>RESTOREFH operation, under certain conditions (see <lb/>Section 2.6.3.1.1), is permitted to return NFS4ERR_WRONGSEC so that <lb/>security policies can be honored. <lb/>The READDIR operation will not directly return the NFS4ERR_WRONGSEC <lb/>error. However, if the READDIR request included a request for <lb/>attributes, it is possible that the READDIR request&apos;s security triple <lb/>did not match that of a directory entry. If this is the case and the <lb/>client has requested the rdattr_error attribute, the server will <lb/>return the NFS4ERR_WRONGSEC error in rdattr_error for the entry. <lb/>To resolve an error return of NFS4ERR_WRONGSEC, the client does the <lb/>following: <lb/>o For LOOKUP and OPEN, the client will use SECINFO with the same <lb/>current filehandle and name as provided in the original LOOKUP or <lb/>OPEN to enumerate the available security triples. <lb/>o For the rdattr_error, the client will use SECINFO with the same <lb/>current filehandle as provided in the original READDIR. The name <lb/>passed to SECINFO will be that of the directory entry (as returned <lb/>from READDIR) that had the NFS4ERR_WRONGSEC error in the <lb/>rdattr_error attribute. <lb/>o For PUTFH, PUTROOTFH, PUTPUBFH, RESTOREFH, LINK, and RENAME, the <lb/>client will use SECINFO_NO_NAME { style = <lb/>SECINFO_STYLE4_CURRENT_FH }. The client will prefix the <lb/>SECINFO_NO_NAME operation with the appropriate PUTFH, PUTPUBFH, or <lb/>PUTROOTFH operation that provides the filehandle originally <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 506] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>provided by the PUTFH, PUTPUBFH, PUTROOTFH, or RESTOREFH <lb/>operation. <lb/>NOTE: In NFSv4.0, the client was required to use SECINFO, and had <lb/>to reconstruct the parent of the original filehandle and the <lb/>component name of the original filehandle. The introduction in <lb/>NFSv4.1 of SECINFO_NO_NAME obviates the need for reconstruction. <lb/>o For LOOKUPP, the client will use SECINFO_NO_NAME { style = <lb/>SECINFO_STYLE4_PARENT } and provide the filehandle that equals the <lb/>filehandle originally provided to LOOKUPP. <lb/>See Section 21 for a discussion on the recommendations for the <lb/>security flavor used by SECINFO and SECINFO_NO_NAME. <lb/>18.30. Operation 34: SETATTR -Set Attributes <lb/>18.30.1. ARGUMENTS <lb/>struct SETATTR4args { <lb/>/* CURRENT_FH: target object */ <lb/>stateid4 <lb/>stateid; <lb/>fattr4 <lb/>obj_attributes; <lb/>}; <lb/>18.30.2. RESULTS <lb/>struct SETATTR4res { <lb/>nfsstat4 <lb/>status; <lb/>bitmap4 <lb/>attrsset; <lb/>}; <lb/>18.30.3. DESCRIPTION <lb/>The SETATTR operation changes one or more of the attributes of a file <lb/>system object. The new attributes are specified with a bitmap and <lb/>the attributes that follow the bitmap in bit order. <lb/>The stateid argument for SETATTR is used to provide byte-range <lb/>locking context that is necessary for SETATTR requests that set the <lb/>size attribute. Since setting the size attribute modifies the file&apos;s <lb/>data, it has the same locking requirements as a corresponding WRITE. <lb/>Any SETATTR that sets the size attribute is incompatible with a share <lb/>reservation that specifies OPEN4_SHARE_DENY_WRITE. The area between <lb/>the old end-of-file and the new end-of-file is considered to be <lb/>modified just as would have been the case had the area in question <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 507] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>been specified as the target of WRITE, for the purpose of checking <lb/>conflicts with byte-range locks, for those cases in which a server is <lb/>implementing mandatory byte-range locking behavior. A valid stateid <lb/>SHOULD always be specified. When the file size attribute is not set, <lb/>the special stateid consisting of all bits equal to zero MAY be <lb/>passed. <lb/>On either success or failure of the operation, the server will return <lb/>the attrsset bitmask to represent what (if any) attributes were <lb/>successfully set. The attrsset in the response is a subset of the <lb/>attrmask field of the obj_attributes field in the argument. <lb/>On success, the current filehandle retains its value. <lb/>18.30.4. IMPLEMENTATION <lb/>If the request specifies the owner attribute to be set, the server <lb/>SHOULD allow the operation to succeed if the current owner of the <lb/>object matches the value specified in the request. Some servers may <lb/>be implemented in a way as to prohibit the setting of the owner <lb/>attribute unless the requester has privilege to do so. If the server <lb/>is lenient in this one case of matching owner values, the client <lb/>implementation may be simplified in cases of creation of an object <lb/>(e.g., an exclusive create via OPEN) followed by a SETATTR. <lb/>The file size attribute is used to request changes to the size of a <lb/>file. A value of zero causes the file to be truncated, a value less <lb/>than the current size of the file causes data from new size to the <lb/>end of the file to be discarded, and a size greater than the current <lb/>size of the file causes logically zeroed data bytes to be added to <lb/>the end of the file. Servers are free to implement this using <lb/>unallocated bytes (holes) or allocated data bytes set to zero. <lb/>Clients should not make any assumptions regarding a server&apos;s <lb/>implementation of this feature, beyond that the bytes in the affected <lb/>byte-range returned by READ will be zeroed. Servers MUST support <lb/>extending the file size via SETATTR. <lb/>SETATTR is not guaranteed to be atomic. A failed SETATTR may <lb/>partially change a file&apos;s attributes, hence the reason why the reply <lb/>always includes the status and the list of attributes that were set. <lb/>If the object whose attributes are being changed has a file <lb/>delegation that is held by a client other than the one doing the <lb/>SETATTR, the delegation(s) must be recalled, and the operation cannot <lb/>proceed to actually change an attribute until each such delegation is <lb/>returned or revoked. In all cases in which delegations are recalled, <lb/>the server is likely to return one or more NFS4ERR_DELAY errors while <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 508] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the delegation(s) remains outstanding, although it might not do that <lb/>if the delegations are returned quickly. <lb/>If the object whose attributes are being set is a directory and <lb/>another client holds a directory delegation for that directory, then <lb/>if enabled, asynchronous notifications will be generated when the set <lb/>of attributes changed has a non-null intersection with the set of <lb/>attributes for which notification is requested. Notifications of <lb/>type NOTIFY4_CHANGE_DIR_ATTRS will be sent to the appropriate <lb/>client(s), but the SETATTR is not delayed by waiting for these <lb/>notifications to be sent. <lb/>If the object whose attributes are being set is a member of the <lb/>directory for which another client holds a directory delegation, then <lb/>asynchronous notifications will be generated when the set of <lb/>attributes changed has a non-null intersection with the set of <lb/>attributes for which notification is requested. Notifications of <lb/>type NOTIFY4_CHANGE_CHILD_ATTRS will be sent to the appropriate <lb/>clients, but the SETATTR is not delayed by waiting for these <lb/>notifications to be sent. <lb/>Changing the size of a file with SETATTR indirectly changes the <lb/>time_modify and change attributes. A client must account for this as <lb/>size changes can result in data deletion. <lb/>The attributes time_access_set and time_modify_set are write-only <lb/>attributes constructed as a switched union so the client can direct <lb/>the server in setting the time values. If the switched union <lb/>specifies SET_TO_CLIENT_TIME4, the client has provided an nfstime4 to <lb/>be used for the operation. If the switch union does not specify <lb/>SET_TO_CLIENT_TIME4, the server is to use its current time for the <lb/>SETATTR operation. <lb/>If server and client times differ, programs that compare client time <lb/>to file times can break. A time synchronization protocol should be <lb/>used to limit client/server time skew. <lb/>Use of a COMPOUND containing a VERIFY operation specifying only the <lb/>change attribute, immediately followed by a SETATTR, provides a means <lb/>whereby a client may specify a request that emulates the <lb/>functionality of the SETATTR guard mechanism of NFSv3. Since the <lb/>function of the guard mechanism is to avoid changes to the file <lb/>attributes based on stale information, delays between checking of the <lb/>guard condition and the setting of the attributes have the potential <lb/>to compromise this function, as would the corresponding delay in the <lb/>NFSv4 emulation. Therefore, NFSv4.1 servers SHOULD take care to <lb/>avoid such delays, to the degree possible, when executing such a <lb/>request. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 509] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If the server does not support an attribute as requested by the <lb/>client, the server SHOULD return NFS4ERR_ATTRNOTSUPP. <lb/>A mask of the attributes actually set is returned by SETATTR in all <lb/>cases. That mask MUST NOT include attribute bits not requested to be <lb/>set by the client. If the attribute masks in the request and reply <lb/>are equal, the status field in the reply MUST be NFS4_OK. <lb/>18.31. Operation 37: VERIFY -Verify Same Attributes <lb/>18.31.1. ARGUMENTS <lb/>struct VERIFY4args { <lb/>/* CURRENT_FH: object */ <lb/>fattr4 <lb/>obj_attributes; <lb/>}; <lb/>18.31.2. RESULTS <lb/>struct VERIFY4res { <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/>18.31.3. DESCRIPTION <lb/>The VERIFY operation is used to verify that attributes have the value <lb/>assumed by the client before proceeding with the following operations <lb/>in the COMPOUND request. If any of the attributes do not match, then <lb/>the error NFS4ERR_NOT_SAME must be returned. The current filehandle <lb/>retains its value after successful completion of the operation. <lb/>18.31.4. IMPLEMENTATION <lb/>One possible use of the VERIFY operation is the following series of <lb/>operations. With this, the client is attempting to verify that the <lb/>file being removed will match what the client expects to be removed. <lb/>This series can help prevent the unintended deletion of a file. <lb/>PUTFH (directory filehandle) <lb/>LOOKUP (file name) <lb/>VERIFY (filehandle == fh) <lb/>PUTFH (directory filehandle) <lb/>REMOVE (file name) <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 510] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>This series does not prevent a second client from removing and <lb/>creating a new file in the middle of this sequence, but it does help <lb/>avoid the unintended result. <lb/>In the case that a RECOMMENDED attribute is specified in the VERIFY <lb/>operation and the server does not support that attribute for the file <lb/>system object, the error NFS4ERR_ATTRNOTSUPP is returned to the <lb/>client. <lb/>When the attribute rdattr_error or any set-only attribute (e.g., <lb/>time_modify_set) is specified, the error NFS4ERR_INVAL is returned to <lb/>the client. <lb/>18.32. Operation 38: WRITE -Write to File <lb/>18.32.1. ARGUMENTS <lb/>enum stable_how4 { <lb/>UNSTABLE4 <lb/>= 0, <lb/>DATA_SYNC4 <lb/>= 1, <lb/>FILE_SYNC4 <lb/>= 2 <lb/>}; <lb/>struct WRITE4args { <lb/>/* CURRENT_FH: file */ <lb/>stateid4 <lb/>stateid; <lb/>offset4 <lb/>offset; <lb/>stable_how4 <lb/>stable; <lb/>opaque <lb/>data&lt;&gt;; <lb/>}; <lb/>18.32.2. RESULTS <lb/>struct WRITE4resok { <lb/>count4 <lb/>count; <lb/>stable_how4 <lb/>committed; <lb/>verifier4 <lb/>writeverf; <lb/>}; <lb/>union WRITE4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>WRITE4resok <lb/>resok4; <lb/>default: <lb/>void; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 511] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.32.3. DESCRIPTION <lb/>The WRITE operation is used to write data to a regular file. The <lb/>target file is specified by the current filehandle. The offset <lb/>specifies the offset where the data should be written. An offset of <lb/>zero specifies that the write should start at the beginning of the <lb/>file. The count, as encoded as part of the opaque data parameter, <lb/>represents the number of bytes of data that are to be written. If <lb/>the count is zero, the WRITE will succeed and return a count of zero <lb/>subject to permissions checking. The server MAY write fewer bytes <lb/>than requested by the client. <lb/>The client specifies with the stable parameter the method of how the <lb/>data is to be processed by the server. If stable is FILE_SYNC4, the <lb/>server MUST commit the data written plus all file system metadata to <lb/>stable storage before returning results. This corresponds to the <lb/>NFSv2 protocol semantics. Any other behavior constitutes a protocol <lb/>violation. If stable is DATA_SYNC4, then the server MUST commit all <lb/>of the data to stable storage and enough of the metadata to retrieve <lb/>the data before returning. The server implementor is free to <lb/>implement DATA_SYNC4 in the same fashion as FILE_SYNC4, but with a <lb/>possible performance drop. If stable is UNSTABLE4, the server is <lb/>free to commit any part of the data and the metadata to stable <lb/>storage, including all or none, before returning a reply to the <lb/>client. There is no guarantee whether or when any uncommitted data <lb/>will subsequently be committed to stable storage. The only <lb/>guarantees made by the server are that it will not destroy any data <lb/>without changing the value of writeverf and that it will not commit <lb/>the data and metadata at a level less than that requested by the <lb/>client. <lb/>Except when special stateids are used, the stateid value for a WRITE <lb/>request represents a value returned from a previous byte-range LOCK <lb/>or OPEN request or the stateid associated with a delegation. The <lb/>stateid identifies the associated owners if any and is used by the <lb/>server to verify that the associated locks are still valid (e.g., <lb/>have not been revoked). <lb/>Upon successful completion, the following results are returned. The <lb/>count result is the number of bytes of data written to the file. The <lb/>server may write fewer bytes than requested. If so, the actual <lb/>number of bytes written starting at location, offset, is returned. <lb/>The server also returns an indication of the level of commitment of <lb/>the data and metadata via committed. Per Table 11, <lb/>o The server MAY commit the data at a stronger level than requested. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 512] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o The server MUST commit the data at a level at least as high as <lb/>that committed. <lb/>Valid combinations of the fields stable in the request and committed <lb/>in the reply. <lb/>+------------+-----------------------------------+ <lb/>| stable <lb/>| committed <lb/>| <lb/>+------------+-----------------------------------+ <lb/>| UNSTABLE4 | FILE_SYNC4, DATA_SYNC4, UNSTABLE4 | <lb/>| DATA_SYNC4 | FILE_SYNC4, DATA_SYNC4 <lb/>| <lb/>| FILE_SYNC4 | FILE_SYNC4 <lb/>| <lb/>+------------+-----------------------------------+ <lb/>Table 11 <lb/>The final portion of the result is the field writeverf. This field <lb/>is the write verifier and is a cookie that the client can use to <lb/>determine whether a server has changed instance state (e.g., server <lb/>restart) between a call to WRITE and a subsequent call to either <lb/>WRITE or COMMIT. This cookie MUST be unchanged during a single <lb/>instance of the NFSv4.1 server and MUST be unique between instances <lb/>of the NFSv4.1 server. If the cookie changes, then the client MUST <lb/>assume that any data written with an UNSTABLE4 value for committed <lb/>and an old writeverf in the reply has been lost and will need to be <lb/>recovered. <lb/>If a client writes data to the server with the stable argument set to <lb/>UNSTABLE4 and the reply yields a committed response of DATA_SYNC4 or <lb/>UNSTABLE4, the client will follow up some time in the future with a <lb/>COMMIT operation to synchronize outstanding asynchronous data and <lb/>metadata with the server&apos;s stable storage, barring client error. It <lb/>is possible that due to client crash or other error that a subsequent <lb/>COMMIT will not be received by the server. <lb/>For a WRITE with a stateid value of all bits equal to zero, the <lb/>server MAY allow the WRITE to be serviced subject to mandatory byte-<lb/>range locks or the current share deny modes for the file. For a <lb/>WRITE with a stateid value of all bits equal to 1, the server MUST <lb/>NOT allow the WRITE operation to bypass locking checks at the server <lb/>and otherwise is treated as if a stateid of all bits equal to zero <lb/>were used. <lb/>On success, the current filehandle retains its value. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 513] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.32.4. IMPLEMENTATION <lb/>It is possible for the server to write fewer bytes of data than <lb/>requested by the client. In this case, the server SHOULD NOT return <lb/>an error unless no data was written at all. If the server writes <lb/>less than the number of bytes specified, the client will need to send <lb/>another WRITE to write the remaining data. <lb/>It is assumed that the act of writing data to a file will cause the <lb/>time_modified and change attributes of the file to be updated. <lb/>However, these attributes SHOULD NOT be changed unless the contents <lb/>of the file are changed. Thus, a WRITE request with count set to <lb/>zero SHOULD NOT cause the time_modified and change attributes of the <lb/>file to be updated. <lb/>Stable storage is persistent storage that survives: <lb/>1. Repeated power failures. <lb/>2. Hardware failures (of any board, power supply, etc.). <lb/>3. Repeated software crashes and restarts. <lb/>This definition does not address failure of the stable storage module <lb/>itself. <lb/>The verifier is defined to allow a client to detect different <lb/>instances of an NFSv4.1 protocol server over which cached, <lb/>uncommitted data may be lost. In the most likely case, the verifier <lb/>allows the client to detect server restarts. This information is <lb/>required so that the client can safely determine whether the server <lb/>could have lost cached data. If the server fails unexpectedly and <lb/>the client has uncommitted data from previous WRITE requests (done <lb/>with the stable argument set to UNSTABLE4 and in which the result <lb/>committed was returned as UNSTABLE4 as well), the server might not <lb/>have flushed cached data to stable storage. The burden of recovery <lb/>is on the client, and the client will need to retransmit the data to <lb/>the server. <lb/>A suggested verifier would be to use the time that the server was <lb/>last started (if restarting the server results in lost buffers). <lb/>The reply&apos;s committed field allows the client to do more effective <lb/>caching. If the server is committing all WRITE requests to stable <lb/>storage, then it SHOULD return with committed set to FILE_SYNC4, <lb/>regardless of the value of the stable field in the arguments. A <lb/>server that uses an NVRAM accelerator may choose to implement this <lb/>policy. The client can use this to increase the effectiveness of the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 514] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>cache by discarding cached data that has already been committed on <lb/>the server. <lb/>Some implementations may return NFS4ERR_NOSPC instead of <lb/>NFS4ERR_DQUOT when a user&apos;s quota is exceeded. <lb/>In the case that the current filehandle is of type NF4DIR, the server <lb/>will return NFS4ERR_ISDIR. If the current file is a symbolic link, <lb/>the error NFS4ERR_SYMLINK will be returned. Otherwise, if the <lb/>current filehandle does not designate an ordinary file, the server <lb/>will return NFS4ERR_WRONG_TYPE. <lb/>If mandatory byte-range locking is in effect for the file, and the <lb/>corresponding byte-range of the data to be written to the file is <lb/>READ_LT or WRITE_LT locked by an owner that is not associated with <lb/>the stateid, the server MUST return NFS4ERR_LOCKED. If so, the <lb/>client MUST check if the owner corresponding to the stateid used with <lb/>the WRITE operation has a conflicting READ_LT lock that overlaps with <lb/>the byte-range that was to be written. If the stateid&apos;s owner has no <lb/>conflicting READ_LT lock, then the client SHOULD try to get the <lb/>appropriate write byte-range lock via the LOCK operation before re-<lb/>attempting the WRITE. When the WRITE completes, the client SHOULD <lb/>release the byte-range lock via LOCKU. <lb/>If the stateid&apos;s owner had a conflicting READ_LT lock, then the <lb/>client has no choice but to return an error to the application that <lb/>attempted the WRITE. The reason is that since the stateid&apos;s owner <lb/>had a READ_LT lock, either the server attempted to temporarily <lb/>effectively upgrade this READ_LT lock to a WRITE_LT lock or the <lb/>server has no upgrade capability. If the server attempted to upgrade <lb/>the READ_LT lock and failed, it is pointless for the client to re-<lb/>attempt the upgrade via the LOCK operation, because there might be <lb/>another client also trying to upgrade. If two clients are blocked <lb/>trying to upgrade the same lock, the clients deadlock. If the server <lb/>has no upgrade capability, then it is pointless to try a LOCK <lb/>operation to upgrade. <lb/>If one or more other clients have delegations for the file being <lb/>written, those delegations MUST be recalled, and the operation cannot <lb/>proceed until those delegations are returned or revoked. Except <lb/>where this happens very quickly, one or more NFS4ERR_DELAY errors <lb/>will be returned to requests made while the delegation remains <lb/>outstanding. Normally, delegations will not be recalled as a result <lb/>of a WRITE operation since the recall will occur as a result of an <lb/>earlier OPEN. However, since it is possible for a WRITE to be done <lb/>with a special stateid, the server needs to check for this case even <lb/>though the client should have done an OPEN previously. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 515] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.33. Operation 40: BACKCHANNEL_CTL -Backchannel Control <lb/>18.33.1. ARGUMENT <lb/>typedef opaque gsshandle4_t&lt;&gt;; <lb/>struct gss_cb_handles4 { <lb/>rpc_gss_svc_t <lb/>gcbp_service; /* RFC 2203 */ <lb/>gsshandle4_t <lb/>gcbp_handle_from_server; <lb/>gsshandle4_t <lb/>gcbp_handle_from_client; <lb/>}; <lb/>union callback_sec_parms4 switch (uint32_t cb_secflavor) { <lb/>case AUTH_NONE: <lb/>void; <lb/>case AUTH_SYS: <lb/>authsys_parms <lb/>cbsp_sys_cred; /* RFC 1831 */ <lb/>case RPCSEC_GSS: <lb/>gss_cb_handles4 cbsp_gss_handles; <lb/>}; <lb/>struct BACKCHANNEL_CTL4args { <lb/>uint32_t <lb/>bca_cb_program; <lb/>callback_sec_parms4 <lb/>bca_sec_parms&lt;&gt;; <lb/>}; <lb/>18.33.2. RESULT <lb/>struct BACKCHANNEL_CTL4res { <lb/>nfsstat4 <lb/>bcr_status; <lb/>}; <lb/>18.33.3. DESCRIPTION <lb/>The BACKCHANNEL_CTL operation replaces the backchannel&apos;s callback <lb/>program number and adds (not replaces) RPCSEC_GSS handles for use by <lb/>the backchannel. <lb/>The arguments of the BACKCHANNEL_CTL call are a subset of the <lb/>CREATE_SESSION parameters. In the arguments of BACKCHANNEL_CTL, the <lb/>bca_cb_program field and bca_sec_parms fields correspond respectively <lb/>to the csa_cb_program and csa_sec_parms fields of the arguments of <lb/>CREATE_SESSION (Section 18.36). <lb/>BACKCHANNEL_CTL MUST appear in a COMPOUND that starts with SEQUENCE. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 516] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If the RPCSEC_GSS handle identified by gcbp_handle_from_server does <lb/>not exist on the server, the server MUST return NFS4ERR_NOENT. <lb/>If an RPCSEC_GSS handle is using the SSV context (see <lb/>Section 2.10.9), then because each SSV RPCSEC_GSS handle shares a <lb/>common SSV GSS context, there are security considerations specific to <lb/>this situation discussed in Section 2.10.10. <lb/>18.34. Operation 41: BIND_CONN_TO_SESSION -Associate Connection with <lb/>Session <lb/>18.34.1. ARGUMENT <lb/>enum channel_dir_from_client4 { <lb/>CDFC4_FORE <lb/>= 0x1, <lb/>CDFC4_BACK <lb/>= 0x2, <lb/>CDFC4_FORE_OR_BOTH <lb/>= 0x3, <lb/>CDFC4_BACK_OR_BOTH <lb/>= 0x7 <lb/>}; <lb/>struct BIND_CONN_TO_SESSION4args { <lb/>sessionid4 <lb/>bctsa_sessid; <lb/>channel_dir_from_client4 <lb/>bctsa_dir; <lb/>bool <lb/>bctsa_use_conn_in_rdma_mode; <lb/>}; <lb/>18.34.2. RESULT <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 517] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>enum channel_dir_from_server4 { <lb/>CDFS4_FORE <lb/>= 0x1, <lb/>CDFS4_BACK <lb/>= 0x2, <lb/>CDFS4_BOTH <lb/>= 0x3 <lb/>}; <lb/>struct BIND_CONN_TO_SESSION4resok { <lb/>sessionid4 <lb/>bctsr_sessid; <lb/>channel_dir_from_server4 <lb/>bctsr_dir; <lb/>bool <lb/>bctsr_use_conn_in_rdma_mode; <lb/>}; <lb/>union BIND_CONN_TO_SESSION4res <lb/>switch (nfsstat4 bctsr_status) { <lb/>case NFS4_OK: <lb/>BIND_CONN_TO_SESSION4resok <lb/>bctsr_resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.34.3. DESCRIPTION <lb/>BIND_CONN_TO_SESSION is used to associate additional connections with <lb/>a session. It MUST be used on the connection being associated with <lb/>the session. It MUST be the only operation in the COMPOUND <lb/>procedure. If SP4_NONE (Section 18.35) state protection is used, any <lb/>principal, security flavor, or RPCSEC_GSS context MAY be used to <lb/>invoke the operation. If SP4_MACH_CRED is used, RPCSEC_GSS MUST be <lb/>used with the integrity or privacy services, using the principal that <lb/>created the client ID. If SP4_SSV is used, RPCSEC_GSS with the SSV <lb/>GSS mechanism (Section 2.10.9) and integrity or privacy MUST be used. <lb/>If, when the client ID was created, the client opted for SP4_NONE <lb/>state protection, the client is not required to use <lb/>BIND_CONN_TO_SESSION to associate the connection with the session, <lb/>unless the client wishes to associate the connection with the <lb/>backchannel. When SP4_NONE protection is used, simply sending a <lb/>COMPOUND request with a SEQUENCE operation is sufficient to associate <lb/>the connection with the session specified in SEQUENCE. <lb/>The field bctsa_dir indicates whether the client wants to associate <lb/>the connection with the fore channel or the backchannel or both <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 518] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>channels. The value CDFC4_FORE_OR_BOTH indicates that the client <lb/>wants to associate the connection with both the fore channel and <lb/>backchannel, but will accept the connection being associated to just <lb/>the fore channel. The value CDFC4_BACK_OR_BOTH indicates that the <lb/>client wants to associate with both the fore channel and backchannel, <lb/>but will accept the connection being associated with just the <lb/>backchannel. The server replies in bctsr_dir which channel(s) the <lb/>connection is associated with. If the client specified CDFC4_FORE, <lb/>the server MUST return CDFS4_FORE. If the client specified <lb/>CDFC4_BACK, the server MUST return CDFS4_BACK. If the client <lb/>specified CDFC4_FORE_OR_BOTH, the server MUST return CDFS4_FORE or <lb/>CDFS4_BOTH. If the client specified CDFC4_BACK_OR_BOTH, the server <lb/>MUST return CDFS4_BACK or CDFS4_BOTH. <lb/>See the CREATE_SESSION operation (Section 18.36), and the description <lb/>of the argument csa_use_conn_in_rdma_mode to understand <lb/>bctsa_use_conn_in_rdma_mode, and the description of <lb/>csr_use_conn_in_rdma_mode to understand bctsr_use_conn_in_rdma_mode. <lb/>Invoking BIND_CONN_TO_SESSION on a connection already associated with <lb/>the specified session has no effect, and the server MUST respond with <lb/>NFS4_OK, unless the client is demanding changes to the set of <lb/>channels the connection is associated with. If so, the server MUST <lb/>return NFS4ERR_INVAL. <lb/>18.34.4. IMPLEMENTATION <lb/>If a session&apos;s channel loses all connections, depending on the client <lb/>ID&apos;s state protection and type of channel, the client might need to <lb/>use BIND_CONN_TO_SESSION to associate a new connection. If the <lb/>server restarted and does not keep the reply cache in stable storage, <lb/>the server will not recognize the session ID. The client will <lb/>ultimately have to invoke EXCHANGE_ID to create a new client ID and <lb/>session. <lb/>Suppose SP4_SSV state protection is being used, and <lb/>BIND_CONN_TO_SESSION is among the operations included in the <lb/>spo_must_enforce set when the client ID was created (Section 18.35). <lb/>If so, there is an issue if SET_SSV is sent, no response is returned, <lb/>and the last connection associated with the client ID drops. The <lb/>client, per the sessions model, MUST retry the SET_SSV. But it needs <lb/>a new connection to do so, and MUST associate that connection with <lb/>the session via a BIND_CONN_TO_SESSION authenticated with the SSV GSS <lb/>mechanism. The problem is that the RPCSEC_GSS message integrity <lb/>codes use a subkey derived from the SSV as the key and the SSV may <lb/>have changed. While there are multiple recovery strategies, a <lb/>single, general strategy is described here. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 519] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o The client reconnects. <lb/>o The client assumes that the SET_SSV was executed, and so sends <lb/>BIND_CONN_TO_SESSION with the subkey (derived from the new SSV, <lb/>i.e., what SET_SSV would have set the SSV to) used as the key for <lb/>the RPCSEC_GSS credential message integrity codes. <lb/>o If the request succeeds, this means that the original attempted <lb/>SET_SSV did execute successfully. The client re-sends the <lb/>original SET_SSV, which the server will reply to via the reply <lb/>cache. <lb/>o If the server returns an RPC authentication error, this means that <lb/>the server&apos;s current SSV was not changed (and the SET_SSV was <lb/>likely not executed). The client then tries BIND_CONN_TO_SESSION <lb/>with the subkey derived from the old SSV as the key for the <lb/>RPCSEC_GSS message integrity codes. <lb/>o The attempted BIND_CONN_TO_SESSION with the old SSV should <lb/>succeed. If so, the client re-sends the original SET_SSV. If the <lb/>original SET_SSV was not executed, then the server executes it. <lb/>If the original SET_SSV was executed but failed, the server will <lb/>return the SET_SSV from the reply cache. <lb/>18.35. Operation 42: EXCHANGE_ID -Instantiate Client ID <lb/>The EXCHANGE_ID operation exchanges long-hand client and server <lb/>identifiers (owners), and provides access to a client ID, creating <lb/>one if necessary. This client ID becomes associated with the <lb/>connection on which the operation is done, so that it is available <lb/>when a CREATE_SESSION is done or when the connection is used to issue <lb/>a request on an existing session associated with the current client. <lb/>18.35.1. ARGUMENT <lb/>const EXCHGID4_FLAG_SUPP_MOVED_REFER <lb/>= 0x00000001; <lb/>const EXCHGID4_FLAG_SUPP_MOVED_MIGR <lb/>= 0x00000002; <lb/>const EXCHGID4_FLAG_BIND_PRINC_STATEID = 0x00000100; <lb/>const EXCHGID4_FLAG_USE_NON_PNFS <lb/>= 0x00010000; <lb/>const EXCHGID4_FLAG_USE_PNFS_MDS <lb/>= 0x00020000; <lb/>const EXCHGID4_FLAG_USE_PNFS_DS <lb/>= 0x00040000; <lb/>const EXCHGID4_FLAG_MASK_PNFS <lb/>= 0x00070000; <lb/>const EXCHGID4_FLAG_UPD_CONFIRMED_REC_A = 0x40000000; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 520] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>const EXCHGID4_FLAG_CONFIRMED_R <lb/>= 0x80000000; <lb/>struct state_protect_ops4 { <lb/>bitmap4 spo_must_enforce; <lb/>bitmap4 spo_must_allow; <lb/>}; <lb/>struct ssv_sp_parms4 { <lb/>state_protect_ops4 <lb/>ssp_ops; <lb/>sec_oid4 <lb/>ssp_hash_algs&lt;&gt;; <lb/>sec_oid4 <lb/>ssp_encr_algs&lt;&gt;; <lb/>uint32_t <lb/>ssp_window; <lb/>uint32_t <lb/>ssp_num_gss_handles; <lb/>}; <lb/>enum state_protect_how4 { <lb/>SP4_NONE = 0, <lb/>SP4_MACH_CRED = 1, <lb/>SP4_SSV = 2 <lb/>}; <lb/>union state_protect4_a switch(state_protect_how4 spa_how) { <lb/>case SP4_NONE: <lb/>void; <lb/>case SP4_MACH_CRED: <lb/>state_protect_ops4 <lb/>spa_mach_ops; <lb/>case SP4_SSV: <lb/>ssv_sp_parms4 <lb/>spa_ssv_parms; <lb/>}; <lb/>struct EXCHANGE_ID4args { <lb/>client_owner4 <lb/>eia_clientowner; <lb/>uint32_t <lb/>eia_flags; <lb/>state_protect4_a <lb/>eia_state_protect; <lb/>nfs_impl_id4 <lb/>eia_client_impl_id&lt;1&gt;; <lb/>}; <lb/>18.35.2. RESULT <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 521] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct ssv_prot_info4 { <lb/>state_protect_ops4 <lb/>spi_ops; <lb/>uint32_t <lb/>spi_hash_alg; <lb/>uint32_t <lb/>spi_encr_alg; <lb/>uint32_t <lb/>spi_ssv_len; <lb/>uint32_t <lb/>spi_window; <lb/>gsshandle4_t <lb/>spi_handles&lt;&gt;; <lb/>}; <lb/>union state_protect4_r switch(state_protect_how4 spr_how) { <lb/>case SP4_NONE: <lb/>void; <lb/>case SP4_MACH_CRED: <lb/>state_protect_ops4 <lb/>spr_mach_ops; <lb/>case SP4_SSV: <lb/>ssv_prot_info4 <lb/>spr_ssv_info; <lb/>}; <lb/>struct EXCHANGE_ID4resok { <lb/>clientid4 <lb/>eir_clientid; <lb/>sequenceid4 <lb/>eir_sequenceid; <lb/>uint32_t <lb/>eir_flags; <lb/>state_protect4_r eir_state_protect; <lb/>server_owner4 <lb/>eir_server_owner; <lb/>opaque <lb/>eir_server_scope&lt;NFS4_OPAQUE_LIMIT&gt;; <lb/>nfs_impl_id4 <lb/>eir_server_impl_id&lt;1&gt;; <lb/>}; <lb/>union EXCHANGE_ID4res switch (nfsstat4 eir_status) { <lb/>case NFS4_OK: <lb/>EXCHANGE_ID4resok <lb/>eir_resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.35.3. DESCRIPTION <lb/>The client uses the EXCHANGE_ID operation to register a particular <lb/>client_owner with the server. However, when the client_owner has <lb/>already been registered by other means (e.g. Transparent State <lb/>Migration), the client may still use EXCHANGE_ID to obtain the client <lb/>ID assigned previously. <lb/>The client ID returned from this operation will be associated with <lb/>the connection on which the EXCHANGE_ID is received and will serve as <lb/>a parent object for sessions created by the client on this connection <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 522] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>or to which the connection is bound. As a result of using those <lb/>sessions to make requests involving the creation of state, that state <lb/>will become associated with the client ID returned. <lb/>In situations in which the registration of the client_owner has not <lb/>occurred previously, the client ID must first be used, along with the <lb/>returned eir_sequenceid, in creating an associated session using <lb/>CREATE_SESSION. <lb/>If the flag EXCHGID4_FLAG_CONFIRMED_R is set in the result, <lb/>eir_flags, then it is an indication that the registration of the <lb/>client_owner has already occurred and that a further CREATE_SESSION <lb/>is not needed to confirm it. Of course, subsequent CREATE_SESSION <lb/>operations may be needed for other reasons. <lb/>The value eir_sequenceid is used to establish an initial sequence <lb/>value associate with the client ID returned. In cases in which a <lb/>CREATE_SESSION has already been done, there is no need for this <lb/>value, since sequencing of such request has already been established <lb/>and the client has no need for this value and will ignore it <lb/>EXCHANGE_ID MAY be sent in a COMPOUND procedure that starts with <lb/>SEQUENCE. However, when a client communicates with a server for the <lb/>first time, it will not have a session, so using SEQUENCE will not be <lb/>possible. If EXCHANGE_ID is sent without a preceding SEQUENCE, then <lb/>it MUST be the only operation in the COMPOUND procedure&apos;s request. <lb/>If it is not, the server MUST return NFS4ERR_NOT_ONLY_OP. <lb/>The eia_clientowner field is composed of a co_verifier field and a <lb/>co_ownerid string. As noted in s Section 2.4, the co_ownerid <lb/>describes the client, and the co_verifier is the incarnation of the <lb/>client. An EXCHANGE_ID sent with a new incarnation of the client <lb/>will lead to the server removing lock state of the old incarnation. <lb/>Whereas an EXCHANGE_ID sent with the current incarnation and <lb/>co_ownerid will result in an error or an update of the client ID&apos;s <lb/>properties, depending on the arguments to EXCHANGE_ID. <lb/>A server MUST NOT provide the same client ID to two different <lb/>incarnations of an eia_clientowner. <lb/>In addition to the client ID and sequence ID, the server returns a <lb/>server owner (eir_server_owner) and server scope (eir_server_scope). <lb/>The former field is used in connection with network trunking as <lb/>described in Section 2.10.5. The latter field is used to allow <lb/>clients to determine when client IDs sent by one server may be <lb/>recognized by another in the event of file system migration (see <lb/>Section 11.10.9 of the current document). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 523] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The client ID returned by EXCHANGE_ID is only unique relative to the <lb/>combination of eir_server_owner.so_major_id and eir_server_scope. <lb/>Thus, if two servers return the same client ID, the onus is on the <lb/>client to distinguish the client IDs on the basis of <lb/>eir_server_owner.so_major_id and eir_server_scope. In the event two <lb/>different servers claim matching server_owner.so_major_id and <lb/>eir_server_scope, the client can use the verification techniques <lb/>discussed in Section 2.10.5.1 to determine if the servers are <lb/>distinct. If they are distinct, then the client will need to note <lb/>the destination network addresses of the connections used with each <lb/>server and use the network address as the final discriminator. <lb/>The server, as defined by the unique identity expressed in the <lb/>so_major_id of the server owner and the server scope, needs to track <lb/>several properties of each client ID it hands out. The properties <lb/>apply to the client ID and all sessions associated with the client <lb/>ID. The properties are derived from the arguments and results of <lb/>EXCHANGE_ID. The client ID properties include: <lb/>o The capabilities expressed by the following bits, which come from <lb/>the results of EXCHANGE_ID: <lb/>* EXCHGID4_FLAG_SUPP_MOVED_REFER <lb/>* EXCHGID4_FLAG_SUPP_MOVED_MIGR <lb/>* EXCHGID4_FLAG_BIND_PRINC_STATEID <lb/>* EXCHGID4_FLAG_USE_NON_PNFS <lb/>* EXCHGID4_FLAG_USE_PNFS_MDS <lb/>* EXCHGID4_FLAG_USE_PNFS_DS <lb/>These properties may be updated by subsequent EXCHANGE_ID <lb/>operations on confirmed client IDs though the server MAY refuse to <lb/>change them. <lb/>o The state protection method used, one of SP4_NONE, SP4_MACH_CRED, <lb/>or SP4_SSV, as set by the spa_how field of the arguments to <lb/>EXCHANGE_ID. Once the client ID is confirmed, this property <lb/>cannot be updated by subsequent EXCHANGE_ID operations. <lb/>o For SP4_MACH_CRED or SP4_SSV state protection: <lb/>* The list of operations (spo_must_enforce) that MUST use the <lb/>specified state protection. This list comes from the results <lb/>of EXCHANGE_ID. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 524] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>* The list of operations (spo_must_allow) that MAY use the <lb/>specified state protection. This list comes from the results <lb/>of EXCHANGE_ID. <lb/>Once the client ID is confirmed, these properties cannot be <lb/>updated by subsequent EXCHANGE_ID requests. <lb/>o For SP4_SSV protection: <lb/>* The OID of the hash algorithm. This property is represented by <lb/>one of the algorithms in the ssp_hash_algs field of the <lb/>EXCHANGE_ID arguments. Once the client ID is confirmed, this <lb/>property cannot be updated by subsequent EXCHANGE_ID requests. <lb/>* The OID of the encryption algorithm. This property is <lb/>represented by one of the algorithms in the ssp_encr_algs field <lb/>of the EXCHANGE_ID arguments. Once the client ID is confirmed, <lb/>this property cannot be updated by subsequent EXCHANGE_ID <lb/>requests. <lb/>* The length of the SSV. This property is represented by the <lb/>spi_ssv_len field in the EXCHANGE_ID results. Once the client <lb/>ID is confirmed, this property cannot be updated by subsequent <lb/>EXCHANGE_ID operations. <lb/>There are REQUIRED and RECOMMENDED relationships among the <lb/>length of the key of the encryption algorithm (&quot;key length&quot;), <lb/>the length of the output of hash algorithm (&quot;hash length&quot;), and <lb/>the length of the SSV (&quot;SSV length&quot;). <lb/>+ key length MUST be &lt;= hash length. This is because the keys <lb/>used for the encryption algorithm are actually subkeys <lb/>derived from the SSV, and the derivation is via the hash <lb/>algorithm. The selection of an encryption algorithm with a <lb/>key length that exceeded the length of the output of the <lb/>hash algorithm would require padding, and thus weaken the <lb/>use of the encryption algorithm. <lb/>+ hash length SHOULD be &lt;= SSV length. This is because the <lb/>SSV is a key used to derive subkeys via an HMAC, and it is <lb/>recommended that the key used as input to an HMAC be at <lb/>least as long as the length of the HMAC&apos;s hash algorithm&apos;s <lb/>output (see Section 3 of [59]). <lb/>+ key length SHOULD be &lt;= SSV length. This is a transitive <lb/>result of the above two invariants. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 525] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>+ key length SHOULD be &gt;= hash length / 2. This is because <lb/>the subkey derivation is via an HMAC and it is recommended <lb/>that if the HMAC has to be truncated, it should not be <lb/>truncated to less than half the hash length (see Section 4 <lb/>of RFC2104 [59]). <lb/>* Number of concurrent versions of the SSV the client and server <lb/>will support (see Section 2.10.9). This property is <lb/>represented by spi_window in the EXCHANGE_ID results. The <lb/>property may be updated by subsequent EXCHANGE_ID operations. <lb/>o The client&apos;s implementation ID as represented by the <lb/>eia_client_impl_id field of the arguments. The property may be <lb/>updated by subsequent EXCHANGE_ID requests. <lb/>o The server&apos;s implementation ID as represented by the <lb/>eir_server_impl_id field of the reply. The property may be <lb/>updated by replies to subsequent EXCHANGE_ID requests. <lb/>The eia_flags passed as part of the arguments and the eir_flags <lb/>results allow the client and server to inform each other of their <lb/>capabilities as well as indicate how the client ID will be used. <lb/>Whether a bit is set or cleared on the arguments&apos; flags does not <lb/>force the server to set or clear the same bit on the results&apos; side. <lb/>Bits not defined above cannot be set in the eia_flags field. If they <lb/>are, the server MUST reject the operation with NFS4ERR_INVAL. <lb/>The EXCHGID4_FLAG_UPD_CONFIRMED_REC_A bit can only be set in <lb/>eia_flags; it is always off in eir_flags. The <lb/>EXCHGID4_FLAG_CONFIRMED_R bit can only be set in eir_flags; it is <lb/>always off in eia_flags. If the server recognizes the co_ownerid and <lb/>co_verifier as mapping to a confirmed client ID, it sets <lb/>EXCHGID4_FLAG_CONFIRMED_R in eir_flags. The <lb/>EXCHGID4_FLAG_CONFIRMED_R flag allows a client to tell if the client <lb/>ID it is trying to create already exists and is confirmed. <lb/>If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is set in eia_flags, this means <lb/>that the client is attempting to update properties of an existing <lb/>confirmed client ID (if the client wants to update properties of an <lb/>unconfirmed client ID, it MUST NOT set <lb/>EXCHGID4_FLAG_UPD_CONFIRMED_REC_A). If so, it is RECOMMENDED that <lb/>the client send the update EXCHANGE_ID operation in the same COMPOUND <lb/>as a SEQUENCE so that the EXCHANGE_ID is executed exactly once. <lb/>Whether the client can update the properties of client ID depends on <lb/>the state protection it selected when the client ID was created, and <lb/>the principal and security flavor it used when sending the <lb/>EXCHANGE_ID operation. The situations described in items 6, 7, 8, or <lb/>9 of the second numbered list of Section 18.35.4 below will apply. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 526] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Note that if the operation succeeds and returns a client ID that is <lb/>already confirmed, the server MUST set the EXCHGID4_FLAG_CONFIRMED_R <lb/>bit in eir_flags. <lb/>If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is not set in eia_flags, this <lb/>means that the client is trying to establish a new client ID; it is <lb/>attempting to trunk data communication to the server (See <lb/>Section 2.10.5); or it is attempting to update properties of an <lb/>unconfirmed client ID. The situations described in items 1, 2, 3, 4, <lb/>or 5 of the second numbered list of Section 18.35.4 below will apply. <lb/>Note that if the operation succeeds and returns a client ID that was <lb/>previously confirmed, the server MUST set the <lb/>EXCHGID4_FLAG_CONFIRMED_R bit in eir_flags. <lb/>When the EXCHGID4_FLAG_SUPP_MOVED_REFER flag bit is set, the client <lb/>indicates that it is capable of dealing with an NFS4ERR_MOVED error <lb/>as part of a referral sequence. When this bit is not set, it is <lb/>still legal for the server to perform a referral sequence. However, <lb/>a server may use the fact that the client is incapable of correctly <lb/>responding to a referral, by avoiding it for that particular client. <lb/>It may, for instance, act as a proxy for that particular file system, <lb/>at some cost in performance, although it is not obligated to do so. <lb/>If the server will potentially perform a referral, it MUST set <lb/>EXCHGID4_FLAG_SUPP_MOVED_REFER in eir_flags. <lb/>When the EXCHGID4_FLAG_SUPP_MOVED_MIGR is set, the client indicates <lb/>that it is capable of dealing with an NFS4ERR_MOVED error as part of <lb/>a file system migration sequence. When this bit is not set, it is <lb/>still legal for the server to indicate that a file system has moved, <lb/>when this in fact happens. However, a server may use the fact that <lb/>the client is incapable of correctly responding to a migration in its <lb/>scheduling of file systems to migrate so as to avoid migration of <lb/>file systems being actively used. It may also hide actual migrations <lb/>from clients unable to deal with them by acting as a proxy for a <lb/>migrated file system for particular clients, at some cost in <lb/>performance, although it is not obligated to do so. If the server <lb/>will potentially perform a migration, it MUST set <lb/>EXCHGID4_FLAG_SUPP_MOVED_MIGR in eir_flags. <lb/>When EXCHGID4_FLAG_BIND_PRINC_STATEID is set, the client indicates <lb/>that it wants the server to bind the stateid to the principal. This <lb/>means that when a principal creates a stateid, it has to be the one <lb/>to use the stateid. If the server will perform binding, it will <lb/>return EXCHGID4_FLAG_BIND_PRINC_STATEID. The server MAY return <lb/>EXCHGID4_FLAG_BIND_PRINC_STATEID even if the client does not request <lb/>it. If an update to the client ID changes the value of <lb/>EXCHGID4_FLAG_BIND_PRINC_STATEID&apos;s client ID property, the effect <lb/>applies only to new stateids. Existing stateids (and all stateids <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 527] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>with the same &quot;other&quot; field) that were created with stateid to <lb/>principal binding in force will continue to have binding in force. <lb/>Existing stateids (and all stateids with the same &quot;other&quot; field) that <lb/>were created with stateid to principal not in force will continue to <lb/>have binding not in force. <lb/>The EXCHGID4_FLAG_USE_NON_PNFS, EXCHGID4_FLAG_USE_PNFS_MDS, and <lb/>EXCHGID4_FLAG_USE_PNFS_DS bits are described in Section 2.10.2.2 and <lb/>convey roles the client ID is to be used for in a pNFS environment. <lb/>The server MUST set one of the acceptable combinations of these bits <lb/>(roles) in eir_flags, as specified in that section. Note that the <lb/>same client owner/server owner pair can have multiple roles. <lb/>Multiple roles can be associated with the same client ID or with <lb/>different client IDs. Thus, if a client sends EXCHANGE_ID from the <lb/>same client owner to the same server owner multiple times, but <lb/>specifies different pNFS roles each time, the server might return <lb/>different client IDs. Given that different pNFS roles might have <lb/>different client IDs, the client may ask for different properties for <lb/>each role/client ID. <lb/>The spa_how field of the eia_state_protect field specifies how the <lb/>client wants to protect its client, locking, and session states from <lb/>unauthorized changes (Section 2.10.8.3): <lb/>o SP4_NONE. The client does not request the NFSv4.1 server to <lb/>enforce state protection. The NFSv4.1 server MUST NOT enforce <lb/>state protection for the returned client ID. <lb/>o SP4_MACH_CRED. If spa_how is SP4_MACH_CRED, then the client MUST <lb/>send the EXCHANGE_ID operation with RPCSEC_GSS as the security <lb/>flavor, and with a service of RPC_GSS_SVC_INTEGRITY or <lb/>RPC_GSS_SVC_PRIVACY. If SP4_MACH_CRED is specified, then the <lb/>client wants to use an RPCSEC_GSS-based machine credential to <lb/>protect its state. The server MUST note the principal the <lb/>EXCHANGE_ID operation was sent with, and the GSS mechanism used. <lb/>These notes collectively comprise the machine credential. <lb/>After the client ID is confirmed, as long as the lease associated <lb/>with the client ID is unexpired, a subsequent EXCHANGE_ID <lb/>operation that uses the same eia_clientowner.co_owner as the first <lb/>EXCHANGE_ID MUST also use the same machine credential as the first <lb/>EXCHANGE_ID. The server returns the same client ID for the <lb/>subsequent EXCHANGE_ID as that returned from the first <lb/>EXCHANGE_ID. <lb/>o SP4_SSV. If spa_how is SP4_SSV, then the client MUST send the <lb/>EXCHANGE_ID operation with RPCSEC_GSS as the security flavor, and <lb/>with a service of RPC_GSS_SVC_INTEGRITY or RPC_GSS_SVC_PRIVACY. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 528] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If SP4_SSV is specified, then the client wants to use the SSV to <lb/>protect its state. The server records the credential used in the <lb/>request as the machine credential (as defined above) for the <lb/>eia_clientowner.co_owner. The CREATE_SESSION operation that <lb/>confirms the client ID MUST use the same machine credential. <lb/>When a client specifies SP4_MACH_CRED or SP4_SSV, it also provides <lb/>two lists of operations (each expressed as a bitmap). The first list <lb/>is spo_must_enforce and consists of those operations the client MUST <lb/>send (subject to the server confirming the list of operations in the <lb/>result of EXCHANGE_ID) with the machine credential (if SP4_MACH_CRED <lb/>protection is specified) or the SSV-based credential (if SP4_SSV <lb/>protection is used). The client MUST send the operations with <lb/>RPCSEC_GSS credentials that specify the RPC_GSS_SVC_INTEGRITY or <lb/>RPC_GSS_SVC_PRIVACY security service. Typically, the first list of <lb/>operations includes EXCHANGE_ID, CREATE_SESSION, DELEGPURGE, <lb/>DESTROY_SESSION, BIND_CONN_TO_SESSION, and DESTROY_CLIENTID. The <lb/>client SHOULD NOT specify in this list any operations that require a <lb/>filehandle because the server&apos;s access policies MAY conflict with the <lb/>client&apos;s choice, and thus the client would then be unable to access a <lb/>subset of the server&apos;s namespace. <lb/>Note that if SP4_SSV protection is specified, and the client <lb/>indicates that CREATE_SESSION must be protected with SP4_SSV, because <lb/>the SSV cannot exist without a confirmed client ID, the first <lb/>CREATE_SESSION MUST instead be sent using the machine credential, and <lb/>the server MUST accept the machine credential. <lb/>There is a corresponding result, also called spo_must_enforce, of the <lb/>operations for which the server will require SP4_MACH_CRED or SP4_SSV <lb/>protection. Normally, the server&apos;s result equals the client&apos;s <lb/>argument, but the result MAY be different. If the client requests <lb/>one or more operations in the set { EXCHANGE_ID, CREATE_SESSION, <lb/>DELEGPURGE, DESTROY_SESSION, BIND_CONN_TO_SESSION, DESTROY_CLIENTID <lb/>}, then the result spo_must_enforce MUST include the operations the <lb/>client requested from that set. <lb/>If spo_must_enforce in the results has BIND_CONN_TO_SESSION set, then <lb/>connection binding enforcement is enabled, and the client MUST use <lb/>the machine (if SP4_MACH_CRED protection is used) or SSV (if SP4_SSV <lb/>protection is used) credential on calls to BIND_CONN_TO_SESSION. <lb/>The second list is spo_must_allow and consists of those operations <lb/>the client wants to have the option of sending with the machine <lb/>credential or the SSV-based credential, even if the object the <lb/>operations are performed on is not owned by the machine or SSV <lb/>credential. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 529] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The corresponding result, also called spo_must_allow, consists of the <lb/>operations the server will allow the client to use SP4_SSV or <lb/>SP4_MACH_CRED credentials with. Normally, the server&apos;s result equals <lb/>the client&apos;s argument, but the result MAY be different. <lb/>The purpose of spo_must_allow is to allow clients to solve the <lb/>following conundrum. Suppose the client ID is confirmed with <lb/>EXCHGID4_FLAG_BIND_PRINC_STATEID, and it calls OPEN with the <lb/>RPCSEC_GSS credentials of a normal user. Now suppose the user&apos;s <lb/>credentials expire, and cannot be renewed (e.g., a Kerberos ticket <lb/>granting ticket expires, and the user has logged off and will not be <lb/>acquiring a new ticket granting ticket). The client will be unable <lb/>to send CLOSE without the user&apos;s credentials, which is to say the <lb/>client has to either leave the state on the server or re-send <lb/>EXCHANGE_ID with a new verifier to clear all state, that is, unless <lb/>the client includes CLOSE on the list of operations in spo_must_allow <lb/>and the server agrees. <lb/>The SP4_SSV protection parameters also have: <lb/>ssp_hash_algs: <lb/>This is the set of algorithms the client supports for the purpose <lb/>of computing the digests needed for the internal SSV GSS mechanism <lb/>and for the SET_SSV operation. Each algorithm is specified as an <lb/>object identifier (OID). The REQUIRED algorithms for a server are <lb/>id-sha1, id-sha224, id-sha256, id-sha384, and id-sha512 [25]. The <lb/>algorithm the server selects among the set is indicated in <lb/>spi_hash_alg, a field of spr_ssv_prot_info. The field <lb/>spi_hash_alg is an index into the array ssp_hash_algs. If the <lb/>server does not support any of the offered algorithms, it returns <lb/>NFS4ERR_HASH_ALG_UNSUPP. If ssp_hash_algs is empty, the server <lb/>MUST return NFS4ERR_INVAL. <lb/>ssp_encr_algs: <lb/>This is the set of algorithms the client supports for the purpose <lb/>of providing privacy protection for the internal SSV GSS <lb/>mechanism. Each algorithm is specified as an OID. The REQUIRED <lb/>algorithm for a server is id-aes256-CBC. The RECOMMENDED <lb/>algorithms are id-aes192-CBC and id-aes128-CBC [26]. The selected <lb/>algorithm is returned in spi_encr_alg, an index into <lb/>ssp_encr_algs. If the server does not support any of the offered <lb/>algorithms, it returns NFS4ERR_ENCR_ALG_UNSUPP. If ssp_encr_algs <lb/>is empty, the server MUST return NFS4ERR_INVAL. Note that due to <lb/>previously stated requirements and recommendations on the <lb/>relationships between key length and hash length, some <lb/>combinations of RECOMMENDED and REQUIRED encryption algorithm and <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 530] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>hash algorithm either SHOULD NOT or MUST NOT be used. Table 12 <lb/>summarizes the illegal and discouraged combinations. <lb/>ssp_window: <lb/>This is the number of SSV versions the client wants the server to <lb/>maintain (i.e., each successful call to SET_SSV produces a new <lb/>version of the SSV). If ssp_window is zero, the server MUST <lb/>return NFS4ERR_INVAL. The server responds with spi_window, which <lb/>MUST NOT exceed ssp_window and MUST be at least one. Any requests <lb/>on the backchannel or fore channel that are using a version of the <lb/>SSV that is outside the window will fail with an ONC RPC <lb/>authentication error, and the requester will have to retry them <lb/>with the same slot ID and sequence ID. <lb/>ssp_num_gss_handles: <lb/>This is the number of RPCSEC_GSS handles the server should create <lb/>that are based on the GSS SSV mechanism (see Section 2.10.9). It <lb/>is not the total number of RPCSEC_GSS handles for the client ID. <lb/>Indeed, subsequent calls to EXCHANGE_ID will add RPCSEC_GSS <lb/>handles. The server responds with a list of handles in <lb/>spi_handles. If the client asks for at least one handle and the <lb/>server cannot create it, the server MUST return an error. The <lb/>handles in spi_handles are not available for use until the client <lb/>ID is confirmed, which could be immediately if EXCHANGE_ID returns <lb/>EXCHGID4_FLAG_CONFIRMED_R, or upon successful confirmation from <lb/>CREATE_SESSION. <lb/>While a client ID can span all the connections that are connected <lb/>to a server sharing the same eir_server_owner.so_major_id, the <lb/>RPCSEC_GSS handles returned in spi_handles can only be used on <lb/>connections connected to a server that returns the same the <lb/>eir_server_owner.so_major_id and eir_server_owner.so_minor_id on <lb/>each connection. It is permissible for the client to set <lb/>ssp_num_gss_handles to zero; the client can create more handles <lb/>with another EXCHANGE_ID call. <lb/>Because each SSV RPCSEC_GSS handle shares a common SSV GSS <lb/>context, there are security considerations specific to this <lb/>situation discussed in Section 2.10.10. <lb/>The seq_window (see Section 5.2.3.1 of RFC2203 [4]) of each <lb/>RPCSEC_GSS handle in spi_handle MUST be the same as the seq_window <lb/>of the RPCSEC_GSS handle used for the credential of the RPC <lb/>request that the EXCHANGE_ID operation was sent as a part of. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 531] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>+-------------------+----------------------+------------------------+ <lb/>| Encryption <lb/>| MUST NOT be combined | SHOULD NOT be combined | <lb/>| Algorithm <lb/>| with <lb/>| with <lb/>| <lb/>+-------------------+----------------------+------------------------+ <lb/>| id-aes128-CBC <lb/>| <lb/>| id-sha384, id-sha512 <lb/>| <lb/>| id-aes192-CBC <lb/>| id-sha1 <lb/>| id-sha512 <lb/>| <lb/>| id-aes256-CBC <lb/>| id-sha1, id-sha224 <lb/>| <lb/>| <lb/>+-------------------+----------------------+------------------------+ <lb/>Table 12 <lb/>The arguments include an array of up to one element in length called <lb/>eia_client_impl_id. If eia_client_impl_id is present, it contains <lb/>the information identifying the implementation of the client. <lb/>Similarly, the results include an array of up to one element in <lb/>length called eir_server_impl_id that identifies the implementation <lb/>of the server. Servers MUST accept a zero-length eia_client_impl_id <lb/>array, and clients MUST accept a zero-length eir_server_impl_id <lb/>array. <lb/>A possible use for implementation identifiers would be in diagnostic <lb/>software that extracts this information in an attempt to identify <lb/>interoperability problems, performance workload behaviors, or general <lb/>usage statistics. Since the intent of having access to this <lb/>information is for planning or general diagnosis only, the client and <lb/>server MUST NOT interpret this implementation identity information in <lb/>a way that affects how the implementation interacts with its peer. <lb/>The client and server are not allowed to depend on the peer&apos;s <lb/>manifesting a particular allowed behavior based on an implementation <lb/>identifier but are required to interoperate as specified elsewhere in <lb/>the protocol specification. <lb/>Because it is possible that some implementations might violate the <lb/>protocol specification and interpret the identity information, <lb/>implementations MUST provide facilities to allow the NFSv4 client and <lb/>server be configured to set the contents of the nfs_impl_id <lb/>structures sent to any specified value. <lb/>18.35.4. IMPLEMENTATION <lb/>A server&apos;s client record is a 5-tuple: <lb/>1. co_ownerid <lb/>The client identifier string, from the eia_clientowner <lb/>structure of the EXCHANGE_ID4args structure. <lb/>2. co_verifier: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 532] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>A client-specific value used to indicate incarnations (where a <lb/>client restart represents a new incarnation), from the <lb/>eia_clientowner structure of the EXCHANGE_ID4args structure. <lb/>3. principal: <lb/>The principal that was defined in the RPC header&apos;s credential <lb/>and/or verifier at the time the client record was established. <lb/>4. client ID: <lb/>The shorthand client identifier, generated by the server and <lb/>returned via the eir_clientid field in the EXCHANGE_ID4resok <lb/>structure. <lb/>5. confirmed: <lb/>A private field on the server indicating whether or not a <lb/>client record has been confirmed. A client record is <lb/>confirmed if there has been a successful CREATE_SESSION <lb/>operation to confirm it. Otherwise, it is unconfirmed. An <lb/>unconfirmed record is established by an EXCHANGE_ID call. Any <lb/>unconfirmed record that is not confirmed within a lease period <lb/>SHOULD be removed. <lb/>The following identifiers represent special values for the fields in <lb/>the records. <lb/>ownerid_arg: <lb/>The value of the eia_clientowner.co_ownerid subfield of the <lb/>EXCHANGE_ID4args structure of the current request. <lb/>verifier_arg: <lb/>The value of the eia_clientowner.co_verifier subfield of the <lb/>EXCHANGE_ID4args structure of the current request. <lb/>old_verifier_arg: <lb/>A value of the eia_clientowner.co_verifier field of a client <lb/>record received in a previous request; this is distinct from <lb/>verifier_arg. <lb/>principal_arg: <lb/>The value of the RPCSEC_GSS principal for the current request. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 533] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>old_principal_arg: <lb/>A value of the principal of a client record as defined by the RPC <lb/>header&apos;s credential or verifier of a previous request. This is <lb/>distinct from principal_arg. <lb/>clientid_ret: <lb/>The value of the eir_clientid field the server will return in the <lb/>EXCHANGE_ID4resok structure for the current request. <lb/>old_clientid_ret: <lb/>The value of the eir_clientid field the server returned in the <lb/>EXCHANGE_ID4resok structure for a previous request. This is <lb/>distinct from clientid_ret. <lb/>confirmed: <lb/>The client ID has been confirmed. <lb/>unconfirmed: <lb/>The client ID has not been confirmed. <lb/>Since EXCHANGE_ID is a non-idempotent operation, we must consider the <lb/>possibility that retries occur as a result of a client restart, <lb/>network partition, malfunctioning router, etc. Retries are <lb/>identified by the value of the eia_clientowner field of <lb/>EXCHANGE_ID4args, and the method for dealing with them is outlined in <lb/>the scenarios below. <lb/>The scenarios are described in terms of the client record(s) a server <lb/>has for a given co_ownerid. Note that if the client ID was created <lb/>specifying SP4_SSV state protection and EXCHANGE_ID as the one of the <lb/>operations in spo_must_allow, then the server MUST authorize <lb/>EXCHANGE_IDs with the SSV principal in addition to the principal that <lb/>created the client ID. <lb/>1. New Owner ID <lb/>If the server has no client records with <lb/>eia_clientowner.co_ownerid matching ownerid_arg, and <lb/>EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is not set in the <lb/>EXCHANGE_ID, then a new shorthand client ID (let us call it <lb/>clientid_ret) is generated, and the following unconfirmed <lb/>record is added to the server&apos;s state. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 534] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>{ ownerid_arg, verifier_arg, principal_arg, clientid_ret, <lb/>unconfirmed } <lb/>Subsequently, the server returns clientid_ret. <lb/>2. Non-Update on Existing Client ID <lb/>If the server has the following confirmed record, and the <lb/>request does not have EXCHGID4_FLAG_UPD_CONFIRMED_REC_A set, <lb/>then the request is the result of a retried request due to a <lb/>faulty router or lost connection, or the client is trying to <lb/>determine if it can perform trunking. <lb/>{ ownerid_arg, verifier_arg, principal_arg, clientid_ret, <lb/>confirmed } <lb/>Since the record has been confirmed, the client must have <lb/>received the server&apos;s reply from the initial EXCHANGE_ID <lb/>request. Since the server has a confirmed record, and since <lb/>EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is not set, with the <lb/>possible exception of eir_server_owner.so_minor_id, the server <lb/>returns the same result it did when the client ID&apos;s properties <lb/>were last updated (or if never updated, the result when the <lb/>client ID was created). The confirmed record is unchanged. <lb/>3. Client Collision <lb/>If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is not set, and if the <lb/>server has the following confirmed record, then this request <lb/>is likely the result of a chance collision between the values <lb/>of the eia_clientowner.co_ownerid subfield of EXCHANGE_ID4args <lb/>for two different clients. <lb/>{ ownerid_arg, *, old_principal_arg, old_clientid_ret, <lb/>confirmed } <lb/>If there is currently no state associated with <lb/>old_clientid_ret, or if there is state but the lease has <lb/>expired, then this case is effectively equivalent to the New <lb/>Owner ID case of Paragraph 1. The confirmed record is <lb/>deleted, the old_clientid_ret and its lock state are deleted, <lb/>a new shorthand client ID is generated, and the following <lb/>unconfirmed record is added to the server&apos;s state. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 535] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>{ ownerid_arg, verifier_arg, principal_arg, clientid_ret, <lb/>unconfirmed } <lb/>Subsequently, the server returns clientid_ret. <lb/>If old_clientid_ret has an unexpired lease with state, then no <lb/>state of old_clientid_ret is changed or deleted. The server <lb/>returns NFS4ERR_CLID_INUSE to indicate that the client should <lb/>retry with a different value for the <lb/>eia_clientowner.co_ownerid subfield of EXCHANGE_ID4args. The <lb/>client record is not changed. <lb/>4. Replacement of Unconfirmed Record <lb/>If the EXCHGID4_FLAG_UPD_CONFIRMED_REC_A flag is not set, and <lb/>the server has the following unconfirmed record, then the <lb/>client is attempting EXCHANGE_ID again on an unconfirmed <lb/>client ID, perhaps due to a retry, a client restart before <lb/>client ID confirmation (i.e., before CREATE_SESSION was <lb/>called), or some other reason. <lb/>{ ownerid_arg, *, *, old_clientid_ret, unconfirmed } <lb/>It is possible that the properties of old_clientid_ret are <lb/>different than those specified in the current EXCHANGE_ID. <lb/>Whether or not the properties are being updated, to eliminate <lb/>ambiguity, the server deletes the unconfirmed record, <lb/>generates a new client ID (clientid_ret), and establishes the <lb/>following unconfirmed record: <lb/>{ ownerid_arg, verifier_arg, principal_arg, clientid_ret, <lb/>unconfirmed } <lb/>5. Client Restart <lb/>If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is not set, and if the <lb/>server has the following confirmed client record, then this <lb/>request is likely from a previously confirmed client that has <lb/>restarted. <lb/>{ ownerid_arg, old_verifier_arg, principal_arg, <lb/>old_clientid_ret, confirmed } <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 536] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Since the previous incarnation of the same client will no <lb/>longer be making requests, once the new client ID is confirmed <lb/>by CREATE_SESSION, byte-range locks and share reservations <lb/>should be released immediately rather than forcing the new <lb/>incarnation to wait for the lease time on the previous <lb/>incarnation to expire. Furthermore, session state should be <lb/>removed since if the client had maintained that information <lb/>across restart, this request would not have been sent. If the <lb/>server supports neither the CLAIM_DELEGATE_PREV nor <lb/>CLAIM_DELEG_PREV_FH claim types, associated delegations should <lb/>be purged as well; otherwise, delegations are retained and <lb/>recovery proceeds according to Section 10.2.1. <lb/>After processing, clientid_ret is returned to the client and <lb/>this client record is added: <lb/>{ ownerid_arg, verifier_arg, principal_arg, clientid_ret, <lb/>unconfirmed } <lb/>The previously described confirmed record continues to exist, <lb/>and thus the same ownerid_arg exists in both a confirmed and <lb/>unconfirmed state at the same time. The number of states can <lb/>collapse to one once the server receives an applicable <lb/>CREATE_SESSION or EXCHANGE_ID. <lb/>+ If the server subsequently receives a successful <lb/>CREATE_SESSION that confirms clientid_ret, then the server <lb/>atomically destroys the confirmed record and makes the <lb/>unconfirmed record confirmed as described in <lb/>Section 18.36.3. <lb/>+ If the server instead subsequently receives an EXCHANGE_ID <lb/>with the client owner equal to ownerid_arg, one strategy is <lb/>to simply delete the unconfirmed record, and process the <lb/>EXCHANGE_ID as described in the entirety of <lb/>Section 18.35.4. <lb/>6. Update <lb/>If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is set, and the server <lb/>has the following confirmed record, then this request is an <lb/>attempt at an update. <lb/>{ ownerid_arg, verifier_arg, principal_arg, clientid_ret, <lb/>confirmed } <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 537] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Since the record has been confirmed, the client must have <lb/>received the server&apos;s reply from the initial EXCHANGE_ID <lb/>request. The server allows the update, and the client record <lb/>is left intact. <lb/>7. Update but No Confirmed Record <lb/>If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is set, and the server <lb/>has no confirmed record corresponding ownerid_arg, then the <lb/>server returns NFS4ERR_NOENT and leaves any unconfirmed record <lb/>intact. <lb/>8. Update but Wrong Verifier <lb/>If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is set, and the server <lb/>has the following confirmed record, then this request is an <lb/>illegal attempt at an update, perhaps because of a retry from <lb/>a previous client incarnation. <lb/>{ ownerid_arg, old_verifier_arg, *, clientid_ret, confirmed } <lb/>The server returns NFS4ERR_NOT_SAME and leaves the client <lb/>record intact. <lb/>9. Update but Wrong Principal <lb/>If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is set, and the server <lb/>has the following confirmed record, then this request is an <lb/>illegal attempt at an update by an unauthorized principal. <lb/>{ ownerid_arg, verifier_arg, old_principal_arg, clientid_ret, <lb/>confirmed } <lb/>The server returns NFS4ERR_PERM and leaves the client record <lb/>intact. <lb/>18.36. Operation 43: CREATE_SESSION -Create New Session and Confirm <lb/>Client ID <lb/>18.36.1. ARGUMENT <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 538] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct channel_attrs4 { <lb/>count4 <lb/>ca_headerpadsize; <lb/>count4 <lb/>ca_maxrequestsize; <lb/>count4 <lb/>ca_maxresponsesize; <lb/>count4 <lb/>ca_maxresponsesize_cached; <lb/>count4 <lb/>ca_maxoperations; <lb/>count4 <lb/>ca_maxrequests; <lb/>uint32_t <lb/>ca_rdma_ird&lt;1&gt;; <lb/>}; <lb/>const CREATE_SESSION4_FLAG_PERSIST <lb/>= 0x00000001; <lb/>const CREATE_SESSION4_FLAG_CONN_BACK_CHAN <lb/>= 0x00000002; <lb/>const CREATE_SESSION4_FLAG_CONN_RDMA <lb/>= 0x00000004; <lb/>struct CREATE_SESSION4args { <lb/>clientid4 <lb/>csa_clientid; <lb/>sequenceid4 <lb/>csa_sequence; <lb/>uint32_t <lb/>csa_flags; <lb/>channel_attrs4 <lb/>csa_fore_chan_attrs; <lb/>channel_attrs4 <lb/>csa_back_chan_attrs; <lb/>uint32_t <lb/>csa_cb_program; <lb/>callback_sec_parms4 <lb/>csa_sec_parms&lt;&gt;; <lb/>}; <lb/>18.36.2. RESULT <lb/>struct CREATE_SESSION4resok { <lb/>sessionid4 <lb/>csr_sessionid; <lb/>sequenceid4 <lb/>csr_sequence; <lb/>uint32_t <lb/>csr_flags; <lb/>channel_attrs4 <lb/>csr_fore_chan_attrs; <lb/>channel_attrs4 <lb/>csr_back_chan_attrs; <lb/>}; <lb/>union CREATE_SESSION4res switch (nfsstat4 csr_status) { <lb/>case NFS4_OK: <lb/>CREATE_SESSION4resok <lb/>csr_resok4; <lb/>default: <lb/>void; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 539] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.36.3. DESCRIPTION <lb/>This operation is used by the client to create new session objects on <lb/>the server. <lb/>CREATE_SESSION can be sent with or without a preceding SEQUENCE <lb/>operation in the same COMPOUND procedure. If CREATE_SESSION is sent <lb/>with a preceding SEQUENCE operation, any session created by <lb/>CREATE_SESSION has no direct relation to the session specified in the <lb/>SEQUENCE operation, although the two sessions might be associated <lb/>with the same client ID. If CREATE_SESSION is sent without a <lb/>preceding SEQUENCE, then it MUST be the only operation in the <lb/>COMPOUND procedure&apos;s request. If it is not, the server MUST return <lb/>NFS4ERR_NOT_ONLY_OP. <lb/>In addition to creating a session, CREATE_SESSION has the following <lb/>effects: <lb/>o The first session created with a new client ID serves to confirm <lb/>the creation of that client&apos;s state on the server. The server <lb/>returns the parameter values for the new session. <lb/>o The connection CREATE_SESSION that is sent over is associated with <lb/>the session&apos;s fore channel. <lb/>The arguments and results of CREATE_SESSION are described as follows: <lb/>csa_clientid: <lb/>This is the client ID with which the new session will be <lb/>associated. The corresponding result is csr_sessionid, the <lb/>session ID of the new session. <lb/>csa_sequence: <lb/>Each client ID serializes CREATE_SESSION via a per-client ID <lb/>sequence number (see Section 18.36.4). The corresponding result <lb/>is csr_sequence, which MUST be equal to csa_sequence. <lb/>In the next three arguments, the client offers a value that is to be <lb/>a property of the session. Except where stated otherwise, it is <lb/>RECOMMENDED that the server accept the value. If it is not <lb/>acceptable, the server MAY use a different value. Regardless, the <lb/>server MUST return the value the session will use (which will be <lb/>either what the client offered, or what the server is insisting on) <lb/>to the client. <lb/>csa_flags: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 540] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The csa_flags field contains a list of the following flag bits: <lb/>CREATE_SESSION4_FLAG_PERSIST: <lb/>If CREATE_SESSION4_FLAG_PERSIST is set, the client wants the <lb/>server to provide a persistent reply cache. For sessions in <lb/>which only idempotent operations will be used (e.g., a read-<lb/>only session), clients SHOULD NOT set <lb/>CREATE_SESSION4_FLAG_PERSIST. If the server does not or cannot <lb/>provide a persistent reply cache, the server MUST NOT set <lb/>CREATE_SESSION4_FLAG_PERSIST in the field csr_flags. <lb/>If the server is a pNFS metadata server, for reasons described <lb/>in Section 12.5.2 it SHOULD support <lb/>CREATE_SESSION4_FLAG_PERSIST if it supports the layout_hint <lb/>(Section 5.12.4) attribute. <lb/>CREATE_SESSION4_FLAG_CONN_BACK_CHAN: <lb/>If CREATE_SESSION4_FLAG_CONN_BACK_CHAN is set in csa_flags, the <lb/>client is requesting that the connection over which the <lb/>CREATE_SESSION operation arrived be associated with the <lb/>session&apos;s backchannel in addition to its fore channel. If the <lb/>server agrees, it sets CREATE_SESSION4_FLAG_CONN_BACK_CHAN in <lb/>the result field csr_flags. If <lb/>CREATE_SESSION4_FLAG_CONN_BACK_CHAN is not set in csa_flags, <lb/>then CREATE_SESSION4_FLAG_CONN_BACK_CHAN MUST NOT be set in <lb/>csr_flags. <lb/>CREATE_SESSION4_FLAG_CONN_RDMA: <lb/>If CREATE_SESSION4_FLAG_CONN_RDMA is set in csa_flags, and if <lb/>the connection over which the CREATE_SESSION operation arrived <lb/>is currently in non-RDMA mode but has the capability to operate <lb/>in RDMA mode, then the client is requesting that the server <lb/>&quot;step up&quot; to RDMA mode on the connection. If the server <lb/>agrees, it sets CREATE_SESSION4_FLAG_CONN_RDMA in the result <lb/>field csr_flags. If CREATE_SESSION4_FLAG_CONN_RDMA is not set <lb/>in csa_flags, then CREATE_SESSION4_FLAG_CONN_RDMA MUST NOT be <lb/>set in csr_flags. Note that once the server agrees to step up, <lb/>it and the client MUST exchange all future traffic on the <lb/>connection with RPC RDMA framing and not Record Marking ([31]). <lb/>csa_fore_chan_attrs, csa_fore_chan_attrs: <lb/>The csa_fore_chan_attrs and csa_back_chan_attrs fields apply to <lb/>attributes of the fore channel (which conveys requests originating <lb/>from the client to the server), and the backchannel (the channel <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 541] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>that conveys callback requests originating from the server to the <lb/>client), respectively. The results are in corresponding <lb/>structures called csr_fore_chan_attrs and csr_back_chan_attrs. <lb/>The results establish attributes for each channel, and on all <lb/>subsequent use of each channel of the session. Each structure has <lb/>the following fields: <lb/>ca_headerpadsize: <lb/>The maximum amount of padding the requester is willing to apply <lb/>to ensure that write payloads are aligned on some boundary at <lb/>the replier. For each channel, the server <lb/>+ will reply in ca_headerpadsize with its preferred value, or <lb/>zero if padding is not in use, and <lb/>+ MAY decrease this value but MUST NOT increase it. <lb/>ca_maxrequestsize: <lb/>The maximum size of a COMPOUND or CB_COMPOUND request that will <lb/>be sent. This size represents the XDR encoded size of the <lb/>request, including the RPC headers (including security flavor <lb/>credentials and verifiers) but excludes any RPC transport <lb/>framing headers. Imagine a request coming over a non-RDMA TCP/ <lb/>IP connection, and that it has a single Record Marking header <lb/>preceding it. The maximum allowable count encoded in the <lb/>header will be ca_maxrequestsize. If a requester sends a <lb/>request that exceeds ca_maxrequestsize, the error <lb/>NFS4ERR_REQ_TOO_BIG will be returned per the description in <lb/>Section 2.10.6.4. For each channel, the server MAY decrease <lb/>this value but MUST NOT increase it. <lb/>ca_maxresponsesize: <lb/>The maximum size of a COMPOUND or CB_COMPOUND reply that the <lb/>requester will accept from the replier including RPC headers <lb/>(see the ca_maxrequestsize definition). For each channel, the <lb/>server MAY decrease this value, but MUST NOT increase it. <lb/>However, if the client selects a value for ca_maxresponsesize <lb/>such that a replier on a channel could never send a response, <lb/>the server SHOULD return NFS4ERR_TOOSMALL in the CREATE_SESSION <lb/>reply. After the session is created, if a requester sends a <lb/>request for which the size of the reply would exceed this <lb/>value, the replier will return NFS4ERR_REP_TOO_BIG, per the <lb/>description in Section 2.10.6.4. <lb/>ca_maxresponsesize_cached: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 542] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Like ca_maxresponsesize, but the maximum size of a reply that <lb/>will be stored in the reply cache (Section 2.10.6.1). For each <lb/>channel, the server MAY decrease this value, but MUST NOT <lb/>increase it. If, in the reply to CREATE_SESSION, the value of <lb/>ca_maxresponsesize_cached of a channel is less than the value <lb/>of ca_maxresponsesize of the same channel, then this is an <lb/>indication to the requester that it needs to be selective about <lb/>which replies it directs the replier to cache; for example, <lb/>large replies from nonidempotent operations (e.g., COMPOUND <lb/>requests with a READ operation) should not be cached. The <lb/>requester decides which replies to cache via an argument to the <lb/>SEQUENCE (the sa_cachethis field, see Section 18.46) or <lb/>CB_SEQUENCE (the csa_cachethis field, see Section 20.9) <lb/>operations. After the session is created, if a requester sends <lb/>a request for which the size of the reply would exceed <lb/>ca_maxresponsesize_cached, the replier will return <lb/>NFS4ERR_REP_TOO_BIG_TO_CACHE, per the description in <lb/>Section 2.10.6.4. <lb/>ca_maxoperations: <lb/>The maximum number of operations the replier will accept in a <lb/>COMPOUND or CB_COMPOUND. For the backchannel, the server MUST <lb/>NOT change the value the client offers. For the fore channel, <lb/>the server MAY change the requested value. After the session <lb/>is created, if a requester sends a COMPOUND or CB_COMPOUND with <lb/>more operations than ca_maxoperations, the replier MUST return <lb/>NFS4ERR_TOO_MANY_OPS. <lb/>ca_maxrequests: <lb/>The maximum number of concurrent COMPOUND or CB_COMPOUND <lb/>requests the requester will send on the session. Subsequent <lb/>requests will each be assigned a slot identifier by the <lb/>requester within the range zero to ca_maxrequests -1 <lb/>inclusive. For the backchannel, the server MUST NOT change the <lb/>value the client offers. For the fore channel, the server MAY <lb/>change the requested value. <lb/>ca_rdma_ird: <lb/>This array has a maximum of one element. If this array has one <lb/>element, then the element contains the inbound RDMA read queue <lb/>depth (IRD). For each channel, the server MAY decrease this <lb/>value, but MUST NOT increase it. <lb/>csa_cb_program <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 543] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>This is the ONC RPC program number the server MUST use in any <lb/>callbacks sent through the backchannel to the client. The server <lb/>MUST specify an ONC RPC program number equal to csa_cb_program and <lb/>an ONC RPC version number equal to 4 in callbacks sent to the <lb/>client. If a CB_COMPOUND is sent to the client, the server MUST <lb/>use a minor version number of 1. There is no corresponding <lb/>result. <lb/>csa_sec_parms <lb/>The field csa_sec_parms is an array of acceptable security <lb/>credentials the server can use on the session&apos;s backchannel. <lb/>Three security flavors are supported: AUTH_NONE, AUTH_SYS, and <lb/>RPCSEC_GSS. If AUTH_NONE is specified for a credential, then this <lb/>says the client is authorizing the server to use AUTH_NONE on all <lb/>callbacks for the session. If AUTH_SYS is specified, then the <lb/>client is authorizing the server to use AUTH_SYS on all callbacks, <lb/>using the credential specified cbsp_sys_cred. If RPCSEC_GSS is <lb/>specified, then the server is allowed to use the RPCSEC_GSS <lb/>context specified in cbsp_gss_parms as the RPCSEC_GSS context in <lb/>the credential of the RPC header of callbacks to the client. <lb/>There is no corresponding result. <lb/>The RPCSEC_GSS context for the backchannel is specified via a pair <lb/>of values of data type gsshandle4_t. The data type gsshandle4_t <lb/>represents an RPCSEC_GSS handle, and is precisely the same as the <lb/>data type of the &quot;handle&quot; field of the rpc_gss_init_res data type <lb/>defined in Section 5.2.3.1, &quot;Context Creation Response -<lb/>Successful Acceptance&quot;, of [4]. <lb/>The first RPCSEC_GSS handle, gcbp_handle_from_server, is the fore <lb/>handle the server returned to the client (either in the handle <lb/>field of data type rpc_gss_init_res or as one of the elements of <lb/>the spi_handles field returned in the reply to EXCHANGE_ID) when <lb/>the RPCSEC_GSS context was created on the server. The second <lb/>handle, gcbp_handle_from_client, is the back handle to which the <lb/>client will map the RPCSEC_GSS context. The server can <lb/>immediately use the value of gcbp_handle_from_client in the <lb/>RPCSEC_GSS credential in callback RPCs. That is, the value in <lb/>gcbp_handle_from_client can be used as the value of the field <lb/>&quot;handle&quot; in data type rpc_gss_cred_t (see Section 5, &quot;Elements of <lb/>the RPCSEC_GSS Security Protocol&quot;, of [4]) in callback RPCs. The <lb/>server MUST use the RPCSEC_GSS security service specified in <lb/>gcbp_service, i.e., it MUST set the &quot;service&quot; field of the <lb/>rpc_gss_cred_t data type in RPCSEC_GSS credential to the value of <lb/>gcbp_service (see Section 5.3.1, &quot;RPC Request Header&quot;, of [4]). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 544] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If the RPCSEC_GSS handle identified by gcbp_handle_from_server <lb/>does not exist on the server, the server will return <lb/>NFS4ERR_NOENT. <lb/>Within each element of csa_sec_parms, the fore and back RPCSEC_GSS <lb/>contexts MUST share the same GSS context and MUST have the same <lb/>seq_window (see Section 5.2.3.1 of RFC2203 [4]). The fore and <lb/>back RPCSEC_GSS context state are independent of each other as far <lb/>as the RPCSEC_GSS sequence number (see the seq_num field in the <lb/>rpc_gss_cred_t data type of Sections 5 and 5.3.1 of [4]). <lb/>If an RPCSEC_GSS handle is using the SSV context (see <lb/>Section 2.10.9), then because each SSV RPCSEC_GSS handle shares a <lb/>common SSV GSS context, there are security considerations specific <lb/>to this situation discussed in Section 2.10.10. <lb/>Once the session is created, the first SEQUENCE or CB_SEQUENCE <lb/>received on a slot MUST have a sequence ID equal to 1; if not, the <lb/>replier MUST return NFS4ERR_SEQ_MISORDERED. <lb/>18.36.4. IMPLEMENTATION <lb/>To describe a possible implementation, the same notation for client <lb/>records introduced in the description of EXCHANGE_ID is used with the <lb/>following addition: <lb/>clientid_arg: The value of the csa_clientid field of the <lb/>CREATE_SESSION4args structure of the current request. <lb/>Since CREATE_SESSION is a non-idempotent operation, we need to <lb/>consider the possibility that retries may occur as a result of a <lb/>client restart, network partition, malfunctioning router, etc. For <lb/>each client ID created by EXCHANGE_ID, the server maintains a <lb/>separate reply cache (called the CREATE_SESSION reply cache) similar <lb/>to the session reply cache used for SEQUENCE operations, with two <lb/>distinctions. <lb/>o First, this is a reply cache just for detecting and processing <lb/>CREATE_SESSION requests for a given client ID. <lb/>o Second, the size of the client ID reply cache is of one slot (and <lb/>as a result, the CREATE_SESSION request does not carry a slot <lb/>number). This means that at most one CREATE_SESSION request for a <lb/>given client ID can be outstanding. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 545] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>As previously stated, CREATE_SESSION can be sent with or without a <lb/>preceding SEQUENCE operation. Even if a SEQUENCE precedes <lb/>CREATE_SESSION, the server MUST maintain the CREATE_SESSION reply <lb/>cache, which is separate from the reply cache for the session <lb/>associated with a SEQUENCE. If CREATE_SESSION was originally sent by <lb/>itself, the client MAY send a retry of the CREATE_SESSION operation <lb/>within a COMPOUND preceded by a SEQUENCE. If CREATE_SESSION was <lb/>originally sent in a COMPOUND that started with a SEQUENCE, then the <lb/>client SHOULD send a retry in a COMPOUND that starts with a SEQUENCE <lb/>that has the same session ID as the SEQUENCE of the original request. <lb/>However, the client MAY send a retry in a COMPOUND that either has no <lb/>preceding SEQUENCE, or has a preceding SEQUENCE that refers to a <lb/>different session than the original CREATE_SESSION. This might be <lb/>necessary if the client sends a CREATE_SESSION in a COMPOUND preceded <lb/>by a SEQUENCE with session ID X, and session X no longer exists. <lb/>Regardless, any retry of CREATE_SESSION, with or without a preceding <lb/>SEQUENCE, MUST use the same value of csa_sequence as the original. <lb/>After the client received a reply to an EXCHANGE_ID operation that <lb/>contains a new, unconfirmed client ID, the server expects the client <lb/>to follow with a CREATE_SESSION operation to confirm the client ID. <lb/>The server expects value of csa_sequenceid in the arguments to that <lb/>CREATE_SESSION to be to equal the value of the field eir_sequenceid <lb/>that was returned in results of the EXCHANGE_ID that returned the <lb/>unconfirmed client ID. Before the server replies to that EXCHANGE_ID <lb/>operation, it initializes the client ID slot to be equal to <lb/>eir_sequenceid -1 (accounting for underflow), and records a <lb/>contrived CREATE_SESSION result with a &quot;cached&quot; result of <lb/>NFS4ERR_SEQ_MISORDERED. With the client ID slot thus initialized, <lb/>the processing of the CREATE_SESSION operation is divided into four <lb/>phases: <lb/>1. Client record look up. The server looks up the client ID in its <lb/>client record table. If the server contains no records with <lb/>client ID equal to clientid_arg, then most likely the client&apos;s <lb/>state has been purged during a period of inactivity, possibly due <lb/>to a loss of connectivity. NFS4ERR_STALE_CLIENTID is returned, <lb/>and no changes are made to any client records on the server. <lb/>Otherwise, the server goes to phase 2. <lb/>2. Sequence ID processing. If csa_sequenceid is equal to the <lb/>sequence ID in the client ID&apos;s slot, then this is a replay of the <lb/>previous CREATE_SESSION request, and the server returns the <lb/>cached result. If csa_sequenceid is not equal to the sequence ID <lb/>in the slot, and is more than one greater (accounting for <lb/>wraparound), then the server returns the error <lb/>NFS4ERR_SEQ_MISORDERED, and does not change the slot. If <lb/>csa_sequenceid is equal to the slot&apos;s sequence ID + 1 (accounting <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 546] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>for wraparound), then the slot&apos;s sequence ID is set to <lb/>csa_sequenceid, and the CREATE_SESSION processing goes to the <lb/>next phase. A subsequent new CREATE_SESSION call over the same <lb/>client ID MUST use a csa_sequenceid that is one greater than the <lb/>sequence ID in the slot. <lb/>3. Client ID confirmation. If this would be the first session for <lb/>the client ID, the CREATE_SESSION operation serves to confirm the <lb/>client ID. Otherwise, the client ID confirmation phase is <lb/>skipped and only the session creation phase occurs. Any case in <lb/>which there is more than one record with identical values for <lb/>client ID represents a server implementation error. Operation in <lb/>the potential valid cases is summarized as follows. <lb/>* Successful Confirmation <lb/>If the server has the following unconfirmed record, then <lb/>this is the expected confirmation of an unconfirmed record. <lb/>{ ownerid, verifier, principal_arg, clientid_arg, <lb/>unconfirmed } <lb/>As noted in Section 18.35.4, the server might also have the <lb/>following confirmed record. <lb/>{ ownerid, old_verifier, principal_arg, old_clientid, <lb/>confirmed } <lb/>The server schedules the replacement of both records with: <lb/>{ ownerid, verifier, principal_arg, clientid_arg, confirmed <lb/>} <lb/>The processing of CREATE_SESSION continues on to session <lb/>creation. Once the session is successfully created, the <lb/>scheduled client record replacement is committed. If the <lb/>session is not successfully created, then no changes are <lb/>made to any client records on the server. <lb/>* Unsuccessful Confirmation <lb/>If the server has the following record, then the client has <lb/>changed principals after the previous EXCHANGE_ID request, <lb/>or there has been a chance collision between shorthand <lb/>client identifiers. <lb/>{ *, *, old_principal_arg, clientid_arg, * } <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 547] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Neither of these cases is permissible. Processing stops <lb/>and NFS4ERR_CLID_INUSE is returned to the client. No <lb/>changes are made to any client records on the server. <lb/>4. Session creation. The server confirmed the client ID, either in <lb/>this CREATE_SESSION operation, or a previous CREATE_SESSION <lb/>operation. The server examines the remaining fields of the <lb/>arguments. <lb/>The server creates the session by recording the parameter values <lb/>used (including whether the CREATE_SESSION4_FLAG_PERSIST flag is <lb/>set and has been accepted by the server) and allocating space for <lb/>the session reply cache (if there is not enough space, the server <lb/>returns NFS4ERR_NOSPC). For each slot in the reply cache, the <lb/>server sets the sequence ID to zero, and records an entry <lb/>containing a COMPOUND reply with zero operations and the error <lb/>NFS4ERR_SEQ_MISORDERED. This way, if the first SEQUENCE request <lb/>sent has a sequence ID equal to zero, the server can simply <lb/>return what is in the reply cache: NFS4ERR_SEQ_MISORDERED. The <lb/>client initializes its reply cache for receiving callbacks in the <lb/>same way, and similarly, the first CB_SEQUENCE operation on a <lb/>slot after session creation MUST have a sequence ID of one. <lb/>If the session state is created successfully, the server <lb/>associates the session with the client ID provided by the client. <lb/>When a request that had CREATE_SESSION4_FLAG_CONN_RDMA set needs <lb/>to be retried, the retry MUST be done on a new connection that is <lb/>in non-RDMA mode. If properties of the new connection are <lb/>different enough that the arguments to CREATE_SESSION need to <lb/>change, then a non-retry MUST be sent. The server will <lb/>eventually dispose of any session that was created on the <lb/>original connection. <lb/>On the backchannel, the client and server might wish to have many <lb/>slots, in some cases perhaps more that the fore channel, in order to <lb/>deal with the situations where the network link has high latency and <lb/>is the primary bottleneck for response to recalls. If so, and if the <lb/>client provides too few slots to the backchannel, the server might <lb/>limit the number of recallable objects it gives to the client. <lb/>Implementing RPCSEC_GSS callback support requires changes to both the <lb/>client and server implementations of RPCSEC_GSS. One possible set of <lb/>changes includes: <lb/>o Adding a data structure that wraps the GSS-API context with a <lb/>reference count. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 548] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o New functions to increment and decrement the reference count. If <lb/>the reference count is decremented to zero, the wrapper data <lb/>structure and the GSS-API context it refers to would be freed. <lb/>o Change RPCSEC_GSS to create the wrapper data structure upon <lb/>receiving GSS-API context from gss_accept_sec_context() and <lb/>gss_init_sec_context(). The reference count would be initialized <lb/>to 1. <lb/>o Adding a function to map an existing RPCSEC_GSS handle to a <lb/>pointer to the wrapper data structure. The reference count would <lb/>be incremented. <lb/>o Adding a function to create a new RPCSEC_GSS handle from a pointer <lb/>to the wrapper data structure. The reference count would be <lb/>incremented. <lb/>o Replacing calls from RPCSEC_GSS that free GSS-API contexts, with <lb/>calls to decrement the reference count on the wrapper data <lb/>structure. <lb/>18.37. Operation 44: DESTROY_SESSION -Destroy a Session <lb/>18.37.1. ARGUMENT <lb/>struct DESTROY_SESSION4args { <lb/>sessionid4 <lb/>dsa_sessionid; <lb/>}; <lb/>18.37.2. RESULT <lb/>struct DESTROY_SESSION4res { <lb/>nfsstat4 <lb/>dsr_status; <lb/>}; <lb/>18.37.3. DESCRIPTION <lb/>The DESTROY_SESSION operation closes the session and discards the <lb/>session&apos;s reply cache, if any. Any remaining connections associated <lb/>with the session are immediately disassociated. If the connection <lb/>has no remaining associated sessions, the connection MAY be closed by <lb/>the server. Locks, delegations, layouts, wants, and the lease, which <lb/>are all tied to the client ID, are not affected by DESTROY_SESSION. <lb/>DESTROY_SESSION MUST be invoked on a connection that is associated <lb/>with the session being destroyed. In addition, if SP4_MACH_CRED <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 549] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>state protection was specified when the client ID was created, the <lb/>RPCSEC_GSS principal that created the session MUST be the one that <lb/>destroys the session, using RPCSEC_GSS privacy or integrity. If <lb/>SP4_SSV state protection was specified when the client ID was <lb/>created, RPCSEC_GSS using the SSV mechanism (Section 2.10.9) MUST be <lb/>used, with integrity or privacy. <lb/>If the COMPOUND request starts with SEQUENCE, and if the sessionids <lb/>specified in SEQUENCE and DESTROY_SESSION are the same, then <lb/>o DESTROY_SESSION MUST be the final operation in the COMPOUND <lb/>request. <lb/>o It is advisable to avoid placing DESTROY_SESSION in a COMPOUND <lb/>request with other state-modifying operations, because the <lb/>DESTROY_SESSION will destroy the reply cache. <lb/>o Because the session and its reply cache are destroyed, a client <lb/>that retries the request may receive an error in reply to the <lb/>retry, even though the original request was successful. <lb/>If the COMPOUND request starts with SEQUENCE, and if the sessionids <lb/>specified in SEQUENCE and DESTROY_SESSION are different, then <lb/>DESTROY_SESSION can appear in any position of the COMPOUND request <lb/>(except for the first position). The two sessionids can belong to <lb/>different client IDs. <lb/>If the COMPOUND request does not start with SEQUENCE, and if <lb/>DESTROY_SESSION is not the sole operation, then server MUST return <lb/>NFS4ERR_NOT_ONLY_OP. <lb/>If there is a backchannel on the session and the server has <lb/>outstanding CB_COMPOUND operations for the session which have not <lb/>been replied to, then the server MAY refuse to destroy the session <lb/>and return an error. If so, then in the event the backchannel is <lb/>down, the server SHOULD return NFS4ERR_CB_PATH_DOWN to inform the <lb/>client that the backchannel needs to be repaired before the server <lb/>will allow the session to be destroyed. Otherwise, the error <lb/>CB_BACK_CHAN_BUSY SHOULD be returned to indicate that there are <lb/>CB_COMPOUNDs that need to be replied to. The client SHOULD reply to <lb/>all outstanding CB_COMPOUNDs before re-sending DESTROY_SESSION. <lb/>18.38. Operation 45: FREE_STATEID -Free Stateid with No Locks <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 550] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.38.1. ARGUMENT <lb/>struct FREE_STATEID4args { <lb/>stateid4 <lb/>fsa_stateid; <lb/>}; <lb/>18.38.2. RESULT <lb/>struct FREE_STATEID4res { <lb/>nfsstat4 <lb/>fsr_status; <lb/>}; <lb/>18.38.3. DESCRIPTION <lb/>The FREE_STATEID operation is used to free a stateid that no longer <lb/>has any associated locks (including opens, byte-range locks, <lb/>delegations, and layouts). This may be because of client LOCKU <lb/>operations or because of server revocation. If there are valid locks <lb/>(of any kind) associated with the stateid in question, the error <lb/>NFS4ERR_LOCKS_HELD will be returned, and the associated stateid will <lb/>not be freed. <lb/>When a stateid is freed that had been associated with revoked locks, <lb/>by sending the FREE_STATEID operation, the client acknowledges the <lb/>loss of those locks. This allows the server, once all such revoked <lb/>state is acknowledged, to allow that client again to reclaim locks, <lb/>without encountering the edge conditions discussed in Section 8.4.2. <lb/>Once a successful FREE_STATEID is done for a given stateid, any <lb/>subsequent use of that stateid will result in an NFS4ERR_BAD_STATEID <lb/>error. <lb/>18.39. Operation 46: GET_DIR_DELEGATION -Get a Directory Delegation <lb/>18.39.1. ARGUMENT <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 551] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>typedef nfstime4 attr_notice4; <lb/>struct GET_DIR_DELEGATION4args { <lb/>/* CURRENT_FH: delegated directory */ <lb/>bool <lb/>gdda_signal_deleg_avail; <lb/>bitmap4 <lb/>gdda_notification_types; <lb/>attr_notice4 <lb/>gdda_child_attr_delay; <lb/>attr_notice4 <lb/>gdda_dir_attr_delay; <lb/>bitmap4 <lb/>gdda_child_attributes; <lb/>bitmap4 <lb/>gdda_dir_attributes; <lb/>}; <lb/>18.39.2. RESULT <lb/>struct GET_DIR_DELEGATION4resok { <lb/>verifier4 <lb/>gddr_cookieverf; <lb/>/* Stateid for get_dir_delegation */ <lb/>stateid4 <lb/>gddr_stateid; <lb/>/* Which notifications can the server support */ <lb/>bitmap4 <lb/>gddr_notification; <lb/>bitmap4 <lb/>gddr_child_attributes; <lb/>bitmap4 <lb/>gddr_dir_attributes; <lb/>}; <lb/>enum gddrnf4_status { <lb/>GDD4_OK <lb/>= 0, <lb/>GDD4_UNAVAIL <lb/>= 1 <lb/>}; <lb/>union GET_DIR_DELEGATION4res_non_fatal <lb/>switch (gddrnf4_status gddrnf_status) { <lb/>case GDD4_OK: <lb/>GET_DIR_DELEGATION4resok <lb/>gddrnf_resok4; <lb/>case GDD4_UNAVAIL: <lb/>bool <lb/>gddrnf_will_signal_deleg_avail; <lb/>}; <lb/>union GET_DIR_DELEGATION4res <lb/>switch (nfsstat4 gddr_status) { <lb/>case NFS4_OK: <lb/>GET_DIR_DELEGATION4res_non_fatal <lb/>gddr_res_non_fatal4; <lb/>default: <lb/>void; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 552] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.39.3. DESCRIPTION <lb/>The GET_DIR_DELEGATION operation is used by a client to request a <lb/>directory delegation. The directory is represented by the current <lb/>filehandle. The client also specifies whether it wants the server to <lb/>notify it when the directory changes in certain ways by setting one <lb/>or more bits in a bitmap. The server may refuse to grant the <lb/>delegation. In that case, the server will return <lb/>NFS4ERR_DIRDELEG_UNAVAIL. If the server decides to hand out the <lb/>delegation, it will return a cookie verifier for that directory. If <lb/>the cookie verifier changes when the client is holding the <lb/>delegation, the delegation will be recalled unless the client has <lb/>asked for notification for this event. <lb/>The server will also return a directory delegation stateid, <lb/>gddr_stateid, as a result of the GET_DIR_DELEGATION operation. This <lb/>stateid will appear in callback messages related to the delegation, <lb/>such as notifications and delegation recalls. The client will use <lb/>this stateid to return the delegation voluntarily or upon recall. A <lb/>delegation is returned by calling the DELEGRETURN operation. <lb/>The server might not be able to support notifications of certain <lb/>events. If the client asks for such notifications, the server MUST <lb/>inform the client of its inability to do so as part of the <lb/>GET_DIR_DELEGATION reply by not setting the appropriate bits in the <lb/>supported notifications bitmask, gddr_notification, contained in the <lb/>reply. The server MUST NOT add bits to gddr_notification that the <lb/>client did not request. <lb/>The GET_DIR_DELEGATION operation can be used for both normal and <lb/>named attribute directories. <lb/>If client sets gdda_signal_deleg_avail to TRUE, then it is <lb/>registering with the client a &quot;want&quot; for a directory delegation. If <lb/>the delegation is not available, and the server supports and will <lb/>honor the &quot;want&quot;, the results will have <lb/>gddrnf_will_signal_deleg_avail set to TRUE and no error will be <lb/>indicated on return. If so, the client should expect a future <lb/>CB_RECALLABLE_OBJ_AVAIL operation to indicate that a directory <lb/>delegation is available. If the server does not wish to honor the <lb/>&quot;want&quot; or is not able to do so, it returns the error <lb/>NFS4ERR_DIRDELEG_UNAVAIL. If the delegation is immediately <lb/>available, the server SHOULD return it with the response to the <lb/>operation, rather than via a callback. <lb/>When a client makes a request for a directory delegation while it <lb/>already holds a directory delegation for that directory (including <lb/>the case where it has been recalled but not yet returned by the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 553] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>client or revoked by the server), the server MUST reply with the <lb/>value of gddr_status set to NFS4_OK, the value of gddrnf_status set <lb/>to GDD4_UNAVAIL, and the value of gddrnf_will_signal_deleg_avail set <lb/>to FALSE. The delegation the client held before the request remains <lb/>intact, and its state is unchanged. The current stateid is not <lb/>changed (see Section 16.2.3.1.2 for a description of the current <lb/>stateid). <lb/>18.39.4. IMPLEMENTATION <lb/>Directory delegations provide the benefit of improving cache <lb/>consistency of namespace information. This is done through <lb/>synchronous callbacks. A server must support synchronous callbacks <lb/>in order to support directory delegations. In addition to that, <lb/>asynchronous notifications provide a way to reduce network traffic as <lb/>well as improve client performance in certain conditions. <lb/>Notifications are specified in terms of potential changes to the <lb/>directory. A client can ask to be notified of events by setting one <lb/>or more bits in gdda_notification_types. The client can ask for <lb/>notifications on addition of entries to a directory (by setting the <lb/>NOTIFY4_ADD_ENTRY in gdda_notification_types), notifications on entry <lb/>removal (NOTIFY4_REMOVE_ENTRY), renames (NOTIFY4_RENAME_ENTRY), <lb/>directory attribute changes (NOTIFY4_CHANGE_DIR_ATTRIBUTES), and <lb/>cookie verifier changes (NOTIFY4_CHANGE_COOKIE_VERIFIER) by setting <lb/>one or more corresponding bits in the gdda_notification_types field. <lb/>The client can also ask for notifications of changes to attributes of <lb/>directory entries (NOTIFY4_CHANGE_CHILD_ATTRIBUTES) in order to keep <lb/>its attribute cache up to date. However, any changes made to child <lb/>attributes do not cause the delegation to be recalled. If a client <lb/>is interested in directory entry caching or negative name caching, it <lb/>can set the gdda_notification_types appropriately to its particular <lb/>need and the server will notify it of all changes that would <lb/>otherwise invalidate its name cache. The kind of notification a <lb/>client asks for may depend on the directory size, its rate of change, <lb/>and the applications being used to access that directory. The <lb/>enumeration of the conditions under which a client might ask for a <lb/>notification is out of the scope of this specification. <lb/>For attribute notifications, the client will set bits in the <lb/>gdda_dir_attributes bitmap to indicate which attributes it wants to <lb/>be notified of. If the server does not support notifications for <lb/>changes to a certain attribute, it SHOULD NOT set that attribute in <lb/>the supported attribute bitmap specified in the reply <lb/>(gddr_dir_attributes). The client will also set in the <lb/>gdda_child_attributes bitmap the attributes of directory entries it <lb/>wants to be notified of, and the server will indicate in <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 554] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>gddr_child_attributes which attributes of directory entries it will <lb/>notify the client of. <lb/>The client will also let the server know if it wants to get the <lb/>notification as soon as the attribute change occurs or after a <lb/>certain delay by setting a delay factor; gdda_child_attr_delay is for <lb/>attribute changes to directory entries and gdda_dir_attr_delay is for <lb/>attribute changes to the directory. If this delay factor is set to <lb/>zero, that indicates to the server that the client wants to be <lb/>notified of any attribute changes as soon as they occur. If the <lb/>delay factor is set to N seconds, the server will make a best-effort <lb/>guarantee that attribute updates are synchronized within N seconds. <lb/>If the client asks for a delay factor that the server does not <lb/>support or that may cause significant resource consumption on the <lb/>server by causing the server to send a lot of notifications, the <lb/>server should not commit to sending out notifications for attributes <lb/>and therefore must not set the appropriate bit in the <lb/>gddr_child_attributes and gddr_dir_attributes bitmaps in the <lb/>response. <lb/>The client MUST use a security tuple (Section 2.6.1) that the <lb/>directory or its applicable ancestor (Section 2.6) is exported with. <lb/>If not, the server MUST return NFS4ERR_WRONGSEC to the operation that <lb/>both precedes GET_DIR_DELEGATION and sets the current filehandle (see <lb/>Section 2.6.3.1). <lb/>The directory delegation covers all the entries in the directory <lb/>except the parent entry. That means if a directory and its parent <lb/>both hold directory delegations, any changes to the parent will not <lb/>cause a notification to be sent for the child even though the child&apos;s <lb/>parent entry points to the parent directory. <lb/>18.40. Operation 47: GETDEVICEINFO -Get Device Information <lb/>18.40.1. ARGUMENT <lb/>struct GETDEVICEINFO4args { <lb/>deviceid4 <lb/>gdia_device_id; <lb/>layouttype4 <lb/>gdia_layout_type; <lb/>count4 <lb/>gdia_maxcount; <lb/>bitmap4 <lb/>gdia_notify_types; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 555] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.40.2. RESULT <lb/>struct GETDEVICEINFO4resok { <lb/>device_addr4 <lb/>gdir_device_addr; <lb/>bitmap4 <lb/>gdir_notification; <lb/>}; <lb/>union GETDEVICEINFO4res switch (nfsstat4 gdir_status) { <lb/>case NFS4_OK: <lb/>GETDEVICEINFO4resok <lb/>gdir_resok4; <lb/>case NFS4ERR_TOOSMALL: <lb/>count4 <lb/>gdir_mincount; <lb/>default: <lb/>void; <lb/>}; <lb/>18.40.3. DESCRIPTION <lb/>The GETDEVICEINFO operation returns pNFS storage device address <lb/>information for the specified device ID. The client identifies the <lb/>device information to be returned by providing the gdia_device_id and <lb/>gdia_layout_type that uniquely identify the device. The client <lb/>provides gdia_maxcount to limit the number of bytes for the result. <lb/>This maximum size represents all of the data being returned within <lb/>the GETDEVICEINFO4resok structure and includes the XDR overhead. The <lb/>server may return less data. If the server is unable to return any <lb/>information within the gdia_maxcount limit, the error <lb/>NFS4ERR_TOOSMALL will be returned. However, if gdia_maxcount is <lb/>zero, NFS4ERR_TOOSMALL MUST NOT be returned. <lb/>The da_layout_type field of the gdir_device_addr returned by the <lb/>server MUST be equal to the gdia_layout_type specified by the client. <lb/>If it is not equal, the client SHOULD ignore the response as invalid <lb/>and behave as if the server returned an error, even if the client <lb/>does have support for the layout type returned. <lb/>The client also provides a notification bitmap, gdia_notify_types, <lb/>for the device ID mapping notification for which it is interested in <lb/>receiving; the server must support device ID notifications for the <lb/>notification request to have affect. The notification mask is <lb/>composed in the same manner as the bitmap for file attributes <lb/>(Section 3.3.7). The numbers of bit positions are listed in the <lb/>notify_device_type4 enumeration type (Section 20.12). Only two <lb/>enumerated values of notify_device_type4 currently apply to <lb/>GETDEVICEINFO: NOTIFY_DEVICEID4_CHANGE and NOTIFY_DEVICEID4_DELETE <lb/>(see Section 20.12). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 556] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The notification bitmap applies only to the specified device ID. If <lb/>a client sends a GETDEVICEINFO operation on a deviceID multiple <lb/>times, the last notification bitmap is used by the server for <lb/>subsequent notifications. If the bitmap is zero or empty, then the <lb/>device ID&apos;s notifications are turned off. <lb/>If the client wants to just update or turn off notifications, it MAY <lb/>send a GETDEVICEINFO operation with gdia_maxcount set to zero. In <lb/>that event, if the device ID is valid, the reply&apos;s da_addr_body field <lb/>of the gdir_device_addr field will be of zero length. <lb/>If an unknown device ID is given in gdia_device_id, the server <lb/>returns NFS4ERR_NOENT. Otherwise, the device address information is <lb/>returned in gdir_device_addr. Finally, if the server supports <lb/>notifications for device ID mappings, the gdir_notification result <lb/>will contain a bitmap of which notifications it will actually send to <lb/>the client (via CB_NOTIFY_DEVICEID, see Section 20.12). <lb/>If NFS4ERR_TOOSMALL is returned, the results also contain <lb/>gdir_mincount. The value of gdir_mincount represents the minimum <lb/>size necessary to obtain the device information. <lb/>18.40.4. IMPLEMENTATION <lb/>Aside from updating or turning off notifications, another use case <lb/>for gdia_maxcount being set to zero is to validate a device ID. <lb/>The client SHOULD request a notification for changes or deletion of a <lb/>device ID to device address mapping so that the server can allow the <lb/>client gracefully use a new mapping, without having pending I/O fail <lb/>abruptly, or force layouts using the device ID to be recalled or <lb/>revoked. <lb/>It is possible that GETDEVICEINFO (and GETDEVICELIST) will race with <lb/>CB_NOTIFY_DEVICEID, i.e., CB_NOTIFY_DEVICEID arrives before the <lb/>client gets and processes the response to GETDEVICEINFO or <lb/>GETDEVICELIST. The analysis of the race leverages the fact that the <lb/>server MUST NOT delete a device ID that is referred to by a layout <lb/>the client has. <lb/>o CB_NOTIFY_DEVICEID deletes a device ID. If the client believes it <lb/>has layouts that refer to the device ID, then it is possible that <lb/>layouts referring to the deleted device ID have been revoked. The <lb/>client should send a TEST_STATEID request using the stateid for <lb/>each layout that might have been revoked. If TEST_STATEID <lb/>indicates that any layouts have been revoked, the client must <lb/>recover from layout revocation as described in Section 12.5.6. If <lb/>TEST_STATEID indicates that at least one layout has not been <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 557] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>revoked, the client should send a GETDEVICEINFO operation on the <lb/>supposedly deleted device ID to verify that the device ID has been <lb/>deleted. <lb/>If GETDEVICEINFO indicates that the device ID does not exist, then <lb/>the client assumes the server is faulty and recovers by sending an <lb/>EXCHANGE_ID operation. If GETDEVICEINFO indicates that the device <lb/>ID does exist, then while the server is faulty for sending an <lb/>erroneous device ID deletion notification, the degree to which it <lb/>is faulty does not require the client to create a new client ID. <lb/>If the client does not have layouts that refer to the device ID, <lb/>no harm is done. The client should mark the device ID as deleted, <lb/>and when GETDEVICEINFO or GETDEVICELIST results are received that <lb/>indicate that the device ID has been in fact deleted, the device <lb/>ID should be removed from the client&apos;s cache. <lb/>o CB_NOTIFY_DEVICEID indicates that a device ID&apos;s device addressing <lb/>mappings have changed. The client should assume that the results <lb/>from the in-progress GETDEVICEINFO will be stale for the device ID <lb/>once received, and so it should send another GETDEVICEINFO on the <lb/>device ID. <lb/>18.41. Operation 48: GETDEVICELIST -Get All Device Mappings for a File <lb/>System <lb/>18.41.1. ARGUMENT <lb/>struct GETDEVICELIST4args { <lb/>/* CURRENT_FH: object belonging to the file system */ <lb/>layouttype4 <lb/>gdla_layout_type; <lb/>/* number of deviceIDs to return */ <lb/>count4 <lb/>gdla_maxdevices; <lb/>nfs_cookie4 <lb/>gdla_cookie; <lb/>verifier4 <lb/>gdla_cookieverf; <lb/>}; <lb/>18.41.2. RESULT <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 558] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct GETDEVICELIST4resok { <lb/>nfs_cookie4 <lb/>gdlr_cookie; <lb/>verifier4 <lb/>gdlr_cookieverf; <lb/>deviceid4 <lb/>gdlr_deviceid_list&lt;&gt;; <lb/>bool <lb/>gdlr_eof; <lb/>}; <lb/>union GETDEVICELIST4res switch (nfsstat4 gdlr_status) { <lb/>case NFS4_OK: <lb/>GETDEVICELIST4resok <lb/>gdlr_resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.41.3. DESCRIPTION <lb/>This operation is used by the client to enumerate all of the device <lb/>IDs that a server&apos;s file system uses. <lb/>The client provides a current filehandle of a file object that <lb/>belongs to the file system (i.e., all file objects sharing the same <lb/>fsid as that of the current filehandle) and the layout type in <lb/>gdia_layout_type. Since this operation might require multiple calls <lb/>to enumerate all the device IDs (and is thus similar to the READDIR <lb/>(Section 18.23) operation), the client also provides gdia_cookie and <lb/>gdia_cookieverf to specify the current cursor position in the list. <lb/>When the client wants to read from the beginning of the file system&apos;s <lb/>device mappings, it sets gdla_cookie to zero. The field <lb/>gdla_cookieverf MUST be ignored by the server when gdla_cookie is <lb/>zero. The client provides gdla_maxdevices to limit the number of <lb/>device IDs in the result. If gdla_maxdevices is zero, the server <lb/>MUST return NFS4ERR_INVAL. The server MAY return fewer device IDs. <lb/>The successful response to the operation will contain the cookie, <lb/>gdlr_cookie, and the cookie verifier, gdlr_cookieverf, to be used on <lb/>the subsequent GETDEVICELIST. A gdlr_eof value of TRUE signifies <lb/>that there are no remaining entries in the server&apos;s device list. <lb/>Each element of gdlr_deviceid_list contains a device ID. <lb/>18.41.4. IMPLEMENTATION <lb/>An example of the use of this operation is for pNFS clients and <lb/>servers that use LAYOUT4_BLOCK_VOLUME layouts. In these environments <lb/>it may be helpful for a client to determine device accessibility upon <lb/>first file system access. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 559] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.42. Operation 49: LAYOUTCOMMIT -Commit Writes Made Using a Layout <lb/>18.42.1. ARGUMENT <lb/>union newtime4 switch (bool nt_timechanged) { <lb/>case TRUE: <lb/>nfstime4 <lb/>nt_time; <lb/>case FALSE: <lb/>void; <lb/>}; <lb/>union newoffset4 switch (bool no_newoffset) { <lb/>case TRUE: <lb/>offset4 <lb/>no_offset; <lb/>case FALSE: <lb/>void; <lb/>}; <lb/>struct LAYOUTCOMMIT4args { <lb/>/* CURRENT_FH: file */ <lb/>offset4 <lb/>loca_offset; <lb/>length4 <lb/>loca_length; <lb/>bool <lb/>loca_reclaim; <lb/>stateid4 <lb/>loca_stateid; <lb/>newoffset4 <lb/>loca_last_write_offset; <lb/>newtime4 <lb/>loca_time_modify; <lb/>layoutupdate4 <lb/>loca_layoutupdate; <lb/>}; <lb/>18.42.2. RESULT <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 560] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>union newsize4 switch (bool ns_sizechanged) { <lb/>case TRUE: <lb/>length4 <lb/>ns_size; <lb/>case FALSE: <lb/>void; <lb/>}; <lb/>struct LAYOUTCOMMIT4resok { <lb/>newsize4 <lb/>locr_newsize; <lb/>}; <lb/>union LAYOUTCOMMIT4res switch (nfsstat4 locr_status) { <lb/>case NFS4_OK: <lb/>LAYOUTCOMMIT4resok <lb/>locr_resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.42.3. DESCRIPTION <lb/>The LAYOUTCOMMIT operation commits changes in the layout represented <lb/>by the current filehandle, client ID (derived from the session ID in <lb/>the preceding SEQUENCE operation), byte-range, and stateid. Since <lb/>layouts are sub-dividable, a smaller portion of a layout, retrieved <lb/>via LAYOUTGET, can be committed. The byte-range being committed is <lb/>specified through the byte-range (loca_offset and loca_length). This <lb/>byte-range MUST overlap with one or more existing layouts previously <lb/>granted via LAYOUTGET (Section 18.43), each with an iomode of <lb/>LAYOUTIOMODE4_RW. In the case where the iomode of any held layout <lb/>segment is not LAYOUTIOMODE4_RW, the server should return the error <lb/>NFS4ERR_BAD_IOMODE. For the case where the client does not hold <lb/>matching layout segment(s) for the defined byte-range, the server <lb/>should return the error NFS4ERR_BAD_LAYOUT. <lb/>The LAYOUTCOMMIT operation indicates that the client has completed <lb/>writes using a layout obtained by a previous LAYOUTGET. The client <lb/>may have only written a subset of the data range it previously <lb/>requested. LAYOUTCOMMIT allows it to commit or discard provisionally <lb/>allocated space and to update the server with a new end-of-file. The <lb/>layout referenced by LAYOUTCOMMIT is still valid after the operation <lb/>completes and can be continued to be referenced by the client ID, <lb/>filehandle, byte-range, layout type, and stateid. <lb/>If the loca_reclaim field is set to TRUE, this indicates that the <lb/>client is attempting to commit changes to a layout after the restart <lb/>of the metadata server during the metadata server&apos;s recovery grace <lb/>period (see Section 12.7.4). This type of request may be necessary <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 561] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>when the client has uncommitted writes to provisionally allocated <lb/>byte-ranges of a file that were sent to the storage devices before <lb/>the restart of the metadata server. In this case, the layout <lb/>provided by the client MUST be a subset of a writable layout that the <lb/>client held immediately before the restart of the metadata server. <lb/>The value of the field loca_stateid MUST be a value that the metadata <lb/>server returned before it restarted. The metadata server is free to <lb/>accept or reject this request based on its own internal metadata <lb/>consistency checks. If the metadata server finds that the layout <lb/>provided by the client does not pass its consistency checks, it MUST <lb/>reject the request with the status NFS4ERR_RECLAIM_BAD. The <lb/>successful completion of the LAYOUTCOMMIT request with loca_reclaim <lb/>set to TRUE does NOT provide the client with a layout for the file. <lb/>It simply commits the changes to the layout specified in the <lb/>loca_layoutupdate field. To obtain a layout for the file, the client <lb/>must send a LAYOUTGET request to the server after the server&apos;s grace <lb/>period has expired. If the metadata server receives a LAYOUTCOMMIT <lb/>request with loca_reclaim set to TRUE when the metadata server is not <lb/>in its recovery grace period, it MUST reject the request with the <lb/>status NFS4ERR_NO_GRACE. <lb/>Setting the loca_reclaim field to TRUE is required if and only if the <lb/>committed layout was acquired before the metadata server restart. If <lb/>the client is committing a layout that was acquired during the <lb/>metadata server&apos;s grace period, it MUST set the &quot;reclaim&quot; field to <lb/>FALSE. <lb/>The loca_stateid is a layout stateid value as returned by previously <lb/>successful layout operations (see Section 12.5.3). <lb/>The loca_last_write_offset field specifies the offset of the last <lb/>byte written by the client previous to the LAYOUTCOMMIT. Note that <lb/>this value is never equal to the file&apos;s size (at most it is one byte <lb/>less than the file&apos;s size) and MUST be less than or equal to <lb/>NFS4_MAXFILEOFF. Also, loca_last_write_offset MUST overlap the range <lb/>described by loca_offset and loca_length. The metadata server may <lb/>use this information to determine whether the file&apos;s size needs to be <lb/>updated. If the metadata server updates the file&apos;s size as the <lb/>result of the LAYOUTCOMMIT operation, it must return the new size <lb/>(locr_newsize.ns_size) as part of the results. <lb/>The loca_time_modify field allows the client to suggest a <lb/>modification time it would like the metadata server to set. The <lb/>metadata server may use the suggestion or it may use the time of the <lb/>LAYOUTCOMMIT operation to set the modification time. If the metadata <lb/>server uses the client-provided modification time, it should ensure <lb/>that time does not flow backwards. If the client wants to force the <lb/>metadata server to set an exact time, the client should use a SETATTR <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 562] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>operation in a COMPOUND right after LAYOUTCOMMIT. See Section 12.5.4 <lb/>for more details. If the client desires the resultant modification <lb/>time, it should construct the COMPOUND so that a GETATTR follows the <lb/>LAYOUTCOMMIT. <lb/>The loca_layoutupdate argument to LAYOUTCOMMIT provides a mechanism <lb/>for a client to provide layout-specific updates to the metadata <lb/>server. For example, the layout update can describe what byte-ranges <lb/>of the original layout have been used and what byte-ranges can be <lb/>deallocated. There is no NFSv4.1 file layout-specific layoutupdate4 <lb/>structure. <lb/>The layout information is more verbose for block devices than for <lb/>objects and files because the latter two hide the details of block <lb/>allocation behind their storage protocols. At the minimum, the <lb/>client needs to communicate changes to the end-of-file location back <lb/>to the server, and, if desired, its view of the file&apos;s modification <lb/>time. For block/volume layouts, it needs to specify precisely which <lb/>blocks have been used. <lb/>If the layout identified in the arguments does not exist, the error <lb/>NFS4ERR_BADLAYOUT is returned. The layout being committed may also <lb/>be rejected if it does not correspond to an existing layout with an <lb/>iomode of LAYOUTIOMODE4_RW. <lb/>On success, the current filehandle retains its value and the current <lb/>stateid retains its value. <lb/>18.42.4. IMPLEMENTATION <lb/>The client MAY also use LAYOUTCOMMIT with the loca_reclaim field set <lb/>to TRUE to convey hints to modified file attributes or to report <lb/>layout-type specific information such as I/O errors for object-based <lb/>storage layouts, as normally done during normal operation. Doing so <lb/>may help the metadata server to recover files more efficiently after <lb/>restart. For example, some file system implementations may require <lb/>expansive recovery of file system objects if the metadata server does <lb/>not get a positive indication from all clients holding a <lb/>LAYOUTIOMODE4_RW layout that they have successfully completed all <lb/>their writes. Sending a LAYOUTCOMMIT (if required) and then <lb/>following with LAYOUTRETURN can provide such an indication and allow <lb/>for graceful and efficient recovery. <lb/>If loca_reclaim is TRUE, the metadata server is free to either <lb/>examine or ignore the value in the field loca_stateid. The metadata <lb/>server implementation might or might not encode in its layout stateid <lb/>information that allows the metadate server to perform a consistency <lb/>check on the LAYOUTCOMMIT request. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 563] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.43. Operation 50: LAYOUTGET -Get Layout Information <lb/>18.43.1. ARGUMENT <lb/>struct LAYOUTGET4args { <lb/>/* CURRENT_FH: file */ <lb/>bool <lb/>loga_signal_layout_avail; <lb/>layouttype4 <lb/>loga_layout_type; <lb/>layoutiomode4 <lb/>loga_iomode; <lb/>offset4 <lb/>loga_offset; <lb/>length4 <lb/>loga_length; <lb/>length4 <lb/>loga_minlength; <lb/>stateid4 <lb/>loga_stateid; <lb/>count4 <lb/>loga_maxcount; <lb/>}; <lb/>18.43.2. RESULT <lb/>struct LAYOUTGET4resok { <lb/>bool <lb/>logr_return_on_close; <lb/>stateid4 <lb/>logr_stateid; <lb/>layout4 <lb/>logr_layout&lt;&gt;; <lb/>}; <lb/>union LAYOUTGET4res switch (nfsstat4 logr_status) { <lb/>case NFS4_OK: <lb/>LAYOUTGET4resok <lb/>logr_resok4; <lb/>case NFS4ERR_LAYOUTTRYLATER: <lb/>bool <lb/>logr_will_signal_layout_avail; <lb/>default: <lb/>void; <lb/>}; <lb/>18.43.3. DESCRIPTION <lb/>The LAYOUTGET operation requests a layout from the metadata server <lb/>for reading or writing the file given by the filehandle at the byte-<lb/>range specified by offset and length. Layouts are identified by the <lb/>client ID (derived from the session ID in the preceding SEQUENCE <lb/>operation), current filehandle, layout type (loga_layout_type), and <lb/>the layout stateid (loga_stateid). The use of the loga_iomode field <lb/>depends upon the layout type, but should reflect the client&apos;s data <lb/>access intent. <lb/>If the metadata server is in a grace period, and does not persist <lb/>layouts and device ID to device address mappings, then it MUST return <lb/>NFS4ERR_GRACE (see Section 8.4.2.1). <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 564] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The LAYOUTGET operation returns layout information for the specified <lb/>byte-range: a layout. The client actually specifies two ranges, both <lb/>starting at the offset in the loga_offset field. The first range is <lb/>between loga_offset and loga_offset + loga_length -1 inclusive. <lb/>This range indicates the desired range the client wants the layout to <lb/>cover. The second range is between loga_offset and loga_offset + <lb/>loga_minlength -1 inclusive. This range indicates the required <lb/>range the client needs the layout to cover. Thus, loga_minlength <lb/>MUST be less than or equal to loga_length. <lb/>When a length field is set to NFS4_UINT64_MAX, this indicates a <lb/>desire (when loga_length is NFS4_UINT64_MAX) or requirement (when <lb/>loga_minlength is NFS4_UINT64_MAX) to get a layout from loga_offset <lb/>through the end-of-file, regardless of the file&apos;s length. <lb/>The following rules govern the relationships among, and the minima <lb/>of, loga_length, loga_minlength, and loga_offset. <lb/>o If loga_length is less than loga_minlength, the metadata server <lb/>MUST return NFS4ERR_INVAL. <lb/>o If loga_minlength is zero, this is an indication to the metadata <lb/>server that the client desires any layout at offset loga_offset or <lb/>less that the metadata server has &quot;readily available&quot;. Readily is <lb/>subjective, and depends on the layout type and the pNFS server <lb/>implementation. For example, some metadata servers might have to <lb/>pre-allocate stable storage when they receive a request for a <lb/>range of a file that goes beyond the file&apos;s current length. If <lb/>loga_minlength is zero and loga_length is greater than zero, this <lb/>tells the metadata server what range of the layout the client <lb/>would prefer to have. If loga_length and loga_minlength are both <lb/>zero, then the client is indicating that it desires a layout of <lb/>any length with the ending offset of the range no less than the <lb/>value specified loga_offset, and the starting offset at or below <lb/>loga_offset. If the metadata server does not have a layout that <lb/>is readily available, then it MUST return NFS4ERR_LAYOUTTRYLATER. <lb/>o If the sum of loga_offset and loga_minlength exceeds <lb/>NFS4_UINT64_MAX, and loga_minlength is not NFS4_UINT64_MAX, the <lb/>error NFS4ERR_INVAL MUST result. <lb/>o If the sum of loga_offset and loga_length exceeds NFS4_UINT64_MAX, <lb/>and loga_length is not NFS4_UINT64_MAX, the error NFS4ERR_INVAL <lb/>MUST result. <lb/>After the metadata server has performed the above checks on <lb/>loga_offset, loga_minlength, and loga_offset, the metadata server <lb/>MUST return a layout according to the rules in Table 13. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 565] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Acceptable layouts based on loga_minlength. Note: u64m = <lb/>NFS4_UINT64_MAX; a_off = loga_offset; a_minlen = loga_minlength. <lb/>+-----------+-----------+----------+----------+---------------------+ <lb/>| Layout <lb/>| Layout <lb/>| Layout <lb/>| Layout <lb/>| Layout length of <lb/>| <lb/>| iomode of | a_minlen | iomode <lb/>| offset <lb/>| reply <lb/>| <lb/>| request <lb/>| of <lb/>| of reply | of reply | <lb/>| <lb/>| <lb/>| request <lb/>| <lb/>| <lb/>| <lb/>| <lb/>+-----------+-----------+----------+----------+---------------------+ <lb/>| _READ <lb/>| u64m <lb/>| MAY be <lb/>| MUST be | MUST be &gt;= file <lb/>| <lb/>| <lb/>| <lb/>| _READ <lb/>| &lt;= a_off | length -layout <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| offset <lb/>| <lb/>| _READ <lb/>| u64m <lb/>| MAY be <lb/>| MUST be | MUST be u64m <lb/>| <lb/>| <lb/>| <lb/>| _RW <lb/>| &lt;= a_off | <lb/>| <lb/>| _READ <lb/>| &gt; 0 and &lt; | MAY be <lb/>| MUST be | MUST be &gt;= MIN(file | <lb/>| <lb/>| u64m <lb/>| _READ <lb/>| &lt;= a_off | length, a_minlen + | <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| a_off) -layout <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| offset <lb/>| <lb/>| _READ <lb/>| &gt; 0 and &lt; | MAY be <lb/>| MUST be | MUST be &gt;= a_off -| <lb/>| <lb/>| u64m <lb/>| _RW <lb/>| &lt;= a_off | layout offset + <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| a_minlen <lb/>| <lb/>| _READ <lb/>| 0 <lb/>| MAY be <lb/>| MUST be | MUST be &gt; 0 <lb/>| <lb/>| <lb/>| <lb/>| _READ <lb/>| &lt;= a_off | <lb/>| <lb/>| _READ <lb/>| 0 <lb/>| MAY be <lb/>| MUST be | MUST be &gt; 0 <lb/>| <lb/>| <lb/>| <lb/>| _RW <lb/>| &lt;= a_off | <lb/>| <lb/>| _RW <lb/>| u64m <lb/>| MUST be | MUST be | MUST be u64m <lb/>| <lb/>| <lb/>| <lb/>| _RW <lb/>| &lt;= a_off | <lb/>| <lb/>| _RW <lb/>| &gt; 0 and &lt; | MUST be | MUST be | MUST be &gt;= a_off -| <lb/>| <lb/>| u64m <lb/>| _RW <lb/>| &lt;= a_off | layout offset + <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| a_minlen <lb/>| <lb/>| _RW <lb/>| 0 <lb/>| MUST be | MUST be | MUST be &gt; 0 <lb/>| <lb/>| <lb/>| <lb/>| _RW <lb/>| &lt;= a_off | <lb/>| <lb/>+-----------+-----------+----------+----------+---------------------+ <lb/>Table 13 <lb/>If loga_minlength is not zero and the metadata server cannot return a <lb/>layout according to the rules in Table 13, then the metadata server <lb/>MUST return the error NFS4ERR_BADLAYOUT. If loga_minlength is zero <lb/>and the metadata server cannot or will not return a layout according <lb/>to the rules in Table 13, then the metadata server MUST return the <lb/>error NFS4ERR_LAYOUTTRYLATER. Assuming that loga_length is greater <lb/>than loga_minlength or equal to zero, the metadata server SHOULD <lb/>return a layout according to the rules in Table 14. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 566] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Desired layouts based on loga_length. The rules of Table 13 MUST be <lb/>applied first. Note: u64m = NFS4_UINT64_MAX; a_off = loga_offset; <lb/>a_len = loga_length. <lb/>+------------+------------+-----------+-----------+-----------------+ <lb/>| Layout <lb/>| Layout <lb/>| Layout <lb/>| Layout <lb/>| Layout length <lb/>| <lb/>| iomode of | a_len of <lb/>| iomode of | offset of | of reply <lb/>| <lb/>| request <lb/>| request <lb/>| reply <lb/>| reply <lb/>| <lb/>| <lb/>+------------+------------+-----------+-----------+-----------------+ <lb/>| _READ <lb/>| u64m <lb/>| MAY be <lb/>| MUST be <lb/>| SHOULD be u64m | <lb/>| <lb/>| <lb/>| _READ <lb/>| &lt;= a_off | <lb/>| <lb/>| _READ <lb/>| u64m <lb/>| MAY be <lb/>| MUST be <lb/>| SHOULD be u64m | <lb/>| <lb/>| <lb/>| _RW <lb/>| &lt;= a_off | <lb/>| <lb/>| _READ <lb/>| &gt; 0 and &lt; | MAY be <lb/>| MUST be <lb/>| SHOULD be &gt;= <lb/>| <lb/>| <lb/>| u64m <lb/>| _READ <lb/>| &lt;= a_off | a_off -layout | <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| offset + a_len | <lb/>| _READ <lb/>| &gt; 0 and &lt; | MAY be <lb/>| MUST be <lb/>| SHOULD be &gt;= <lb/>| <lb/>| <lb/>| u64m <lb/>| _RW <lb/>| &lt;= a_off | a_off -layout | <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| offset + a_len | <lb/>| _READ <lb/>| 0 <lb/>| MAY be <lb/>| MUST be <lb/>| SHOULD be &gt; <lb/>| <lb/>| <lb/>| <lb/>| _READ <lb/>| &lt;= a_off | a_off -layout | <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| offset <lb/>| <lb/>| _READ <lb/>| 0 <lb/>| MAY be <lb/>| MUST be <lb/>| SHOULD be &gt; <lb/>| <lb/>| <lb/>| <lb/>| _READ <lb/>| &lt;= a_off | a_off -layout | <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| offset <lb/>| <lb/>| _RW <lb/>| u64m <lb/>| MUST be <lb/>| MUST be <lb/>| SHOULD be u64m | <lb/>| <lb/>| <lb/>| _RW <lb/>| &lt;= a_off | <lb/>| <lb/>| _RW <lb/>| &gt; 0 and &lt; | MUST be <lb/>| MUST be <lb/>| SHOULD be &gt;= <lb/>| <lb/>| <lb/>| u64m <lb/>| _RW <lb/>| &lt;= a_off | a_off -layout | <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| offset + a_len | <lb/>| _RW <lb/>| 0 <lb/>| MUST be <lb/>| MUST be <lb/>| SHOULD be &gt; <lb/>| <lb/>| <lb/>| <lb/>| _RW <lb/>| &lt;= a_off | a_off -layout | <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| offset <lb/>| <lb/>+------------+------------+-----------+-----------+-----------------+ <lb/>Table 14 <lb/>The loga_stateid field specifies a valid stateid. If a layout is not <lb/>currently held by the client, the loga_stateid field represents a <lb/>stateid reflecting the correspondingly valid open, byte-range lock, <lb/>or delegation stateid. Once a layout is held on the file by the <lb/>client, the loga_stateid field MUST be a stateid as returned from a <lb/>previous LAYOUTGET or LAYOUTRETURN operation or provided by a <lb/>CB_LAYOUTRECALL operation (see Section 12.5.3). <lb/>The loga_maxcount field specifies the maximum layout size (in bytes) <lb/>that the client can handle. If the size of the layout structure <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 567] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>exceeds the size specified by maxcount, the metadata server will <lb/>return the NFS4ERR_TOOSMALL error. <lb/>The returned layout is expressed as an array, logr_layout, with each <lb/>element of type layout4. If a file has a single striping pattern, <lb/>then logr_layout SHOULD contain just one entry. Otherwise, if the <lb/>requested range overlaps more than one striping pattern, logr_layout <lb/>will contain the required number of entries. The elements of <lb/>logr_layout MUST be sorted in ascending order of the value of the <lb/>lo_offset field of each element. There MUST be no gaps or overlaps <lb/>in the range between two successive elements of logr_layout. The <lb/>lo_iomode field in each element of logr_layout MUST be the same. <lb/>Table 13 and Table 14 both refer to a returned layout iomode, offset, <lb/>and length. Because the returned layout is encoded in the <lb/>logr_layout array, more description is required. <lb/>iomode <lb/>The value of the returned layout iomode listed in Table 13 and <lb/>Table 14 is equal to the value of the lo_iomode field in each <lb/>element of logr_layout. As shown in Table 13 and Table 14, the <lb/>metadata server MAY return a layout with an lo_iomode different <lb/>from the requested iomode (field loga_iomode of the request). If <lb/>it does so, it MUST ensure that the lo_iomode is more permissive <lb/>than the loga_iomode requested. For example, this behavior allows <lb/>an implementation to upgrade LAYOUTIOMODE4_READ requests to <lb/>LAYOUTIOMODE4_RW requests at its discretion, within the limits of <lb/>the layout type specific protocol. A lo_iomode of either <lb/>LAYOUTIOMODE4_READ or LAYOUTIOMODE4_RW MUST be returned. <lb/>offset <lb/>The value of the returned layout offset listed in Table 13 and <lb/>Table 14 is always equal to the lo_offset field of the first <lb/>element logr_layout. <lb/>length <lb/>When setting the value of the returned layout length, the <lb/>situation is complicated by the possibility that the special <lb/>layout length value NFS4_UINT64_MAX is involved. For a <lb/>logr_layout array of N elements, the lo_length field in the first <lb/>N-1 elements MUST NOT be NFS4_UINT64_MAX. The lo_length field of <lb/>the last element of logr_layout can be NFS4_UINT64_MAX under some <lb/>conditions as described in the following list. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 568] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>* If an applicable rule of Table 13 states that the metadata <lb/>server MUST return a layout of length NFS4_UINT64_MAX, then the <lb/>lo_length field of the last element of logr_layout MUST be <lb/>NFS4_UINT64_MAX. <lb/>* If an applicable rule of Table 13 states that the metadata <lb/>server MUST NOT return a layout of length NFS4_UINT64_MAX, then <lb/>the lo_length field of the last element of logr_layout MUST NOT <lb/>be NFS4_UINT64_MAX. <lb/>* If an applicable rule of Table 14 states that the metadata <lb/>server SHOULD return a layout of length NFS4_UINT64_MAX, then <lb/>the lo_length field of the last element of logr_layout SHOULD <lb/>be NFS4_UINT64_MAX. <lb/>* When the value of the returned layout length of Table 13 and <lb/>Table 14 is not NFS4_UINT64_MAX, then the returned layout <lb/>length is equal to the sum of the lo_length fields of each <lb/>element of logr_layout. <lb/>The logr_return_on_close result field is a directive to return the <lb/>layout before closing the file. When the metadata server sets this <lb/>return value to TRUE, it MUST be prepared to recall the layout in the <lb/>case in which the client fails to return the layout before close. <lb/>For the metadata server that knows a layout must be returned before a <lb/>close of the file, this return value can be used to communicate the <lb/>desired behavior to the client and thus remove one extra step from <lb/>the client&apos;s and metadata server&apos;s interaction. <lb/>The logr_stateid stateid is returned to the client for use in <lb/>subsequent layout related operations. See Sections 8.2, 12.5.3, and <lb/>12.5.5.2 for a further discussion and requirements. <lb/>The format of the returned layout (lo_content) is specific to the <lb/>layout type. The value of the layout type (lo_content.loc_type) for <lb/>each of the elements of the array of layouts returned by the metadata <lb/>server (logr_layout) MUST be equal to the loga_layout_type specified <lb/>by the client. If it is not equal, the client SHOULD ignore the <lb/>response as invalid and behave as if the metadata server returned an <lb/>error, even if the client does have support for the layout type <lb/>returned. <lb/>If neither the requested file nor its containing file system support <lb/>layouts, the metadata server MUST return NFS4ERR_LAYOUTUNAVAILABLE. <lb/>If the layout type is not supported, the metadata server MUST return <lb/>NFS4ERR_UNKNOWN_LAYOUTTYPE. If layouts are supported but no layout <lb/>matches the client provided layout identification, the metadata <lb/>server MUST return NFS4ERR_BADLAYOUT. If an invalid loga_iomode is <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 569] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>specified, or a loga_iomode of LAYOUTIOMODE4_ANY is specified, the <lb/>metadata server MUST return NFS4ERR_BADIOMODE. <lb/>If the layout for the file is unavailable due to transient <lb/>conditions, e.g., file sharing prohibits layouts, the metadata server <lb/>MUST return NFS4ERR_LAYOUTTRYLATER. <lb/>If the layout request is rejected due to an overlapping layout <lb/>recall, the metadata server MUST return NFS4ERR_RECALLCONFLICT. See <lb/>Section 12.5.5.2 for details. <lb/>If the layout conflicts with a mandatory byte-range lock held on the <lb/>file, and if the storage devices have no method of enforcing <lb/>mandatory locks, other than through the restriction of layouts, the <lb/>metadata server SHOULD return NFS4ERR_LOCKED. <lb/>If client sets loga_signal_layout_avail to TRUE, then it is <lb/>registering with the client a &quot;want&quot; for a layout in the event the <lb/>layout cannot be obtained due to resource exhaustion. If the <lb/>metadata server supports and will honor the &quot;want&quot;, the results will <lb/>have logr_will_signal_layout_avail set to TRUE. If so, the client <lb/>should expect a CB_RECALLABLE_OBJ_AVAIL operation to indicate that a <lb/>layout is available. <lb/>On success, the current filehandle retains its value and the current <lb/>stateid is updated to match the value as returned in the results. <lb/>18.43.4. IMPLEMENTATION <lb/>Typically, LAYOUTGET will be called as part of a COMPOUND request <lb/>after an OPEN operation and results in the client having location <lb/>information for the file. This requires that loga_stateid be set to <lb/>the special stateid that tells the metadata server to use the current <lb/>stateid, which is set by OPEN (see Section 16.2.3.1.2). A client may <lb/>also hold a layout across multiple OPENs. The client specifies a <lb/>layout type that limits what kind of layout the metadata server will <lb/>return. This prevents metadata servers from granting layouts that <lb/>are unusable by the client. <lb/>As indicated by Table 13 and Table 14, the specification of LAYOUTGET <lb/>allows a pNFS client and server considerable flexibility. A pNFS <lb/>client can take several strategies for sending LAYOUTGET. Some <lb/>examples are as follows. <lb/>o If LAYOUTGET is preceded by OPEN in the same COMPOUND request and <lb/>the OPEN requests OPEN4_SHARE_ACCESS_READ access, the client might <lb/>opt to request a _READ layout with loga_offset set to zero, <lb/>loga_minlength set to zero, and loga_length set to <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 570] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>NFS4_UINT64_MAX. If the file has space allocated to it, that <lb/>space is striped over one or more storage devices, and there is <lb/>either no conflicting layout or the concept of a conflicting <lb/>layout does not apply to the pNFS server&apos;s layout type or <lb/>implementation, then the metadata server might return a layout <lb/>with a starting offset of zero, and a length equal to the length <lb/>of the file, if not NFS4_UINT64_MAX. If the length of the file is <lb/>not a multiple of the pNFS server&apos;s stripe width (see Section 13.2 <lb/>for a formal definition), the metadata server might round up the <lb/>returned layout&apos;s length. <lb/>o If LAYOUTGET is preceded by OPEN in the same COMPOUND request, and <lb/>the OPEN requests OPEN4_SHARE_ACCESS_WRITE access and does not <lb/>truncate the file, the client might opt to request a _RW layout <lb/>with loga_offset set to zero, loga_minlength set to zero, and <lb/>loga_length set to the file&apos;s current length (if known), or <lb/>NFS4_UINT64_MAX. As with the previous case, under some conditions <lb/>the metadata server might return a layout that covers the entire <lb/>length of the file or beyond. <lb/>o This strategy is as above, but the OPEN truncates the file. In <lb/>this case, the client might anticipate it will be writing to the <lb/>file from offset zero, and so loga_offset and loga_minlength are <lb/>set to zero, and loga_length is set to the value of <lb/>threshold4_write_iosize. The metadata server might return a <lb/>layout from offset zero with a length at least as long as <lb/>threshold4_write_iosize. <lb/>o A process on the client invokes a request to read from offset <lb/>10000 for length 50000. The client is using buffered I/O, and has <lb/>buffer sizes of 4096 bytes. The client intends to map the request <lb/>of the process into a series of READ requests starting at offset <lb/>8192. The end offset needs to be higher than 10000 + 50000 = <lb/>60000, and the next offset that is a multiple of 4096 is 61440. <lb/>The difference between 61440 and that starting offset of the <lb/>layout is 53248 (which is the product of 4096 and 15). The value <lb/>of threshold4_read_iosize is less than 53248, so the client sends <lb/>a LAYOUTGET request with loga_offset set to 8192, loga_minlength <lb/>set to 53248, and loga_length set to the file&apos;s length (if known) <lb/>minus 8192 or NFS4_UINT64_MAX (if the file&apos;s length is not known). <lb/>Since this LAYOUTGET request exceeds the metadata server&apos;s <lb/>threshold, it grants the layout, possibly with an initial offset <lb/>of zero, with an end offset of at least 8192 + 53248 -1 = 61439, <lb/>but preferably a layout with an offset aligned on the stripe width <lb/>and a length that is a multiple of the stripe width. <lb/>o This strategy is as above, but the client is not using buffered I/ <lb/>O, and instead all internal I/O requests are sent directly to the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 571] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>server. The LAYOUTGET request has loga_offset equal to 10000 and <lb/>loga_minlength set to 50000. The value of loga_length is set to <lb/>the length of the file. The metadata server is free to return a <lb/>layout that fully overlaps the requested range, with a starting <lb/>offset and length aligned on the stripe width. <lb/>o Again, a process on the client invokes a request to read from <lb/>offset 10000 for length 50000 (i.e. a range with a starting offset <lb/>of 10000 and an ending offset of 69999), and buffered I/O is in <lb/>use. The client is expecting that the server might not be able to <lb/>return the layout for the full I/O range. The client intends to <lb/>map the request of the process into a series of thirteen READ <lb/>requests starting at offset 8192, each with length 4096, with a <lb/>total length of 53248 (which equals 13 * 4096), which fully <lb/>contains the range that client&apos;s process wants to read. Because <lb/>the value of threshold4_read_iosize is equal to 4096, it is <lb/>practical and reasonable for the client to use several LAYOUTGET <lb/>operations to complete the series of READs. The client sends a <lb/>LAYOUTGET request with loga_offset set to 8192, loga_minlength set <lb/>to 4096, and loga_length set to 53248 or higher. The server will <lb/>grant a layout possibly with an initial offset of zero, with an <lb/>end offset of at least 8192 + 4096 -1 = 12287, but preferably a <lb/>layout with an offset aligned on the stripe width and a length <lb/>that is a multiple of the stripe width. This will allow the <lb/>client to make forward progress, possibly sending more LAYOUTGET <lb/>operations for the remainder of the range. <lb/>o An NFS client detects a sequential read pattern, and so sends a <lb/>LAYOUTGET operation that goes well beyond any current or pending <lb/>read requests to the server. The server might likewise detect <lb/>this pattern, and grant the LAYOUTGET request. Once the client <lb/>reads from an offset of the file that represents 50% of the way <lb/>through the range of the last layout it received, in order to <lb/>avoid stalling I/O that would wait for a layout, the client sends <lb/>more operations from an offset of the file that represents 50% of <lb/>the way through the last layout it received. The client continues <lb/>to request layouts with byte-ranges that are well in advance of <lb/>the byte-ranges of recent and/or read requests of processes <lb/>running on the client. <lb/>o This strategy is as above, but the client fails to detect the <lb/>pattern, but the server does. The next time the metadata server <lb/>gets a LAYOUTGET, it returns a layout with a length that is well <lb/>beyond loga_minlength. <lb/>o A client is using buffered I/O, and has a long queue of write-<lb/>behinds to process and also detects a sequential write pattern. <lb/>It sends a LAYOUTGET for a layout that spans the range of the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 572] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>queued write-behinds and well beyond, including ranges beyond the <lb/>filer&apos;s current length. The client continues to send LAYOUTGET <lb/>operations once the write-behind queue reaches 50% of the maximum <lb/>queue length. <lb/>Once the client has obtained a layout referring to a particular <lb/>device ID, the metadata server MUST NOT delete the device ID until <lb/>the layout is returned or revoked. <lb/>CB_NOTIFY_DEVICEID can race with LAYOUTGET. One race scenario is <lb/>that LAYOUTGET returns a device ID for which the client does not have <lb/>device address mappings, and the metadata server sends a <lb/>CB_NOTIFY_DEVICEID to add the device ID to the client&apos;s awareness and <lb/>meanwhile the client sends GETDEVICEINFO on the device ID. This <lb/>scenario is discussed in Section 18.40.4. Another scenario is that <lb/>the CB_NOTIFY_DEVICEID is processed by the client before it processes <lb/>the results from LAYOUTGET. The client will send a GETDEVICEINFO on <lb/>the device ID. If the results from GETDEVICEINFO are received before <lb/>the client gets results from LAYOUTGET, then there is no longer a <lb/>race. If the results from LAYOUTGET are received before the results <lb/>from GETDEVICEINFO, the client can either wait for results of <lb/>GETDEVICEINFO or send another one to get possibly more up-to-date <lb/>device address mappings for the device ID. <lb/>18.44. Operation 51: LAYOUTRETURN -Release Layout Information <lb/>18.44.1. ARGUMENT <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 573] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>/* Constants used for LAYOUTRETURN and CB_LAYOUTRECALL */ <lb/>const LAYOUT4_RET_REC_FILE <lb/>= 1; <lb/>const LAYOUT4_RET_REC_FSID <lb/>= 2; <lb/>const LAYOUT4_RET_REC_ALL <lb/>= 3; <lb/>enum layoutreturn_type4 { <lb/>LAYOUTRETURN4_FILE = LAYOUT4_RET_REC_FILE, <lb/>LAYOUTRETURN4_FSID = LAYOUT4_RET_REC_FSID, <lb/>LAYOUTRETURN4_ALL = LAYOUT4_RET_REC_ALL <lb/>}; <lb/>struct layoutreturn_file4 { <lb/>offset4 <lb/>lrf_offset; <lb/>length4 <lb/>lrf_length; <lb/>stateid4 <lb/>lrf_stateid; <lb/>/* layouttype4 specific data */ <lb/>opaque <lb/>lrf_body&lt;&gt;; <lb/>}; <lb/>union layoutreturn4 switch(layoutreturn_type4 lr_returntype) { <lb/>case LAYOUTRETURN4_FILE: <lb/>layoutreturn_file4 <lb/>lr_layout; <lb/>default: <lb/>void; <lb/>}; <lb/>struct LAYOUTRETURN4args { <lb/>/* CURRENT_FH: file */ <lb/>bool <lb/>lora_reclaim; <lb/>layouttype4 <lb/>lora_layout_type; <lb/>layoutiomode4 <lb/>lora_iomode; <lb/>layoutreturn4 <lb/>lora_layoutreturn; <lb/>}; <lb/>18.44.2. RESULT <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 574] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>union layoutreturn_stateid switch (bool lrs_present) { <lb/>case TRUE: <lb/>stateid4 <lb/>lrs_stateid; <lb/>case FALSE: <lb/>void; <lb/>}; <lb/>union LAYOUTRETURN4res switch (nfsstat4 lorr_status) { <lb/>case NFS4_OK: <lb/>layoutreturn_stateid <lb/>lorr_stateid; <lb/>default: <lb/>void; <lb/>}; <lb/>18.44.3. DESCRIPTION <lb/>This operation returns from the client to the server one or more <lb/>layouts represented by the client ID (derived from the session ID in <lb/>the preceding SEQUENCE operation), lora_layout_type, and lora_iomode. <lb/>When lr_returntype is LAYOUTRETURN4_FILE, the returned layout is <lb/>further identified by the current filehandle, lrf_offset, lrf_length, <lb/>and lrf_stateid. If the lrf_length field is NFS4_UINT64_MAX, all <lb/>bytes of the layout, starting at lrf_offset, are returned. When <lb/>lr_returntype is LAYOUTRETURN4_FSID, the current filehandle is used <lb/>to identify the file system and all layouts matching the client ID, <lb/>the fsid of the file system, lora_layout_type, and lora_iomode are <lb/>returned. When lr_returntype is LAYOUTRETURN4_ALL, all layouts <lb/>matching the client ID, lora_layout_type, and lora_iomode are <lb/>returned and the current filehandle is not used. After this call, <lb/>the client MUST NOT use the returned layout(s) and the associated <lb/>storage protocol to access the file data. <lb/>If the set of layouts designated in the case of LAYOUTRETURN4_FSID or <lb/>LAYOUTRETURN4_ALL is empty, then no error results. In the case of <lb/>LAYOUTRETURN4_FILE, the byte-range specified is returned even if it <lb/>is a subdivision of a layout previously obtained with LAYOUTGET, a <lb/>combination of multiple layouts previously obtained with LAYOUTGET, <lb/>or a combination including some layouts previously obtained with <lb/>LAYOUTGET, and one or more subdivisions of such layouts. When the <lb/>byte-range does not designate any bytes for which a layout is held <lb/>for the specified file, client ID, layout type and mode, no error <lb/>results. See Section 12.5.5.2.1.5 for considerations with &quot;bulk&quot; <lb/>return of layouts. <lb/>The layout being returned may be a subset or superset of a layout <lb/>specified by CB_LAYOUTRECALL. However, if it is a subset, the recall <lb/>is not complete until the full recalled scope has been returned. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 575] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Recalled scope refers to the byte-range in the case of <lb/>LAYOUTRETURN4_FILE, the use of LAYOUTRETURN4_FSID, or the use of <lb/>LAYOUTRETURN4_ALL. There must be a LAYOUTRETURN with a matching <lb/>scope to complete the return even if all current layout ranges have <lb/>been previously individually returned. <lb/>For all lr_returntype values, an iomode of LAYOUTIOMODE4_ANY <lb/>specifies that all layouts that match the other arguments to <lb/>LAYOUTRETURN (i.e., client ID, lora_layout_type, and one of current <lb/>filehandle and range; fsid derived from current filehandle; or <lb/>LAYOUTRETURN4_ALL) are being returned. <lb/>In the case that lr_returntype is LAYOUTRETURN4_FILE, the lrf_stateid <lb/>provided by the client is a layout stateid as returned from previous <lb/>layout operations. Note that the &quot;seqid&quot; field of lrf_stateid MUST <lb/>NOT be zero. See Sections 8.2, 12.5.3, and 12.5.5.2 for a further <lb/>discussion and requirements. <lb/>Return of a layout or all layouts does not invalidate the mapping of <lb/>storage device ID to a storage device address. The mapping remains <lb/>in effect until specifically changed or deleted via device ID <lb/>notification callbacks. Of course if there are no remaining layouts <lb/>that refer to a previously used device ID, the server is free to <lb/>delete a device ID without a notification callback, which will be the <lb/>case when notifications are not in effect. <lb/>If the lora_reclaim field is set to TRUE, the client is attempting to <lb/>return a layout that was acquired before the restart of the metadata <lb/>server during the metadata server&apos;s grace period. When returning <lb/>layouts that were acquired during the metadata server&apos;s grace period, <lb/>the client MUST set the lora_reclaim field to FALSE. The <lb/>lora_reclaim field MUST be set to FALSE also when lr_layoutreturn is <lb/>LAYOUTRETURN4_FSID or LAYOUTRETURN4_ALL. See LAYOUTCOMMIT <lb/>(Section 18.42) for more details. <lb/>Layouts may be returned when recalled or voluntarily (i.e., before <lb/>the server has recalled them). In either case, the client must <lb/>properly propagate state changed under the context of the layout to <lb/>the storage device(s) or to the metadata server before returning the <lb/>layout. <lb/>If the client returns the layout in response to a CB_LAYOUTRECALL <lb/>where the lor_recalltype field of the clora_recall field was <lb/>LAYOUTRECALL4_FILE, the client should use the lor_stateid value from <lb/>CB_LAYOUTRECALL as the value for lrf_stateid. Otherwise, it should <lb/>use logr_stateid (from a previous LAYOUTGET result) or lorr_stateid <lb/>(from a previous LAYRETURN result). This is done to indicate the <lb/>point in time (in terms of layout stateid transitions) when the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 576] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>recall was sent. The client uses the precise lora_recallstateid <lb/>value and MUST NOT set the stateid&apos;s seqid to zero; otherwise, <lb/>NFS4ERR_BAD_STATEID MUST be returned. NFS4ERR_OLD_STATEID can be <lb/>returned if the client is using an old seqid, and the server knows <lb/>the client should not be using the old seqid. For example, the <lb/>client uses the seqid on slot 1 of the session, receives the response <lb/>with the new seqid, and uses the slot to send another request with <lb/>the old seqid. <lb/>If a client fails to return a layout in a timely manner, then the <lb/>metadata server SHOULD use its control protocol with the storage <lb/>devices to fence the client from accessing the data referenced by the <lb/>layout. See Section 12.5.5 for more details. <lb/>If the LAYOUTRETURN request sets the lora_reclaim field to TRUE after <lb/>the metadata server&apos;s grace period, NFS4ERR_NO_GRACE is returned. <lb/>If the LAYOUTRETURN request sets the lora_reclaim field to TRUE and <lb/>lr_returntype is set to LAYOUTRETURN4_FSID or LAYOUTRETURN4_ALL, <lb/>NFS4ERR_INVAL is returned. <lb/>If the client sets the lr_returntype field to LAYOUTRETURN4_FILE, <lb/>then the lrs_stateid field will represent the layout stateid as <lb/>updated for this operation&apos;s processing; the current stateid will <lb/>also be updated to match the returned value. If the last byte of any <lb/>layout for the current file, client ID, and layout type is being <lb/>returned and there are no remaining pending CB_LAYOUTRECALL <lb/>operations for which a LAYOUTRETURN operation must be done, <lb/>lrs_present MUST be FALSE, and no stateid will be returned. In <lb/>addition, the COMPOUND request&apos;s current stateid will be set to the <lb/>all-zeroes special stateid (see Section 16.2.3.1.2). The server MUST <lb/>reject with NFS4ERR_BAD_STATEID any further use of the current <lb/>stateid in that COMPOUND until the current stateid is re-established <lb/>by a later stateid-returning operation. <lb/>On success, the current filehandle retains its value. <lb/>If the EXCHGID4_FLAG_BIND_PRINC_STATEID capability is set on the <lb/>client ID (see Section 18.35), the server will require that the <lb/>principal, security flavor, and if applicable, the GSS mechanism, <lb/>combination that acquired the layout also be the one to send <lb/>LAYOUTRETURN. This might not be possible if credentials for the <lb/>principal are no longer available. The server will allow the machine <lb/>credential or SSV credential (see Section 18.35) to send LAYOUTRETURN <lb/>if LAYOUTRETURN&apos;s operation code was set in the spo_must_allow result <lb/>of EXCHANGE_ID. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 577] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.44.4. IMPLEMENTATION <lb/>The final LAYOUTRETURN operation in response to a CB_LAYOUTRECALL <lb/>callback MUST be serialized with any outstanding, intersecting <lb/>LAYOUTRETURN operations. Note that it is possible that while a <lb/>client is returning the layout for some recalled range, the server <lb/>may recall a superset of that range (e.g., LAYOUTRECALL4_ALL); the <lb/>final return operation for the latter must block until the former <lb/>layout recall is done. <lb/>Returning all layouts in a file system using LAYOUTRETURN4_FSID is <lb/>typically done in response to a CB_LAYOUTRECALL for that file system <lb/>as the final return operation. Similarly, LAYOUTRETURN4_ALL is used <lb/>in response to a recall callback for all layouts. It is possible <lb/>that the client already returned some outstanding layouts via <lb/>individual LAYOUTRETURN calls and the call for LAYOUTRETURN4_FSID or <lb/>LAYOUTRETURN4_ALL marks the end of the LAYOUTRETURN sequence. See <lb/>Section 12.5.5.1 for more details. <lb/>Once the client has returned all layouts referring to a particular <lb/>device ID, the server MAY delete the device ID. <lb/>18.45. Operation 52: SECINFO_NO_NAME -Get Security on Unnamed Object <lb/>18.45.1. ARGUMENT <lb/>enum secinfo_style4 { <lb/>SECINFO_STYLE4_CURRENT_FH <lb/>= 0, <lb/>SECINFO_STYLE4_PARENT <lb/>= 1 <lb/>}; <lb/>/* CURRENT_FH: object or child directory */ <lb/>typedef secinfo_style4 SECINFO_NO_NAME4args; <lb/>18.45.2. RESULT <lb/>/* CURRENTFH: consumed if status is NFS4_OK */ <lb/>typedef SECINFO4res SECINFO_NO_NAME4res; <lb/>18.45.3. DESCRIPTION <lb/>Like the SECINFO operation, SECINFO_NO_NAME is used by the client to <lb/>obtain a list of valid RPC authentication flavors for a specific file <lb/>object. Unlike SECINFO, SECINFO_NO_NAME only works with objects that <lb/>are accessed by filehandle. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 578] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>There are two styles of SECINFO_NO_NAME, as determined by the value <lb/>of the secinfo_style4 enumeration. If SECINFO_STYLE4_CURRENT_FH is <lb/>passed, then SECINFO_NO_NAME is querying for the required security <lb/>for the current filehandle. If SECINFO_STYLE4_PARENT is passed, then <lb/>SECINFO_NO_NAME is querying for the required security of the current <lb/>filehandle&apos;s parent. If the style selected is SECINFO_STYLE4_PARENT, <lb/>then SECINFO should apply the same access methodology used for <lb/>LOOKUPP when evaluating the traversal to the parent directory. <lb/>Therefore, if the requester does not have the appropriate access to <lb/>LOOKUPP the parent, then SECINFO_NO_NAME must behave the same way and <lb/>return NFS4ERR_ACCESS. <lb/>If PUTFH, PUTPUBFH, PUTROOTFH, or RESTOREFH returns NFS4ERR_WRONGSEC, <lb/>then the client resolves the situation by sending a COMPOUND request <lb/>that consists of PUTFH, PUTPUBFH, or PUTROOTFH immediately followed <lb/>by SECINFO_NO_NAME, style SECINFO_STYLE4_CURRENT_FH. See Section 2.6 <lb/>for instructions on dealing with NFS4ERR_WRONGSEC error returns from <lb/>PUTFH, PUTROOTFH, PUTPUBFH, or RESTOREFH. <lb/>If SECINFO_STYLE4_PARENT is specified and there is no parent <lb/>directory, SECINFO_NO_NAME MUST return NFS4ERR_NOENT. <lb/>On success, the current filehandle is consumed (see <lb/>Section 2.6.3.1.1.8), and if the next operation after SECINFO_NO_NAME <lb/>tries to use the current filehandle, that operation will fail with <lb/>the status NFS4ERR_NOFILEHANDLE. <lb/>Everything else about SECINFO_NO_NAME is the same as SECINFO. See <lb/>the discussion on SECINFO (Section 18.29.3). <lb/>18.45.4. IMPLEMENTATION <lb/>See the discussion on SECINFO (Section 18.29.4). <lb/>18.46. Operation 53: SEQUENCE -Supply Per-Procedure Sequencing and <lb/>Control <lb/>18.46.1. ARGUMENT <lb/>struct SEQUENCE4args { <lb/>sessionid4 <lb/>sa_sessionid; <lb/>sequenceid4 <lb/>sa_sequenceid; <lb/>slotid4 <lb/>sa_slotid; <lb/>slotid4 <lb/>sa_highest_slotid; <lb/>bool <lb/>sa_cachethis; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 579] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.46.2. RESULT <lb/>const SEQ4_STATUS_CB_PATH_DOWN <lb/>= 0x00000001; <lb/>const SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRING <lb/>= 0x00000002; <lb/>const SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRED <lb/>= 0x00000004; <lb/>const SEQ4_STATUS_EXPIRED_ALL_STATE_REVOKED <lb/>= 0x00000008; <lb/>const SEQ4_STATUS_EXPIRED_SOME_STATE_REVOKED <lb/>= 0x00000010; <lb/>const SEQ4_STATUS_ADMIN_STATE_REVOKED <lb/>= 0x00000020; <lb/>const SEQ4_STATUS_RECALLABLE_STATE_REVOKED <lb/>= 0x00000040; <lb/>const SEQ4_STATUS_LEASE_MOVED <lb/>= 0x00000080; <lb/>const SEQ4_STATUS_RESTART_RECLAIM_NEEDED <lb/>= 0x00000100; <lb/>const SEQ4_STATUS_CB_PATH_DOWN_SESSION <lb/>= 0x00000200; <lb/>const SEQ4_STATUS_BACKCHANNEL_FAULT <lb/>= 0x00000400; <lb/>const SEQ4_STATUS_DEVID_CHANGED <lb/>= 0x00000800; <lb/>const SEQ4_STATUS_DEVID_DELETED <lb/>= 0x00001000; <lb/>struct SEQUENCE4resok { <lb/>sessionid4 <lb/>sr_sessionid; <lb/>sequenceid4 <lb/>sr_sequenceid; <lb/>slotid4 <lb/>sr_slotid; <lb/>slotid4 <lb/>sr_highest_slotid; <lb/>slotid4 <lb/>sr_target_highest_slotid; <lb/>uint32_t <lb/>sr_status_flags; <lb/>}; <lb/>union SEQUENCE4res switch (nfsstat4 sr_status) { <lb/>case NFS4_OK: <lb/>SEQUENCE4resok sr_resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.46.3. DESCRIPTION <lb/>The SEQUENCE operation is used by the server to implement session <lb/>request control and the reply cache semantics. <lb/>SEQUENCE MUST appear as the first operation of any COMPOUND in which <lb/>it appears. The error NFS4ERR_SEQUENCE_POS will be returned when it <lb/>is found in any position in a COMPOUND beyond the first. Operations <lb/>other than SEQUENCE, BIND_CONN_TO_SESSION, EXCHANGE_ID, <lb/>CREATE_SESSION, and DESTROY_SESSION, MUST NOT appear as the first <lb/>operation in a COMPOUND. Such operations MUST yield the error <lb/>NFS4ERR_OP_NOT_IN_SESSION if they do appear at the start of a <lb/>COMPOUND. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 580] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If SEQUENCE is received on a connection not associated with the <lb/>session via CREATE_SESSION or BIND_CONN_TO_SESSION, and connection <lb/>association enforcement is enabled (see Section 18.35), then the <lb/>server returns NFS4ERR_CONN_NOT_BOUND_TO_SESSION. <lb/>The sa_sessionid argument identifies the session to which this <lb/>request applies. The sr_sessionid result MUST equal sa_sessionid. <lb/>The sa_slotid argument is the index in the reply cache for the <lb/>request. The sa_sequenceid field is the sequence number of the <lb/>request for the reply cache entry (slot). The sr_slotid result MUST <lb/>equal sa_slotid. The sr_sequenceid result MUST equal sa_sequenceid. <lb/>The sa_highest_slotid argument is the highest slot ID for which the <lb/>client has a request outstanding; it could be equal to sa_slotid. <lb/>The server returns two &quot;highest_slotid&quot; values: sr_highest_slotid and <lb/>sr_target_highest_slotid. The former is the highest slot ID the <lb/>server will accept in future SEQUENCE operation, and SHOULD NOT be <lb/>less than the value of sa_highest_slotid (but see Section 2.10.6.1 <lb/>for an exception). The latter is the highest slot ID the server <lb/>would prefer the client use on a future SEQUENCE operation. <lb/>If sa_cachethis is TRUE, then the client is requesting that the <lb/>server cache the entire reply in the server&apos;s reply cache; therefore, <lb/>the server MUST cache the reply (see Section 2.10.6.1.3). The server <lb/>MAY cache the reply if sa_cachethis is FALSE. If the server does not <lb/>cache the entire reply, it MUST still record that it executed the <lb/>request at the specified slot and sequence ID. <lb/>The response to the SEQUENCE operation contains a word of status <lb/>flags (sr_status_flags) that can provide to the client information <lb/>related to the status of the client&apos;s lock state and communications <lb/>paths. Note that any status bits relating to lock state MAY be reset <lb/>when lock state is lost due to a server restart (even if the session <lb/>is persistent across restarts; session persistence does not imply <lb/>lock state persistence) or the establishment of a new client <lb/>instance. <lb/>SEQ4_STATUS_CB_PATH_DOWN <lb/>When set, indicates that the client has no operational backchannel <lb/>path for any session associated with the client ID, making it <lb/>necessary for the client to re-establish one. This bit remains <lb/>set on all SEQUENCE responses on all sessions associated with the <lb/>client ID until at least one backchannel is available on any <lb/>session associated with the client ID. If the client fails to re-<lb/>establish a backchannel for the client ID, it is subject to having <lb/>recallable state revoked. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 581] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>SEQ4_STATUS_CB_PATH_DOWN_SESSION <lb/>When set, indicates that the session has no operational <lb/>backchannel. There are two reasons why <lb/>SEQ4_STATUS_CB_PATH_DOWN_SESSION may be set and not <lb/>SEQ4_STATUS_CB_PATH_DOWN. First is that a callback operation that <lb/>applies specifically to the session (e.g., CB_RECALL_SLOT, see <lb/>Section 20.8) needs to be sent. Second is that the server did <lb/>send a callback operation, but the connection was lost before the <lb/>reply. The server cannot be sure whether or not the client <lb/>received the callback operation, and so, per rules on request <lb/>retry, the server MUST retry the callback operation over the same <lb/>session. The SEQ4_STATUS_CB_PATH_DOWN_SESSION bit is the <lb/>indication to the client that it needs to associate a connection <lb/>to the session&apos;s backchannel. This bit remains set on all <lb/>SEQUENCE responses of the session until a connection is associated <lb/>with the session&apos;s a backchannel. If the client fails to re-<lb/>establish a backchannel for the session, it is subject to having <lb/>recallable state revoked. <lb/>SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRING <lb/>When set, indicates that all GSS contexts or RPCSEC_GSS handles <lb/>assigned to the session&apos;s backchannel will expire within a period <lb/>equal to the lease time. This bit remains set on all SEQUENCE <lb/>replies until at least one of the following are true: <lb/>* All SSV RPCSEC_GSS handles on the session&apos;s backchannel have <lb/>been destroyed and all non-SSV GSS contexts have expired. <lb/>* At least one more SSV RPCSEC_GSS handle has been added to the <lb/>backchannel. <lb/>* The expiration time of at least one non-SSV GSS context of an <lb/>RPCSEC_GSS handle is beyond the lease period from the current <lb/>time (relative to the time of when a SEQUENCE response was <lb/>sent) <lb/>SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRED <lb/>When set, indicates all non-SSV GSS contexts and all SSV <lb/>RPCSEC_GSS handles assigned to the session&apos;s backchannel have <lb/>expired or have been destroyed. This bit remains set on all <lb/>SEQUENCE replies until at least one non-expired non-SSV GSS <lb/>context for the session&apos;s backchannel has been established or at <lb/>least one SSV RPCSEC_GSS handle has been assigned to the <lb/>backchannel. <lb/>SEQ4_STATUS_EXPIRED_ALL_STATE_REVOKED <lb/>When set, indicates that the lease has expired and as a result the <lb/>server released all of the client&apos;s locking state. This status <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 582] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>bit remains set on all SEQUENCE replies until the loss of all such <lb/>locks has been acknowledged by use of FREE_STATEID (see <lb/>Section 18.38), or by establishing a new client instance by <lb/>destroying all sessions (via DESTROY_SESSION), the client ID (via <lb/>DESTROY_CLIENTID), and then invoking EXCHANGE_ID and <lb/>CREATE_SESSION to establish a new client ID. <lb/>SEQ4_STATUS_EXPIRED_SOME_STATE_REVOKED <lb/>When set, indicates that some subset of the client&apos;s locks have <lb/>been revoked due to expiration of the lease period followed by <lb/>another client&apos;s conflicting LOCK operation. This status bit <lb/>remains set on all SEQUENCE replies until the loss of all such <lb/>locks has been acknowledged by use of FREE_STATEID. <lb/>SEQ4_STATUS_ADMIN_STATE_REVOKED <lb/>When set, indicates that one or more locks have been revoked <lb/>without expiration of the lease period, due to administrative <lb/>action. This status bit remains set on all SEQUENCE replies until <lb/>the loss of all such locks has been acknowledged by use of <lb/>FREE_STATEID. <lb/>SEQ4_STATUS_RECALLABLE_STATE_REVOKED <lb/>When set, indicates that one or more recallable objects have been <lb/>revoked without expiration of the lease period, due to the <lb/>client&apos;s failure to return them when recalled, which may be a <lb/>consequence of there being no working backchannel and the client <lb/>failing to re-establish a backchannel per the <lb/>SEQ4_STATUS_CB_PATH_DOWN, SEQ4_STATUS_CB_PATH_DOWN_SESSION, or <lb/>SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRED status flags. This status bit <lb/>remains set on all SEQUENCE replies until the loss of all such <lb/>locks has been acknowledged by use of FREE_STATEID. <lb/>SEQ4_STATUS_LEASE_MOVED <lb/>When set, indicates that responsibility for lease renewal has been <lb/>transferred to one or more new servers. This condition will <lb/>continue until the client receives an NFS4ERR_MOVED error and the <lb/>server receives the subsequent GETATTR for the fs_locations or <lb/>fs_locations_info attribute for an access to each file system for <lb/>which a lease has been moved to a new server. See <lb/>Section 11.10.9.1. <lb/>SEQ4_STATUS_RESTART_RECLAIM_NEEDED <lb/>When set, indicates that due to server restart, the client must <lb/>reclaim locking state. Until the client sends a global <lb/>RECLAIM_COMPLETE (Section 18.51), every SEQUENCE operation will <lb/>return SEQ4_STATUS_RESTART_RECLAIM_NEEDED. <lb/>SEQ4_STATUS_BACKCHANNEL_FAULT <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 583] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The server has encountered an unrecoverable fault with the <lb/>backchannel (e.g., it has lost track of the sequence ID for a slot <lb/>in the backchannel). The client MUST stop sending more requests <lb/>on the session&apos;s fore channel, wait for all outstanding requests <lb/>to complete on the fore and back channel, and then destroy the <lb/>session. <lb/>SEQ4_STATUS_DEVID_CHANGED <lb/>The client is using device ID notifications and the server has <lb/>changed a device ID mapping held by the client. This flag will <lb/>stay present until the client has obtained the new mapping with <lb/>GETDEVICEINFO. <lb/>SEQ4_STATUS_DEVID_DELETED <lb/>The client is using device ID notifications and the server has <lb/>deleted a device ID mapping held by the client. This flag will <lb/>stay in effect until the client sends a GETDEVICEINFO on the <lb/>device ID with a null value in the argument gdia_notify_types. <lb/>The value of the sa_sequenceid argument relative to the cached <lb/>sequence ID on the slot falls into one of three cases. <lb/>o If the difference between sa_sequenceid and the server&apos;s cached <lb/>sequence ID at the slot ID is two (2) or more, or if sa_sequenceid <lb/>is less than the cached sequence ID (accounting for wraparound of <lb/>the unsigned sequence ID value), then the server MUST return <lb/>NFS4ERR_SEQ_MISORDERED. <lb/>o If sa_sequenceid and the cached sequence ID are the same, this is <lb/>a retry, and the server replies with what is recorded in the reply <lb/>cache. The lease is possibly renewed as described below. <lb/>o If sa_sequenceid is one greater (accounting for wraparound) than <lb/>the cached sequence ID, then this is a new request, and the slot&apos;s <lb/>sequence ID is incremented. The operations subsequent to <lb/>SEQUENCE, if any, are processed. If there are no other <lb/>operations, the only other effects are to cache the SEQUENCE reply <lb/>in the slot, maintain the session&apos;s activity, and possibly renew <lb/>the lease. <lb/>If the client reuses a slot ID and sequence ID for a completely <lb/>different request, the server MAY treat the request as if it is a <lb/>retry of what it has already executed. The server MAY however detect <lb/>the client&apos;s illegal reuse and return NFS4ERR_SEQ_FALSE_RETRY. <lb/>If SEQUENCE returns an error, then the state of the slot (sequence <lb/>ID, cached reply) MUST NOT change, and the associated lease MUST NOT <lb/>be renewed. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 584] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If SEQUENCE returns NFS4_OK, then the associated lease MUST be <lb/>renewed (see Section 8.3), except if <lb/>SEQ4_STATUS_EXPIRED_ALL_STATE_REVOKED is returned in sr_status_flags. <lb/>18.46.4. IMPLEMENTATION <lb/>The server MUST maintain a mapping of session ID to client ID in <lb/>order to validate any operations that follow SEQUENCE that take a <lb/>stateid as an argument and/or result. <lb/>If the client establishes a persistent session, then a SEQUENCE <lb/>received after a server restart might encounter requests performed <lb/>and recorded in a persistent reply cache before the server restart. <lb/>In this case, SEQUENCE will be processed successfully, while requests <lb/>that were not previously performed and recorded are rejected with <lb/>NFS4ERR_DEADSESSION. <lb/>Depending on which of the operations within the COMPOUND were <lb/>successfully performed before the server restart, these operations <lb/>will also have replies sent from the server reply cache. Note that <lb/>when these operations establish locking state, it is locking state <lb/>that applies to the previous server instance and to the previous <lb/>client ID, even though the server restart, which logically happened <lb/>after these operations, eliminated that state. In the case of a <lb/>partially executed COMPOUND, processing may reach an operation not <lb/>processed during the earlier server instance, making this operation a <lb/>new one and not performable on the existing session. In this case, <lb/>NFS4ERR_DEADSESSION will be returned from that operation. <lb/>18.47. Operation 54: SET_SSV -Update SSV for a Client ID <lb/>18.47.1. ARGUMENT <lb/>struct ssa_digest_input4 { <lb/>SEQUENCE4args sdi_seqargs; <lb/>}; <lb/>struct SET_SSV4args { <lb/>opaque <lb/>ssa_ssv&lt;&gt;; <lb/>opaque <lb/>ssa_digest&lt;&gt;; <lb/>}; <lb/>18.47.2. RESULT <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 585] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct ssr_digest_input4 { <lb/>SEQUENCE4res sdi_seqres; <lb/>}; <lb/>struct SET_SSV4resok { <lb/>opaque <lb/>ssr_digest&lt;&gt;; <lb/>}; <lb/>union SET_SSV4res switch (nfsstat4 ssr_status) { <lb/>case NFS4_OK: <lb/>SET_SSV4resok <lb/>ssr_resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.47.3. DESCRIPTION <lb/>This operation is used to update the SSV for a client ID. Before <lb/>SET_SSV is called the first time on a client ID, the SSV is zero. <lb/>The SSV is the key used for the SSV GSS mechanism (Section 2.10.9) <lb/>SET_SSV MUST be preceded by a SEQUENCE operation in the same <lb/>COMPOUND. It MUST NOT be used if the client did not opt for SP4_SSV <lb/>state protection when the client ID was created (see Section 18.35); <lb/>the server returns NFS4ERR_INVAL in that case. <lb/>The field ssa_digest is computed as the output of the HMAC (RFC 2104 <lb/>[59]) using the subkey derived from the SSV4_SUBKEY_MIC_I2T and <lb/>current SSV as the key (see Section 2.10.9 for a description of <lb/>subkeys), and an XDR encoded value of data type ssa_digest_input4. <lb/>The field sdi_seqargs is equal to the arguments of the SEQUENCE <lb/>operation for the COMPOUND procedure that SET_SSV is within. <lb/>The argument ssa_ssv is XORed with the current SSV to produce the new <lb/>SSV. The argument ssa_ssv SHOULD be generated randomly. <lb/>In the response, ssr_digest is the output of the HMAC using the <lb/>subkey derived from SSV4_SUBKEY_MIC_T2I and new SSV as the key, and <lb/>an XDR encoded value of data type ssr_digest_input4. The field <lb/>sdi_seqres is equal to the results of the SEQUENCE operation for the <lb/>COMPOUND procedure that SET_SSV is within. <lb/>As noted in Section 18.35, the client and server can maintain <lb/>multiple concurrent versions of the SSV. The client and server each <lb/>MUST maintain an internal SSV version number, which is set to one the <lb/>first time SET_SSV executes on the server and the client receives the <lb/>first SET_SSV reply. Each subsequent SET_SSV increases the internal <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 586] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>SSV version number by one. The value of this version number <lb/>corresponds to the smpt_ssv_seq, smt_ssv_seq, sspt_ssv_seq, and <lb/>ssct_ssv_seq fields of the SSV GSS mechanism tokens (see <lb/>Section 2.10.9). <lb/>18.47.4. IMPLEMENTATION <lb/>When the server receives ssa_digest, it MUST verify the digest by <lb/>computing the digest the same way the client did and comparing it <lb/>with ssa_digest. If the server gets a different result, this is an <lb/>error, NFS4ERR_BAD_SESSION_DIGEST. This error might be the result of <lb/>another SET_SSV from the same client ID changing the SSV. If so, the <lb/>client recovers by sending a SET_SSV operation again with a <lb/>recomputed digest based on the subkey of the new SSV. If the <lb/>transport connection is dropped after the SET_SSV request is sent, <lb/>but before the SET_SSV reply is received, then there are special <lb/>considerations for recovery if the client has no more connections <lb/>associated with sessions associated with the client ID of the SSV. <lb/>See Section 18.34.4. <lb/>Clients SHOULD NOT send an ssa_ssv that is equal to a previous <lb/>ssa_ssv, nor equal to a previous or current SSV (including an ssa_ssv <lb/>equal to zero since the SSV is initialized to zero when the client ID <lb/>is created). <lb/>Clients SHOULD send SET_SSV with RPCSEC_GSS privacy. Servers MUST <lb/>support RPCSEC_GSS with privacy for any COMPOUND that has { SEQUENCE, <lb/>SET_SSV }. <lb/>A client SHOULD NOT send SET_SSV with the SSV GSS mechanism&apos;s <lb/>credential because the purpose of SET_SSV is to seed the SSV from <lb/>non-SSV credentials. Instead, SET_SSV SHOULD be sent with the <lb/>credential of a user that is accessing the client ID for the first <lb/>time (Section 2.10.8.3). However, if the client does send SET_SSV <lb/>with SSV credentials, the digest protecting the arguments uses the <lb/>value of the SSV before ssa_ssv is XORed in, and the digest <lb/>protecting the results uses the value of the SSV after the ssa_ssv is <lb/>XORed in. <lb/>18.48. Operation 55: TEST_STATEID -Test Stateids for Validity <lb/>18.48.1. ARGUMENT <lb/>struct TEST_STATEID4args { <lb/>stateid4 <lb/>ts_stateids&lt;&gt;; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 587] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.48.2. RESULT <lb/>struct TEST_STATEID4resok { <lb/>nfsstat4 <lb/>tsr_status_codes&lt;&gt;; <lb/>}; <lb/>union TEST_STATEID4res switch (nfsstat4 tsr_status) { <lb/>case NFS4_OK: <lb/>TEST_STATEID4resok tsr_resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>18.48.3. DESCRIPTION <lb/>The TEST_STATEID operation is used to check the validity of a set of <lb/>stateids. It can be used at any time, but the client should <lb/>definitely use it when it receives an indication that one or more of <lb/>its stateids have been invalidated due to lock revocation. This <lb/>occurs when the SEQUENCE operation returns with one of the following <lb/>sr_status_flags set: <lb/>o SEQ4_STATUS_EXPIRED_SOME_STATE_REVOKED <lb/>o SEQ4_STATUS_EXPIRED_ADMIN_STATE_REVOKED <lb/>o SEQ4_STATUS_EXPIRED_RECALLABLE_STATE_REVOKED <lb/>The client can use TEST_STATEID one or more times to test the <lb/>validity of its stateids. Each use of TEST_STATEID allows a large <lb/>set of such stateids to be tested and avoids problems with earlier <lb/>stateids in a COMPOUND request from interfering with the checking of <lb/>subsequent stateids, as would happen if individual stateids were <lb/>tested by a series of corresponding by operations in a COMPOUND <lb/>request. <lb/>For each stateid, the server returns the status code that would be <lb/>returned if that stateid were to be used in normal operation. <lb/>Returning such a status indication is not an error and does not cause <lb/>COMPOUND processing to terminate. Checks for the validity of the <lb/>stateid proceed as they would for normal operations with a number of <lb/>exceptions: <lb/>o There is no check for the type of stateid object, as would be the <lb/>case for normal use of a stateid. <lb/>o There is no reference to the current filehandle. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 588] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>o Special stateids are always considered invalid (they result in the <lb/>error code NFS4ERR_BAD_STATEID). <lb/>All stateids are interpreted as being associated with the client for <lb/>the current session. Any possible association with a previous <lb/>instance of the client (as stale stateids) is not considered. <lb/>The valid status values in the returned status_code array are <lb/>NFS4ERR_OK, NFS4ERR_BAD_STATEID, NFS4ERR_OLD_STATEID, <lb/>NFS4ERR_EXPIRED, NFS4ERR_ADMIN_REVOKED, and NFS4ERR_DELEG_REVOKED. <lb/>18.48.4. IMPLEMENTATION <lb/>See Sections 8.2.2 and 8.2.4 for a discussion of stateid structure, <lb/>lifetime, and validation. <lb/>18.49. Operation 56: WANT_DELEGATION -Request Delegation <lb/>18.49.1. ARGUMENT <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 589] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>union deleg_claim4 switch (open_claim_type4 dc_claim) { <lb/>/* <lb/>* No special rights to object. Ordinary delegation <lb/>* request of the specified object. Object identified <lb/>* by filehandle. <lb/>*/ <lb/>case CLAIM_FH: /* new to v4.1 */ <lb/>/* CURRENT_FH: object being delegated */ <lb/>void; <lb/>/* <lb/>* Right to file based on a delegation granted <lb/>* to a previous boot instance of the client. <lb/>* File is specified by filehandle. <lb/>*/ <lb/>case CLAIM_DELEG_PREV_FH: /* new to v4.1 */ <lb/>/* CURRENT_FH: object being delegated */ <lb/>void; <lb/>/* <lb/>* Right to the file established by an open previous <lb/>* to server reboot. File identified by filehandle. <lb/>* Used during server reclaim grace period. <lb/>*/ <lb/>case CLAIM_PREVIOUS: <lb/>/* CURRENT_FH: object being reclaimed */ <lb/>open_delegation_type4 <lb/>dc_delegate_type; <lb/>}; <lb/>struct WANT_DELEGATION4args { <lb/>uint32_t <lb/>wda_want; <lb/>deleg_claim4 <lb/>wda_claim; <lb/>}; <lb/>18.49.2. RESULT <lb/>union WANT_DELEGATION4res switch (nfsstat4 wdr_status) { <lb/>case NFS4_OK: <lb/>open_delegation4 wdr_resok4; <lb/>default: <lb/>void; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 590] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.49.3. DESCRIPTION <lb/>Where this description mandates the return of a specific error code <lb/>for a specific condition, and where multiple conditions apply, the <lb/>server MAY return any of the mandated error codes. <lb/>This operation allows a client to: <lb/>o Get a delegation on all types of files except directories. <lb/>o Register a &quot;want&quot; for a delegation for the specified file object, <lb/>and be notified via a callback when the delegation is available. <lb/>The server MAY support notifications of availability via <lb/>callbacks. If the server does not support registration of wants, <lb/>it MUST NOT return an error to indicate that, and instead MUST <lb/>return with ond_why set to WND4_CONTENTION or WND4_RESOURCE and <lb/>ond_server_will_push_deleg or ond_server_will_signal_avail set to <lb/>FALSE. When the server indicates that it will notify the client <lb/>by means of a callback, it will either provide the delegation <lb/>using a CB_PUSH_DELEG operation or cancel its promise by sending a <lb/>CB_WANTS_CANCELLED operation. <lb/>o Cancel a want for a delegation. <lb/>The client SHOULD NOT set OPEN4_SHARE_ACCESS_READ and SHOULD NOT set <lb/>OPEN4_SHARE_ACCESS_WRITE in wda_want. If it does, the server MUST <lb/>ignore them. <lb/>The meanings of the following flags in wda_want are the same as they <lb/>are in OPEN, except as noted below. <lb/>o OPEN4_SHARE_ACCESS_WANT_READ_DELEG <lb/>o OPEN4_SHARE_ACCESS_WANT_WRITE_DELEG <lb/>o OPEN4_SHARE_ACCESS_WANT_ANY_DELEG <lb/>o OPEN4_SHARE_ACCESS_WANT_NO_DELEG. Unlike the OPEN operation, this <lb/>flag SHOULD NOT be set by the client in the arguments to <lb/>WANT_DELEGATION, and MUST be ignored by the server. <lb/>o OPEN4_SHARE_ACCESS_WANT_CANCEL <lb/>o OPEN4_SHARE_ACCESS_WANT_SIGNAL_DELEG_WHEN_RESRC_AVAIL <lb/>o OPEN4_SHARE_ACCESS_WANT_PUSH_DELEG_WHEN_UNCONTENDED <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 591] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The handling of the above flags in WANT_DELEGATION is the same as in <lb/>OPEN. Information about the delegation and/or the promises the <lb/>server is making regarding future callbacks are the same as those <lb/>described in the open_delegation4 structure. <lb/>The successful results of WANT_DELEGATION are of data type <lb/>open_delegation4, which is the same data type as the &quot;delegation&quot; <lb/>field in the results of the OPEN operation (see Section 18.16.3). <lb/>The server constructs wdr_resok4 the same way it constructs OPEN&apos;s <lb/>&quot;delegation&quot; with one difference: WANT_DELEGATION MUST NOT return a <lb/>delegation type of OPEN_DELEGATE_NONE. <lb/>If ((wda_want &amp; OPEN4_SHARE_ACCESS_WANT_DELEG_MASK) &amp; <lb/>~OPEN4_SHARE_ACCESS_WANT_NO_DELEG) is zero, then the client is <lb/>indicating no explicit desire or non-desire for a delegation and the <lb/>server MUST return NFS4ERR_INVAL. <lb/>The client uses the OPEN4_SHARE_ACCESS_WANT_CANCEL flag in the <lb/>WANT_DELEGATION operation to cancel a previously requested want for a <lb/>delegation. Note that if the server is in the process of sending the <lb/>delegation (via CB_PUSH_DELEG) at the time the client sends a <lb/>cancellation of the want, the delegation might still be pushed to the <lb/>client. <lb/>If WANT_DELEGATION fails to return a delegation, and the server <lb/>returns NFS4_OK, the server MUST set the delegation type to <lb/>OPEN4_DELEGATE_NONE_EXT, and set od_whynone, as described in <lb/>Section 18.16. Write delegations are not available for file types <lb/>that are not writable. This includes file objects of types NF4BLK, <lb/>NF4CHR, NF4LNK, NF4SOCK, and NF4FIFO. If the client requests <lb/>OPEN4_SHARE_ACCESS_WANT_WRITE_DELEG without <lb/>OPEN4_SHARE_ACCESS_WANT_READ_DELEG on an object with one of the <lb/>aforementioned file types, the server must set <lb/>wdr_resok4.od_whynone.ond_why to WND4_WRITE_DELEG_NOT_SUPP_FTYPE. <lb/>18.49.4. IMPLEMENTATION <lb/>A request for a conflicting delegation is not normally intended to <lb/>trigger the recall of the existing delegation. Servers may choose to <lb/>treat some clients as having higher priority such that their wants <lb/>will trigger recall of an existing delegation, although that is <lb/>expected to be an unusual situation. <lb/>Servers will generally recall delegations assigned by WANT_DELEGATION <lb/>on the same basis as those assigned by OPEN. CB_RECALL will <lb/>generally be done only when other clients perform operations <lb/>inconsistent with the delegation. The normal response to aging of <lb/>delegations is to use CB_RECALL_ANY, in order to give the client the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 592] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>opportunity to keep the delegations most useful from its point of <lb/>view. <lb/>18.50. Operation 57: DESTROY_CLIENTID -Destroy a Client ID <lb/>18.50.1. ARGUMENT <lb/>struct DESTROY_CLIENTID4args { <lb/>clientid4 <lb/>dca_clientid; <lb/>}; <lb/>18.50.2. RESULT <lb/>struct DESTROY_CLIENTID4res { <lb/>nfsstat4 <lb/>dcr_status; <lb/>}; <lb/>18.50.3. DESCRIPTION <lb/>The DESTROY_CLIENTID operation destroys the client ID. If there are <lb/>sessions (both idle and non-idle), opens, locks, delegations, <lb/>layouts, and/or wants (Section 18.49) associated with the unexpired <lb/>lease of the client ID, the server MUST return NFS4ERR_CLIENTID_BUSY. <lb/>DESTROY_CLIENTID MAY be preceded with a SEQUENCE operation as long as <lb/>the client ID derived from the session ID of SEQUENCE is not the same <lb/>as the client ID to be destroyed. If the client IDs are the same, <lb/>then the server MUST return NFS4ERR_CLIENTID_BUSY. <lb/>If DESTROY_CLIENTID is not prefixed by SEQUENCE, it MUST be the only <lb/>operation in the COMPOUND request (otherwise, the server MUST return <lb/>NFS4ERR_NOT_ONLY_OP). If the operation is sent without a SEQUENCE <lb/>preceding it, a client that retransmits the request may receive an <lb/>error in response, because the original request might have been <lb/>successfully executed. <lb/>18.50.4. IMPLEMENTATION <lb/>DESTROY_CLIENTID allows a server to immediately reclaim the resources <lb/>consumed by an unused client ID, and also to forget that it ever <lb/>generated the client ID. By forgetting that it ever generated the <lb/>client ID, the server can safely reuse the client ID on a future <lb/>EXCHANGE_ID operation. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 593] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>18.51. Operation 58: RECLAIM_COMPLETE -Indicates Reclaims Finished <lb/>18.51.1. ARGUMENT <lb/>&lt;CODE BEGINS&gt; <lb/>struct RECLAIM_COMPLETE4args { <lb/>/* <lb/>* If rca_one_fs TRUE, <lb/>* <lb/>* <lb/>CURRENT_FH: object in <lb/>* <lb/>file system reclaim is <lb/>* <lb/>complete for. <lb/>*/ <lb/>bool <lb/>rca_one_fs; <lb/>}; <lb/>&lt;CODE ENDS&gt; <lb/>18.51.2. RESULTS <lb/>&lt;CODE BEGINS&gt; <lb/>struct RECLAIM_COMPLETE4res { <lb/>nfsstat4 <lb/>rcr_status; <lb/>}; <lb/>&lt;CODE ENDS&gt; <lb/>18.51.3. DESCRIPTION <lb/>A RECLAIM_COMPLETE operation is used to indicate that the client has <lb/>reclaimed all of the locking state that it will recover using <lb/>reclaim, when it is recovering state due to either a server restart <lb/>or the migration of a file system to another server. There are two <lb/>types of RECLAIM_COMPLETE operations: <lb/>o When rca_one_fs is FALSE, a global RECLAIM_COMPLETE is being done. <lb/>This indicates that recovery of all locks that the client held on <lb/>the previous server instance has been completed. The current <lb/>filehandle need not be set in this case. <lb/>o When rca_one_fs is TRUE, a file system-specific RECLAIM_COMPLETE <lb/>is being done. This indicates that recovery of locks for a single <lb/>fs (the one designated by the current filehandle) due to the <lb/>migration of the file system has been completed. Presence of a <lb/>current filehandle is required when rca_one_fs is set to TRUE. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 594] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>When the current filehandle designates a filehandle in a file <lb/>system not in the process of migration, the operation returns <lb/>NFS4_OK and is otherwise ignored. <lb/>Once a RECLAIM_COMPLETE is done, there can be no further reclaim <lb/>operations for locks whose scope is defined as having completed <lb/>recovery. Once the client sends RECLAIM_COMPLETE, the server will <lb/>not allow the client to do subsequent reclaims of locking state for <lb/>that scope and, if these are attempted, will return NFS4ERR_NO_GRACE. <lb/>Whenever a client establishes a new client ID and before it does the <lb/>first non-reclaim operation that obtains a lock, it MUST send a <lb/>RECLAIM_COMPLETE with rca_one_fs set to FALSE, even if there are no <lb/>locks to reclaim. If non-reclaim locking operations are done before <lb/>the RECLAIM_COMPLETE, an NFS4ERR_GRACE error will be returned. <lb/>Similarly, when the client accesses a migrated file system on a new <lb/>server, before it sends the first non-reclaim operation that obtains <lb/>a lock on this new server, it MUST send a RECLAIM_COMPLETE with <lb/>rca_one_fs set to TRUE and current filehandle within that file <lb/>system, even if there are no locks to reclaim. If non-reclaim <lb/>locking operations are done on that file system before the <lb/>RECLAIM_COMPLETE, an NFS4ERR_GRACE error will be returned. <lb/>It should be noted that there are situations in which a client needs <lb/>to issue both forms of RECLAIM_COMPLETE. An example is an instance <lb/>of file system migration in which the file system is migrated to a <lb/>server for which the client has no clientid. As a result, the client <lb/>needs to obtain a clientid from the server (incurring the <lb/>responsibility to do RECLAIM_COMPLETE with rca_one_fs set to FALSE) <lb/>as well as RECLAIM_COMPLETE with rca_one_fs set to TRUE to complete <lb/>the per-fs grace period associated with the file system migration. <lb/>These two may be done in any order as long as all necessary lock <lb/>reclaims have been done before issuing either of them. <lb/>Any locks not reclaimed at the point at which RECLAIM_COMPLETE is <lb/>done become non-reclaimable. The client MUST NOT attempt to reclaim <lb/>them, either during the current server instance or in any subsequent <lb/>server instance, or on another server to which responsibility for <lb/>that file system is transferred. If the client were to do so, it <lb/>would be violating the protocol by representing itself as owning <lb/>locks that it does not own, and so has no right to reclaim. See <lb/>Section 8.4.3 of [60] for a discussion of edge conditions related to <lb/>lock reclaim. <lb/>By sending a RECLAIM_COMPLETE, the client indicates readiness to <lb/>proceed to do normal non-reclaim locking operations. The client <lb/>should be aware that such operations may temporarily result in <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 595] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>NFS4ERR_GRACE errors until the server is ready to terminate its grace <lb/>period. <lb/>18.51.4. IMPLEMENTATION <lb/>Servers will typically use the information as to when reclaim <lb/>activity is complete to reduce the length of the grace period. When <lb/>the server maintains in persistent storage a list of clients that <lb/>might have had locks, it is able to use the fact that all such <lb/>clients have done a RECLAIM_COMPLETE to terminate the grace period <lb/>and begin normal operations (i.e., grant requests for new locks) <lb/>sooner than it might otherwise. <lb/>Latency can be minimized by doing a RECLAIM_COMPLETE as part of the <lb/>COMPOUND request in which the last lock-reclaiming operation is done. <lb/>When there are no reclaims to be done, RECLAIM_COMPLETE should be <lb/>done immediately in order to allow the grace period to end as soon as <lb/>possible. <lb/>RECLAIM_COMPLETE should only be done once for each server instance or <lb/>occasion of the transition of a file system. If it is done a second <lb/>time, the error NFS4ERR_COMPLETE_ALREADY will result. Note that <lb/>because of the session feature&apos;s retry protection, retries of <lb/>COMPOUND requests containing RECLAIM_COMPLETE operation will not <lb/>result in this error. <lb/>When a RECLAIM_COMPLETE is sent, the client effectively acknowledges <lb/>any locks not yet reclaimed as lost. This allows the server to re-<lb/>enable the client to recover locks if the occurrence of edge <lb/>conditions, as described in Section 8.4.3, had caused the server to <lb/>disable the client&apos;s ability to recover locks. <lb/>Because previous descriptions of RECLAIM_COMPLETE were not <lb/>sufficiently explicit about the circumstances in which use of <lb/>RECLAIM_COMPLETE with rca_one_fs set to TRUE was appropriate, there <lb/>have been cases which it has been misused by clients, and cases in <lb/>which servers have, in various ways, not responded to such misuse as <lb/>described above. While clients SHOULD NOT misuse this feature and <lb/>servers SHOULD respond to such misuse as described above, <lb/>implementers need to be aware of the following considerations as they <lb/>make necessary tradeoffs between interoperability with existing <lb/>implementations and proper support for facilities to allow lock <lb/>recovery in the event of file system migration. <lb/>o When servers have no support for becoming the destination server <lb/>of a file system subject to migration, there is no possibility of <lb/>a per-fs RECLAIM_COMPLETE being done legitimately and occurrences <lb/>of it SHOULD be ignored. However, the negative consequences of <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 596] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>accepting such mistaken use are quite limited as long as the <lb/>client does not issue it before all necessary reclaims are done. <lb/>o When a server might become the destination for a file system being <lb/>migrated, inappropriate use of per-fs RECLAIM_COMPLETE is more <lb/>concerning. In the case in which the file system designated is <lb/>not within a per-fs grace period, the per-fs RECLAIM_COMPLETE <lb/>SHOULD be ignored, with the negative consequences of accepting it <lb/>being limited, as in the case in which migration is not supported. <lb/>However, if the server encounters a file system undergoing <lb/>migration, the operation cannot be accepted as if it were a global <lb/>RECLAIM_COMPLETE without invalidating its intended use. <lb/>18.52. Operation 10044: ILLEGAL -Illegal Operation <lb/>18.52.1. ARGUMENTS <lb/>void; <lb/>18.52.2. RESULTS <lb/>struct ILLEGAL4res { <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/>18.52.3. DESCRIPTION <lb/>This operation is a placeholder for encoding a result to handle the <lb/>case of the client sending an operation code within COMPOUND that is <lb/>not supported. See the COMPOUND procedure description for more <lb/>details. <lb/>The status field of ILLEGAL4res MUST be set to NFS4ERR_OP_ILLEGAL. <lb/>18.52.4. IMPLEMENTATION <lb/>A client will probably not send an operation with code OP_ILLEGAL but <lb/>if it does, the response will be ILLEGAL4res just as it would be with <lb/>any other invalid operation code. Note that if the server gets an <lb/>illegal operation code that is not OP_ILLEGAL, and if the server <lb/>checks for legal operation codes during the XDR decode phase, then <lb/>the ILLEGAL4res would not be returned. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 597] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>19. NFSv4.1 Callback Procedures <lb/>The procedures used for callbacks are defined in the following <lb/>sections. In the interest of clarity, the terms &quot;client&quot; and <lb/>&quot;server&quot; refer to NFS clients and servers, despite the fact that for <lb/>an individual callback RPC, the sense of these terms would be <lb/>precisely the opposite. <lb/>Both procedures, CB_NULL and CB_COMPOUND, MUST be implemented. <lb/>19.1. Procedure 0: CB_NULL -No Operation <lb/>19.1.1. ARGUMENTS <lb/>void; <lb/>19.1.2. RESULTS <lb/>void; <lb/>19.1.3. DESCRIPTION <lb/>CB_NULL is the standard ONC RPC NULL procedure, with the standard <lb/>void argument and void response. Even though there is no direct <lb/>functionality associated with this procedure, the server will use <lb/>CB_NULL to confirm the existence of a path for RPCs from the server <lb/>to client. <lb/>19.1.4. ERRORS <lb/>None. <lb/>19.2. Procedure 1: CB_COMPOUND -Compound Operations <lb/>19.2.1. ARGUMENTS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 598] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>enum nfs_cb_opnum4 { <lb/>OP_CB_GETATTR <lb/>= 3, <lb/>OP_CB_RECALL <lb/>= 4, <lb/>/* Callback operations new to NFSv4.1 */ <lb/>OP_CB_LAYOUTRECALL <lb/>= 5, <lb/>OP_CB_NOTIFY <lb/>= 6, <lb/>OP_CB_PUSH_DELEG <lb/>= 7, <lb/>OP_CB_RECALL_ANY <lb/>= 8, <lb/>OP_CB_RECALLABLE_OBJ_AVAIL = 9, <lb/>OP_CB_RECALL_SLOT <lb/>= 10, <lb/>OP_CB_SEQUENCE <lb/>= 11, <lb/>OP_CB_WANTS_CANCELLED <lb/>= 12, <lb/>OP_CB_NOTIFY_LOCK <lb/>= 13, <lb/>OP_CB_NOTIFY_DEVICEID <lb/>= 14, <lb/>OP_CB_ILLEGAL <lb/>= 10044 <lb/>}; <lb/>union nfs_cb_argop4 switch (unsigned argop) { <lb/>case OP_CB_GETATTR: <lb/>CB_GETATTR4args <lb/>opcbgetattr; <lb/>case OP_CB_RECALL: <lb/>CB_RECALL4args <lb/>opcbrecall; <lb/>case OP_CB_LAYOUTRECALL: <lb/>CB_LAYOUTRECALL4args <lb/>opcblayoutrecall; <lb/>case OP_CB_NOTIFY: <lb/>CB_NOTIFY4args <lb/>opcbnotify; <lb/>case OP_CB_PUSH_DELEG: <lb/>CB_PUSH_DELEG4args <lb/>opcbpush_deleg; <lb/>case OP_CB_RECALL_ANY: <lb/>CB_RECALL_ANY4args <lb/>opcbrecall_any; <lb/>case OP_CB_RECALLABLE_OBJ_AVAIL: <lb/>CB_RECALLABLE_OBJ_AVAIL4args opcbrecallable_obj_avail; <lb/>case OP_CB_RECALL_SLOT: <lb/>CB_RECALL_SLOT4args <lb/>opcbrecall_slot; <lb/>case OP_CB_SEQUENCE: <lb/>CB_SEQUENCE4args <lb/>opcbsequence; <lb/>case OP_CB_WANTS_CANCELLED: <lb/>CB_WANTS_CANCELLED4args <lb/>opcbwants_cancelled; <lb/>case OP_CB_NOTIFY_LOCK: <lb/>CB_NOTIFY_LOCK4args <lb/>opcbnotify_lock; <lb/>case OP_CB_NOTIFY_DEVICEID: <lb/>CB_NOTIFY_DEVICEID4args <lb/>opcbnotify_deviceid; <lb/>case OP_CB_ILLEGAL: <lb/>void; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 599] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct CB_COMPOUND4args { <lb/>utf8str_cs <lb/>tag; <lb/>uint32_t <lb/>minorversion; <lb/>uint32_t <lb/>callback_ident; <lb/>nfs_cb_argop4 <lb/>argarray&lt;&gt;; <lb/>}; <lb/>19.2.2. RESULTS <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 600] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>union nfs_cb_resop4 switch (unsigned resop) { <lb/>case OP_CB_GETATTR: <lb/>CB_GETATTR4res opcbgetattr; <lb/>case OP_CB_RECALL: <lb/>CB_RECALL4res <lb/>opcbrecall; <lb/>/* new NFSv4.1 operations */ <lb/>case OP_CB_LAYOUTRECALL: <lb/>CB_LAYOUTRECALL4res <lb/>opcblayoutrecall; <lb/>case OP_CB_NOTIFY: <lb/>CB_NOTIFY4res <lb/>opcbnotify; <lb/>case OP_CB_PUSH_DELEG: CB_PUSH_DELEG4res <lb/>opcbpush_deleg; <lb/>case OP_CB_RECALL_ANY: CB_RECALL_ANY4res <lb/>opcbrecall_any; <lb/>case OP_CB_RECALLABLE_OBJ_AVAIL: <lb/>CB_RECALLABLE_OBJ_AVAIL4res <lb/>opcbrecallable_obj_avail; <lb/>case OP_CB_RECALL_SLOT: <lb/>CB_RECALL_SLOT4res <lb/>opcbrecall_slot; <lb/>case OP_CB_SEQUENCE: <lb/>CB_SEQUENCE4res opcbsequence; <lb/>case OP_CB_WANTS_CANCELLED: <lb/>CB_WANTS_CANCELLED4res <lb/>opcbwants_cancelled; <lb/>case OP_CB_NOTIFY_LOCK: <lb/>CB_NOTIFY_LOCK4res <lb/>opcbnotify_lock; <lb/>case OP_CB_NOTIFY_DEVICEID: <lb/>CB_NOTIFY_DEVICEID4res <lb/>opcbnotify_deviceid; <lb/>/* Not new operation */ <lb/>case OP_CB_ILLEGAL: <lb/>CB_ILLEGAL4res opcbillegal; <lb/>}; <lb/>struct CB_COMPOUND4res { <lb/>nfsstat4 status; <lb/>utf8str_cs <lb/>tag; <lb/>nfs_cb_resop4 <lb/>resarray&lt;&gt;; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 601] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>19.2.3. DESCRIPTION <lb/>The CB_COMPOUND procedure is used to combine one or more of the <lb/>callback procedures into a single RPC request. The main callback RPC <lb/>program has two main procedures: CB_NULL and CB_COMPOUND. All other <lb/>operations use the CB_COMPOUND procedure as a wrapper. <lb/>During the processing of the CB_COMPOUND procedure, the client may <lb/>find that it does not have the available resources to execute any or <lb/>all of the operations within the CB_COMPOUND sequence. Refer to <lb/>Section 2.10.6.4 for details. <lb/>The minorversion field of the arguments MUST be the same as the <lb/>minorversion of the COMPOUND procedure used to create the client ID <lb/>and session. For NFSv4.1, minorversion MUST be set to 1. <lb/>Contained within the CB_COMPOUND results is a &quot;status&quot; field. This <lb/>status MUST be equal to the status of the last operation that was <lb/>executed within the CB_COMPOUND procedure. Therefore, if an <lb/>operation incurred an error, then the &quot;status&quot; value will be the same <lb/>error value as is being returned for the operation that failed. <lb/>The &quot;tag&quot; field is handled the same way as that of the COMPOUND <lb/>procedure (see Section 16.2.3). <lb/>Illegal operation codes are handled in the same way as they are <lb/>handled for the COMPOUND procedure. <lb/>19.2.4. IMPLEMENTATION <lb/>The CB_COMPOUND procedure is used to combine individual operations <lb/>into a single RPC request. The client interprets each of the <lb/>operations in turn. If an operation is executed by the client and <lb/>the status of that operation is NFS4_OK, then the next operation in <lb/>the CB_COMPOUND procedure is executed. The client continues this <lb/>process until there are no more operations to be executed or one of <lb/>the operations has a status value other than NFS4_OK. <lb/>19.2.5. ERRORS <lb/>CB_COMPOUND will of course return every error that each operation on <lb/>the backchannel can return (see Table 7). However, if CB_COMPOUND <lb/>returns zero operations, obviously the error returned by COMPOUND has <lb/>nothing to do with an error returned by an operation. The list of <lb/>errors CB_COMPOUND will return if it processes zero operations <lb/>includes: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 602] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>CB_COMPOUND error returns <lb/>+------------------------------+------------------------------------+ <lb/>| Error <lb/>| Notes <lb/>| <lb/>+------------------------------+------------------------------------+ <lb/>| NFS4ERR_BADCHAR <lb/>| The tag argument has a character <lb/>| <lb/>| <lb/>| the replier does not support. <lb/>| <lb/>| NFS4ERR_BADXDR <lb/>| <lb/>| <lb/>| NFS4ERR_DELAY <lb/>| <lb/>| <lb/>| NFS4ERR_INVAL <lb/>| The tag argument is not in UTF-8 <lb/>| <lb/>| <lb/>| encoding. <lb/>| <lb/>| NFS4ERR_MINOR_VERS_MISMATCH | <lb/>| <lb/>| NFS4ERR_SERVERFAULT <lb/>| <lb/>| <lb/>| NFS4ERR_TOO_MANY_OPS <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG <lb/>| <lb/>| <lb/>| NFS4ERR_REP_TOO_BIG_TO_CACHE | <lb/>| <lb/>| NFS4ERR_REQ_TOO_BIG <lb/>| <lb/>| <lb/>+------------------------------+------------------------------------+ <lb/>Table 15 <lb/>20. NFSv4.1 Callback Operations <lb/>20.1. Operation 3: CB_GETATTR -Get Attributes <lb/>20.1.1. ARGUMENT <lb/>struct CB_GETATTR4args { <lb/>nfs_fh4 fh; <lb/>bitmap4 attr_request; <lb/>}; <lb/>20.1.2. RESULT <lb/>struct CB_GETATTR4resok { <lb/>fattr4 obj_attributes; <lb/>}; <lb/>union CB_GETATTR4res switch (nfsstat4 status) { <lb/>case NFS4_OK: <lb/>CB_GETATTR4resok <lb/>resok4; <lb/>default: <lb/>void; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 603] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>20.1.3. DESCRIPTION <lb/>The CB_GETATTR operation is used by the server to obtain the current <lb/>modified state of a file that has been OPEN_DELEGATE_WRITE delegated. <lb/>The size and change attributes are the only ones guaranteed to be <lb/>serviced by the client. See Section 10.4.3 for a full description of <lb/>how the client and server are to interact with the use of CB_GETATTR. <lb/>If the filehandle specified is not one for which the client holds an <lb/>OPEN_DELEGATE_WRITE delegation, an NFS4ERR_BADHANDLE error is <lb/>returned. <lb/>20.1.4. IMPLEMENTATION <lb/>The client returns attrmask bits and the associated attribute values <lb/>only for the change attribute, and attributes that it may change <lb/>(time_modify, and size). <lb/>20.2. Operation 4: CB_RECALL -Recall a Delegation <lb/>20.2.1. ARGUMENT <lb/>struct CB_RECALL4args { <lb/>stateid4 <lb/>stateid; <lb/>bool <lb/>truncate; <lb/>nfs_fh4 <lb/>fh; <lb/>}; <lb/>20.2.2. RESULT <lb/>struct CB_RECALL4res { <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/>20.2.3. DESCRIPTION <lb/>The CB_RECALL operation is used to begin the process of recalling a <lb/>delegation and returning it to the server. <lb/>The truncate flag is used to optimize recall for a file object that <lb/>is a regular file and is about to be truncated to zero. When it is <lb/>TRUE, the client is freed of the obligation to propagate modified <lb/>data for the file to the server, since this data is irrelevant. <lb/>If the handle specified is not one for which the client holds a <lb/>delegation, an NFS4ERR_BADHANDLE error is returned. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 604] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If the stateid specified is not one corresponding to an OPEN <lb/>delegation for the file specified by the filehandle, an <lb/>NFS4ERR_BAD_STATEID is returned. <lb/>20.2.4. IMPLEMENTATION <lb/>The client SHOULD reply to the callback immediately. Replying does <lb/>not complete the recall except when the value of the reply&apos;s status <lb/>field is neither NFS4ERR_DELAY nor NFS4_OK. The recall is not <lb/>complete until the delegation is returned using a DELEGRETURN <lb/>operation. <lb/>20.3. Operation 5: CB_LAYOUTRECALL -Recall Layout from Client <lb/>20.3.1. ARGUMENT <lb/>/* <lb/>* NFSv4.1 callback arguments and results <lb/>*/ <lb/>enum layoutrecall_type4 { <lb/>LAYOUTRECALL4_FILE = LAYOUT4_RET_REC_FILE, <lb/>LAYOUTRECALL4_FSID = LAYOUT4_RET_REC_FSID, <lb/>LAYOUTRECALL4_ALL = LAYOUT4_RET_REC_ALL <lb/>}; <lb/>struct layoutrecall_file4 { <lb/>nfs_fh4 <lb/>lor_fh; <lb/>offset4 <lb/>lor_offset; <lb/>length4 <lb/>lor_length; <lb/>stateid4 <lb/>lor_stateid; <lb/>}; <lb/>union layoutrecall4 switch(layoutrecall_type4 lor_recalltype) { <lb/>case LAYOUTRECALL4_FILE: <lb/>layoutrecall_file4 lor_layout; <lb/>case LAYOUTRECALL4_FSID: <lb/>fsid4 <lb/>lor_fsid; <lb/>case LAYOUTRECALL4_ALL: <lb/>void; <lb/>}; <lb/>struct CB_LAYOUTRECALL4args { <lb/>layouttype4 <lb/>clora_type; <lb/>layoutiomode4 <lb/>clora_iomode; <lb/>bool <lb/>clora_changed; <lb/>layoutrecall4 <lb/>clora_recall; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 605] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>20.3.2. RESULT <lb/>struct CB_LAYOUTRECALL4res { <lb/>nfsstat4 <lb/>clorr_status; <lb/>}; <lb/>20.3.3. DESCRIPTION <lb/>The CB_LAYOUTRECALL operation is used by the server to recall layouts <lb/>from the client; as a result, the client will begin the process of <lb/>returning layouts via LAYOUTRETURN. The CB_LAYOUTRECALL operation <lb/>specifies one of three forms of recall processing with the value of <lb/>layoutrecall_type4. The recall is for one of the following: a <lb/>specific layout of a specific file (LAYOUTRECALL4_FILE), an entire <lb/>file system ID (LAYOUTRECALL4_FSID), or all file systems <lb/>(LAYOUTRECALL4_ALL). <lb/>The behavior of the operation varies based on the value of the <lb/>layoutrecall_type4. The value and behaviors are: <lb/>LAYOUTRECALL4_FILE <lb/>For a layout to match the recall request, the values of the <lb/>following fields must match those of the layout: clora_type, <lb/>clora_iomode, lor_fh, and the byte-range specified by lor_offset <lb/>and lor_length. The clora_iomode field may have a special value <lb/>of LAYOUTIOMODE4_ANY. The special value LAYOUTIOMODE4_ANY will <lb/>match any iomode originally returned in a layout; therefore, it <lb/>acts as a wild card. The other special value used is for <lb/>lor_length. If lor_length has a value of NFS4_UINT64_MAX, the <lb/>lor_length field means the maximum possible file size. If a <lb/>matching layout is found, it MUST be returned using the <lb/>LAYOUTRETURN operation (see Section 18.44). An example of the <lb/>field&apos;s special value use is if clora_iomode is LAYOUTIOMODE4_ANY, <lb/>lor_offset is zero, and lor_length is NFS4_UINT64_MAX, then the <lb/>entire layout is to be returned. <lb/>The NFS4ERR_NOMATCHING_LAYOUT error is only returned when the <lb/>client does not hold layouts for the file or if the client does <lb/>not have any overlapping layouts for the specification in the <lb/>layout recall. <lb/>LAYOUTRECALL4_FSID and LAYOUTRECALL4_ALL <lb/>If LAYOUTRECALL4_FSID is specified, the fsid specifies the file <lb/>system for which any outstanding layouts MUST be returned. If <lb/>LAYOUTRECALL4_ALL is specified, all outstanding layouts MUST be <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 606] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>returned. In addition, LAYOUTRECALL4_FSID and LAYOUTRECALL4_ALL <lb/>specify that all the storage device ID to storage device address <lb/>mappings in the affected file system(s) are also recalled. The <lb/>respective LAYOUTRETURN with either LAYOUTRETURN4_FSID or <lb/>LAYOUTRETURN4_ALL acknowledges to the server that the client <lb/>invalidated the said device mappings. See Section 12.5.5.2.1.5 <lb/>for considerations with &quot;bulk&quot; recall of layouts. <lb/>The NFS4ERR_NOMATCHING_LAYOUT error is only returned when the <lb/>client does not hold layouts and does not have valid deviceid <lb/>mappings. <lb/>In processing the layout recall request, the client also varies its <lb/>behavior based on the value of the clora_changed field. This field <lb/>is used by the server to provide additional context for the reason <lb/>why the layout is being recalled. A FALSE value for clora_changed <lb/>indicates that no change in the layout is expected and the client may <lb/>write modified data to the storage devices involved; this must be <lb/>done prior to returning the layout via LAYOUTRETURN. A TRUE value <lb/>for clora_changed indicates that the server is changing the layout. <lb/>Examples of layout changes and reasons for a TRUE indication are the <lb/>following: the metadata server is restriping the file or a permanent <lb/>error has occurred on a storage device and the metadata server would <lb/>like to provide a new layout for the file. Therefore, a <lb/>clora_changed value of TRUE indicates some level of change for the <lb/>layout and the client SHOULD NOT write and commit modified data to <lb/>the storage devices. In this case, the client writes and commits <lb/>data through the metadata server. <lb/>See Section 12.5.3 for a description of how the lor_stateid field in <lb/>the arguments is to be constructed. Note that the &quot;seqid&quot; field of <lb/>lor_stateid MUST NOT be zero. See Sections 8.2, 12.5.3, and 12.5.5.2 <lb/>for a further discussion and requirements. <lb/>20.3.4. IMPLEMENTATION <lb/>The client&apos;s processing for CB_LAYOUTRECALL is similar to CB_RECALL <lb/>(recall of file delegations) in that the client responds to the <lb/>request before actually returning layouts via the LAYOUTRETURN <lb/>operation. While the client responds to the CB_LAYOUTRECALL <lb/>immediately, the operation is not considered complete (i.e., <lb/>considered pending) until all affected layouts are returned to the <lb/>server via the LAYOUTRETURN operation. <lb/>Before returning the layout to the server via LAYOUTRETURN, the <lb/>client should wait for the response from in-process or in-flight <lb/>READ, WRITE, or COMMIT operations that use the recalled layout. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 607] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>If the client is holding modified data that is affected by a recalled <lb/>layout, the client has various options for writing the data to the <lb/>server. As always, the client may write the data through the <lb/>metadata server. In fact, the client may not have a choice other <lb/>than writing to the metadata server when the clora_changed argument <lb/>is TRUE and a new layout is unavailable from the server. However, <lb/>the client may be able to write the modified data to the storage <lb/>device if the clora_changed argument is FALSE; this needs to be done <lb/>before returning the layout via LAYOUTRETURN. If the client were to <lb/>obtain a new layout covering the modified data&apos;s byte-range, then <lb/>writing to the storage devices is an available alternative. Note <lb/>that before obtaining a new layout, the client must first return the <lb/>original layout. <lb/>In the case of modified data being written while the layout is held, <lb/>the client must use LAYOUTCOMMIT operations at the appropriate time; <lb/>as required LAYOUTCOMMIT must be done before the LAYOUTRETURN. If a <lb/>large amount of modified data is outstanding, the client may send <lb/>LAYOUTRETURNs for portions of the recalled layout; this allows the <lb/>server to monitor the client&apos;s progress and adherence to the original <lb/>recall request. However, the last LAYOUTRETURN in a sequence of <lb/>returns MUST specify the full range being recalled (see <lb/>Section 12.5.5.1 for details). <lb/>If a server needs to delete a device ID and there are layouts <lb/>referring to the device ID, CB_LAYOUTRECALL MUST be invoked to cause <lb/>the client to return all layouts referring to the device ID before <lb/>the server can delete the device ID. If the client does not return <lb/>the affected layouts, the server MAY revoke the layouts. <lb/></body>

			<listBibl>20.4. Operation 6: CB_NOTIFY -Notify Client of Directory Changes <lb/>20.4.1. ARGUMENT <lb/>/* <lb/>* Directory notification types. <lb/>*/ <lb/>enum notify_type4 { <lb/>NOTIFY4_CHANGE_CHILD_ATTRS = 0, <lb/>NOTIFY4_CHANGE_DIR_ATTRS = 1, <lb/>NOTIFY4_REMOVE_ENTRY = 2, <lb/>NOTIFY4_ADD_ENTRY = 3, <lb/>NOTIFY4_RENAME_ENTRY = 4, <lb/>NOTIFY4_CHANGE_COOKIE_VERIFIER = 5 <lb/>}; <lb/>/* Changed entry information. */ <lb/>struct notify_entry4 { <lb/></listBibl>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 608] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>component4 <lb/>ne_file; <lb/>fattr4 <lb/>ne_attrs; <lb/>}; <lb/>/* Previous entry information */ <lb/>struct prev_entry4 { <lb/>notify_entry4 <lb/>pe_prev_entry; <lb/>/* what READDIR returned for this entry */ <lb/>nfs_cookie4 <lb/>pe_prev_entry_cookie; <lb/>}; <lb/>struct notify_remove4 { <lb/>notify_entry4 <lb/>nrm_old_entry; <lb/>nfs_cookie4 <lb/>nrm_old_entry_cookie; <lb/>}; <lb/>struct notify_add4 { <lb/>/* <lb/>* Information on object <lb/>* possibly renamed over. <lb/>*/ <lb/>notify_remove4 <lb/>nad_old_entry&lt;1&gt;; <lb/>notify_entry4 <lb/>nad_new_entry; <lb/>/* what READDIR would have returned for this entry */ <lb/>nfs_cookie4 <lb/>nad_new_entry_cookie&lt;1&gt;; <lb/>prev_entry4 <lb/>nad_prev_entry&lt;1&gt;; <lb/>bool <lb/>nad_last_entry; <lb/>}; <lb/>struct notify_attr4 { <lb/>notify_entry4 <lb/>na_changed_entry; <lb/>}; <lb/>struct notify_rename4 { <lb/>notify_remove4 nrn_old_entry; <lb/>notify_add4 <lb/>nrn_new_entry; <lb/>}; <lb/>struct notify_verifier4 { <lb/>verifier4 <lb/>nv_old_cookieverf; <lb/>verifier4 <lb/>nv_new_cookieverf; <lb/>}; <lb/>/* <lb/>* Objects of type notify_&lt;&gt;4 and <lb/>* notify_device_&lt;&gt;4 are encoded in this. <lb/>*/ <lb/>typedef opaque notifylist4&lt;&gt;; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 609] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct notify4 { <lb/>/* composed from notify_type4 or notify_deviceid_type4 */ <lb/>bitmap4 <lb/>notify_mask; <lb/>notifylist4 <lb/>notify_vals; <lb/>}; <lb/>struct CB_NOTIFY4args { <lb/>stateid4 <lb/>cna_stateid; <lb/>nfs_fh4 <lb/>cna_fh; <lb/>notify4 <lb/>cna_changes&lt;&gt;; <lb/>}; <lb/>20.4.2. RESULT <lb/>struct CB_NOTIFY4res { <lb/>nfsstat4 <lb/>cnr_status; <lb/>}; <lb/>20.4.3. DESCRIPTION <lb/>The CB_NOTIFY operation is used by the server to send notifications <lb/>to clients about changes to delegated directories. The registration <lb/>of notifications for the directories occurs when the delegation is <lb/>established using GET_DIR_DELEGATION. These notifications are sent <lb/>over the backchannel. The notification is sent once the original <lb/>request has been processed on the server. The server will send an <lb/>array of notifications for changes that might have occurred in the <lb/>directory. The notifications are sent as list of pairs of bitmaps <lb/>and values. See Section 3.3.7 for a description of how NFSv4.1 <lb/>bitmaps work. <lb/>If the server has more notifications than can fit in the CB_COMPOUND <lb/>request, it SHOULD send a sequence of serial CB_COMPOUND requests so <lb/>that the client&apos;s view of the directory does not become confused. <lb/>For example, if the server indicates that a file named &quot;foo&quot; is added <lb/>and that the file &quot;foo&quot; is removed, the order in which the client <lb/>receives these notifications needs to be the same as the order in <lb/>which the corresponding operations occurred on the server. <lb/>If the client holding the delegation makes any changes in the <lb/>directory that cause files or sub-directories to be added or removed, <lb/>the server will notify that client of the resulting change(s). If <lb/>the client holding the delegation is making attribute or cookie <lb/>verifier changes only, the server does not need to send notifications <lb/>to that client. The server will send the following information for <lb/>each operation: <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 610] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>NOTIFY4_ADD_ENTRY <lb/>The server will send information about the new directory entry <lb/>being created along with the cookie for that entry. The entry <lb/>information (data type notify_add4) includes the component name of <lb/>the entry and attributes. The server will send this type of entry <lb/>when a file is actually being created, when an entry is being <lb/>added to a directory as a result of a rename across directories <lb/>(see below), and when a hard link is being created to an existing <lb/>file. If this entry is added to the end of the directory, the <lb/>server will set the nad_last_entry flag to TRUE. If the file is <lb/>added such that there is at least one entry before it, the server <lb/>will also return the previous entry information (nad_prev_entry, a <lb/>variable-length array of up to one element. If the array is of <lb/>zero length, there is no previous entry), along with its cookie. <lb/>This is to help clients find the right location in their file name <lb/>caches and directory caches where this entry should be cached. If <lb/>the new entry&apos;s cookie is available, it will be in the <lb/>nad_new_entry_cookie (another variable-length array of up to one <lb/>element) field. If the addition of the entry causes another entry <lb/>to be deleted (which can only happen in the rename case) <lb/>atomically with the addition, then information on this entry is <lb/>reported in nad_old_entry. <lb/>NOTIFY4_REMOVE_ENTRY <lb/>The server will send information about the directory entry being <lb/>deleted. The server will also send the cookie value for the <lb/>deleted entry so that clients can get to the cached information <lb/>for this entry. <lb/>NOTIFY4_RENAME_ENTRY <lb/>The server will send information about both the old entry and the <lb/>new entry. This includes the name and attributes for each entry. <lb/>In addition, if the rename causes the deletion of an entry (i.e., <lb/>the case of a file renamed over), then this is reported in <lb/>nrn_new_new_entry.nad_old_entry. This notification is only sent <lb/>if both entries are in the same directory. If the rename is <lb/>across directories, the server will send a remove notification to <lb/>one directory and an add notification to the other directory, <lb/>assuming both have a directory delegation. <lb/>NOTIFY4_CHANGE_CHILD_ATTRS/NOTIFY4_CHANGE_DIR_ATTRS <lb/>The client will use the attribute mask to inform the server of <lb/>attributes for which it wants to receive notifications. This <lb/>change notification can be requested for changes to the attributes <lb/>of the directory as well as changes to any file&apos;s attributes in <lb/>the directory by using two separate attribute masks. The client <lb/>cannot ask for change attribute notification for a specific file. <lb/>One attribute mask covers all the files in the directory. Upon <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 611] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>any attribute change, the server will send back the values of <lb/>changed attributes. Notifications might not make sense for some <lb/>file system-wide attributes, and it is up to the server to decide <lb/>which subset it wants to support. The client can negotiate the <lb/>frequency of attribute notifications by letting the server know <lb/>how often it wants to be notified of an attribute change. The <lb/>server will return supported notification frequencies or an <lb/>indication that no notification is permitted for directory or <lb/>child attributes by setting the dir_notif_delay and <lb/>dir_entry_notif_delay attributes, respectively. <lb/>NOTIFY4_CHANGE_COOKIE_VERIFIER <lb/>If the cookie verifier changes while a client is holding a <lb/>delegation, the server will notify the client so that it can <lb/>invalidate its cookies and re-send a READDIR to get the new set of <lb/>cookies. <lb/>20.5. Operation 7: CB_PUSH_DELEG -Offer Previously Requested <lb/>Delegation to Client <lb/>20.5.1. ARGUMENT <lb/>struct CB_PUSH_DELEG4args { <lb/>nfs_fh4 <lb/>cpda_fh; <lb/>open_delegation4 cpda_delegation; <lb/>}; <lb/>20.5.2. RESULT <lb/>struct CB_PUSH_DELEG4res { <lb/>nfsstat4 cpdr_status; <lb/>}; <lb/>20.5.3. DESCRIPTION <lb/>CB_PUSH_DELEG is used by the server both to signal to the client that <lb/>the delegation it wants (previously indicated via a want established <lb/>from an OPEN or WANT_DELEGATION operation) is available and to <lb/>simultaneously offer the delegation to the client. The client has <lb/>the choice of accepting the delegation by returning NFS4_OK to the <lb/>server, delaying the decision to accept the offered delegation by <lb/>returning NFS4ERR_DELAY, or permanently rejecting the offer of the <lb/>delegation by returning NFS4ERR_REJECT_DELEG. When a delegation is <lb/>rejected in this fashion, the want previously established is <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 612] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>permanently deleted and the delegation is subject to acquisition by <lb/>another client. <lb/>20.5.4. IMPLEMENTATION <lb/>If the client does return NFS4ERR_DELAY and there is a conflicting <lb/>delegation request, the server MAY process it at the expense of the <lb/>client that returned NFS4ERR_DELAY. The client&apos;s want will not be <lb/>cancelled, but MAY be processed behind other delegation requests or <lb/>registered wants. <lb/>When a client returns a status other than NFS4_OK, NFS4ERR_DELAY, or <lb/>NFS4ERR_REJECT_DELAY, the want remains pending, although servers may <lb/>decide to cancel the want by sending a CB_WANTS_CANCELLED. <lb/>20.6. Operation 8: CB_RECALL_ANY -Keep Any N Recallable Objects <lb/>20.6.1. ARGUMENT <lb/>const RCA4_TYPE_MASK_RDATA_DLG <lb/>= 0; <lb/>const RCA4_TYPE_MASK_WDATA_DLG <lb/>= 1; <lb/>const RCA4_TYPE_MASK_DIR_DLG <lb/>= 2; <lb/>const RCA4_TYPE_MASK_FILE_LAYOUT <lb/>= 3; <lb/>const RCA4_TYPE_MASK_BLK_LAYOUT <lb/>= 4; <lb/>const RCA4_TYPE_MASK_OBJ_LAYOUT_MIN <lb/>= 8; <lb/>const RCA4_TYPE_MASK_OBJ_LAYOUT_MAX <lb/>= 9; <lb/>const RCA4_TYPE_MASK_OTHER_LAYOUT_MIN <lb/>= 12; <lb/>const RCA4_TYPE_MASK_OTHER_LAYOUT_MAX <lb/>= 15; <lb/>struct CB_RECALL_ANY4args <lb/>{ <lb/>uint32_t <lb/>craa_objects_to_keep; <lb/>bitmap4 <lb/>craa_type_mask; <lb/>}; <lb/>20.6.2. RESULT <lb/>struct CB_RECALL_ANY4res { <lb/>nfsstat4 <lb/>crar_status; <lb/>}; <lb/>20.6.3. DESCRIPTION <lb/>The server may decide that it cannot hold all of the state for <lb/>recallable objects, such as delegations and layouts, without running <lb/>out of resources. In such a case, while not optimal, the server is <lb/>free to recall individual objects to reduce the load. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 613] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Because the general purpose of such recallable objects as delegations <lb/>is to eliminate client interaction with the server, the server cannot <lb/>interpret lack of recent use as indicating that the object is no <lb/>longer useful. The absence of visible use is consistent with a <lb/>delegation keeping potential operations from being sent to the <lb/>server. In the case of layouts, while it is true that the usefulness <lb/>of a layout is indicated by the use of the layout when storage <lb/>devices receive I/O requests, because there is no mandate that a <lb/>storage device indicate to the metadata server any past or present <lb/>use of a layout, the metadata server is not likely to know which <lb/>layouts are good candidates to recall in response to low resources. <lb/>In order to implement an effective reclaim scheme for such objects, <lb/>the server&apos;s knowledge of available resources must be used to <lb/>determine when objects must be recalled with the clients selecting <lb/>the actual objects to be returned. <lb/>Server implementations may differ in their resource allocation <lb/>requirements. For example, one server may share resources among all <lb/>classes of recallable objects, whereas another may use separate <lb/>resource pools for layouts and for delegations, or further separate <lb/>resources by types of delegations. <lb/>When a given resource pool is over-utilized, the server can send a <lb/>CB_RECALL_ANY to clients holding recallable objects of the types <lb/>involved, allowing it to keep a certain number of such objects and <lb/>return any excess. A mask specifies which types of objects are to be <lb/>limited. The client chooses, based on its own knowledge of current <lb/>usefulness, which of the objects in that class should be returned. <lb/>A number of bits are defined. For some of these, ranges are defined <lb/>and it is up to the definition of the storage protocol to specify how <lb/>these are to be used. There are ranges reserved for object-based <lb/>storage protocols and for other experimental storage protocols. An <lb/>RFC defining such a storage protocol needs to specify how particular <lb/>bits within its range are to be used. For example, it may specify a <lb/>mapping between attributes of the layout (read vs. write, size of <lb/>area) and the bit to be used, or it may define a field in the layout <lb/>where the associated bit position is made available by the server to <lb/>the client. <lb/>RCA4_TYPE_MASK_RDATA_DLG <lb/>The client is to return OPEN_DELEGATE_READ delegations on non-<lb/>directory file objects. <lb/>RCA4_TYPE_MASK_WDATA_DLG <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 614] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>The client is to return OPEN_DELEGATE_WRITE delegations on regular <lb/>file objects. <lb/>RCA4_TYPE_MASK_DIR_DLG <lb/>The client is to return directory delegations. <lb/>RCA4_TYPE_MASK_FILE_LAYOUT <lb/>The client is to return layouts of type LAYOUT4_NFSV4_1_FILES. <lb/>RCA4_TYPE_MASK_BLK_LAYOUT <lb/>See [44] for a description. <lb/>RCA4_TYPE_MASK_OBJ_LAYOUT_MIN to RCA4_TYPE_MASK_OBJ_LAYOUT_MAX <lb/>See [43] for a description. <lb/>RCA4_TYPE_MASK_OTHER_LAYOUT_MIN to RCA4_TYPE_MASK_OTHER_LAYOUT_MAX <lb/>This range is reserved for telling the client to recall layouts of <lb/>experimental or site-specific layout types (see Section 3.3.13). <lb/>When a bit is set in the type mask that corresponds to an undefined <lb/>type of recallable object, NFS4ERR_INVAL MUST be returned. When a <lb/>bit is set that corresponds to a defined type of object but the <lb/>client does not support an object of the type, NFS4ERR_INVAL MUST NOT <lb/>be returned. Future minor versions of NFSv4 may expand the set of <lb/>valid type mask bits. <lb/>CB_RECALL_ANY specifies a count of objects that the client may keep <lb/>as opposed to a count that the client must return. This is to avoid <lb/>a potential race between a CB_RECALL_ANY that had a count of objects <lb/>to free with a set of client-originated operations to return layouts <lb/>or delegations. As a result of the race, the client and server would <lb/>have differing ideas as to how many objects to return. Hence, the <lb/>client could mistakenly free too many. <lb/>If resource demands prompt it, the server may send another <lb/>CB_RECALL_ANY with a lower count, even if it has not yet received an <lb/>acknowledgment from the client for a previous CB_RECALL_ANY with the <lb/>same type mask. Although the possibility exists that these will be <lb/>received by the client in an order different from the order in which <lb/>they were sent, any such permutation of the callback stream is <lb/>harmless. It is the job of the client to bring down the size of the <lb/>recallable object set in line with each CB_RECALL_ANY received, and <lb/>until that obligation is met, it cannot be cancelled or modified by <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 615] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>any subsequent CB_RECALL_ANY for the same type mask. Thus, if the <lb/>server sends two CB_RECALL_ANYs, the effect will be the same as if <lb/>the lower count was sent, whatever the order of recall receipt. Note <lb/>that this means that a server may not cancel the effect of a <lb/>CB_RECALL_ANY by sending another recall with a higher count. When a <lb/>CB_RECALL_ANY is received and the count is already within the limit <lb/>set or is above a limit that the client is working to get down to, <lb/>that callback has no effect. <lb/>Servers are generally free to deny recallable objects when <lb/>insufficient resources are available. Note that the effect of such a <lb/>policy is implicitly to give precedence to existing objects relative <lb/>to requested ones, with the result that resources might not be <lb/>optimally used. To prevent this, servers are well advised to make <lb/>the point at which they start sending CB_RECALL_ANY callbacks <lb/>somewhat below that at which they cease to give out new delegations <lb/>and layouts. This allows the client to purge its less-used objects <lb/>whenever appropriate and so continue to have its subsequent requests <lb/>given new resources freed up by object returns. <lb/>20.6.4. IMPLEMENTATION <lb/>The client can choose to return any type of object specified by the <lb/>mask. If a server wishes to limit the use of objects of a specific <lb/>type, it should only specify that type in the mask it sends. Should <lb/>the client fail to return requested objects, it is up to the server <lb/>to handle this situation, typically by sending specific recalls <lb/>(i.e., sending CB_RECALL operations) to properly limit resource <lb/>usage. The server should give the client enough time to return <lb/>objects before proceeding to specific recalls. This time should not <lb/>be less than the lease period. <lb/>20.7. Operation 9: CB_RECALLABLE_OBJ_AVAIL -Signal Resources for <lb/>Recallable Objects <lb/>20.7.1. ARGUMENT <lb/>typedef CB_RECALL_ANY4args CB_RECALLABLE_OBJ_AVAIL4args; <lb/>20.7.2. RESULT <lb/>struct CB_RECALLABLE_OBJ_AVAIL4res { <lb/>nfsstat4 <lb/>croa_status; <lb/>}; <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 616] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>20.7.3. DESCRIPTION <lb/>CB_RECALLABLE_OBJ_AVAIL is used by the server to signal the client <lb/>that the server has resources to grant recallable objects that might <lb/>previously have been denied by OPEN, WANT_DELEGATION, GET_DIR_DELEG, <lb/>or LAYOUTGET. <lb/>The argument craa_objects_to_keep means the total number of <lb/>recallable objects of the types indicated in the argument type_mask <lb/>that the server believes it can allow the client to have, including <lb/>the number of such objects the client already has. A client that <lb/>tries to acquire more recallable objects than the server informs it <lb/>can have runs the risk of having objects recalled. <lb/>The server is not obligated to reserve the difference between the <lb/>number of the objects the client currently has and the value of <lb/>craa_objects_to_keep, nor does delaying the reply to <lb/>CB_RECALLABLE_OBJ_AVAIL prevent the server from using the resources <lb/>of the recallable objects for another purpose. Indeed, if a client <lb/>responds slowly to CB_RECALLABLE_OBJ_AVAIL, the server might <lb/>interpret the client as having reduced capability to manage <lb/>recallable objects, and so cancel or reduce any reservation it is <lb/>maintaining on behalf of the client. Thus, if the client desires to <lb/>acquire more recallable objects, it needs to reply quickly to <lb/>CB_RECALLABLE_OBJ_AVAIL, and then send the appropriate operations to <lb/>acquire recallable objects. <lb/>20.8. Operation 10: CB_RECALL_SLOT -Change Flow Control Limits <lb/>20.8.1. ARGUMENT <lb/>struct CB_RECALL_SLOT4args { <lb/>slotid4 <lb/>rsa_target_highest_slotid; <lb/>}; <lb/>20.8.2. RESULT <lb/>struct CB_RECALL_SLOT4res { <lb/>nfsstat4 <lb/>rsr_status; <lb/>}; <lb/>20.8.3. DESCRIPTION <lb/>The CB_RECALL_SLOT operation requests the client to return session <lb/>slots, and if applicable, transport credits (e.g., RDMA credits for <lb/>connections associated with the operations channel) of the session&apos;s <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 617] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>fore channel. CB_RECALL_SLOT specifies rsa_target_highest_slotid, <lb/>the value of the target highest slot ID the server wants for the <lb/>session. The client MUST then progress toward reducing the session&apos;s <lb/>highest slot ID to the target value. <lb/>If the session has only non-RDMA connections associated with its <lb/>operations channel, then the client need only wait for all <lb/>outstanding requests with a slot ID &gt; rsa_target_highest_slotid to <lb/>complete, then send a single COMPOUND consisting of a single SEQUENCE <lb/>operation, with the sa_highestslot field set to <lb/>rsa_target_highest_slotid. If there are RDMA-based connections <lb/>associated with operation channel, then the client needs to also send <lb/>enough zero-length &quot;RDMA Send&quot; messages to take the total RDMA credit <lb/>count to rsa_target_highest_slotid + 1 or below. <lb/>20.8.4. IMPLEMENTATION <lb/>If the client fails to reduce highest slot it has on the fore channel <lb/>to what the server requests, the server can force the issue by <lb/>asserting flow control on the receive side of all connections bound <lb/>to the fore channel, and then finish servicing all outstanding <lb/>requests that are in slots greater than rsa_target_highest_slotid. <lb/>Once that is done, the server can then open the flow control, and any <lb/>time the client sends a new request on a slot greater than <lb/>rsa_target_highest_slotid, the server can return NFS4ERR_BADSLOT. <lb/>20.9. Operation 11: CB_SEQUENCE -Supply Backchannel Sequencing and <lb/>Control <lb/>20.9.1. ARGUMENT <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 618] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>struct referring_call4 { <lb/>sequenceid4 <lb/>rc_sequenceid; <lb/>slotid4 <lb/>rc_slotid; <lb/>}; <lb/>struct referring_call_list4 { <lb/>sessionid4 <lb/>rcl_sessionid; <lb/>referring_call4 rcl_referring_calls&lt;&gt;; <lb/>}; <lb/>struct CB_SEQUENCE4args { <lb/>sessionid4 <lb/>csa_sessionid; <lb/>sequenceid4 <lb/>csa_sequenceid; <lb/>slotid4 <lb/>csa_slotid; <lb/>slotid4 <lb/>csa_highest_slotid; <lb/>bool <lb/>csa_cachethis; <lb/>referring_call_list4 csa_referring_call_lists&lt;&gt;; <lb/>}; <lb/>20.9.2. RESULT <lb/>struct CB_SEQUENCE4resok { <lb/>sessionid4 <lb/>csr_sessionid; <lb/>sequenceid4 <lb/>csr_sequenceid; <lb/>slotid4 <lb/>csr_slotid; <lb/>slotid4 <lb/>csr_highest_slotid; <lb/>slotid4 <lb/>csr_target_highest_slotid; <lb/>}; <lb/>union CB_SEQUENCE4res switch (nfsstat4 csr_status) { <lb/>case NFS4_OK: <lb/>CB_SEQUENCE4resok <lb/>csr_resok4; <lb/>default: <lb/>void; <lb/>}; <lb/>20.9.3. DESCRIPTION <lb/>The CB_SEQUENCE operation is used to manage operational accounting <lb/>for the backchannel of the session on which a request is sent. The <lb/>contents include the session ID to which this request belongs, the <lb/>slot ID and sequence ID used by the server to implement session <lb/>request control and exactly once semantics, and exchanged slot ID <lb/>maxima that are used to adjust the size of the reply cache. In each <lb/>CB_COMPOUND request, CB_SEQUENCE MUST appear once and MUST be the <lb/>first operation. The error NFS4ERR_SEQUENCE_POS MUST be returned <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 619] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>when CB_SEQUENCE is found in any position in a CB_COMPOUND beyond the <lb/>first. If any other operation is in the first position of <lb/>CB_COMPOUND, NFS4ERR_OP_NOT_IN_SESSION MUST be returned. <lb/>See Section 18.46.3 for a description of how slots are processed. <lb/>If csa_cachethis is TRUE, then the server is requesting that the <lb/>client cache the reply in the callback reply cache. The client MUST <lb/>cache the reply (see Section 2.10.6.1.3). <lb/>The csa_referring_call_lists array is the list of COMPOUND requests, <lb/>identified by session ID, slot ID, and sequence ID. These are <lb/>requests that the client previously sent to the server. These <lb/>previous requests created state that some operation(s) in the same <lb/>CB_COMPOUND as the csa_referring_call_lists are identifying. A <lb/>session ID is included because leased state is tied to a client ID, <lb/>and a client ID can have multiple sessions. See Section 2.10.6.3. <lb/>The value of the csa_sequenceid argument relative to the cached <lb/>sequence ID on the slot falls into one of three cases. <lb/>o If the difference between csa_sequenceid and the client&apos;s cached <lb/>sequence ID at the slot ID is two (2) or more, or if <lb/>csa_sequenceid is less than the cached sequence ID (accounting for <lb/>wraparound of the unsigned sequence ID value), then the client <lb/>MUST return NFS4ERR_SEQ_MISORDERED. <lb/>o If csa_sequenceid and the cached sequence ID are the same, this is <lb/>a retry, and the client returns the CB_COMPOUND request&apos;s cached <lb/>reply. <lb/>o If csa_sequenceid is one greater (accounting for wraparound) than <lb/>the cached sequence ID, then this is a new request, and the slot&apos;s <lb/>sequence ID is incremented. The operations subsequent to <lb/>CB_SEQUENCE, if any, are processed. If there are no other <lb/>operations, the only other effects are to cache the CB_SEQUENCE <lb/>reply in the slot, maintain the session&apos;s activity, and when the <lb/>server receives the CB_SEQUENCE reply, renew the lease of state <lb/>related to the client ID. <lb/>If the server reuses a slot ID and sequence ID for a completely <lb/>different request, the client MAY treat the request as if it is a <lb/>retry of what it has already executed. The client MAY however detect <lb/>the server&apos;s illegal reuse and return NFS4ERR_SEQ_FALSE_RETRY. <lb/>If CB_SEQUENCE returns an error, then the state of the slot (sequence <lb/>ID, cached reply) MUST NOT change. See Section 2.10.6.1.3 for the <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 620] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>conditions when the error NFS4ERR_RETRY_UNCACHED_REP might be <lb/>returned. <lb/>The client returns two &quot;highest_slotid&quot; values: csr_highest_slotid <lb/>and csr_target_highest_slotid. The former is the highest slot ID the <lb/>client will accept in a future CB_SEQUENCE operation, and SHOULD NOT <lb/>be less than the value of csa_highest_slotid (but see <lb/>Section 2.10.6.1 for an exception). The latter is the highest slot <lb/>ID the client would prefer the server use on a future CB_SEQUENCE <lb/>operation. <lb/>20.10. Operation 12: CB_WANTS_CANCELLED -Cancel Pending Delegation <lb/>Wants <lb/>20.10.1. ARGUMENT <lb/>struct CB_WANTS_CANCELLED4args { <lb/>bool cwca_contended_wants_cancelled; <lb/>bool cwca_resourced_wants_cancelled; <lb/>}; <lb/>20.10.2. RESULT <lb/>struct CB_WANTS_CANCELLED4res { <lb/>nfsstat4 <lb/>cwcr_status; <lb/>}; <lb/>20.10.3. DESCRIPTION <lb/>The CB_WANTS_CANCELLED operation is used to notify the client that <lb/>some or all of the wants it registered for recallable delegations and <lb/>layouts have been cancelled. <lb/>If cwca_contended_wants_cancelled is TRUE, this indicates that the <lb/>server will not be pushing to the client any delegations that become <lb/>available after contention passes. <lb/>If cwca_resourced_wants_cancelled is TRUE, this indicates that the <lb/>server will not notify the client when there are resources on the <lb/>server to grant delegations or layouts. <lb/>After receiving a CB_WANTS_CANCELLED operation, the client is free to <lb/>attempt to acquire the delegations or layouts it was waiting for, and <lb/>possibly re-register wants. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 621] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>20.10.4. IMPLEMENTATION <lb/>When a client has an OPEN, WANT_DELEGATION, or GET_DIR_DELEGATION <lb/>request outstanding, when a CB_WANTS_CANCELLED is sent, the server <lb/>may need to make clear to the client whether a promise to signal <lb/>delegation availability happened before the CB_WANTS_CANCELLED and is <lb/>thus covered by it, or after the CB_WANTS_CANCELLED in which case it <lb/>was not covered by it. The server can make this distinction by <lb/>putting the appropriate requests into the list of referring calls in <lb/>the associated CB_SEQUENCE. <lb/>20.11. Operation 13: CB_NOTIFY_LOCK -Notify Client of Possible Lock <lb/>Availability <lb/>20.11.1. ARGUMENT <lb/>struct CB_NOTIFY_LOCK4args { <lb/>nfs_fh4 <lb/>cnla_fh; <lb/>lock_owner4 cnla_lock_owner; <lb/>}; <lb/>20.11.2. RESULT <lb/>struct CB_NOTIFY_LOCK4res { <lb/>nfsstat4 <lb/>cnlr_status; <lb/>}; <lb/>20.11.3. DESCRIPTION <lb/>The server can use this operation to indicate that a byte-range lock <lb/>for the given file and lock-owner, previously requested by the client <lb/>via an unsuccessful LOCK operation, might be available. <lb/>This callback is meant to be used by servers to help reduce the <lb/>latency of blocking locks in the case where they recognize that a <lb/>client that has been polling for a blocking byte-range lock may now <lb/>be able to acquire the lock. If the server supports this callback <lb/>for a given file, it MUST set the OPEN4_RESULT_MAY_NOTIFY_LOCK flag <lb/>when responding to successful opens for that file. This does not <lb/>commit the server to the use of CB_NOTIFY_LOCK, but the client may <lb/>use this as a hint to decide how frequently to poll for locks derived <lb/>from that open. <lb/>If an OPEN operation results in an upgrade, in which the stateid <lb/>returned has an &quot;other&quot; value matching that of a stateid already <lb/>allocated, with a new &quot;seqid&quot; indicating a change in the lock being <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 622] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>represented, then the value of the OPEN4_RESULT_MAY_NOTIFY_LOCK flag <lb/>when responding to that new OPEN controls handling from that point <lb/>going forward. When parallel OPENs are done on the same file and <lb/>open-owner, the ordering of the &quot;seqid&quot; fields of the returned <lb/>stateids (subject to wraparound) are to be used to select the <lb/>controlling value of the OPEN4_RESULT_MAY_NOTIFY_LOCK flag. <lb/>20.11.4. IMPLEMENTATION <lb/>The server MUST NOT grant the byte-range lock to the client unless <lb/>and until it receives a LOCK operation from the client. Similarly, <lb/>the client receiving this callback cannot assume that it now has the <lb/>lock or that a subsequent LOCK operation for the lock will be <lb/>successful. <lb/>The server is not required to implement this callback, and even if it <lb/>does, it is not required to use it in any particular case. <lb/>Therefore, the client must still rely on polling for blocking locks, <lb/>as described in Section 9.6. <lb/>Similarly, the client is not required to implement this callback, and <lb/>even it does, is still free to ignore it. Therefore, the server MUST <lb/>NOT assume that the client will act based on the callback. <lb/>20.12. Operation 14: CB_NOTIFY_DEVICEID -Notify Client of Device ID <lb/>Changes <lb/>20.12.1. ARGUMENT <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 623] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>/* <lb/>* Device notification types. <lb/>*/ <lb/>enum notify_deviceid_type4 { <lb/>NOTIFY_DEVICEID4_CHANGE = 1, <lb/>NOTIFY_DEVICEID4_DELETE = 2 <lb/>}; <lb/>/* For NOTIFY4_DEVICEID4_DELETE */ <lb/>struct notify_deviceid_delete4 { <lb/>layouttype4 <lb/>ndd_layouttype; <lb/>deviceid4 <lb/>ndd_deviceid; <lb/>}; <lb/>/* For NOTIFY4_DEVICEID4_CHANGE */ <lb/>struct notify_deviceid_change4 { <lb/>layouttype4 <lb/>ndc_layouttype; <lb/>deviceid4 <lb/>ndc_deviceid; <lb/>bool <lb/>ndc_immediate; <lb/>}; <lb/>struct CB_NOTIFY_DEVICEID4args { <lb/>notify4 cnda_changes&lt;&gt;; <lb/>}; <lb/>20.12.2. RESULT <lb/>struct CB_NOTIFY_DEVICEID4res { <lb/>nfsstat4 <lb/>cndr_status; <lb/>}; <lb/>20.12.3. DESCRIPTION <lb/>The CB_NOTIFY_DEVICEID operation is used by the server to send <lb/>notifications to clients about changes to pNFS device IDs. The <lb/>registration of device ID notifications is optional and is done via <lb/>GETDEVICEINFO. These notifications are sent over the backchannel <lb/>once the original request has been processed on the server. The <lb/>server will send an array of notifications, cnda_changes, as a list <lb/>of pairs of bitmaps and values. See Section 3.3.7 for a description <lb/>of how NFSv4.1 bitmaps work. <lb/>As with CB_NOTIFY (Section 20.4.3), it is possible the server has <lb/>more notifications than can fit in a CB_COMPOUND, thus requiring <lb/>multiple CB_COMPOUNDs. Unlike CB_NOTIFY, serialization is not an <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 624] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>issue because unlike directory entries, device IDs cannot be re-used <lb/>after being deleted (Section 12.2.10). <lb/>All device ID notifications contain a device ID and a layout type. <lb/>The layout type is necessary because two different layout types can <lb/>share the same device ID, and the common device ID can have <lb/>completely different mappings for each layout type. <lb/>The server will send the following notifications: <lb/>NOTIFY_DEVICEID4_CHANGE <lb/>A previously provided device-ID-to-device-address mapping has <lb/>changed and the client uses GETDEVICEINFO to obtain the updated <lb/>mapping. The notification is encoded in a value of data type <lb/>notify_deviceid_change4. This data type also contains a boolean <lb/>field, ndc_immediate, which if TRUE indicates that the change will <lb/>be enforced immediately, and so the client might not be able to <lb/>complete any pending I/O to the device ID. If ndc_immediate is <lb/>FALSE, then for an indefinite time, the client can complete <lb/>pending I/O. After pending I/O is complete, the client SHOULD get <lb/>the new device-ID-to-device-address mappings before sending new I/ <lb/>O requests to the storage devices addressed by the device ID. <lb/>NOTIFY4_DEVICEID_DELETE <lb/>Deletes a device ID from the mappings. This notification MUST NOT <lb/>be sent if the client has a layout that refers to the device ID. <lb/>In other words, if the server is sending a delete device ID <lb/>notification, one of the following is true for layouts associated <lb/>with the layout type: <lb/>* The client never had a layout referring to that device ID. <lb/>* The client has returned all layouts referring to that device <lb/>ID. <lb/>* The server has revoked all layouts referring to that device ID. <lb/>The notification is encoded in a value of data type <lb/>notify_deviceid_delete4. After a server deletes a device ID, it <lb/>MUST NOT reuse that device ID for the same layout type until the <lb/>client ID is deleted. <lb/>20.13. Operation 10044: CB_ILLEGAL -Illegal Callback Operation <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 625] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>20.13.1. ARGUMENT <lb/>void; <lb/>20.13.2. RESULT <lb/>/* <lb/>* CB_ILLEGAL: Response for illegal operation numbers <lb/>*/ <lb/>struct CB_ILLEGAL4res { <lb/>nfsstat4 <lb/>status; <lb/>}; <lb/>20.13.3. DESCRIPTION <lb/>This operation is a placeholder for encoding a result to handle the <lb/>case of the server sending an operation code within CB_COMPOUND that <lb/>is not defined in the NFSv4.1 specification. See Section 19.2.3 for <lb/>more details. <lb/>The status field of CB_ILLEGAL4res MUST be set to NFS4ERR_OP_ILLEGAL. <lb/>20.13.4. IMPLEMENTATION <lb/>A server will probably not send an operation with code OP_CB_ILLEGAL, <lb/>but if it does, the response will be CB_ILLEGAL4res just as it would <lb/>be with any other invalid operation code. Note that if the client <lb/>gets an illegal operation code that is not OP_ILLEGAL, and if the <lb/>client checks for legal operation codes during the XDR decode phase, <lb/>then an instance of data type CB_ILLEGAL4res will not be returned. <lb/>21. Security Considerations <lb/>Historically, the authentication model of NFS was based on the entire <lb/>machine being the NFS client, with the NFS server trusting the NFS <lb/>client to authenticate the end-user. The NFS server in turn shared <lb/>its files only to specific clients, as identified by the client&apos;s <lb/>source network address. Given this model, the AUTH_SYS RPC security <lb/>flavor simply identified the end-user using the client to the NFS <lb/>server. When processing NFS responses, the client ensured that the <lb/>responses came from the same network address and port number to which <lb/>the request was sent. While such a model is easy to implement and <lb/>simple to deploy and use, it is unsafe. Thus, NFSv4.1 <lb/>implementations are REQUIRED to support a security model that uses <lb/>end-to-end authentication, where an end-user on a client mutually <lb/>authenticates (via cryptographic schemes that do not expose passwords <lb/>or keys in the clear on the network) to a principal on an NFS server. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 626] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Consideration is also given to the integrity and privacy of NFS <lb/>requests and responses. The issues of end-to-end mutual <lb/>authentication, integrity, and privacy are discussed in <lb/>Section 2.2.1.1.1. There are specific considerations when using <lb/>Kerberos V5 as described in Section 2.2.1.1.1.2.1.1. <lb/>Note that being REQUIRED to implement does not mean REQUIRED to use; <lb/>AUTH_SYS can be used by NFSv4.1 clients and servers. However, <lb/>AUTH_SYS is merely an OPTIONAL security flavor in NFSv4.1, and so <lb/>interoperability via AUTH_SYS is not assured. <lb/>For reasons of reduced administration overhead, better performance, <lb/>and/or reduction of CPU utilization, users of NFSv4.1 implementations <lb/>might decline to use security mechanisms that enable integrity <lb/>protection on each remote procedure call and response. The use of <lb/>mechanisms without integrity leaves the user vulnerable to a man-in-<lb/>the-middle of the NFS client and server that modifies the RPC request <lb/>and/or the response. While implementations are free to provide the <lb/>option to use weaker security mechanisms, there are three operations <lb/>in particular that warrant the implementation overriding user <lb/>choices. <lb/>o The first two such operations are SECINFO and SECINFO_NO_NAME. It <lb/>is RECOMMENDED that the client send both operations such that they <lb/>are protected with a security flavor that has integrity <lb/>protection, such as RPCSEC_GSS with either the <lb/>rpc_gss_svc_integrity or rpc_gss_svc_privacy service. Without <lb/>integrity protection encapsulating SECINFO and SECINFO_NO_NAME and <lb/>their results, a man-in-the-middle could modify results such that <lb/>the client might select a weaker algorithm in the set allowed by <lb/>the server, making the client and/or server vulnerable to further <lb/>attacks. <lb/>o The third operation that SHOULD use integrity protection is any <lb/>GETATTR for the fs_locations and fs_locations_info attributes, in <lb/>order to mitigate the severity of a man-in-the-middle attack. The <lb/>attack has two steps. First the attacker modifies the unprotected <lb/>results of some operation to return NFS4ERR_MOVED. Second, when <lb/>the client follows up with a GETATTR for the fs_locations or <lb/>fs_locations_info attributes, the attacker modifies the results to <lb/>cause the client to migrate its traffic to a server controlled by <lb/>the attacker. With integrity protection, this attack is <lb/>mitigated. <lb/>Relative to previous NFS versions, NFSv4.1 has additional security <lb/>considerations for pNFS (see Sections 12.9 and 13.12), locking and <lb/>session state (see Section 2.10.8.3), and state recovery during grace <lb/>period (see Section 8.4.2.1.1). With respect to locking and session <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 627] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>state, if SP4_SSV state protection is being used, Section 2.10.10 has <lb/>specific security considerations for the NFSv4.1 client and server. <lb/>The use of the multi-server bamespace features described in <lb/>Section 11 raises the possibility that requests to determine the set <lb/>of network addresses corresponding to a given server might be <lb/>interfered with or have their responses modified in flight. In light <lb/>of this possibility, the following considerations should be taken <lb/>note of: <lb/>o When DNS is used to convert server names to addresses and DNSSEC <lb/>[29] is not available, the validity of the network addresses <lb/>returned cannot be relied upon. However, when the client uses <lb/>RPCSEC_GSS to access the designated server, it is possible for <lb/>mutual authentication to discover invalid server addresses <lb/>provided, as long as the RPCSEC_GSS implementation used does not <lb/>use insecure DNS queries to canonicalize the hostname components <lb/>of the service principal names, as explained in [28]. <lb/>o The fetching of attributes containing file system location <lb/>information SHOULD be performed using RPCSEC_GSS with integrity <lb/>protection. It is important to note here that a client making a <lb/>request of this sort without using RPCSEC_GSS including integrity <lb/>protection needs be aware of the negative consequences of doing <lb/>so, which can lead to invalid host names or network addresses <lb/>being returned. These include cases in which the client is <lb/>directed a server under the control of an attacker, who might get <lb/>access to data written or provide incorrect values for data read. <lb/>In light of this, the client needs to recognize that using such <lb/>returned location information to access an NFSv4 server without <lb/>use of RPCSEC_GSS (i.e. by using AUTH_SYS) poses dangers as it <lb/>can result in the client interacting with such an attacker-<lb/>controlled server, without any authentication facilities to verify <lb/>the server&apos;s identity. <lb/>o Despite the fact that it is a requirement that &quot;implementations&quot; <lb/>provide &quot;support&quot; for use of RPCSEC_GSS, it cannot be assumed that <lb/>use of RPCSEC_GSS is always available between any particular <lb/>client-server pair. <lb/>o When a client has the network addresses of a server but not the <lb/>associated host names, that would interfere with its ability to <lb/>use RPCSEC_GSS. <lb/>In light of the above, a server SHOULD present file system location <lb/>entries that correspond to file systems on other servers using a host <lb/>name. This would allow the client to interrogate the fs_locations on <lb/>the destination server to obtain trunking information (as well as <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 628] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>replica information) using RPCSEC_GSS with integrity, validating the <lb/>name provided while assuring that the response has not been modified <lb/>in flight. <lb/>When RPCSEC_GSS is not available on a server, the client needs to be <lb/>aware of the fact that the location entries are subject to <lb/>modification in flight and so cannot be relied upon. In the case of <lb/>a client being directed to another server after NFS4ERR_MOVED, this <lb/>could vitiate the authentication provided by the use of RPCSEC_GSS on <lb/>the destination. Even when RPCSEC_GSS authentication is available on <lb/>the destination, the server might validly represent itself as the <lb/>server to which the client was erroneously directed. Without a way <lb/>to decide whether the server is a valid one, the client can only <lb/>determine, using RPCSEC_GSS, that the server corresponds to the name <lb/>provided, with no basis for trusting that server. As a result, the <lb/>client SHOULD NOT use such unverified location entries as a basis for <lb/>migration, even though RPCSEC_GSS might be available on the <lb/>destination. <lb/>When a file system location attribute is fetched upon connecting with <lb/>an NFS server, it SHOULD, as stated above, be done using RPCSEC_GSS <lb/>with integrity protection. When this not possible, it is generally <lb/>best for the client to ignore trunking and replica information or <lb/>simply not fetch the location information for these purposes. <lb/>When location information cannot be verified, it can be subjected to <lb/>additional filtering to prevent the client from being inappropriately <lb/>directed. For example, if a range of network addresses can be <lb/>determined that assure that the servers and clients using AUTH_SYS <lb/>are subject to the appropriate set of constraints (e.g. physical <lb/>network isolation, administrative controls on the operating systems <lb/>used), then network addresses in the appropriate range can be used <lb/>with others discarded or restricted in their use of AUTH_SYS. <lb/>To summarize considerations regarding the use of RPCSEC_GSS in <lb/>fetching location information, we need to consider the following <lb/>possibilities for requests to interrogate location information, with <lb/>interrogation approaches on the referring and destination servers <lb/>arrived at separately: <lb/>o The use of RPCSEC_GSS with integrity protection is RECOMMENDED in <lb/>all cases, since the absence of integrity protection exposes the <lb/>client to the possibility of the results being modified in <lb/>transit. <lb/>o The use of requests issued without RPCSEC_GSS (i.e. using AUTH_SYS <lb/>which has no provision to avoid modification of data in flight), <lb/>while undesirable and a potential security exposure, may not be <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 629] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>avoidable in all cases. Where the use of the returned information <lb/>cannot be avoided, it is made subject to filtering as described <lb/>above to eliminate the possibility that the client would treat an <lb/>invalid address as if it were a NFSv4 server. The specifics will <lb/>vary depending on the degree of network isolation and whether the <lb/>request is to the referring or destination servers. <lb/>22. IANA Considerations <lb/>This section uses terms that are defined in [58]. <lb/>22.1. IANA Actions Neeeded <lb/>This update does not require any actions by IANA. <lb/>Previous actions by IANA related to NFSv4.1 are listed in the <lb/>remaining subsections of Section 22. <lb/>22.2. Named Attribute Definitions <lb/>IANA created a registry called the &quot;NFSv4 Named Attribute Definitions <lb/>Registry&quot;. <lb/>The NFSv4.1 protocol supports the association of a file with zero or <lb/>more named attributes. The namespace identifiers for these <lb/>attributes are defined as string names. The protocol does not define <lb/>the specific assignment of the namespace for these file attributes. <lb/>The IANA registry promotes interoperability where common interests <lb/>exist. While application developers are allowed to define and use <lb/>attributes as needed, they are encouraged to register the attributes <lb/>with IANA. <lb/>Such registered named attributes are presumed to apply to all minor <lb/>versions of NFSv4, including those defined subsequently to the <lb/>registration. If the named attribute is intended to be limited to <lb/>specific minor versions, this will be clearly stated in the <lb/>registry&apos;s assignment. <lb/>All assignments to the registry are made on a First Come First Served <lb/>basis, per Section 4.1 of [58]. The policy for each assignment is <lb/>Specification Required, per Section 4.1 of [58]. <lb/>Under the NFSv4.1 specification, the name of a named attribute can in <lb/>theory be up to 2^32 -1 bytes in length, but in practice NFSv4.1 <lb/>clients and servers will be unable to handle a string that long. <lb/>IANA should reject any assignment request with a named attribute that <lb/>exceeds 128 UTF-8 characters. To give the IESG the flexibility to <lb/>set up bases of assignment of Experimental Use and Standards Action, <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 630] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>the prefixes of &quot;EXPE&quot; and &quot;STDS&quot; are Reserved. The named attribute <lb/>with a zero-length name is Reserved. <lb/>The prefix &quot;PRIV&quot; is designated for Private Use. A site that wants <lb/>to make use of unregistered named attributes without risk of <lb/>conflicting with an assignment in IANA&apos;s registry should use the <lb/>prefix &quot;PRIV&quot; in all of its named attributes. <lb/>Because some NFSv4.1 clients and servers have case-insensitive <lb/>semantics, the fifteen additional lower case and mixed case <lb/>permutations of each of &quot;EXPE&quot;, &quot;PRIV&quot;, and &quot;STDS&quot; are Reserved <lb/>(e.g., &quot;expe&quot;, &quot;expE&quot;, &quot;exPe&quot;, etc. are Reserved). Similarly, IANA <lb/>must not allow two assignments that would conflict if both named <lb/>attributes were converted to a common case. <lb/>The registry of named attributes is a list of assignments, each <lb/>containing three fields for each assignment. <lb/>1. A US-ASCII string name that is the actual name of the attribute. <lb/>This name must be unique. This string name can be 1 to 128 UTF-8 <lb/>characters long. <lb/>2. A reference to the specification of the named attribute. The <lb/>reference can consume up to 256 bytes (or more if IANA permits). <lb/>3. The point of contact of the registrant. The point of contact can <lb/>consume up to 256 bytes (or more if IANA permits). <lb/>22.2.1. Initial Registry <lb/>There is no initial registry. <lb/>22.2.2. Updating Registrations <lb/>The registrant is always permitted to update the point of contact <lb/>field. Any other change will require Expert Review or IESG Approval. <lb/>22.3. Device ID Notifications <lb/>IANA created a registry called the &quot;NFSv4 Device ID Notifications <lb/>Registry&quot;. <lb/>The potential exists for new notification types to be added to the <lb/>CB_NOTIFY_DEVICEID operation (see Section 20.12). This can be done <lb/>via changes to the operations that register notifications, or by <lb/>adding new operations to NFSv4. This requires a new minor version of <lb/>NFSv4, and requires a Standards Track document from the IETF. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 631] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>Another way to add a notification is to specify a new layout type <lb/>(see Section 22.5). <lb/>Hence, all assignments to the registry are made on a Standards Action <lb/>basis per Section 4.1 of [58], with Expert Review required. <lb/>The registry is a list of assignments, each containing five fields <lb/>per assignment. <lb/>1. The name of the notification type. This name must have the <lb/>prefix &quot;NOTIFY_DEVICEID4_&quot;. This name must be unique. <lb/>2. The value of the notification. IANA will assign this number, and <lb/>the request from the registrant will use TBD1 instead of an <lb/>actual value. IANA MUST use a whole number that can be no higher <lb/>than 2^32-1, and should be the next available value. The value <lb/>assigned must be unique. A Designated Expert must be used to <lb/>ensure that when the name of the notification type and its value <lb/>are added to the NFSv4.1 notify_deviceid_type4 enumerated data <lb/>type in the NFSv4.1 XDR description ([10]), the result continues <lb/>to be a valid XDR description. <lb/>3. The Standards Track RFC(s) that describe the notification. If <lb/>the RFC(s) have not yet been published, the registrant will use <lb/>RFCTBD2, RFCTBD3, etc. instead of an actual RFC number. <lb/>4. How the RFC introduces the notification. This is indicated by a <lb/>single US-ASCII value. If the value is N, it means a minor <lb/>revision to the NFSv4 protocol. If the value is L, it means a <lb/>new pNFS layout type. Other values can be used with IESG <lb/>Approval. <lb/>5. The minor versions of NFSv4 that are allowed to use the <lb/>notification. While these are numeric values, IANA will not <lb/>allocate and assign them; the author of the relevant RFCs with <lb/>IESG Approval assigns these numbers. Each time there is a new <lb/>minor version of NFSv4 approved, a Designated Expert should <lb/>review the registry to make recommended updates as needed. <lb/>22.3.1. Initial Registry <lb/>The initial registry is in Table 16. Note that the next available <lb/>value is zero. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 632] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>+-------------------------+-------+---------+-----+----------------+ <lb/>| Notification Name <lb/>| Value | RFC <lb/>| How | Minor Versions | <lb/>+-------------------------+-------+---------+-----+----------------+ <lb/>| NOTIFY_DEVICEID4_CHANGE | 1 <lb/>| RFC5661 | N <lb/>| 1 <lb/>| <lb/>| NOTIFY_DEVICEID4_DELETE | 2 <lb/>| RFC5661 | N <lb/>| 1 <lb/>| <lb/>+-------------------------+-------+---------+-----+----------------+ <lb/>Table 16: Initial Device ID Notification Assignments <lb/>22.3.2. Updating Registrations <lb/>The update of a registration will require IESG Approval on the advice <lb/>of a Designated Expert. <lb/>22.4. Object Recall Types <lb/>IANA created a registry called the &quot;NFSv4 Recallable Object Types <lb/>Registry&quot;. <lb/>The potential exists for new object types to be added to the <lb/>CB_RECALL_ANY operation (see Section 20.6). This can be done via <lb/>changes to the operations that add recallable types, or by adding new <lb/>operations to NFSv4. This requires a new minor version of NFSv4, and <lb/>requires a Standards Track document from IETF. Another way to add a <lb/>new recallable object is to specify a new layout type (see <lb/>Section 22.5). <lb/>All assignments to the registry are made on a Standards Action basis <lb/>per Section 4.1 of [58], with Expert Review required. <lb/>Recallable object types are 32-bit unsigned numbers. There are no <lb/>Reserved values. Values in the range 12 through 15, inclusive, are <lb/>designated for Private Use. <lb/>The registry is a list of assignments, each containing five fields <lb/>per assignment. <lb/>1. The name of the recallable object type. This name must have the <lb/>prefix &quot;RCA4_TYPE_MASK_&quot;. The name must be unique. <lb/>2. The value of the recallable object type. IANA will assign this <lb/>number, and the request from the registrant will use TBD1 instead <lb/>of an actual value. IANA MUST use a whole number that can be no <lb/>higher than 2^32-1, and should be the next available value. The <lb/>value must be unique. A Designated Expert must be used to ensure <lb/>that when the name of the recallable type and its value are added <lb/>to the NFSv4 XDR description [10], the result continues to be a <lb/>valid XDR description. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 633] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>3. The Standards Track RFC(s) that describe the recallable object <lb/>type. If the RFC(s) have not yet been published, the registrant <lb/>will use RFCTBD2, RFCTBD3, etc. instead of an actual RFC number. <lb/>4. How the RFC introduces the recallable object type. This is <lb/>indicated by a single US-ASCII value. If the value is N, it <lb/>means a minor revision to the NFSv4 protocol. If the value is L, <lb/>it means a new pNFS layout type. Other values can be used with <lb/>IESG Approval. <lb/>5. The minor versions of NFSv4 that are allowed to use the <lb/>recallable object type. While these are numeric values, IANA <lb/>will not allocate and assign them; the author of the relevant <lb/>RFCs with IESG Approval assigns these numbers. Each time there <lb/>is a new minor version of NFSv4 approved, a Designated Expert <lb/>should review the registry to make recommended updates as needed. <lb/>22.4.1. Initial Registry <lb/>The initial registry is in Table 17. Note that the next available <lb/>value is five. <lb/>+-------------------------------+-------+--------+-----+------------+ <lb/>| Recallable Object Type Name <lb/>| Value | RFC <lb/>| How | Minor <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| <lb/>| Versions <lb/>| <lb/>+-------------------------------+-------+--------+-----+------------+ <lb/>| RCA4_TYPE_MASK_RDATA_DLG <lb/>| 0 <lb/>| RFC <lb/>| N <lb/>| 1 <lb/>| <lb/>| <lb/>| <lb/>| 5661 <lb/>| <lb/>| <lb/>| <lb/>| RCA4_TYPE_MASK_WDATA_DLG <lb/>| 1 <lb/>| RFC <lb/>| N <lb/>| 1 <lb/>| <lb/>| <lb/>| <lb/>| 5661 <lb/>| <lb/>| <lb/>| <lb/>| RCA4_TYPE_MASK_DIR_DLG <lb/>| 2 <lb/>| RFC <lb/>| N <lb/>| 1 <lb/>| <lb/>| <lb/>| <lb/>| 5661 <lb/>| <lb/>| <lb/>| <lb/>| RCA4_TYPE_MASK_FILE_LAYOUT <lb/>| 3 <lb/>| RFC <lb/>| N <lb/>| 1 <lb/>| <lb/>| <lb/>| <lb/>| 5661 <lb/>| <lb/>| <lb/>| <lb/>| RCA4_TYPE_MASK_BLK_LAYOUT <lb/>| 4 <lb/>| RFC <lb/>| L <lb/>| 1 <lb/>| <lb/>| <lb/>| <lb/>| 5661 <lb/>| <lb/>| <lb/>| <lb/>| RCA4_TYPE_MASK_OBJ_LAYOUT_MIN | 8 <lb/>| RFC <lb/>| L <lb/>| 1 <lb/>| <lb/>| <lb/>| <lb/>| 5661 <lb/>| <lb/>| <lb/>| <lb/>| RCA4_TYPE_MASK_OBJ_LAYOUT_MAX | 9 <lb/>| RFC <lb/>| L <lb/>| 1 <lb/>| <lb/>| <lb/>| <lb/>| 5661 <lb/>| <lb/>| <lb/>| <lb/>+-------------------------------+-------+--------+-----+------------+ <lb/>Table 17: Initial Recallable Object Type Assignments <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 634] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>22.4.2. Updating Registrations <lb/>The update of a registration will require IESG Approval on the advice <lb/>of a Designated Expert. <lb/>22.5. Layout Types <lb/>IANA created a registry called the &quot;pNFS Layout Types Registry&quot;. <lb/>All assignments to the registry are made on a Standards Action basis, <lb/>with Expert Review required. <lb/>Layout types are 32-bit numbers. The value zero is Reserved. Values <lb/>in the range 0x80000000 to 0xFFFFFFFF inclusive are designated for <lb/>Private Use. IANA will assign numbers from the range 0x00000001 to <lb/>0x7FFFFFFF inclusive. <lb/>The registry is a list of assignments, each containing five fields. <lb/>1. The name of the layout type. This name must have the prefix <lb/>&quot;LAYOUT4_&quot;. The name must be unique. <lb/>2. The value of the layout type. IANA will assign this number, and <lb/>the request from the registrant will use TBD1 instead of an <lb/>actual value. The value assigned must be unique. A Designated <lb/>Expert must be used to ensure that when the name of the layout <lb/>type and its value are added to the NFSv4.1 layouttype4 <lb/>enumerated data type in the NFSv4.1 XDR description ([10]), the <lb/>result continues to be a valid XDR description. <lb/>3. The Standards Track RFC(s) that describe the notification. If <lb/>the RFC(s) have not yet been published, the registrant will use <lb/>RFCTBD2, RFCTBD3, etc. instead of an actual RFC number. <lb/>Collectively, the RFC(s) must adhere to the guidelines listed in <lb/>Section 22.5.3. <lb/>4. How the RFC introduces the layout type. This is indicated by a <lb/>single US-ASCII value. If the value is N, it means a minor <lb/>revision to the NFSv4 protocol. If the value is L, it means a <lb/>new pNFS layout type. Other values can be used with IESG <lb/>Approval. <lb/>5. The minor versions of NFSv4 that are allowed to use the <lb/>notification. While these are numeric values, IANA will not <lb/>allocate and assign them; the author of the relevant RFCs with <lb/>IESG Approval assigns these numbers. Each time there is a new <lb/>minor version of NFSv4 approved, a Designated Expert should <lb/>review the registry to make recommended updates as needed. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 635] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>22.5.1. Initial Registry <lb/>The initial registry is in Table 18. <lb/>+-----------------------+-------+----------+-----+----------------+ <lb/>| Layout Type Name <lb/>| Value | RFC <lb/>| How | Minor Versions | <lb/>+-----------------------+-------+----------+-----+----------------+ <lb/>| LAYOUT4_NFSV4_1_FILES | 0x1 <lb/>| RFC 5661 | N <lb/>| 1 <lb/>| <lb/>| LAYOUT4_OSD2_OBJECTS | 0x2 <lb/>| RFC 5664 | L <lb/>| 1 <lb/>| <lb/>| LAYOUT4_BLOCK_VOLUME | 0x3 <lb/>| RFC 5663 | L <lb/>| 1 <lb/>| <lb/>+-----------------------+-------+----------+-----+----------------+ <lb/>Table 18: Initial Layout Type Assignments <lb/>22.5.2. Updating Registrations <lb/>The update of a registration will require IESG Approval on the advice <lb/>of a Designated Expert. <lb/>22.5.3. Guidelines for Writing Layout Type Specifications <lb/>The author of a new pNFS layout specification must follow these steps <lb/>to obtain acceptance of the layout type as a Standards Track RFC: <lb/>1. The author devises the new layout specification. <lb/>2. The new layout type specification MUST, at a minimum: <lb/>* Define the contents of the layout-type-specific fields of the <lb/>following data types: <lb/>+ the da_addr_body field of the device_addr4 data type; <lb/>+ the loh_body field of the layouthint4 data type; <lb/>+ the loc_body field of layout_content4 data type (which in <lb/>turn is the lo_content field of the layout4 data type); <lb/>+ the lou_body field of the layoutupdate4 data type; <lb/>* Describe or define the storage access protocol used to access <lb/>the storage devices. <lb/>* Describe whether revocation of layouts is supported. <lb/>* At a minimum, describe the methods of recovery from: <lb/>1. Failure and restart for client, server, storage device. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 636] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2. Lease expiration from perspective of the active client, <lb/>server, storage device. <lb/>3. Loss of layout state resulting in fencing of client access <lb/>to storage devices (for an example, see Section 12.7.3). <lb/>* Include an IANA considerations section, which will in turn <lb/>include: <lb/>+ A request to IANA for a new layout type per Section 22.5. <lb/>+ A list of requests to IANA for any new recallable object <lb/>types for CB_RECALL_ANY; each entry is to be presented in <lb/>the form described in Section 22.4. <lb/>+ A list of requests to IANA for any new notification values <lb/>for CB_NOTIFY_DEVICEID; each entry is to be presented in <lb/>the form described in Section 22.3. <lb/>* Include a security considerations section. This section MUST <lb/>explain how the NFSv4.1 authentication, authorization, and <lb/>access-control models are preserved. That is, if a metadata <lb/>server would restrict a READ or WRITE operation, how would <lb/>pNFS via the layout similarly restrict a corresponding input <lb/>or output operation? <lb/>3. The author documents the new layout specification as an Internet-<lb/>Draft. <lb/>4. The author submits the Internet-Draft for review through the IETF <lb/>standards process as defined in &quot;The Internet Standards Process--<lb/>Revision 3&quot; (BCP 9). The new layout specification will be <lb/>submitted for eventual publication as a Standards Track RFC. <lb/>5. The layout specification progresses through the IETF standards <lb/>process. <lb/>22.6. Path Variable Definitions <lb/>This section deals with the IANA considerations associated with the <lb/>variable substitution feature for location names as described in <lb/>Section 11.16.3. As described there, variables subject to <lb/>substitution consist of a domain name and a specific name within that <lb/>domain, with the two separated by a colon. There are two sets of <lb/>IANA considerations here: <lb/>1. The list of variable names. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 637] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2. For each variable name, the list of possible values. <lb/>Thus, there will be one registry for the list of variable names, and <lb/>possibly one registry for listing the values of each variable name. <lb/>22.6.1. Path Variables Registry <lb/>IANA created a registry called the &quot;NFSv4 Path Variables Registry&quot;. <lb/>22.6.1.1. Path Variable Values <lb/>Variable names are of the form &quot;${&quot;, followed by a domain name, <lb/>followed by a colon (&quot;:&quot;), followed by a domain-specific portion of <lb/>the variable name, followed by &quot;}&quot;. When the domain name is <lb/>&quot;ietf.org&quot;, all variables names must be registered with IANA on a <lb/>Standards Action basis, with Expert Review required. Path variables <lb/>with registered domain names neither part of nor equal to ietf.org <lb/>are assigned on a Hierarchical Allocation basis (delegating to the <lb/>domain owner) and thus of no concern to IANA, unless the domain owner <lb/>chooses to register a variable name from his domain. If the domain <lb/>owner chooses to do so, IANA will do so on a First Come First Serve <lb/>basis. To accommodate registrants who do not have their own domain, <lb/>IANA will accept requests to register variables with the prefix <lb/>&quot;${FCFS.ietf.org:&quot; on a First Come First Served basis. Assignments <lb/>on a First Come First Basis do not require Expert Review, unless the <lb/>registrant also wants IANA to establish a registry for the values of <lb/>the registered variable. <lb/>The registry is a list of assignments, each containing three fields. <lb/>1. The name of the variable. The name of this variable must start <lb/>with a &quot;${&quot; followed by a registered domain name, followed by <lb/>&quot;:&quot;, or it must start with &quot;${FCFS.ietf.org&quot;. The name must be <lb/>no more than 64 UTF-8 characters long. The name must be unique. <lb/>2. For assignments made on Standards Action basis, the Standards <lb/>Track RFC(s) that describe the variable. If the RFC(s) have not <lb/>yet been published, the registrant will use RFCTBD1, RFCTBD2, <lb/>etc. instead of an actual RFC number. Note that the RFCs do not <lb/>have to be a part of an NFS minor version. For assignments made <lb/>on a First Come First Serve basis, an explanation (consuming no <lb/>more than 1024 bytes, or more if IANA permits) of the purpose of <lb/>the variable. A reference to the explanation can be substituted. <lb/>3. The point of contact, including an email address. The point of <lb/>contact can consume up to 256 bytes (or more if IANA permits). <lb/>For assignments made on a Standards Action basis, the point of <lb/>contact is always IESG. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 638] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>22.6.1.1.1. Initial Registry <lb/>The initial registry is in Table 19. <lb/>+------------------------+----------+------------------+ <lb/>| Variable Name <lb/>| RFC <lb/>| Point of Contact | <lb/>+------------------------+----------+------------------+ <lb/>| ${ietf.org:CPU_ARCH} <lb/>| RFC 5661 | IESG <lb/>| <lb/>| ${ietf.org:OS_TYPE} <lb/>| RFC 5661 | IESG <lb/>| <lb/>| ${ietf.org:OS_VERSION} | RFC 5661 | IESG <lb/>| <lb/>+------------------------+----------+------------------+ <lb/>Table 19: Initial List of Path Variables <lb/>IANA has created registries for the values of the variable names <lb/>${ietf.org:CPU_ARCH} and ${ietf.org:OS_TYPE}. See Sections 22.6.2 and <lb/>22.6.3. <lb/>For the values of the variable ${ietf.org:OS_VERSION}, no registry is <lb/>needed as the specifics of the values of the variable will vary with <lb/>the value of ${ietf.org:OS_TYPE}. Thus, values for <lb/>${ietf.org:OS_VERSION} are on a Hierarchical Allocation basis and are <lb/>of no concern to IANA. <lb/>22.6.1.1.2. Updating Registrations <lb/>The update of an assignment made on a Standards Action basis will <lb/>require IESG Approval on the advice of a Designated Expert. <lb/>The registrant can always update the point of contact of an <lb/>assignment made on a First Come First Serve basis. Any other update <lb/>will require Expert Review. <lb/>22.6.2. Values for the ${ietf.org:CPU_ARCH} Variable <lb/>IANA created a registry called the &quot;NFSv4 ${ietf.org:CPU_ARCH} Value <lb/>Registry&quot;. <lb/>Assignments to the registry are made on a First Come First Serve <lb/>basis. The zero-length value of ${ietf.org:CPU_ARCH} is Reserved. <lb/>Values with a prefix of &quot;PRIV&quot; are designated for Private Use. <lb/>The registry is a list of assignments, each containing three fields. <lb/>1. A value of the ${ietf.org:CPU_ARCH} variable. The value must be <lb/>1 to 32 UTF-8 characters long. The value must be unique. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 639] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<body>2. An explanation (consuming no more than 1024 bytes, or more if <lb/>IANA permits) of what CPU architecture the value denotes. A <lb/>reference to the explanation can be substituted. <lb/>3. The point of contact, including an email address. The point of <lb/>contact can consume up to 256 bytes (or more if IANA permits). <lb/>22.6.2.1. Initial Registry <lb/>There is no initial registry. <lb/>22.6.2.2. Updating Registrations <lb/>The registrant is free to update the assignment, i.e., change the <lb/>explanation and/or point-of-contact fields. <lb/>22.6.3. Values for the ${ietf.org:OS_TYPE} Variable <lb/>IANA created a registry called the &quot;NFSv4 ${ietf.org:OS_TYPE} Value <lb/>Registry&quot;. <lb/>Assignments to the registry are made on a First Come First Serve <lb/>basis. The zero-length value of ${ietf.org:OS_TYPE} is Reserved. <lb/>Values with a prefix of &quot;PRIV&quot; are designated for Private Use. <lb/>The registry is a list of assignments, each containing three fields. <lb/>1. A value of the ${ietf.org:OS_TYPE} variable. The value must be 1 <lb/>to 32 UTF-8 characters long. The value must be unique. <lb/>2. An explanation (consuming no more than 1024 bytes, or more if <lb/>IANA permits) of what CPU architecture the value denotes. A <lb/>reference to the explanation can be substituted. <lb/>3. The point of contact, including an email address. The point of <lb/>contact can consume up to 256 bytes (or more if IANA permits). <lb/>22.6.3.1. Initial Registry <lb/>There is no initial registry. <lb/>22.6.3.2. Updating Registrations <lb/>The registrant is free to update the assignment, i.e., change the <lb/>explanation and/or point of contact fields. <lb/></body>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 640] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<listBibl>23. References <lb/>23.1. Normative References <lb/>[1] <lb/>Bradner, S., &quot;Key words for use in RFCs to Indicate <lb/>Requirement Levels&quot;, BCP 14, RFC 2119, March 1997. <lb/>[2] <lb/>Eisler, M., Ed., &quot;XDR: External Data Representation <lb/>Standard&quot;, STD 67, RFC 4506, May 2006. <lb/>[3] <lb/>Thurlow, R., &quot;RPC: Remote Procedure Call Protocol <lb/>Specification Version 2&quot;, RFC 5531, May 2009. <lb/>[4] <lb/>Eisler, M., Chiu, A., and L. Ling, &quot;RPCSEC_GSS Protocol <lb/>Specification&quot;, RFC 2203, September 1997. <lb/>[5] <lb/>Zhu, L., Jaganathan, K., and S. Hartman, &quot;The Kerberos <lb/>Version 5 Generic Security Service Application Program <lb/>Interface (GSS-API) Mechanism Version 2&quot;, RFC 4121, July <lb/>2005. <lb/>[6] <lb/>The Open Group, &quot;Section 3.191 of Chapter 3 of Base <lb/>Definitions of The Open Group Base Specifications Issue 6 <lb/>IEEE Std 1003.1, 2004 Edition, HTML Version <lb/>(www.opengroup.org), ISBN 1931624232&quot;, 2004. <lb/>[7] <lb/>Linn, J., &quot;Generic Security Service Application Program <lb/>Interface Version 2, Update 1&quot;, RFC 2743, January 2000. <lb/>[8] <lb/>Recio, R., Metzler, B., Culley, P., Hilland, J., and D. <lb/>Garcia, &quot;A Remote Direct Memory Access Protocol <lb/>Specification&quot;, RFC 5040, October 2007. <lb/>[9] <lb/>Eisler, M., &quot;RPCSEC_GSS Version 2&quot;, RFC 5403, February <lb/>2009. <lb/>[10] <lb/>Shepler, S., Ed., Eisler, M., Ed., and D. Noveck, Ed., <lb/>&quot;Network File System (NFS) Version 4 Minor Version 1 <lb/>External Data Representation Standard (XDR) Description&quot;, <lb/>RFC 5662, January 2010. <lb/>[11] <lb/>The Open Group, &quot;Section 3.372 of Chapter 3 of Base <lb/>Definitions of The Open Group Base Specifications Issue 6 <lb/>IEEE Std 1003.1, 2004 Edition, HTML Version <lb/>(www.opengroup.org), ISBN 1931624232&quot;, 2004. <lb/></listBibl>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 641] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<listBibl>[12] <lb/>Eisler, M., &quot;IANA Considerations for Remote Procedure Call <lb/>(RPC) Network Identifiers and Universal Address Formats&quot;, <lb/>RFC 5665, January 2010. <lb/>[13] <lb/>The Open Group, &quot;Section &apos;read()&apos; of System Interfaces of <lb/>The Open Group Base Specifications Issue 6 IEEE Std <lb/>1003.1, 2004 Edition, HTML Version (www.opengroup.org), <lb/>ISBN 1931624232&quot;, 2004. <lb/>[14] <lb/>The Open Group, &quot;Section &apos;readdir()&apos; of System Interfaces <lb/>of The Open Group Base Specifications Issue 6 IEEE Std <lb/>1003.1, 2004 Edition, HTML Version (www.opengroup.org), <lb/>ISBN 1931624232&quot;, 2004. <lb/>[15] <lb/>The Open Group, &quot;Section &apos;write()&apos; of System Interfaces of <lb/>The Open Group Base Specifications Issue 6 IEEE Std <lb/>1003.1, 2004 Edition, HTML Version (www.opengroup.org), <lb/>ISBN 1931624232&quot;, 2004. <lb/>[16] <lb/>Hoffman, P. and M. Blanchet, &quot;Preparation of <lb/>Internationalized Strings (&quot;stringprep&quot;)&quot;, RFC 3454, <lb/>December 2002. <lb/>[17] <lb/>The Open Group, &quot;Section &apos;chmod()&apos; of System Interfaces of <lb/>The Open Group Base Specifications Issue 6 IEEE Std <lb/>1003.1, 2004 Edition, HTML Version (www.opengroup.org), <lb/>ISBN 1931624232&quot;, 2004. <lb/>[18] <lb/>International Organization for Standardization, <lb/>&quot;Information Technology -Universal Multiple-octet coded <lb/>Character Set (UCS) -Part 1: Architecture and Basic <lb/>Multilingual Plane&quot;, ISO Standard 10646-1, May 1993. <lb/>[19] <lb/>Alvestrand, H., &quot;IETF Policy on Character Sets and <lb/>Languages&quot;, BCP 18, RFC 2277, January 1998. <lb/>[20] <lb/>Hoffman, P. and M. Blanchet, &quot;Nameprep: A Stringprep <lb/>Profile for Internationalized Domain Names (IDN)&quot;, <lb/>RFC 3491, March 2003. <lb/>[21] <lb/>The Open Group, &quot;Section &apos;fcntl()&apos; of System Interfaces of <lb/>The Open Group Base Specifications Issue 6 IEEE Std <lb/>1003.1, 2004 Edition, HTML Version (www.opengroup.org), <lb/>ISBN 1931624232&quot;, 2004. <lb/></listBibl>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 642] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<listBibl>[22] <lb/>The Open Group, &quot;Section &apos;fsync()&apos; of System Interfaces of <lb/>The Open Group Base Specifications Issue 6 IEEE Std <lb/>1003.1, 2004 Edition, HTML Version (www.opengroup.org), <lb/>ISBN 1931624232&quot;, 2004. <lb/>[23] <lb/>The Open Group, &quot;Section &apos;getpwnam()&apos; of System Interfaces <lb/>of The Open Group Base Specifications Issue 6 IEEE Std <lb/>1003.1, 2004 Edition, HTML Version (www.opengroup.org), <lb/>ISBN 1931624232&quot;, 2004. <lb/>[24] <lb/>The Open Group, &quot;Section &apos;unlink()&apos; of System Interfaces <lb/>of The Open Group Base Specifications Issue 6 IEEE Std <lb/>1003.1, 2004 Edition, HTML Version (www.opengroup.org), <lb/>ISBN 1931624232&quot;, 2004. <lb/>[25] <lb/>Schaad, J., Kaliski, B., and R. Housley, &quot;Additional <lb/>Algorithms and Identifiers for RSA Cryptography for use in <lb/>the Internet X.509 Public Key Infrastructure Certificate <lb/>and Certificate Revocation List (CRL) Profile&quot;, RFC 4055, <lb/>June 2005. <lb/>[26] <lb/>National Institute of Standards and Technology, <lb/>&quot;Cryptographic Algorithm Object Registration&quot;, URL <lb/>http://csrc.nist.gov/groups/ST/crypto_apps_infra/csor/ <lb/>algorithms.html, November 2007. <lb/>[27] <lb/>Adamson, A. and N. Williams, &quot;Remote Procedure Call (RPC) <lb/>Security Version 3&quot;, RFC 7861, DOI 10.17487/RFC7861, <lb/>November 2016, &lt;https://www.rfc-editor.org/info/rfc7861&gt;. <lb/>[28] <lb/>Neuman, C., Yu, T., Hartman, S., and K. Raeburn, &quot;The <lb/>Kerberos Network Authentication Service (V5)&quot;, RFC 4120, <lb/>DOI 10.17487/RFC4120, July 2005, <lb/>&lt;https://www.rfc-editor.org/info/rfc4120&gt;. <lb/>[29] <lb/>Arends, R., Austein, R., Larson, M., Massey, D., and S. <lb/>Rose, &quot;DNS Security Introduction and Requirements&quot;, <lb/>RFC 4033, DOI 10.17487/RFC4033, March 2005, <lb/>&lt;https://www.rfc-editor.org/info/rfc4033&gt;. <lb/>[30] <lb/>Adamson, A. and N. Williams, &quot;Requirements for NFSv4 <lb/>Multi-Domain Namespace Deployment&quot;, RFC 8000, <lb/>DOI 10.17487/RFC8000, November 2016, <lb/>&lt;https://www.rfc-editor.org/info/rfc8000&gt;. <lb/></listBibl>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 643] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<listBibl>[31] <lb/>Lever, C., Ed., Simpson, W., and T. Talpey, &quot;Remote Direct <lb/>Memory Access Transport for Remote Procedure Call Version <lb/>1&quot;, RFC 8166, DOI 10.17487/RFC8166, June 2017, <lb/>&lt;https://www.rfc-editor.org/info/rfc8166&gt;. <lb/>[32] <lb/>Lever, C., &quot;Network File System (NFS) Upper-Layer Binding <lb/>to RPC-over-RDMA Version 1&quot;, RFC 8267, <lb/>DOI 10.17487/RFC8267, October 2017, <lb/>&lt;https://www.rfc-editor.org/info/rfc8267&gt;. <lb/>23.2. Informative References <lb/>[33] <lb/>Shepler, S., Callaghan, B., Robinson, D., Thurlow, R., <lb/>Beame, C., Eisler, M., and D. Noveck, &quot;Network File System <lb/>(NFS) version 4 Protocol&quot;, RFC 3530, April 2003. <lb/>[34] <lb/>Callaghan, B., Pawlowski, B., and P. Staubach, &quot;NFS <lb/>Version 3 Protocol Specification&quot;, RFC 1813, June 1995. <lb/>[35] <lb/>Eisler, M., &quot;LIPKEY -A Low Infrastructure Public Key <lb/>Mechanism Using SPKM&quot;, RFC 2847, June 2000. <lb/>[36] <lb/>Eisler, M., &quot;NFS Version 2 and Version 3 Security Issues <lb/>and the NFS Protocol&apos;s Use of RPCSEC_GSS and Kerberos V5&quot;, <lb/>RFC 2623, June 1999. <lb/>[37] <lb/>Juszczak, C., &quot;Improving the Performance and Correctness <lb/>of an NFS Server&quot;, USENIX Conference Proceedings , June <lb/>1990. <lb/>[38] <lb/>Reynolds, J., Ed., &quot;Assigned Numbers: RFC 1700 is Replaced <lb/>by an On-line Database&quot;, RFC 3232, January 2002. <lb/>[39] <lb/>Srinivasan, R., &quot;Binding Protocols for ONC RPC Version 2&quot;, <lb/>RFC 1833, August 1995. <lb/>[40] <lb/>Werme, R., &quot;RPC XID Issues&quot;, USENIX Conference <lb/>Proceedings , February 1996. <lb/>[41] <lb/>Nowicki, B., &quot;NFS: Network File System Protocol <lb/>specification&quot;, RFC 1094, March 1989. <lb/>[42] <lb/>Bhide, A., Elnozahy, E., and S. Morgan, &quot;A Highly <lb/>Available Network Server&quot;, USENIX Conference Proceedings , <lb/>January 1991. <lb/>[43] <lb/>Halevy, B., Welch, B., and J. Zelenka, &quot;Object-Based <lb/>Parallel NFS (pNFS) Operations&quot;, RFC 5664, January 2010. <lb/></listBibl>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 644] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<listBibl>[44] <lb/>Black, D., Glasgow, J., and S. Fridella, &quot;Parallel NFS <lb/>(pNFS) Block/Volume Layout&quot;, RFC 5663, January 2010. <lb/>[45] <lb/>Callaghan, B., &quot;WebNFS Client Specification&quot;, RFC 2054, <lb/>October 1996. <lb/>[46] <lb/>Callaghan, B., &quot;WebNFS Server Specification&quot;, RFC 2055, <lb/>October 1996. <lb/>[47] <lb/>IESG, &quot;IESG Processing of RFC Errata for the IETF Stream&quot;, <lb/>July 2008. <lb/>[48] <lb/>Shepler, S., &quot;NFS Version 4 Design Considerations&quot;, <lb/>RFC 2624, June 1999. <lb/>[49] <lb/>The Open Group, &quot;Protocols for Interworking: XNFS, Version <lb/>3W, ISBN 1-85912-184-5&quot;, February 1998. <lb/>[50] <lb/>Floyd, S. and V. Jacobson, &quot;The Synchronization of <lb/>Periodic Routing Messages&quot;, IEEE/ACM Transactions on <lb/>Networking 2(2), pp. 122-136, April 1994. <lb/>[51] <lb/>Satran, J., Meth, K., Sapuntzakis, C., Chadalapaka, M., <lb/>and E. Zeidner, &quot;Internet Small Computer Systems Interface <lb/>(iSCSI)&quot;, RFC 3720, April 2004. <lb/>[52] <lb/>Snively, R., &quot;Fibre Channel Protocol for SCSI, 2nd Version <lb/>(FCP-2)&quot;, ANSI/INCITS 350-2003, Oct 2003. <lb/>[53] <lb/>Weber, R., &quot;Object-Based Storage Device Commands (OSD)&quot;, <lb/>ANSI/INCITS 400-2004, July 2004, <lb/>&lt;http://www.t10.org/ftp/t10/drafts/osd/osd-r10.pdf&gt;. <lb/>[54] <lb/>Carns, P., Ligon III, W., Ross, R., and R. Thakur, &quot;PVFS: <lb/>A Parallel File System for Linux Clusters.&quot;, Proceedings <lb/>of the 4th Annual Linux Showcase and Conference , 2000. <lb/>[55] <lb/>The Open Group, &quot;The Open Group Base Specifications Issue <lb/>6, IEEE Std 1003.1, 2004 Edition&quot;, 2004. <lb/>[56] <lb/>Callaghan, B., &quot;NFS URL Scheme&quot;, RFC 2224, October 1997. <lb/>[57] <lb/>Chiu, A., Eisler, M., and B. Callaghan, &quot;Security <lb/>Negotiation for WebNFS&quot;, RFC 2755, January 2000. <lb/>[58] <lb/>Narten, T. and H. Alvestrand, &quot;Guidelines for Writing an <lb/>IANA Considerations Section in RFCs&quot;, BCP 26, RFC 5226, <lb/>May 2008. <lb/></listBibl>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 645] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<listBibl>[59] <lb/>Krawczyk, H., Bellare, M., and R. Canetti, &quot;HMAC: Keyed-<lb/>Hashing for Message Authentication&quot;, RFC 2104, February <lb/>1997. <lb/>[60] <lb/>Shepler, S., Ed., Eisler, M., Ed., and D. Noveck, Ed., <lb/>&quot;Network File System (NFS) Version 4 Minor Version 1 <lb/>Protocol&quot;, RFC 5661, DOI 10.17487/RFC5661, January 2010, <lb/>&lt;https://www.rfc-editor.org/info/rfc5661&gt;. <lb/>[61] <lb/>Noveck, D., &quot;Rules for NFSv4 Extensions and Minor <lb/>Versions&quot;, RFC 8178, DOI 10.17487/RFC8178, July 2017, <lb/>&lt;https://www.rfc-editor.org/info/rfc8178&gt;. <lb/>[62] <lb/>Haynes, T., Ed. and D. Noveck, Ed., &quot;Network File System <lb/>(NFS) Version 4 Protocol&quot;, RFC 7530, DOI 10.17487/RFC7530, <lb/>March 2015, &lt;https://www.rfc-editor.org/info/rfc7530&gt;. <lb/>[63] <lb/>Noveck, D., Ed., Shivam, P., Lever, C., and B. Baker, <lb/>&quot;NFSv4.0 Migration: Specification Update&quot;, RFC 7931, <lb/>DOI 10.17487/RFC7931, July 2016, <lb/>&lt;https://www.rfc-editor.org/info/rfc7931&gt;. <lb/>[64] <lb/>Haynes, T., &quot;Requirements for Parallel NFS (pNFS) Layout <lb/>Types&quot;, RFC 8434, DOI 10.17487/RFC8434, August 2018, <lb/>&lt;https://www.rfc-editor.org/info/rfc8434&gt;. <lb/>[65] <lb/>Farrell, S. and H. Tschofenig, &quot;Pervasive Monitoring Is an <lb/>Attack&quot;, BCP 188, RFC 7258, DOI 10.17487/RFC7258, May <lb/>2014, &lt;https://www.rfc-editor.org/info/rfc7258&gt;. <lb/>[66] <lb/>Rescorla, E. and B. Korver, &quot;Guidelines for Writing RFC <lb/>Text on Security Considerations&quot;, BCP 72, RFC 3552, <lb/>DOI 10.17487/RFC3552, July 2003, <lb/>&lt;https://www.rfc-editor.org/info/rfc3552&gt;. <lb/></listBibl>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 646] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">Appendix A. Need for this Update <lb/>This document includes an explanation of how clients and servers are <lb/>to determine the particular network access paths to be used to access <lb/>a file system. This includes describing how changes to the specific <lb/>replica to be used or to the set of addresses to be used to access it <lb/>are to be dealt with, and how transfers of responsibility that need <lb/>to be made can be dealt with transparently. This includes cases in <lb/>which there is a shift between one replica and another and those in <lb/>which different network access paths are used to access the same <lb/>replica. <lb/>As a result of the following problems in RFC5661 [60], it is <lb/>necessary to provide the specific updates which are made by this <lb/>document. These updates are described in Appendix B <lb/>o RFC5661 [60], while it dealt with situations in which various <lb/>forms of clustering allowed co-ordination of the state assigned by <lb/>co-operating servers to be used, made no provisions for <lb/>Transparent State Migration. Within NFSv4.0, Transparent <lb/>Migration was first explained cearly in RFC7530 [62] and corrected <lb/>and clarified by RFC7931 [63]. No correesponding explanation for <lb/>NFSv4.1 had been provided. <lb/>o Although NFSv4.1 was defined with a clear definition of how <lb/>trunking detection was to be done, there was no clear <lb/>specification of how trunking discovery was to be done, despite <lb/>the fact that the specification clearly indicated that this <lb/>information could be made available via the file system location <lb/>attributes. <lb/>o Because the existence of multiple network access paths to the same <lb/>file system was dealt with as if there were multiple replicas, <lb/>issues relating to transitions between replicas could never be <lb/>clearly distinguished from trunking-related transitions between <lb/>the addresses used to access a particular file system instance. <lb/>As a result, in situations in which both migration and trunking <lb/>configuration changes were involved, neither of these could be <lb/>clearly dealt with and the relationship between these two features <lb/>was not seriously addressed. <lb/>o Because use of two network access paths to the same file system <lb/>instance (i.e. trunking) was often treated as if two replicas were <lb/>involved, it was considered that two replicas were being used <lb/>simultaneously. As a result, the treatment of replicas being used <lb/>simultaneously in RFC5661 [60] was not clear as it covered the two <lb/>distinct cases of a single file system instance being accessed by <lb/>two different network access paths and two replicas being accessed <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 647] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">simultaneously, with the limitations of the latter case not being <lb/>clearly laid out. <lb/>The majority of the consequences of these issues are dealt with by <lb/>presenting in Section 11 a replacement for Section 11 within RFC5661 <lb/>[60]. This replacement modifies existing sub-sections within that <lb/>section and adds new ones, as described in Appendix B.1. Also, some <lb/>existing sections are deleted. These changes were made in order to: <lb/>o Reorganize the description so that the case of two network access <lb/>paths to the same file system instance needs to be distinguished <lb/>clearly from the case of two different replicas since, in the <lb/>former case, locking state is shared and there also can be sharing <lb/>of session state. <lb/>o Provide a clear statement regarding the desirability of <lb/>transparent transfer of state between replicas together with a <lb/>recommendation that either that or a single-fs grace period be <lb/>provided. <lb/>o Specifically delineate how such transfers are to be dealt with by <lb/>the client, taking into account the differences from the treatment <lb/>in [63] made necessary by the major protocol changes made in <lb/>NFSv4.1. <lb/>o Provide discussion of the relationship between transparent state <lb/>transfer and Parallel NFS (pNFS). <lb/>o Provide clarification of the fs_locations_info attribute in order <lb/>to specify which portions of the information provided apply to a <lb/>specific network access path and which to the replica which that <lb/>path is used to access. <lb/>In addition, there are also updates to other sections of RFC5661 <lb/>[60], where the consequences of the incorrect assumptions underlying <lb/>the current treatment of multi-server namespace issues also needed to <lb/>be corrected. These are to be dealt with as described in Sections <lb/>B.2 through B.4. <lb/>o A revised introductory section regarding multi-server namespace <lb/>facilities is provided. <lb/>o A more realistic treatment of server scope is provided, which <lb/>reflects the more limited co-ordination of locking state adopted <lb/>by servers actually sharing a common server scope. <lb/>o Some confusing text regarding changes in server_owner has been <lb/>clarified. <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 648] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">o The description of some existing errors has been modified to more <lb/>clearly explain certain errors situations to reflect the existence <lb/>of trunking and the possible use of fs-specific grace periods. <lb/>For details, see Appendix B.3. <lb/>o New descriptions of certain existing operations are provided, <lb/>either because the existing treatment did not account for <lb/>situations that would arise in dealing with transparent state <lb/>migration, or because some types of reclaim issues were not <lb/>adequately dealt with in the context of fs-specific grace periods. <lb/>For details, see Appendix B.3. <lb/></div>


			<div type="annex">Appendix B. Changes in this Update <lb/>B.1. Revisions Made to Section 11 of [RFC5661] <lb/>A number of areas needed to be revised or extended, in many case <lb/>replacing existing sub-sections within section 11 of RFC5661 [60]: <lb/>o New introductory material, including a terminology section, <lb/>replaces the existing material in RFC5661 [60] ranging from the <lb/>start of the existing Section 11 up to and including the existing <lb/>Section 11.1. The new material starts at the beginning of <lb/>Section 11 and continues through 11.2 below. <lb/>o A significant reorganization of the material in the existing <lb/>Sections 11.4 and 11.5 (of RFC5661 [60]) is necessary. The <lb/>reasons for the reorganization of these sections into a single <lb/>section with multiple subsections are discussed in Appendix B.1.1 <lb/>below. This replacement appears as Section 11.5 below. <lb/>New material relating to the handling of the file system location <lb/>attributes is contained in Sections 11.5.1 and 11.5.7 below. <lb/>o A new section describing requirements for user and group handling <lb/>within a multi-server namespace has been added as Section 11.6 <lb/>o A major replacement for the existing Section 11.7 of RFC5661 [60] <lb/>entitled &quot;Effecting File System Transitions&quot;, will appear as <lb/>Sections 11.8 through 11.13. The reasons for the reorganization <lb/>of this section into multiple sections are discussed in <lb/>Appendix B.1.2. <lb/>o A replacement for the existing Section 11.10 of RFC5661 [60] <lb/>entitled &quot;The Attribute fs_locations_info&quot;, will appear as <lb/>Section 11.16, with Appendix B.1.3 describing the differences <lb/>between the new section and the treatment within [60]. A revised <lb/>treatment is necessary because the existing treatment did not make <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 649] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">clear how the added attribute information relates to the case of <lb/>trunked paths to the same replica. These issues were not <lb/>addressed in RFC5661 [60] where the concepts of a replica and a <lb/>network path used to access a replica were not clearly <lb/>distinguished. <lb/>B.1.1. Re-organization of Sections 11.4 and 11.5 of [RFC5661] <lb/>Previously, issues related to the fact that multiple location entries <lb/>directed the client to the same file system instance were dealt with <lb/>in a separate Section 11.5 of RFC5661 [60]. Because of the new <lb/>treatment of trunking, these issues now belong within Section 11.5 <lb/>below. <lb/>In this new section, trunking is dealt with in Section 11.5.2 <lb/>together with the other uses of file system location information <lb/>described in Sections Section 11.5.3 through 11.5.6. <lb/>As a result, Section 11.5 which will replace Section 11.4 of RFC5661 <lb/>[60] is substantially different than the section it replaces in that <lb/>some existing sections will be replaced by corresponding sections <lb/>below while, at the same time, new sections will be added, resulting <lb/>in a replacement containing some renumbered sections, as follows: <lb/>o The material in Section 11.5, exclusive of subsections, replaces <lb/>the material in Section 11.4 of RFC5661 [60] exclusive of <lb/>subsections. <lb/>o Section 11.5.1 is a new first subsection of the overall section. <lb/>o Section 11.5.2 is a new second subsection of the overall section. <lb/>o Each of the Sections 11.5.4, 11.5.5, and 11.5.6 replaces (in <lb/>order) one of the corresponding Sections 11.4.1, 11.4.2, and <lb/>11.4.3 of RFC5661 [60]. 11.4.4, and 11.4.5. <lb/>o Section 11.5.7 is a new final subsection of the overall section. <lb/>B.1.2. Re-organization of Material Dealing with File System Transitions <lb/>The material relating to file system transition, previously contained <lb/>in Section 11.7 of RFC5661 [60] has been reorganized and augmented as <lb/>described below: <lb/>o Because there can be a shift of the network access paths used to <lb/>access a file system instance without any shift between replicas, <lb/>a new Section 11.8 distinguishes between those cases in which <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 650] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">there is a shift between distinct replicas and those involving a <lb/>shift in network access paths with no shift between replicas. <lb/>As a result, a new Section 11.9 deals with network address <lb/>transitions while the bulk of the former Section 11.7 (in RFC5661 <lb/>[60]) is extensively modified as reflected in Section 11.10 which <lb/>is now limited to cases in which there is a shift between two <lb/>different sets of replicas. <lb/>o The additional Section 11.11 discusses the case in which a shift <lb/>to a different replica is made and state is transferred to allow <lb/>the client the ability to have continued access to its accumulated <lb/>locking state on the new server. <lb/>o The additional Section 11.12 discusses the client&apos;s response to <lb/>access transitions and how it determines whether migration has <lb/>occurred, and how it gets access to any transferred locking and <lb/>session state. <lb/>o The additional Section 11.13 discusses the responsibilities of the <lb/>source and destination servers when transferring locking and <lb/>session state. <lb/>This re-organization has caused a renumbering of the sections within <lb/>Section 11 of [60] as described below: <lb/>o The new Sections 11.8 and 11.9 have resulted in existing sections <lb/>wit these numbers to be renumbered. <lb/>o Section 11.7 of [60] will be substantially modified and appear as <lb/>Section 11.10. The necessary modifications reflect the fact that <lb/>this section will only deal with transitions between replicas <lb/>while transitions between network addresses are dealt with in <lb/>other sections. Details of the reorganization are described later <lb/>in this section. <lb/>o The additional Sections 11.11, 11.12, and 11.13 have been added. <lb/>o Consequently, Sections 11.8, 11.9, 11.10, and 11.11 in [60] now <lb/>appear as Sections 11.13, 11.14, 11.15, and 11.16, respectively. <lb/>As part of this general re-organization, Section 11.7 of RFC5661 [60] <lb/>will be modified as described below: <lb/>o Sections 11.7 and 11.7.1 of RFC5661 [60] are to be replaced by <lb/>Sections 11.10 and 11.10.1, respectively. <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 651] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">o Section 11.7.2 (and included subsections) of RFC5661 [60] are to <lb/>be deleted. <lb/>o Sections 11.7.3, 11.7.4. 11.7.5, 11.7.5.1, and 11.7.6 of RFC5661 <lb/>[60] are to be replaced by Sections 11.10.2, 11.10.3, 11.10.4, <lb/>11.10.4.1, and 11.10.5 respectively in this document. <lb/>o Section 11.7.7 of RFC5661 [60] is to be replaced by <lb/>Section 11.10.9 This sub-section has been moved to the end of the <lb/>section dealing with file system transitions. <lb/>o Sections 11.7.8, 11.7.9. and 11.7.10 of RFC5661 [60] are to be <lb/>replaced by Sections 11.10.6, 11.10.7, and 11.10.8 respectively in <lb/>this document. <lb/>B.1.3. Updates to treatment of fs_locations_info <lb/>Various elements of the fs_locations_info attribute contain <lb/>information that applies to either a specific file system replica or <lb/>to a network path or set of network paths used to access such a <lb/>replica. The existing treatment of fs_locations info (in <lb/>Section 11.10 of RFC5661 [60]) does not clearly distinguish these <lb/>cases, in part because the document did not clearly distinguish <lb/>replicas from the paths used to access them. <lb/>In addition, special clarification needed to be provided with regard <lb/>to the following fields: <lb/>o With regard to the handling of FSLI4GF_GOING, it needs to be made <lb/>clear that this only applies to the unavailability of a replica <lb/>rather than to a path to access a replica. <lb/>o In describing the appropriate value for a server to use for <lb/>fli_valid_for, it needs to be made clear that there is no need for <lb/>the client to frequently fetch the fs_locations_info value to be <lb/>prepared for shifts in trunking patterns. <lb/>o Clarification of the rules for extensions to the fls_info needs to <lb/>be provided. The existing treatment reflects the extension model <lb/>in effect at the time RFC5661 [60] was written, and needed to be <lb/>updated in accordance with the extension model described in <lb/>RFC8178 [61]. <lb/>B.2. Revisions Made to Operations in [RFC5661] <lb/>Revised descriptions were needed to address issues that arose in <lb/>effecting necessary changes to multi-server namespace features. <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 652] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">o The existing treatment of EXCHANGE_ID (in Section 18.35 of RFC5661 <lb/>[60]) assumes that client IDs cannot be created/ confirmed other <lb/>than by the EXCHANGE_ID and CREATE_SESSION operations. Also, the <lb/>necessary use of EXCHANGE_ID in recovery from migration and <lb/>related situations is not addressed clearly. A revised treatment <lb/>of EXCHANGE_ID is necessary and it appears in Section 18.35 while <lb/>the specific differences between it and the treatment within [60] <lb/>are explained in Appendix B.2.1 below. <lb/>o The existing treatment of RECLAIM_COMPLETE in section 18.51 of <lb/>RFC5661 [60]) is not sufficiently clear about the purpose and use <lb/>of the rca_one_fs and how the server is to deal with inappropriate <lb/>values of this argument. Because the resulting confusion raises <lb/>interoperability issues, a new treatment of RECLAIM_COMPLETE is <lb/>necessary and it appears in Section 18.51 below while the specific <lb/>differences between it and the treatment within RFC5661 [60] are <lb/>discussed in Appendix B.2.2 below. In addition, the definitions <lb/>of the reclaim-related errors receive an updated treatment in <lb/>Section 15.1.9 to reflect the fact that there are multiple <lb/>contexts for lock reclaim operations. <lb/>B.2.1. Revision to Treatment of EXCHANGE_ID <lb/>There are a number of issues in the original treatment of EXCHANGE_ID <lb/>(in RFC5661 [60]) that cause problems for Transparent State Migration <lb/>and for the transfer of access between different network access paths <lb/>to the same file system instance. <lb/>These issues arise from the fact that this treatment was written, <lb/>o Assuming that a client ID can only become known to a server by <lb/>having been created by executing an EXCHANGE_ID, with confirmation <lb/>of the ID only possible by execution of a CREATE_SESSION. <lb/>o Considering the interactions between a client and a server only <lb/>occurring on a single network address <lb/>As these assumptions have become invalid in the context of <lb/>Transparent State Migration and active use of trunking, the treatment <lb/>has been modified in several respects. <lb/>o It had been assumed that an EXCHANGED_ID executed when the server <lb/>is already aware of a given client instance must be either <lb/>updating associated parameters (e.g. with respect to callbacks) or <lb/>a lingering retransmission to deal with a previously lost reply. <lb/>As result, any slot sequence returned by that operation would be <lb/>of no use. The existing treatment goes so far as to say that it <lb/>&quot;MUST NOT&quot; be used, although this usage is not in accord with [1]. <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 653] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">This created a difficulty when an EXCHANGE_ID is done after <lb/>Transparent State Migration since that slot sequence would need to <lb/>be used in a subsequent CREATE_SESSION. <lb/>In the updated treatment, CREATE_SESSION is a way that client IDs <lb/>are confirmed but it is understood that other ways are possible. <lb/>The slot sequence can be used as needed and cases in which it <lb/>would be of no use are appropriately noted. <lb/>o It was assumed that the only functions of EXCHANGE_ID were to <lb/>inform the server of the client, create the client ID, and <lb/>communicate it to the client. When multiple simultaneous <lb/>connections are involved, as often happens when trunking, that <lb/>treatment was inadequate in that it ignored the role of <lb/>EXCHANGE_ID in associating the client ID with the connection on <lb/>which it was done, so that it could be used by a subsequent <lb/>CREATE_SESSSION, whose parameters do not include an explicit <lb/>client ID. <lb/>The new treatment explicitly discusses the role of EXCHANGE_ID in <lb/>associating the client ID with the connection so it can be used by <lb/>CREATE_SESSION and in associating a connection with an existing <lb/>session. <lb/>The new treatment can be found in Section 18.35 below. It is <lb/>intended to supersede the treatment in Section 18.35 of RFC5661 [60]. <lb/>Publishing a complete replacement for Section 18.35 allows the <lb/>corrected definition to be read as a whole, in place of the one in <lb/>RFC5661 [60]. <lb/>B.2.2. Revision to Treatment of RECLAIM_COMPLETE <lb/>The following changes were made to the treatment of RECLAIM_COMPLETE <lb/>in RFC5661 [60] to arrive at the treatment in Section 18.51. <lb/>o In a number of places the text is made more explicit about the <lb/>purpose of rca_one_fs and its connection to file system migration. <lb/>o There is a discussion of situations in which particular forms of <lb/>RECLAIM_COMPLETE would need to be done. <lb/>o There is a discussion of interoperability issues that result from <lb/>implementations that may have arisen due to the lack of clarity of <lb/>the previous treatment of RECLAIM_COMPLETE. <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 654] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">B.3. Revisions Made to Error Definitions in [RFC5661] <lb/>The new handling of various situations required revisions of some <lb/>existing error definition: <lb/>o Because of the need to appropriately address trunking-related <lb/>issues, some uses of the term &quot;replica&quot; in RFC5661 [60] have <lb/>become problematic since a shift in network access paths was <lb/>considered to be a shift to a different replica. As a result, the <lb/>existing definition of NFS4ERR_MOVED (in Section 15.1.2.4 of <lb/>RFC5661 [60]) needs to be updated to reflect the different <lb/>handling of unavailability of a particular fs via a specific <lb/>network address. <lb/>Since such a situation is no longer considered to constitute <lb/>unavailability of a file system instance, the description needs to <lb/>change even though the set of circumstances in which it is to be <lb/>returned remain the same. The new paragraph explicitly recognizes <lb/>that a different network address might be used, while the previous <lb/>description, misleadingly, treated this as a shift between two <lb/>replicas while only a single file system instance might be <lb/>involved. The updated description appears in Section 15.1.2.4 <lb/>below. <lb/>o Because of the need to accommodate use of fs-specific grace <lb/>periods, it is necessary to clarify some of the error definitions <lb/>of reclaim-related errors in Section 15 of RFC5661 [60], so the <lb/>text applies properly to reclaims for all types of grace periods. <lb/>The updated descriptions appear within Section 15.1.9 below. <lb/>B.4. Other Revisions Made to [RFC5661] <lb/>Beside the major reworking of Section 11 and the associated revisions <lb/>to existing operations and errors, there are a number of related <lb/>changes that are necessary: <lb/>o The summary that appeared in Section 1.7.3.3 of RFC5661 [60] was <lb/>revised to reflect the changes made in the revised Section 11 <lb/>above. The updated summary appears as Section 1.8.3.3 above. <lb/>o The discussion of server scope which appeared in Section 2.10.4 of <lb/>RFC5661 [60] needed to be replaced, since the previous text <lb/>appears to require a level of inter-server co-ordination <lb/>incompatible with its basic function of avoiding the need for a <lb/>globally uniform means of assigning server_owner values. A <lb/>revised treatment appears in Section 2.10.4. <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 655] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">o The discussion of trunking which appeared in Section 2.10.5 of <lb/>RFC5661 [60] needed to be revised, to more clearly explain the <lb/>multiple types of trunking supporting and how the client can be <lb/>made aware of the existing trunking configuration. In addition <lb/>the last paragraph (exclusive of sub-sections) of that section, <lb/>dealing with server_owner changes, is literally true, it has been <lb/>a source of confusion. Since the existing paragraph can be read <lb/>as suggesting that such changes be dealt with non-disruptively, <lb/>the issue needs to be clarified in the revised section, which <lb/>appears in Section 2.10.5 <lb/></div>

			<div type="annex">Appendix C. Security Issues that Need to be Addressed <lb/>The following issues in the treatment of security within the NFSv4.1 <lb/>specification need to be addressed: <lb/>o The Security Considerations Section of RFC5661 [60] is not written <lb/>in accord with RFC3552 [66] (also BCP72). Of particular concern <lb/>is the fact that the section does not contain a threat analysis. <lb/>o Initial analysis of the existing security issues with NFSv4.1 has <lb/>made it likely that a revised Security Considerations Section for <lb/>the existing protocol (one containing a threat analysis) would be <lb/>likely to conclude that NFSv4.1 does not meet the goal of secure <lb/>use on the internet. <lb/>The Security Considerations Section of this document (in Section 21) <lb/>has not been thoroughly revised to correct the difficulties mentioned <lb/>above. Instead, it has been modified to take proper account of <lb/>issues related to the multi-server namespace features discussed in <lb/>Section 11, leaving the incomplete discussion and security weaknesses <lb/>pretty much as they were. <lb/>The following major security issues need to be addressed in a <lb/>satisfactory fashion before an updated Security Considerations <lb/>section can be published as part of a bis document for NFSv4.1: <lb/>o The continued use of AUTH_SYS and the security exposures it <lb/>creates needs to be addressed. Addressing this issue must not be <lb/>limited to the questions of whether the designation of this as <lb/>OPTIONAL was justified and whether it should be changed. <lb/>In any event, it may not be possible, at this point, to correct <lb/>the security problems created by continued use of AUTH_SYS simply <lb/>by revising this designation. <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 656] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">o The lack of attention within the protocol to the possibility of <lb/>pervasive monitoring attacks such as those described in RFC7258 <lb/>[65] (also BCP188). <lb/>In that connection, the use of CREATE_SESSION without privacy <lb/>protection needs to be addressed as it exposes the session ID to <lb/>view by an attacker. This is worrisome as this is precisely the <lb/>type of protocol artifact alluded to in RFC7258, which can enable <lb/>further mischief on the part of the attacker as it enables denial-<lb/>of-service attacks which can be executed effectively with only a <lb/>single, normally low-value, credential, even when RPCSEC_GSS <lb/>authentication is in use. <lb/>o The lack of effective use of privacy and integrity, even where the <lb/>infrastructure to support use of RPCSEC_GSS in present, needs to <lb/>be addressed. <lb/>In light of the security exposures that this situation creates, it <lb/>is not enough to define a protocol that could, with the provision <lb/>of sufficient resources, address the problem. Instead, what is <lb/>needed is a way to provide the necessary security, with very <lb/>limited performance costs and without requiring security <lb/>infrastructure that experience has shown is difficult for many <lb/>clients and servers to provide. <lb/>In trying to provide a major security upgrade for a deployed protocol <lb/>such as NFSv4.1, the working group, and the internet community is <lb/>likely to find itself dealing with a number of considerations such as <lb/>the following: <lb/>o The need to accommodate existing deployments of existing protocols <lb/>as specified previously in existing Proposed Standards. <lb/>o The difficulty of effecting changes to existing interoperating <lb/>implementations. <lb/>o The difficulty of making changes to NFSv4 protocols other than <lb/>those in the form of OPTIONAL extensions. <lb/>o The tendency of those responsible for existing NFSv4 deployments <lb/>to ignore security flaws in the context of local area networks <lb/>under the mistaken impression that network isolation provides, in <lb/>and of itself, isolation from all potential attackers. <lb/>Given that the difficulties mentioned above apply to minor version <lb/>zero as well, it may make sense to deal with these security issues in <lb/>a common document applying to all NFSv4 minor versions. If that <lb/>approach is taken the, Security Considertions section of an eventual <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 657] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">NFv4.1 bis document would reference that common document and the <lb/>defining RFCs for other minor versions might do so as well. <lb/></div>

			<div type="acknowledgement">Appendix D. Acknowledgments <lb/>D.1. Acknowledgments for this Update <lb/>The authors wish to acknowledge the important role of Andy Adamson of <lb/>Netapp in clarifying the need for trunking discovery functionality, <lb/>and exploring the role of the file system location attributes in <lb/>providing the necessary support. <lb/>The authors wish to thank Tom Haynes of Hammerspace for drawing our <lb/>attention to the fact that internationalization and security might <lb/>best be handled in documents dealing with such protocol issues as <lb/>they apply to all NFSv4 minor versions. <lb/>The authors also wish to acknowledge the work of Xuan Qi of Oracle <lb/>with NFSv4.1 client and server prototypes of transparent state <lb/>migration functionality. <lb/>The authors wish to thank others that brought attention to important <lb/>issues. The comments of Trond Myklebust of Primary Data related to <lb/>trunking helped to clarify the role of DNS in trunking discovery. <lb/>Rick Macklem&apos;s comments brought attention to problems in the handling <lb/>of the per-fs version of RECLAIM_COMPLETE. <lb/>The authors wish to thank Olga Kornievskaia of Netapp for her helpful <lb/>review comments. <lb/>D.2. Acknowledgments for RFC5661 <lb/>The initial text for the SECINFO extensions were edited by Mike <lb/>Eisler with contributions from Peng Dai, Sergey Klyushin, and Carl <lb/>Burnett. <lb/>The initial text for the SESSIONS extensions were edited by Tom <lb/>Talpey, Spencer Shepler, Jon Bauman with contributions from Charles <lb/>Antonelli, Brent Callaghan, Mike Eisler, John Howard, Chet Juszczak, <lb/>Trond Myklebust, Dave Noveck, John Scott, Mike Stolarchuk, and Mark <lb/>Wittle. <lb/>Initial text relating to multi-server namespace features, including <lb/>the concept of referrals, were contributed by Dave Noveck, Carl <lb/>Burnett, and Charles Fan with contributions from Ted Anderson, Neil <lb/>Brown, and Jon Haswell. <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 658] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">The initial text for the Directory Delegations support were <lb/>contributed by Saadia Khan with input from Dave Noveck, Mike Eisler, <lb/>Carl Burnett, Ted Anderson, and Tom Talpey. <lb/>The initial text for the ACL explanations were contributed by Sam <lb/>Falkner and Lisa Week. <lb/>The pNFS work was inspired by the NASD and OSD work done by Garth <lb/>Gibson. Gary Grider has also been a champion of high-performance <lb/>parallel I/O. Garth Gibson and Peter Corbett started the pNFS effort <lb/>with a problem statement document for the IETF that formed the basis <lb/>for the pNFS work in NFSv4.1. <lb/>The initial text for the parallel NFS support was edited by Brent <lb/>Welch and Garth Goodson. Additional authors for those documents were <lb/>Benny Halevy, David Black, and Andy Adamson. Additional input came <lb/>from the informal group that contributed to the construction of the <lb/>initial pNFS drafts; specific acknowledgment goes to Gary Grider, <lb/>Peter Corbett, Dave Noveck, Peter Honeyman, and Stephen Fridella. <lb/>Fredric Isaman found several errors in draft versions of the ONC RPC <lb/>XDR description of the NFSv4.1 protocol. <lb/>Audrey Van Belleghem provided, in numerous ways, essential co-<lb/>ordination and management of the process of editing the specification <lb/>documents. <lb/>Richard Jernigan gave feedback on the file layout&apos;s striping pattern <lb/>design. <lb/>Several formal inspection teams were formed to review various areas <lb/>of the protocol. All the inspections found significant errors and <lb/> room for improvement. NFSv4.1&apos;s inspection teams were: <lb/>o ACLs, with the following inspectors: Sam Falkner, Bruce Fields, <lb/>Rahul Iyer, Saadia Khan, Dave Noveck, Lisa Week, Mario Wurzl, and <lb/>Alan Yoder. <lb/>o Sessions, with the following inspectors: William Brown, Tom <lb/>Doeppner, Robert Gordon, Benny Halevy, Fredric Isaman, Rick <lb/>Macklem, Trond Myklebust, Dave Noveck, Karen Rochford, John Scott, <lb/>and Peter Shah. <lb/>o Initial pNFS inspection, with the following inspectors: Andy <lb/>Adamson, David Black, Mike Eisler, Marc Eshel, Sam Falkner, Garth <lb/>Goodson, Benny Halevy, Rahul Iyer, Trond Myklebust, Spencer <lb/>Shepler, and Lisa Week. <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 659] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			<div type="annex">o Global namespace, with the following inspectors: Mike Eisler, Dan <lb/>Ellard, Craig Everhart, Fredric Isaman, Trond Myklebust, Dave <lb/>Noveck, Theresa Raj, Spencer Shepler, Renu Tewari, and Robert <lb/>Thurlow. <lb/>o NFSv4.1 file layout type, with the following inspectors: Andy <lb/>Adamson, Marc Eshel, Sam Falkner, Garth Goodson, Rahul Iyer, Trond <lb/>Myklebust, and Lisa Week. <lb/>o NFSv4.1 locking and directory delegations, with the following <lb/>inspectors: Mike Eisler, Pranoop Erasani, Robert Gordon, Saadia <lb/>Khan, Eric Kustarz, Dave Noveck, Spencer Shepler, and Amy Weaver. <lb/>o EXCHANGE_ID and DESTROY_CLIENTID, with the following inspectors: <lb/>Mike Eisler, Pranoop Erasani, Robert Gordon, Benny Halevy, Fredric <lb/>Isaman, Saadia Khan, Ricardo Labiaga, Rick Macklem, Trond <lb/>Myklebust, Spencer Shepler, and Brent Welch. <lb/>o Final pNFS inspection, with the following inspectors: Andy <lb/>Adamson, Mike Eisler, Mark Eshel, Sam Falkner, Jason Glasgow, <lb/>Garth Goodson, Robert Gordon, Benny Halevy, Dean Hildebrand, Rahul <lb/>Iyer, Suchit Kaura, Trond Myklebust, Anatoly Pinchuk, Spencer <lb/>Shepler, Renu Tewari, Lisa Week, and Brent Welch. <lb/>A review team worked together to generate the tables of assignments <lb/>of error sets to operations and make sure that each such assignment <lb/>had two or more people validating it. Participating in the process <lb/>were Andy Adamson, Mike Eisler, Sam Falkner, Garth Goodson, Robert <lb/>Gordon, Trond Myklebust, Dave Noveck, Spencer Shepler, Tom Talpey, <lb/>Amy Weaver, and Lisa Week. <lb/>Jari Arkko, David Black, Scott Bradner, Lisa Dusseault, Lars Eggert, <lb/>Chris Newman, and Tim Polk provided valuable review and guidance. <lb/>Olga Kornievskaia found several errors in the SSV specification. <lb/>Ricardo Labiaga found several places where the use of RPCSEC_GSS was <lb/>underspecified. <lb/>Those who provided miscellaneous comments include: Andy Adamson, <lb/>Sunil Bhargo, Alex Burlyga, Pranoop Erasani, Bruce Fields, Vadim <lb/>Finkelstein, Jason Goldschmidt, Vijay K. Gurbani, Sergey Klyushin, <lb/>Ricardo Labiaga, James Lentini, Anshul Madan, Daniel Muntz, Daniel <lb/>Picken, Archana Ramani, Jim Rees, Mahesh Siddheshwar, Tom Talpey, and <lb/>Peter Varga. <lb/></div>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 660] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>NFSv4.1 with Namespace Update <lb/>August 2019 <lb/></note>

			Author&apos;s Address <lb/>

			<front>David Noveck (editor) <lb/>NetApp <lb/>1601 Trapelo Road, Suite 16 <lb/>Waltham, MA 02451 <lb/>USA <lb/>Phone: +1-781-768-5347 <lb/>EMail: dnoveck@netapp.com <lb/>Charles Lever <lb/>Oracle Corporation <lb/>1015 Granger Avenue <lb/>Ann Arbor, MI 48104 <lb/>United States of America <lb/>Phone: +1 248 614 5091 <lb/>EMail: chuck.lever@oracle.com <lb/></front>

			<note place="footnote">Noveck &amp; Lever <lb/>Expires February 5, 2020 <lb/></note>

			<page>[Page 661] </page>


	</text>
</tei>
