<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>server date 20190708; downloaded by EPO on 20190710 <lb/>Network Working Group <lb/>I. Learmonth <lb/>Internet-Draft <lb/>Tor Project <lb/>Intended status: Informational <lb/>July 8, 2019 <lb/>Expires: January 9, 2020 <lb/>Guidelines for Performing Safe Measurement on the Internet <lb/>draft-irtf-pearg-safe-internet-measurement-01 <lb/>Abstract <lb/>Researchers from industry and academia often use Internet <lb/>measurements as part of their work. While these measurements can <lb/>give insight into the functioning and usage of the Internet, they can <lb/>come at the cost of user privacy. This document describes guidelines <lb/>for ensuring that such measurements can be carried out safely. <lb/>Note <lb/>Comments are solicited and should be addressed to the research <lb/>group&apos;s mailing list at pearg@irtf.org and/or the author(s). <lb/>The sources for this draft are at: <lb/>https://github.com/irl/draft-safe-internet-measurement <lb/>Status of This Memo <lb/>This Internet-Draft is submitted in full conformance with the <lb/>provisions of BCP 78 and BCP 79. <lb/>Internet-Drafts are working documents of the Internet Engineering <lb/>Task Force (IETF). Note that other groups may also distribute <lb/>working documents as Internet-Drafts. The list of current Internet-<lb/>Drafts is at https://datatracker.ietf.org/drafts/current/. <lb/>Internet-Drafts are draft documents valid for a maximum of six months <lb/>and may be updated, replaced, or obsoleted by other documents at any <lb/>time. It is inappropriate to use Internet-Drafts as reference <lb/>material or to cite them other than as &quot;work in progress.&quot; <lb/>This Internet-Draft will expire on January 9, 2020. <lb/>Copyright Notice <lb/>Copyright (c) 2019 IETF Trust and the persons identified as the <lb/>document authors. All rights reserved. <lb/>Learmonth <lb/>Expires January 9, 2020 <lb/>[Page 1] <lb/>Internet-Draft <lb/>Safe Internet Measurement <lb/>July 2019 <lb/>This document is subject to BCP 78 and the IETF Trust&apos;s Legal <lb/>Provisions Relating to IETF Documents <lb/>(https://trustee.ietf.org/license-info) in effect on the date of <lb/>publication of this document. Please review these documents <lb/>carefully, as they describe your rights and restrictions with respect <lb/>to this document. <lb/></front>

			<body>1. Introduction <lb/>Performing research using the Internet, as opposed to an isolated <lb/>testbed or simulation platform, means that experiments co-exist in a <lb/>space with other users. This document outlines guidelines for <lb/>academic and industry researchers that might use the Internet as part <lb/>of scientific experimentation to mitigate risks to the safety of <lb/>other users. <lb/>1.1. Scope of this document <lb/>Following the guidelines contained within this document is not a <lb/>substitute for any institutional ethics review process, although <lb/>these guidelines could help to inform that process. Similarly, these <lb/>guidelines are not legal advice and local laws must also be <lb/>considered before starting any experiment that could have adverse <lb/>impacts on user safety. <lb/>1.2. Active and passive measurements <lb/>Internet measurement studies can be broadly categorized into two <lb/>groups: active measurements and passive measurements. Active <lb/>measurements generate traffic. Performance measurements such as TCP <lb/>throughput testing [RFC6349] or functional measurements such as the <lb/>feature-dependent connectivity failure tests performed by <lb/>[PATHspider] both fall into this category. Performing passive <lb/>measurements requires existing traffic. <lb/>Both active and passive measurements carry risk. A poorly considered <lb/>active measurement could result in an inadvertent denial-of-service <lb/>attack, while passive measurements could result in serious violations <lb/>of user privacy. <lb/>The type of measurement is not truly binary and many studies will <lb/>include both active and passive components. Each of the <lb/>considerations in this document must be carefully considered for <lb/>their applicability regardless of the type of measurement. <lb/></body>

			<note place="footnote">Learmonth <lb/>Expires January 9, 2020 <lb/></note>

			<page>[Page 2] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>Safe Internet Measurement <lb/>July 2019 <lb/></note>

			<body>2. Consent <lb/>In an ideal world, informed consent would be collected from all users <lb/>that may be placed at risk, no matter how small a risk, by an <lb/>experiment. In cases where it is practical to do so, this should be <lb/>done. <lb/>2.1. Informed Consent <lb/>For consent to be informed, all possible risks must be presented to <lb/>the users. The considerations in this document can be used to <lb/>provide a starting point although other risks may be present <lb/>depending on the nature of the measurements to be performed. <lb/>2.2. Informed Consent: Case Study <lb/>A researcher would like to use volunteer owned mobile devices to <lb/>collect information about local Internet censorship. Connections <lb/>will be made from the volunteer&apos;s device towards known or suspected <lb/>blocked webpages. <lb/>This experiment can carry substantial risk for the user depending on <lb/>the circumstances, from disciplinary action from their employer to <lb/>arrest or imprisonment. Fully informed consent ensures that any risk <lb/>that is being taken has been carefully considered by the volunteer <lb/>before proceeding. <lb/>2.3. Proxy Consent <lb/>In cases where it is not practical to collect informed consent from <lb/>all users of a shared network, it may be possible to obtain proxy <lb/>consent. Proxy consent may be given by a network operator or <lb/>employer that would be more familiar with the expectations of users <lb/>of a network than the researcher. <lb/>In some cases, a network operator or employer may have terms of <lb/>service that specifically allow for giving consent to 3rd parties to <lb/>perform certain experiments. <lb/>2.4. Proxy Consent: Case Study <lb/>A researcher would like to perform a packet capture to determine the <lb/>TCP options and their values used by all client devices on an <lb/>corporate wireless network. <lb/>The employer may already have terms of service laid out that allow <lb/>them to provide proxy consent for this experiment on behalf of the <lb/>employees (the users of the network). The purpose of the experiment <lb/></body>

			<note place="footnote">Learmonth <lb/>Expires January 9, 2020 <lb/></note>

			<page>[Page 3] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>Safe Internet Measurement <lb/>July 2019 <lb/></note>

			<body>may affect whether or not they are able to provide this consent. For <lb/>example, to perform engineering work on the network then it may be <lb/>allowed, whereas academic research may not be covered. <lb/>2.5. Implied Consent <lb/>In larger scale measurements, even proxy consent collection may not <lb/>be practical. In this case, implied consent may be presumed from <lb/>users for some measurements. Consider that users of a network will <lb/>have certain expectations of privacy and those expectations may not <lb/>align with the privacy guarantees offered by the technologies they <lb/>are using. As a thought experiment, consider how users might respond <lb/>if asked for their informed consent for the measurements you&apos;d like <lb/>to perform. <lb/>Implied consent should not be considered sufficient for any <lb/>experiment that may collect sensitive or personally identifying <lb/>information. If practical, attempt to obtain informed consent or <lb/>proxy consent from a sample of users to better understand the <lb/>expectations of other users. <lb/>2.6. Implied Consent: Case Study 1 <lb/>A researcher would like to run a measurement campaign to determine <lb/>the maximum supported TLS version on popular web servers. <lb/>The operator of a web server that is exposed to the Internet hosting <lb/>a popular website would have the expectation that it may be included <lb/>in surveys that look at supported protocols or extensions but would <lb/>not expect that attempts be made to degrade the service with large <lb/>numbers of simultaneous connections. <lb/>2.7. Implied Consent: Case Study 2 <lb/>A researcher would like to perform A/B testing for protocol feature <lb/>and how it affects web performance. They have created two versions <lb/>of their software and have instrumented both to report telemetry <lb/>back. These updates will be pushed to users at random by the <lb/>software&apos;s auto-update framework. The telemetry consists only of <lb/>performance metrics and does not contain any personally identifying <lb/>or sensitive information. <lb/>As users expect to receive automatic updates, the effect of changing <lb/>the behaviour of the software is already expected by the user. If <lb/>users have already been informed that data will be reported back to <lb/>the developers of the software, then again the addition of new <lb/>metrics would be expected. There are risks in pushing any new <lb/></body>

			<note place="footnote">Learmonth <lb/>Expires January 9, 2020 <lb/></note>

			<page>[Page 4] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>Safe Internet Measurement <lb/>July 2019 <lb/></note>

			<body>software update, and the A/B testing technique can reduce the number <lb/>of users that may be adversely affected by a bad update. <lb/>The reduced impact should not be used as an excuse for pushing higher <lb/>risk updates, only updates that could be considered appropriate to <lb/>push to all users should be A/B tested. Likewise, not pushing the <lb/>new behaviour to any user should be considered appropriate if some <lb/>users are to remain with the old behavior. <lb/>In the event that something does go wrong with the update, it should <lb/>be easy for a user to discover that they have been part of an <lb/>experiment and roll back the change, allowing for explicit refusal of <lb/>consent to override the presumed implied consent. <lb/>3. Safety Considerations <lb/>3.1. Isolate risk with a dedicated testbed <lb/>Wherever possible, use a testbed. An isolated network means that <lb/>there are no other users sharing the infrastructure you are using for <lb/>your experiments. <lb/>When measuring performance, competing traffic can have negative <lb/>effects on the performance of your test traffic and so the testbed <lb/>approach can also produce more accurate and repeatable results than <lb/>experiments using the public Internet. <lb/>WAN link conditions can be emulated through artificial delays and/or <lb/>packet loss using a tool like [netem]. Competing traffic can also be <lb/>emulated using traffic generators. <lb/>3.2. Be respectful of other&apos;s infrastructure <lb/>If your experiment is designed to trigger a response from <lb/>infrastructure that is not your own, consider what the negative <lb/>consequences of that may be. At the very least your experiment will <lb/>consume bandwidth that may have to be paid for. <lb/>In more extreme circumstances, you could cause traffic to be <lb/>generated that causes legal trouble for the owner of that <lb/>infrastructure. The Internet is a global network crossing many legal <lb/>jurisdictions and so what may be legal for you is not necessarily <lb/>legal for everyone. <lb/>If you are sending a lot of traffic quickly, or otherwise generally <lb/>deviate from typical client behaviour, a network may identify this as <lb/>an attack which means that you will not be collecting results that <lb/>are representative of what a typical client would see. <lb/></body>

			<note place="footnote">Learmonth <lb/>Expires January 9, 2020 <lb/></note>

			<page>[Page 5] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>Safe Internet Measurement <lb/>July 2019 <lb/></note>

			<body>3.2.1. Maintain a &quot;Do Not Scan&quot; list <lb/>When performing active measurements on a shared network, maintain a <lb/>list of hosts that you will never scan regardless of whether they <lb/>appear in your target lists. When developing tools for performing <lb/>active measurement, or traffic generation for use in a larger <lb/>measurement system, ensure that the tool will support the use of a <lb/>&quot;Do Not Scan&quot; list. <lb/>If complaints are made that request you do not generate traffic <lb/>towards a host or network, you must add that host or network to your <lb/>&quot;Do Not Scan&quot; list, even if no explanation is given or the request is <lb/>automated. <lb/>You may ask the requester for their reasoning if it would be useful <lb/>to your experiment. This can also be an opportunity to explain your <lb/>research and offer to share any results that may be of interest. If <lb/>you plan to share the reasoning when publishing your measurement <lb/>results, e.g. in an academic paper, you must seek consent for this <lb/>from the requester. <lb/>Be aware that in publishing your measurement results, it may be <lb/>possible to infer your &quot;Do Not Scan&quot; list from those results. For <lb/>example, if you measured a well-known list of popular websites then <lb/>it would be possible to correlate the results with that list to <lb/>determine which are missing. <lb/>3.3. Data Minimization <lb/>When collecting, using, disclosing, and storing data from a <lb/>measurement, use only the minimal data necessary to perform a task. <lb/>Reducing the amount of data reduces the amount of data that can be <lb/>misused or leaked. <lb/>When deciding on the data to collect, assume that any data collected <lb/>might be disclosed. There are many ways that this could happen, <lb/>through operation security mistakes or compulsion by a judicial <lb/>system. <lb/>When directly instrumenting a protocol to provide metrics to a <lb/>passive observer, see section 6.1 of RFC6973 [RFC6973] for data <lb/>minimalization considerations specific to this use case. <lb/>3.3.1. Discarding Data <lb/>XXX: Discard data that is not required to perform the task. <lb/></body>

			<note place="footnote">Learmonth <lb/>Expires January 9, 2020 <lb/></note>

			<page>[Page 6] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>Safe Internet Measurement <lb/>July 2019 <lb/></note>

			<body>When performing active measurements be sure to only capture traffic <lb/>that you have generated. Traffic may be identified by IP ranges or <lb/>by some token that is unlikely to be used by other users. <lb/>Again, this can help to improve the accuracy and repeatability of <lb/>your experiment. [RFC2544], for performance benchmarking, requires <lb/>that any frames received that were not part of the test traffic are <lb/>discarded and not counted in the results. <lb/>3.3.2. Masking Data <lb/>XXX: Mask data that is not required to perform the task. <lb/>Particularly useful for content of traffic to indicate that either a <lb/>particular class of content existed or did not exist, or the length <lb/>of the content, but not recording the content itself. Can also <lb/>replace content with tokens, or encrypt. <lb/>3.3.3. Reduce Accuracy <lb/>XXX: Binning, categorizing, geoip, noise. <lb/>3.3.4. Data Aggregation <lb/>When collecting data, consider if the granularity can be limited by <lb/>using bins or adding noise. XXX: Differential privacy. <lb/>XXX: Do this at the source, definitely do it before you write to <lb/>disk. <lb/>[Tor.2017-04-001] presents a case-study on the in-memory statistics <lb/>in the software used by the Tor network, as an example. <lb/>4. Risk Analysis <lb/>The benefits should outweigh the risks. Consider auxiliary data <lb/>(e.g. third-party data sets) when assessing the risks. <lb/>5. Security Considerations <lb/>Take reasonable security precautions, e.g. about who has access to <lb/>your data sets or experimental systems. <lb/>6. IANA Considerations <lb/>This document has no actions for IANA. <lb/></body>

			<note place="footnote">Learmonth <lb/>Expires January 9, 2020 <lb/></note>

			<page>[Page 7] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>Safe Internet Measurement <lb/>July 2019 <lb/></note>

			<div type="acknowledgement">7. Acknowledgements <lb/>Many of these considerations are based on those from the <lb/>[TorSafetyBoard] adapted and generalised to be applied to Internet <lb/>research. <lb/>Other considerations are taken from the Menlo Report [MenloReport] <lb/>and its companion document [MenloReportCompanion]. <lb/></div>

			<listBibl>8. Informative References <lb/>[MenloReport] <lb/>Dittrich, D. and E. Kenneally, &quot;The Menlo Report: Ethical <lb/>Principles Guiding Information and Communication <lb/>Technology Research&quot;, August 2012, <lb/>&lt;https://www.caida.org/publications/papers/2012/ <lb/>menlo_report_actual_formatted/&gt;. <lb/>[MenloReportCompanion] <lb/>Bailey, M., Dittrich, D., and E. Kenneally, &quot;Applying <lb/>Ethical Principles to Information and Communication <lb/>Technology Research&quot;, October 2013, <lb/>&lt;https://www.impactcybertrust.org/link_docs/ <lb/>Menlo-Report-Companion.pdf&gt;. <lb/>[netem] <lb/>Stephen, H., &quot;Network emulation with NetEm&quot;, April 2005. <lb/>[PATHspider] <lb/>Learmonth, I., Trammell, B., Kuehlewind, M., and G. <lb/>Fairhurst, &quot;PATHspider: A tool for active measurement of <lb/>path transparency&quot;, DOI 10.1145/2959424.2959441, July <lb/>2016, <lb/>&lt;https://dl.acm.org/citation.cfm?doid=2959424.2959441&gt;. <lb/>[RFC2544] Bradner, S. and J. McQuaid, &quot;Benchmarking Methodology for <lb/>Network Interconnect Devices&quot;, RFC 2544, <lb/>DOI 10.17487/RFC2544, March 1999, <lb/>&lt;https://www.rfc-editor.org/info/rfc2544&gt;. <lb/>[RFC6349] Constantine, B., Forget, G., Geib, R., and R. Schrage, <lb/>&quot;Framework for TCP Throughput Testing&quot;, RFC 6349, <lb/>DOI 10.17487/RFC6349, August 2011, <lb/>&lt;https://www.rfc-editor.org/info/rfc6349&gt;. <lb/>[RFC6973] Cooper, A., Tschofenig, H., Aboba, B., Peterson, J., <lb/>Morris, J., Hansen, M., and R. Smith, &quot;Privacy <lb/>Considerations for Internet Protocols&quot;, RFC 6973, July <lb/>2013, &lt;https://www.rfc-editor.org/info/rfc6937&gt;. <lb/></listBibl>

			<note place="footnote">Learmonth <lb/>Expires January 9, 2020 <lb/></note>

			<page>[Page 8] <lb/></page>

			<note place="headnote">Internet-Draft <lb/>Safe Internet Measurement <lb/>July 2019 <lb/></note>

			<listBibl>[Tor.2017-04-001] <lb/>Herm, K., &quot;Privacy analysis of Tor&apos;s in-memory <lb/>statistics&quot;, Tor Tech Report 2017-04-001, April 2017, <lb/>&lt;https://research.torproject.org/techreports/ <lb/>privacy-in-memory-2017-04-28.pdf&gt;. <lb/>[TorSafetyBoard] <lb/>Tor Project, &quot;Tor Research Safety Board&quot;, <lb/>&lt;https://research.torproject.org/safetyboard/&gt;. <lb/></listBibl>

			Authors&apos; Addresses <lb/>			

			<front>Iain R. Learmonth <lb/>Tor Project <lb/>Email: irl@torproject.org <lb/></front>

			<note place="footnote">Learmonth <lb/>Expires January 9, 2020 <lb/></note>

			<page>[Page 9] </page>


	</text>
</tei>
