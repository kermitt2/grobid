<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>
				Internet Engineering Task Force (IETF) <lb/>S. Banks <lb/>Request for Comments: 7654 <lb/>VSS Monitoring <lb/>Category: Informational <lb/>F. Calabria <lb/>ISSN: 2070-1721 <lb/>Cisco Systems <lb/>G. Czirjak <lb/>R. Machat <lb/>Juniper Networks <lb/>October 2015 <lb/>Benchmarking Methodology for In-Service Software Upgrade (ISSU) <lb/>Abstract <lb/>Modern forwarding devices attempt to minimize any control-and data-<lb/>plane disruptions while performing planned software changes by <lb/>implementing a technique commonly known as In-Service Software <lb/>Upgrade (ISSU). This document specifies a set of common <lb/>methodologies and procedures designed to characterize the overall <lb/>behavior of a Device Under Test (DUT), subject to an ISSU event. <lb/>Status of This Memo <lb/>This document is not an Internet Standards Track specification; it is <lb/>published for informational purposes. <lb/>This document is a product of the Internet Engineering Task Force <lb/>(IETF). It represents the consensus of the IETF community. It has <lb/>received public review and has been approved for publication by the <lb/>Internet Engineering Steering Group (IESG). Not all documents <lb/>approved by the IESG are a candidate for any level of Internet <lb/>Standard; see Section 2 of RFC 5741. <lb/>Information about the current status of this document, any errata, <lb/>and how to provide feedback on it may be obtained at <lb/>http://www.rfc-editor.org/info/rfc7654. <lb/>Banks, et al. <lb/>Informational <lb/>[Page 1] <lb/>RFC 7654 <lb/>Benchmarking Software Upgrade <lb/>October 2015 <lb/>Copyright Notice <lb/>Copyright (c) 2015 IETF Trust and the persons identified as the <lb/>document authors. All rights reserved. <lb/>This document is subject to BCP 78 and the IETF Trust&apos;s Legal <lb/>Provisions Relating to IETF Documents <lb/>(http://trustee.ietf.org/license-info) in effect on the date of <lb/>publication of this document. Please review these documents <lb/>carefully, as they describe your rights and restrictions with respect <lb/>to this document. Code Components extracted from this document must <lb/>include Simplified BSD License text as described in Section 4.e of <lb/>the Trust Legal Provisions and are provided without warranty as <lb/>described in the Simplified BSD License. <lb/>
			</front>

			<div type="toc">
				Table of Contents <lb/>1. Introduction ....................................................3 <lb/>2. Conventions Used in This Document ...............................4 <lb/>3. Generic ISSU Process, Phased Approach ...........................4 <lb/>3.1. Software Download ..........................................5 <lb/>3.2. Software Staging ...........................................6 <lb/>3.3. Upgrade Run ................................................6 <lb/>3.4. Upgrade Acceptance .........................................7 <lb/>4. Test Methodology ................................................7 <lb/>4.1. Test Topology ..............................................7 <lb/>4.2. Load Model .................................................8 <lb/>5. ISSU Test Methodology ...........................................9 <lb/>5.1. Pre-ISSU Recommended Verifications .........................9 <lb/>5.2. Software Staging ...........................................9 <lb/>5.3. Upgrade Run ...............................................10 <lb/>5.4. Post-ISSU Verification ....................................11 <lb/>5.5. ISSU under Negative Stimuli ...............................12 <lb/>6. ISSU Abort and Rollback ........................................12 <lb/>7. Final Report: Data Presentation and Analysis ...................13 <lb/>7.1. Data Collection Considerations ............................14 <lb/>8. Security Considerations ........................................15 <lb/>9. References .....................................................15 <lb/>9.1. Normative References ......................................15 <lb/>9.2. Informative References ....................................16 <lb/>Acknowledgments ...................................................16 <lb/>Authors&apos; Addresses ................................................16 <lb/>
			</div>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 2] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<body>
				1. Introduction <lb/>As required by most Service Provider (SP) network operators, ISSU <lb/>functionality has been implemented by modern forwarding devices to <lb/>upgrade or downgrade from one software version to another with a goal <lb/>of eliminating the downtime of the router and/or the outage of <lb/>service. However, it is noted that while most operators desire <lb/>complete elimination of downtime, minimization of downtime and <lb/>service degradation is often the expectation. <lb/>The ISSU operation may apply in terms of an atomic version change of <lb/>the entire system software or it may be applied in a more modular <lb/>sense, such as for a patch or maintenance upgrade. The procedure <lb/>described herein may be used to verify either approach, as may be <lb/>supported by the vendor hardware and software. <lb/>In support of this document, the desired behavior for an ISSU <lb/>operation can be summarized as follows: <lb/>-The software is successfully migrated from one version to a <lb/>successive version or vice versa. <lb/>-There are no control-plane interruptions throughout the process. <lb/>That is, the upgrade/downgrade could be accomplished while the <lb/>device remains &quot;in service&quot;. It is noted, however, that most <lb/>service providers will still undertake such actions in a <lb/>maintenance window (even in redundant environments) to minimize <lb/>any risk. <lb/>-Interruptions to the forwarding plane are minimal to none. <lb/>-The total time to accomplish the upgrade is minimized, again to <lb/>reduce potential network outage exposure (e.g., an external <lb/>failure event might impact the network as it operates with reduced <lb/>redundancy). <lb/>This document provides a set of procedures to characterize a given <lb/>forwarding device&apos;s ISSU behavior quantitatively, from the <lb/>perspective of meeting the above expectations. <lb/>Different hardware configurations may be expected to be benchmarked, <lb/>but a typical configuration for a forwarding device that supports <lb/>ISSU consists of at least one pair of Routing Processors (RPs) that <lb/>operate in a redundant fashion, and single or multiple forwarding <lb/>engines (line cards) that may or may not be redundant, as well as <lb/>fabric cards or other components as applicable. This does not <lb/>preclude the possibility that a device in question can perform ISSU <lb/>functions through the operation of independent process components, <lb/>
			</body>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 3] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<body>
				which may be upgraded without impact to the overall operation of the <lb/>device. As an example, perhaps the software module involved in SNMP <lb/>functions can be upgraded without impacting other operations. <lb/>The concept of a multi-chassis deployment may also be characterized <lb/>by the current set of proposed methodologies, but the implementation-<lb/>specific details (i.e., process placement and others) are beyond the <lb/>scope of the current document. <lb/>Since most modern forwarding devices, where ISSU would be applicable, <lb/>do consist of redundant RPs and hardware-separated control-plane and <lb/>data-plane functionality, this document will focus on methodologies <lb/>that would be directly applicable to those platforms. It is <lb/>anticipated that the concepts and approaches described herein may be <lb/>readily extended to accommodate other device architectures as well. <lb/>2. Conventions Used in This Document <lb/>The key words &quot;MUST&quot;, &quot;MUST NOT&quot;, &quot;REQUIRED&quot;, &quot;SHALL&quot;, &quot;SHALL NOT&quot;, <lb/>&quot;SHOULD&quot;, &quot;SHOULD NOT&quot;, &quot;RECOMMENDED&quot;, &quot;MAY&quot;, and &quot;OPTIONAL&quot; in this <lb/>document are to be interpreted as described in RFC 2119 [RFC2119]. <lb/>In this document, these words will appear with that interpretation <lb/>only when in ALL CAPS. Lowercase uses of these words are not to be <lb/>interpreted as carrying the significance of RFC 2119. <lb/>3. Generic ISSU Process, Phased Approach <lb/>ISSU may be viewed as the behavior of a device when exposed to a <lb/>planned change in its software functionality. This may mean changes <lb/>to the core operating system, separate processes or daemons, or even <lb/>firmware logic in programmable hardware devices (e.g., Complex <lb/>Programmable Logic Device (CPLD) or Field-Programmable Gate Array <lb/>(FPGA)). The goal of an ISSU implementation is to permit such <lb/>actions with minimal or no disruption to the primary operation of the <lb/>device in question. <lb/>ISSU may be user initiated through direct interaction with the device <lb/>or activated through some automated process on a management system or <lb/>even on the device itself. For the purposes of this document, we <lb/>will focus on the model where the ISSU action is initiated by direct <lb/>user intervention. <lb/>The ISSU process can be viewed as a series of different phases or <lb/>activities, as defined below. For each of these phases, the test <lb/>operator must record the outcome as well as any relevant observations <lb/>(defined further in the present document). Note that, a given vendor <lb/>implementation may or may not permit the abortion of the in-progress <lb/>
			</body>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 4] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<body>
				ISSU at particular stages. There may also be certain restrictions as <lb/>to ISSU availability given certain functional configurations (for <lb/>example, ISSU in the presence of Bidirectional Failure Detection <lb/>(BFD) [RFC5880] may not be supported). It is incumbent upon the test <lb/>operator to ensure that the DUT is appropriately configured to <lb/>provide the appropriate test environment. As with any properly <lb/>orchestrated test effort, the test plan document should reflect these <lb/>and other relevant details and should be written with close attention <lb/>to the expected production operating environment. The combined <lb/>analysis of the results of each phase will characterize the overall <lb/>ISSU process with the main goal of being able to identify and <lb/>quantify any disruption in service (from the data-and control-plane <lb/>perspective) allowing operators to plan their maintenance activities <lb/>with greater precision. <lb/>3.1. Software Download <lb/>In this first phase, the requested software package may be downloaded <lb/>to the router and is typically stored onto a device. The downloading <lb/>of software may be performed automatically by the device as part of <lb/>the upgrade process, or it may be initiated separately. Such <lb/>separation allows an administrator to download the new code inside or <lb/>outside of a maintenance window; it is anticipated that downloading <lb/>new code and saving it to disk on the router will not impact <lb/>operations. In the case where the software can be downloaded outside <lb/>of the actual upgrade process, the administrator should do so; <lb/>downloading software can skew timing results based on factors that <lb/>are often not comparative in nature. Internal compatibility <lb/>verification may be performed by the software running on the DUT, to <lb/>verify the checksum of the files downloaded as well as any other <lb/>pertinent checks. Depending upon vendor implementation, these <lb/>mechanisms may include 1) verifying that the downloaded module(s) <lb/>meet a set of identified prerequisites such as (but not limited to) <lb/>hardware or firmware compatibility or minimum software requirements <lb/>or even 2) ensuring that device is &quot;authorized&quot; to run the target <lb/>software. <lb/>Where such mechanisms are made available by the product, they should <lb/>be verified, by the tester, with the goal of avoiding operational <lb/>issues in production. Verification should include both positive <lb/>verification (ensuring that an ISSU action should be permitted) as <lb/>well as negative tests (creation of scenarios where the verification <lb/>mechanisms would report exceptions). <lb/>
			</body>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 5] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<body>
				3.2. Software Staging <lb/>In this second phase, the requested software package is loaded in the <lb/>pertinent components of a given forwarding device (typically the RP <lb/>in standby state). Internal compatibility verification may be <lb/>performed by the software running on the DUT, as part of the upgrade <lb/>process itself, to verify the checksum of the files downloaded as <lb/>well as any other pertinent checks. Depending upon vendor <lb/>implementation, these mechanisms may include verification that the <lb/>downloaded module(s) meet a set of identified prerequisites such as <lb/>hardware or firmware compatibility or minimum software requirements. <lb/>Where such mechanisms are made available by the product, they should <lb/>be verified, by the tester (again with the goal of avoiding <lb/>operational issues in production). In this case, the execution of <lb/>these checks is within the scope of the upgrade time and should be <lb/>included in the testing results. Once the new software is downloaded <lb/>to the pertinent components of the DUT, the upgrade begins, and the <lb/>DUT begins to prepare itself for upgrade. Depending on the vendor <lb/>implementation, it is expected that redundant hardware pieces within <lb/>the DUT are upgraded, including the backup or secondary RP. <lb/>3.3. Upgrade Run <lb/>In this phase, a switchover of RPs may take place, where one RP is <lb/>now upgraded with the new version of software. More importantly, the <lb/>&quot;Upgrade Run&quot; phase is where the internal changes made to information <lb/>and state (stored on the router, on disk, and in memory) are either <lb/>migrated to the &quot;new&quot; version of code, or transformed/rebuilt to meet <lb/>the standards of the new version of code, and pushed onto the <lb/>appropriate pieces of hardware. It is within this phase that any <lb/>outage(s) on the control or forwarding plane may be expected to be <lb/>observed. This is the critical phase of the ISSU, where the control <lb/>plane should not be impacted and any interruptions to the forwarding <lb/>plane should be minimal to none. <lb/>If any control-or data-plane interruptions are observed within this <lb/>stage, they should be recorded as part of the results document. <lb/>For some implementations, the two stages, as described in Section 3.2 <lb/>and above, may be concatenated into one monolithic operation. In <lb/>that case, the calculation of the respective ISSU time intervals may <lb/>need to be adapted accordingly. <lb/>
			</body>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 6] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<body>
				3.4. Upgrade Acceptance <lb/>In this phase, the new version of software must be running in all the <lb/>physical nodes of the logical forwarding device (RPs and line cards <lb/>as applicable). At this point, configuration control is returned to <lb/>the operator, and normal device operation, i.e., outside of ISSU-<lb/>oriented operation, is resumed. <lb/>4. Test Methodology <lb/>As stated by [RFC6815], the Test Topology Setup must be part of an <lb/>Isolated Test Environment (ITE). <lb/>The reporting of results must take into account the repeatability <lb/>considerations from Section 4 of [RFC2544]. It is RECOMMENDED to <lb/>perform multiple trials and report average results. The results are <lb/>reported in a simple statement including the measured frame loss and <lb/>ISSU impact times. <lb/>4.1. Test Topology <lb/>The hardware configuration of the DUT (Device Under Test) should be <lb/>identical to the one expected to be or currently deployed in <lb/>production in order for the benchmark to have relevance. This would <lb/>include the number of RPs, hardware version, memory, and initial <lb/>software release, any common chassis components, such as fabric <lb/>hardware in the case of a fabric-switching platform, and the specific <lb/>line cards (version, memory, interfaces type, rate, etc.). <lb/>For the control and data plane, differing configuration approaches <lb/>may be utilized. The recommended approach relies on &quot;mimicking&quot; the <lb/>existing production data-and control-plane information, in order to <lb/>emulate all the necessary Layer 1 through Layer 3 communications and, <lb/>if appropriate, the upper-layer characteristics of the network, as <lb/>well as end-to-end traffic/communication pairs. In other words, <lb/>design a representative load model of the production environment and <lb/>deploy a collapsed topology utilizing test tools and/or external <lb/>devices, where the DUT will be tested. Note that, the negative <lb/>impact of ISSU operations is likely to impact scaled, dynamic <lb/>topologies to a greater extent than simpler, static environments. As <lb/>such, this methodology (based upon production configuration) is <lb/>advised for most test scenarios. <lb/>The second, more simplistic approach is to deploy an ITE in which <lb/>endpoints are &quot;directly&quot; connected to the DUT. In this manner, <lb/>control-plane information is kept to a minimum (only connected <lb/>interfaces), and only a basic data-plane of sources and destinations <lb/>is applied. If this methodology is selected, care must be taken to <lb/>
			</body>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 7] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<body>
				understand that the systemic behavior of the ITE may not be identical <lb/>to that experienced by a device in a production network role. That <lb/>is, control-plane validation may be minimal to none with this <lb/>methodology. Consequently, if this approach is chosen, comparison <lb/>with at least one production configuration is recommended in order to <lb/>understand the direct relevance and limitations of the test exercise. <lb/>4.2. Load Model <lb/>In consideration of the defined test topology, a load model must be <lb/>developed to exercise the DUT while the ISSU event is introduced. <lb/>This applied load should be defined in such a manner as to provide a <lb/>granular, repeatable verification of the ISSU impact on transit <lb/>traffic. Sufficient traffic load (rate) should be applied to permit <lb/>timing extrapolations at a minimum granularity of 100 milliseconds, <lb/>e.g., 100 Mbps for a 10 Gbps interface. The use of steady traffic <lb/>streams rather than bursty loads is preferred to simplify analysis. <lb/>The traffic should be patterned to provide a broad range of source <lb/>and destination pairs, which resolve to a variety of FIB (Forwarding <lb/>Information Base) prefix lengths. If the production network <lb/>environment includes multicast traffic or VPNs (L2, L3, or IPsec), it <lb/>is critical to include these in the model. <lb/>For mixed protocol environments (e.g., IPv4 and IPv6), frames should <lb/>be distributed between the different protocols. The distribution <lb/>should approximate the network conditions of deployment. In all <lb/>cases, the details of the mixed protocol distribution must be <lb/>included in the reporting. <lb/>The feature, protocol timing, and other relevant configurations <lb/>should be matched to the expected production environment. Deviations <lb/>from the production templates may be deemed necessary by the test <lb/>operator (for example, certain features may not support ISSU or the <lb/>test bed may not be able to accommodate such). However, the impact <lb/>of any such divergence should be clearly understood, and the <lb/>differences must be recorded in the results documentation. It is <lb/>recommended that a Network Management System (NMS) be deployed, <lb/>preferably similar to that utilized in production. This will allow <lb/>for monitoring of the DUT while it is being tested, both in terms of <lb/>supporting the impact analysis on system resources as well as <lb/>detecting interference with non-transit (management) traffic as a <lb/>result of the ISSU operation. It is suggested that the actual test <lb/>exercise be managed utilizing direct console access to the DUT, if at <lb/>all possible, to avoid the possibility that a network interruption <lb/>impairs execution of the test exercise. <lb/>
			</body>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 8] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<body>
				All in all, the load model should attempt to simulate the production <lb/>network environment to the greatest extent possible in order to <lb/>maximize the applicability of the results generated. <lb/>5. ISSU Test Methodology <lb/>As previously described, for the purposes of this test document, the <lb/>ISSU process is divided into three main phases. The following <lb/>methodology assumes that a suitable test topology has been <lb/>constructed per Section 4. A description of the methodology to be <lb/>applied for each of the above phases follows. <lb/>5.1. Pre-ISSU Recommended Verifications <lb/>The steps of this phase are as follows. <lb/>1. Verify that enough hardware and software resources are available <lb/>to complete the Load operation (e.g., enough disk space). <lb/>2. Verify that the redundancy states between RPs and other nodes are <lb/>as expected (e.g., redundancy on, RPs synchronized). <lb/>3. Verify that the device, if running protocols capable of NSR (Non-<lb/>Stop Routing), is in a &quot;ready&quot; state; that is, that the sync <lb/>between RPs is complete and the system is ready for failover, if <lb/>necessary. <lb/>4. Gather a configuration snapshot of the device and all of its <lb/>applicable components. <lb/>5. Verify that the node is operating in a &quot;steady&quot; state (that is, <lb/>no critical or maintenance function is being currently <lb/>performed). <lb/>6. Note any other operational characteristics that the tester may <lb/>deem applicable to the specific implementation deployed. <lb/>5.2. Software Staging <lb/>The steps of this phase are as follows. <lb/>1. Establish all relevant protocol adjacencies and stabilize routing <lb/>within the test topology. In particular, ensure that the scaled <lb/>levels of the dynamic protocols are dimensioned as specified by <lb/>the test topology plan. <lb/>
			</body>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 9] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<body>
				2. Clear, relevant logs and interface counters to simplify analysis. <lb/>If possible, set logging timestamps to a highly granular mode. <lb/>If the topology includes management systems, ensure that the <lb/>appropriate polling levels have been applied, sessions have been <lb/>established, and the responses are per expectation. <lb/>3. Apply the traffic loads as specified in the load model previously <lb/>developed for this exercise. <lb/>4. Document an operational baseline for the test bed with relevant <lb/>data supporting the above steps (include all relevant load <lb/>characteristics of interest in the topology, e.g., routing load, <lb/>traffic volumes, memory and CPU utilization). <lb/>5. Note the start time (T0) and begin the code change process <lb/>utilizing the appropriate mechanisms as expected to be used in <lb/>production (e.g., active download with TFTP, FTP, SCP, etc., or <lb/>direct install from local or external storage facility). In <lb/>order to ensure that ISSU process timings are not skewed by the <lb/>lack of a network-wide synchronization source, the use of a <lb/>network NTP source is encouraged. <lb/>6. Take note of any logging information and command-line interface <lb/>(CLI) prompts as needed. (This detail will be vendor specific.) <lb/>Respond to any DUT prompts in a timely manner. <lb/>7. Monitor the DUT for the reload of the secondary RP to the new <lb/>software level. Once the secondary has stabilized on the new <lb/>code, note the completion time. The duration of these steps will <lb/>be recorded as &quot;T1&quot;. <lb/>8. Review system logs for any anomalies, check that relevant dynamic <lb/>protocols have remained stable, and note traffic loss if any. <lb/>Verify that deployed management systems have not identified any <lb/>unexpected behavior. <lb/>5.3. Upgrade Run <lb/>The following assumes that the software load step and upgrade step <lb/>are discretely controllable. If not, maintain the aforementioned <lb/>timer and monitor for completion of the ISSU as described below. <lb/>1. Note the start time and initiate the actual upgrade procedure. <lb/>2. Monitor the operation of the secondary route processor while it <lb/>initializes with the new software and assumes mastership of the <lb/>DUT. At this point, pay particular attention to any indications <lb/>of control-plane disruption, traffic impact, or other anomalous <lb/>
			</body>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 10] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<body>
				behavior. Once the DUT has converged upon the new code and <lb/>returned to normal operation, note the completion time and log <lb/>the duration of this step as &quot;T2&quot;. <lb/>3. Review the syslog data in the DUT and neighboring devices for any <lb/>behavior that would be disruptive in a production environment <lb/>(line card reloads, control-plane flaps, etc.). Examine the <lb/>traffic generators for any indication of traffic loss over this <lb/>interval. If the Test Set reported any traffic loss, note the <lb/>number of frames lost as &quot;TPL_frames&quot;, where TPL stands for <lb/>&quot;Total Packet Loss&quot;. If the Test Set also provides outage <lb/>duration, note this as &quot;TPL_time&quot;. (Alternatively, TPL_time may <lb/>be calculated as (TPL / Offered Load) * 1000. The units for <lb/>Offered Load are packets per second; the units for TPL_time are <lb/>milliseconds.) <lb/>4. Verify the DUT status observations as per any NMS managing the <lb/>DUT and its neighboring devices. Document the observed CPU and <lb/>memory statistics both during and after the ISSU upgrade event, <lb/>and ensure that memory and CPU have returned to an expected <lb/>(previously baselined) level. <lb/>5.4. Post-ISSU Verification <lb/>The following describes a set of post-ISSU verification tasks that <lb/>are not directly part of the ISSU process, but are recommended for <lb/>execution in order to validate a successful upgrade. <lb/>1. Configuration delta analysis <lb/>Examine the post-ISSU configurations to determine if any changes <lb/>have occurred either through process error or due to differences <lb/>in the implementation of the upgraded code. <lb/>2. Exhaustive control-plane analysis <lb/>Review the details of the Routing Information Base (RIB) and FIB <lb/>to assess whether any unexpected changes have been introduced in <lb/>the forwarding paths. <lb/>3. Verify that both RPs are up and that the redundancy mechanism for <lb/>the control plane is enabled and fully synchronized. <lb/>4. Verify that no control-plane (protocol) events or flaps were <lb/>detected. <lb/>5. Verify that no L1 and or L2 interface flaps were observed. <lb/>
			</body>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 11] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<body>
				6. Document the hitless operation or presence of an outage based <lb/>upon the counter values provided by the Test Set. <lb/>5.5. ISSU under Negative Stimuli <lb/>As an OPTIONAL Test Case, the operator may want to perform an ISSU <lb/>test while the DUT is under stress by introducing route churn to any <lb/>or all of the involved phases of the ISSU process. <lb/>One approach relies on the operator to gather statistical information <lb/>from the production environment and determine a specific number of <lb/>routes to flap every &apos;fixed&apos; or &apos;variable&apos; interval. Alternatively, <lb/>the operator may wish to simply preselect a fixed number of prefixes <lb/>to flap. As an example, an operator may decide to flap 1% of all the <lb/>BGP routes every minute and restore them 1 minute afterwards. The <lb/>tester may wish to apply this negative stimulus throughout the entire <lb/>ISSU process or, most importantly, during the run phase. It is <lb/>important to ensure that these routes, which are introduced solely <lb/>for stress proposes, must not overlap the ones (per the load model) <lb/>specifically leveraged to calculate the TPL_time (recorded outage). <lb/>Furthermore, there should not be &apos;operator-induced&apos; control-plane <lb/>protocol adjacency flaps for the duration of the test process as it <lb/>may adversely affect the characterization of the entire test <lb/>exercise. For example, triggering IGP adjacency events may force <lb/>recomputation of underlying routing tables with attendant impact to <lb/>the perceived ISSU timings. While not recommended, if such trigger <lb/>events are desired by the test operator, care should be taken to <lb/>avoid the introduction of unexpected anomalies within the test <lb/>harness. <lb/>6. ISSU Abort and Rollback <lb/>Where a vendor provides such support, the ISSU process could be <lb/>aborted for any reason by the operator. However, the end results and <lb/>behavior may depend on the specific phase where the process was <lb/>aborted. While this is implementation dependent, as a general <lb/>recommendation, if the process is aborted during the &quot;Software <lb/>Download&quot; or &quot;Software Staging&quot; phases, no impact to service or <lb/>device functionality should be observed. In contrast, if the process <lb/>is aborted during the &quot;Upgrade Run&quot; or &quot;Upgrade Accept&quot; phases, the <lb/>system may reload and revert back to the previous software release, <lb/>and, as such, this operation may be service affecting. Where vendor <lb/>support is available, the abort/rollback functionality should be <lb/>verified, and the impact, if any, quantified generally following the <lb/>procedures provided above. <lb/>
			</body>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 12] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<body>
				7. Final Report: Data Presentation and Analysis <lb/>All ISSU impact results are summarized in a simple statement <lb/>describing the &quot;ISSU Disruption Impact&quot; including the measured frame <lb/>loss and impact time, where impact time is defined as the time frame <lb/>determined per the TPL_time reported outage. These are considered to <lb/>be the primary data points of interest. <lb/>However, the entire ISSU operational impact should also be considered <lb/>in support of planning for maintenance, and, as such, additional <lb/>reporting points are included. <lb/>Software download / secondary update <lb/>T1 <lb/>Upgrade/Run <lb/>T2 <lb/>ISSU Traffic Disruption (Frame Loss) <lb/>TPL_frames <lb/>ISSU Traffic Impact Time (milliseconds) <lb/>TPL_time <lb/>ISSU Housekeeping Interval <lb/>T3 <lb/>(Time for both RPs up on new code and fully synced -Redundancy <lb/>restored) <lb/>Total ISSU Maintenance Window <lb/>T4 (sum of T1+T2+T3) <lb/>The results reporting must provide the following information: <lb/>-DUT hardware and software detail <lb/>-Test Topology definition and diagram (especially as related to the <lb/>ISSU operation) <lb/>-Load Model description including protocol mixes and any divergence <lb/>from the production environment <lb/>-Time Results as per above <lb/>-Anomalies Observed during ISSU <lb/>-Anomalies Observed in post-ISSU analysis <lb/>
			</body>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 13] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<body>
				It is RECOMMENDED that the following parameters be reported as <lb/>outlined below: <lb/>Parameter <lb/>Units or Examples <lb/>---------------------------------------------------------------<lb/>Traffic Load <lb/>Frames per second and bits per second <lb/>Disruption (average) <lb/>Frames <lb/>Impact Time (average) <lb/>Milliseconds <lb/>Number of trials <lb/>Integer count <lb/>Protocols <lb/>IPv4, IPv6, MPLS, etc. <lb/>Frame Size <lb/>Octets <lb/>Port Media <lb/>Ethernet, Gigabit Ethernet (GbE), <lb/>Packet over SONET (POS), etc. <lb/>Port Speed <lb/>10 Gbps, 1 Gbps, 100 Mbps, etc. <lb/>Interface Encaps <lb/>Ethernet, Ethernet VLAN, PPP, <lb/>High-Level Data Link Control (HDLC), etc. <lb/>Number of Prefixes <lb/>Integer count <lb/> flapped (ON Interval) <lb/>(Optional) # of prefixes / Time (min.) <lb/>flapped (OFF Interval) <lb/>(Optional) # of prefixes / Time (min.) <lb/>Document any configuration deltas that are observed after the ISSU <lb/>upgrade has taken effect. Note differences that are driven by <lb/>changes in the patch or release level, as well as items that are <lb/>aberrant changes due to software faults. In either of these cases, <lb/>any unexpected behavioral changes should be analyzed and a <lb/>determination made as to the impact of the change (be it functional <lb/>variances or operational impacts to existing scripts or management <lb/>mechanisms). <lb/>7.1. Data Collection Considerations <lb/>When a DUT is undergoing an ISSU operation, it&apos;s worth noting that <lb/>the DUT&apos;s data collection and reporting of data, such as counters, <lb/>interface statistics, log messages, etc., may not be accurate. As <lb/>such, one should not rely on the DUT&apos;s data collection methods, but <lb/>rather, should use the test tools and equipment to collect data used <lb/>
			</body>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 14] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<body>
				for reporting in Section 7. Care and consideration should be paid in <lb/>testing or adding new test cases, such that the desired data can be <lb/>collected from the test tools themselves, or other external <lb/>equipment, outside of the DUT itself. <lb/>8. Security Considerations <lb/>All BMWG memos are limited to testing in a laboratory Isolated Test <lb/>Environment (ITE), thus avoiding accidental interruption to <lb/>production networks due to test activities. <lb/>All benchmarking activities are limited to technology <lb/>characterization using controlled stimuli in a laboratory environment <lb/>with dedicated address space and the other constraints [RFC2544]. <lb/>The benchmarking network topology will be an independent test setup <lb/>and MUST NOT be connected to devices that may forward the test <lb/>traffic into a production network or misroute traffic to the test <lb/>management network. <lb/>Further, benchmarking is performed on a &quot;black-box&quot; basis, relying <lb/>solely on measurements observable external to the Device Under Test / <lb/>System Under Test (DUT/SUT). <lb/>Special capabilities should not exist in the DUT/SUT specifically for <lb/>benchmarking purposes. Any implications for network security arising <lb/>from the DUT/SUT should be identical in the lab and in production <lb/>networks. <lb/>
			</body>

			<listBibl>
				9. References <lb/>9.1. Normative References <lb/>[RFC2119] Bradner, S., &quot;Key words for use in RFCs to Indicate <lb/>Requirement Levels&quot;, BCP 14, RFC 2119, <lb/>DOI 10.17487/RFC2119, March 1997, <lb/>&lt;http://www.rfc-editor.org/info/rfc2119&gt;. <lb/>[RFC2544] Bradner, S. and J. McQuaid, &quot;Benchmarking Methodology for <lb/>Network Interconnect Devices&quot;, RFC 2544, <lb/>DOI 10.17487/RFC2544, March 1999, <lb/>&lt;http://www.rfc-editor.org/info/rfc2544&gt;. <lb/>
			</listBibl>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 15] <lb/></page>

			<note place="headnote">RFC 7654 <lb/> Benchmarking Software Upgrade <lb/> October 2015 <lb/></note>

			<listBibl>
				9.2. Informative References <lb/>[RFC5880] Katz, D. and D. Ward, &quot;Bidirectional Forwarding Detection <lb/>(BFD)&quot;, RFC 5880, DOI 10.17487/RFC5880, June 2010, <lb/>&lt;http://www.rfc-editor.org/info/rfc5880&gt;. <lb/>[RFC6815] Bradner, S., Dubray, K., McQuaid, J., and A. Morton, <lb/>&quot;Applicability Statement for RFC 2544: Use on Production <lb/>Networks Considered Harmful&quot;, RFC 6815, <lb/>DOI 10.17487/RFC6815, November 2012, <lb/>&lt;http://www.rfc-editor.org/info/rfc6815&gt;. <lb/>
			</listBibl>

			<div type="acknowledgement">
				Acknowledgments <lb/>The authors wish to thank Vibin Thomas for his valued review and <lb/>feedback. <lb/>
			</div>

			Authors&apos; Addresses <lb/>

			<front>
				Sarah Banks <lb/>VSS Monitoring <lb/>Email: sbanks@encrypted.net <lb/>Fernando Calabria <lb/>Cisco Systems <lb/>Email: fcalabri@cisco.com <lb/>Gery Czirjak <lb/>Juniper Networks <lb/>Email: gczirjak@juniper.net <lb/>Ramdas Machat <lb/>Juniper Networks <lb/>Email: rmachat@juniper.net <lb/>
			</front>

			<note place="footnote">Banks, et al. <lb/>Informational <lb/></note>

			<page>[Page 16] <lb/></page>

	</text>
</tei>
