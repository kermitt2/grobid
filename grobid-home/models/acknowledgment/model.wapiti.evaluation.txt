Recap results for each fold:


====================== Fold 0 ====================== 
Saving model in /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment_nfold_0.wapiti
Training input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment8860774342984624590.train
Evaluation input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment4819500969241712377.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        97.49        73.33        57.89        64.71        19     
<fundingAgency>      82.25        37.5         20           26.09        75     
<grantNumber>        97.08        50           57.14        53.33        14     
<individual>         98.96        93.44        98.28        95.8         58     
<otherInstitution>   98.75        0            0            0            5      
<projectName>        98.12        0            0            0            6      
<researchInstitution> 98.75        100          14.29        25           7      

all (micro avg.)     95.91        67.15        50           57.32        184    
all (macro avg.)     95.91        50.61        35.37        37.85        184    

===== Instance-level results =====

Total expected instances:   21
Correct instances:          5
Instance-level recall:      23.81



====================== Fold 1 ====================== 
Saving model in /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment_nfold_1.wapiti
Training input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment717472843744876289.train
Evaluation input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment2964540760034427112.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        96.62        20           100          33.33        2      
<educationalInstitution> 98.73        0            0            0            2      
<fundingAgency>      89.45        42.86        40.91        41.86        22     
<grantNumber>        98.73        62.5         100          76.92        5      
<individual>         97.47        86.84        97.06        91.67        34     
<otherInstitution>   97.89        33.33        25           28.57        4      
<projectName>        98.31        0            0            0            3      
<researchInstitution> 97.47        0            0            0            5      

all (micro avg.)     96.84        60.24        64.94        62.5         77     
all (macro avg.)     96.84        30.69        45.37        34.04        77     

===== Instance-level results =====

Total expected instances:   21
Correct instances:          5
Instance-level recall:      23.81



====================== Fold 2 ====================== 
Saving model in /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment_nfold_2.wapiti
Training input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment4868861148709957825.train
Evaluation input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment6639905392950154568.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        98.41        50           50           50           6      
<educationalInstitution> 99.47        0            0            0            2      
<fundingAgency>      93.37        71.88        58.97        64.79        39     
<grantName>          99.2         0            0            0            3      
<grantNumber>        95.49        83.33        60.61        70.18        33     
<individual>         97.08        95.74        83.33        89.11        54     
<otherInstitution>   97.08        25           11.11        15.38        9      
<projectName>        99.47        0            0            0            1      
<researchInstitution> 98.94        33.33        33.33        33.33        3      

all (micro avg.)     97.61        79.49        62           69.66        150    
all (macro avg.)     97.61        39.92        33.04        35.87        150    

===== Instance-level results =====

Total expected instances:   21
Correct instances:          6
Instance-level recall:      28.57



====================== Fold 3 ====================== 
Saving model in /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment_nfold_3.wapiti
Training input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment5858785970787010244.train
Evaluation input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment8136687774693158257.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        97.9         57.14        57.14        57.14        7      
<fundingAgency>      90.56        61.11        62.86        61.97        35     
<grantNumber>        97.55        80           61.54        69.57        13     
<individual>         94.41        78.85        89.13        83.67        46     
<otherInstitution>   98.95        50           33.33        40           3      
<researchInstitution> 99.65        0            0            0            1      

all (micro avg.)     96.5         71.03        72.38        71.7         105    
all (macro avg.)     96.5         54.52        50.67        52.06        105    

===== Instance-level results =====

Total expected instances:   21
Correct instances:          6
Instance-level recall:      28.57



====================== Fold 4 ====================== 
Saving model in /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment_nfold_4.wapiti
Training input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment6153151590215105992.train
Evaluation input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment7836100829873817641.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        97.9         50           28.57        36.36        7      
<educationalInstitution> 99.1         50           33.33        40           3      
<fundingAgency>      93.41        59.26        59.26        59.26        27     
<grantNumber>        92.51        55.17        57.14        56.14        28     
<individual>         96.71        93.33        84           88.42        50     
<otherInstitution>   97.31        0            0            0            7      
<projectName>        99.4         0            0            0            2      
<researchInstitution> 99.4         100          33.33        50           3      

all (micro avg.)     96.97        70.91        61.42        65.82        127    
all (macro avg.)     96.97        50.97        36.96        41.27        127    

===== Instance-level results =====

Total expected instances:   21
Correct instances:          6
Instance-level recall:      28.57



====================== Fold 5 ====================== 
Saving model in /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment_nfold_5.wapiti
Training input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment3671488262237719540.train
Evaluation input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment4582724578005224683.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        97.42        37.5         37.5         37.5         8      
<educationalInstitution> 99.23        0            0            0            2      
<fundingAgency>      88.66        59.57        52.83        56           53     
<grantName>          99.74        0            0            0            1      
<grantNumber>        94.07        56.67        62.96        59.65        27     
<individual>         97.16        87.18        85           86.08        40     
<otherInstitution>   98.45        40           40           40           5      
<projectName>        99.23        0            0            0            3      
<researchInstitution> 99.74        0            0            0            0      

all (micro avg.)     96.75        64.62        60.43        62.45        139    
all (macro avg.)     96.75        35.12        34.79        34.9         139    

===== Instance-level results =====

Total expected instances:   21
Correct instances:          4
Instance-level recall:      19.05



====================== Fold 6 ====================== 
Saving model in /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment_nfold_6.wapiti
Training input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment6853162797455780197.train
Evaluation input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment345142530733590899.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        95.94        60           46.15        52.17        13     
<educationalInstitution> 99.63        0            0            0            0      
<fundingAgency>      94.1         54.55        66.67        60           18     
<grantNumber>        97.42        57.14        50           53.33        8      
<individual>         96.31        93.75        86.54        90           52     
<otherInstitution>   98.15        0            0            0            3      
<projectName>        98.89        0            0            0            3      
<researchInstitution> 99.26        50           50           50           2      

all (micro avg.)     97.15        74.73        68.69        71.58        99     
all (macro avg.)     97.15        45.06        42.77        43.64        99     

===== Instance-level results =====

Total expected instances:   21
Correct instances:          7
Instance-level recall:      33.33



====================== Fold 7 ====================== 
Saving model in /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment_nfold_7.wapiti
Training input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment7867130707192458764.train
Evaluation input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment3432741720658720868.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        95.68        40           40           40           10     
<educationalInstitution> 99.64        0            0            0            1      
<fundingAgency>      88.85        60           48.65        53.73        37     
<grantName>          99.64        0            0            0            1      
<grantNumber>        98.2         87.5         63.64        73.68        11     
<individual>         95.32        77.42        80           78.69        30     
<otherInstitution>   97.12        0            0            0            4      
<projectName>        99.28        0            0            0            2      
<researchInstitution> 98.56        0            0            0            4      

all (micro avg.)     96.92        63.86        53           57.92        100    
all (macro avg.)     96.92        29.44        25.81        27.34        100    

===== Instance-level results =====

Total expected instances:   21
Correct instances:          5
Instance-level recall:      23.81



====================== Fold 8 ====================== 
Saving model in /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment_nfold_8.wapiti
Training input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment206229541307873214.train
Evaluation input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment2415789326974765696.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        97.64        56.25        75           64.29        12     
<educationalInstitution> 98.82        0            0            0            3      
<fundingAgency>      92.43        60.53        57.5         58.97        40     
<grantName>          99.76        0            0            0            1      
<grantNumber>        96.22        50           43.75        46.67        16     
<individual>         96.22        89.19        89.19        89.19        74     
<otherInstitution>   97.4         0            0            0            9      
<projectName>        99.29        0            0            0            3      
<researchInstitution> 99.29        0            0            0            1      

all (micro avg.)     97.45        70.95        66.04        68.4         159    
all (macro avg.)     97.45        28.44        29.49        28.79        159    

===== Instance-level results =====

Total expected instances:   21
Correct instances:          1
Instance-level recall:      4.76



====================== Fold 9 ====================== 
Saving model in /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment_nfold_9.wapiti
Training input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment4187619904250891094.train
Evaluation input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment4369479857572886207.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        96.89        66.67        30.77        42.11        13     
<educationalInstitution> 99.15        0            0            0            3      
<fundingAgency>      90.11        28.12        42.86        33.96        21     
<grantName>          99.72        0            0            0            1      
<grantNumber>        98.31        66.67        50           57.14        8      
<individual>         94.92        80.56        93.55        86.57        62     
<otherInstitution>   97.74        0            0            0            6      
<projectName>        99.15        0            0            0            2      
<researchInstitution> 99.44        50           50           50           2      

all (micro avg.)     97.27        62.81        64.41        63.6         118    
all (macro avg.)     97.27        32.45        29.69        29.98        118    

===== Instance-level results =====

Total expected instances:   28
Correct instances:          6
Instance-level recall:      21.43



Summary results: 
Worst fold

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        95.68        40           40           40           10     
<educationalInstitution> 99.64        0            0            0            1      
<fundingAgency>      88.85        60           48.65        53.73        37     
<grantName>          99.64        0            0            0            1      
<grantNumber>        98.2         87.5         63.64        73.68        11     
<individual>         95.32        77.42        80           78.69        30     
<otherInstitution>   97.12        0            0            0            4      
<projectName>        99.28        0            0            0            2      
<researchInstitution> 98.56        0            0            0            4      

all (micro avg.)     96.92        63.86        53           57.92        100    
all (macro avg.)     96.92        29.44        25.81        27.34        100    

===== Instance-level results =====

Total expected instances:   21
Correct instances:          5
Instance-level recall:      23.81

Best fold:

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        97.9         57.14        57.14        57.14        7      
<fundingAgency>      90.56        61.11        62.86        61.97        35     
<grantNumber>        97.55        80           61.54        69.57        13     
<individual>         94.41        78.85        89.13        83.67        46     
<otherInstitution>   98.95        50           33.33        40           3      
<researchInstitution> 99.65        0            0            0            1      

all (micro avg.)     96.5         71.03        72.38        71.7         105    
all (macro avg.)     96.5         54.52        50.67        52.06        105    

===== Instance-level results =====

Total expected instances:   21
Correct instances:          6
Instance-level recall:      28.57


Average over 10 folds: 

label                accuracy     precision    recall       f1           support

<affiliation>        97.19        51.09        52.3         47.76        97     
<educationalInstitution> 79.38        5            3.33         4            16     
<fundingAgency>      90.32        53.54        51.05        51.66        367    
<grantName>          49.81        0            0            0            7      
<grantNumber>        96.56        64.9         60.68        61.66        163    
<individual>         96.46        87.63        88.61        87.92        500    
<otherInstitution>   97.88        14.83        10.94        12.4         55     
<projectName>        89.11        0            0            0            25     
<researchInstitution> 99.05        33.33        18.1         20.83        28     

all (macro avg.)     96.94        39.72        36.39        36.57  

===== Instance-level results =====

Total expected instances:   21.7
Correct instances:          5.1
Instance-level recall:      23.5


N-Fold evaluation for acknowledgment model is realized in 2808538 ms