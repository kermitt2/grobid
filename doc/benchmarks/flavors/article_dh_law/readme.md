# Benchmarks

## Iterations batch 1,2,3 
Date: 2025-10-25

### List of files used for training: 
```
10.1093$1$gerhis$1$ghaf028.training.segmentation.tei.xml
10.3249$1$1868-1581-2-2-clark.training.segmentation.tei.xml
10.5354$1$rti.v1i1.21339.training.segmentation.tei.xml
10.5354$1$rti.v1i2.25648.training.segmentation.tei.xml
10.5771$1$2699-1284-2024-3-149.training.segmentation.tei.xml
10.5771__2699-1284-2020-1-83.training.segmentation.tei.xml
10.6092__issn.2531-6133__10402.training.segmentation.tei.xml
10.12759$1$hsr.6.1981.3.3-17.training.segmentation.tei.xml
10.12775$1$clr.2013.004.training.segmentation.tei.xml
10.12775$1$clr.2013.008.training.segmentation.tei.xml
10.14276$1$2384-8901$1$448.training.segmentation.tei.xml
10.16995$1$lefou.9.training.segmentation.tei.xml
10.19164__ijple.v6i1.1295.training.segmentation.tei.xml
10.19195$1$0524-4544.337.9.training.segmentation.tei.xml
10.25364%2F01.10%3A2023.2.1.training.segmentation.tei.xml
10.25364%2F01.11%3A2024.1.5.training.segmentation.tei.xml
10.26321$1$a.facchinetti.01.2025.05.training.segmentation.tei.xml
10.26321$1$s.marino.01.2025.06.training.segmentation.tei.xml
10.32361$1$2025170222092.training.segmentation.tei.xml
10.34767$1$dp.2024.02.02.training.segmentation.tei.xml
1296-Article Text-4476-1-10-20221017.training.segmentation.tei.xml
```
### List of files used for evaluation: 
```
10.1093$1$gerhis$1$ghae045.training.segmentation.tei.xml
10.3249$1$1868-1581-1-2-gutbrod.training.segmentation.tei.xml
10.5771__2699-1284-2020-1-16.training.segmentation.tei.xml
10.6092__issn.2531-6133__6356.training.segmentation.tei.xml
10.12759$1$hsr.3.1978.1.3-10.training.segmentation.tei.xml
10.12775$1$clr.2013.002.training.segmentation.tei.xml
10.14276$1$2384-8901$1$443.training.segmentation.tei.xml
10.19164__ijple.v6i1.1293.training.segmentation.tei.xml
10.19195$1$0524-4544.337.2.training.segmentation.tei.xml
10.32361$1$201810011903.training.segmentation.tei.xml
1294-Article Text-4464-1-10-20221017.training.segmentation.tei.xml
```
### Results 
```
===== Field-level results =====

label                accuracy     precision    recall       f1           support

<body>               91.57        79.45        82.86        81.12        210    
<cover>              99.79        0            0            0            0      
<footnote>           98.54        64.29        50           56.25        18     
<header>             96.98        36.84        29.17        32.56        24     
<headnote>           91.16        59.86        75.22        66.67        113    
<page>               96.15        85.71        96.88        90.95        192    
<references>         91.05        76.06        82.23        79.02        197    
<toc>                99.79        0            0            0            2      

all (micro avg.)     95.03        75.61        82.41        78.86        756    
all (macro avg.)     95.03        57.46        59.48        58.08        756    

===== Instance-level results =====

Total expected instances:   11
Correct instances:          0
Instance-level recall:      0
```
